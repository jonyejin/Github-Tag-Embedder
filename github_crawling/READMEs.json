{
	"data-science deep-learning machine-learning neural-networks python tensorflow": "Keras: Deep Learning for humans\nThis repository hosts the development of the Keras library.\nRead the documentation at keras.io.\nAbout Keras\nKeras is a deep learning API written in Python,\nrunning on top of the machine learning platform TensorFlow.\nIt was developed with a focus on enabling fast experimentation.\nBeing able to go from idea to result as fast as possible is key to doing good research.\nKeras is:\nSimple -- but not simplistic. Keras reduces developer cognitive load\n    to free you to focus on the parts of the problem that really matter.\nFlexible -- Keras adopts the principle of progressive disclosure of\n    complexity: simple workflows should be quick and easy, while arbitrarily\n    advanced workflows should be possible via a clear path that builds upon\n    what you've already learned.\nPowerful -- Keras provides industry-strength performance and\n    scalability: it is used by organizations and companies including NASA,\n    YouTube, and Waymo.\nKeras & TensorFlow 2\nTensorFlow 2 is an end-to-end, open-source machine learning platform.\nYou can think of it as an infrastructure layer for\ndifferentiable programming.\nIt combines four key abilities:\nEfficiently executing low-level tensor operations on CPU, GPU, or TPU.\nComputing the gradient of arbitrary differentiable expressions.\nScaling computation to many devices, such as clusters of hundreds of GPUs.\nExporting programs (\"graphs\") to external runtimes such as servers, browsers, mobile and embedded devices.\nKeras is the high-level API of TensorFlow 2: an approachable, highly-productive interface\nfor solving machine learning problems,\nwith a focus on modern deep learning. It provides essential abstractions and building blocks for developing\nand shipping machine learning solutions with high iteration velocity.\nKeras empowers engineers and researchers to take full advantage of the scalability\nand cross-platform capabilities of TensorFlow 2: you can run Keras on TPU or on large clusters of GPUs,\nand you can export your Keras models to run in the browser or on a mobile device.\nFirst contact with Keras\nThe core data structures of Keras are layers and models.\nThe simplest type of model is the Sequential model, a linear stack of layers.\nFor more complex architectures, you should use the Keras functional API,\nwhich allows you to build arbitrary graphs of layers or write models entirely from scratch via subclassing.\nHere is the Sequential model:\npython\nfrom tensorflow.keras.models import Sequential\nmodel = Sequential()\nStacking layers is as easy as .add():\npython\nfrom tensorflow.keras.layers import Dense\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dense(units=10, activation='softmax'))\nOnce your model looks good, configure its learning process with .compile():\npython\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])\nIf you need to, you can further configure your optimizer. The Keras philosophy is to keep simple things simple,\nwhile allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code via subclassing).\npython\nmodel.compile(loss=tf.keras.losses.categorical_crossentropy,\n              optimizer=tf.keras.optimizers.SGD(\n                  learning_rate=0.01, momentum=0.9, nesterov=True))\nYou can now iterate on your training data in batches:\npython\nx_train and y_train are Numpy arrays.\nmodel.fit(x_train, y_train, epochs=5, batch_size=32)\nEvaluate your test loss and metrics in one line:\npython\nloss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\nOr generate predictions on new data:\npython\nclasses = model.predict(x_test, batch_size=128)\nWhat you just saw is the most elementary way to use Keras.\nHowever, Keras is also a highly-flexible framework suitable to iterate on state-of-the-art research ideas.\nKeras follows the principle of progressive disclosure of complexity: it makes it easy to get started,\nyet it makes it possible to handle arbitrarily advanced use cases,\nonly requiring incremental learning at each step.\nIn much the same way that you were able to train & evaluate a simple neural network above in a few lines,\nyou can use Keras to quickly develop new training procedures or exotic model architectures.\nHere's a low-level training loop example, combining Keras functionality with the TensorFlow GradientTape:\n```python\nimport tensorflow as tf\nPrepare an optimizer.\noptimizer = tf.keras.optimizers.Adam()\nPrepare a loss function.\nloss_fn = tf.keras.losses.kl_divergence\nIterate over the batches of a dataset.\nfor inputs, targets in dataset:\n    # Open a GradientTape.\n    with tf.GradientTape() as tape:\n        # Forward pass.\n        predictions = model(inputs)\n        # Compute the loss value for this batch.\n        loss_value = loss_fn(targets, predictions)\nGet gradients of loss wrt the weights.\ngradients = tape.gradient(loss_value, model.trainable_weights)\nUpdate the weights of the model.\noptimizer.apply_gradients(zip(gradients, model.trainable_weights))\n```\nFor more in-depth tutorials about Keras, you can check out:\nIntroduction to Keras for engineers\nIntroduction to Keras for researchers\nDeveloper guides\nOther learning resources\nInstallation\nKeras comes packaged with TensorFlow 2 as tensorflow.keras.\nTo start using Keras, simply install TensorFlow 2.\nRelease and compatibility\nKeras has nightly releases (keras-nightly on PyPI)\nand stable releases (keras on PyPI).\nThe nightly Keras releases are usually compatible with the corresponding version\nof the tf-nightly releases\n(e.g. keras-nightly==2.7.0.dev2021100607 should be\nused with tf-nightly==2.7.0.dev2021100607).\nWe don't maintain backward compatibility for nightly releases.\nFor stable releases, each Keras\nversion maps to a specific stable version of TensorFlow.\nThe table below shows the compatibility version mapping\nbetween TensorFlow versions and Keras versions.\nAll the release branches can be found on GitHub.\nAll the release binaries can be found on Pypi.\n| Keras release | Note      | Compatible Tensorflow version |\n| -----------   | ----------- | -----------        |\n| 2.4  | Last stable release of multi-backend Keras | < 2.5\n| 2.5-pre| Pre-release (not formal) for standalone Keras repo | >= 2.5 < 2.6\n| 2.6    | First formal release of standalone Keras.  | >= 2.6 < 2.7\n| 2.7    | (Upcoming release) | >= 2.7 < 2.8\n| nightly|                                            | tf-nightly\nSupport\nYou can ask questions and join the development discussion:\nIn the TensorFlow forum.\nOn the Keras Google group.\nOpening an issue\nYou can also post bug reports and feature requests (only)\nin GitHub issues.\nOpening a PR\nWe welcome contributions! Before opening a PR, please read\nour contributor guide,\nand the API design guideline.",
	"analytics apache apache-superset asf bi business-analytics business-intelligence data-analysis data-analytics data-engineering data-science data-visualization data-viz flask python react sql-editor superset": "Superset\nA modern, enterprise-ready business intelligence web application.\nWhy Superset? |\nSupported Databases |\nInstallation and Configuration |\nRelease Notes |\nGet Involved |\nContributor Guide |\nResources |\nOrganizations Using Superset\nWhy Superset?\nSuperset is a modern data exploration and data visualization platform. Superset can replace or augment proprietary business intelligence tools for many teams. Superset integrates well with a variety of data sources.\nSuperset provides:\nA no-code interface for building charts quickly\nA powerful, web-based SQL Editor for advanced querying\nA lightweight semantic layer for quickly defining custom dimensions and metrics\nOut of the box support for nearly any SQL database or data engine\nA wide array of beautiful visualizations to showcase your data, ranging from simple bar charts to geospatial visualizations\nLightweight, configurable caching layer to help ease database load\nHighly extensible security roles and authentication options\nAn API for programmatic customization\nA cloud-native architecture designed from the ground up for scale\nScreenshots & Gifs\nLarge Gallery of Visualizations\nCraft Beautiful, Dynamic Dashboards\nNo-Code Chart Builder\nPowerful SQL Editor\nSupported Databases\nSuperset can query data from any SQL-speaking datastore or data engine (Presto, Trino, Athena, and more) that has a Python DB-API driver and a SQLAlchemy dialect.\nHere are some of the major database solutions that are supported:\nA more comprehensive list of supported databases along with the configuration instructions can be found here.\nWant to add support for your datastore or data engine? Read more here about the technical requirements.\nInstallation and Configuration\nExtended documentation for Superset\nGet Involved\nAsk and answer questions on StackOverflow using the apache-superset tag\nJoin our community's Slack\n  and please read our Slack Community Guidelines\nJoin our dev@superset.apache.org Mailing list\nContributor Guide\nInterested in contributing? Check out our\nCONTRIBUTING.md\nto find resources around contributing along with a detailed guide on\nhow to set up a development environment.\nResources\nSuperset 2.0!\n- Superset 2.0 Meetup\n- Superset 2.0 Release Notes\nUnderstanding the Superset Points of View\n- The Case for Dataset-Centric Visualization\n- Understanding the Superset Semantic Layer\nGetting Started with Superset\nSuperset in 2 Minutes using Docker Compose\nInstalling Database Drivers\nBuilding New Database Connectors\nCreate Your First Dashboard\nComprehensive Tutorial for Contributing Code to Apache Superset\nResources to master Superset by Preset\nDeploying Superset\nOfficial Docker image\nHelm Chart\nRecordings of Past Superset Community Events\nMixed Time Series Charts \nHow the Bing Team Customized Superset for the Internal Self-Serve Data & Analytics Platform\nLive Demo: Visualizing MongoDB and Pinot Data using Trino\nIntroduction to the Superset API\nBuilding a Database Connector for Superset\nVisualizations\nBuilding Custom Viz Plugins\nManaging and Deploying Custom Viz Plugins\nWhy Apache Superset is Betting on Apache ECharts\nSuperset API",
	"data-science education machine-learning machine-learning-algorithms machinelearning machinelearning-python ml python r scikit-learn scikit-learn-python": "Machine Learning for Beginners - A Curriculum\n\ud83c\udf0d Travel around the world as we explore Machine Learning by means of world cultures \ud83c\udf0d\nAzure Cloud Advocates at Microsoft are pleased to offer a 12-week, 26-lesson curriculum all about Machine Learning. In this curriculum, you will learn about what is sometimes called classic machine learning, using primarily Scikit-learn as a library and avoiding deep learning, which is covered in our forthcoming 'AI for Beginners' curriculum. Pair these lessons with our 'Data Science for Beginners' curriculum, as well!\nTravel with us around the world as we apply these classic techniques to data from many areas of the world. Each lesson includes pre- and post-lesson quizzes, written instructions to complete the lesson, a solution, an assignment, and more. Our project-based pedagogy allows you to learn while building, a proven way for new skills to 'stick'.\n\u270d\ufe0f Hearty thanks to our authors Jen Looper, Stephen Howell, Francesca Lazzeri, Tomomi Imura, Cassie Breviu, Dmitry Soshnikov, Chris Noring, Anirban Mukherjee, Ornella Altunyan, and Amy Boyd\n\ud83c\udfa8 Thanks as well to our illustrators Tomomi Imura, Dasani Madipalli, and Jen Looper\n\ud83d\ude4f Special thanks \ud83d\ude4f to our Microsoft Student Ambassador authors, reviewers, and content contributors, notably Rishit Dagli, Muhammad Sakib Khan Inan, Rohan Raj, Alexandru Petrescu, Abhishek Jaiswal, Nawrin Tabassum, Ioan Samuila, and Snigdha Agarwal\n\ud83e\udd29 Extra gratitude to Microsoft Student Ambassador Eric Wanjau for our R lessons!\nGetting Started\nStudents, to use this curriculum, fork the entire repo to your own GitHub account and complete the exercises on your own or with a group:\nStart with a pre-lecture quiz.\nRead the lecture and complete the activities, pausing and reflecting at each knowledge check.\nTry to create the projects by comprehending the lessons rather than running the solution code; however that code is available in the /solution folders in each project-oriented lesson.\nTake the post-lecture quiz.\nComplete the challenge.\nComplete the assignment.\nAfter completing a lesson group, visit the Discussion Board and \"learn out loud\" by filling out the appropriate PAT rubric. A 'PAT' is a Progress Assessment Tool that is a rubric you fill out to further your learning. You can also react to other PATs so we can learn together.\nFor further study, we recommend following these Microsoft Learn modules and learning paths.\nTeachers, we have included some suggestions on how to use this curriculum.\nMeet the Team\nGif by Mohit Jaisal\n\ud83c\udfa5 Click the image above for a video about the project and the folks who created it!\nPedagogy\nWe have chosen two pedagogical tenets while building this curriculum: ensuring that it is hands-on project-based and that it includes frequent quizzes. In addition, this curriculum has a common theme to give it cohesion.\nBy ensuring that the content aligns with projects, the process is made more engaging for students and retention of concepts will be augmented. In addition, a low-stakes quiz before a class sets the intention of the student towards learning a topic, while a second quiz after class ensures further retention. This curriculum was designed to be flexible and fun and can be taken in whole or in part. The projects start small and become increasingly complex by the end of the 12-week cycle. This curriculum also includes a postscript on real-world applications of ML, which can be used as extra credit or as a basis for discussion.\nFind our Code of Conduct, Contributing, and Translation guidelines. We welcome your constructive feedback!\nEach lesson includes:\noptional sketchnote\noptional supplemental video\npre-lecture warmup quiz\nwritten lesson\nfor project-based lessons, step-by-step guides on how to build the project\nknowledge checks\na challenge\nsupplemental reading\nassignment\npost-lecture quiz\nA note about languages: These lessons are primarily written in Python, but many are also available in R. To complete an R lesson, go to the /solution folder and look for R lessons. They include an .rmd extension that represents an R Markdown file which can be simply defined as an embedding of code chunks (of R or other languages) and a YAML header (that guides how to format outputs such as PDF) in a Markdown document. As such, it serves as an exemplary authoring framework for data science since it allows you to combine your code, its output, and your thoughts by allowing you to write them down in Markdown. Moreover, R Markdown documents can be rendered to output formats such as PDF, HTML, or Word.\nA note about quizzes: All quizzes are contained in this app, for 52 total quizzes of three questions each. They are linked from within the lessons but the quiz app can be run locally; follow the instruction in the quiz-app folder.\n| Lesson Number |                             Topic                              |                   Lesson Grouping                   | Learning Objectives                                                                                                             |                                                              Linked Lesson                                                               |                        Author                        |\n| :-----------: | :------------------------------------------------------------: | :-------------------------------------------------: | ------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------: |\n|      01       |                Introduction to machine learning                |      Introduction       | Learn the basic concepts behind machine learning                                                                                |                                             Lesson                                             |                       Muhammad                       |\n|      02       |                The History of machine learning                 |      Introduction       | Learn the history underlying this field                                                                                         |                                            Lesson                                            |                     Jen and Amy                      |\n|      03       |                 Fairness and machine learning                  |      Introduction       | What are the important philosophical issues around fairness that students should consider when building and applying ML models? |                                              Lesson                                               |                        Tomomi                        |\n|      04       |                Techniques for machine learning                 |      Introduction       | What techniques do ML researchers use to build ML models?                                                                       |                                          Lesson                                           |                    Chris and Jen                     |\n|      05       |                   Introduction to regression                   |        Regression         | Get started with Python and Scikit-learn for regression models                                                                  |         PythonR         |      JenEric Wanjau       |\n|      06       |                North American pumpkin prices \ud83c\udf83                |        Regression         | Visualize and clean data in preparation for ML                                                                                  |          PythonR          |      JenEric Wanjau       |\n|      07       |                North American pumpkin prices \ud83c\udf83                |        Regression         | Build linear and polynomial regression models                                                                                   |        PythonR        |      Jen and DmitryEric Wanjau       |\n|      08       |                North American pumpkin prices \ud83c\udf83                |        Regression         | Build a logistic regression model                                                                                               |     Python R      |      JenEric Wanjau       |\n|      09       |                          A Web App \ud83d\udd0c                          |           Web App            | Build a web app to use your trained model                                                                                       |                                                 Python                                                  |                         Jen                          |\n|      10       |                 Introduction to classification                 |    Classification     | Clean, prep, and visualize your data; introduction to classification                                                            |  Python R  | Jen and CassieEric Wanjau |\n|      11       |             Delicious Asian and Indian cuisines \ud83c\udf5c             |    Classification     | Introduction to classifiers                                                                                                     |  PythonR | Jen and CassieEric Wanjau |\n|      12       |             Delicious Asian and Indian cuisines \ud83c\udf5c             |    Classification     | More classifiers                                                                                                                |  PythonR | Jen and CassieEric Wanjau |\n|      13       |             Delicious Asian and Indian cuisines \ud83c\udf5c             |    Classification     | Build a recommender web app using your model                                                                                    |                                              Python                                              |                         Jen                          |\n|      14       |                   Introduction to clustering                   |        Clustering         | Clean, prep, and visualize your data; Introduction to clustering                                                                |          PythonR         |      JenEric Wanjau       |\n|      15       |              Exploring Nigerian Musical Tastes \ud83c\udfa7              |        Clustering         | Explore the K-Means clustering method                                                                                           |            PythonR           |      JenEric Wanjau       |\n|      16       |        Introduction to natural language processing \u2615\ufe0f         |   Natural language processing    | Learn the basics about NLP by building a simple bot                                                                             |                                             Python                                              |                       Stephen                        |\n|      17       |                      Common NLP Tasks \u2615\ufe0f                      |   Natural language processing    | Deepen your NLP knowledge by understanding common tasks required when dealing with language structures                          |                                                    Python                                                     |                       Stephen                        |\n|      18       |             Translation and sentiment analysis \u2665\ufe0f              |   Natural language processing    | Translation and sentiment analysis with Jane Austen                                                                             |                                            Python                                             |                       Stephen                        |\n|      19       |                  Romantic hotels of Europe \u2665\ufe0f                  |   Natural language processing    | Sentiment analysis with hotel reviews 1                                                                                         |                                               Python                                                |                       Stephen                        |\n|      20       |                  Romantic hotels of Europe \u2665\ufe0f                  |   Natural language processing    | Sentiment analysis with hotel reviews 2                                                                                         |                                               Python                                                |                       Stephen                        |\n|      21       |            Introduction to time series forecasting             |        Time series        | Introduction to time series forecasting                                                                                         |                                             Python                                              |                      Francesca                       |\n|      22       | \u26a1\ufe0f World Power Usage \u26a1\ufe0f - time series forecasting with ARIMA |        Time series        | Time series forecasting with ARIMA                                                                                              |                                                 Python                                                 |                      Francesca                       |\n|      23       |  \u26a1\ufe0f World Power Usage \u26a1\ufe0f - time series forecasting with SVR  |        Time series        | Time series forecasting with Support Vector Regressor                                                                           |                                                  Python                                                  |                       Anirban                        |\n|      24       |             Introduction to reinforcement learning             | Reinforcement learning | Introduction to reinforcement learning with Q-Learning                                                                          |                                             Python                                              |                        Dmitry                        |\n|      25       |                 Help Peter avoid the wolf! \ud83d\udc3a                  | Reinforcement learning | Reinforcement learning Gym                                                                                                      |                                                Python                                                 |                        Dmitry                        |\n|  Postscript   |            Real-World ML scenarios and applications            |      ML in the Wild       | Interesting and revealing real-world applications of classical ML                                                               |                                             Lesson                                              |                         Team                         |\nOffline access\nYou can run this documentation offline by using Docsify. Fork this repo, install Docsify on your local machine, and then in the root folder of this repo, type docsify serve. The website will be served on port 3000 on your localhost: localhost:3000.\nPDFs\nFind a pdf of the curriculum with links here.\nHelp Wanted!\nWould you like to contribute a translation? Please read our translation guidelines and add a templated issue to manage the workload here.\nOther Curricula\nOur team produces other curricula! Check out:\nWeb Dev for Beginners\nIoT for Beginners\nData Science for Beginners\nAI for Beginners",
	"alignment data-analysis data-science flexible pandas python": "pandas: powerful Python data analysis toolkit\nWhat is it?\npandas is a Python package that provides fast, flexible, and expressive data\nstructures designed to make working with \"relational\" or \"labeled\" data both\neasy and intuitive. It aims to be the fundamental high-level building block for\ndoing practical, real world data analysis in Python. Additionally, it has\nthe broader goal of becoming the most powerful and flexible open source data\nanalysis / manipulation tool available in any language. It is already well on\nits way towards this goal.\nMain Features\nHere are just a few of the things that pandas does well:\nEasy handling of missing data (represented as\n    NaN, NA, or NaT) in floating point as well as non-floating point data\nSize mutability: columns can be inserted and\n    deleted from DataFrame and higher dimensional\n    objects\nAutomatic and explicit data alignment: objects can\n    be explicitly aligned to a set of labels, or the user can simply\n    ignore the labels and let Series, DataFrame, etc. automatically\n    align the data for you in computations\nPowerful, flexible group by functionality to perform\n    split-apply-combine operations on data sets, for both aggregating\n    and transforming data\nMake it easy to convert ragged,\n    differently-indexed data in other Python and NumPy data structures\n    into DataFrame objects\nIntelligent label-based slicing, fancy\n    indexing, and subsetting of\n    large data sets\nIntuitive merging and joining data\n    sets\nFlexible reshaping and pivoting of\n    data sets\nHierarchical labeling of axes (possible to have multiple\n    labels per tick)\nRobust IO tools for loading data from flat files\n    (CSV and delimited), Excel files, databases,\n    and saving/loading data from the ultrafast HDF5 format\nTime series-specific functionality: date range\n    generation and frequency conversion, moving window statistics,\n    date shifting and lagging\nWhere to get it\nThe source code is currently hosted on GitHub at:\nhttps://github.com/pandas-dev/pandas\nBinary installers for the latest released version are available at the Python\nPackage Index (PyPI) and on Conda.\nsh\nconda\nconda install pandas\nsh\nor PyPI\npip install pandas\nDependencies\nNumPy - Adds support for large, multi-dimensional arrays, matrices and high-level mathematical functions to operate on these arrays\npython-dateutil - Provides powerful extensions to the standard datetime module\npytz - Brings the Olson tz database into Python which allows accurate and cross platform timezone calculations\nSee the full installation instructions for minimum supported versions of required, recommended and optional dependencies.\nInstallation from sources\nTo install pandas from source you need Cython in addition to the normal\ndependencies above. Cython can be installed from PyPI:\nsh\npip install cython\nIn the pandas directory (same one where you found this file after\ncloning the git repo), execute:\nsh\npython setup.py install\nor for installing in development mode:\nsh\npython -m pip install -e . --no-build-isolation --no-use-pep517\nor alternatively\nsh\npython setup.py develop\nSee the full instructions for installing from source.\nLicense\nBSD 3\nDocumentation\nThe official documentation is hosted on PyData.org: https://pandas.pydata.org/pandas-docs/stable\nBackground\nWork on pandas started at AQR (a quantitative hedge fund) in 2008 and\nhas been under active development since then.\nGetting Help\nFor usage questions, the best place to go to is StackOverflow.\nFurther, general questions and discussions can also take place on the pydata mailing list.\nDiscussion and Development\nMost development discussions take place on GitHub in this repo. Further, the pandas-dev mailing list can also be used for specialized discussions or design issues, and a Slack channel is available for quick development related questions.\nContributing to pandas \nAll contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome.\nA detailed overview on how to contribute can be found in the contributing guide.\nIf you are simply looking to start working with the pandas codebase, navigate to the GitHub \"issues\" tab and start looking through interesting issues. There are a number of issues listed under Docs and good first issue where you could start out.\nYou can also triage issues which may include reproducing bug reports, or asking for vital information such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to subscribe to pandas on CodeTriage.\nOr maybe through using pandas you have an idea of your own or are looking for something in the documentation and thinking \u2018this can be improved\u2019...you can do something about it!\nFeel free to ask questions on the mailing list or on Slack.\nAs contributors and maintainers to this project, you are expected to abide by pandas' code of conduct. More information can be found at: Contributor Code of Conduct",
	"data-engineering data-science deep-learning machine-learning mlops natural-language-processing python pytorch": "Made With ML\nApplied ML \u00b7 MLOps \u00b7 Production\nJoin 30K+ developers in learning how to responsibly deliver value with ML.\n\ud83d\udd25\u00a0 Among the top MLOps repositories on GitHub\n\nFoundations\nLearn the foundations of machine learning through intuitive explanations, clean code and visualizations.\nLessons: https://madewithml.com/#foundations\nCode: GokuMohandas/Made-With-ML/tree/master/notebooks\n\ud83d\udee0\u00a0 Toolkit\n\ud83d\udd25\u00a0 Machine Learning\n\ud83e\udd16\u00a0 Deep Learning\nNotebooks\nLinear Regression\nCNNs\nPython\nLogistic Regression\nEmbeddings\nNumPy\nNeural Network\nRNNs\nPandas\nData Quality\nAttention\nPyTorch\nUtilities\nTransformers\nMLOps course\nLearn how to combine machine learning with software engineering to build production-grade applications.\nLessons: https://madewithml.com/#mlops\nCode: GokuMohandas/mlops-course\n\ud83c\udfa8\u00a0 Design\n\ud83d\udcbb\u00a0 Developing\u00a0\n\u267b\ufe0f\u00a0 Reproducibility\nProduct\nPackaging\nGit\nEngineering\nOrganization\nPre-commit\nProject\nLogging\nVersioning\n\ud83d\udd22\u00a0 Data\nDocumentation\nDocker\nExploration\nStyling\n\ud83d\ude80\u00a0 Production\nLabeling\nMakefile\nDashboard\nPreprocessing\n\ud83d\udce6\u00a0 Serving\nCI/CD\nSplitting\nCommand-line\nMonitoring\nAugmentation\nRESTful API\nSystems design\n\ud83d\udcc8\u00a0 Modeling\n\u2705\u00a0 Testing\n\u2388\u00a0 Data engineering\nBaselines\nCode\nData stack\nEvaluation\nData\nOrchestration\nExperiment tracking\nModels\nFeature store\nOptimization\n\u00a0\n\u00a0\nMission\nML is not a separate industry, instead, it's a powerful way of thinking about data, so let's make sure we have a solid foundation before we start changing the world with it. Made With ML is our medium to catalyze this goal and though we're off to great start, we still have a long way to go.\nWho is this content for?\nSoftware engineers looking to learn ML and become even better software engineers.\nData scientists who want to learn how to responsibly deliver value with ML.\nCollege graduates looking to learn the practical skills they'll need for the industry.\nProduct Managers who want to develop a technical foundation for ML applications.\nWhat makes this content unique?\nhands-on: If you search production ML or MLOps online, you'll find great blog posts and tweets. But in order to really understand these concepts, you need to implement them. Unfortunately, you don\u2019t see a lot of the inner workings of running production ML because of scale, proprietary content & expensive tools. However, Made With ML is free, open and live which makes it a perfect learning opportunity for the community.\nintuition-first: We will never jump straight to code. In every lesson, we will develop intuition for the concepts and think about it from a product perspective.\nsoftware engineering: This course isn't just about ML. In fact, it's mostly about clean software engineering! We'll cover important concepts like versioning, testing, logging, etc. that really makes something production-grade product.\nfocused yet holistic: For every concept, we'll not only cover what's most important for our specific task (this is the case study aspect) but we'll also cover related methods (this is the guide aspect) which may prove to be useful in other situations.\nWho is the author?\nI've built and deployed large scale ML systems at Apple, as well as smaller systems with constraints at startups. I currently work closely with early-stage and F500 companies in helping them deliver value with ML while diving into the best and bespoke practices of this rapidly evolving space. I want to share this knowledge with the rest of the world so we can accelerate progress in this space.\nConnect with me on Twitter and LinkedIn\nWhy is this free?\nWhile this content is for everyone, it's especially targeted towards people who don't have as much opportunity to learn. I believe that creativity and intelligence are randomly distributed while opportunities are siloed. I want to enable more people to create and contribute to innovation.\nTo cite this content, please use:\nbibtex\n@misc{madewithml,\n    author       = {Goku Mohandas},\n    title        = {Made With ML},\n    howpublished = {\\url{https://madewithml.com/}},\n    year         = {2022}\n}",
	"ai artificial-intelligence cython data-science deep-learning entity-linking machine-learning named-entity-recognition natural-language-processing neural-network neural-networks nlp nlp-library python spacy text-classification tokenization": "spaCy: Industrial-strength NLP\nspaCy is a library for advanced Natural Language Processing in Python and\nCython. It's built on the very latest research, and was designed from day one to\nbe used in real products.\nspaCy comes with\npretrained pipelines and\ncurrently supports tokenization and training for 70+ languages. It features\nstate-of-the-art speed and neural network models for tagging,\nparsing, named entity recognition, text classification and more,\nmulti-task learning with pretrained transformers like BERT, as well as a\nproduction-ready training system and easy\nmodel packaging, deployment and workflow management. spaCy is commercial\nopen-source software, released under the MIT license.\n\ud83d\udcab Version 3.4 out now!\nCheck out the release notes here.\n\ud83d\udcd6 Documentation\n| Documentation                                                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                              |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| \u2b50\ufe0f spaCy 101                                                                                                                                                                                                       | New to spaCy? Here's everything you need to know!                                                                                                                                                                                                                                                                            |\n| \ud83d\udcda Usage Guides                                                                                                                                                                                                     | How to use spaCy and its features.                                                                                                                                                                                                                                                                                           |\n| \ud83d\ude80 New in v3.0                                                                                                                                                                                                      | New features, backwards incompatibilities and migration guide.                                                                                                                                                                                                                                                               |\n| \ud83e\ude90 Project Templates                                                                                                                                                                                                | End-to-end workflows you can clone, modify and run.                                                                                                                                                                                                                                                                          |\n| \ud83c\udf9b API Reference                                                                                                                                                                                                     | The detailed reference for spaCy's API.                                                                                                                                                                                                                                                                                      |\n| \ud83d\udce6 Models                                                                                                                                                                                                           | Download trained pipelines for spaCy.                                                                                                                                                                                                                                                                                        |\n| \ud83c\udf0c Universe                                                                                                                                                                                                         | Plugins, extensions, demos and books from the spaCy ecosystem.                                                                                                                                                                                                                                                               |\n| \ud83d\udc69\u200d\ud83c\udfeb Online Course                                                                                                                                                                                                    | Learn spaCy in this free and interactive online course.                                                                                                                                                                                                                                                                      |\n| \ud83d\udcfa Videos                                                                                                                                                                                                           | Our YouTube channel with video tutorials, talks and more.                                                                                                                                                                                                                                                                    |\n| \ud83d\udee0 Changelog                                                                                                                                                                                                         | Changes and version history.                                                                                                                                                                                                                                                                                                 |\n| \ud83d\udc9d Contribute                                                                                                                                                                                                       | How to contribute to the spaCy project and code base.                                                                                                                                                                                                                                                                        |\n|  | Get a custom spaCy pipeline, tailor-made for your NLP problem by spaCy's core developers. Streamlined, production-ready, predictable and maintainable. Start by completing our 5-minute questionnaire to tell us what you need and we'll be in touch! Learn more \u2192 |\n\ud83d\udcac Where to ask questions\nThe spaCy project is maintained by the spaCy team.\nPlease understand that we won't be able to provide individual support via email.\nWe also believe that help is much more valuable if it's shared publicly, so that\nmore people can benefit from it.\n| Type                            | Platforms                               |\n| ------------------------------- | --------------------------------------- |\n| \ud83d\udea8 Bug Reports              | GitHub Issue Tracker                  |\n| \ud83c\udf81 Feature Requests & Ideas | GitHub Discussions                    |\n| \ud83d\udc69\u200d\ud83d\udcbb Usage Questions          | GitHub Discussions \u00b7 Stack Overflow |\n| \ud83d\uddef General Discussion        | GitHub Discussions                    |\nFeatures\nSupport for 70+ languages\nTrained pipelines for different languages and tasks\nMulti-task learning with pretrained transformers like BERT\nSupport for pretrained word vectors and embeddings\nState-of-the-art speed\nProduction-ready training system\nLinguistically-motivated tokenization\nComponents for named entity recognition, part-of-speech-tagging, dependency parsing, sentence segmentation, text classification, lemmatization, morphological analysis, entity linking and more\nEasily extensible with custom components and attributes\nSupport for custom models in PyTorch, TensorFlow and other frameworks\nBuilt in visualizers for syntax and NER\nEasy model packaging, deployment and workflow management\nRobust, rigorously evaluated accuracy\n\ud83d\udcd6 For more details, see the\nfacts, figures and benchmarks.\n\u23f3 Install spaCy\nFor detailed installation instructions, see the\ndocumentation.\nOperating system: macOS / OS X \u00b7 Linux \u00b7 Windows (Cygwin, MinGW, Visual\n  Studio)\nPython version: Python 3.6+ (only 64 bit)\nPackage managers: pip \u00b7 conda (via conda-forge)\npip\nUsing pip, spaCy releases are available as source packages and binary wheels.\nBefore you install spaCy and its dependencies, make sure that\nyour pip, setuptools and wheel are up to date.\nbash\npip install -U pip setuptools wheel\npip install spacy\nTo install additional data tables for lemmatization and normalization you can\nrun pip install spacy[lookups] or install\nspacy-lookups-data\nseparately. The lookups package is needed to create blank models with\nlemmatization data, and to lemmatize in languages that don't yet come with\npretrained models and aren't powered by third-party libraries.\nWhen using pip it is generally recommended to install packages in a virtual\nenvironment to avoid modifying system state:\nbash\npython -m venv .env\nsource .env/bin/activate\npip install -U pip setuptools wheel\npip install spacy\nconda\nYou can also install spaCy from conda via the conda-forge channel. For the\nfeedstock including the build recipe and configuration, check out\nthis repository.\nbash\nconda install -c conda-forge spacy\nUpdating spaCy\nSome updates to spaCy may require downloading new statistical models. If you're\nrunning spaCy v2.0 or higher, you can use the validate command to check if\nyour installed models are compatible and if not, print details on how to update\nthem:\nbash\npip install -U spacy\npython -m spacy validate\nIf you've trained your own models, keep in mind that your training and runtime\ninputs must match. After updating spaCy, we recommend retraining your models\nwith the new version.\n\ud83d\udcd6 For details on upgrading from spaCy 2.x to spaCy 3.x, see the\nmigration guide.\n\ud83d\udce6 Download model packages\nTrained pipelines for spaCy can be installed as Python packages. This\nmeans that they're a component of your application, just like any other module.\nModels can be installed using spaCy's download\ncommand, or manually by pointing pip to a path or URL.\n| Documentation              |                                                                  |\n| -------------------------- | ---------------------------------------------------------------- |\n| Available Pipelines  | Detailed pipeline descriptions, accuracy figures and benchmarks. |\n| Models Documentation | Detailed usage and installation instructions.                    |\n| Training             | How to train your own pipelines on your data.                    |\nbash\nDownload best-matching version of specific model for your spaCy installation\npython -m spacy download en_core_web_sm\npip install .tar.gz archive or .whl from path or URL\npip install /Users/you/en_core_web_sm-3.0.0.tar.gz\npip install /Users/you/en_core_web_sm-3.0.0-py3-none-any.whl\npip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\nLoading and using models\nTo load a model, use spacy.load()\nwith the model name or a path to the model data directory.\npython\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"This is a sentence.\")\nYou can also import a model directly via its full name and then call its\nload() method with no arguments.\npython\nimport spacy\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\ndoc = nlp(\"This is a sentence.\")\n\ud83d\udcd6 For more info and examples, check out the\nmodels documentation.\n\u2692 Compile from source\nThe other way to install spaCy is to clone its\nGitHub repository and build it from\nsource. That is the common way if you want to make changes to the code base.\nYou'll need to make sure that you have a development environment consisting of a\nPython distribution including header files, a compiler,\npip,\nvirtualenv and\ngit installed. The compiler part is the trickiest. How to\ndo that depends on your system.\n| Platform    |                                                                                                                                                                                                                                                                     |\n| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Ubuntu  | Install system-level dependencies via apt-get: sudo apt-get install build-essential python-dev git .                                                                                                                                                            |\n| Mac     | Install a recent version of XCode, including the so-called \"Command Line Tools\". macOS and OS X ship with Python and git preinstalled.                                                                                        |\n| Windows | Install a version of the Visual C++ Build Tools or Visual Studio Express that matches the version that was used to compile your Python interpreter. |\nFor more details\nand instructions, see the documentation on\ncompiling spaCy from source and the\nquickstart widget to get the right\ncommands for your platform and Python version.\nbash\ngit clone https://github.com/explosion/spaCy\ncd spaCy\npython -m venv .env\nsource .env/bin/activate\nmake sure you are using the latest pip\npython -m pip install -U pip setuptools wheel\npip install -r requirements.txt\npip install --no-build-isolation --editable .\nTo install with extras:\nbash\npip install --no-build-isolation --editable .[lookups,cuda102]\n\ud83d\udea6 Run tests\nspaCy comes with an extensive test suite. In order to run the\ntests, you'll usually want to clone the repository and build spaCy from source.\nThis will also install the required development dependencies and test utilities\ndefined in the requirements.txt.\nAlternatively, you can run pytest on the tests from within the installed\nspacy package. Don't forget to also install the test utilities via spaCy's\nrequirements.txt:\nbash\npip install -r requirements.txt\npython -m pytest --pyargs spacy",
	"aws big-data caffe data-science deep-learning hadoop kaggle keras machine-learning mapreduce matplotlib numpy pandas python scikit-learn scipy spark tensorflow theano": "data-science-ipython-notebooks\nIndex\ndeep-learning\ntensorflow\ntheano\nkeras\ncaffe\nscikit-learn\nstatistical-inference-scipy\npandas\nmatplotlib\nnumpy\npython-data\nkaggle-and-business-analyses\nspark\nmapreduce-python\namazon web services\ncommand lines\nmisc\nnotebook-installation\ncredits\ncontributing\ncontact-info\nlicense\ndeep-learning\nIPython Notebook(s) demonstrating deep learning functionality.\ntensor-flow-tutorials\nAdditional TensorFlow tutorials:\npkmital/tensorflow_tutorials\nnlintz/TensorFlow-Tutorials\nalrojo/tensorflow-tutorial\nBinRoot/TensorFlow-Book\ntuanavu/tensorflow-basic-tutorials\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| tsf-basics | Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google. |\n| tsf-linear | Implement linear regression in TensorFlow. |\n| tsf-logistic | Implement logistic regression in TensorFlow. |\n| tsf-nn | Implement nearest neighboars in TensorFlow. |\n| tsf-alex | Implement AlexNet in TensorFlow. |\n| tsf-cnn | Implement convolutional neural networks in TensorFlow. |\n| tsf-mlp | Implement multilayer perceptrons in TensorFlow. |\n| tsf-rnn | Implement recurrent neural networks in TensorFlow. |\n| tsf-gpu | Learn about basic multi-GPU computation in TensorFlow. |\n| tsf-gviz | Learn about graph visualization in TensorFlow. |\n| tsf-lviz | Learn about loss visualization in TensorFlow. |\ntensor-flow-exercises\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| tsf-not-mnist | Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow. |\n| tsf-fully-connected | Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow. |\n| tsf-regularization | Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow. |\n| tsf-convolutions | Create convolutional neural networks in TensorFlow. |\n| tsf-word2vec | Train a skip-gram model over Text8 data in TensorFlow. |\n| tsf-lstm | Train a LSTM character model over Text8 data in TensorFlow. |\ntheano-tutorials\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| theano-intro | Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation. |\n| theano-scan | Learn scans, a mechanism to perform loops in a Theano graph. |\n| theano-logistic | Implement logistic regression in Theano. |\n| theano-rnn | Implement recurrent neural networks in Theano. |\n| theano-mlp | Implement multilayer perceptrons in Theano. |\nkeras-tutorials\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| keras | Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano. |\n| setup | Learn about the tutorial goals and how to set up your Keras environment. |\n| intro-deep-learning-ann | Get an intro to deep learning with Keras and Artificial Neural Networks (ANN). |\n| theano | Learn about Theano by working with weights matrices and gradients. |\n| keras-otto | Learn about Keras by looking at the Kaggle Otto challenge. |\n| ann-mnist | Review a simple implementation of ANN for MNIST using Keras. |\n| conv-nets | Learn about Convolutional Neural Networks (CNNs) with Keras. |\n| conv-net-1 | Recognize handwritten digits from MNIST using Keras - Part 1. |\n| conv-net-2 | Recognize handwritten digits from MNIST using Keras - Part 2. |\n| keras-models | Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras. |\n| auto-encoders | Learn about Autoencoders with Keras. |\n| rnn-lstm | Learn about Recurrent Neural Networks (RNNs) with Keras. |\n| lstm-sentence-gen |  Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras. |\ndeep-learning-misc\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| deep-dream | Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images. |\nscikit-learn\nIPython Notebook(s) demonstrating scikit-learn functionality.\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| intro | Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| knn | Implement k-nearest neighbors in scikit-learn. |\n| linear-reg | Implement linear regression in scikit-learn. |\n| svm | Implement support vector machine classifiers with and without kernels in scikit-learn. |\n| random-forest | Implement random forest classifiers and regressors in scikit-learn. |\n| k-means | Implement k-means clustering in scikit-learn. |\n| pca | Implement principal component analysis in scikit-learn. |\n| gmm | Implement Gaussian mixture models in scikit-learn. |\n| validation | Implement validation and model selection in scikit-learn. |\nstatistical-inference-scipy\nIPython Notebook(s) demonstrating statistical inference with SciPy functionality.\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| scipy | SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. |\n| effect-size | Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States. |\n| sampling | Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data. |\n| hypothesis | Explore hypothesis testing by analyzing the difference of first-born babies compared with others. |\npandas\nIPython Notebook(s) demonstrating pandas functionality.\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| pandas | Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series. |\n| github-data-wrangling | Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the Viz repo. |\n| Introduction-to-Pandas | Introduction to Pandas. |\n| Introducing-Pandas-Objects | Learn about Pandas objects. |\n| Data Indexing and Selection | Learn about data indexing and selection in Pandas. |\n| Operations-in-Pandas | Learn about operating on data in Pandas. |\n| Missing-Values | Learn about handling missing data in Pandas. |\n| Hierarchical-Indexing | Learn about hierarchical indexing in Pandas. |\n| Concat-And-Append | Learn about combining datasets: concat and append in Pandas. |\n| Merge-and-Join | Learn about combining datasets: merge and join in Pandas. |\n| Aggregation-and-Grouping | Learn about aggregation and grouping in Pandas. |\n| Pivot-Tables | Learn about pivot tables in Pandas. |\n| Working-With-Strings | Learn about vectorized string operations in Pandas. |\n| Working-with-Time-Series | Learn about working with time series in pandas. |\n| Performance-Eval-and-Query | Learn about high-performance Pandas: eval() and query() in Pandas. |\nmatplotlib\nIPython Notebook(s) demonstrating matplotlib functionality.\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|\n| matplotlib | Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. |\n| matplotlib-applied | Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots. |\n| Introduction-To-Matplotlib | Introduction to Matplotlib. |\n| Simple-Line-Plots | Learn about simple line plots in Matplotlib. |\n| Simple-Scatter-Plots | Learn about simple scatter plots in Matplotlib. |\n| Errorbars.ipynb | Learn about visualizing errors in Matplotlib. |\n| Density-and-Contour-Plots | Learn about density and contour plots in Matplotlib. |\n| Histograms-and-Binnings | Learn about histograms, binnings, and density in Matplotlib. |\n| Customizing-Legends | Learn about customizing plot legends in Matplotlib. |\n| Customizing-Colorbars | Learn about customizing colorbars in Matplotlib. |\n| Multiple-Subplots | Learn about multiple subplots in Matplotlib. |\n| Text-and-Annotation | Learn about text and annotation in Matplotlib. |\n| Customizing-Ticks | Learn about customizing ticks in Matplotlib. |\n| Settings-and-Stylesheets | Learn about customizing Matplotlib: configurations and stylesheets. |\n| Three-Dimensional-Plotting | Learn about three-dimensional plotting in Matplotlib. |\n| Geographic-Data-With-Basemap | Learn about geographic data with basemap in Matplotlib. |\n| Visualization-With-Seaborn | Learn about visualization with Seaborn. |\nnumpy\nIPython Notebook(s) demonstrating NumPy functionality.\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| numpy | Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| Introduction-to-NumPy | Introduction to NumPy. |\n| Understanding-Data-Types | Learn about data types in Python. |\n| The-Basics-Of-NumPy-Arrays | Learn about the basics of NumPy arrays. |\n| Computation-on-arrays-ufuncs | Learn about computations on NumPy arrays: universal functions. |\n| Computation-on-arrays-aggregates | Learn about aggregations: min, max, and everything in between in NumPy. |\n| Computation-on-arrays-broadcasting | Learn about computation on arrays: broadcasting in NumPy. |\n| Boolean-Arrays-and-Masks | Learn about comparisons, masks, and boolean logic in NumPy. |\n| Fancy-Indexing | Learn about fancy indexing in NumPy. |\n| Sorting | Learn about sorting arrays in NumPy. |\n| Structured-Data-NumPy | Learn about structured data: NumPy's structured arrays. |\npython-data\nIPython Notebook(s) demonstrating Python functionality geared towards data analysis.\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n| data structures | Learn Python basics with tuples, lists, dicts, sets. |\n| data structure utilities | Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions. |\n| functions | Learn about more advanced Python features: Functions as objects, lambda functions, closures, args, *kwargs currying, generators, generator expressions, itertools. |\n| datetime | Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta. |\n| logging | Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler. |\n| pdb | Learn how to debug in Python with the interactive source code debugger. |\n| unit tests | Learn how to test in Python with Nose unit tests. |\nkaggle-and-business-analyses\nIPython Notebook(s) used in kaggle competitions and business analyses.\n| Notebook | Description |\n|-------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|\n| titanic | Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning. |\n| churn-analysis | Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.|\nspark\nIPython Notebook(s) demonstrating spark and HDFS functionality.\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| spark | In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms. |\n| hdfs | Reliably stores very large files across machines in a large cluster. |\nmapreduce-python\nIPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| mapreduce-python | Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and mrjob config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  Disco is another python-based alternative.|\naws\nIPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.\nAlso check out:\nSAWS: A Supercharged AWS command line interface (CLI).\nAwesome AWS: A curated list of libraries, open source repos, guides, blogs, and other resources.\n| Notebook | Description |\n|------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| boto | Official AWS SDK for Python. |\n| s3cmd | Interacts with S3 through the command line. |\n| s3distcp | Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster. |\n| s3-parallel-put | Uploads multiple files to S3 in parallel. |\n| redshift | Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP). |\n| kinesis | Streams data in real time with the ability to process thousands of data streams per second. |\n| lambda | Runs code in response to events, automatically managing compute resources. |\ncommands\nIPython Notebook(s) demonstrating various command lines for Linux, Git, etc.\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| linux | Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.|\n| anaconda | Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment. |\n| ipython notebook | Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document. |\n| git | Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows. |\n| ruby | Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages. |\n| jekyll | Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server. |\n| pelican | Python-based alternative to Jekyll. |\n| django | High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include Pyramid, Flask, Tornado, and Bottle.\nmisc\nIPython Notebook(s) demonstrating miscellaneous functionality.\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| regex | Regular expression cheat sheet useful in data wrangling.|\nalgorithmia | Algorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.|\nnotebook-installation\nanaconda\nAnaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.\nFollow instructions to install Anaconda or the more lightweight miniconda.\ndev-setup\nFor detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the dev-setup repo.\nrunning-notebooks\nTo view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found here.\n$ git clone https://github.com/donnemartin/data-science-ipython-notebooks.git\n$ cd data-science-ipython-notebooks\n$ jupyter notebook\nNotebooks tested with Python 2.7.x.\ncredits\nPython for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython by Wes McKinney\nPyCon 2015 Scikit-learn Tutorial by Jake VanderPlas\nPython Data Science Handbook by Jake VanderPlas\nParallel Machine Learning with scikit-learn and IPython by Olivier Grisel\nStatistical Interference Using Computational Methods in Python by Allen Downey\nTensorFlow Examples by Aymeric Damien\nTensorFlow Tutorials by Parag K Mital\nTensorFlow Tutorials by Nathan Lintz\nTensorFlow Tutorials by Alexander R Johansen\nTensorFlow Book by Nishant Shukla\nSummer School 2015 by mila-udem\nKeras tutorials by Valerio Maggio\nKaggle\nYhat Blog\ncontributing\nContributions are welcome!  For bug reports or requests please submit an issue.\ncontact-info\nFeel free to contact me to discuss any issues, questions, or comments.\nEmail: donne.martin@gmail.com\nTwitter: @donne_martin\nGitHub: donnemartin\nLinkedIn: donnemartin\nWebsite: donnemartin.com\nlicense\nThis repository contains a variety of content; some developed by Donne Martin, and some from third-parties.  The third-party content is distributed under the license provided by those parties.\nThe content developed by Donne Martin is distributed under the following license:\nI am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).\nCopyright 2015 Donne Martin\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.",
	"applied-data-science applied-machine-learning computer-vision data-discovery data-engineering data-quality data-science deep-learning machine-learning natural-language-processing production recsys reinforcement-learning search": "applied-ml\nCurated papers, articles, and blogs on data science & machine learning in production. \u2699\ufe0f\nFiguring out how to implement your ML project? Learn how other organizations did it:\nHow the problem is framed \ud83d\udd0e(e.g., personalization as recsys vs. search vs. sequences)\nWhat machine learning techniques worked \u2705 (and sometimes, what didn't \u274c)\nWhy it works, the science behind it with research, literature, and references \ud83d\udcc2\nWhat real-world results were achieved (so you can better assess ROI \u23f0\ud83d\udcb0\ud83d\udcc8)\nP.S., Want a summary of ML advancements? \ud83d\udc49ml-surveys\nP.P.S, Looking for guides and interviews on applying ML? \ud83d\udc49applyingML\nTable of Contents\nData Quality\nData Engineering\nData Discovery\nFeature Stores\nClassification\nRegression\nForecasting\nRecommendation\nSearch & Ranking\nEmbeddings\nNatural Language Processing\nSequence Modelling\nComputer Vision\nReinforcement Learning\nAnomaly Detection\nGraph\nOptimization\nInformation Extraction\nWeak Supervision\nGeneration\nAudio\nValidation and A/B Testing\nModel Management\nEfficiency\nEthics\nInfra\nMLOps Platforms\nPractices\nTeam Structure\nFails\nData Quality\nReliable and Scalable Data Ingestion at Airbnb Airbnb 2016\nMonitoring Data Quality at Scale with Statistical Modeling Uber 2017\nData Management Challenges in Production Machine Learning (Paper) Google 2017\nAutomating Large-Scale Data Quality Verification (Paper)Amazon 2018\nMeet Hodor \u2014 Gojek\u2019s Upstream Data Quality Tool Gojek 2019\nAn Approach to Data Quality for Netflix Personalization Systems Netflix 2020\nImproving Accuracy By Certainty Estimation of Human Decisions, Labels, and Raters (Paper) Facebook 2020\nData Engineering\nZipline: Airbnb\u2019s Machine Learning Data Management Platform Airbnb 2018\nSputnik: Airbnb\u2019s Apache Spark Framework for Data Engineering Airbnb 2020\nUnbundling Data Science Workflows with Metaflow and AWS Step Functions Netflix 2020\nHow DoorDash is Scaling its Data Platform to Delight Customers and Meet Growing Demand DoorDash 2020\nRevolutionizing Money Movements at Scale with Strong Data Consistency Uber 2020\nZipline - A Declarative Feature Engineering Framework Airbnb 2020\nAutomating Data Protection at Scale, Part 1 (Part 2) Airbnb 2021\nReal-time Data Infrastructure at Uber Uber 2021\nIntroducing Fabricator: A Declarative Feature Engineering Framework DoorDash 2022\nFunctions & DAGs: introducing Hamilton, a microframework for dataframe generation Stitch Fix 2021\nOptimizing Pinterest\u2019s Data Ingestion Stack: Findings and Learnings Pinterest 2022\nLessons Learned From Running Apache Airflow at Scale Shopify 2022\nUnderstanding Data Storage and Ingestion for Large-Scale Deep Recommendation Model Training Meta 2022\nData Discovery\nApache Atlas: Data Goverance and Metadata Framework for Hadoop (Code) Apache\nCollect, Aggregate, and Visualize a Data Ecosystem's Metadata (Code) WeWork\nDiscovery and Consumption of Analytics Data at Twitter Twitter 2016\nDemocratizing Data at Airbnb Airbnb 2017\nDatabook: Turning Big Data into Knowledge with Metadata at Uber Uber 2018\nMetacat: Making Big Data Discoverable and Meaningful at Netflix (Code) Netflix 2018\nAmundsen \u2014 Lyft\u2019s Data Discovery & Metadata Engine Lyft 2019\nOpen Sourcing Amundsen: A Data Discovery And Metadata Platform (Code) Lyft 2019\nDataHub: A Generalized Metadata Search & Discovery Tool (Code) LinkedIn 2019\nAmundsen: One Year Later Lyft 2020\nUsing Amundsen to Support User Privacy via Metadata Collection at Square Square 2020\nTurning Metadata Into Insights with Databook Uber 2020\nDataHub: Popular Metadata Architectures Explained LinkedIn 2020\nHow We Improved Data Discovery for Data Scientists at Spotify Spotify 2020 \nHow We\u2019re Solving Data Discovery Challenges at Shopify Shopify 2020\nNemo: Data discovery at Facebook Facebook 2020\nExploring Data @ Netflix (Code) Netflix 2021\nFeature Stores\nDistributed Time Travel for Feature Generation Netflix 2016\nBuilding the Activity Graph, Part 2 (Feature Storage Section) LinkedIn 2017\nFact Store at Scale for Netflix Recommendations Netflix 2018\nZipline: Airbnb\u2019s Machine Learning Data Management Platform Airbnb 2018\nIntroducing Feast: An Open Source Feature Store for Machine Learning (Code) Gojek 2019\nMichelangelo Palette: A Feature Engineering Platform at Uber Uber 2019\nThe Architecture That Powers Twitter's Feature Store Twitter 2019\nAccelerating Machine Learning with the Feature Store Service Cond\u00e9 Nast 2019 \nFeast: Bridging ML Models and Data Gojek 2020\nBuilding a Scalable ML Feature Store with Redis, Binary Serialization, and Compression DoorDash 2020\nRapid Experimentation Through Standardization: Typed AI features for LinkedIn\u2019s Feed LinkedIn 2020\nBuilding a Feature Store Monzo Bank 2020\nButterfree: A Spark-based Framework for Feature Store Building (Code) QuintoAndar 2020\nBuilding Riviera: A Declarative Real-Time Feature Engineering Framework DoorDash 2021\nOptimal Feature Discovery: Better, Leaner Machine Learning Models Through Information Theory Uber 2021\nML Feature Serving Infrastructure at Lyft Lyft 2021\nNear real-time features for near real-time personalization LinkedIn 2022\nBuilding the Model Behind DoorDash\u2019s Expansive Merchant Selection DoorDash 2022\nOpen sourcing Feathr \u2013 LinkedIn\u2019s feature store for productive machine learning LinkedIn 2022\nDeveloping scalable feature engineering DAGs Metaflow + Hamilton via Outerbounds 2022\nClassification\nPrediction of Advertiser Churn for Google AdWords (Paper) Google 2010\nHigh-Precision Phrase-Based Document Classification on a Modern Scale (Paper) LinkedIn 2011\nChimera: Large-scale Classification using Machine Learning, Rules, and Crowdsourcing (Paper) Walmart 2014\nLarge-scale Item Categorization in e-Commerce Using Multiple Recurrent Neural Networks (Paper) NAVER 2016\nLearning to Diagnose with LSTM Recurrent Neural Networks (Paper) Google 2017\nDiscovering and Classifying In-app Message Intent at Airbnb Airbnb 2019\nTeaching Machines to Triage Firefox Bugs Mozilla 2019\nCategorizing Products at Scale Shopify 2020\nHow We Built the Good First Issues Feature GitHub 2020\nTesting Firefox More Efficiently with Machine Learning Mozilla 2020\nUsing ML to Subtype Patients Receiving Digital Mental Health Interventions (Paper) Microsoft 2020\nScalable Data Classification for Security and Privacy (Paper) Facebook 2020\nUncovering Online Delivery Menu Best Practices with Machine Learning DoorDash 2020\nUsing a Human-in-the-Loop to Overcome the Cold Start Problem in Menu Item Tagging DoorDash 2020\nDeep Learning: Product Categorization and Shelving Walmart 2021\nLarge-scale Item Categorization for e-Commerce (Paper) DianPing, eBay 2012\nSemantic Label Representation with an Application on Multimodal Product Categorization Walmart 2022\nRegression\nUsing Machine Learning to Predict Value of Homes On Airbnb Airbnb 2017\nUsing Machine Learning to Predict the Value of Ad Requests Twitter 2020\nOpen-Sourcing Riskquant, a Library for Quantifying Risk (Code) Netflix 2020\nSolving for Unobserved Data in a Regression Model Using a Simple Data Adjustment DoorDash 2020\nForecasting\nEngineering Extreme Event Forecasting at Uber with RNN Uber 2017\nForecasting at Uber: An Introduction Uber 2018\nTransforming Financial Forecasting with Data Science and Machine Learning at Uber Uber 2018\nUnder the Hood of Gojek\u2019s Automated Forecasting Tool Gojek 2019\nBusTr: Predicting Bus Travel Times from Real-Time Traffic (Paper, Video) Google 2020\nRetraining Machine Learning Models in the Wake of COVID-19 DoorDash 2020\nAutomatic Forecasting using Prophet, Databricks, Delta Lake and MLflow (Paper, Code) Atlassian 2020\nIntroducing Orbit, An Open Source Package for Time Series Inference and Forecasting (Paper, Video, Code) Uber 2021\nManaging Supply and Demand Balance Through Machine Learning DoorDash 2021\nGreykite: A flexible, intuitive, and fast forecasting library LinkedIn 2021\nDeepETA: How Uber Predicts Arrival Times Using Deep Learning Uber 2022\nForecasting Grubhub Order Volume At Scale Grubhub 2022\nRecommendation\nAmazon.com Recommendations: Item-to-Item Collaborative Filtering (Paper) Amazon 2003\nNetflix Recommendations: Beyond the 5 stars (Part 1 (Part 2) Netflix 2012\nHow Music Recommendation Works \u2014 And Doesn\u2019t Work Spotify 2012\nLearning to Rank Recommendations with the k -Order Statistic Loss (Paper) Google 2013\nRecommending Music on Spotify with Deep Learning Spotify 2014\nLearning a Personalized Homepage Netflix 2015\nSession-based Recommendations with Recurrent Neural Networks (Paper) Telefonica 2016\nDeep Neural Networks for YouTube Recommendations YouTube 2016\nE-commerce in Your Inbox: Product Recommendations at Scale (Paper) Yahoo 2016\nTo Be Continued: Helping you find shows to continue watching on Netflix Netflix 2016\nPersonalized Recommendations in LinkedIn Learning LinkedIn 2016\nPersonalized Channel Recommendations in Slack Slack 2016\nRecommending Complementary Products in E-Commerce Push Notifications (Paper) Alibaba 2017\nArtwork Personalization at Netflix Netflix 2017\nA Meta-Learning Perspective on Cold-Start Recommendations for Items (Paper) Twitter 2017\nPixie: A System for Recommending 3+ Billion Items to 200+ Million Users in Real-Time (Paper) Pinterest 2017\nHow 20th Century Fox uses ML to predict a movie audience (Paper) 20th Century Fox 2018\nCalibrated Recommendations (Paper) Netflix 2018\nFood Discovery with Uber Eats: Recommending for the Marketplace Uber 2018\nExplore, Exploit, and Explain: Personalizing Explainable Recommendations with Bandits (Paper) Spotify 2018\nBehavior Sequence Transformer for E-commerce Recommendation in Alibaba (Paper) Alibaba 2019\nSDM: Sequential Deep Matching Model for Online Large-scale Recommender System (Paper) Alibaba 2019\nMulti-Interest Network with Dynamic Routing for Recommendation at Tmall (Paper) Alibaba 2019\nPersonalized Recommendations for Experiences Using Deep Learning TripAdvisor 2019\nPowered by AI: Instagram\u2019s Explore recommender system Facebook 2019\nMarginal Posterior Sampling for Slate Bandits (Paper) Netflix 2019\nFood Discovery with Uber Eats: Using Graph Learning to Power Recommendations Uber 2019\nMusic recommendation at Spotify Spotify 2019\nUsing Machine Learning to Predict what File you Need Next (Part 1) Dropbox 2019\nUsing Machine Learning to Predict what File you Need Next (Part 2) Dropbox 2019\nLearning to be Relevant: Evolution of a Course Recommendation System (PAPER NEEDED)LinkedIn 2019\nTemporal-Contextual Recommendation in Real-Time (Paper) Amazon 2020\nP-Companion: A Framework for Diversified Complementary Product Recommendation (Paper) Amazon 2020\nDeep Interest with Hierarchical Attention Network for Click-Through Rate Prediction (Paper) Alibaba 2020\nTPG-DNN: A Method for User Intent Prediction with Multi-task Learning (Paper) Alibaba 2020\nPURS: Personalized Unexpected Recommender System for Improving User Satisfaction (Paper) Alibaba 2020\nControllable Multi-Interest Framework for Recommendation (Paper) Alibaba 2020\nMiNet: Mixed Interest Network for Cross-Domain Click-Through Rate Prediction (Paper) Alibaba 2020\nATBRG: Adaptive Target-Behavior Relational Graph Network for Effective Recommendation (Paper) Alibaba 2020\nFor Your Ears Only: Personalizing Spotify Home with Machine Learning Spotify 2020\nReach for the Top: How Spotify Built Shortcuts in Just Six Months Spotify 2020\nContextual and Sequential User Embeddings for Large-Scale Music Recommendation (Paper) Spotify 2020\nThe Evolution of Kit: Automating Marketing Using Machine Learning Shopify 2020\nA Closer Look at the AI Behind Course Recommendations on LinkedIn Learning (Part 1) LinkedIn 2020\nA Closer Look at the AI Behind Course Recommendations on LinkedIn Learning (Part 2) LinkedIn 2020\nBuilding a Heterogeneous Social Network Recommendation System LinkedIn 2020\nHow TikTok recommends videos #ForYou ByteDance 2020\nZero-Shot Heterogeneous Transfer Learning from RecSys to Cold-Start Search Retrieval (Paper) Google 2020\nImproved Deep & Cross Network for Feature Cross Learning in Web-scale LTR Systems (Paper) Google 2020\nMixed Negative Sampling for Learning Two-tower Neural Networks in Recommendations (Paper) Google 2020\nFuture Data Helps Training: Modeling Future Contexts for Session-based Recommendation (Paper) Tencent 2020\nA Case Study of Session-based Recommendations in the Home-improvement Domain (Paper) Home Depot 2020\nBalancing Relevance and Discovery to Inspire Customers in the IKEA App (Paper) Ikea 2020\nHow we use AutoML, Multi-task learning and Multi-tower models for Pinterest Ads Pinterest 2020\nMulti-task Learning for Related Products Recommendations at Pinterest Pinterest 2020\nImproving the Quality of Recommended Pins with Lightweight Ranking Pinterest 2020\nMulti-task Learning and Calibration for Utility-based Home Feed Ranking Pinterest 2020\nPersonalized Cuisine Filter Based on Customer Preference and Local Popularity DoorDash 2020\nHow We Built a Matchmaking Algorithm to Cross-Sell Products Gojek 2020\nLessons Learned Addressing Dataset Bias in Model-Based Candidate Generation (Paper) Twitter 2021\nSelf-supervised Learning for Large-scale Item Recommendations (Paper) Google 2021\nDeep Retrieval: End-to-End Learnable Structure Model for Large-Scale Recommendations (Paper) ByteDance 2021\nUsing AI to Help Health Experts Address the COVID-19 Pandemic Facebook 2021\nAdvertiser Recommendation Systems at Pinterest Pinterest 2021\nOn YouTube's Recommendation System YouTube 2021\nMozrt, a Deep Learning Recommendation System Empowering Walmart Store Associates Walmart 2021\nThe Amazon Music conversational recommender is hitting the right notes Amazon 2022\nPersonalized complementary product recommendation (Paper) Amazon 2022\nBuilding a Deep Learning Based Retrieval System for Personalized Recommendations eBay 2022\nHow We Built: An Early-Stage Machine Learning Model for Recommendations Peloton 2022\nBeyond Matrix Factorization: Using hybrid features for user-business recommendations Yelp 2022\nImproving job matching with machine-learned activity features LinkedIn 2022\nUnderstanding Data Storage and Ingestion for Large-Scale Deep Recommendation Model Training Meta 2022\nHomepage Recommendation with Exploitation and Exploration DoorDash 2022\nSearch & Ranking\nAmazon Search: The Joy of Ranking Products (Paper, Video, Code) Amazon 2016\nHow Lazada Ranks Products to Improve Customer Experience and Conversion Lazada 2016\nRanking Relevance in Yahoo Search (Paper) Yahoo 2016\nLearning to Rank Personalized Search Results in Professional Networks (Paper) LinkedIn 2016\nUsing Deep Learning at Scale in Twitter\u2019s Timelines Twitter 2017\nAn Ensemble-based Approach to Click-Through Rate Prediction for Promoted Listings at Etsy (Paper) Etsy 2017\nPowering Search & Recommendations at DoorDash DoorDash 2017\nApplying Deep Learning To Airbnb Search (Paper) Airbnb 2018\nIn-session Personalization for Talent Search (Paper) LinkedIn 2018\nTalent Search and Recommendation Systems at LinkedIn (Paper) LinkedIn 2018\nFood Discovery with Uber Eats: Building a Query Understanding Engine Uber 2018\nGlobally Optimized Mutual Influence Aware Ranking in E-Commerce Search (Paper) Alibaba 2018\nReinforcement Learning to Rank in E-Commerce Search Engine (Paper) Alibaba 2018\nSemantic Product Search (Paper) Amazon 2019\nMachine Learning-Powered Search Ranking of Airbnb Experiences Airbnb 2019\nEntity Personalized Talent Search Models with Tree Interaction Features (Paper) LinkedIn 2019\nThe AI Behind LinkedIn Recruiter Search and recommendation systems LinkedIn 2019\nLearning Hiring Preferences: The AI Behind LinkedIn Jobs LinkedIn 2019\nThe Secret Sauce Behind Search Personalisation Gojek 2019\nNeural Code Search: ML-based Code Search Using Natural Language Queries Facebook 2019\nAggregating Search Results from Heterogeneous Sources via Reinforcement Learning (Paper) Alibaba 2019\nCross-domain Attention Network with Wasserstein Regularizers for E-commerce Search Alibaba 2019\nUnderstanding Searches Better Than Ever Before (Paper) Google 2019\nHow We Used Semantic Search to Make Our Search 10x Smarter Tokopedia 2019\nQuery2vec: Search query expansion with query embeddings GrubHub 2019\nMOBIUS: Towards the Next Generation of Query-Ad Matching in Baidu\u2019s Sponsored Search Baidu 2019\nWhy Do People Buy Seemingly Irrelevant Items in Voice Product Search? (Paper) Amazon 2020\nManaging Diversity in Airbnb Search (Paper) Airbnb 2020\nImproving Deep Learning for Airbnb Search (Paper) Airbnb 2020\nQuality Matches Via Personalized AI for Hirer and Seeker Preferences LinkedIn 2020\nUnderstanding Dwell Time to Improve LinkedIn Feed Ranking LinkedIn 2020\nAds Allocation in Feed via Constrained Optimization (Paper, Video) LinkedIn 2020\nUnderstanding Dwell Time to Improve LinkedIn Feed Ranking LinkedIn 2020\nAI at Scale in Bing Microsoft 2020\nQuery Understanding Engine in Traveloka Universal Search Traveloka 2020\nBayesian Product Ranking at Wayfair Wayfair 2020\nCOLD: Towards the Next Generation of Pre-Ranking System (Paper) Alibaba 2020\nShop The Look: Building a Large Scale Visual Shopping System at Pinterest (Paper, Video) Pinterest 2020\nDriving Shopping Upsells from Pinterest Search Pinterest 2020\nGDMix: A Deep Ranking Personalization Framework (Code) LinkedIn 2020\nBringing Personalized Search to Etsy Etsy 2020\nBuilding a Better Search Engine for Semantic Scholar Allen Institute for AI 2020\nQuery Understanding for Natural Language Enterprise Search (Paper) Salesforce 2020\nThings Not Strings: Understanding Search Intent with Better Recall DoorDash 2020\nQuery Understanding for Surfacing Under-served Music Content (Paper) Spotify 2020\nEmbedding-based Retrieval in Facebook Search (Paper) Facebook 2020\nTowards Personalized and Semantic Retrieval for E-commerce Search via Embedding Learning (Paper) JD 2020\nQUEEN: Neural query rewriting in e-commerce (Paper) Amazon 2021\nUsing Learning-to-rank to Precisely Locate Where to Deliver Packages (Paper) Amazon 2021\nSeasonal relevance in e-commerce search (Paper) Amazon 2021\nGraph Intention Network for Click-through Rate Prediction in Sponsored Search (Paper) Alibaba 2021\nHow We Built A Context-Specific Bidding System for Etsy Ads Etsy 2021\nPre-trained Language Model based Ranking in Baidu Search (Paper) Baidu 2021\nStitching together spaces for query-based recommendations Stitch Fix 2021\nDeep Natural Language Processing for LinkedIn Search Systems (Paper) LinkedIn 2021\nSiamese BERT-based Model for Web Search Relevance Ranking (Paper, Code) Seznam 2021\nSearchSage: Learning Search Query Representations at Pinterest Pinterest 2021\n3 Changes to Expand DoorDash\u2019s Product Search Beyond Delivery DoorDash 2022\nEmbeddings\nVector Representation Of Items, Customer And Cart To Build A Recommendation System (Paper) Sears 2017\nBillion-scale Commodity Embedding for E-commerce Recommendation in Alibaba (Paper) Alibaba 2018\nEmbeddings@Twitter Twitter 2018\nListing Embeddings in Search Ranking (Paper) Airbnb 2018\nUnderstanding Latent Style Stitch Fix 2018\nTowards Deep and Representation Learning for Talent Search at LinkedIn (Paper) LinkedIn 2018\nPersonalized Store Feed with Vector Embeddings DoorDash 2018\nShould we Embed? A Study on Performance of Embeddings for Real-Time Recommendations(Paper) Moshbit 2019\nMachine Learning for a Better Developer Experience Netflix 2020\nAnnouncing ScaNN: Efficient Vector Similarity Search (Paper, Code) Google 2020\nEmbedding-based Retrieval at Scribd Scribd 2021\nNatural Language Processing\nAbusive Language Detection in Online User Content (Paper) Yahoo 2016\nSmart Reply: Automated Response Suggestion for Email (Paper) Google 2016 \nBuilding Smart Replies for Member Messages LinkedIn 2017\nActive Annotation: bootstrapping annotation lexicon and guidelines for supervised NLU learning (Paper) Trento University 2019\nHow Natural Language Processing Helps LinkedIn Members Get Support Easily LinkedIn 2019\nGmail Smart Compose: Real-Time Assisted Writing (Paper) Google 2019\nGoal-Oriented End-to-End Conversational Models with Profile Features in a Real-World Setting (Paper) Amazon 2019\nGive Me Jeans not Shoes: How BERT Helps Us Deliver What Clients Want Stitch Fix 2019\nDeText: A deep NLP Framework for Intelligent Text Understanding (Code) LinkedIn 2020\nSmartReply for YouTube Creators Google 2020\nUsing Neural Networks to Find Answers in Tables (Paper) Google 2020\nA Scalable Approach to Reducing Gender Bias in Google Translate Google 2020\nAssistive AI Makes Replying Easier Microsoft 2020\nAI Advances to Better Detect Hate Speech Facebook 2020\nA State-of-the-Art Open Source Chatbot (Paper) Facebook 2020\nA Highly Efficient, Real-Time Text-to-Speech System Deployed on CPUs Facebook 2020\nDeep Learning to Translate Between Programming Languages (Paper, Code) Facebook 2020\nDeploying Lifelong Open-Domain Dialogue Learning (Paper) Facebook 2020\nIntroducing Dynabench: Rethinking the way we benchmark AI Facebook 2020\nHow Gojek Uses NLP to Name Pickup Locations at Scale Gojek 2020\nThe State-of-the-art Open-Domain Chatbot in Chinese and English (Paper) Baidu 2020\nPEGASUS: A State-of-the-Art Model for Abstractive Text Summarization (Paper, Code) Google 2020\nPhoton: A Robust Cross-Domain Text-to-SQL System (Paper) (Demo) Salesforce 2020\nGeDi: A Powerful New Method for Controlling Language Models (Paper, Code) Salesforce 2020\nApplying Topic Modeling to Improve Call Center Operations RICOH 2020\nWIDeText: A Multimodal Deep Learning Framework Airbnb 2020\nDynaboard: Moving Beyond Accuracy to Holistic Model Evaluation in NLP (Code) Facebook 2021\nHow we reduced our text similarity runtime by 99.96% Microsoft 2021\nTextless NLP: Generating expressive speech from raw audio (Part 1) (Part 2) (Part 3) (Code and Pretrained Models) Facebook 2021\nGrammar Correction as You Type, on Pixel 6 Google 2021\nAuto-generated Summaries in Google Docs Google 2022\nWords All the Way Down \u2014 Conversational Sentiment Analysis PayPal 2022\nSequence Modelling\nDoctor AI: Predicting Clinical Events via Recurrent Neural Networks (Paper) Sutter Health 2015\nDeep Learning for Understanding Consumer Histories (Paper) Zalando 2016\nUsing Recurrent Neural Network Models for Early Detection of Heart Failure Onset (Paper) Sutter Health 2016\nContinual Prediction of Notification Attendance with Classical and Deep Networks (Paper) Telefonica 2017 \nDeep Learning for Electronic Health Records (Paper) Google 2018\nPractice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction (Paper)Alibaba 2019\nSearch-based User Interest Modeling with Sequential Behavior Data for CTR Prediction (Paper) Alibaba 2020\nHow Duolingo uses AI in every part of its app Duolingo 2020\nLeveraging Online Social Interactions For Enhancing Integrity at Facebook (Paper, Video) Facebook 2020\nUsing deep learning to detect abusive sequences of member activity (Video) LinkedIn 2021\nComputer Vision\nCreating a Modern OCR Pipeline Using Computer Vision and Deep Learning Dropbox 2017\nCategorizing Listing Photos at Airbnb Airbnb 2018\nAmenity Detection and Beyond \u2014 New Frontiers of Computer Vision at Airbnb Airbnb 2019\nHow we Improved Computer Vision Metrics by More Than 5% Only by Cleaning Labelling Errors Deepomatic\nMaking machines recognize and transcribe conversations in meetings using audio and video Microsoft 2019\nPowered by AI: Advancing product understanding and building new shopping experiences Facebook 2020\nA Neural Weather Model for Eight-Hour Precipitation Forecasting (Paper) Google 2020\nMachine Learning-based Damage Assessment for Disaster Relief (Paper) Google 2020\nRepNet: Counting Repetitions in Videos (Paper) Google 2020\nConverting Text to Images for Product Discovery (Paper) Amazon 2020\nHow Disney Uses PyTorch for Animated Character Recognition Disney 2020\nImage Captioning as an Assistive Technology (Video) IBM 2020\nAI for AG: Production machine learning for agriculture Blue River 2020\nAI for Full-Self Driving at Tesla Tesla 2020\nOn-device Supermarket Product Recognition Google 2020\nUsing Machine Learning to Detect Deficient Coverage in Colonoscopy Screenings (Paper) Google 2020\nShop The Look: Building a Large Scale Visual Shopping System at Pinterest (Paper, Video) Pinterest 2020\nDeveloping Real-Time, Automatic Sign Language Detection for Video Conferencing (Paper) Google 2020\nVision-based Price Suggestion for Online Second-hand Items (Paper) Alibaba 2020\nNew AI Research to Help Predict COVID-19 Resource Needs From X-rays (Paper, Model) Facebook 2021\nAn Efficient Training Approach for Very Large Scale Face Recognition (Paper) Alibaba 2021\nIdentifying Document Types at Scribd Scribd 2021\nSemi-Supervised Visual Representation Learning for Fashion Compatibility (Paper) Walmart 2021\nRecognizing People in Photos Through Private On-Device Machine Learning Apple 2021\nDeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection Google 2022\nReinforcement Learning\nDeep Reinforcement Learning for Sponsored Search Real-time Bidding (Paper) Alibaba 2018\nBudget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising (Paper) Alibaba 2018\nReinforcement Learning for On-Demand Logistics DoorDash 2018\nReinforcement Learning to Rank in E-Commerce Search Engine (Paper) Alibaba 2018\nDynamic Pricing on E-commerce Platform with Deep Reinforcement Learning (Paper) Alibaba 2019\nProductionizing Deep Reinforcement Learning with Spark and MLflow Zynga 2020\nDeep Reinforcement Learning in Production Part1 Part 2 Zynga 2020\nBuilding AI Trading Systems Denny Britz 2020\nShifting Consumption towards Diverse content via Reinforcement Learning (Paper) Spotify 2022\nAnomaly Detection\nDetecting Performance Anomalies in External Firmware Deployments Netflix 2019\nDetecting and Preventing Abuse on LinkedIn using Isolation Forests (Code) LinkedIn 2019\nDeep Anomaly Detection with Spark and Tensorflow (Hopsworks Video) Swedbank, Hopsworks 2019\nPreventing Abuse Using Unsupervised Learning LinkedIn 2020\nThe Technology Behind Fighting Harassment on LinkedIn LinkedIn 2020\nUncovering Insurance Fraud Conspiracy with Network Learning (Paper) Ant Financial 2020\nHow Does Spam Protection Work on Stack Exchange? Stack Exchange 2020\nAuto Content Moderation in C2C e-Commerce Mercari 2020\nBlocking Slack Invite Spam With Machine Learning Slack 2020\nCloudflare Bot Management: Machine Learning and More Cloudflare 2020\nAnomalies in Oil Temperature Variations in a Tunnel Boring Machine SENER 2020\nUsing Anomaly Detection to Monitor Low-Risk Bank Customers Rabobank 2020\nFighting fraud with Triplet Loss OLX Group 2020\nFacebook is Now Using AI to Sort Content for Quicker Moderation (Alternative) Facebook 2020\nHow AI is getting better at detecting hate speech Part 1, Part 2, Part 3, Part 4 Facebook 2020\nProject RADAR: Intelligent Early Fraud Detection System with Humans in the Loop Uber 2022\nGraph\nBuilding The LinkedIn Knowledge Graph LinkedIn 2016\nScaling Knowledge Access and Retrieval at Airbnb Airbnb 2018\nGraph Convolutional Neural Networks for Web-Scale Recommender Systems (Paper)Pinterest 2018\nFood Discovery with Uber Eats: Using Graph Learning to Power Recommendations Uber 2019\nAliGraph: A Comprehensive Graph Neural Network Platform (Paper) Alibaba 2019\nContextualizing Airbnb by Building Knowledge Graph Airbnb 2019\nRetail Graph \u2014 Walmart\u2019s Product Knowledge Graph Walmart 2020\nTraffic Prediction with Advanced Graph Neural Networks DeepMind 2020\nSimClusters: Community-Based Representations for Recommendations (Paper, Video) Twitter 2020\nMetapaths guided Neighbors aggregated Network for Heterogeneous Graph Reasoning (Paper) Alibaba 2021\nGraph Intention Network for Click-through Rate Prediction in Sponsored Search (Paper) Alibaba 2021\nJEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase (Paper) JPMorgan Chase 2021\nHow AWS uses graph neural networks to meet customer needs Amazon 2022\nOptimization\nMatchmaking in Lyft Line (Part 1) (Part 2) (Part 3) Lyft 2016\nThe Data and Science behind GrabShare Carpooling (Part 1) (PAPER NEEDED) Grab 2017\nHow Trip Inferences and Machine Learning Optimize Delivery Times on Uber Eats Uber 2018\nNext-Generation Optimization for Dasher Dispatch at DoorDash DoorDash 2020 \nOptimization of Passengers Waiting Time in Elevators Using Machine Learning Thyssen Krupp AG 2020\nThink Out of The Package: Recommending Package Types for E-commerce Shipments (Paper) Amazon 2020\nOptimizing DoorDash\u2019s Marketing Spend with Machine Learning DoorDash 2020\nUsing learning-to-rank to precisely locate where to deliver packages (Paper)Amazon 2021\nInformation Extraction\nUnsupervised Extraction of Attributes and Their Values from Product Description (Paper) Rakuten 2013\nUsing Machine Learning to Index Text from Billions of Images Dropbox 2018\nExtracting Structured Data from Templatic Documents (Paper) Google 2020\nAutoKnow: self-driving knowledge collection for products of thousands of types (Paper, Video) Amazon 2020\nOne-shot Text Labeling using Attention and Belief Propagation for Information Extraction (Paper) Alibaba 2020\nInformation Extraction from Receipts with Graph Convolutional Networks Nanonets 2021\nWeak Supervision\nSnorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale (Paper) Google 2019\nOsprey: Weak Supervision of Imbalanced Extraction Problems without Code (Paper) Intel 2019 \nOverton: A Data System for Monitoring and Improving Machine-Learned Products (Paper) Apple 2019\nBootstrapping Conversational Agents with Weak Supervision (Paper) IBM 2019\nGeneration\nBetter Language Models and Their Implications (Paper)OpenAI 2019\nImage GPT (Paper, Code) OpenAI 2019\nLanguage Models are Few-Shot Learners (Paper) (GPT-3 Blog post) OpenAI 2020\nDeep Learned Super Resolution for Feature Film Production (Paper) Pixar 2020\nUnit Test Case Generation with Transformers Microsoft 2021\nAudio\nImproving On-Device Speech Recognition with VoiceFilter-Lite (Paper)Google 2020\nThe Machine Learning Behind Hum to Search Google 2020\nValidation and A/B Testing\nOverlapping Experiment Infrastructure: More, Better, Faster Experimentation (Paper) Google 2010\nThe Reusable Holdout: Preserving Validity in Adaptive Data Analysis (Paper) Google 2015\nTwitter Experimentation: Technical Overview Twitter 2015\nIt\u2019s All A/Bout Testing: The Netflix Experimentation Platform Netflix 2016\nBuilding Pinterest\u2019s A/B Testing Platform Pinterest 2016 \nExperimenting to Solve Cramming Twitter 2017\nBuilding an Intelligent Experimentation Platform with Uber Engineering Uber 2017\nScaling Airbnb\u2019s Experimentation Platform Airbnb 2017\nMeet Wasabi, an Open Source A/B Testing Platform (Code) Intuit 2017 \nAnalyzing Experiment Outcomes: Beyond Average Treatment Effects Uber 2018\nUnder the Hood of Uber\u2019s Experimentation Platform Uber 2018\nConstrained Bayesian Optimization with Noisy Experiments (Paper) Facebook 2018\nReliable and Scalable Feature Toggles and A/B Testing SDK at Grab Grab 2018\nModeling Conversion Rates and Saving Millions Using Kaplan-Meier and Gamma Distributions (Code) Better 2019\nDetecting Interference: An A/B Test of A/B Tests LinkedIn 2019\nAnnouncing a New Framework for Designing Optimal Experiments with Pyro (Paper) (Paper) Uber 2020\nEnabling 10x More Experiments with Traveloka Experiment Platform Traveloka 2020\nLarge Scale Experimentation at Stitch Fix (Paper) Stitch Fix 2020\nMulti-Armed Bandits and the Stitch Fix Experimentation Platform Stitch Fix 2020\nExperimentation with Resource Constraints Stitch Fix 2020\nComputational Causal Inference at Netflix (Paper) Netflix 2020\nKey Challenges with Quasi Experiments at Netflix Netflix 2020\nMaking the LinkedIn experimentation engine 20x faster LinkedIn 2020\nOur Evolution Towards T-REX: The Prehistory of Experimentation Infrastructure at LinkedIn LinkedIn 2020\nHow to Use Quasi-experiments and Counterfactuals to Build Great Products Shopify 2020\nImproving Experimental Power through Control Using Predictions as Covariate DoorDash 2020\nSupporting Rapid Product Iteration with an Experimentation Analysis Platform DoorDash 2020\nImproving Online Experiment Capacity by 4X with Parallelization and Increased Sensitivity DoorDash 2020\nLeveraging Causal Modeling to Get More Value from Flat Experiment Results DoorDash 2020\nIterating Real-time Assignment Algorithms Through Experimentation DoorDash 2020\nSpotify\u2019s New Experimentation Platform (Part 1) (Part 2) Spotify 2020\nInterpreting A/B Test Results: False Positives and Statistical Significance Netflix 2021\nInterpreting A/B Test Results: False Negatives and Power Netflix 2021\nRunning Experiments with Google Adwords for Campaign Optimization DoorDash 2021\nThe 4 Principles DoorDash Used to Increase Its Logistics Experiment Capacity by 1000% DoorDash 2021\nExperimentation Platform at Zalando: Part 1 - Evolution Zalando 2021\nDesigning Experimentation Guardrails Airbnb 2021\nHow Airbnb Measures Future Value to Standardize Tradeoffs Airbnb 2021\nNetwork Experimentation at Scale(Paper] Facebook 2021\nUniversal Holdout Groups at Disney Streaming Disney 2021\nExperimentation is a major focus of Data Science across Netflix Netflix 2022\nSearch Journey Towards Better Experimentation Practices Spotify 2022\nArtificial Counterfactual Estimation: Machine Learning-Based Causal Inference at Airbnb Airbnb 2022\nChallenges in Experimentation Lyft 2022\nOvertracking and Trigger Analysis: Reducing sample sizes while INCREASING sensitivity Booking 2022\nMeet Dash-AB \u2014 The Statistics Engine of Experimentation at DoorDash DoorDash 2022\nComparing quantiles at scale in online A/B-testing Spotify 2022\nModel Management\nOperationalizing Machine Learning\u2014Managing Provenance from Raw Data to Predictions Comcast 2018\nOverton: A Data System for Monitoring and Improving Machine-Learned Products (Paper) Apple 2019\nRunway - Model Lifecycle Management at Netflix Netflix 2020\nManaging ML Models @ Scale - Intuit\u2019s ML Platform Intuit 2020\nML Model Monitoring - 9 Tips From the Trenches Nubank 2021\nEfficiency\nGrokNet: Unified Computer Vision Model Trunk and Embeddings For Commerce (Paper) Facebook 2020\nHow We Scaled Bert To Serve 1+ Billion Daily Requests on CPUs Roblox 2020\nPermute, Quantize, and Fine-tune: Efficient Compression of Neural Networks (Paper) Uber 2021\nEthics\nBuilding Inclusive Products Through A/B Testing (Paper) LinkedIn 2020\nLiFT: A Scalable Framework for Measuring Fairness in ML Applications (Paper) LinkedIn 2020\nIntroducing Twitter\u2019s first algorithmic bias bounty challenge Twitter 2021\nExamining algorithmic amplification of political content on Twitter Twitter 2021\nA closer look at how LinkedIn integrates fairness into its AI products LinkedIn 2022\nInfra\nReengineering Facebook AI\u2019s Deep Learning Platforms for Interoperability Facebook 2020\nElastic Distributed Training with XGBoost on Ray Uber 2021\nMLOps Platforms\nMeet Michelangelo: Uber\u2019s Machine Learning Platform Uber 2017\nOperationalizing Machine Learning\u2014Managing Provenance from Raw Data to Predictions Comcast 2018\nBig Data Machine Learning Platform at Pinterest Pinterest 2019\nCore Modeling at Instagram Instagram 2019\nOpen-Sourcing Metaflow - a Human-Centric Framework for Data Science Netflix 2019\nManaging ML Models @ Scale - Intuit\u2019s ML Platform Intuit 2020\nReal-time Machine Learning Inference Platform at Zomato Zomato 2020\nIntroducing Flyte: Cloud Native Machine Learning and Data Processing Platform Lyft 2020\nBuilding Flexible Ensemble ML Models with a Computational Graph DoorDash 2021\nLyftLearn: ML Model Training Infrastructure built on Kubernetes Lyft 2021\n\"You Don't Need a Bigger Boat\": A Full Data Pipeline Built with Open-Source Tools (Paper) Coveo 2021\nMLOps at GreenSteam: Shipping Machine Learning GreenSteam 2021\nEvolving Reddit\u2019s ML Model Deployment and Serving Architecture Reddit 2021\nRedesigning Etsy\u2019s Machine Learning Platform Etsy 2021\nBuilding a Platform for Serving Recommendations at Etsy Etsy 2022 \nIntelligent Automation Platform: Empowering Conversational AI and Beyond at Airbnb Airbnb 2022\nDARWIN: Data Science and Artificial Intelligence Workbench at LinkedIn LinkedIn 2022\nThe Magic of Merlin: Shopify's New Machine Learning Platform Shopify 2022\nZalando's Machine Learning Platform Zalando 2022\nInside Meta's AI optimization platform for engineers across the company (Paper) Meta 2022\nMonzo\u2019s machine learning stack Monzo 2022\nEvolution of ML Fact Store Netflix 2022\nDeployment for Free: A Machine Learning Platform for Stitch Fix's Data Scientists Stitch Fix\nPractices\nPractical Recommendations for Gradient-Based Training of Deep Architectures (Paper) Yoshua Bengio 2012\nMachine Learning: The High Interest Credit Card of Technical Debt (Paper) (Paper) Google 2014\nRules of Machine Learning: Best Practices for ML Engineering Google 2018\nOn Challenges in Machine Learning Model Management Amazon 2018\nMachine Learning in Production: The Booking.com Approach Booking 2019\n150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com (Paper) Booking 2019\nSuccesses and Challenges in Adopting Machine Learning at Scale at a Global Bank Rabobank 2019\nChallenges in Deploying Machine Learning: a Survey of Case Studies (Paper) Cambridge 2020\nReengineering Facebook AI\u2019s Deep Learning Platforms for Interoperability Facebook 2020\nThe problem with AI developer tools for enterprises Databricks 2020\nContinuous Integration and Deployment for Machine Learning Online Serving and Models Uber 2021\nTuning Model Performance Uber 2021\nMaintaining Machine Learning Model Accuracy Through Monitoring DoorDash 2021\nBuilding Scalable and Performant Marketing ML Systems at Wayfair Wayfair 2021\nOur approach to building transparent and explainable AI systems LinkedIn 2021\n5 Steps for Building Machine Learning Models for Business Shopify 2021\nData Is An Art, Not Just A Science\u2014And Storytelling Is The Key Shopify 2022\nTeam structure\nEngineers Shouldn\u2019t Write ETL: A Guide to Building a High Functioning Data Science Department Stitch Fix 2016\nBuilding The Analytics Team At Wish Wish 2018\nBeware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist Stitch Fix 2019\nCultivating Algorithms: How We Grow Data Science at Stitch Fix Stitch Fix\nAnalytics at Netflix: Who We Are and What We Do Netflix 2020\nBuilding a Data Team at a Mid-stage Startup: A Short Story Erikbern 2021\nA Behind-the-Scenes Look at How Postman\u2019s Data Team Works Postman 2021\nData Scientist x Machine Learning Engineer Roles: How are they different? How are they alike? Nubank 2022\nFails\nWhen It Comes to Gorillas, Google Photos Remains Blind Google 2018\n160k+ High School Students Will Graduate Only If a Model Allows Them to International Baccalaureate 2020\nAn Algorithm That \u2018Predicts\u2019 Criminality Based on a Face Sparks a Furor Harrisburg University 2020\nIt's Hard to Generate Neural Text From GPT-3 About Muslims OpenAI 2020\nA British AI Tool to Predict Violent Crime Is Too Flawed to Use United Kingdom 2020\nMore in awful-ai\nP.S., Want a summary of ML advancements? Get up to speed with survey papers \ud83d\udc49ml-surveys",
	"data-mining data-science deep-learning deep-reinforcement-learning genetic-algorithm machine-learning machine-learning-from-scratch": "Machine Learning From Scratch\nAbout\nPython implementations of some of the fundamental Machine Learning models and algorithms from scratch.\nThe purpose of this project is not to produce as optimized and computationally efficient algorithms as possible\nbut rather to present the inner workings of them in a transparent and accessible way.\nTable of Contents\nMachine Learning From Scratch\nAbout\nTable of Contents\nInstallation\nExamples\nPolynomial Regression\nClassification With CNN\nDensity-Based Clustering\nGenerating Handwritten Digits\nDeep Reinforcement Learning\nImage Reconstruction With RBM\nEvolutionary Evolved Neural Network\nGenetic Algorithm\nAssociation Analysis\nImplementations\nSupervised Learning\nUnsupervised Learning\nReinforcement Learning\nDeep Learning\nContact\nInstallation\n$ git clone https://github.com/eriklindernoren/ML-From-Scratch\n$ cd ML-From-Scratch\n$ python setup.py install\nExamples\nPolynomial Regression\n$ python mlfromscratch/examples/polynomial_regression.py\nFigure: Training progress of a regularized polynomial regression model fitting \ntemperature data measured in Link\u00f6ping, Sweden 2016.\n\nClassification With CNN\n$ python mlfromscratch/examples/convolutional_neural_network.py\n+---------+\n| ConvNet |\n+---------+\nInput Shape: (1, 8, 8)\n+----------------------+------------+--------------+\n| Layer Type           | Parameters | Output Shape |\n+----------------------+------------+--------------+\n| Conv2D               | 160        | (16, 8, 8)   |\n| Activation (ReLU)    | 0          | (16, 8, 8)   |\n| Dropout              | 0          | (16, 8, 8)   |\n| BatchNormalization   | 2048       | (16, 8, 8)   |\n| Conv2D               | 4640       | (32, 8, 8)   |\n| Activation (ReLU)    | 0          | (32, 8, 8)   |\n| Dropout              | 0          | (32, 8, 8)   |\n| BatchNormalization   | 4096       | (32, 8, 8)   |\n| Flatten              | 0          | (2048,)      |\n| Dense                | 524544     | (256,)       |\n| Activation (ReLU)    | 0          | (256,)       |\n| Dropout              | 0          | (256,)       |\n| BatchNormalization   | 512        | (256,)       |\n| Dense                | 2570       | (10,)        |\n| Activation (Softmax) | 0          | (10,)        |\n+----------------------+------------+--------------+\nTotal Parameters: 538570\nTraining: 100% [------------------------------------------------------------------------] Time: 0:01:55\nAccuracy: 0.987465181058\nFigure: Classification of the digit dataset using CNN.\n\nDensity-Based Clustering\n$ python mlfromscratch/examples/dbscan.py\nFigure: Clustering of the moons dataset using DBSCAN.\n\nGenerating Handwritten Digits\n$ python mlfromscratch/unsupervised_learning/generative_adversarial_network.py\n+-----------+\n| Generator |\n+-----------+\nInput Shape: (100,)\n+------------------------+------------+--------------+\n| Layer Type             | Parameters | Output Shape |\n+------------------------+------------+--------------+\n| Dense                  | 25856      | (256,)       |\n| Activation (LeakyReLU) | 0          | (256,)       |\n| BatchNormalization     | 512        | (256,)       |\n| Dense                  | 131584     | (512,)       |\n| Activation (LeakyReLU) | 0          | (512,)       |\n| BatchNormalization     | 1024       | (512,)       |\n| Dense                  | 525312     | (1024,)      |\n| Activation (LeakyReLU) | 0          | (1024,)      |\n| BatchNormalization     | 2048       | (1024,)      |\n| Dense                  | 803600     | (784,)       |\n| Activation (TanH)      | 0          | (784,)       |\n+------------------------+------------+--------------+\nTotal Parameters: 1489936\n+---------------+\n| Discriminator |\n+---------------+\nInput Shape: (784,)\n+------------------------+------------+--------------+\n| Layer Type             | Parameters | Output Shape |\n+------------------------+------------+--------------+\n| Dense                  | 401920     | (512,)       |\n| Activation (LeakyReLU) | 0          | (512,)       |\n| Dropout                | 0          | (512,)       |\n| Dense                  | 131328     | (256,)       |\n| Activation (LeakyReLU) | 0          | (256,)       |\n| Dropout                | 0          | (256,)       |\n| Dense                  | 514        | (2,)         |\n| Activation (Softmax)   | 0          | (2,)         |\n+------------------------+------------+--------------+\nTotal Parameters: 533762\nFigure: Training progress of a Generative Adversarial Network generating \nhandwritten digits.\n\nDeep Reinforcement Learning\n$ python mlfromscratch/examples/deep_q_network.py\n+----------------+\n| Deep Q-Network |\n+----------------+\nInput Shape: (4,)\n+-------------------+------------+--------------+\n| Layer Type        | Parameters | Output Shape |\n+-------------------+------------+--------------+\n| Dense             | 320        | (64,)        |\n| Activation (ReLU) | 0          | (64,)        |\n| Dense             | 130        | (2,)         |\n+-------------------+------------+--------------+\nTotal Parameters: 450\nFigure: Deep Q-Network solution to the CartPole-v1 environment in OpenAI gym.\n\nImage Reconstruction With RBM\n$ python mlfromscratch/examples/restricted_boltzmann_machine.py\nFigure: Shows how the network gets better during training at reconstructing \nthe digit 2 in the MNIST dataset.\n\nEvolutionary Evolved Neural Network\n$ python mlfromscratch/examples/neuroevolution.py\n+---------------+\n| Model Summary |\n+---------------+\nInput Shape: (64,)\n+----------------------+------------+--------------+\n| Layer Type           | Parameters | Output Shape |\n+----------------------+------------+--------------+\n| Dense                | 1040       | (16,)        |\n| Activation (ReLU)    | 0          | (16,)        |\n| Dense                | 170        | (10,)        |\n| Activation (Softmax) | 0          | (10,)        |\n+----------------------+------------+--------------+\nTotal Parameters: 1210\nPopulation Size: 100\nGenerations: 3000\nMutation Rate: 0.01\n[0 Best Individual - Fitness: 3.08301, Accuracy: 10.5%]\n[1 Best Individual - Fitness: 3.08746, Accuracy: 12.0%]\n...\n[2999 Best Individual - Fitness: 94.08513, Accuracy: 98.5%]\nTest set accuracy: 96.7%\nFigure: Classification of the digit dataset by a neural network which has\nbeen evolutionary evolved.\n\nGenetic Algorithm\n$ python mlfromscratch/examples/genetic_algorithm.py\n+--------+\n|   GA   |\n+--------+\nDescription: Implementation of a Genetic Algorithm which aims to produce\nthe user specified target string. This implementation calculates each\ncandidate's fitness based on the alphabetical distance between the candidate\nand the target. A candidate is selected as a parent with probabilities proportional\nto the candidate's fitness. Reproduction is implemented as a single-point\ncrossover between pairs of parents. Mutation is done by randomly assigning\nnew characters with uniform probability.\nParameters\nTarget String: 'Genetic Algorithm'\nPopulation Size: 100\nMutation Rate: 0.05\n[0 Closest Candidate: 'CJqlJguPlqzvpoJmb', Fitness: 0.00]\n[1 Closest Candidate: 'MCxZxdr nlfiwwGEk', Fitness: 0.01]\n[2 Closest Candidate: 'MCxZxdm nlfiwwGcx', Fitness: 0.01]\n[3 Closest Candidate: 'SmdsAklMHn kBIwKn', Fitness: 0.01]\n[4 Closest Candidate: '  lotneaJOasWfu Z', Fitness: 0.01]\n...\n[292 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]\n[293 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]\n[294 Answer: 'Genetic Algorithm']\nAssociation Analysis\n$ python mlfromscratch/examples/apriori.py\n+-------------+\n|   Apriori   |\n+-------------+\nMinimum Support: 0.25\nMinimum Confidence: 0.8\nTransactions:\n    [1, 2, 3, 4]\n    [1, 2, 4]\n    [1, 2]\n    [2, 3, 4]\n    [2, 3]\n    [3, 4]\n    [2, 4]\nFrequent Itemsets:\n    [1, 2, 3, 4, [1, 2], [1, 4], [2, 3], [2, 4], [3, 4], [1, 2, 4], [2, 3, 4]]\nRules:\n    1 -> 2 (support: 0.43, confidence: 1.0)\n    4 -> 2 (support: 0.57, confidence: 0.8)\n    [1, 4] -> 2 (support: 0.29, confidence: 1.0)\nImplementations\nSupervised Learning\nAdaboost\nBayesian Regression\nDecision Tree\nElastic Net\nGradient Boosting\nK Nearest Neighbors\nLasso Regression\nLinear Discriminant Analysis\nLinear Regression\nLogistic Regression\nMulti-class Linear Discriminant Analysis\nMultilayer Perceptron\nNaive Bayes\nNeuroevolution\nParticle Swarm Optimization of Neural Network\nPerceptron\nPolynomial Regression\nRandom Forest\nRidge Regression\nSupport Vector Machine\nXGBoost\nUnsupervised Learning\nApriori\nAutoencoder\nDBSCAN\nFP-Growth\nGaussian Mixture Model\nGenerative Adversarial Network\nGenetic Algorithm\nK-Means\nPartitioning Around Medoids\nPrincipal Component Analysis\nRestricted Boltzmann Machine\nReinforcement Learning\nDeep Q-Network\nDeep Learning\nNeural Network\nLayers\nActivation Layer\nAverage Pooling Layer\nBatch Normalization Layer\nConstant Padding Layer\nConvolutional Layer\nDropout Layer\nFlatten Layer\nFully-Connected (Dense) Layer\nFully-Connected RNN Layer\nMax Pooling Layer\nReshape Layer\nUp Sampling Layer\nZero Padding Layer\nModel Types\nConvolutional Neural Network\nMultilayer Perceptron\nRecurrent Neural Network\nContact\nIf there's some implementation you would like to see here or if you're just feeling social,\nfeel free to email me or connect with me on LinkedIn.",
	"data-analysis data-science data-visualization deep-learning developer-tools machine-learning python streamlit": "Welcome to Streamlit :wave:\nThe fastest way to build and share data apps.\nStreamlit lets you turn data scripts into shareable web apps in minutes, not weeks. It\u2019s all Python, open-source, and free! And once you\u2019ve created an app you can use our\u00a0Community Cloud platform\u00a0to deploy, manage, and share your app!\nInstallation\nbash\npip install streamlit\nstreamlit hello\nStreamlit can also be installed in a virtual environment on Windows, Mac, and Linux.\nA little example\nStreamlit makes it incredibly easy to build interactive apps:\npython\nimport streamlit as st\nx = st.slider('Select a value')\nst.write(x, 'squared is', x * x)\nA bigger example\nStreamlit's simple and focused API lets you build incredibly rich and powerful tools.\u00a0 This demo project lets you browse the entire Udacity self-driving-car dataset and run inference in real-time using the YOLO object detection net.\nThe complete demo is implemented in less than 300 lines of Python. In fact, the app contains only 23 Streamlit calls which illustrates all the major building blocks of Streamlit. You can try it right now at share.streamlit.io/streamlit/demo-self-driving.\nThe Streamlit GitHub badge\nStreamlit's GitHub badge helps others find and play with your Streamlit app.\nOnce you deploy your app, you can embed this badge right into your GitHub readme.md as follows:\nmarkdown\n\nMore Information\nOur launch post explaining why we created Streamlit\nOur Community Cloud platform announcement\nOur amazing community where Streamlit users share apps, ask questions, and help each other out\nStreamlit documentation and blog for the latest Streamlit info\nMore demo projects to inspire you\nAnd if you would like to contribute, see instructions here\nCommunity Cloud\nWith Community Cloud you can deploy, manage, and share your apps with the world, directly from Streamlit \u2014 all for free. Sign-up here.\nLicense\nStreamlit is completely free and open-source and licensed under the Apache 2.0 license.",
	"ai artificial-intelligence data-science deep-learning machine-learning python pytorch": " NEWS: PyTorch Lightning has been renamed Lightning! In addition to building models, you can now build lightning apps that glue together everything around the models, without the pain of infrastructure, cost management, scaling and everything else.\nBuild and train PyTorch models and connect them to the ML lifecycle using Lightning App templates, without handling DIY infrastructure, cost management, scaling, and other headaches.\n\nLightning Gallery \u2022\n  Key Features \u2022\n  How To Use \u2022\n  Docs \u2022\n  Examples \u2022\n  Community \u2022\n  Contribute \u2022\n  License\n\n\n\n\n\n\n\n\n\n*Codecov is > 90%+ but build delays may show less\nPyTorch Lightning is just organized PyTorch\nLightning disentangles PyTorch code to decouple the science from the engineering.\nBuild AI products with Lightning Apps\nOnce you're done building models, publish a paper demo or build a full production end-to-end ML system with Lightning Apps. Lightning Apps remove the cloud infrastructure boilerplate so you can focus on solving the research or business problems. Lightning Apps can run on the Lightning Cloud, your own cluster or a private cloud.\nBrowse available Lightning apps here\nLearn more about Lightning Apps\nLightning Design Philosophy\nLightning structures PyTorch code with these principles:\nLightning forces the following structure to your code which makes it reusable and shareable:\nResearch code (the LightningModule).\nEngineering code (you delete, and is handled by the Trainer).\nNon-essential research code (logging, etc... this goes in Callbacks).\nData (use PyTorch DataLoaders or organize them into a LightningDataModule).\nOnce you do this, you can train on multiple-GPUs, TPUs, CPUs and even in 16-bit precision without changing your code!\nGet started in just 15 minutes\nContinuous Integration\nLightning is rigorously tested across multiple CPUs, GPUs, TPUs, IPUs, and HPUs and against major Python and PyTorch versions.\nCurrent build statuses\n|   System / PyTorch ver.    |                                                                                                              1.10                                                                                                               |                                                                                                       1.12                                                                                                       |\n| :------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\n|  Linux py3.7 [GPUs**]  |                                                                                                                -                                                                                                                |                                                                                                        -                                                                                                         |\n| Linux py3.7 [TPUs***] |                                                                                                                -                                                                                                                |                                                                                                        -                                                                                                         |\n|    Linux py3.8 [IPUs]    |                                                                                                                -                                                                                                                |                                                                                                        -                                                                                                         |\n|    Linux py3.8 [HPUs]    |  |                                                                                                        -                                                                                                         |\n|      Linux py3.{7,9}       |                                                                                                                -                                                                                                                |  |\n|       OSX py3.{7,9}        |                                                                                                                -                                                                                                                |  |\n|     Windows py3.{7,9}      |                                                                                                                -                                                                                                                |  |\n\n** tests run on two NVIDIA P100\n*** tests run on Google GKE TPUv2/3. TPU py3.7 means we support Colab and Kaggle env.\n\nHow To Use\nStep 0: Install\nSimple installation from PyPI\nbash\npip install pytorch-lightning\nOther installation options\nInstall with optional dependencies\nbash\npip install pytorch-lightning['extra']\nConda\nbash\nconda install pytorch-lightning -c conda-forge\nInstall stable version\nInstall future release from the source\nbash\npip install https://github.com/Lightning-AI/lightning/archive/refs/heads/release/stable.zip -U\nInstall bleeding-edge\nInstall nightly from the source (no guarantees)\nbash\npip install https://github.com/Lightning-AI/lightning/archive/refs/heads/master.zip -U\nor from testing PyPI\nbash\npip install -iU https://test.pypi.org/simple/ pytorch-lightning\nStep 1: Add these imports\npython\nimport os\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import transforms\nimport pytorch_lightning as pl\nStep 2: Define a LightningModule (nn.Module subclass)\nA LightningModule defines a full system (ie: a GAN, autoencoder, BERT or a simple Image Classifier).\n```python\nclass LitAutoEncoder(pl.LightningModule):\n    def init(self):\n        super().init()\n        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))\n        self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))\ndef forward(self, x):\n    # in lightning, forward defines the prediction/inference actions\n    embedding = self.encoder(x)\n    return embedding\ndef training_step(self, batch, batch_idx):\n    # training_step defines the train loop. It is independent of forward\n    x, y = batch\n    x = x.view(x.size(0), -1)\n    z = self.encoder(x)\n    x_hat = self.decoder(z)\n    loss = F.mse_loss(x_hat, x)\n    self.log(\"train_loss\", loss)\n    return loss\ndef configure_optimizers(self):\n    optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n    return optimizer\nNote: Training_step defines the training loop. Forward defines how the LightningModule behaves during inference/prediction.\nStep 3: Train!python\ndataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\ntrain, val = random_split(dataset, [55000, 5000])\nautoencoder = LitAutoEncoder()\ntrainer = pl.Trainer()\ntrainer.fit(autoencoder, DataLoader(train), DataLoader(val))\n```\nAdvanced features\nLightning has over 40+ advanced features designed for professional AI research at scale.\nHere are some examples:\nHighlighted feature code snippets\n```python\n8 GPUs\nno code changes needed\ntrainer = Trainer(max_epochs=1, accelerator=\"gpu\", devices=8)\n256 GPUs\ntrainer = Trainer(max_epochs=1, accelerator=\"gpu\", devices=8, num_nodes=32)\n```\nTrain on TPUs without code changes\n```python\nno code changes needed\ntrainer = Trainer(accelerator=\"tpu\", devices=8)\n```\n16-bit precision\n```python\nno code changes needed\ntrainer = Trainer(precision=16)\n```\nExperiment managers\n```python\nfrom pytorch_lightning import loggers\ntensorboard\ntrainer = Trainer(logger=TensorBoardLogger(\"logs/\"))\nweights and biases\ntrainer = Trainer(logger=loggers.WandbLogger())\ncomet\ntrainer = Trainer(logger=loggers.CometLogger())\nmlflow\ntrainer = Trainer(logger=loggers.MLFlowLogger())\nneptune\ntrainer = Trainer(logger=loggers.NeptuneLogger())\n... and dozens more\n```\nEarlyStopping\npython\nes = EarlyStopping(monitor=\"val_loss\")\ntrainer = Trainer(callbacks=[es])\nCheckpointing\npython\ncheckpointing = ModelCheckpoint(monitor=\"val_loss\")\ntrainer = Trainer(callbacks=[checkpointing])\nExport to torchscript (JIT) (production use)\n```python\ntorchscript\nautoencoder = LitAutoEncoder()\ntorch.jit.save(autoencoder.to_torchscript(), \"model.pt\")\n```\nExport to ONNX (production use)\n```python\nonnx\nwith tempfile.NamedTemporaryFile(suffix=\".onnx\", delete=False) as tmpfile:\n    autoencoder = LitAutoEncoder()\n    input_sample = torch.randn((1, 64))\n    autoencoder.to_onnx(tmpfile.name, input_sample, export_params=True)\n    os.path.isfile(tmpfile.name)\n```\nPro-level control of training loops (advanced users)\nFor complex/professional level work, you have optional full control of the training loop and optimizers.\n```python\nclass LitAutoEncoder(pl.LightningModule):\n    def init(self):\n        super().init()\n        self.automatic_optimization = False\ndef training_step(self, batch, batch_idx):\n    # access your optimizers with use_pl_optimizer=False. Default is True\n    opt_a, opt_b = self.optimizers(use_pl_optimizer=True)\nloss_a = ...\nself.manual_backward(loss_a, opt_a)\nopt_a.step()\nopt_a.zero_grad()\n\nloss_b = ...\nself.manual_backward(loss_b, opt_b, retain_graph=True)\nself.manual_backward(loss_b, opt_b)\nopt_b.step()\nopt_b.zero_grad()\n\n```\nAdvantages over unstructured PyTorch\nModels become hardware agnostic\nCode is clear to read because engineering code is abstracted away\nEasier to reproduce\nMake fewer mistakes because lightning handles the tricky engineering\nKeeps all the flexibility (LightningModules are still PyTorch modules), but removes a ton of boilerplate\nLightning has dozens of integrations with popular machine learning tools.\nTested rigorously with every new PR. We test every combination of PyTorch and Python supported versions, every OS, multi GPUs and even TPUs.\nMinimal running speed overhead (about 300 ms per epoch compared with pure PyTorch).\nLightning Lite\nIn the Lightning v1.5 release, LightningLite now enables you to leverage all the capabilities of PyTorch Lightning Accelerators without any refactoring to your training loop. Check out the\nblogpost and\ndocs for more info.\nExamples\nHello world\nMNIST hello world\nContrastive Learning\nBYOL\nCPC v2\nMoco v2\nSIMCLR\nNLP\nGPT-2\nBERT\nReinforcement Learning\nDQN\nDueling-DQN\nReinforce\nVision\nGAN\nClassic ML\nLogistic Regression\nLinear Regression\nCommunity\nThe lightning community is maintained by\n10+ core contributors who are all a mix of professional engineers, Research Scientists, and Ph.D. students from top AI labs.\n590+ active community contributors.\nWant to help us build Lightning and reduce boilerplate for thousands of researchers? Learn how to make your first contribution here\nLightning is also part of the PyTorch ecosystem which requires projects to have solid testing, documentation and support.\nAsking for help\nIf you have any questions please:\nRead the docs.\nSearch through existing Discussions, or add a new question\nJoin our slack.",
	"bioinformatics charting dash data-science data-visualization finance flask gui-framework julia jupyter modeling plotly plotly-dash productivity python r react rstats technical-computing web-app": "Dash\nDash is the most downloaded, trusted Python framework for building ML & data science web apps.\nBuilt on top of Plotly.js, React and Flask, Dash ties modern UI elements like dropdowns, sliders, and graphs directly to your analytical Python code. Read our tutorial (proudly crafted \u2764\ufe0f with Dash itself).\nDocs: Create your first Dash app in under 5 minutes\ndash.gallery: Dash app gallery with Python & R code\nDash App Examples\n| Dash App | Description |\n|--- | :---: |\n| | Here\u2019s a simple example of a Dash App that ties a Dropdown to a Plotly Graph. As the user selects a value in the Dropdown, the application code dynamically exports data from Google Finance into a Pandas DataFrame. This app was written in just 43 lines of code (view the source). |\n||Dash app code is declarative and reactive, which makes it easy to build complex apps that contain many interactive elements. Here\u2019s an example with 5 inputs, 3 outputs, and cross filtering. This app was composed in just 160 lines of code, all of which were Python.|\n|| Dash uses Plotly.js for charting. About 50 chart types are supported, including maps. |\n|| Dash isn't just for dashboards. You have full control over the look and feel of your applications. Here's a Dash App that's styled to look like a PDF report. |\nTo learn more about Dash, read the extensive announcement letter or jump in with the user guide.\nDash OSS & Dash Enterprise\nWith Dash Open Source, Dash apps run on your local laptop or workstation, but cannot be easily accessed by others in your organization.\nScale up with Dash Enterprise when your Dash app is ready for department or company-wide consumption. Or, launch your initiative with Dash Enterprise from the start to unlock developer productivity gains and hands-on acceleration from Plotly's team.\nML Ops Features: A one-stop shop for ML Ops: Horizontally scalable hosting, deployment, and authentication for your Dash apps. No IT or DevOps required.\n- App manager Deploy & manage Dash apps without needing IT or a DevOps team. App Manager gives you point & click control over all aspects of your Dash deployments.\n- Kubernetes scaling Ensure high availability of Dash apps and scale horizontally with Dash Enterprise\u2019s Kubernetes architecture. No IT or Helm required.\n- No code auth Control Dash app access in a few clicks. Dash Enterprise supports LDAP, AD, PKI, Okta, SAML, OpenID Connect, OAuth, SSO, and simple email authentication.\n- Job Queue The Job Queue is the key to building scalable Dash apps. Move heavy computation from synchronous Dash callbacks to the Job Queue for asynchronous background processing.\nLow-Code Features: Low-code Dash app capabilities that supercharge developer productivity.\n- Design Kit Design like a pro without writing a line of CSS. Easily arrange, style, brand, and customize your Dash apps.\n- Snapshot Engine Save & share Dash app views as links or PDFs. Or, run a Python job through Dash and have Snapshot Engine email a report when the job is done.\n- Dashboard Toolkit Drag & drop layouts, chart editing, and crossfilter for your Dash apps.\n- Embedding Natively embed Dash apps in an existing web application or website without the use of IFrames.\nEnterprise AI Features: Everything that your data science team needs to rapidly deliver AI/ML research and business initiatives.\n- AI App Marketplace Dash Enterprise ships with dozens of Dash app templates for business problems where AI/ML is having the greatest impact.\n- Big Data for Pything Connect to Python's most popular big data back ends: Dask, Databricks, NVIDIA RAPIDS, Snowflake, Postgres, Vaex, and more.\n- GPU & Dask Acceleration Dash Enterprise puts Python\u2019s most popular HPC stack for GPU and parallel CPU computing in the hands of business users.\n- Data Science Workspaces Be productive from Day 1. Write and execute Python, R, & Julia code from Dash Enterprise's onboard code editor.\nSee https://plotly.com/contact-us/ to get in touch.",
	"book data-science deep-learning fastai machine-learning notebooks python": "English / Spanish / Korean / Chinese / Bengali / Indonesian / Italian / Portuguese / Vietnamese\nThe fastai book\nThese notebooks cover an introduction to deep learning, fastai, and PyTorch. fastai is a layered API for deep learning; for more information, see the fastai paper. Everything in this repo is copyright Jeremy Howard and Sylvain Gugger, 2020 onwards. A selection of chapters is available to read online here.\nThe notebooks in this repo are used for a MOOC and form the basis of this book, which is currently available for purchase. It does not have the same GPL restrictions that are on this repository.\nThe code in the notebooks and python .py files is covered by the GPL v3 license; see the LICENSE file for details. The remainder (including all markdown cells in the notebooks and other prose) is not licensed for any redistribution or change of format or medium, other than making copies of the notebooks or forking this repo for your own private use. No commercial or broadcast use is allowed. We are making these materials freely available to help you learn deep learning, so please respect our copyright and these restrictions.\nIf you see someone hosting a copy of these materials somewhere else, please let them know that their actions are not allowed and may lead to legal action. Moreover, they would be hurting the community because we're not likely to release additional materials in this way if people ignore our copyright.\nColab\nInstead of cloning this repo and opening it on your machine, you can read and work with the notebooks using Google Colab. This is the recommended approach for folks who are just getting started -- there's no need to set up a Python development environment on your own machine, since you can just work directly in your web-browser.\nYou can open any chapter of the book in Colab by clicking on one of these links: Introduction to Jupyter | Chapter 1, Intro | Chapter 2, Production | Chapter 3, Ethics | Chapter 4, MNIST Basics | Chapter 5, Pet Breeds | Chapter 6, Multi-Category | Chapter 7, Sizing and TTA | Chapter 8, Collab | Chapter 9, Tabular | Chapter 10, NLP | Chapter 11, Mid-Level API | Chapter 12, NLP Deep-Dive | Chapter 13, Convolutions | Chapter 14, Resnet | Chapter 15, Arch Details | Chapter 16, Optimizers and Callbacks | Chapter 17, Foundations | Chapter 18, GradCAM | Chapter 19, Learner | Chapter 20, conclusion\nContributions\nIf you make any pull requests to this repo, then you are assigning copyright of that work to Jeremy Howard and Sylvain Gugger. (Additionally, if you are making small edits to spelling or text, please specify the name of the file and a very brief description of what you're fixing. It's difficult for reviewers to know which corrections have already been made. Thank you.)\nCitations\nIf you wish to cite the book, you may use the following:\n@book{howard2020deep,\ntitle={Deep Learning for Coders with Fastai and Pytorch: AI Applications Without a PhD},\nauthor={Howard, J. and Gugger, S.},\nisbn={9781492045526},\nurl={https://books.google.no/books?id=xd6LxgEACAAJ},\nyear={2020},\npublisher={O'Reilly Media, Incorporated}\n}",
	"data-analysis data-science data-visualization pandas python": "Data Science for Beginners - A Curriculum\nAzure Cloud Advocates at Microsoft are pleased to offer a 10-week, 20-lesson curriculum all about Data Science. Each lesson includes pre-lesson and post-lesson quizzes, written instructions to complete the lesson, a solution, and an assignment. Our project-based pedagogy allows you to learn while building, a proven way for new skills to 'stick'.\nHearty thanks to our authors: Jasmine Greenaway, Dmitry Soshnikov, Nitya Narasimhan, Jalen McGee, Jen Looper, Maud Levy, Tiffany Souterre, Christopher Harrison.\n\ud83d\ude4f Special thanks \ud83d\ude4f to our Microsoft Student Ambassador authors, reviewers and content contributors, notably Aaryan Arora, Aditya Garg, Alondra Sanchez, Ankita Singh, Anupam Mishra, Arpita Das, ChhailBihari Dubey, Dibri Nsofor, Dishita Bhasin, Majd Safi, Max Blum, Miguel Correa, Mohamma Iftekher (Iftu) Ebne Jalal, Nawrin Tabassum, Raymond Wangsa Putra, Rohit Yadav, Samridhi Sharma, Sanya Sinha,\nSheena Narula, Tauqeer Ahmad, Yogendrasingh Pawar , Vidushi Gupta, Jasleen Sondhi\n||\n|:---:|\n| Data Science For Beginners - Sketchnote by @nitya |\nAre you a student?\nGet started with the following resources:\nStudent Hub page In this page, you will find beginner resources, Student packs and even ways to get a free cert voucher. This is one page you want to bookmark and check from time to time as we switch out content at least monthly.\nMicrosoft Learn Student Ambassadors Join a global community of student ambassadors, this could be your way into Microsoft\nGetting Started\nTeachers: we have included some suggestions on how to use this curriculum.  We'd love your feedback in our discussion forum!\nStudents: to use this curriculum on your own, fork the entire repo and complete the exercises on your own, starting with a pre-lecture quiz.  Then read the lecture and complete the rest of the activities. Try to create the projects by comprehending the lessons rather than copying the solution code; however, that code is available in the /solutions folders in each project-oriented lesson. Another idea would be to form a study group with friends and go through the content together. For further study, we recommend Microsoft Learn.\nMeet the Team\nGif by Mohit Jaisal\n\ud83c\udfa5 Click the image above for a video about the project  the folks who created it!\nPedagogy\nWe have chosen two pedagogical tenets while building this curriculum: ensuring that it is project-based and that it includes frequent quizzes. By the end of this series, students will have learned basic principles of data science, including ethical concepts, data preparation, different ways of working with data, data visualization, data analysis, real-world use cases of data science, and more.\nIn addition, a low-stakes quiz before a class sets the intention of the student towards learning a topic, while a second quiz after class ensures further retention. This curriculum was designed to be flexible and fun and can be taken in whole or in part. The projects start small and become increasingly complex by the end of the 10 week cycle.\nFind our Code of Conduct, Contributing,  Translation guidelines. We welcome your constructive feedback!\nEach lesson includes:\nOptional sketchnote\nOptional supplemental video\nPre-lesson warmup quiz\nWritten lesson\nFor project-based lessons, step-by-step guides on how to build the project\nKnowledge checks\nA challenge\nSupplemental reading\nAssignment\nPost-lesson quiz\nA note about quizzes: All quizzes are contained in this app, for 40 total quizzes of three questions each. They are linked from within the lessons, but the quiz app can be run locally; follow the instruction in the quiz-app folder. They are gradually being localized.\nLessons\n||\n|:---:|\n| Data Science For Beginners: Roadmap - Sketchnote by @nitya |\n| Lesson Number | Topic | Lesson Grouping | Learning Objectives | Linked Lesson | Author |\n| :-----------: | :----------------------------------------: | :--------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :---------------------------------------------------------------------: | :----: |\n| 01 | Defining Data Science | Introduction | Learn the basic concepts behind data science and how it\u2019s related to artificial intelligence, machine learning, and big data. | lesson video | Dmitry |\n| 02 | Data Science Ethics | Introduction | Data Ethics Concepts, Challenges & Frameworks. | lesson | Nitya |\n| 03 | Defining Data | Introduction | How data is classified and its common sources. | lesson | Jasmine |\n| 04 | Introduction to Statistics & Probability | Introduction | The mathematical techniques of probability and statistics to understand data. | lesson video | Dmitry |\n| 05 | Working with Relational Data | Working With Data | Introduction to relational data and the basics of exploring and analyzing relational data with the Structured Query Language, also known as SQL (pronounced \u201csee-quell\u201d). | lesson | Christopher | | |\n| 06 | Working with NoSQL Data | Working With Data | Introduction to non-relational data, its various types and the basics of exploring and analyzing document databases. | lesson | Jasmine|\n| 07 | Working with Python | Working With Data | Basics of using Python for data exploration with libraries such as Pandas. Foundational understanding of Python programming is recommended. | lesson video | Dmitry |\n| 08 | Data Preparation | Working With Data | Topics on data techniques for cleaning and transforming the data to handle challenges of missing, inaccurate, or incomplete data. | lesson | Jasmine |\n| 09 | Visualizing Quantities | Data Visualization | Learn how to use Matplotlib to visualize bird data \ud83e\udd86 | lesson | Jen |\n| 10 | Visualizing Distributions of Data | Data Visualization | Visualizing observations and trends within an interval. | lesson | Jen |\n| 11 | Visualizing Proportions | Data Visualization | Visualizing discrete and grouped percentages. | lesson | Jen |\n| 12 | Visualizing Relationships | Data Visualization | Visualizing connections and correlations between sets of data and their variables. | lesson | Jen |\n| 13 | Meaningful Visualizations | Data Visualization | Techniques and guidance for making your visualizations valuable for effective problem solving and insights. | lesson | Jen |\n| 14 | Introduction to the Data Science lifecycle | Lifecycle | Introduction to the data science lifecycle and its first step of acquiring and extracting data. | lesson | Jasmine |\n| 15 | Analyzing | Lifecycle | This phase of the data science lifecycle focuses on techniques to analyze data. | lesson | Jasmine | | |\n| 16 | Communication | Lifecycle | This phase of the data science lifecycle focuses on presenting the insights from the data in a way that makes it easier for decision makers to understand. | lesson | Jalen | | |\n| 17 | Data Science in the Cloud | Cloud Data | This series of lessons introduces data science in the cloud and its benefits. | lesson | Tiffany and Maud |\n| 18 | Data Science in the Cloud | Cloud Data | Training models using Low Code tools. |lesson | Tiffany and Maud |\n| 19 | Data Science in the Cloud | Cloud Data | Deploying models with Azure Machine Learning Studio. | lesson| Tiffany and Maud |\n| 20 | Data Science in the Wild | In the Wild | Data science driven projects in the real world. | lesson | Nitya |\nOffline access\nYou can run this documentation offline by using Docsify. Fork this repo, install Docsify on your local machine,  then in the root folder of this repo, type docsify serve. The website will be served on port 3000 on your localhost: localhost:3000.\nNote, notebooks will not be rendered via Docsify, so when you need to run a notebook, do that separately in VS Code running a Python kernel.\nPDF\nA PDF of all of the lessons can be found here\nHelp Wanted!\nIf you would like to translate all or part of the curriculum, please follow our Translations guide\nOther Curricula\nOur team produces other curricula! Check out:\nMachine Learning for Beginners\nIoT for Beginners\nWeb Dev for Beginners\nAI for Beginners",
	"data-science data-visualization gtk hacktoberfest matplotlib plotting python qt tk wx": "Matplotlib is a comprehensive library for creating static, animated, and\ninteractive visualizations in Python.\nCheck out our home page for more information.\nMatplotlib produces publication-quality figures in a variety of hardcopy\nformats and interactive environments across platforms. Matplotlib can be\nused in Python scripts, Python/IPython shells, web application servers,\nand various graphical user interface toolkits.\nInstall\nSee the install\ndocumentation,\nwhich is generated from /doc/users/installing/index.rst\nContribute\nYou've discovered a bug or something else you want to change -\nexcellent!\nYou've worked out a way to fix it -- even better!\nYou want to tell us about it -- best of all!\nStart at the contributing\nguide!\nContact\nDiscourse is the discussion forum\nfor general questions and discussions and our recommended starting\npoint.\nOur active mailing lists (which are mirrored on Discourse) are:\nUsers\n    mailing list: matplotlib-users@python.org\nAnnouncement\n    mailing list: matplotlib-announce@python.org\nDevelopment\n    mailing list: matplotlib-devel@python.org\nGitter is for coordinating\ndevelopment and asking questions directly related to contributing to\nmatplotlib.\nCiting Matplotlib\nIf Matplotlib contributes to a project that leads to publication, please\nacknowledge this by citing Matplotlib.\nA ready-made citation\nentry is\navailable.\nResearch notice\nPlease note that this repository is participating in a study into\nsustainability of open source projects. Data will be gathered about this\nrepository for approximately the next 12 months, starting from June\n2021.\nData collected will include number of contributors, number of PRs, time\ntaken to close/merge these PRs, and issues closed.\nFor more information, please visit the informational\npage or\ndownload the participant information\nsheet.",
	"architecture awesome awesome-list backend big-data computer-science design-patterns devops distributed-systems interview interview-practice interview-questions lists machine-learning programming resources scalability system system-design web-development": "An updated and organized reading list for illustrating the patterns of scalable, reliable, and performant large-scale systems. Concepts are explained in the articles of prominent engineers and credible references. Case studies are taken from battle-tested systems that serve millions to billions of users.\nIf your system goes slow\nUnderstand your problems: scalability problem (fast for a single user but slow under heavy load) or performance problem (slow for a single user) by reviewing some design principles and checking how scalability and performance problems are solved at tech companies. The section of intelligence are created for those who work with data and machine learning at big (data) and deep (learning) scale.\nIf your system goes down\n\"Even if you lose all one day, you can build all over again if you retain your calm!\" - Thuan Pham, former CTO of Uber. So, keep calm and mind the availability and stability matters! \nIf you are having a system design interview\nLook at some interview notes and real-world architectures with completed diagrams to get a comprehensive view before designing your system on whiteboard. You can check some talks of engineers from tech giants to know how they build, scale, and optimize their systems. There are some selected books for you (most of them are free)! Good luck!\nIf you are building your dream team\nThe goal of scaling team is not growing team size but increasing team output and value. You can find out how tech companies reach that goal in various aspects: hiring, management, organization, culture, and communication in the organization section.\nCommunity power\nContributions are greatly welcome! You may want to take a look at the contribution guidelines. If you see a link here that is no longer maintained or is not a good fit, please submit a pull request!\nMany long hours of hard work have gone into this project. If you find it helpful, please share on Facebook, on Twitter, on Weibo, or on your chat groups! Knowledge is power, knowledge shared is power multiplied. Thank you!\nContent\nPrinciple\nScalability\nAvailability\nStability\nPerformance\nIntelligence\nArchitecture\nInterview\nOrganization\nTalk\nBook\nPrinciple\nLessons from Giant-Scale Services - Eric Brewer, UC Berkeley & Google\nDesigns, Lessons and Advice from Building Large Distributed Systems - Jeff Dean, Google\nHow to Design a Good API & Why it Matters - Joshua Bloch, CMU & Google\nOn Efficiency, Reliability, Scaling - James Hamilton, VP at AWS\nThings to Keep in Mind When Building a Platform for the Enterprise - Heidi Williams, VP Platform at Box\nPrinciples of Chaos Engineering\nFinding the Order in Chaos\nThe Twelve-Factor App\nClean Architecture\nHigh Cohesion and Low Coupling\nMonoliths and Microservices\nCAP Theorem and Trade-offs\nCP Databases and AP Databases\nStateless vs Stateful Scalability \nScale Up vs Scale Out\nScale Up vs Scale Out: Hidden Costs\nACID and BASE\nBlocking/Non-Blocking and Sync/Async\nPerformance and Scalability of Databases\nDatabase Isolation Levels and Effects on Performance and Scalability\nThe Probability of Data Loss in Large Clusters\nData Access for Highly-Scalable Solutions: Using SQL, NoSQL, and Polyglot Persistence\nSQL vs NoSQL\nSQL vs NoSQL - Lesson Learned at Salesforce\nNoSQL Databases: Survey and Decision Guidance\nHow Sharding Works\nConsistent Hashing\nConsistent Hashing: Algorithmic Tradeoffs\nDon\u2019t be tricked by the Hashing Trick\nUniform Consistent Hashing at Netflix\nEventually Consistent - Werner Vogels, CTO at Amazon\nCache is King\nAnti-Caching\nUnderstand Latency\nLatency Numbers Every Programmer Should Know\nThe Calculus of Service Availability\nArchitecture Issues When Scaling Web Applications: Bottlenecks, Database, CPU, IO \nCommon Bottlenecks\nLife Beyond Distributed Transactions\nRelying on Software to Redirect Traffic Reliably at Various Layers\nBreaking Things on Purpose\nAvoid Over Engineering\nScalability Worst Practices\nUse Solid Technologies - Don\u2019t Re-invent the Wheel - Keep It Simple!\nSimplicity by Distributing Complexity\nWhy Over-Reusing is Bad\nPerformance is a Feature\nMake Performance Part of Your Workflow\nThe Benefits of Server Side Rendering over Client Side Rendering\nAutomate and Abstract: Lessons at Facebook\nAWS Do's and Don'ts\n(UI) Design Doesn\u2019t Scale - Stanley Wood, Design Director at Spotify\nLinux Performance\nBuilding Fast and Resilient Web Applications - Ilya Grigorik\nAccept Partial Failures, Minimize Service Loss\nDesign for Resiliency\nDesign for Self-healing\nDesign for Scaling Out \nDesign for Evolution\nLearn from Mistakes\nScalability\nMicroservices and Orchestration\nDomain-Oriented Microservice Architecture at Uber\nContainer (8 parts) at Riot Games\nContainerization at Pinterest\nEvolution of Container Usage at Netflix\nDockerizing MySQL at Uber\nTesting of Microservices at Spotify\nDocker in Production at Treehouse\nMicroservice at SoundCloud\nOperate Kubernetes Reliably at Stripe\nCross-Cluster Traffic Mirroring with Istio at Trivago\nAgrarian-Scale Kubernetes (3 parts) at New York Times\nNanoservices at BBC\nPowerfulSeal: Testing Tool for Kubernetes Clusters at Bloomberg\nConductor: Microservices Orchestrator at Netflix\nDocker Containers that Power Over 100.000 Online Shops at Shopify\nMicroservice Architecture at Medium\nFrom bare-metal to Kubernetes at Betabrand\nKubernetes at Tinder\nKubernetes at Quora \nKubernetes Platform at Pinterest\nMicroservices at Nubank\nPayment Transaction Management in Microservices at Mercari\nService Mesh at Snap\nGRIT: Protocol for Distributed Transactions across Microservices at eBay\nRubix: Kubernetes at Palantir\nCRISP: Critical Path Analysis for Microservice Architectures at Uber\nDistributed Caching\nEVCache: Distributed In-memory Caching at Netflix\nEVCache Cache Warmer Infrastructure at Netflix\nMemsniff: Robust Memcache Traffic Analyzer at Box\nCaching with Consistent Hashing and Cache Smearing at Etsy\nAnalysis of Photo Caching at Facebook\nCache Efficiency Exercise at Facebook\ntCache: Scalable Data-aware Java Caching at Trivago\nPycache: In-process Caching at Quora \nReduce Memcached Memory Usage by 50% at Trivago\nCaching Internal Service Calls at Yelp\nEstimating the Cache Efficiency using Big Data at Allegro\nDistributed Cache at Zalando\nApplication Data Caching from RAM to SSD at NetFlix\nTradeoffs of Replicated Cache at Skyscanner\nAvoiding Cache Stampede at DoorDash\nLocation Caching with Quadtrees at Yext\nVideo Metadata Caching at Vimeo\nScaling Redis at Twitter\nScaling Job Queue with Redis at Slack\nMoving persistent data out of Redis at Github\nStoring Hundreds of Millions of Simple Key-Value Pairs in Redis at Instagram\nRedis at Trivago\nOptimizing Redis Storage at Deliveroo\nMemory Optimization in Redis at Wattpad\nRedis Fleet at Heroku\nSolving Remote Build Cache Misses (2 parts) at SoundCloud\nRatings & Reviews (2 parts) at Flipkart\nPrefetch Caching of Items at eBay\nCross-Region Caching Library at Wix\nImproving Distributed Caching Performance and Efficiency at Pinterest\nHTTP Caching and CDN\nZynga Geo Proxy: Reducing Mobile Game Latency at Zynga\nGoogle AMP at Cond\u00e9 Nast\nA/B Tests on Hosting Infrastructure (CDNs) at Deliveroo\nHAProxy with Kubernetes for User-facing Traffic at SoundCloud\nBandaid: Service Proxy at Dropbox\nCDN in LIVE's Encoder Layer at LINE\nService Workers at Slack\nCDN Services at Spotify\nDistributed Locking\nChubby: Lock Service for Loosely Coupled Distributed Systems at Google\nDistributed Locking at Uber\nDistributed Locks using Redis at GoSquared\nZooKeeper at Twitter\nEliminating Duplicate Queries using Distributed Locking at Chartio\nDistributed Tracking, Tracing, and Measuring\nZipkin: Distributed Systems Tracing at Twitter\nImprove Zipkin Traces using Kubernetes Pod Metadata at SoundCloud\nCanopy: Scalable Distributed Tracing & Analysis at Facebook\nPintrace: Distributed Tracing at Pinterest\nXCMetrics: All-in-One Tool for Tracking Xcode Build Metrics at Spotify\nReal-time Distributed Tracing at LinkedIn \nTracking Service Infrastructure at Scale at Shopify \nDistributed Tracing at HelloFresh\nAnalyzing Distributed Trace Data at Pinterest\nDistributed Tracing at Uber\nJVM Profiler: Tracing Distributed JVM Applications at Uber\nData Checking at Dropbox\nTracing Distributed Systems at Showmax\nosquery Across the Enterprise at Palantir\nStatsD at Etsy\nStatsD at DoorDash\nDistributed Scheduling\nDistributed Task Scheduling (3 parts) at PagerDuty\nBuilding Cron at Google\nDistributed Cron Architecture at Quora\nChronos: A Replacement for Cron at Airbnb\nScheduler at Nextdoor\nPeloton: Unified Resource Scheduler for Diverse Cluster Workloads at Uber\nFenzo: OSS Scheduler for Apache Mesos Frameworks at Netflix\nAirflow - Workflow Orchestration\nAirflow at Airbnb\nAirflow at Pandora\nAirflow at Robinhood\nAirflow at Lyft\nAirflow at Drivy\nAirflow at Grab\nAirflow at Adobe\nAuditing Airflow Job Runs at Walmart\nMaaT: DAG-based Distributed Task Scheduler at Alibaba\nboundary-layer: Declarative Airflow Workflows at Etsy\nDistributed Monitoring and Alerting\nUnicorn: Remediation System at eBay\nM3: Metrics and Monitoring Platform at Uber\nAthena: Automated Build Health Management System at Dropbox\nVortex: Monitoring Server Applications at Dropbox \nNuage: Cloud Management Service at LinkedIn\nTelltale: Application Monitoring at Netflix\nThirdEye: Monitoring Platform at LinkedIn\nPeriskop: Exception Monitoring Service at SoundCloud\nSecuritybot: Distributed Alerting Bot at Dropbox \nMonitoring System at Alibaba\nReal User Monitoring at Dailymotion\nAlerting Ecosystem at Uber\nAlerting Framework at Airbnb\nAlerting on Service-Level Objectives (SLOs) at SoundCloud\nJob-based Forecasting Workflow for Observability Anomaly Detection at Uber\nMonitoring and Alert System using Graphite and Cabot at HackerEarth\nObservability (2 parts) at Twitter\nDistributed Security Alerting at Slack\nReal-Time News Alerting at Bloomberg\nData Pipeline Monitoring System at LinkedIn\nMonitoring and Observability at Picnic\nDistributed Security\nApproach to Security at Scale at Dropbox\nAardvark and Repokid: AWS Least Privilege for Distributed, High-Velocity Development at Netflix \nLISA: Distributed Firewall at LinkedIn\nSecure Infrastructure To Store Bitcoin In The Cloud at Coinbase\nBinaryAlert: Real-time Serverless Malware Detection at Airbnb\nScalable IAM Architecture to Secure Access to 100 AWS Accounts at Segment\nOAuth Audit Toolbox at Indeed\nActive Directory Password Blacklisting at Yelp \nSyscall Auditing at Scale at Slack\nAthenz: Fine-Grained, Role-Based Access Control at Yahoo\nWebAuthn Support for Secure Sign In at Dropbox\nSecurity Development Lifecycle at Slack\nUnprivileged Container Builds at Kinvolk\nDiffy: Differencing Engine for Digital Forensics in the Cloud at Netflix\nDetecting Credential Compromise in AWS at Netflix\nScalable User Privacy at Spotify\nAVA: Audit Web Applications at Indeed\nTTL as a Service: Automatic Revocation of Stale Privileges at Yelp\nEnterprise Key Management at Slack \nScalability and Authentication at Twitch\nEdge Authentication and Token-Agnostic Identity Propagation at Netflix\nHardening Kubernetes Infrastructure with Cilium at Palantir\nImproving Web Vulnerability Management through Automation at Lyft\nClock Skew when Syncing Password Payloads at Drobbox\nDistributed Messaging, Queuing, and Event Streaming\nCape: Event Stream Processing Framework at Dropbox\nBrooklin: Distributed Service for Near Real-Time Data Streaming at LinkedIn\nSamza: Stream Processing System for Latency Insighs at LinkedIn \nBullet: Forward-Looking Query Engine for Streaming Data at Yahoo\nEventHorizon: Tool for Watching Events Streaming at Etsy\nQmessage: Distributed, Asynchronous Task Queue at Quora\nCherami: Message Queue System for Transporting Async Tasks at Uber\nDynein: Distributed Delayed Job Queueing System at Airbnb\nMessaging Service at Riot Games\nDebugging Production with Event Logging at Zillow\nCross-platform In-app Messaging Orchestration Service at Netflix\nVideo Gatekeeper at Netflix\nScaling Push Messaging for Millions of Devices at Netflix\nDelaying Asynchronous Message Processing with RabbitMQ at Indeed \nBenchmarking Streaming Computation Engines at Yahoo\nImproving Stream Data Quality With Protobuf Schema Validation at Deliveroo\nScaling Email Infrastructure at Medium\nEvent Stream Database at Nike\nEvent-Driven Messaging\nDomain-Driven Design at Alibaba\nDomain-Driven Design at Weebly\nDomain-Driven Design at Moonpig\nScaling Event Sourcing for Netflix Downloads\nScaling Event-Sourcing at Jet.com\nEvent Sourcing (2 parts) at eBay\nEvent Sourcing at FREE NOW\nScalable content feed using Event Sourcing and CQRS patterns at Brainly\nPub-Sub Messaging\nPulsar: Pub-Sub Messaging at Scale at Yahoo\nWormhole: Pub-Sub System at Facebook\nMemQ: Cloud Native Pub-Sub System at Pinterest\nPub-Sub in Chatting Architecture at LINE\nPub-Sub in Microservices at Netflix\nKafka - Message Broker \nKafka at LinkedIn\nKafka at Pinterest\nKafka at Trello \nKafka at Salesforce\nKafka at The New York Times\nKafka at Yelp\nKafka at Criteo\nKafka on Kubernetes at Shopify\nKafka on PaaSTA: Running Kafka on Kubernetes at Yelp (2 parts)\nMigrating Kafka's Zookeeper with No Downtime at Yelp\nReprocessing and Dead Letter Queues with Kafka at Uber\nChaperone: Audit Kafka End-to-End at Uber\nFinding Kafka throughput limit in infrastructure at Dropbox\nCost Orchestration at Walmart\nInfluxDB and Kafka to Scale to Over 1 Million Metrics a Second at Hulu\nStream Data Deduplication\nExactly-once Semantics with Kafka\nReal-time Deduping at Tapjoy\nDeduplication at Segment\nDeduplication at Mail.Ru\nPetabyte Scale Data Deduplication at Mixpanel\nDistributed Logging\nLogging at LinkedIn\nScalable and Reliable Log Ingestion at Pinterest\nHigh-performance Replicated Log Service at Twitter\nLogging Service with Spark at CERN Accelerator\nLogging and Aggregation at Quora\nCollection and Analysis of Daemon Logs at Badoo\nLog Parsing with Static Code Analysis at Palantir \nCentralized Application Logging at eBay\nEnrich VPC Flow Logs at Hyper Scale to provide Network Insight at Netflix \nBookKeeper: Distributed Log Storage at Yahoo\nLogDevice: Distributed Data Store for Logs at Facebook\nLogFeeder: Log Collection System at Yelp\nDBLog: Generic Change-Data-Capture Framework at Netflix \nDistributed Searching\nSearch Architecture at Instagram\nSearch Architecture at eBay\nSearch Architecture at Box\nSearch Discovery Indexing Platform at Coupang\nUniversal Search System at Pinterest\nImproving Search Engine Efficiency by over 25% at eBay \nIndexing and Querying Telemetry Logs with Lucene at Palantir\nQuery Understanding at TripAdvisor\nSearch Federation Architecture at LinkedIn (2018)\nSearch at Slack\nSearch and Recommendations at DoorDash\nSearch Service at Twitter (2014)\nAutocomplete Search (2 parts) at Traveloka\nData-Driven Autocorrection System at Canva\nAdapting Search to Indian Phonetics at Flipkart\nNautilus: Search Engine at Dropbox\nGalene: Search Architecture of LinkedIn\nManas: High Performing Customized Search System at Pinterest\nSherlock: Near Real Time Search Indexing at Flipkart\nNebula: Storage Platform to Build Search Backends at Airbnb\nELK (Elasticsearch, Logstash, Kibana) Stack\nPredictions in Real Time with ELK at Uber\nBuilding a scalable ELK stack at Envato\nELK at Robinhood\nScaling Elasticsearch Clusters at Uber\nElasticsearch Performance Tuning Practice at eBay\nImprove Performance using Elasticsearch Plugins (2 parts) at Tinder\nElasticsearch at Kickstarter\nLog Parsing with Logstash and Google Protocol Buffers at Trivago\nFast Order Search using Data Pipeline and Elasticsearch at Yelp\nMoving Core Business Search to Elasticsearch at Yelp\nSharding out Elasticsearch at Vinted\nSelf-Ranking Search with Elasticsearch at Wattpad\nVulcanizer: a library for operating Elasticsearch at Github \nDistributed Storage\nIn-memory Storage\nMemSQL Architecture - The Fast (MVCC, InMem, LockFree, CodeGen) And Familiar (SQL)\nOptimizing Memcached Efficiency at Quora\nReal-Time Data Warehouse with MemSQL on Cisco UCS\nMoving to MemSQL at Tapjoy\nMemSQL and Kinesis for Real-time Insights at Disney\nMemSQL to Query Hundreds of Billions of Rows in a Dashboard at Pandora\nObject Storage\nScaling HDFS at Uber\nReasons for Choosing S3 over HDFS at Databricks\nFile System on Amazon S3 at Quantcast\nImage Recovery at Scale Using S3 Versioning at Trivago\nCloud Object Store at Yahoo\nAmbry: Distributed Immutable Object Store at LinkedIn\nDynamometer: Scale Testing HDFS on Minimal Hardware with Maximum Fidelity at LinkedIn\nHammerspace: Persistent, Concurrent, Off-heap Storage at Airbnb\nMezzFS: Mounting Object Storage in Media Processing Platform at Netflix \nMagic Pocket: In-house Multi-exabyte Storage System at Dropbox\nRelational Databases\nMySQL for Schema-less Data at FriendFeed\nMySQL at Pinterest\nPostgreSQL at Twitch\nScaling MySQL-based Financial Reporting System at Airbnb\nScaling MySQL at Wix\nMaxScale (MySQL) Database Proxy at Airbnb\nSwitching from Postgres to MySQL at Uber\nHandling Growth with Postgres at Instagram\nScaling the Analytics Database (Postgres) at TransferWise\nUpdating a 50 Terabyte PostgreSQL Database at Adyen\nScaling Database Access for 100s of Billions of Queries per Day at PayPal\nMinimizing Read-Write MySQL Downtime at Yelp\nMigrating MySQL from 5.6 to 8.0 at Facebook\nMigration from HBase to MyRocks at Quora\nReplication\nMySQL Parallel Replication (4 parts) at Booking.com\nMitigating MySQL Replication Lag and Reducing Read Load at Github\nRead Consistency with Database Replicas at Shopify\nBlack-Box Auditing: Verifying End-to-End Replication Integrity between MySQL and Redshift at Yelp\nPartitioning Main MySQL Database at Airbnb\nHerb: Multi-DC Replication Engine for Schemaless Datastore at Uber\nSharding\nSharding MySQL at Pinterest\nSharding MySQL at Twilio\nSharding MySQL at Square\nSharding MySQL at Quora\nSharding Layer of Schemaless Datastore at Uber\nSharding & IDs at Instagram\nSharding Postgres at Notion\nSolr: Improving Performance for Batch Indexing at Box \nGeosharded Recommendations (3 parts) at Tinder\nScaling Services with Shard Manager at Facebook\nPresto the Distributed SQL Query Engine\nPresto at Pinterest\nPresto Infrastructure at Lyft\nPresto at Grab\nEngineering Data Analytics with Presto and Apache Parquet at Uber\nData Wrangling at Slack\nPresto in Big Data Platform on AWS at Netflix\nPresto Auto Scaling at Eventbrite\nNoSQL Databases\nKey-Value Databases\nDynamoDB at Nike\nDynamoDB at Segment\nDynamoDB at Mapbox\nManhattan: Distributed Key-Value Database at Twitter\nSherpa: Distributed NoSQL Key-Value Store at Yahoo\nHaloDB: Embedded Key-Value Storage Engine at Yahoo\nMPH: Fast and Compact Immutable Key-Value Stores at Indeed\nVenice: Distributed Key-Value Database at Linkedin\nColumnar Databases\nCassandra\nCassandra at Instagram\nStoring Images in Cassandra at Walmart\nStoring Messages with Cassandra at Discord\nScaling Cassandra Cluster at Walmart\nScaling Ad Analytics with Cassandra at Yelp\nScaling to 100+ Million Reads/Writes using Spark and Cassandra at Dream11 \nMoving Food Feed from Redis to Cassandra at Zomato\nBenchmarking Cassandra Scalability on AWS at Netflix\nService Decomposition at Scale with Cassandra at Intuit QuickBooks\nCassandra for Keeping Counts In Sync at SoundCloud\nCassandra Driver Configuration for Improved Performance and Load Balancing at Glassdoor\ncstar: Cassandra Orchestration Tool at Spotify\nHBase\nHBase at Salesforce\nHBase in Facebook Messages\nHBase in Imgur Notification\nImproving HBase Backup Efficiency at Pinterest\nHBase at Xiaomi\nRedshift\nRedshift at GIPHY\nRedshift at Hudl\nRedshift at Drivy\nDocument Databases\neBay: Building Mission-Critical Multi-Data Center Applications with MongoDB\nMongoDB at Baidu: Multi-Tenant Cluster Storing 200+ Billion Documents across 160 Shards\nMigrating Mongo Data at Addepar\nThe AWS and MongoDB Infrastructure of Parse (acquired by Facebook)\nMigrating Mountains of Mongo Data at Addepar\nCouchbase Ecosystem at LinkedIn\nSimpleDB at Zendesk\nEspresso: Distributed Document Store at LinkedIn\nGraph Databases\nFlockDB: Distributed Graph Database at Twitter\nTAO: Distributed Data Store for the Social Graph at Facebook\nAkutan: Distributed Knowledge Graph Store at eBay\nTime Series Databases\nBeringei: High-performance Time Series Storage Engine at Facebook\nMetricsDB: TimeSeries Database for storing metrics at Twitter \nAtlas: In-memory Dimensional Time Series Database at Netflix\nHeroic: Time Series Database at Spotify\nRoshi: Distributed Storage System for Time-Series Event at SoundCloud\nGoku: Time Series Database at Pinterest\nScaling Time Series Data Storage (2 parts) at Netflix \nDruid - Real-time Analytics Database\nDruid at Airbnb\nDruid at Walmart\nDruid at eBay\nDruid at Netflix\nDistributed Repositories, Dependencies, and Configurations Management\nDGit: Distributed Git at Github\nStemma: Distributed Git Server at Palantir\nConfiguration Management for Distributed Systems at Flickr\nGit Repository at Microsoft\nSolve Git Problem with Large Repositories at Microsoft \nSingle Repository at Google \nScaling Infrastructure and (Git) Workflow at Adyen \nDotfiles Distribution at Booking.com\nSecret Detector: Preventing Secrets in Source Code at Yelp\nManaging Software Dependency at Scale at LinkedIn\nMerging Code in High-velocity Repositories at LinkedIn\nDynamic Configuration at Twitter\nDynamic Configuration at Mixpanel\nDynamic Configuration at GoDaddy\nScaling Continuous Integration and Continuous Delivery\nContinuous Integration Stack at Facebook\nContinuous Integration with Distributed Repositories and Dependencies at Netflix\nContinuous Integration and Deployment with Bazel at Dropbox\nContinuous Deployments at BuzzFeed\nScrewdriver: Continuous Delivery Build System for Dynamic Infrastructure at Yahoo\nCI/CD at Betterment\nCI/CD at Brainly\nScaling iOS CI with Anka at Shopify\nScaling Jira Server at Yelp\nAuto-scaling CI/CD cluster at Flexport\nAvailability\nResilience Engineering: Learning to Embrace Failure \nResilience Engineering with Project Waterbear at LinkedIn\nResiliency against Traffic Oversaturation at iHeartRadio\nResiliency in Distributed Systems at GO-JEK\nPractical NoSQL Resilience Design Pattern for the Enterprise at eBay\nEnsuring Resilience to Disaster at Quora\nSite Resiliency at Expedia\nResiliency and Disaster Recovery with Kafka at eBay\nDisaster Recovery for Multi-Region Kafka at Uber\nFailover\nThe Evolution of Global Traffic Routing and Failover\nTesting for Disaster Recovery Failover Testing\nDesigning a Microservices Architecture for Failure\nELB for Automatic Failover at GoSquared\nEliminate the Database for Higher Availability at American Express\nFailover with Redis Sentinel at Vinted\nHigh-availability SaaS Infrastructure at FreeAgent\nMySQL High Availability at GitHub\nMySQL High Availability at Eventbrite\nBusiness Continuity & Disaster Recovery at Walmart\nLoad Balancing\nIntroduction to Modern Network Load Balancing and Proxying\nTop Five (Load Balancing) Scalability Patterns\nLoad Balancing infrastructure to support more than 1.3 billion users at Facebook\nDHCPLB: DHCP Load Balancer at Facebook\nKatran: Scalable Network Load Balancer at Facebook\nDeterministic Aperture: A Distributed, Load Balancing Algorithm at Twitter \nLoad Balancing with Eureka at Netflix\nEdge Load Balancing at Netflix\nZuul 2: Cloud Gateway at Netflix\nLoad Balancing at Yelp\nLoad Balancing at Github\nConsistent Hashing to Improve Load Balancing at Vimeo\nUDP Load Balancing at 500 pixel\nQALM: QoS Load Management Framework at Uber \nTraffic Steering using Rum DNS at LinkedIn\nTraffic Infrastructure (Edge Network) at Dropbox\nIntelligent DNS based load balancing at Dropbox\nMonitor DNS systems at Stripe\nMulti-DNS Architecture (3 parts) at Monday\nDynamic Anycast DNS Infrastructure at Hulu\nRate Limiting\nRate Limiting for Scaling to Millions of Domains at Cloudflare\nCloud Bouncer: Distributed Rate Limiting at Yahoo\nScaling API with Rate Limiters at Stripe\nDistributed Rate Limiting at Allegro\nRatequeue: Core Queueing-And-Rate-Limiting System at Twilio\nQuotas Service at Grab\nAutoscaling\nAutoscaling Pinterest\nAutoscaling Based on Request Queuing at Square\nAutoscaling Jenkins at Trivago\nAutoscaling Pub-Sub Consumers at Spotify\nAutoscaling Bigtable Clusters based on CPU Load at Spotify\nAutoscaling AWS Step Functions Activities at Yelp\nScryer: Predictive Auto Scaling Engine at Netflix \nBouncer: Simple AWS Auto Scaling Rollovers at Palantir\nClusterman: Autoscaling Mesos Clusters at Yelp\nAvailability in Globally Distributed Storage Systems at Google \nNodeJS High Availability at Yahoo\nOperations (11 parts) at LinkedIn\nMonitoring Powers High Availability for LinkedIn Feed\nSupporting Global Events at Facebook\nHigh Availability at BlaBlaCar\nHigh Availability at Netflix\nHigh Availability Cloud Infrastructure at Twilio\nAutomating Datacenter Operations at Dropbox\nGlobalizing Player Accounts at Riot Games\nStability\nCircuit Breaker\nCircuit Breaking in Distributed Systems\nCircuit Breaker for Scaling Containers\nCircuit Breakers for Distributed Services at LINE\nApplying Circuit Breaker to Channel Gateway at LINE\nLessons in Resilience at SoundCloud\nProtector: Circuit Breaker for Time Series Databases at Trivago\nImproved Production Stability with Circuit Breakers at Heroku\nCircuit Breaker at Zendesk\nCircuit Breaker at Traveloka\nCircuit Breaker at Shopify\nTimeouts\nFault Tolerance (Timeouts and Retries, Thread Separation, Semaphores, Circuit Breakers) at Neflix\nEnforce Timeout: A Reliability Methodology at DoorDash\nTroubleshooting a Connection Timeout Issue with tcp_tw_recycle Enabled at eBay\nCrash-safe Replication for MySQL at Booking.com\nBulkheads: Partition and Tolerate Failure in One Part\nSteady State: Always Put Logs on Separate Disk\nThrottling: Maintain a Steady Pace\nMulti-Clustering: Improving Resiliency and Stability of a Large-scale Monolithic API Service at LinkedIn\nDeterminism (4 parts) in League of Legends Server\nPerformance\nPerformance Optimization on OS, Storage, Database, Network\nImproving Performance with Background Data Prefetching at Instagram\nFixing Linux filesystem performance regressions at LinkedIn\nCompression Techniques to Solve Network I/O Bottlenecks at eBay\nOptimizing Web Servers for High Throughput and Low Latency at Dropbox\nLinux Performance Analysis in 60.000 Milliseconds at Netflix\nLive Downsizing Google Cloud Persistent Disks (PD-SSD) at Mixpanel\nDecreasing RAM Usage by 40% Using jemalloc with Python & Celery at Zapier\nReducing Memory Footprint at Slack\nContinuous Load Testing at Slack\nPerformance Improvements at Pinterest\nServer Side Rendering at Wix\n30x Performance Improvements on MySQLStreamer at Yelp\nOptimizing APIs at Netflix\nPerformance Monitoring with Riemann and Clojure at Walmart\nPerformance Tracking Dashboard for Live Games at Zynga\nOptimizing CAL Report Hadoop MapReduce Jobs at eBay\nPerformance Tuning on Quartz Scheduler at eBay\nProfiling C++ (Part 1: Optimization, Part 2: Measurement and Analysis) at Riot Games\nProfiling React Server-Side Rendering at HomeAway\nHardware-Assisted Video Transcoding at Dailymotion\nCross Shard Transactions at 10 Million RPS at Dropbox\nAPI Profiling at Pinterest\nPagelets Parallelize Server-side Processing at Yelp\nImproving key expiration in Redis at Twitter\nAd Delivery Network Performance Optimization with Flame Graphs at MindGeek\nPredictive CPU isolation of containers at Netflix\nImproving HDFS I/O Utilization for Efficiency at Uber\nCloud Jewels: Estimating kWh in the Cloud at Etsy\nUnthrottled: Fixing CPU Limits in the Cloud (2 parts) at Indeed\nPerformance Optimization by Tuning Garbage Collection\nGarbage Collection in Java Applications at LinkedIn\nGarbage Collection in High-Throughput, Low-Latency Machine Learning Services at Adobe\nGarbage Collection in Redux Applications at SoundCloud\nGarbage Collection in Go Application at Twitch\nAnalyzing V8 Garbage Collection Logs at Alibaba\nPython Garbage Collection for Dropping 50% Memory Growth Per Request at Instagram\nPerformance Impact of Removing Out of Band Garbage Collector (OOBGC) at Github\nDebugging Java Memory Leaks at Allegro\nOptimizing JVM at Alibaba\nTuning JVM Memory for Large-scale Services at Uber\nSolr Performance Tuning at Walmart\nMemory Tuning a High Throughput Microservice at Flipkart\nPerformance Optimization on Image, Video, Page Load\nOptimizing 360 Photos at Scale at Facebook\nReducing Image File Size in the Photos Infrastructure at Etsy\nImproving GIF Performance at Pinterest\nOptimizing Video Playback Performance at Pinterest\nOptimizing Video Stream for Low Bandwidth with Dynamic Optimizer at Netflix\nAdaptive Video Streaming at YouTube\nReducing Video Loading Time at Dailymotion\nImproving Homepage Performance at Zillow\nThe Process of Optimizing for Client Performance at Expedia\nWeb Performance at BBC\nPerformance Optimization by Brotli Compression\nBoosting Site Speed Using Brotli Compression at LinkedIn \nBrotli at Booking.com\nBrotli at Treebo\nDeploying Brotli for Static Content at Dropbox\nProgressive Enhancement with Brotli at Yelp\nSpeeding Up Redis with Compression at Doordash\nPerformance Optimization on Languages and Frameworks\nPython at Netflix\nPython at scale (3 parts) at Instagram\nOCaml best practices (2 parts) at Issuu\nPHP at Slack\nGo at Trivago\nTypeScript at Etsy\nKotlin for taming state at Etsy\nBPF and Go at Bumble\nRuby on Rails at GitLab\nRust in production at Figma\nChoosing a Language Stack at WeWork\nSwitching from Go to Rust at Discord\nASP.NET Core Performance Optimization at Agoda\nData Race Patterns in Go at Uber \nIntelligence\nBig Data \nData Platform at Uber\nData Platform at BMW\nData Platform at Netflix\nData Platform at Flipkart\nData Platform at Coupang\nData Platform at DoorDash\nData Platform at Khan Academy\nData Infrastructure at Airbnb\nData Infrastructure at LinkedIn\nData Infrastructure at GO-JEK\nData Ingestion Infrastructure at Pinterest\nData Analytics Architecture at Pinterest\nData Orchestration Service at Spotify\nBig Data Processing (2 parts) at Spotify\nBig Data Processing at Uber\nAnalytics Pipeline at Lyft\nAnalytics Pipeline at Grammarly\nAnalytics Pipeline at Teads\nML Data Pipelines for Real-Time Fraud Prevention at PayPal\nBig Data Analytics and ML Techniques at LinkedIn\nSelf-Serve Reporting Platform on Hadoop at LinkedIn\nPrivacy-Preserving Analytics and Reporting at LinkedIn\nAnalytics Platform for Tracking Item Availability at Walmart\nHALO: Hardware Analytics and Lifecycle Optimization at Facebook\nRBEA: Real-time Analytics Platform at King\nAresDB: GPU-Powered Real-time Analytics Engine at Uber\nAthenaX: Streaming Analytics Platform at Uber\nDelta: Data Synchronization and Enrichment Platform at Netflix\nKeystone: Real-time Stream Processing Platform at Netflix\nDatabook: Turning Big Data into Knowledge with Metadata at Uber\nAmundsen: Data Discovery & Metadata Engine at Lyft\nMaze: Funnel Visualization Platform at Uber\nMetacat: Making Big Data Discoverable and Meaningful at Netflix\nSpinalTap: Change Data Capture System at Airbnb\nAccelerator: Fast Data Processing Framework at eBay\nOmid: Transaction Processing Platform at Yahoo\nTensorFlowOnSpark: Distributed Deep Learning on Big Data Clusters at Yahoo\nCaffeOnSpark: Distributed Deep Learning on Big Data Clusters at Yahoo\nSpark on Scala: Analytics Reference Architecture at Adobe\nExperimentation Platform (2 parts) at Spotify\nExperimentation Platform at Airbnb\nSmart Product Platform at Zalando\nLog Analysis Platform at LINE\nData Visualisation Platform at Myntra\nBuilding and Scaling Data Lineage at Netflix\nBuilding a scalable data management system for computer vision tasks at Pinterest\nStructured Data at Etsy\nScaling a Mature Data Pipeline - Managing Overhead at Airbnb\nSpark Partitioning Strategies at Airbnb\nScaling the Hadoop Distributed File System at LinkedIn\nScaling Hadoop YARN cluster beyond 10,000 nodes at LinkedIn\nDistributed Machine Learning\nMachine Learning Platform at Uber\nMachine Learning Platform at Yelp\nMachine Learning Platform at Etsy\nPlatform for Serving Recommendations at Etsy\nInfrastructure to Run User Forecasts at Spotify\nAroma: Using ML for Code Recommendation at Facebook\nFlyte: Cloud Native Machine Learning and Data Processing Platform at Lyft\nLyftLearn: ML Model Training Infrastructure built on Kubernetes at Lyft\nHorovod: Open Source Distributed Deep Learning Framework for TensorFlow at Uber\nCOTA: Improving Customer Care with NLP & Machine Learning at Uber\nManifold: Model-Agnostic Visual Debugging Tool for Machine Learning at Uber \nRepo-Topix: Topic Extraction Framework at Github\nConcourse: Generating Personalized Content Notifications in Near-Real-Time at LinkedIn\nAltus Care: Applying a Chatbot to Platform Engineering at eBay\nPyKrylov: Accelerating Machine Learning Research at eBay\nBox Graph: Spontaneous Social Network at Box\nPricingNet: Pricing Modelling with Neural Networks at Skyscanner\nPinText: Multitask Text Embedding System at Pinterest\nSearchSage: Learning Search Query Representations at Pinterest\nCannes: ML saves $1.7M a year on document previews at Dropbox\nScaling Gradient Boosted Trees for Click-Through-Rate Prediction at Yelp \nLearning with Privacy at Scale at Apple\nDeep Learning for Image Classification Experiment at Mercari\nDeep Learning for Frame Detection in Product Images at Allegro\nContent-based Video Relevance Prediction at Hulu\nImproving Photo Selection With Deep Learning at TripAdvisor\nPersonalized Recommendations for Experiences Using Deep Learning at TripAdvisor\nPersonalised Recommender Systems at BBC\nMachine Learning (2 parts) at Cond\u00e9 Nast\nNatural Language Processing and Content Analysis (2 parts) at Cond\u00e9 Nast\nMapping the World of Music Using Machine Learning (2 parts) at iHeartRadio\nMachine Learning to Improve Streaming Quality at Netflix\nMachine Learning to Match Drivers & Riders at GO-JEK\nImproving Video Thumbnails with Deep Neural Nets at YouTube\nQuantile Regression for Delivering On Time at Instacart\nCross-Lingual End-to-End Product Search with Deep Learning at Zalando\nMachine Learning at Jane Street\nMachine Learning for Ranking Answers End-to-End at Quora\nClustering Similar Stories Using LDA at Flipboard\nSimilarity Search at Flickr\nLarge-Scale Machine Learning Pipeline for Job Recommendations at Indeed\nDeep Learning from Prototype to Production at Taboola\nAtom Smashing using Machine Learning at CERN\nMapping Tags at Medium\nClustering with the Dirichlet Process Mixture Model in Scala at Monsanto\nMap Pins with DBSCAN & Random Forests at Foursquare\nForecasting at Uber\nFinancial Forecasting at Uber\nProductionizing ML with Workflows at Twitter\nGUI Testing Powered by Deep Learning at eBay\nScaling Machine Learning to Recommend Driving Routes at Pivotal\nReal-Time Predictions at DoorDash\nMachine Intelligence at Dropbox\nMachine Learning for Indexing Text from Billions of Images at Dropbox\nModeling User Journeys via Semantic Embeddings at Etsy\nAutomated Fake Account Detection at LinkedIn\nBuilding Knowledge Graph at Airbnb\nCore Modeling at Instagram\nNeural Architecture Search (NAS) for Prohibited Item Detection at Mercari\nComputer Vision at Airbnb\n3D Home Backend Algorithms at Zillow\nLong-term Forecasts at Lyft\nDiscovering Popular Dishes with Deep Learning at Yelp\nSplitNet Architecture for Ad Candidate Ranking at Twitter\nJobs Filter at Indeed\nArchitecting Restaurant Wait Time Predictions at Yelp\nMusic Personalization at Spotify\nDeep Learning for Domain Name Valuation at GoDaddy\nSimilarity Clustering to Catch Fraud Rings at Stripe\nPersonalized Search at Etsy\nML Feature Serving Infrastructure at Lyft\nContext-Specific Bidding System at Etsy\nModerating Promotional Spam and Inappropriate Content in Photos at Scale at Yelp\nOptimizing Payments with Machine Learning at Dropbox\nArchitecture\nTech Stack (2 parts) at Uber\nTech Stack at Medium\nTech Stack at Shopify\nBuilding Services (4 parts) at Airbnb\nArchitecture of Evernote\nArchitecture of Chat Service (3 parts) at Riot Games\nArchitecture of League of Legends Client Update\nArchitecture of Ad Platform at Twitter\nArchitecture of API Gateway at Uber\nBasic Architecture of Slack\nBack-end at LinkedIn\nBack-end at Flickr\nInfrastructure (3 parts) at Zendesk\nCloud Infrastructure at Grubhub\nReal-time Presence Platform at LinkedIn\nSettings Platform at LinkedIn\nNearline System for Scale and Performance (2 parts) at Glassdoor\nReal-time User Action Counting System for Ads at Pinterest\nAPI Platform at Riot Games\nGames Platform at The New York Times\nKabootar: Communication Platform at Swiggy\nSimone: Distributed Simulation Service at Netflix\nSeagull: Distributed System that Helps Running > 20 Million Tests Per Day at Yelp\nPriceAggregator: Intelligent System for Hotel Price Fetching (3 parts) at Agoda\nPhoenix: Testing Platform (3 parts) at Tinder\nHexagonal Architecture at Netflix\nArchitecture of Play API Service at Netflix\nArchitecture of Sticker Services at LINE\nStack Overflow Enterprise at Palantir\nArchitecture of Following Feed, Interest Feed, and Picked For You at Pinterest\nAPI Specification Workflow at WeWork\nMedia Database at Netflix\nMember Transaction History Architecture at Walmart\nSync Engine (2 parts) at Dropbox\nAds Pacing Service at Twitter\nRapid Event Notification System at Netflix\nArchitectures of Finance and Banking Systems\nBank Backend at Monzo\nTrading Platform for Scale at Wealthsimple\nCore Banking System at Margo Bank\nArchitecture of Nubank\nTech Stack at TransferWise\nTech Stack at Addepar\nAvoiding Double Payments in a Distributed Payments System at Airbnb\nInterview\nDesigning Large-Scale Systems\nMy Scaling Hero - Jeff Atwood (a dose of Endorphins before your interview, JK)\nSoftware Engineering Advice from Building Large-Scale Distributed Systems - Jeff Dean\nIntroduction to Architecting Systems for Scale\nAnatomy of a System Design Interview\n8 Things You Need to Know Before a System Design Interview\nTop 10 System Design Interview Questions \nTop 10 Common Large-Scale Software Architectural Patterns in a Nutshell\nCloud Big Data Design Patterns - Lynn Langit \nHow NOT to design Netflix in your 45-minute System Design Interview?\nAPI Best Practices: Webhooks, Deprecation, and Design\nExplaining Low-Level Systems (OS, Network/Protocol, Database, Storage)\nThe Precise Meaning of I/O Wait Time in Linux\nPaxos Made Live \u2013 An Engineering Perspective\nHow to do Distributed Locking\nSQL Transaction Isolation Levels Explained\n\"What Happens When... and How\" Questions\nNetflix: What Happens When You Press Play?\nMonzo: How Peer-To-Peer Payments Work\nTransit and Peering: How Your Requests Reach GitHub\nHow Spotify Streams Music\nOrganization\nEngineering Levels at SoundCloud\nEngineering Roles at Palantir\nScaling Engineering Teams at Twitter\nScaling Decision-Making Across Teams at LinkedIn\nScaling Data Science Team at GOJEK\nScaling Agile at Zalando\nScaling Agile at bol.com\nLessons Learned from Scaling a Product Team at Intercom\nHiring, Managing, and Scaling Engineering Teams at Typeform \nScaling the Datagram Team at Instagram\nScaling the Design Team at Flexport\nTeam Model for Scaling a Design System at Salesforce\nBuilding Analytics Team (4 parts) at Wish\nFrom 2 Founders to 1000 Employees at Transferwise\nLessons Learned Growing a UX Team from 10 to 170 at Adobe\nFive Lessons from Scaling at Pinterest\nApproach Engineering at Vinted\nUsing Metrics to Improve the Development Process (and Coach People) at Indeed\nMistakes to Avoid while Creating an Internal Product at Skyscanner\nRACI (Responsible, Accountable, Consulted, Informed) at Etsy\nFour Pillars of Leading People (Empathy, Inspiration, Trust, Honesty) at Zalando\nPair Programming at Shopify\nDistributed Responsibility at Asana\nRotating Engineers at Zalando\nExperiment Idea Review at Pinterest\nTech Migrations at Spotify\nImproving Code Ownership at Yelp\nAgile Code Base at eBay\nAgile Data Engineering at Miro\nAutomated Incident Management through Slack at Airbnb\nCode Review\nCode Review at Palantir\nCode Review at LINE\nCode Reviews at Medium\nCode Review at LinkedIn\nCode Review at Disney\nCode Review at Netlify\nTalk\nDistributed Systems in One Lesson - Tim Berglund, Senior Director of Developer Experience at Confluent\nBuilding Real Time Infrastructure at Facebook - Jeff Barber and Shie Erlich, Software Engineer at Facebook\nBuilding Reliable Social Infrastructure for Google - Marc Alvidrez, Senior Manager at Google\nBuilding a Distributed Build System at Google Scale - Aysylu Greenberg, SDE at Google\nSite Reliability Engineering at Dropbox - Tammy Butow, Site Reliability Engineering Manager at Dropbox\nHow Google Does Planet-Scale for Planet-Scale Infra - Melissa Binde, SRE Director for Google Cloud Platform\nNetflix Guide to Microservices - Josh Evans, Director of Operations Engineering at Netflix\nAchieving Rapid Response Times in Large Online Services - Jeff Dean, Google Senior Fellow\nArchitecture to Handle 80K RPS Celebrity Sales at Shopify - Simon Eskildsen, Engineering Lead at Shopify\nLessons of Scale at Facebook - Bobby Johnson, Director of Engineering at Facebook\nPerformance Optimization for the Greater China Region at Salesforce - Jeff Cheng, Enterprise Architect at Salesforce\nHow GIPHY Delivers a GIF to 300 Millions Users - Alex Hoang and Nima Khoshini, Services Engineers at GIPHY\nHigh Performance Packet Processing Platform at Alibaba - Haiyong Wang, Senior Director at Alibaba\nSolving Large-scale Data Center and Cloud Interconnection Problems -  Ihab Tarazi, CTO at Equinix\nScaling Dropbox - Kevin Modzelewski, Back-end Engineer at Dropbox\nScaling Reliability at Dropbox - Sat Kriya Khalsa, SRE at Dropbox\nScaling with Performance at Facebook - Bill Jia, VP of Infrastructure at Facebook\nScaling Live Videos to a Billion Users at Facebook - Sachin Kulkarni, Director of Engineering at Facebook\nScaling Infrastructure at Instagram - Lisa Guo, Instagram Engineering\nScaling Infrastructure at Twitter - Yao Yue, Staff Software Engineer at Twitter\nScaling Infrastructure at Etsy - Bethany Macri, Engineering Manager at Etsy\nScaling Real-time Infrastructure at Alibaba for Global Shopping Holiday - Xiaowei Jiang, Senior Director at Alibaba\nScaling Data Infrastructure at Spotify - Matti (Lepist\u00f6) Pehrs, Spotify\nScaling Pinterest - Marty Weiner, Pinterest\u2019s founding engineer\nScaling Slack - Bing Wei, Software Engineer (Infrastructure) at Slack\nScaling Backend at Youtube - Sugu Sougoumarane, SDE at Youtube\nScaling Backend at Uber - Matt Ranney, Chief Systems Architect at Uber\nScaling Global CDN at Netflix - Dave Temkin, Director of Global Networks at Netflix\nScaling Load Balancing Infra to Support 1.3 Billion Users at Facebook - Patrick Shuff, Production Engineer at Facebook\nScaling (a NSFW site) to 200 Million Views A Day And Beyond - Eric Pickup, Lead Platform Developer at MindGeek\nScaling Counting Infrastructure at Quora - Chun-Ho Hung and Nikhil Gar, SEs at Quora\nScaling Git at Microsoft - Saeed Noursalehi, Principal Program Manager at Microsoft\nScaling Multitenant Architecture Across Multiple Data Centres at Shopify - Weingarten, Engineering Lead at Shopify\nBook\nBig Data, Web Ops & DevOps Ebooks - O'Reilly (Online - Free)\nGoogle Site Reliability Engineering (Online - Free)\nDistributed Systems for Fun and Profit (Online - Free)\nWhat Every Developer Should Know About SQL Performance (Online - Free)\nBeyond the Twelve-Factor App - Exploring the DNA of Highly Scalable, Resilient Cloud Applications (Free)\nChaos Engineering - Building Confidence in System Behavior through Experiments (Free)\nThe Art of Scalability\nWeb Scalability for Startup Engineers\nScalability Rules: 50 Principles for Scaling Web Sites\nDonation\nRoses are red. Violets are blue. Binh likes sweet. Treat Binh a tiramisu? :cake:",
	"big-data java jdbc python r scala spark sql": "Apache Spark\nSpark is a unified analytics engine for large-scale data processing. It provides\nhigh-level APIs in Scala, Java, Python, and R, and an optimized engine that\nsupports general computation graphs for data analysis. It also supports a\nrich set of higher-level tools including Spark SQL for SQL and DataFrames,\npandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing,\nand Structured Streaming for stream processing.\nhttps://spark.apache.org/\nOnline Documentation\nYou can find the latest Spark documentation, including a programming\nguide, on the project web page.\nThis README file only contains basic setup instructions.\nBuilding Spark\nSpark is built using Apache Maven.\nTo build Spark and its example programs, run:\nbash\n./build/mvn -DskipTests clean package\n(You do not need to do this if you downloaded a pre-built package.)\nMore detailed documentation is available from the project site, at\n\"Building Spark\".\nFor general development tips, including info on developing Spark using an IDE, see \"Useful Developer Tools\".\nInteractive Scala Shell\nThe easiest way to start using Spark is through the Scala shell:\nbash\n./bin/spark-shell\nTry the following command, which should return 1,000,000,000:\nscala\nscala> spark.range(1000 * 1000 * 1000).count()\nInteractive Python Shell\nAlternatively, if you prefer Python, you can use the Python shell:\nbash\n./bin/pyspark\nAnd run the following command, which should also return 1,000,000,000:\n```python\nspark.range(1000 * 1000 * 1000).count()\n```\nExample Programs\nSpark also comes with several sample programs in the examples directory.\nTo run one of them, use ./bin/run-example  [params]. For example:\nbash\n./bin/run-example SparkPi\nwill run the Pi example locally.\nYou can set the MASTER environment variable when running examples to submit\nexamples to a cluster. This can be a mesos:// or spark:// URL,\n\"yarn\" to run on YARN, and \"local\" to run\nlocally with one thread, or \"local[N]\" to run locally with N threads. You\ncan also use an abbreviated class name if the class is in the examples\npackage. For instance:\nbash\nMASTER=spark://host:7077 ./bin/run-example SparkPi\nMany of the example programs print usage help if no params are given.\nRunning Tests\nTesting first requires building Spark. Once Spark is built, tests\ncan be run using:\nbash\n./dev/run-tests\nPlease see the guidance on how to\nrun tests for a module, or individual tests.\nThere is also a Kubernetes integration test, see resource-managers/kubernetes/integration-tests/README.md\nA Note About Hadoop Versions\nSpark uses the Hadoop core library to talk to HDFS and other Hadoop-supported\nstorage systems. Because the protocols have changed in different versions of\nHadoop, you must build Spark against the same version that your cluster runs.\nPlease refer to the build documentation at\n\"Specifying the Hadoop Version and Enabling YARN\"\nfor detailed guidance on building for a particular distribution of Hadoop, including\nbuilding for particular Hive and Hive Thriftserver distributions.\nConfiguration\nPlease refer to the Configuration Guide\nin the online documentation for an overview on how to configure Spark.\nContributing\nPlease review the Contribution to Spark guide\nfor information on how to get started contributing to the project.",
	"analytics big-data clickhouse dbms distributed-database hacktoberfest mpp olap sql": "ClickHouse\u00ae is an open-source column-oriented database management system that allows generating analytical data reports in real-time.\nUseful Links\nOfficial website has a quick high-level overview of ClickHouse on the main page.\nClickHouse Cloud ClickHouse as a service, built by the creators and maintainers.\nTutorial shows how to set up and query a small ClickHouse cluster.\nDocumentation provides more in-depth information.\nYouTube channel has a lot of content about ClickHouse in video format.\nSlack and Telegram allow chatting with ClickHouse users in real-time.\nBlog contains various ClickHouse-related articles, as well as announcements and reports about events.\nCode Browser (Woboq) with syntax highlight and navigation.\nCode Browser (github.dev) with syntax highlight, powered by github.dev.\nContacts can help to get your questions answered if there are any.\nUpcoming events\nv22.11 Release Webinar Original creator, co-founder, and CTO of ClickHouse Alexey Milovidov will walk us through the highlights of the release, provide live demos, and share vision into what is coming in the roadmap.\nClickHouse Meetup at the Deutsche Bank office in Berlin Hear from Deutsche Bank on why they chose ClickHouse for big sensitive data in a regulated environment. The ClickHouse team will then present how ClickHouse is used for real time financial data analytics, including tick data, trade analytics and risk management.\nAWS re:Invent Core members of the ClickHouse team -- including 2 of our founders -- will be at re:Invent from November 29 to December 3. We are available on the show floor, but are also determining interest in holding an event during the time there. ",
	"big-data flink java python scala sql": "Apache Flink\nApache Flink is an open source stream processing framework with powerful stream- and batch-processing capabilities.\nLearn more about Flink at https://flink.apache.org/\nFeatures\nA streaming-first runtime that supports both batch processing and data streaming programs\nElegant and fluent APIs in Java and Scala\nA runtime that supports very high throughput and low event latency at the same time\nSupport for event time and out-of-order processing in the DataStream API, based on the Dataflow Model\nFlexible windowing (time, count, sessions, custom triggers) across different time semantics (event time, processing time)\nFault-tolerance with exactly-once processing guarantees\nNatural back-pressure in streaming programs\nLibraries for Graph processing (batch), Machine Learning (batch), and Complex Event Processing (streaming)\nBuilt-in support for iterative programs (BSP) in the DataSet (batch) API\nCustom memory management for efficient and robust switching between in-memory and out-of-core data processing algorithms\nCompatibility layers for Apache Hadoop MapReduce\nIntegration with YARN, HDFS, HBase, and other components of the Apache Hadoop ecosystem\nStreaming Example\nscala\ncase class WordWithCount(word: String, count: Long)\nval text = env.socketTextStream(host, port, '\\n')\nval windowCounts = text.flatMap { w => w.split(\"\\s\") }\n  .map { w => WordWithCount(w, 1) }\n  .keyBy(\"word\")\n  .window(TumblingProcessingTimeWindow.of(Time.seconds(5)))\n  .sum(\"count\")\nwindowCounts.print()\nBatch Example\nscala\ncase class WordWithCount(word: String, count: Long)\nval text = env.readTextFile(path)\nval counts = text.flatMap { w => w.split(\"\\s\") }\n  .map { w => WordWithCount(w, 1) }\n  .groupBy(\"word\")\n  .sum(\"count\")\ncounts.writeAsCsv(outputPath)\nBuilding Apache Flink from Source\nPrerequisites for building Flink:\nUnix-like environment (we use Linux, Mac OS X, Cygwin, WSL)\nGit\nMaven (we recommend version 3.2.5 and require at least 3.1.1)\nJava 8 or 11 (Java 9 or 10 may work)\ngit clone https://github.com/apache/flink.git\ncd flink\n./mvnw clean package -DskipTests # this will take up to 10 minutes\nFlink is now installed in build-target.\nNOTE: Maven 3.3.x can build Flink, but will not properly shade away certain dependencies. Maven 3.1.1 creates the libraries properly.\nTo build unit tests with Java 8, use Java 8u51 or above to prevent failures in unit tests that use the PowerMock runner.\nDeveloping Flink\nThe Flink committers use IntelliJ IDEA to develop the Flink codebase.\nWe recommend IntelliJ IDEA for developing projects that involve Scala code.\nMinimal requirements for an IDE are:\n* Support for Java and Scala (also mixed projects)\n* Support for Maven with Java and Scala\nIntelliJ IDEA\nThe IntelliJ IDE supports Maven out of the box and offers a plugin for Scala development.\nIntelliJ download: https://www.jetbrains.com/idea/\nIntelliJ Scala Plugin: https://plugins.jetbrains.com/plugin/?id=1347\nCheck out our Setting up IntelliJ guide for details.\nEclipse Scala IDE\nNOTE: From our experience, this setup does not work with Flink\ndue to deficiencies of the old Eclipse version bundled with Scala IDE 3.0.3 or\ndue to version incompatibilities with the bundled Scala version in Scala IDE 4.4.1.\nWe recommend to use IntelliJ instead (see above)\nSupport\nDon\u2019t hesitate to ask!\nContact the developers and community on the mailing lists if you need any help.\nOpen an issue if you find a bug in Flink.\nDocumentation\nThe documentation of Apache Flink is located on the website: https://flink.apache.org\nor in the docs/ directory of the source code.\nFork and Contribute\nThis is an active open-source project. We are always open to people who want to use the system or contribute to it.\nContact us if you are looking for implementation tasks that fit your skills.\nThis article describes how to contribute to Apache Flink.\nAbout\nApache Flink is an open source project of The Apache Software Foundation (ASF).\nThe Apache Flink project originated from the Stratosphere research project.",
	"artificial-intelligence big-data blockchain crdt crypto cryptography dapp database decentralized dweb encryption end-to-end graph machine-learning metaverse offline-first p2p protocol realtime web3": "GUN is an ecosystem of tools that let you build community run and encrypted applications - like an Open Source Firebase or a Decentralized Dropbox.\nThe Internet Archive and 100s of other apps run GUN in-production. GUN is also part of Twitter's Bluesky initiative!\nMultiplayer by default with realtime p2p state synchronization!\nGraph data lets you use key/value, tables, documents, videos, & more!\nLocal-first, offline, and decentralized with end-to-end encryption.\nDecentralized alternatives to Zoom, Reddit, Instagram, Slack, YouTube, Stripe, Wikipedia, Facebook Horizon and more have already pushed terabytes of daily P2P traffic on GUN. We are a friendly community creating a free fun future for freedom:\nQuickstart\nGUN is super easy to get started with:\nTry the interactive tutorial in the browser (5min ~ average developer).\nOr npm install gun and run the examples with cd node_modules/gun && npm start (5min ~ average developer).\nNote: If you don't have node or npm, read this first.\nIf the npm command line didn't work, you may need to mkdir node_modules first or use sudo.\nAn online demo of the examples are available here: http://gunjs.herokuapp.com/\nOr write a quick app: (try now in a playground)\n```html\n\nOr try something mind blowing, like saving circular references to a table of documents! (play)javascript\ncat = {name: \"Fluffy\", species: \"kitty\"};\nmark = {boss: cat};\ncat.slave = mark;\n// partial updates merge with existing data!\ngun.get('mark').put(mark);\n// access the data as if it is a document.\ngun.get('mark').get('boss').get('name').once(function(data, key){\n  // once grabs the data once, no subscriptions.\n  console.log(\"Mark's boss is\", data);\n});\n// traverse a graph of circular references!\ngun.get('mark').get('boss').get('slave').once(function(data, key){\n  console.log(\"Mark is the cat's slave!\", data);\n});\n// add both of them to a table!\ngun.get('list').set(gun.get('mark').get('boss'));\ngun.get('list').set(gun.get('mark'));\n// grab each item once from the table, continuously:\ngun.get('list').map().once(function(data, key){\n  console.log(\"Item:\", data);\n});\n// live update the table!\ngun.get('list').set({type: \"cucumber\", goal: \"jumping cat\"});\n```\nWant to keep building more? Jump to THE DOCUMENTATION!\nAbout\nFirst & foremost, GUN is a community of the nicest and most helpful people out there. So I want to invite you to come tell us about what you are working on & wanting to build (new or old school alike! Just be nice as well.) and ask us your questions directly. :)\nWatch the 100 second intro!\nThe GUN ecosystem stack is a collection of independent and modular tools covering everything from CRDT conflict resolution, cryptographic security & encryption, radix storage serialization, mesh networking & routing algorithms, to distributed systems correctness & load testing, CPU scheduled JSON parser to prevent UI lag, and more!\n\nOn that note, let's get some official shout outs covered first:\nSupport\nThanks to:\nRobert Heessels,\nLorenzo Mangani,\nNLnet Foundation,\nSam Liu,\nDaniel Dombrowsky,\nVincent Woo,\nAJ ONeal,\nBill Ottman,\nMike Lange,\nSean Matheson,\nAlan Mimms,\nD\u00e1rio Freire,\nJohn Williamson,\nRobin Bron,\nElie Makhoul,\nMike Staub,\nBradley Matusiak,\nJeff Cook,\nNico,\nAaron Artille,\nTim Robinson,\nFabian Stamm,\nMike Staub,\nHunter Owens,\nJacob Millner,\nGerrit Balindt,\nGabriel Lemon\nJoin others in sponsoring code: https://www.patreon.com/gunDB !\nAsk questions: http://stackoverflow.com/questions/tagged/gun ?\nFound a bug? Report at: https://github.com/amark/gun/issues ;\nNeed help? Chat with us: http://chat.gun.eco .\nHistory\nGUN was created by Mark Nadal in 2014 after he had spent 4 years trying to get his collaborative web app to scale up with traditional databases.\n After he realized Master-Slave database architecture causes one big bottleneck, he (as a complete newbie outsider) naively decided to question the status quo and shake things up with controversial, heretical, and contrarian experiments:\nThe NoDB - no master, no servers, no \"single source of truth\", not built with a real programming language or real hardware, no DevOps, no locking, not just SQL or NoSQL but both (all - graphs, documents, tables, key/value).\nThe goal was to build a P2P database that could survive living inside any browser, and could correctly sync data between any device after assuming any offline-first activity.\nTechnically, GUN is a graph synchronization protocol with a lightweight embedded engine, capable of doing 20M+ API ops/sec in just ~9KB gzipped size.\nDocumentation\nAPI reference\nTutorials\nExamples\nGraphQL\nElectron\nReact & Native\nVue\nSvelte\nWebcomponents\nCAP Theorem Tradeoffs\nHow Data Sync Works\nHow GUN is Built\nCrypto Auth\nModules\nRoadmap\nThis would not be possible without community contributors, big shout out to:\najmeyghani (Learn GUN Basics with Diagrams); anywhichway (Block Storage); beebase (Quasar); BrockAtkinson (brunch config); Brysgo (GraphQL); d3x0r (SQLite); forrestjt (file.js); hillct (Docker); JosePedroDias (graph visualizer); JuniperChicago (cycle.js bindings); jveres (todoMVC); kristianmandrup (edge); Lightnet (Awesome Vue User Examples & User Kitchen Sink Playground); lmangani (Cytoscape Visualizer, Cassandra, Fastify, LetsEncrypt); mhelander (SEA); omarzion (Sticky Note App); PsychoLlama (LevelDB); RangerMauve (schema); robertheessels (gun-p2p-auth); rogowski (AXE); sbeleidy; sbiaudet (C# Port); Sean Matheson (Observable/RxJS/Most.js bindings); Shadyzpop (React Native example); sjones6 (Flint); RIP Stefdv (Polymer/web components); zrrrzzt (JWT Auth); xmonader (Python Port); \nI am missing many others, apologies, will be adding them soon! This list is infintiely old & way out of date, if you want to be listed in it please make a PR! :)\nTesting\nYou will need to npm install -g mocha first. Then in the gun root folder run npm test. Tests will trigger persistent writes to the DB, so subsequent runs of the test will fail. You must clear the DB before running the tests again. This can be done by running rm -rf data command in the project directory.\nShims\nThese are only needed for NodeJS & React Native, they shim the native Browser WebCrypto API.\nIf you want to use SEA for User auth and security, you will need to install:\nnpm install @peculiar/webcrypto --save\nPlease see our React Native docs for installation instructions!\nThen you can require SEA without an error:\njavascript\nGUN = require('gun/gun');\nSEA = require('gun/sea');\nDeploy\nNote: The default examples that get auto-deployed on npm start CDN-ify all GUN files, modules, & storage.\nNote: Moving forward, AXE will start to automatically cluster your peer into a shared DHT. You may want to disable this to run an isolated network.\nNote: When deploying a web application using GUN on a cloud provider, you may have to set CI=false in your .env. This prevents GUN-specific warnings from being treated as errors when deploying your app. You may also resolve this by modifying your webpack config to not try to build the GUN dependencies.\nTo quickly spin up a GUN relay peer for your development team, utilize Heroku, Docker, or any others listed below. Or some variant thereof Dokku, K8s, etc. ! Or use all of them so your relays are decentralized too!\nLinux\nSSH into the home directory of a clean OS install with sudo ability. Set any environment variables you need (see below), then do:\nbash\ncurl -o- https://raw.githubusercontent.com/amark/gun/master/examples/install.sh | bash\nRead install.sh first!\nIf curl is not found, copy&paste the contents of install.sh into your ssh.\nYou can now safely CTRL+A+D to escape without stopping the peer. To stop everything killall screen or killall node.\nEnvironment variables may need to be set like export HTTPS_CERT=~/cert.pem HTTPS_KEY=~/key.pem PORT=443. You can also look at a sample nginx config. For production deployments, you probably will want to use something like pm2 or better to keep the peer alive after machine reboots.\nHeroku\nHeroku deletes your data every 15 minutes, one way to fix this is by adding cheap storage.\nOr:\nbash\ngit clone https://github.com/amark/gun.git\ncd gun\nheroku create\ngit push -f heroku HEAD:master\nThen visit the URL in the output of the 'heroku create' step, in a browser. Make sure to set any environment config vars in the settings tab.\nZeet.co\nThen visit the URL in the output of the 'now --npm' step, in your browser.\nDocker\nWarning: Docker image is community contributed and may be old with missing security updates, please check version numbers to compare.\nPull from the Docker Hub . Or:\nbash\ndocker run -p 8765:8765 gundb/gun\nOr build the Docker image locally:\nbash\ngit clone https://github.com/amark/gun.git\ncd gun\ndocker build -t myrepo/gundb:v1 .\ndocker run -p 8765:8765 myrepo/gundb:v1\nOr, if you prefer your Docker image with metadata labels (Linux/Mac only):\nbash\nnpm run docker\ndocker run -p 8765:8765 username/gun:git\nThen visit http://localhost:8765 in your browser.\nLicense\nDesigned with \u2665 by Mark Nadal, the GUN team, and many amazing contributors.\nOpenly licensed under Zlib / MIT / Apache 2.0.\nYouTube . Twitter",
	"big-data hadoop hive java presto sql": "Presto \nPresto is a distributed SQL query engine for big data.\nSee the User Manual for deployment instructions and end user documentation.\nRequirements\nMac OS X or Linux\nJava 8 Update 151 or higher (8u151+), 64-bit. Both Oracle JDK and OpenJDK are supported.\nMaven 3.3.9+ (for building)\nPython 2.4+ (for running with the launcher script)\nBuilding Presto\nPresto is a standard Maven project. Simply run the following command from the project root directory:\n./mvnw clean install\nOn the first build, Maven will download all the dependencies from the internet and cache them in the local repository (~/.m2/repository), which can take a considerable amount of time. Subsequent builds will be faster.\nPresto has a comprehensive set of unit tests that can take several minutes to run. You can disable the tests when building:\n./mvnw clean install -DskipTests\nPresto native and Velox\nPresto native is a C++ rewrite of Presto worker. Presto native uses Velox as its primary engine to run presto workloads.\nVelox is a C++ database library which provides reusable, extensible, and high-performance data processing components.\nCheck out building instructions to get started. \nRunning Presto in your IDE\nOverview\nAfter building Presto for the first time, you can load the project into your IDE and run the server. We recommend using IntelliJ IDEA. Because Presto is a standard Maven project, you can import it into your IDE using the root pom.xml file. In IntelliJ, choose Open Project from the Quick Start box or choose Open from the File menu and select the root pom.xml file.\nAfter opening the project in IntelliJ, double check that the Java SDK is properly configured for the project:\nOpen the File menu and select Project Structure\nIn the SDKs section, ensure that a 1.8 JDK is selected (create one if none exist)\nIn the Project section, ensure the Project language level is set to 8.0 as Presto makes use of several Java 8 language features\nPresto comes with sample configuration that should work out-of-the-box for development. Use the following options to create a run configuration:\nMain Class: com.facebook.presto.server.PrestoServer\nVM Options: -ea -XX:+UseG1GC -XX:G1HeapRegionSize=32M -XX:+UseGCOverheadLimit -XX:+ExplicitGCInvokesConcurrent -Xmx2G -Dconfig=etc/config.properties -Dlog.levels-file=etc/log.properties\nWorking directory: $MODULE_WORKING_DIR$ or $MODULE_DIR$(Depends your version of IntelliJ)\nUse classpath of module: presto-main\nThe working directory should be the presto-main subdirectory. In IntelliJ, using $MODULE_DIR$ accomplishes this automatically.\nAdditionally, the Hive plugin must be configured with location of your Hive metastore Thrift service. Add the following to the list of VM options, replacing localhost:9083 with the correct host and port (or use the below value if you do not have a Hive metastore):\n-Dhive.metastore.uri=thrift://localhost:9083\nUsing SOCKS for Hive or HDFS\nIf your Hive metastore or HDFS cluster is not directly accessible to your local machine, you can use SSH port forwarding to access it. Setup a dynamic SOCKS proxy with SSH listening on local port 1080:\nssh -v -N -D 1080 server\nThen add the following to the list of VM options:\n-Dhive.metastore.thrift.client.socks-proxy=localhost:1080\nRunning the CLI\nStart the CLI to connect to the server and run SQL queries:\npresto-cli/target/presto-cli-*-executable.jar\nRun a query to see the nodes in the cluster:\nSELECT * FROM system.runtime.nodes;\nIn the sample configuration, the Hive connector is mounted in the hive catalog, so you can run the following queries to show the tables in the Hive database default:\nSHOW TABLES FROM hive.default;\nCode Style\nWe recommend you use IntelliJ as your IDE. The code style template for the project can be found in the codestyle repository along with our general programming and Java guidelines. In addition to those you should also adhere to the following:\nAlphabetize sections in the documentation source files (both in table of contents files and other regular documentation files). In general, alphabetize methods/variables/sections if such ordering already exists in the surrounding code.\nWhen appropriate, use the Java 8 stream API. However, note that the stream implementation does not perform well so avoid using it in inner loops or otherwise performance sensitive sections.\nCategorize errors when throwing exceptions. For example, PrestoException takes an error code as an argument, PrestoException(HIVE_TOO_MANY_OPEN_PARTITIONS). This categorization lets you generate reports so you can monitor the frequency of various failures.\nEnsure that all files have the appropriate license header; you can generate the license by running mvn license:format.\nConsider using String formatting (printf style formatting using the Java Formatter class): format(\"Session property %s is invalid: %s\", name, value) (note that format() should always be statically imported). Sometimes, if you only need to append something, consider using the + operator.\nAvoid using the ternary operator except for trivial expressions.\nUse an assertion from Airlift's Assertions class if there is one that covers your case rather than writing the assertion by hand. Over time we may move over to more fluent assertions like AssertJ.\nWhen writing a Git commit message, follow these guidelines.\nBuilding the Documentation\nTo learn how to build the docs, see the docs README.\nBuilding the Web UI\nThe Presto Web UI is composed of several React components and is written in JSX and ES6. This source code is compiled and packaged into browser-compatible JavaScript, which is then checked in to the Presto source code (in the dist folder). You must have Node.js and Yarn installed to execute these commands. To update this folder after making changes, simply run:\nyarn --cwd presto-main/src/main/resources/webapp/src install\nIf no JavaScript dependencies have changed (i.e., no changes to package.json), it is faster to run:\nyarn --cwd presto-main/src/main/resources/webapp/src run package\nTo simplify iteration, you can also run in watch mode, which automatically re-compiles when changes to source files are detected:\nyarn --cwd presto-main/src/main/resources/webapp/src run watch\nTo iterate quickly, simply re-build the project in IntelliJ after packaging is complete. Project resources will be hot-reloaded and changes are reflected on browser refresh.\nRelease Notes\nWhen authoring a pull request, the PR description should include its relevant release notes.\nFollow Release Notes Guidelines when authoring release notes. ",
	"azkaban big-data bigdata flume hadoop hbase hdfs hive kafka mapreduce phoenix scala spark sqoop storm yarn zookeeper": "BigData-Notes\n\u5927\u6570\u636e\u5165\u95e8\u6307\u5357\nHadoop\nHive\nSpark\nStorm\nFlink\nHBase\nKafka\nZookeeper\nFlume\nSqoop\nAzkaban\nScala\n\u5982\u679c\u9700\u8981\u79bb\u7ebf\u9605\u8bfb\uff0c\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u4e0a\u53d1\u9001 \u201cbigdata\u201d \u83b7\u53d6\u300a\u5927\u6570\u636e\u5165\u95e8\u6307\u5357\u300b\u79bb\u7ebf\u9605\u8bfb\u7248\uff01  \n:black_nib: \u524d  \u8a00\n\u5927\u6570\u636e\u5b66\u4e60\u8def\u7ebf\n\u5927\u6570\u636e\u6280\u672f\u6808\u601d\u7ef4\u5bfc\u56fe \n\u5927\u6570\u636e\u5e38\u7528\u8f6f\u4ef6\u5b89\u88c5\u6307\u5357\n\u4e00\u3001Hadoop\n\u5206\u5e03\u5f0f\u6587\u4ef6\u5b58\u50a8\u7cfb\u7edf \u2014\u2014 HDFS\n\u5206\u5e03\u5f0f\u8ba1\u7b97\u6846\u67b6 \u2014\u2014 MapReduce\n\u96c6\u7fa4\u8d44\u6e90\u7ba1\u7406\u5668 \u2014\u2014 YARN\nHadoop \u5355\u673a\u4f2a\u96c6\u7fa4\u73af\u5883\u642d\u5efa\nHadoop \u96c6\u7fa4\u73af\u5883\u642d\u5efa\nHDFS \u5e38\u7528 Shell \u547d\u4ee4\nHDFS Java API \u7684\u4f7f\u7528\n\u57fa\u4e8e Zookeeper \u642d\u5efa Hadoop \u9ad8\u53ef\u7528\u96c6\u7fa4\n\u4e8c\u3001Hive\nHive \u7b80\u4ecb\u53ca\u6838\u5fc3\u6982\u5ff5\nLinux \u73af\u5883\u4e0b Hive \u7684\u5b89\u88c5\u90e8\u7f72\nHive CLI \u548c Beeline \u547d\u4ee4\u884c\u7684\u57fa\u672c\u4f7f\u7528\nHive \u5e38\u7528 DDL \u64cd\u4f5c\nHive \u5206\u533a\u8868\u548c\u5206\u6876\u8868\nHive \u89c6\u56fe\u548c\u7d22\u5f15\nHive \u5e38\u7528 DML \u64cd\u4f5c\nHive \u6570\u636e\u67e5\u8be2\u8be6\u89e3\n\u4e09\u3001Spark\nSpark Core :\nSpark \u7b80\u4ecb\nSpark \u5f00\u53d1\u73af\u5883\u642d\u5efa\n\u5f39\u6027\u5f0f\u6570\u636e\u96c6 RDD\nRDD \u5e38\u7528\u7b97\u5b50\u8be6\u89e3\nSpark \u8fd0\u884c\u6a21\u5f0f\u4e0e\u4f5c\u4e1a\u63d0\u4ea4\nSpark \u7d2f\u52a0\u5668\u4e0e\u5e7f\u64ad\u53d8\u91cf\n\u57fa\u4e8e Zookeeper \u642d\u5efa Spark \u9ad8\u53ef\u7528\u96c6\u7fa4\nSpark SQL :\nDateFrame \u548c DataSet \nStructured API \u7684\u57fa\u672c\u4f7f\u7528\nSpark SQL \u5916\u90e8\u6570\u636e\u6e90\nSpark SQL \u5e38\u7528\u805a\u5408\u51fd\u6570\nSpark SQL JOIN \u64cd\u4f5c\nSpark Streaming \uff1a\nSpark Streaming \u7b80\u4ecb\nSpark Streaming \u57fa\u672c\u64cd\u4f5c\nSpark Streaming \u6574\u5408 Flume\nSpark Streaming \u6574\u5408 Kafka\n\u56db\u3001Storm\nStorm \u548c\u6d41\u5904\u7406\u7b80\u4ecb\nStorm \u6838\u5fc3\u6982\u5ff5\u8be6\u89e3\nStorm \u5355\u673a\u73af\u5883\u642d\u5efa\nStorm \u96c6\u7fa4\u73af\u5883\u642d\u5efa\nStorm \u7f16\u7a0b\u6a21\u578b\u8be6\u89e3\nStorm \u9879\u76ee\u4e09\u79cd\u6253\u5305\u65b9\u5f0f\u5bf9\u6bd4\u5206\u6790\nStorm \u96c6\u6210 Redis \u8be6\u89e3\nStorm \u96c6\u6210 HDFS/HBase\nStorm \u96c6\u6210 Kafka\n\u4e94\u3001Flink\nFlink \u6838\u5fc3\u6982\u5ff5\u7efc\u8ff0\nFlink \u5f00\u53d1\u73af\u5883\u642d\u5efa\nFlink Data Source\nFlink Data Transformation\nFlink Data Sink\nFlink \u7a97\u53e3\u6a21\u578b\nFlink \u72b6\u6001\u7ba1\u7406\u4e0e\u68c0\u67e5\u70b9\u673a\u5236\nFlink Standalone \u96c6\u7fa4\u90e8\u7f72\n\u516d\u3001HBase\nHbase \u7b80\u4ecb\nHBase \u7cfb\u7edf\u67b6\u6784\u53ca\u6570\u636e\u7ed3\u6784\nHBase \u57fa\u672c\u73af\u5883\u642d\u5efa (Standalone /pseudo-distributed mode)\nHBase \u96c6\u7fa4\u73af\u5883\u642d\u5efa\nHBase \u5e38\u7528 Shell \u547d\u4ee4\nHBase Java API\nHBase \u8fc7\u6ee4\u5668\u8be6\u89e3\nHBase \u534f\u5904\u7406\u5668\u8be6\u89e3\nHBase \u5bb9\u707e\u4e0e\u5907\u4efd\nHBase\u7684 SQL \u4e2d\u95f4\u5c42 \u2014\u2014 Phoenix\nSpring/Spring Boot \u6574\u5408 Mybatis + Phoenix\n\u4e03\u3001Kafka\nKafka \u7b80\u4ecb\n\u57fa\u4e8e Zookeeper \u642d\u5efa Kafka \u9ad8\u53ef\u7528\u96c6\u7fa4\nKafka \u751f\u4ea7\u8005\u8be6\u89e3\nKafka \u6d88\u8d39\u8005\u8be6\u89e3\n\u6df1\u5165\u7406\u89e3 Kafka \u526f\u672c\u673a\u5236\n\u516b\u3001Zookeeper\nZookeeper \u7b80\u4ecb\u53ca\u6838\u5fc3\u6982\u5ff5\nZookeeper \u5355\u673a\u73af\u5883\u548c\u96c6\u7fa4\u73af\u5883\u642d\u5efa \nZookeeper \u5e38\u7528 Shell \u547d\u4ee4\nZookeeper Java \u5ba2\u6237\u7aef \u2014\u2014 Apache Curator\nZookeeper  ACL \u6743\u9650\u63a7\u5236\n\u4e5d\u3001Flume\nFlume \u7b80\u4ecb\u53ca\u57fa\u672c\u4f7f\u7528\nLinux \u73af\u5883\u4e0b Flume \u7684\u5b89\u88c5\u90e8\u7f72\nFlume \u6574\u5408 Kafka\n\u5341\u3001Sqoop\nSqoop \u7b80\u4ecb\u4e0e\u5b89\u88c5\nSqoop \u7684\u57fa\u672c\u4f7f\u7528\n\u5341\u4e00\u3001Azkaban\nAzkaban \u7b80\u4ecb\nAzkaban3.x \u7f16\u8bd1\u53ca\u90e8\u7f72\nAzkaban Flow 1.0 \u7684\u4f7f\u7528\nAzkaban Flow 2.0 \u7684\u4f7f\u7528\n\u5341\u4e8c\u3001Scala\nScala \u7b80\u4ecb\u53ca\u5f00\u53d1\u73af\u5883\u914d\u7f6e\n\u57fa\u672c\u6570\u636e\u7c7b\u578b\u548c\u8fd0\u7b97\u7b26\n\u6d41\u7a0b\u63a7\u5236\u8bed\u53e5\n\u6570\u7ec4 \u2014\u2014 Array\n\u96c6\u5408\u7c7b\u578b\u7efc\u8ff0\n\u5e38\u7528\u96c6\u5408\u7c7b\u578b\u4e4b \u2014\u2014 List & Set\n\u5e38\u7528\u96c6\u5408\u7c7b\u578b\u4e4b \u2014\u2014 Map & Tuple\n\u7c7b\u548c\u5bf9\u8c61\n\u7ee7\u627f\u548c\u7279\u8d28\n\u51fd\u6570 & \u95ed\u5305 & \u67ef\u91cc\u5316\n\u6a21\u5f0f\u5339\u914d\n\u7c7b\u578b\u53c2\u6570\n\u9690\u5f0f\u8f6c\u6362\u548c\u9690\u5f0f\u53c2\u6570\n\u5341\u4e09\u3001\u516c\u5171\u5185\u5bb9\n\u5927\u6570\u636e\u5e94\u7528\u5e38\u7528\u6253\u5305\u65b9\u5f0f\n:bookmark_tabs: \u540e  \u8bb0\n\u8d44\u6599\u5206\u4eab\u4e0e\u5f00\u53d1\u5de5\u5177\u63a8\u8350\n\u6b22\u8fce\u5173\u6ce8\u6211\u7684\u535a\u5ba2\uff1ahttps://blog.csdn.net/m0_37809146 ",
	"big-data predictionio scala": "Apache PredictionIO\nApache PredictionIO is an open source machine learning framework\nfor developers, data scientists, and end users. It supports event collection,\ndeployment of algorithms, evaluation, querying predictive results via REST APIs.\nIt is based on scalable open source services like Hadoop, HBase (and other DBs),\nElasticsearch, Spark and implements what is called a Lambda Architecture.\nTo get started, check out http://predictionio.apache.org!\nTable of contents\nInstallation\nQuick Start\nBugs and Feature Requests\nDocumentation\nContributing\nCommunity\nInstallation\nA few installation options available.\nInstalling Apache PredictionIO from\n    Binary/Source\nInstalling Apache PredictionIO with\n    Docker\nQuick Start\nRecommendation Engine Template Quick\n    Start\n    Guide\nSimiliar Product Engine Template Quick\n    Start\n    Guide\nClassification Engine Template Quick\n    Start\n    Guide\nBugs and Feature Requests\nUse Apache JIRA to report bugs or request new features.\nDocumentation\nDocumentation, included in this repo in the docs/manual directory, is built\nwith Middleman and publicly hosted at\npredictionio.apache.org.\nInterested in helping with our documentation? Read Contributing\nDocumentation.\nCommunity\nKeep track of development and community news.\nSubscribe to the user mailing list user-subscribe@predictionio.apache.org\n    and the dev mailing list dev-subscribe@predictionio.apache.org\nFollow @predictionio on Twitter.\nContributing\nRead the Contribute Code page.\nYou can also list your projects on the Community Project\npage.\nLicense\nApache PredictionIO is under Apache 2\nlicense.",
	"best-practices big-data cookbook data-engineer data-engineering": "What is this Book?\u00a0\u00a0\u00a0\n  How to Contribute\u00a0\u00a0\u00a0\n  YouTube\u00a0\u00a0\u00a0\n    Twitter\u00a0\u00a0\u00a0\n  Amazon Shop\nIf You Like This Book & Need More Help\nCheck out my Data Engineering Academy and personal Coaching at LearnDataEngineering.com\nVisit learndataengineering.com: Click Here\nLearn Data Engineering with our online Academy\nPerfect for becoming a Data Engineer or add Data Engineering to your skillset\nProven process based on years of experience and hundreds of hours of personal coaching\nPrepared courses on the most important fundamentals, tools and platforms plus our\nAssociate Data Engineer Certification\nPrivate Slack workgroup with over 500 members\nSupport This Book For Free!\nAmazon: Click Here buy whatever you like from Amazon using this link* (Also check out my complete podcast gear and books)\nContents:\nIntroduction\nBasic Engineering Skills\nAdvanced Engineering Skills\nHands On Course\u201a\nCase Studies\nBest Practices Cloud Platforms\n130+ Data Sources Data Science\n1001 Interview Questions\nRecommended Books and Courses\nHow To Contribute\nSupport What You Like\nImportant Links\nFull Table Of Contents:\nIntroduction\nWhat is this Cookbook\nData Engineer vs Data Scientist\nData Engineer\nData Scientist\nMachine Learning Workflow\nMachine Learning Model and Data\nMy Data Science Platform Blueprint\nConnect\nBuffer\nProcessing Framework\nStore\nVisualize\nWho Companies Need\nBasic Engineering Skills\nLearn To Code\nGet Familiar With Git\nAgile Development\nWhy is agile so important?\nAgile rules I learned over the years\nAgile Frameworks\nScrum\nOKR\nSoftware Engineering Culture\nLearn how a Computer Works\nData Network Transmission\nSecurity and Privacy\nSSL Public and Private Key Certificates\nJSON Web Tokens\nGDPR regulations\nLinux\nOS Basics\nShell scripting\nCron Jobs\nPacket Management\nDocker\nWhat is Docker and How it Works\nDon't Mess Up Your System\nPreconfigured Images\nTake it With You\nKubernetes Container Deployment\nHow to Create Start and Stop a Container\nDocker Micro Services\nKubernetes\nWhy and How To Do Docker Container Orchestration\nUserful Docker Commands\nThe Cloud\nIaaS vs PaaS vs SaaS\nAWS Azure IBM Google IBM\nCloud vs On-Premises\nSecurity\nHybrid Clouds\nSecurity Zone Design\nHow to secure a multi layered application\nCluster security with Kerberos\nAdvanced Engineering Skills\nData Science Platform\nWhy a Good Data Platform Is Important\nBig Data vs Data Science and Analytics\nThe 4 Vs of Big Data\nWhy Big Data\nPlanning is Everything\nThe Problem with ETL\nScaling Up\nScaling Out\nWhen not to Do Big Data\nHadoop Platforms\nWhat is Hadoop\nWhat makes Hadoop so popular\nHadoop Ecosystem Components\nHadoop is Everywhere?\nShould You Learn Hadoop?\nHow to Select Hadoop Cluster Hardware\nConnect\nREST APIs\nAPI Design\nImplemenation Frameworks\nSecurity\nApache Nifi\nLogstash\nBuffer\nApache Kafka\nWhy a Message Queue Tool?\nKafka Architecture\nKafka Topics\nKafka and Zookeeper\nHow to Produce and Consume Messages\nKafka Commands\nApache Redis Pub-Sub\nAWS Kinesis\nGoogle Cloud PubSub\nProcessing Frameworks\nLambda and Kappa Architecture\nBatch Processing\nStream Processing\nThree Methods of Streaming\nAt Least Once\nAt Most Once\nExactly Once\nCheck The Tools\nShould You do Stream or Batch Processing\nIs ETL still relevant for Analytics?\nMapReduce\nHow Does MapReduce Work\nMapReduce\nMapReduce Example\nMapReduce Limitations\nApache Spark\nWhat is the Difference to MapReduce?\nHow Spark Fits to Hadoop\nSpark vs Hadoop\nSpark and Hadoop a Perfect Fit\nSpark on YARn\nMy Simple Rule of Thumb\nAvailable Languages\nSpark Driver Executor and SparkContext\nSpark Batch vs Stream processing\nHow Spark uses Data From Hadoop\nWhat are RDDs and How to Use Them\nSparkSQL How and Why to Use It\nWhat are Dataframes and How to Use Them\nMachine Learning on Spark (TensorFlow)\nMLlib\nSpark Setup\nSpark Resource Management\nAWS Lambda \nApache Flink\nElasticsearch\nApache Drill\nStreamSets\nStore\nData Warehouse vs Data Lake\nSQL Databases\nPostgreSQL DB\nDatabase Design\nSQL Queries\nStored Procedures\nODBC/JDBC Server Connections\nNoSQL Stores\nHBase KeyValue Store\nHDFS Document Store\nMongoDB Document Store\nElasticsearch Document Store\nHive Warehouse\nImpala\nKudu\nApache Druid\nInfluxDB Time Series Database\nGreenplum MPP Database\nVisualize\nAndroid and IOS\nAPI Design for Mobile Apps\nDashboards\nGrafana\nKibana\nWebservers\nTomcat\nJetty\nNodeRED\nReact\nBusiness Intelligence Tools\nTableau\nPower BI\nQuliksense\nIdentity & Device Management\nWhat Is A Digital Twin\nActive Directory\nMachine Learning\nHow to do Machine Learning in production\nWhy machine learning in production is harder then you think\nModels Do Not Work Forever\nWhere are The Platforms That Support Machine Learning\nTraining Parameter Management\nHow to Convince People That Machine Learning Works\nNo Rules No Physical Models\nYou Have The Data. Use It!\nData is Stronger Than Opinions\nAWS Sagemaker\nHands On Course\nWhat We Want To Do\nThoughts On Choosing A Development Environment\nA Look Into the Twitter API\nIngesting Tweets with Apache Nifi\nWriting from Nifi to Apache Kafka\nApache Zeppelin Data Processing\nInstall and Ingest Kafka Topic\nProcessing Messages with Spark & SparkSQL\nVisualizing Data\nSwitch Processing from Zeppelin to Spark\nCase Studies\nData Science @Airbnb\nData Science @Amazon\nData Science @Baidu\nData Science @Blackrock\nData Science @BMW\nData Science @Booking.com\nData Science @CERN\nData Science @Disney\nData Science @DLR\nData Science @Drivetribe\nData Science @Dropbox\nData Science @Ebay\nData Science @Expedia\nData Science @Facebook\nData Science @Google\nData Science @Grammarly\nData Science @ING Fraud\nData Science @Instagram\nData Science @LinkedIn\nData Science @Lyft\nData Science @NASA\nData Science @Netflix\nData Science @OLX\nData Science @OTTO\nData Science @Paypal\nData Science @Pinterest\nData Science @Salesforce\nData Science @Siemens Mindsphere\nData Science @Slack\nData Science @Spotify\nData Science @Symantec\nData Science @Tinder\nData Science @Twitter\nData Science @Uber\nData Science @Upwork\nData Science @Woot\nData Science @Zalando\nBest Practices Cloud Platforms\nAmazon Web Services (AWS)\nConnect\nBuffer\nProcessing\nStore\nVisualize\nContainerization\nBest Practices\nMore Details\nMicrosoft Azure\nConnect\nBuffer\nProcessing\nStore\nVisualize\nContainerization\nBest Practices\nGoogle Cloud Platform (GCP)\nConnect\nBuffer\nProcessing\nStore\nVisualize\nContainerization\nBest Practices\n130+ Free Data Sources For Data Science\nGeneral And Academic\nContent Marketing\nCrime\nDrugs\nEducation\nEntertainment\nEnvironmental And Weather Data\nFinancial And Economic Data\nGovernment And World\nHealth\nHuman Rights\nLabor And Employment Data\nPolitics\nRetail\nSocial\nTravel And Transportation\nVarious Portals\nSource Articles and Blog Posts\nFree Data Sources Data Science\n1001 Interview Questions\nInterview Questions\nRecommended Books and Courses\nAbout Books and Courses\nBooks\nLanguages\nJava\nPython\nScala\nSwift\nData Science Tools\nApache Spark\nApache Kafka\nApache Hadoop\nApache HBase\nBusiness\nThe Lean Startup\nZero to One\nThe Innovators Dilemma\nCrossing the Chasm\nCrush It!\nCommunity Recommendations\nDesigning Data-Intensive Applications\nOnline Courses\nMachine Learning Stanford\nComputer Networking\nSpring Framework\nIOS App Development Specialization\nHow To Contribute\nIf you have some cool links or topics for the cookbook, please become a contributor.\nSimply pull the repo, add your ideas and create a pull request.\nYou can also open an issue and put your thoughts there.\nPlease use the \"Issues\" function for comments.\nSupport\nEverything is free, but please support what you like!\nJoin my Patreon and become a plumber yourself:\nLink to my Patreon\nOr support me and send a message I read on the next livestream through Paypal.me:\nLink to my Paypal.me/feedthestream\nImportant Links\nSubscribe to my Plumbers of Data Science YouTube channel for regular updates:\nLink to YouTube\nCheck out my blog and get updated via mail by joining my mailing list:\nandreaskretz.com\nI have a Medium publication where you can publish your data engineer articles to reach more people:\nMedium publication\n*(As an Amazon Associate I earn from qualifying purchases from Amazon\nThis is free of charge for you, but super helpful for supporting this channel)",
	"big-data cluster-management kafka scala": "CMAK (Cluster Manager for Apache Kafka, previously known as Kafka Manager)\nCMAK (previously known as Kafka Manager) is a tool for managing Apache Kafka clusters.\nSee below for details about the name change.\nCMAK supports the following:\nManage multiple clusters\nEasy inspection of cluster state (topics, consumers, offsets, brokers, replica distribution, partition distribution)\nRun preferred replica election\nGenerate partition assignments with option to select brokers to use\nRun reassignment of partition (based on generated assignments)\nCreate a topic with optional topic configs (0.8.1.1 has different configs than 0.8.2+)\nDelete topic (only supported on 0.8.2+ and remember set delete.topic.enable=true in broker config)\nTopic list now indicates topics marked for deletion (only supported on 0.8.2+)\nBatch generate partition assignments for multiple topics with option to select brokers to use\nBatch run reassignment of partition for multiple topics\nAdd partitions to existing topic\nUpdate config for existing topic\nOptionally enable JMX polling for broker level and topic level metrics.\nOptionally filter out consumers that do not have ids/ owners/ & offsets/ directories in zookeeper.\nCluster Management\nTopic List\nTopic View\nConsumer List View\nConsumed Topic View\nBroker List\nBroker View\nRequirements\nKafka 0.8.. or 0.9.. or 0.10.. or 0.11..\nJava 11+\nConfiguration\nThe minimum configuration is the zookeeper hosts which are to be used for CMAK (pka kafka manager) state.\nThis can be found in the application.conf file in conf directory.  The same file will be packaged\nin the distribution zip file; you may modify settings after unzipping the file on the desired server.\ncmak.zkhosts=\"my.zookeeper.host.com:2181\"\nYou can specify multiple zookeeper hosts by comma delimiting them, like so:\ncmak.zkhosts=\"my.zookeeper.host.com:2181,other.zookeeper.host.com:2181\"\nAlternatively, use the environment variable ZK_HOSTS if you don't want to hardcode any values.\nZK_HOSTS=\"my.zookeeper.host.com:2181\"\nYou can optionally enable/disable the following functionality by modifying the default list in application.conf :\napplication.features=[\"KMClusterManagerFeature\",\"KMTopicManagerFeature\",\"KMPreferredReplicaElectionFeature\",\"KMReassignPartitionsFeature\"]\nKMClusterManagerFeature - allows adding, updating, deleting cluster from CMAK (pka Kafka Manager)\nKMTopicManagerFeature - allows adding, updating, deleting topic from a Kafka cluster\nKMPreferredReplicaElectionFeature - allows running of preferred replica election for a Kafka cluster\nKMReassignPartitionsFeature - allows generating partition assignments and reassigning partitions\nConsider setting these parameters for larger clusters with jmx enabled :\ncmak.broker-view-thread-pool-size=< 3 * number_of_brokers>\ncmak.broker-view-max-queue-size=< 3 * total # of partitions across all topics>\ncmak.broker-view-update-seconds=< cmak.broker-view-max-queue-size / (10 * number_of_brokers) >\nHere is an example for a kafka cluster with 10 brokers, 100 topics, with each topic having 10 partitions giving 1000 total partitions with JMX enabled :\ncmak.broker-view-thread-pool-size=30\ncmak.broker-view-max-queue-size=3000\ncmak.broker-view-update-seconds=30\nThe follow control consumer offset cache's thread pool and queue :\ncmak.offset-cache-thread-pool-size=< default is # of processors>\ncmak.offset-cache-max-queue-size=< default is 1000>\ncmak.kafka-admin-client-thread-pool-size=< default is # of processors>\ncmak.kafka-admin-client-max-queue-size=< default is 1000>\nYou should increase the above for large # of consumers with consumer polling enabled.  Though it mainly affects ZK based consumer polling.\nKafka managed consumer offset is now consumed by KafkaManagedOffsetCache from the \"__consumer_offsets\" topic.  Note, this has not been tested with large number of offsets being tracked.  There is a single thread per cluster consuming this topic so it may not be able to keep up on large # of offsets being pushed to the topic.\nAuthenticating a User with LDAP\nWarning, you need to have SSL configured with CMAK (pka Kafka Manager) to ensure your credentials aren't passed unencrypted.\nAuthenticating a User with LDAP is possible by passing the user credentials with the Authorization header.\nLDAP authentication is done on first visit, if successful, a cookie is set.\nOn next request, the cookie value is compared with credentials from Authorization header.\nLDAP support is through the basic authentication filter.\nConfigure basic authentication\nbasicAuthentication.enabled=true\nbasicAuthentication.realm=< basic authentication realm>\nEncryption parameters (optional, otherwise randomly generated on startup) :\nbasicAuthentication.salt=\"some-hex-string-representing-byte-array\"\nbasicAuthentication.iv=\"some-hex-string-representing-byte-array\"\nbasicAuthentication.secret=\"my-secret-string\"\nConfigure LDAP/LDAPS authentication\nbasicAuthentication.ldap.enabled=< Boolean flag to enable/disable ldap authentication >\nbasicAuthentication.ldap.server=< fqdn of LDAP server>\nbasicAuthentication.ldap.port=< port of LDAP server>\nbasicAuthentication.ldap.username=< LDAP search username>\nbasicAuthentication.ldap.password=< LDAP search password>\nbasicAuthentication.ldap.search-base-dn=< LDAP search base>\nbasicAuthentication.ldap.search-filter=< LDAP search filter>\nbasicAuthentication.ldap.connection-pool-size=< number of connection to LDAP server>\nbasicAuthentication.ldap.ssl=< Boolean flag to enable/disable LDAPS>\n(Optional) Limit access to a specific LDAP Group\nbasicAuthentication.ldap.group-filter=< LDAP group filter>\nbasicAuthentication.ldap.ssl-trust-all=< Boolean flag to allow non-expired invalid certificates>\nExample (Online LDAP Test Server):\nbasicAuthentication.ldap.enabled=true\nbasicAuthentication.ldap.server=\"ldap.forumsys.com\"\nbasicAuthentication.ldap.port=389\nbasicAuthentication.ldap.username=\"cn=read-only-admin,dc=example,dc=com\"\nbasicAuthentication.ldap.password=\"password\"\nbasicAuthentication.ldap.search-base-dn=\"dc=example,dc=com\"\nbasicAuthentication.ldap.search-filter=\"(uid=$capturedLogin$)\"\nbasicAuthentication.ldap.group-filter=\"cn=allowed-group,ou=groups,dc=example,dc=com\"\nbasicAuthentication.ldap.connection-pool-size=10\nbasicAuthentication.ldap.ssl=false\nbasicAuthentication.ldap.ssl-trust-all=false\nDeployment\nThe command below will create a zip file which can be used to deploy the application.\n./sbt clean dist\nPlease refer to play framework documentation on production deployment/configuration.\nIf java is not in your path, or you need to build against a specific java version,\nplease use the following (the example assumes zulu java11):\n$ PATH=/usr/lib/jvm/zulu-11-amd64/bin:$PATH \\\n  JAVA_HOME=/usr/lib/jvm/zulu-11-amd64 \\\n  /path/to/sbt -java-home /usr/lib/jvm/zulu-11-amd64 clean dist\nThis ensures that the 'java' and 'javac' binaries in your path are first looked up in the\ncorrect location. Next, for all downstream tools that only listen to JAVA_HOME, it points\nthem to the java11 location. Lastly, it tells sbt to use the java11 location as\nwell.\nStarting the service\nAfter extracting the produced zipfile, and changing the working directory to it, you can\nrun the service like this:\n$ bin/cmak\nBy default, it will choose port 9000. This is overridable, as is the location of the\nconfiguration file. For example:\n$ bin/cmak -Dconfig.file=/path/to/application.conf -Dhttp.port=8080\nAgain, if java is not in your path, or you need to run against a different version of java,\nadd the -java-home option as follows:\n$ bin/cmak -java-home /usr/lib/jvm/zulu-11-amd64\nStarting the service with Security\nTo add JAAS configuration for SASL, add the config file location at start:\n$ bin/cmak -Djava.security.auth.login.config=/path/to/my-jaas.conf\nNOTE: Make sure the user running CMAK (pka kafka manager) has read permissions on the jaas config file\nPackaging\nIf you'd like to create a Debian or RPM package instead, you can run one of:\nsbt debian:packageBin\nsbt rpm:packageBin\nCredits\nMost of the utils code has been adapted to work with Apache Curator from Apache Kafka.\nName and Management\nCMAK was renamed from its previous name due to this issue. CMAK is designed to be used with Apache Kafka and is offered to support the needs of the Kafka community. This project is currently managed by employees at Verizon Media and the community who supports this project. \nLicense\nLicensed under the terms of the Apache License 2.0. See accompanying LICENSE file for terms.\nConsumer/Producer Lag\nProducer offset is polled.  Consumer offset is read from the offset topic for Kafka based consumers.  This means the reported lag may be negative since we are consuming offset from the offset topic faster then polling the producer offset.  This is normal and not a problem.\nMigration from Kafka Manager to CMAK\nCopy config files from old version to new version (application.conf, consumer.properties)\nChange start script to use bin/cmak instead of bin/kafka-manager",
	"analytics big-data cpp database financial-analysis grafana hacktoberfest iot java low-latency postgres postgresql questdb simd sql time-series time-series-database tsdb": "English | \u7b80\u4f53\u4e2d\u6587 | \u7e41\u9ad4\u4e2d\u6587 | \u0627\u0644\u0639\u0631\u0628\u064a\u0629 | Italiano | \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430 | Espa\u00f1ol | Portugu\u00eas | \u65e5\u672c\nQuestDB\nQuestDB is an open-source time-series database for high throughput ingestion and\nfast SQL queries with operational simplicity. It supports schema-agnostic\ningestion using the InfluxDB line protocol, PostgreSQL wire protocol, and a REST\nAPI for bulk imports and exports.\nQuestDB is well suited for financial market data, application metrics, sensor\ndata, real-time analytics, dashboards, and infrastructure monitoring.\nQuestDB implements ANSI SQL with native time-series SQL semantics. These SQL\nsemantics make it simple to correlate data from multiple sources using\nrelational and time-series joins. We achieve high performance by adopting a\ncolumn-oriented storage model, parallelized vector execution, SIMD instructions,\nand low-latency techniques. The entire codebase is built from the ground up in\nJava and C++, with no dependencies and zero garbage collection.\nTry QuestDB\nWe provide a live demo provisioned with the latest\nQuestDB release and sample datasets:\nTrips: 10 years of NYC taxi trips with 1.6 billion rows\nTrades: live crytocurrency market data with 30M+ rows per month\nPos: geolocations of 250k unique ships over time\n| Query                                                                         | Execution time                                                                                                                                                                                      |\n| ----------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| SELECT sum(double) FROM trips                                               | 0.15 secs                                                                                         |\n| SELECT sum(double), avg(double) FROM trips                                  | 0.5 secs                                                                        |\n| SELECT avg(double) FROM trips WHERE time in '2019'                          | 0.02 secs                                             |\n| SELECT time, avg(double) FROM trips WHERE time in '2019-01-01' SAMPLE BY 1h | 0.01 secs |\n| SELECT * FROM trades LATEST ON time PARTITION BY symbol                     | 0.00025 secs                                                    |\nOur demo is running on c5.metal instance and using 24 cores out of 96.\nGet started\nInstall QuestDB\nTo run QuestDB, Docker can be used to get started quickly:\nbash\ndocker run -p 9000:9000 -p 9009:9009 -p 8812:8812 questdb/questdb\nmacOS users can use Homebrew:\nbash\nbrew install questdb\nbrew services start questdb\nquestdb start // To start questdb\nquestdb stop  // To stop questdb\nThe QuestDB downloads page provides direct\ndownloads for binaries and has details for other installation and deployment\nmethods.\nConnect to QuestDB\nYou can interact with QuestDB using the following interfaces:\nWeb Console for interactive\n  SQL editor on port 9000\nInfluxDB line protocol for\n  high-throughput ingestion on port 9009\nREST API on port 9000\nPostgreSQL wire protocol on\n  port 8812\nInsert data\nBelow are our official InfluxDB line protocol clients for popular programming\nlanguages:\n.NET\nC/C++\nGo\nJava\nNodeJS\nPython\nRust\nHow QuestDB compares to other open source TSDBs\nThis article\ncompares QuestDB to other open source time series databases spanning\nfunctionality, maturity and performance.\nHere are high-cardinality\nTime Series Benchmark Suite\nresults using the cpu-only use case with 6 workers on an AMD Ryzen 3970X:\nResources\n\ud83d\udcda Read the docs\nQuestDB documentation: understand how\n  to run and configure QuestDB.\nTutorials: learn what's possible with QuestDB\n  step by step.\nProduct roadmap: check out our\n  plan for upcoming releases.\n\u2753 Get support\nCommunity Slack: join technical discussions, ask\n  questions, and meet other users!\nGitHub issues: report bugs or\n  issues with QuestDB.\nStack Overflow: look for\n  common troubleshooting solutions.\n\ud83d\udea2 Deploy QuestDB\nAWS AMI\nGoogle Cloud Platform\nOfficial Docker image\nDigitalOcean droplets\nKubernetes Helm charts\nContribute\nWe are always happy to have contributions to the project whether it is source\ncode, documentation, bug reports, feature requests or feedback. To get started\nwith contributing:\nHave a look through GitHub issues labeled\n  \"Good first issue\".\nRead the\n  contribution guide.\nFor details on building QuestDB, see the\n  build instructions.\nCreate a fork\n  of QuestDB and submit a pull request with your proposed changes.\n\u2728 As a sign of our gratitude, we also send QuestDB swag to our\ncontributors. Claim your swag here.\nA big thanks goes to the following wonderful people who have contributed to\nQuestDB: (emoji key):\nclickingbuttons\ud83d\udcbb \ud83e\udd14 \ud83d\udcd3\nideoma\ud83d\udcbb \ud83d\udcd3 \u26a0\ufe0f\ntonytamwk\ud83d\udcbb \ud83d\udcd3\nsirinath\ud83e\udd14\nigor-suhorukov\ud83d\udcbb \ud83e\udd14\nmick2004\ud83d\udcbb \ud83d\udce6\nrawkode\ud83d\udcbb \ud83d\ude87\nsolidnerd\ud83d\udcbb \ud83d\ude87\nsolanav\ud83d\udcbb \ud83d\udcd6\nshantanoo-desai\ud83d\udcdd \ud83d\udca1\nalexprut\ud83d\udcbb \ud83d\udea7\nlbowman\ud83d\udcbb \u26a0\ufe0f\nchankeypathak\ud83d\udcdd\nupsidedownsmile\ud83d\udcbb\nNagriar\ud83d\udcbb\npiotrrzysko\ud83d\udcbb \u26a0\ufe0f\nmpsq\ud83d\udcbb\nsiddheshlatkar\ud83d\udcbb\nYitaek\u2705 \ud83d\udca1\ngabor-boros\u2705 \ud83d\udca1\nkovid-r\u2705 \ud83d\udca1\nTimBo93\ud83d\udc1b \ud83d\udcd3\nzikani03\ud83d\udcbb\njaugsburger\ud83d\udcbb \ud83d\udea7\nTheTanc\ud83d\udcc6 \ud83d\udd8b \ud83e\udd14\ndavidgs\ud83d\udc1b \ud83d\udd8b\nkaishin\ud83d\udcbb \ud83d\udca1\nbluestreak01\ud83d\udcbb \ud83d\udea7 \u26a0\ufe0f\npatrickSpaceSurfer\ud83d\udcbb \ud83d\udea7 \u26a0\ufe0f\nchenrui333\ud83d\ude87\nbsmth\ud83d\udcd6 \ud83d\udd8b\nUgbot\ud83d\udcac \ud83d\udcd3 \ud83d\udce2\nlepolac\ud83d\udcbb \ud83d\udd27\ntiagostutz\ud83d\udcd3 \ud83d\udc1b \ud83d\udcc6\nLyncee59\ud83e\udd14 \ud83d\udcbb\nrrjanbiah\ud83d\udc1b\nsarunas-stasaitis\ud83d\udc1b\nRiccardoGiro\ud83d\udc1b\nduggar\ud83d\udc1b\npostol\ud83d\udc1b\npetrjahoda\ud83d\udc1b\nt00\ud83d\udc1b\nsnenkov\ud83d\udcd3 \ud83d\udc1b \ud83e\udd14\nmarregui\ud83d\udcbb \ud83e\udd14 \ud83c\udfa8\nbratseth\ud83d\udcbb \ud83e\udd14 \ud83d\udcd3\nwelly87\ud83e\udd14\nfuzzthink\ud83e\udd14 \ud83d\udcd3\nnexthack\ud83d\udcbb\ng-metan\ud83d\udc1b\ntim2skew\ud83d\udc1b \ud83d\udcd3\nospqsp\ud83d\udc1b\nSuperFluffy\ud83d\udc1b\nnu11ptr\ud83d\udc1b\ncomunidadio\ud83d\udc1b\nmugendi\ud83e\udd14 \ud83d\udc1b \ud83d\udcd6\npaulwoods222\ud83d\udc1b\nmingodad\ud83e\udd14 \ud83d\udc1b \ud83d\udcd6\nhouarizegai\ud83d\udcd6\njjsaunier\ud83d\udc1b\nzanek\ud83e\udd14 \ud83d\udcc6\nGeekaylee\ud83d\udcd3 \ud83e\udd14\nlg31415\ud83d\udc1b \ud83d\udcc6\nnull-dev\ud83d\udc1b \ud83d\udcc6\nultd\ud83e\udd14 \ud83d\udcc6\nericsun2\ud83e\udd14 \ud83d\udc1b \ud83d\udcc6\ngiovannibonetti\ud83d\udcd3 \ud83d\udc1b \ud83d\udcc6\nwavded\ud83d\udcd3 \ud83d\udc1b\npuzpuzpuz\ud83d\udcd6 \ud83d\udcbb \ud83d\udcd3\nrstreics\ud83d\udcbb \ud83d\ude87 \ud83d\udcd6\nmariusgheorghies\ud83d\udcbb \ud83d\ude87 \ud83d\udcd6\npswu11\ud83d\udd8b \ud83e\udd14 \ud83c\udfa8\ninsmac\ud83d\udcbb \ud83e\udd14 \ud83c\udfa8\neugenels\ud83d\udcbb \ud83e\udd14 \ud83d\udea7\nbziobrowski\ud83d\udcbb \ud83d\udcc6\nZapfmeister\ud83d\udcbb \ud83d\udcd3\nmkaruza\ud83d\udcbb\nDylanDKnight\ud83d\udcd3 \ud83d\udc1b\nenolal826\ud83d\udcbb\nglasstiger\ud83d\udcbb\nargshook\ud83d\udcbb \ud83e\udd14 \ud83c\udfa8 \ud83d\udc1b\namunra\ud83d\udcbb \ud83d\udcd6 \ud83d\udc1b\nGothamsJoker\ud83d\udcbb\nkocko\ud83d\udcbb\njerrinot\ud83d\udcbb \ud83e\udd14 \ud83d\udc1b\nrberrelleza\ud83d\udcbb\nCobalt-27\ud83d\udcbb\neschultz\ud83d\udcbb\nXinyiQiao\ud83d\udcbb\nterasum\ud83d\udcd6\nPlamenHristov\ud83d\udcbb\ntris0laris\ud83d\udcdd \ud83e\udd14\nHeZean\ud83d\udcbb \ud83d\udc1b\niridess\ud83d\udcbb \ud83d\udcd6\nselmanfarukyilmaz\ud83d\udc1b\ndonet5\ud83e\udd14 \ud83d\udc1b\nZahlii\ud83d\udc1b\nsalsasepp\ud83d\udc1b\nEmmettM\ud83d\udc1b \u26a0\ufe0f\nrobd003\ud83e\udd14\nAllenEdison\ud83d\udc1b\nCSharpDummy\ud83d\udc1b\nshimondoodkin\ud83d\udc1b \ud83e\udd14\nhuuhait\ud83d\udc1b \ud83e\udd14\nalexey-milovidov\ud83d\udc1b\nsuconghou\ud83d\udc1b\nTheZal\ud83d\udcd6\nThis project adheres to the\nall-contributors\nspecification. Contributions of any kind are welcome!",
	"big-data cpp database distributed distributed-systems graph graph-database graphdb nebula nebula-graph nebulagraph raft scalability": "English | \u4e2d\u6587\nA distributed, scalable, lightning-fast graph database\nWhat is NebulaGraph?\nNebulaGraph is an open-source graph database capable of hosting super large-scale graphs with dozens of billions of vertices (nodes) and trillions of edges, with milliseconds of latency.\nTrusted and contributed by users, the NebulaGraph community comes with a rich open-source ecosystem. And it has been widely used for social media, recommendation systems, knowledge graphs, security, capital flows, AI, etc, see our users.\nCompared with other graph database solutions, NebulaGraph has the following advantages:\nSymmetrically distributed\nStorage and computing separation\nHorizontal scalability\nStrong data consistency by RAFT protocol\nOpenCypher-compatible query language\nRole-based access control for higher-level security\nQuick start\nRead the Getting started article for a quick start.\nGetting help\nIn case you encounter any problems playing around NebulaGraph, please reach out for help:\n* FAQ\n* Discussions\nDocumentation\nEnglish\nArchitecture\nContributing\nContributions are warmly welcomed and greatly appreciated. And here are a few ways you can contribute:\nStart by some issues\nSubmit Pull Requests to us. See how-to-contribute.\nLandscape\nNebulaGraph enriches the \nCNCF Database Landscape.\nLicensing\nNebulaGraph is under Apache 2.0 license, so you can freely download, modify, and deploy the source code to meet your needs.\nYou can also freely deploy NebulaGraph as a back-end service to support your SaaS deployment.\nContact\nSlack Channel\nStack Overflow\nTwitter: @NebulaGraph\nLinkedIn Page\nEmail: info@vesoft.com\nCommunity\nIf you find NebulaGraph interesting, please \u2b50\ufe0f Star it on GitHub at the top of the page.\nhttps://github.com/vesoft-inc/nebula",
	"big-data catboost categorical-features coreml cuda data-mining data-science decision-trees gbdt gbm gpu gpu-computing gradient-boosting kaggle machine-learning python r tutorial": "Website |\nDocumentation |\nTutorials |\nInstallation |\nRelease Notes\nCatBoost is a machine learning method based on gradient boosting over decision trees.\nMain advantages of CatBoost:\nSuperior quality when compared with other GBDT libraries on many datasets.\nBest in class prediction speed.\nSupport for both numerical and categorical features.\nFast GPU and multi-GPU support for training out of the box.\nVisualization tools included.\nFast and reproducible distributed training with Apache Spark and CLI.\nGet Started and Documentation\nAll CatBoost documentation is available here.\nInstall CatBoost by following the guide for the\n * Python package\n * R-package\n * \u0421ommand line\n * Package for Apache Spark\nNext you may want to investigate:\n* Tutorials\n* Training modes and metrics\n* Cross-validation\n* Parameters tuning\n* Feature importance calculation\n* Regular and staged predictions\n* CatBoost for Apache Spark videos: Introduction and Architecture\nIf you cannot open documentation in your browser try adding yastatic.net and yastat.net to the list of allowed domains in your privacy badger. \nCatboost models in production\nIf you want to evaluate Catboost model in your application read model api documentation.\nQuestions and bug reports\nFor reporting bugs please use the catboost/bugreport page.\nAsk a question on Stack Overflow with the catboost tag, we monitor this for new questions.\nSeek prompt advice at Telegram group or Russian-speaking Telegram chat\nHelp to Make CatBoost Better\nCheck out open problems and help wanted issues to see what can be improved, or open an issue if you want something.\nAdd your stories and experience to Awesome CatBoost.\nTo contribute to CatBoost you need to first read CLA text and add to your pull request, that you agree to the terms of the CLA. More information can be found\nin CONTRIBUTING.md\nInstructions for contributors can be found here.\nNews\nLatest news are published on twitter.\nReference Paper\nAnna Veronika Dorogush, Andrey Gulin, Gleb Gusev, Nikita Kazeev, Liudmila Ostroumova Prokhorenkova, Aleksandr Vorobev \"Fighting biases with dynamic boosting\". arXiv:1706.09516, 2017.\nAnna Veronika Dorogush, Vasily Ershov, Andrey Gulin \"CatBoost: gradient boosting with categorical features support\". Workshop on ML Systems\nat NIPS 2017.\nLicense\n\u00a9 YANDEX LLC, 2017-2022. Licensed under the Apache License, Version 2.0. See LICENSE file for more details.",
	"analytics big-data data-science database databases datalake distributed-database distributed-databases distributed-systems hadoop hive java jdbc presto prestodb query-engine sql trino": "Trino is a fast distributed SQL query engine for big data analytics.\nSee the User Manual for deployment instructions and end user documentation.\n\nDevelopment\nSee DEVELOPMENT for information about code style,\ndevelopment process, and guidelines.\nSee CONTRIBUTING for contribution requirements.\nSecurity\nSee the project security policy for\ninformation about reporting vulnerabilities.\nBuild requirements\nMac OS X or Linux\nJava 17.0.4+, 64-bit\nDocker\nBuilding Trino\nTrino is a standard Maven project. Simply run the following command from the\nproject root directory:\n./mvnw clean install -DskipTests\nOn the first build, Maven downloads all the dependencies from the internet\nand caches them in the local repository (~/.m2/repository), which can take a\nwhile, depending on your connection speed. Subsequent builds are faster.\nTrino has a comprehensive set of tests that take a considerable amount of time\nto run, and are thus disabled by the above command. These tests are run by the\nCI system when you submit a pull request. We recommend only running tests\nlocally for the areas of code that you change.\nRunning Trino in your IDE\nOverview\nAfter building Trino for the first time, you can load the project into your IDE\nand run the server.  We recommend using\nIntelliJ IDEA. Because Trino is a standard\nMaven project, you easily can import it into your IDE.  In IntelliJ, choose\nOpen Project from the Quick Start box or choose Open\nfrom the File menu and select the root pom.xml file.\nAfter opening the project in IntelliJ, double check that the Java SDK is\nproperly configured for the project:\nOpen the File menu and select Project Structure\nIn the SDKs section, ensure that JDK 17 is selected (create one if none exist)\nIn the Project section, ensure the Project language level is set to 17\nRunning a testing server\nThe simplest way to run Trino for development is to run the TpchQueryRunner\nclass. It will start a development version of the server that is configured with\nthe TPCH connector. You can then use the CLI to execute queries against this\nserver. Many other connectors have their own *QueryRunner class that you can\nuse when working on a specific connector.\nRunning the full server\nTrino comes with sample configuration that should work out-of-the-box for\ndevelopment. Use the following options to create a run configuration:\nMain Class: io.trino.server.DevelopmentServer\nVM Options: -ea -Dconfig=etc/config.properties -Dlog.levels-file=etc/log.properties -Djdk.attach.allowAttachSelf=true\nWorking directory: $MODULE_DIR$\nUse classpath of module: trino-server-dev\nThe working directory should be the trino-server-dev subdirectory. In\nIntelliJ, using $MODULE_DIR$ accomplishes this automatically.\nIf VM options doesn't exist in the dialog, you need to select Modify options\nand enable Add VM options.\nRunning the CLI\nStart the CLI to connect to the server and run SQL queries:\nclient/trino-cli/target/trino-cli-*-executable.jar\nRun a query to see the nodes in the cluster:\nSELECT * FROM system.runtime.nodes;\nRun a query against the TPCH connector:\nSELECT * FROM tpch.tiny.region;",
	"analytics big-data data-warehousing database datalake dbms distributed-database hadoop hive hudi iceberg mpp olap real-time sql ssb tpch vectorized": "Apache Doris\nApache Doris is an easy-to-use, high-performance and real-time analytical database based on MPP architecture, known for its extreme speed and ease of use. It only requires a sub-second response time to return query results under massive data and can support not only high-concurrent point query scenarios but also high-throughput complex analysis scenarios.\nBased on this, Apache Doris can better meet the scenarios of report analysis, ad-hoc query, unified data warehouse, Data Lake Query Acceleration, etc. Users can build user behavior analysis, AB test platform, log retrieval analysis, user portrait analysis, order analysis, and other applications on top of this.\n\ud83c\udf89 Version 1.1.4 released now! It is also a LTS (long-term support) release and all users are encouraged to upgrade to this release. Check out the \ud83d\udd17Release Notes here. \n\ud83d\udc40 Have a look at the \ud83d\udd17Official Website for a comprehensive list of Apache Doris's core features, blogs and user cases.\n\ud83d\udcc8 Usage Scenarios\nAs shown in the figure below, after various data integration and processing, the data sources are usually stored in the real-time data warehouse Apache Doris and the offline data lake or data warehouse (in Apache Hive, Apache Iceberg or Apache Hudi).\nApache Doris is widely used in the following scenarios:\nReporting Analysis\nReal-time Dashboards\nReports for in-house analysts and managers\nHighly concurrent user-oriented or customer-oriented report analysis.For example, in the scenarios of site analysis for website owners and advertising reports for advertisers, the concurrency usually requires thousands of QPS and the query latency requires sub-seconds response. The famous e-commerce company JD.com uses Doris in advertising reports, writing 10 billion rows of data per day, with tens of thousands of concurrent query QPS and 150ms query latency for the 99th percentile.\nAd-Hoc Query. Analyst-oriented self-service analytics with irregular query patterns and high throughput requirements. XiaoMi has built a growth analytics platform (Growth Analytics, GA) based on Doris, using user behavior data for business growth analysis, with an average query latency of 10 seconds and a 95th percentile query latency of 30 seconds or less, and tens of thousands of SQL queries per day.\nUnified data warehouse construction. A platform to meet the needs of unified data warehouse construction and simplify the complicated data software stack. HaiDiLao's Doris-based unified data warehouse replaces the old architecture consisting of Apache Spark, Apache Hive, Apache Kudu, Apache HBase, and Apache Phoenix, and greatly simplifies the architecture.\nData Lake Query. By federating the data located in Apache Hive, Apache Iceberg, and Apache Hudi using external tables, the query performance is greatly improved while avoiding data copying.\n\ud83d\udda5\ufe0f Core Concepts\n\ud83d\udcc2 Architecture of Apache Doris\nThe overall architecture of Apache Doris is shown in the following figure. The Doris architecture is very simple, with only two types of processes.\nFrontend\uff08FE\uff09: It is mainly responsible for user request access, query parsing and planning, management of metadata, and node management-related work.\nBackend\uff08BE\uff09: It is mainly responsible for data storage and query plan execution.\nBoth types of processes are horizontally scalable, and a single cluster can support up to hundreds of machines and tens of petabytes of storage capacity. And these two types of processes guarantee high availability of services and high reliability of data through consistency protocols. This highly integrated architecture design greatly reduces the operation and maintenance cost of a distributed system.\nApache Doris adopts MySQL protocol, highly compatible with MySQL dialect, and supports standard SQL. Users can access Doris through various client tools and support seamless connection with BI tools.\n\ud83d\udcbe Storage Engine\nIn terms of the storage engine, Apache Doris uses columnar storage to encode and compress and read data by column, enabling a very high compression ratio while reducing a large number of scans of non-relevant data, thus making more efficient use of IO and CPU resources. Doris also supports a relatively rich index structure to reduce data scans:\nSupport sorted compound key index: Up to three columns can be specified to form a compound sort key. With this index, data can be effectively pruned to better support high concurrent reporting scenarios.\nZ-order index \uff1aUsing Z-order indexing, you can efficiently run range queries on any combination of fields in your schema.\nMIN/MAX index: Effective filtering of equivalence and range queries for numeric types\nBloom Filter index: very effective for equivalence filtering and pruning of high cardinality columns\nInvert index: It enables the fast search of any field.\n\ud83d\udcbf Storage Models\nIn terms of storage models, Apache Doris supports a variety of storage models, with specific optimizations for different scenarios:\nAggregate Key model: Merge the value columns with the same keys, by aggregating in advance to significantly improve performance.\nUnique Key model: The key is unique. Data with the same key will be overwritten to achieve row-level data updates.\nDuplicate Key model: The detailed data model can satisfy the detailed storage of fact tables.\nApache Doris also supports strong consistent materialized views, where updates and selections of materialized views are made automatically within the system and do not require manual selection by the user, thus significantly reducing the cost of materialized view maintenance.\n\ud83d\udd0d Query Engine\nIn terms of query engine, Apache Doris adopts the MPP model, with parallel execution between and within nodes, and also supports distributed shuffle join for multiple large tables, which can better cope with complex queries.\nThe Doris query engine is vectorized, and all memory structures can be laid out in a columnar format to achieve significant reductions in virtual function calls, improved Cache hit rates, and efficient use of SIMD instructions. Performance in wide table aggregation scenarios is 5\u201310 times higher than in non-vectorized engines.\nApache Doris uses Adaptive Query Execution technology, which can dynamically adjust the execution plan based on runtime statistics, such as runtime filter technology to generate filters to push to the probe side at runtime and to automatically penetrate the filters to the probe side which drastically reduces the amount of data in the probe and speeds up join performance. Doris' runtime filter supports In/Min/Max/Bloom filter.\n\ud83d\ude85 Query Optimizer\nIn terms of the optimizer, Doris uses a combination of CBO and RBO, with RBO supporting constant folding, subquery rewriting, predicate pushdown, etc., and CBO supporting Join Reorder. CBO is still under continuous optimization, mainly focusing on more accurate statistical information collection and derivation, more accurate cost model prediction, etc.\nTechnical Overview: \ud83d\udd17Introduction to Apache Doris\n\ud83c\udf86 Why choose Apache Doris?\n\ud83c\udfaf Easy to Use: Two processes, no other dependencies; online cluster scaling, automatic replica recovery; compatible with MySQL protocol, and using standard SQL.\n\ud83d\ude80 High Performance: Extremely fast performance for low-latency and high-throughput queries with columnar storage engine, modern MPP architecture, vectorized query engine, pre-aggregated materialized view and data index.\n\ud83d\udda5\ufe0f Single Unified: A single system can support real-time data serving, interactive data analysis and offline data processing scenarios.\n\u269b\ufe0f Federated Querying: Supports federated querying of data lakes such as Hive, Iceberg, Hudi, and databases such as MySQL and Elasticsearch.\n\u23e9 Various Data Import Methods: Supports batch import from HDFS/S3 and stream import from MySQL Binlog/Kafka; supports micro-batch writing through HTTP interface and real-time writing using Insert in JDBC.\n\ud83d\ude99 Rich Ecology: Spark uses Spark-Doris-Connector to read and write Doris; Flink-Doris-Connector enables Flink CDC to implement exactly-once data writing to Doris; DBT Doris Adapter is provided to transform data in Doris with DBT.\n\ud83d\ude4c Contributors\nApache Doris has graduated from Apache incubator successfully and become a Top-Level Project in June 2022. \nCurrently, the Apache Doris community has gathered more than 350 contributors from nearly 100 companies in different industries, and the number of active contributors is close to 100 per month.\nWe deeply appreciate \ud83d\udd17community contributors for their contribution to Apache Doris.\n\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66 Users\nApache Doris now has a wide user base in China and around the world, and as of today, Apache Doris is used in production environments in over 700 companies worldwide. More than 80% of the top 50 Internet companies in China in terms of market capitalization or valuation have been using Apache Doris for a long time, including Baidu, Meituan, Xiaomi, Jingdong, Bytedance, Tencent, NetEase, Kwai, Weibo, and Ke Holdings. It is also widely used in some traditional industries such as finance, energy, manufacturing, and telecommunications.\nThe users of Apache Doris: \ud83d\udd17https://doris.apache.org/users\nAdd your company logo at Apache Doris Website: \ud83d\udd17Add Your Company\n\ud83d\udc63 Get Started\n\ud83d\udcda Docs\nAll Documentation   \ud83d\udd17Docs \n\u2b07\ufe0f Download\nAll release and binary version \ud83d\udd17Download \n\ud83d\uddc4\ufe0f Compile\nSee how to compile  \ud83d\udd17Compilation\n\ud83d\udcee Install\nSee how to install and deploy \ud83d\udd17Installation and deployment \n\ud83e\udde9 Components\n\ud83d\udcdd Doris Connector\nDoris provides support for Spark/Flink to read data stored in Doris through Connector, and also supports to write data to Doris through Connector.\n\ud83d\udd17apache/doris-flink-connector\n\ud83d\udd17apache/doris-spark-connector\n\ud83d\udee0 Doris Manager\nDoris provides one-click visual automatic installation and deployment, cluster management and monitoring tools for clusters.\n\ud83d\udd17apache/doris-manager\n\ud83c\udf08 Community and Support\n\ud83d\udce4 Subscribe Mailing Lists\nMail List is the most recognized form of communication in Apache community. See how to \ud83d\udd17Subscribe Mailing Lists\n\ud83d\ude4b Report Issues or Submit Pull Request\nIf you meet any questions, feel free to file a \ud83d\udd17GitHub Issue or post it in \ud83d\udd17GitHub Discussion and fix it by submitting a \ud83d\udd17Pull Request \n\ud83c\udf7b How to Contribute\nWe welcome your suggestions, comments (including criticisms), comments and contributions. See \ud83d\udd17How to Contribute and \ud83d\udd17Code Submission Guide\n\u2328\ufe0f Doris Improvement Proposals (DSIP)\n\ud83d\udd17Doris Improvement Proposal (DSIP) can be thought of as A Collection of Design Documents for all Major Feature Updates or Improvements.\n\ud83d\udcac Contact Us\nContact us through the following mailing list.\n| Name                                                                          | Scope                           |                                                                 |                                                                     |                                                                              |\n|:------------------------------------------------------------------------------|:--------------------------------|:----------------------------------------------------------------|:--------------------------------------------------------------------|:-----------------------------------------------------------------------------|\n| dev@doris.apache.org     | Development-related discussions | Subscribe   | Unsubscribe   | Archives   |\n\ud83e\uddf0 Links\nApache Doris Official Website - https://doris.apache.org\nDeveloper Mailing list - dev@doris.apache.org. Mail to dev-subscribe@doris.apache.org, follow the reply to subscribe the mail list.\nSlack channel - Join the Slack\nTwitter - Follow @doris_apache\n\ud83d\udcdc License\nApache License, Version 2.0\nNote\nSome licenses of the third-party dependencies are not compatible with Apache 2.0 License. So you need to disable\nsome Doris features to be complied with Apache 2.0 License. For details, refer to the thirdparty/LICENSE.txt",
	"automl big-data data-science deep-learning distributed ensemble-learning gbm gpu h2o h2o-automl hadoop java machine-learning naive-bayes opensource pca python r random-forest spark": "H2O\nH2O is an in-memory platform for distributed, scalable machine learning. H2O uses familiar interfaces like R, Python, Scala, Java, JSON and the Flow notebook/web interface, and works seamlessly with big data technologies like Hadoop and Spark. H2O provides implementations of many popular algorithms such as Generalized Linear Models (GLM), Gradient Boosting Machines (including XGBoost), Random Forests, Deep Neural Networks, Stacked Ensembles, Naive Bayes, Generalized Additive Models (GAM), Cox Proportional Hazards, K-Means, PCA, Word2Vec, as well as a fully automatic machine learning algorithm (H2O AutoML). \nH2O is extensible so that developers can add data transformations and custom algorithms of their choice and access them through all of those clients.  H2O models can be downloaded and loaded into H2O memory for scoring, or exported into POJO or MOJO format for extemely fast scoring in production.  More information can be found in the H2O User Guide.\nH2O-3 (this repository) is the third incarnation of H2O, and the successor to H2O-2.\nTable of Contents\nDownloading H2O-3\nOpen Source Resources\nIssue Tracking and Feature Requests\nList of H2O Resources\nUsing H2O-3 Code Artifacts (libraries)\nBuilding H2O-3\nLaunching H2O after Building\nBuilding H2O on Hadoop\nSparkling Water\nDocumentation\nCiting H2O\nRoadmap\nCommunity / Advisors / Investors\n\n\nDownloading H2O-3\nWhile most of this README is written for developers who do their own builds, most H2O users just download and use a pre-built version.  If you are a Python or R user, the easiest way to install H2O is via PyPI or Anaconda (for Python) or CRAN (for R):\nPython\nbash\npip install h2o\nR\nr\ninstall.packages(\"h2o\")\nFor the latest stable, nightly, Hadoop (or Spark / Sparkling Water) releases, or the stand-alone H2O jar, please visit: https://h2o.ai/download\nMore info on downloading & installing H2O is available in the H2O User Guide.\n\n\nOpen Source Resources\nMost people interact with three or four primary open source resources:  GitHub (which you've already found), JIRA (for bug reports and issue tracking), Stack Overflow for H2O code/software-specific questions, and h2ostream (a Google Group / email discussion forum) for questions not suitable for Stack Overflow.  There is also a Gitter H2O developer chat group, however for archival purposes & to maximize accessibility, we'd prefer that standard H2O Q&A be conducted on Stack Overflow.\n\n\n2.1 Issue Tracking and Feature Requests\n(Note: There is only one issue tracking system for the project.  GitHub issues are not enabled; you must use JIRA.)\nYou can browse and create new issues in our open source JIRA:  http://jira.h2o.ai\nYou can browse and search for issues without logging in to JIRA:\nClick the Issues menu\nClick Search for issues\nTo create an issue (either a bug or a feature request), please create yourself an account first:\nClick the Log In button on the top right of the screen\nClick Create an acccount near the bottom of the login box\nOnce you have created an account and logged in, use the Create button on the menu to create an issue\nCreate H2O-3 issues in the PUBDEV project.  (Note: Sparkling Water questions should be filed under the SW project.)\nYou can also vote for feature requests and/or other issues. Voting can help H2O prioritize the features that are included in each release.\nGo to the H2O JIRA page.\nClick Log In to either log in or create an account if you do not already have one.\nSearch for the feature that you want to prioritize, or create a new feature.\nClick on the Vote for this issue link. This is located on the right side of the issue under the People section.\n2.2 List of H2O Resources\nGitHub\nhttps://github.com/h2oai/h2o-3\nJIRA -- file bug reports / track issues here\nThe PUBDEV project contains issues for the current H2O-3 project)\nStack Overflow -- ask all code/software questions here\nhttp://stackoverflow.com/questions/tagged/h2o\nCross Validated (Stack Exchange) -- ask algorithm/theory questions here\nhttps://stats.stackexchange.com/questions/tagged/h2o\nh2ostream Google Group -- ask non-code related questions here\nWeb: https://groups.google.com/d/forum/h2ostream\nMail to: h2ostream@googlegroups.com\nGitter H2O Developer Chat\nhttps://gitter.im/h2oai/h2o-3 \nDocumentation\nH2O User Guide (main docs): http://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html\nAll H2O documenation links: http://docs.h2o.ai\nNightly build page (nightly docs linked in page): https://s3.amazonaws.com/h2o-release/h2o/master/latest.html\nDownload (pre-built packages)\nhttp://h2o.ai/download\nJenkins (H2O build and test system)\nhttp://test.h2o.ai\nWebsite\nhttp://h2o.ai\nTwitter -- follow us for updates and H2O news!\nhttps://twitter.com/h2oai\nAwesome H2O -- share your H2O-powered creations with us\nhttps://github.com/h2oai/awesome-h2o\n\nUsing H2O-3 Artifacts\nEvery nightly build publishes R, Python, Java, and Scala artifacts to a build-specific repository.  In particular, you can find Java artifacts in the maven/repo directory.\nHere is an example snippet of a gradle build file using h2o-3 as a dependency.  Replace x, y, z, and nnnn with valid numbers.\n// h2o-3 dependency information\ndef h2oBranch = 'master'\ndef h2oBuildNumber = 'nnnn'\ndef h2oProjectVersion = \"x.y.z.${h2oBuildNumber}\"\nrepositories {\n  // h2o-3 dependencies\n  maven {\n    url \"https://s3.amazonaws.com/h2o-release/h2o-3/${h2oBranch}/${h2oBuildNumber}/maven/repo/\"\n  }\n}\ndependencies {\n  compile \"ai.h2o:h2o-core:${h2oProjectVersion}\"\n  compile \"ai.h2o:h2o-algos:${h2oProjectVersion}\"\n  compile \"ai.h2o:h2o-web:${h2oProjectVersion}\"\n  compile \"ai.h2o:h2o-app:${h2oProjectVersion}\"\n}\nRefer to the latest H2O-3 bleeding edge nightly build page for information about installing nightly build artifacts.\nRefer to the h2o-droplets GitHub repository for a working example of how to use Java artifacts with gradle.\n\nNote: Stable H2O-3 artifacts are periodically published to Maven Central (click here to search) but may substantially lag behind H2O-3 Bleeding Edge nightly builds.\n\nBuilding H2O-3\nGetting started with H2O development requires JDK 1.8+, Node.js, Gradle, Python and R.  We use the Gradle wrapper (called gradlew) to ensure up-to-date local versions of Gradle and other dependencies are installed in your development directory.\n4.1. Before building\nBuilding h2o requires a properly set up R environment with required packages and Python environment with the following packages:\ngrip\nfuture\ntabulate\nrequests\nwheel\nTo install these packages you can use pip or conda.\nIf you have troubles installing these packages on Windows, please follow section Setup on Windows of this guide.\n\n(Note: It is recommended to use some virtual environment such as VirtualEnv, to install all packages. )\n4.2. Building from the command line (Quick Start)\nTo build H2O from the repository, perform the following steps.\nRecipe 1: Clone fresh, build, skip tests, and run H2O\nBuild H2O\ngit clone https://github.com/h2oai/h2o-3.git\ncd h2o-3\n./gradlew build -x test\nYou may encounter problems: e.g. npm missing. Install it:\nbrew install npm\nStart H2O\njava -jar build/h2o.jar\nPoint browser to http://localhost:54321\nRecipe 2: Clone fresh, build, and run tests (requires a working install of R)\ngit clone https://github.com/h2oai/h2o-3.git\ncd h2o-3\n./gradlew syncSmalldata\n./gradlew syncRPackages\n./gradlew build\nNotes:\nRunning tests starts five test JVMs that form an H2O cluster and requires at least 8GB of RAM (preferably 16GB of RAM).\nRunning ./gradlew syncRPackages is supported on Windows, OS X, and Linux, and is strongly recommended but not required. ./gradlew syncRPackages ensures a complete and consistent environment with pre-approved versions of the packages required for tests and builds. The packages can be installed manually, but we recommend setting an ENV variable and using ./gradlew syncRPackages. To set the ENV variable, use the following format (where `${WORKSPACE} can be any path):\nmkdir -p ${WORKSPACE}/Rlibrary\nexport R_LIBS_USER=${WORKSPACE}/Rlibrary\nRecipe 3:  Pull, clean, build, and run tests\ngit pull\n./gradlew syncSmalldata\n./gradlew syncRPackages\n./gradlew clean\n./gradlew build\nNotes\nWe recommend using ./gradlew clean after each git pull.\nSkip tests by adding -x test at the end the gradle build command line.  Tests typically run for 7-10 minutes on a Macbook Pro laptop with 4 CPUs (8 hyperthreads) and 16 GB of RAM.\nSyncing smalldata is not required after each pull, but if tests fail due to missing data files, then try ./gradlew syncSmalldata as the first troubleshooting step.  Syncing smalldata downloads data files from AWS S3 to the smalldata directory in your workspace.  The sync is incremental.  Do not check in these files.  The smalldata directory is in .gitignore.  If you do not run any tests, you do not need the smalldata directory.\nRunning ./gradlew syncRPackages is supported on Windows, OS X, and Linux, and is strongly recommended but not required. ./gradlew syncRPackages ensures a complete and consistent environment with pre-approved versions of the packages required for tests and builds. The packages can be installed manually, but we recommend setting an ENV variable and using ./gradlew syncRPackages. To set the ENV variable, use the following format (where ${WORKSPACE} can be any path):\nmkdir -p ${WORKSPACE}/Rlibrary\n  export R_LIBS_USER=${WORKSPACE}/Rlibrary\nRecipe 4:  Just building the docs\n./gradlew clean && ./gradlew build -x test && (export DO_FAST=1; ./gradlew dist)\nopen target/docs-website/h2o-docs/index.html\nRecipe 5:  Building using a Makefile\nRoot of the git repository contains a Makefile with convenient shortcuts for frequent build targets used in development.\nTo build h2o.jar while skipping tests and also the building of alternative assemblies, execute \nmake\nTo build h2o.jar using the minimal assembly, run\nmake minimal\nThe minimal assembly is well suited for developement of H2O machine learning algorithms. It doesn't bundle some heavyweight\ndependencies (like Hadoop) and using it saves build time as well as need to download large libraries from Maven repositories.\n4.3. Setup on Windows\nStep 1: Download and install WinPython.\nFrom the command line, validate python is using the newly installed package by using which python (or sudo which python). Update the Environment variable with the WinPython path.\nStep 2: Install required Python packages:\npip install grip future tabulate wheel\nStep 3: Install JDK\nInstall Java 1.8+ and add the appropriate directory C:\\Program Files\\Java\\jdk1.7.0_65\\bin with java.exe to PATH in Environment Variables. To make sure the command prompt is detecting the correct Java version, run:\njavac -version\nThe CLASSPATH variable also needs to be set to the lib subfolder of the JDK:\nCLASSPATH=////lib\nStep 4. Install Node.js\nInstall Node.js and add the installed directory C:\\Program Files\\nodejs, which must include node.exe and npm.cmd to PATH if not already prepended.\nStep 5. Install R, the required packages, and Rtools:\nInstall R and add the bin directory to your PATH if not already included.\nInstall the following R packages:\nRCurl\njsonlite\nstatmod\ndevtools\nroxygen2\ntestthat\nTo install these packages from within an R session:\nr\npkgs <- c(\"RCurl\", \"jsonlite\", \"statmod\", \"devtools\", \"roxygen2\", \"testthat\")\nfor (pkg in pkgs) {\n  if (! (pkg %in% rownames(installed.packages()))) install.packages(pkg)\n}\nNote that libcurl is required for installation of the RCurl R package.\nNote that this packages don't cover running tests, they for building H2O only.\nFinally, install Rtools, which is a collection of command line tools to facilitate R development on Windows.\nNOTE: During Rtools installation, do not install Cygwin.dll.\nStep 6. Install Cygwin\nNOTE: During installation of Cygwin, deselect the Python packages to avoid a conflict with the Python.org package.\nStep 6b. Validate Cygwin\nIf Cygwin is already installed, remove the Python packages or ensure that Native Python is before Cygwin in the PATH variable.\nStep 7. Update or validate the Windows PATH variable to include R, Java JDK, Cygwin.\nStep 8. Git Clone h2o-3\nIf you don't already have a Git client, please install one.  The default one can be found here http://git-scm.com/downloads.  Make sure that command prompt support is enabled before the installation.\nDownload and update h2o-3 source codes:\ngit clone https://github.com/h2oai/h2o-3\nStep 9. Run the top-level gradle build:\ncd h2o-3\n./gradlew.bat build\nIf you encounter errors run again with --stacktrace for more instructions on missing dependencies.\n4.4. Setup on OS X\nIf you don't have Homebrew, we recommend installing it.  It makes package management for OS X easy.\nStep 1. Install JDK\nInstall Java 1.8+. To make sure the command prompt is detecting the correct Java version, run:\njavac -version\nStep 2. Install Node.js:\nUsing Homebrew:\nbrew install node\nOtherwise, install from the NodeJS website.\nStep 3. Install R and the required packages:\nInstall R and add the bin directory to your PATH if not already included.\nInstall the following R packages:\nRCurl\njsonlite\nstatmod\ndevtools\nroxygen2\ntestthat\nTo install these packages from within an R session:\nr\npkgs <- c(\"RCurl\", \"jsonlite\", \"statmod\", \"devtools\", \"roxygen2\", \"testthat\")\nfor (pkg in pkgs) {\n  if (! (pkg %in% rownames(installed.packages()))) install.packages(pkg)\n}\nNote that libcurl is required for installation of the RCurl R package.\nNote that this packages don't cover running tests, they for building H2O only.\nStep 4. Install python and the required packages:\nInstall python:\nbrew install python\nInstall pip package manager:\nsudo easy_install pip\nNext install required packages:\nsudo pip install wheel requests future tabulate\nStep 5. Git Clone h2o-3\nOS X should already have Git installed. To download and update h2o-3 source codes:\ngit clone https://github.com/h2oai/h2o-3\nStep 6. Run the top-level gradle build:\ncd h2o-3\n./gradlew build\nNote: on a regular machine it may take very long time (about an hour) to run all the tests.\nIf you encounter errors run again with --stacktrace for more instructions on missing dependencies.\n4.5. Setup on Ubuntu 14.04\nStep 1. Install Node.js\ncurl -sL https://deb.nodesource.com/setup_0.12 | sudo bash -\nsudo apt-get install -y nodejs\nStep 2. Install JDK:\nInstall Java 8. Installation instructions can be found here JDK installation. To make sure the command prompt is detecting the correct Java version, run:\njavac -version\nStep 3. Install R and the required packages:\nInstallation instructions can be found here R installation.  Click \u201cDownload R for Linux\u201d.  Click \u201cubuntu\u201d.  Follow the given instructions.\nTo install the required packages, follow the same instructions as for OS X above.\nNote: If the process fails to install RStudio Server on Linux, run one of the following:\nsudo apt-get install libcurl4-openssl-dev\nor\nsudo apt-get install libcurl4-gnutls-dev\nStep 4. Git Clone h2o-3\nIf you don't already have a Git client:\nsudo apt-get install git\nDownload and update h2o-3 source codes:\ngit clone https://github.com/h2oai/h2o-3\nStep 5. Run the top-level gradle build:\ncd h2o-3\n./gradlew build\nIf you encounter errors, run again using --stacktrace for more instructions on missing dependencies.\nMake sure that you are not running as root, since bower will reject such a run.\n4.6. Setup on Ubuntu 13.10\nStep 1. Install Node.js\ncurl -sL https://deb.nodesource.com/setup_16.x | sudo bash -\nsudo apt-get install -y nodejs\nSteps 2-4. Follow steps 2-4 for Ubuntu 14.04 (above)\n4.7. Setup on CentOS 7\ncd /opt\nsudo wget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/7u79-b15/jdk-7u79-linux-x64.tar.gz\"\nsudo tar xzf jdk-7u79-linux-x64.tar.gz\ncd jdk1.7.0_79\nsudo alternatives --install /usr/bin/java java /opt/jdk1.7.0_79/bin/java 2\nsudo alternatives --install /usr/bin/jar jar /opt/jdk1.7.0_79/bin/jar 2\nsudo alternatives --install /usr/bin/javac javac /opt/jdk1.7.0_79/bin/javac 2\nsudo alternatives --set jar /opt/jdk1.7.0_79/bin/jar\nsudo alternatives --set javac /opt/jdk1.7.0_79/bin/javac\ncd /opt\nsudo wget http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm\nsudo rpm -ivh epel-release-7-5.noarch.rpm\nsudo echo \"multilib_policy=best\" >> /etc/yum.conf\nsudo yum -y update\nsudo yum -y install R R-devel git python-pip openssl-devel libxml2-devel libcurl-devel gcc gcc-c++ make openssl-devel kernel-devel texlive texinfo texlive-latex-fonts libX11-devel mesa-libGL-devel mesa-libGL nodejs npm python-devel numpy scipy python-pandas\nsudo pip install scikit-learn grip tabulate statsmodels wheel\nmkdir ~/Rlibrary\nexport JAVA_HOME=/opt/jdk1.7.0_79\nexport JRE_HOME=/opt/jdk1.7.0_79/jre\nexport PATH=$PATH:/opt/jdk1.7.0_79/bin:/opt/jdk1.7.0_79/jre/bin\nexport R_LIBS_USER=~/Rlibrary\ninstall local R packages\nR -e 'install.packages(c(\"RCurl\",\"jsonlite\",\"statmod\",\"devtools\",\"roxygen2\",\"testthat\"), dependencies=TRUE, repos=\"http://cran.rstudio.com/\")'\ncd\ngit clone https://github.com/h2oai/h2o-3.git\ncd h2o-3\nBuild H2O\n./gradlew syncSmalldata\n./gradlew syncRPackages\n./gradlew build -x test\n\nLaunching H2O after Building\nTo start the H2O cluster locally, execute the following on the command line:\njava -jar build/h2o.jar\n\nA list of available start-up JVM and H2O options (e.g. -Xmx, -nthreads, -ip), is available in the H2O User Guide.\n\nBuilding H2O on Hadoop\nPre-built H2O-on-Hadoop zip files are available on the download page.  Each Hadoop distribution version has a separate zip file in h2o-3.\nTo build H2O with Hadoop support yourself, first install sphinx for python: pip install sphinx\nThen start the build by entering  the following from the top-level h2o-3 directory:\nexport BUILD_HADOOP=1;\n./gradlew build -x test;\n./gradlew dist;\n\nThis will create a directory called 'target' and generate zip files there.  Note that BUILD_HADOOP is the default behavior when the username is jenkins (refer to settings.gradle); otherwise you have to request it, as shown above.\nTo build the zip files only for selected distributions use the H2O_TARGET env variable together with BUILD_HADOOP, for example:\nexport BUILD_HADOOP=1;\nexport H2O_TARGET=hdp2.5,hdp2.6\n./gradlew build -x test;\n./gradlew dist;\nAdding support for a new version of Hadoop\nIn the h2o-hadoop directory, each Hadoop version has a build directory for the driver and an assembly directory for the fatjar.\nYou need to:\nAdd a new driver directory and assembly directory (each with a build.gradle file) in h2o-hadoop\nAdd these new projects to h2o-3/settings.gradle\nAdd the new Hadoop version to HADOOP_VERSIONS in make-dist.sh\nAdd the new Hadoop version to the list in h2o-dist/buildinfo.json\nSecure user impersonation\nHadoop supports secure user impersonation through its Java API.  A kerberos-authenticated user can be allowed to proxy any username that meets specified criteria entered in the NameNode's core-site.xml file.  This impersonation only applies to interactions with the Hadoop API or the APIs of Hadoop-related services that support it (this is not the same as switching to that user on the machine of origin).\nSetting up secure user impersonation (for h2o):\nCreate or find an id to use as proxy which has limited-to-no access to HDFS or related services; the proxy user need only be used to impersonate a user\n(Required if not using h2odriver) If you are not using the driver (e.g. you wrote your own code against h2o's API using Hadoop), make the necessary code changes to impersonate users (see org.apache.hadoop.security.UserGroupInformation)\nIn either of Ambari/Cloudera Manager or directly on the NameNode's core-site.xml file, add 2/3 properties for the user we wish to use as a proxy (replace  with the simple user name - not the fully-qualified principal name).\nhadoop.proxyuser..hosts: the hosts the proxy user is allowed to perform impersonated actions on behalf of a valid user from\nhadoop.proxyuser..groups: the groups an impersonated user must belong to for impersonation to work with that proxy user\nhadoop.proxyuser..users: the users a proxy user is allowed to impersonate\nExample: \nhadoop.proxyuser.myproxyuser.hosts\nhost1,host2\n\n\nhadoop.proxyuser.myproxyuser.groups\ngroup1,group2\n\n\nhadoop.proxyuser.myproxyuser.users\nuser1,user2\n\nRestart core services such as HDFS & YARN for the changes to take effect\nImpersonated HDFS actions can be viewed in the hdfs audit log ('auth:PROXY' should appear in the ugi= field in entries where this is applicable).  YARN similarly should show 'auth:PROXY' somewhere in the Resource Manager UI.\nTo use secure impersonation with h2o's Hadoop driver:\nBefore this is attempted, see Risks with impersonation, below\nWhen using the h2odriver (e.g. when running with hadoop jar ...), specify -principal , -keytab , and -run_as_user , in addition to any other arguments needed.  If the configuration was successful, the proxy user will log in and impersonate the -run_as_user as long as that user is allowed by either the users or groups configuration property (configured above); this is enforced by HDFS & YARN, not h2o's code.  The driver effectively sets its security context as the impersonated user so all supported Hadoop actions will be performed as that user (e.g. YARN, HDFS APIs support securely impersonated users, but others may not).\nPrecautions to take when leveraging secure impersonation\nThe target use case for secure impersonation is applications or services that pre-authenticate a user and then use (in this case) the h2odriver on behalf of that user.  H2O's Steam is a perfect example: auth user in web app over SSL, impersonate that user when creating the h2o YARN container.\nThe proxy user should have limited permissions in the Hadoop cluster; this means no permissions to access data or make API calls.  In this way, if it's compromised it would only have the power to impersonate a specific subset of the users in the cluster and only from specific machines.\nUse the hadoop.proxyuser..hosts property whenever possible or practical.\nDon't give the proxyusername's password or keytab to any user you don't want to impersonate another user (this is generally any user).  The point of impersonation is not to allow users to impersonate each other.  See the first bullet for the typical use case.\nLimit user logon to the machine the proxying is occurring from whenever practical.\nMake sure the keytab used to login the proxy user is properly secured and that users can't login as that id (via su, for instance)\nNever set hadoop.proxyuser..{users,groups} to '' or 'hdfs', 'yarn', etc.  Allowing any user to impersonate hdfs, yarn, or any other important user/group should be done with extreme caution and strongly* analyzed before it's allowed.\nRisks with secure impersonation\nThe id performing the impersonation can be compromised like any other user id.\nSetting any hadoop.proxyuser..{hosts,groups,users} property to '*' can greatly increase exposure to security risk.\nWhen users aren't authenticated before being used with the driver (e.g. like Steam does via a secure web app/API), auditability of the process/system is difficult.\n$ git diff\ndiff --git a/h2o-app/build.gradle b/h2o-app/build.gradle\nindex af3b929..097af85 100644\n--- a/h2o-app/build.gradle\n+++ b/h2o-app/build.gradle\n@@ -8,5 +8,6 @@ dependencies {\n   compile project(\":h2o-algos\")\n   compile project(\":h2o-core\")\n   compile project(\":h2o-genmodel\")\n+  compile project(\":h2o-persist-hdfs\")\n }\ndiff --git a/h2o-persist-hdfs/build.gradle b/h2o-persist-hdfs/build.gradle\nindex 41b96b2..6368ea9 100644\n--- a/h2o-persist-hdfs/build.gradle\n+++ b/h2o-persist-hdfs/build.gradle\n@@ -2,5 +2,6 @@ description = \"H2O Persist HDFS\"\ndependencies {\n   compile project(\":h2o-core\")\n-  compile(\"org.apache.hadoop:hadoop-client:2.0.0-cdh4.3.0\")\n+  compile(\"org.apache.hadoop:hadoop-client:2.4.1-mapr-1408\")\n+  compile(\"org.json:org.json:chargebee-1.0\")\n }\n\nSparkling Water\nSparkling Water combines two open-source technologies: Apache Spark and the H2O Machine Learning platform.  It makes H2O\u2019s library of advanced algorithms, including Deep Learning, GLM, GBM, K-Means, and Distributed Random Forest, accessible from Spark workflows. Spark users can select the best features from either platform to meet their Machine Learning needs.  Users can combine Spark's RDD API and Spark MLLib with H2O\u2019s machine learning algorithms, or use H2O independently of Spark for the model building process and post-process the results in Spark.\nSparkling Water Resources:\n\nDownload page for pre-built packages\nSparkling Water GitHub repository \nREADME\nDeveloper documentation\n\nDocumentation\nDocumenation Homepage\nThe main H2O documentation is the H2O User Guide.  Visit http://docs.h2o.ai for the top-level introduction to documentation on H2O projects.\nGenerate REST API documentation\nTo generate the REST API documentation, use the following commands:\ncd ~/h2o-3\ncd py\npython ./generate_rest_api_docs.py  # to generate Markdown only\npython ./generate_rest_api_docs.py --generate_html  --github_user GITHUB_USER --github_password GITHUB_PASSWORD # to generate Markdown and HTML\n\nThe default location for the generated documentation is build/docs/REST.\nIf the build fails, try gradlew clean, then git clean -f.\nBleeding edge build documentation\nDocumentation for each bleeding edge nightly build is available on the nightly build page.\n\nCiting H2O\nIf you use H2O as part of your workflow in a publication, please cite your H2O resource(s) using the following BibTex entry:\nH2O Software\n@Manual{h2o_package_or_module,\n    title = {package_or_module_title},\n    author = {H2O.ai},\n    year = {year},\n    month = {month},\n    note = {version_information},\n    url = {resource_url},\n}\n\nFormatted H2O Software citation examples:\nH2O.ai (Oct. 2016). Python Interface for H2O, Python module version 3.10.0.8. https://github.com/h2oai/h2o-3.\nH2O.ai (Oct. 2016). R Interface for H2O, R package version 3.10.0.8. https://github.com/h2oai/h2o-3.\nH2O.ai (Oct. 2016). H2O, H2O version 3.10.0.8. https://github.com/h2oai/h2o-3.\nH2O Booklets\nH2O algorithm booklets are available at the Documentation Homepage.\n@Manual{h2o_booklet_name,\n    title = {booklet_title},\n    author = {list_of_authors},\n    year = {year},\n    month = {month},\n    url = {link_url},\n}\nFormatted booklet citation examples:\nArora, A., Candel, A., Lanford, J., LeDell, E., and Parmar, V. (Oct. 2016). Deep Learning with H2O. http://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/DeepLearningBooklet.pdf.\nClick, C., Lanford, J., Malohlava, M., Parmar, V., and Roark, H. (Oct. 2016). Gradient Boosted Models with H2O. http://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/GBMBooklet.pdf.\n\nRoadmap\nH2O 3.36.0.1 - Winter 2021\n\n[PUBDEV-4940] Uplift Trees\n[PUBDEV-8074] Admissible ML - Infogram\nRuleFit improvements (multinomial support, rule deduplication and consolidation)\nBackward elimination in MAXR\nImproved support for CDP (S3A with IDBroker)\nSupport for Java 16 and 17, Python 3.8\nH2O 3.38.0.1 - Spring 2022\n[PUBDEV-8074] Admissible ML - stage 2 (algos)\nMulti-Output Regression in Deep Learning\nGAM Improvements (support for Monotonic Splines)\nXGBoost Upgrade\nData Ingest Improvements (Secured Hive in Standalone/K8S)\nExtended Isolation Forest MOJO\nUplift MOJO\nNew features ICE plots\n\nCommunity\nH2O has been built by a great many number of contributors over the years both within H2O.ai (the company) and the greater open source community.  You can begin to contribute to H2O by answering Stack Overflow questions or filing bug reports.  Please join us!\nTeam & Committers\nSriSatish Ambati\nCliff Click\nTom Kraljevic\nTomas Nykodym\nMichal Malohlava\nKevin Normoyle\nSpencer Aiello\nAnqi Fu\nNidhi Mehta\nArno Candel\nJosephine Wang\nAmy Wang\nMax Schloemer\nRay Peck\nPrithvi Prabhu\nBrandon Hill\nJeff Gambera\nAriel Rao\nViraj Parmar\nKendall Harris\nAnand Avati\nJessica Lanford\nAlex Tellez\nAllison Washburn\nAmy Wang\nErik Eckstrand\nNeeraja Madabhushi\nSebastian Vidrio\nBen Sabrin\nMatt Dowle\nMark Landry\nErin LeDell\nAndrey Spiridonov\nOleg Rogynskyy\nNick Martin\nNancy Jordan\nNishant Kalonia\nNadine Hussami\nJeff Cramer\nStacie Spreitzer\nVinod Iyengar\nCharlene Windom\nParag Sanghavi\nNavdeep Gill\nLauren DiPerna\nAnmol Bal\nMark Chan\nNick Karpov\nAvni Wadhwa\nAshrith Barthur\nKaren Hayrapetyan\nJo-fai Chow\nDmitry Larko\nBranden Murray\nJakub Hava\nWen Phan\nMagnus Stensmo\nPasha Stetsenko\nAngela Bartz\nMateusz Dymczyk\nMicah Stubbs\nIvy Wang\nTerone Ward\nLeland Wilkinson\nWendy Wong\nNikhil Shekhar\nPavel Pscheidl\nMichal Kurka\nVeronika Maurerova\nJan Sterba\nJan Jendrusak\nSebastien Poirier\nTom\u00e1\u0161 Fr\u00fdda\nArd Kelmendi\n\nAdvisors\nScientific Advisory Council\nStephen Boyd\nRob Tibshirani\nTrevor Hastie\nSystems, Data, FileSystems and Hadoop\nDoug Lea\nChris Pouliot\nDhruba Borthakur\nInvestors\nJishnu Bhattacharjee, Nexus Venture Partners\nAnand Babu Periasamy\nAnand Rajaraman\nAsh Bhardwaj\nRakesh Mathur\nMichael Marks\nEgbert Bierman\nRajesh Ambati",
	"batch beam big-data golang java python sql streaming": "Apache Beam\nApache Beam is a unified model for defining both batch and streaming data-parallel processing pipelines, as well as a set of language-specific SDKs for constructing pipelines and Runners for executing them on distributed processing backends, including Apache Flink, Apache Spark, Google Cloud Dataflow, and Hazelcast Jet.\nStatus\nOverview\nBeam provides a general approach to expressing embarrassingly parallel data processing pipelines and supports three categories of users, each of which have relatively disparate backgrounds and needs.\nEnd Users: Writing pipelines with an existing SDK, running it on an existing runner. These users want to focus on writing their application logic and have everything else just work.\nSDK Writers: Developing a Beam SDK targeted at a specific user community (Java, Python, Scala, Go, R, graphical, etc). These users are language geeks and would prefer to be shielded from all the details of various runners and their implementations.\nRunner Writers: Have an execution environment for distributed processing and would like to support programs written against the Beam Model. Would prefer to be shielded from details of multiple SDKs.\nThe Beam Model\nThe model behind Beam evolved from several internal Google data processing projects, including MapReduce, FlumeJava, and Millwheel. This model was originally known as the \u201cDataflow Model\u201d.\nTo learn more about the Beam Model (though still under the original name of Dataflow), see the World Beyond Batch: Streaming 101 and Streaming 102 posts on O\u2019Reilly\u2019s Radar site, and the VLDB 2015 paper.\nThe key concepts in the Beam programming model are:\nPCollection: represents a collection of data, which could be bounded or unbounded in size.\nPTransform: represents a computation that transforms input PCollections into output PCollections.\nPipeline: manages a directed acyclic graph of PTransforms and PCollections that is ready for execution.\nPipelineRunner: specifies where and how the pipeline should execute.\nSDKs\nBeam supports multiple language-specific SDKs for writing pipelines against the Beam Model.\nCurrently, this repository contains SDKs for Java, Python and Go.\nHave ideas for new SDKs or DSLs? See the sdk-ideas label.\nRunners\nBeam supports executing programs on multiple distributed processing backends through PipelineRunners. Currently, the following PipelineRunners are available:\nThe DirectRunner runs the pipeline on your local machine.\nThe DataflowRunner submits the pipeline to the Google Cloud Dataflow.\nThe FlinkRunner runs the pipeline on an Apache Flink cluster. The code has been donated from dataArtisans/flink-dataflow and is now part of Beam.\nThe SparkRunner runs the pipeline on an Apache Spark cluster. The code has been donated from cloudera/spark-dataflow and is now part of Beam.\nThe JetRunner runs the pipeline on a Hazelcast Jet cluster. The code has been donated from hazelcast/hazelcast-jet and is now part of Beam.\nThe Twister2Runner runs the pipeline on a Twister2 cluster. The code has been donated from DSC-SPIDAL/twister2 and is now part of Beam.\nHave ideas for new Runners? See the runner-ideas label.\nGetting Started\nTo learn how to write Beam pipelines, read the Quickstart for [Java, Python, or\nGo] available on our website.\nContact Us\nTo get involved in Apache Beam:\nSubscribe or mail the user@beam.apache.org list.\nSubscribe or mail the dev@beam.apache.org list.\nJoin ASF Slack on #beam channel\nReport an issue.\nInstructions for building and testing Beam itself\nare in the contribution guide.\nMore Information\nApache Beam\nOverview\nQuickstart: Java, Python, Go\nCommunity metrics",
	"analytics bi business-intelligence businessintelligence clojure dashboard data data-analysis data-visualization database metabase mysql postgres postgresql reporting slack sql-editor visualization": "Metabase\nMetabase is the easy, open-source way for everyone in your company to ask questions and learn from data.\nFeatures\nSet up in five minutes (we're not kidding).\nLet anyone on your team ask questions without knowing SQL.\nUse the SQL editor for more complex queries.\nBuild handsome, interactive dashboards with filters, auto-refresh, fullscreen, and custom click behavior.\nCreate models that clean up, annotate, and/or combine raw tables.\nDefine canonical segments and metrics for your team to use.\nSend data to Slack or email on a schedule with dashboard subscriptions.\nSet up alerts to have Metabase notify you when your data changes.\nEmbed charts and dashboards in your app, or even your entire Metabase.\nTake a tour of Metabase.\nSupported databases\nOfficially supported databases\nPartner and Community drivers\nInstallation\nMetabase can be run just about anywhere. Check out our Installation Guides.\nContributing\nTo get started with a development installation of the Metabase, check out our Developers Guide.\nInternationalization\nWe want Metabase to be available in as many languages as possible. See which translations are available and help contribute to internationalization using our project over at POEditor. You can also check out our policies on translations.\nExtending Metabase\nHit our Query API from Javascript to integrate analytics. Metabase enables your application to:\nBuild moderation interfaces.\nExport subsets of your users to third party marketing automation software.\nProvide a custom customer lookup application for the people in your company.\nCheck out our guide, Working with the Metabase API.\nSecurity Disclosure\nSee SECURITY.md for details.\nLicense\nThis repository contains the source code for both the Open Source edition of Metabase, released under the AGPL, as well as the commercial editions of Metabase, which are released under the Metabase Commercial Software License.\nSee LICENSE.txt for details.\nUnless otherwise noted, all files \u00a9 2022 Metabase, Inc.\nMetabase Experts\nIf you\u2019d like more technical resources to set up your data stack with Metabase, connect with a Metabase Expert.",
	"compression data-analysis data-manipulation encoding encryption hashing parsing": "CyberChef\nThe Cyber Swiss Army Knife\nCyberChef is a simple, intuitive web app for carrying out all manner of \"cyber\" operations within a web browser. These operations include simple encoding like XOR and Base64, more complex encryption like AES, DES and Blowfish, creating binary and hexdumps, compression and decompression of data, calculating hashes and checksums, IPv6 and X.509 parsing, changing character encodings, and much more.\nThe tool is designed to enable both technical and non-technical analysts to manipulate data in complex ways without having to deal with complex tools or algorithms. It was conceived, designed, built and incrementally improved by an analyst in their 10% innovation time over several years.\nLive demo\nCyberChef is still under active development. As a result, it shouldn't be considered a finished product. There is still testing and bug fixing to do, new features to be added and additional documentation to write. Please contribute!\nCryptographic operations in CyberChef should not be relied upon to provide security in any situation. No guarantee is offered for their correctness.\nA live demo can be found here - have fun!\nHow it works\nThere are four main areas in CyberChef:\nThe input box in the top right, where you can paste, type or drag the text or file you want to operate on.\nThe output box in the bottom right, where the outcome of your processing will be displayed.\nThe operations list on the far left, where you can find all the operations that CyberChef is capable of in categorised lists, or by searching.\nThe recipe area in the middle, where you can drag the operations that you want to use and specify arguments and options.\nYou can use as many operations as you like in simple or complex ways. Some examples are as follows:\nDecode a Base64-encoded string\nConvert a date and time to a different time zone\nParse a Teredo IPv6 address\nConvert data from a hexdump, then decompress\nDecrypt and disassemble shellcode\nDisplay multiple timestamps as full dates\nCarry out different operations on data of different types\nUse parts of the input as arguments to operations\nPerform AES decryption, extracting the IV from the beginning of the cipher stream\nAutomagically detect several layers of nested encoding\nFeatures\nDrag and drop\nOperations can be dragged in and out of the recipe list, or reorganised.\nFiles up to 2GB can be dragged over the input box to load them directly into the browser.\nAuto Bake\nWhenever you modify the input or the recipe, CyberChef will automatically \"bake\" for you and produce the output immediately.\nThis can be turned off and operated manually if it is affecting performance (if the input is very large, for instance).\nAutomated encoding detection\nCyberChef uses a number of techniques to attempt to automatically detect which encodings your data is under. If it finds a suitable operation that make sense of your data, it displays the 'magic' icon in the Output field which you can click to decode your data.\nBreakpoints\nYou can set breakpoints on any operation in your recipe to pause execution before running it.\nYou can also step through the recipe one operation at a time to see what the data looks like at each stage.\nSave and load recipes\nIf you come up with an awesome recipe that you know you\u2019ll want to use again, just click \"Save recipe\" and add it to your local storage. It'll be waiting for you next time you visit CyberChef.\nYou can also copy the URL, which includes your recipe and input, to easily share it with others.\nSearch\nIf you know the name of the operation you want or a word associated with it, start typing it into the search field and any matching operations will immediately be shown.\nHighlighting\nWhen you highlight text in the input or output, the offset and length values will be displayed and, if possible, the corresponding data will be highlighted in the output or input respectively (example: highlight the word 'question' in the input to see where it appears in the output).\nSave to file and load from file\nYou can save the output to a file at any time or load a file by dragging and dropping it into the input field. Files up to around 2GB are supported (depending on your browser), however, some operations may take a very long time to run over this much data.\nCyberChef is entirely client-side\nIt should be noted that none of your recipe configuration or input (either text or files) is ever sent to the CyberChef web server - all processing is carried out within your browser, on your own computer.\nDue to this feature, CyberChef can be downloaded and run locally. You can use the link in the top left corner of the app to download a full copy of CyberChef and drop it into a virtual machine, share it with other people, or host it in a closed network.\nDeep linking\nBy manipulating CyberChef's URL hash, you can change the initial settings with which the page opens.\nThe format is https://gchq.github.io/CyberChef/#recipe=Operation()&input=...\nSupported arguments are recipe, input (encoded in Base64), and theme.\nBrowser support\nCyberChef is built to support\nGoogle Chrome 50+\nMozilla Firefox 38+\nNode.js support\nCyberChef is built to fully support Node.js v16. For more information, see the Node API page in the project wiki pages\nContributing\nContributing a new operation to CyberChef is super easy! The quickstart script will walk you through the process. If you can write basic JavaScript, you can write a CyberChef operation.\nAn installation walkthrough, how-to guides for adding new operations and themes, descriptions of the repository structure, available data types and coding conventions can all be found in the project wiki pages.\nPush your changes to your fork.\nSubmit a pull request. If you are doing this for the first time, you will be prompted to sign the GCHQ Contributor Licence Agreement via the CLA assistant on the pull request. This will also ask whether you are happy for GCHQ to contact you about a token of thanks for your contribution, or about job opportunities at GCHQ.\nLicencing\nCyberChef is released under the Apache 2.0 Licence and is covered by Crown Copyright.",
	"analytics apache c cli command-line dashboard data-analysis gdpr goaccess google-analytics monitoring ncurses nginx privacy real-time terminal tui web-analytics webserver": "GoAccess\nWhat is it?\nGoAccess is an open source real-time web log analyzer and interactive\nviewer that runs in a terminal on *nix systems or through your\nbrowser. It provides fast and valuable HTTP statistics for system\nadministrators that require a visual server report on the fly.\nMore info at: https://goaccess.io.\nFeatures\nGoAccess parses the specified web log file and outputs the data to the X\nterminal. Features include:\nCompletely Real Time\n  All panels and metrics are timed to be updated every 200 ms on the terminal\n  output and every second on the HTML output.\nMinimal Configuration needed\n  You can just run it against your access log file, pick the log format and let\n  GoAccess parse the access log and show you the stats.\nTrack Application Response Time\n  Track the time taken to serve the request. Extremely useful if you want to\n  track pages that are slowing down your site.\nNearly All Web Log Formats\n  GoAccess allows any custom log format string.  Predefined options include,\n  Apache, Nginx, Amazon S3, Elastic Load Balancing, CloudFront, etc.\nIncremental Log Processing\n  Need data persistence? GoAccess has the ability to process logs incrementally\n  through the on-disk persistence options.\nOnly one dependency\n  GoAccess is written in C. To run it, you only need ncurses as a dependency.\n  That's it. It even features its own Web Socket server \u2014 http://gwsocket.io/.\nVisitors\n  Determine the amount of hits, visitors, bandwidth, and metrics for slowest\n  running requests by the hour, or date.\nMetrics per Virtual Host\n  Have multiple Virtual Hosts (Server Blocks)? It features a panel that\n  displays which virtual host is consuming most of the web server resources.\nColor Scheme Customizable\n  Tailor GoAccess to suit your own color taste/schemes. Either through the\n  terminal, or by simply applying the stylesheet on the HTML output.\nSupport for Large Datasets\n  GoAccess features the ability to parse large logs due to its optimized\n  in-memory hash tables. It has very good memory usage and pretty good\n  performance. This storage has support for on-disk persistence as well.\nDocker Support\n  Ability to build GoAccess' Docker image from upstream. You can still fully\n  configure it, by using Volume mapping and editing goaccess.conf.  See\n  Docker section below.\nNearly all web log formats...\nGoAccess allows any custom log format string. Predefined options include, but\nnot limited to:\nAmazon CloudFront (Download Distribution).\nAmazon Simple Storage Service (S3)\nAWS Elastic Load Balancing\nCombined Log Format (XLF/ELF) Apache | Nginx\nCommon Log Format (CLF) Apache\nGoogle Cloud Storage.\nApache virtual hosts\nSquid Native Format.\nW3C format (IIS).\nCaddy's JSON Structured format.\nWhy GoAccess?\nGoAccess was designed to be a fast, terminal-based log analyzer. Its core idea\nis to quickly analyze and view web server statistics in real time without\nneeding to use your browser (great if you want to do a quick analysis of your\naccess log via SSH, or if you simply love working in the terminal).\nWhile the terminal output is the default output, it has the capability to\ngenerate a complete, self-contained, real-time HTML\nreport, as well as a JSON, and\nCSV report.\nYou can see it more of a monitor command tool than anything else.\nInstallation\nBuild from release\nGoAccess can be compiled and used on *nix systems.\nDownload, extract and compile GoAccess with:\n$ wget https://tar.goaccess.io/goaccess-1.6.5.tar.gz\n$ tar -xzvf goaccess-1.6.5.tar.gz\n$ cd goaccess-1.6.5/\n$ ./configure --enable-utf8 --enable-geoip=mmdb\n$ make\nmake install\nBuild from GitHub (Development)\n$ git clone https://github.com/allinurl/goaccess.git\n$ cd goaccess\n$ autoreconf -fiv\n$ ./configure --enable-utf8 --enable-geoip=mmdb\n$ make\nmake install\nBuild in isolated container\nYou can also build the binary for Debian based systems in an isolated container environment to prevent cluttering your local system with the development libraries:\n$ curl -L \"https://github.com/allinurl/goaccess/archive/refs/heads/master.tar.gz\" | tar -xz && cd goaccess-master\n$ docker build -t goaccess/build.debian-10 -f Dockerfile.debian-10 .\n$ docker run -i --rm -v $PWD:/goaccess goaccess/build.debian-10 > goaccess\nDistributions\nIt is easiest to install GoAccess on GNU+Linux using the preferred package manager\nof your GNU+Linux distribution. Please note that not all distributions will have\nthe latest version of GoAccess available.\nDebian/Ubuntu\napt-get install goaccess\nNote: It is likely this will install an outdated version of GoAccess. To\nmake sure that you're running the latest stable version of GoAccess see\nalternative option below.\nOfficial GoAccess Debian & Ubuntu repository\n$ wget -O - https://deb.goaccess.io/gnugpg.key | gpg --dearmor \\\n    | sudo tee /usr/share/keyrings/goaccess.gpg >/dev/null\n$ echo \"deb [signed-by=/usr/share/keyrings/goaccess.gpg arch=$(dpkg --print-architecture)] https://deb.goaccess.io/ $(lsb_release -cs) main\" \\\n    | sudo tee /etc/apt/sources.list.d/goaccess.list\n$ sudo apt-get update\n$ sudo apt-get install goaccess\nNote:\n* .deb packages in the official repo are available through HTTPS as well. You may need to install apt-transport-https.\nFedora\nyum install goaccess\nArch\npacman -S goaccess\nGentoo\nemerge net-analyzer/goaccess\nOS X / Homebrew\nbrew install goaccess\nFreeBSD\ncd /usr/ports/sysutils/goaccess/ && make install clean\npkg install sysutils/goaccess\nOpenBSD\ncd /usr/ports/www/goaccess && make install clean\npkg_add goaccess\nopenSUSE\nzypper ar -f obs://server:http http\nzypper in goaccess\nOpenIndiana\npkg install goaccess\npkgsrc (NetBSD, Solaris, SmartOS, ...)\npkgin install goaccess\nWindows\nGoAccess can be used in Windows through Cygwin. See Cygwin's packages.  Or through the\nGNU+Linux Subsystem on Windows 10.\nDistribution Packages\nGoAccess has minimal requirements, it's written in C and requires only ncurses.\nHowever, below is a table of some optional dependencies in some distros to\nbuild GoAccess from source.\nDistro                 | NCurses          | GeoIP (opt)      |GeoIP2 (opt)           |  OpenSSL (opt)\n---------------------- | -----------------|------------------|---------------------- | -------------------\nUbuntu/Debian      | libncursesw6-dev | libgeoip-dev     | libmaxminddb-dev      |  libssl-dev\nRHEL/CentOS        | ncurses-devel    | geoip-devel      | libmaxminddb-devel    |  openssl-devel\nArch               | ncurses          | geoip            | libmaxminddb          |  openssl\nGentoo             | sys-libs/ncurses | dev-libs/geoip   | dev-libs/libmaxminddb |  dev-libs/openssl\nSlackware          | ncurses          | GeoIP            | libmaxminddb          |  openssl\nNote: You may need to install build tools like gcc, autoconf,\ngettext, autopoint etc for compiling/building software from source. e.g.,\nbase-devel, build-essential, \"Development Tools\".\nDocker\nA Docker image has been updated, capable of directing output from an access log. If you only want to output a report, you can pipe a log from the external environment to a Docker-based process:\ncat access.log | docker run --rm -i -e LANG=$LANG allinurl/goaccess -a -o html --log-format COMBINED - > report.html\nOR real-time\ntail -F access.log | docker run -p 7890:7890 --rm -i -e LANG=$LANG allinurl/goaccess -a -o html --log-format COMBINED --real-time-html - > report.html\nYou can read more about using the docker image in DOCKER.md.\nStorage\nDefault Hash Tables\nIn-memory storage provides better performance at the cost of limiting the\ndataset size to the amount of available physical memory. GoAccess uses\nin-memory hash tables.  It has very good memory usage and pretty good\nperformance. This storage has support for on-disk persistence as well.\nCommand Line / Config Options\nSee options that can be supplied to the command or\nspecified in the configuration file. If specified in the configuration file, long\noptions need to be used without prepending --.\nUsage / Examples\nNote: Piping data into GoAccess won't prompt a log/date/time\nconfiguration dialog, you will need to previously define it in your\nconfiguration file or in the command line.\nGetting Started\nTo output to a terminal and generate an interactive report:\ngoaccess access.log\nTo generate an HTML report:\ngoaccess access.log -a > report.html\nTo generate a JSON report:\ngoaccess access.log -a -d -o json > report.json\nTo generate a CSV file:\ngoaccess access.log --no-csv-summary -o csv > report.csv\nGoAccess also allows great flexibility for real-time filtering and parsing. For\ninstance, to quickly diagnose issues by monitoring logs since goaccess was\nstarted:\ntail -f access.log | goaccess -\nAnd even better, to filter while maintaining opened a pipe to preserve\nreal-time analysis, we can make use of tail -f and a matching pattern tool\nsuch as grep, awk, sed, etc:\ntail -f access.log | grep -i --line-buffered 'firefox' | goaccess --log-format=COMBINED -\nor to parse from the beginning of the file while maintaining the pipe opened\nand applying a filter\ntail -f -n +0 access.log | grep -i --line-buffered 'firefox' | goaccess -o report.html --real-time-html -\nMultiple Log files\nThere are several ways to parse multiple logs with GoAccess. The simplest is to\npass multiple log files to the command line:\ngoaccess access.log access.log.1\nIt's even possible to parse files from a pipe while reading regular files:\ncat access.log.2 | goaccess access.log access.log.1 -\nNote: the single dash is appended to the command line to let GoAccess\nknow that it should read from the pipe.\nNow if we want to add more flexibility to GoAccess, we can use zcat --force\nto read compressed and uncompressed files. For instance, if we would\nlike to process all log files access.log*, we can do:\nzcat --force access.log* | goaccess -\nNote: On Mac OS X, use gunzip -c instead of zcat.\nReal-time HTML outputs\nGoAccess has the ability the output real-time data in the HTML report. You can\neven email the HTML file since it is composed of a single file with no external\nfile dependencies, how neat is that!\nThe process of generating a real-time HTML report is very similar to the\nprocess of creating a static report. Only --real-time-html is needed to make\nit real-time.\ngoaccess access.log -o /usr/share/nginx/html/your_site/report.html --real-time-html\nTo view the report you can navigate to http://your_site/report.html.\nBy default, GoAccess will use the host name of the generated report.\nOptionally, you can specify the URL to which the client's browser will connect\nto. See FAQ for a more detailed example.\ngoaccess access.log -o report.html --real-time-html --ws-url=goaccess.io\nBy default, GoAccess listens on port 7890, to use a different port other than\n7890, you can specify it as (make sure the port is opened):\ngoaccess access.log -o report.html --real-time-html --port=9870\nAnd to bind the WebSocket server to a different address other than 0.0.0.0, you\ncan specify it as:\ngoaccess access.log -o report.html --real-time-html --addr=127.0.0.1\nNote: To output real time data over a TLS/SSL connection, you need to use\n--ssl-cert= and --ssl-key=.\nFiltering\nWorking with dates\nAnother useful pipe would be filtering dates out of the web log\nThe following will get all HTTP requests starting on 05/Dec/2010 until the\nend of the file.\nsed -n '/05\\/Dec\\/2010/,$ p' access.log | goaccess -a -\nor using relative dates such as yesterdays or tomorrows day:\nsed -n '/'$(date '+%d\\/%b\\/%Y' -d '1 week ago')'/,$ p' access.log | goaccess -a -\nIf we want to parse only a certain time-frame from DATE a to DATE b, we can do:\nsed -n '/5\\/Nov\\/2010/,/5\\/Dec\\/2010/ p' access.log | goaccess -a -\nIf we want to preserve only certain amount of data and recycle storage, we can\nkeep only a certain number of days. For instance to keep & show the last 5\ndays:\ngoaccess access.log --keep-last=5\nVirtual hosts\nAssuming your log contains the virtual host field. For instance:\nvhost.io:80 8.8.4.4 - - [02/Mar/2016:08:14:04 -0600] \"GET /shop HTTP/1.1\" 200 615 \"-\" \"Googlebot-Image/1.0\"\nAnd you would like to append the virtual host to the request in order to see\nwhich virtual host the top urls belong to:\nawk '$8=$1$8' access.log | goaccess -a -\nTo do the same, but also use real-time filtering and parsing:\ntail -f  access.log | unbuffer -p awk '$8=$1$8' | goaccess -a -\nTo exclude a list of virtual hosts you can do the following:\ngrep -v \"cat exclude_vhost_list_file\" vhost_access.log | goaccess -\nFiles, status codes and bots\nTo parse specific pages, e.g., page views, html, htm, php, etc. within a\nrequest:\nawk '$7~/.html|.htm|.php/' access.log | goaccess -\nNote, $7 is the request field for the common and combined log format,\n(without Virtual Host), if your log includes Virtual Host, then you probably\nwant to use $8 instead. It's best to check which field you are shooting for,\ne.g.:\ntail -10 access.log | awk '{print $8}'\nOr to parse a specific status code, e.g., 500 (Internal Server Error):\nawk '$9~/500/' access.log | goaccess -\nOr multiple status codes, e.g., all 3xx and 5xx:\ntail -f -n +0 access.log | awk '$9~/3[0-9]{2}|5[0-9]{2}/' | goaccess -o out.html -\nAnd to get an estimated overview of how many bots (crawlers) are hitting your server:\ntail -F -n +0 access.log | grep -i --line-buffered 'bot' | goaccess -\nTips\nAlso, it is worth pointing out that if we want to run GoAccess at lower\npriority, we can run it as:\nnice -n 19 goaccess -f access.log -a\nand if you don't want to install it on your server, you can still run it from\nyour local machine!\nssh -n root@server 'tail -f /var/log/apache2/access.log' | goaccess -\nNote: SSH requires -n so GoAccess can read from stdin. Also, make sure to\nuse SSH keys for authentication as it won't work if a passphrase is required. \nTroubleshooting\nWe receive many questions and issues that have been answered previously.\nDate/time matching problems? Check that your log format and the system locale in which you run GoAccess match. See #1571\nProblems with pattern matching? Spaces are often a problem, see for instance #136, #1579\nOther issues matching log entries: See >200 closed issues regarding log/date/time formats\nProblems with log processing? See >111 issues regarding log processing\nIncremental log processing\nGoAccess has the ability to process logs incrementally through its internal\nstorage and dump its data to disk. It works in the following way:\nA dataset must be persisted first with --persist, then the same dataset\ncan be loaded with.\n--restore.  If new data is passed (piped or through a log file), it will\nappend it to the original dataset.\nNOTES\nGoAccess keeps track of inodes of all the files processed (assuming files will\nstay on the same partition), in addition, it extracts a snippet of data from\nthe log along with the last line parsed of each file and the timestamp of the\nlast line parsed. e.g., inode:29627417|line:20012|ts:20171231235059\nFirst, it compares if the snippet matches the log being parsed, if it does, it\nassumes the log hasn't changed drastically, e.g., hasn't been truncated. If\nthe inode does not match the current file, it parses all lines. If the current\nfile matches the inode, it then reads the remaining lines and updates the count\nof lines parsed and the timestamp. As an extra precaution, it won't parse log\nlines with a timestamp \u2264 than the one stored.\nPiped  data works based off the timestamp of the last line read. For instance,\nit will parse and discard all incoming entries until it finds a timestamp >=\nthan the one stored.\nExamples\n// last month access log\ngoaccess access.log.1 --persist\nthen, load it with\n// append this month access log, and preserve new data\ngoaccess access.log --restore --persist\nTo read persisted data only (without parsing new data)\ngoaccess --restore\nContributing\nAny help on GoAccess is welcome. The most helpful way is to try it out and give\nfeedback. Feel free to use the Github issue tracker and pull requests to\ndiscuss and submit code changes.\nEnjoy!",
	"automl awesome best-of data-analysis data-science data-visualization data-visualizations deep-learning jax keras machine-learning ml nlp python python-library pytorch scikit-learn tensorflow transformer": "Best-of Machine Learning with Python\n\n\ud83c\udfc6\u00a0 A ranked list of awesome machine learning Python libraries. Updated weekly.\nThis curated list contains 910 awesome open-source projects with a total of 3.5M stars grouped into 34 categories. All projects are ranked by a project-quality score, which is calculated based on various metrics automatically collected from GitHub and different package managers. If you like to add or update projects, feel free to open an issue, submit a pull request, or directly edit the projects.yaml. Contributions are very welcome!\n \ud83e\uddd9\u200d\u2642\ufe0f\u00a0 Discover other best-of lists or create your own.\n\ud83d\udceb\u00a0 Subscribe to our newsletter for updates and trending projects.\n\nContents\nMachine Learning Frameworks 58 projects\nData Visualization 54 projects\nText Data & NLP 100 projects\nImage Data 64 projects\nGraph Data 36 projects\nAudio Data 29 projects\nGeospatial Data 22 projects\nFinancial Data 25 projects\nTime Series Data 28 projects\nMedical Data 20 projects\nTabular Data 5 projects\nOptical Character Recognition 12 projects\nData Containers & Structures 1 projects\nData Loading & Extraction 1 projects\nWeb Scraping & Crawling 1 projects\nData Pipelines & Streaming 1 projects\nDistributed Machine Learning 36 projects\nHyperparameter Optimization & AutoML 52 projects\nReinforcement Learning 23 projects\nRecommender Systems 17 projects\nPrivacy Machine Learning 7 projects\nWorkflow & Experiment Tracking 39 projects\nModel Serialization & Deployment 20 projects\nModel Interpretability 54 projects\nVector Similarity Search (ANN) 12 projects\nProbabilistics & Statistics 23 projects\nAdversarial Robustness 9 projects\nGPU & Accelerator Utilities 20 projects\nTensorflow Utilities 16 projects\nJax Utilities 3 projects\nSklearn Utilities 19 projects\nPytorch Utilities 32 projects\nDatabase Clients 1 projects\nOthers 65 projects\nExplanation\n\ud83e\udd47\ud83e\udd48\ud83e\udd49\u00a0 Combined project-quality score\n\u2b50\ufe0f\u00a0 Star count from GitHub\n\ud83d\udc23\u00a0 New project (less than 6 months old)\n\ud83d\udca4\u00a0 Inactive project (6 months no activity)\n\ud83d\udc80\u00a0 Dead project (12 months no activity)\n\ud83d\udcc8\ud83d\udcc9\u00a0 Project is trending up or down\n\u2795\u00a0 Project was recently added\n\u2757\ufe0f\u00a0 Warning (e.g. missing/risky license)\n\ud83d\udc68\u200d\ud83d\udcbb\u00a0 Contributors count from GitHub\n\ud83d\udd00\u00a0 Fork count from GitHub\n\ud83d\udccb\u00a0 Issue count from GitHub\n\u23f1\ufe0f\u00a0 Last update timestamp on package manager\n\ud83d\udce5\u00a0 Download count from package manager\n\ud83d\udce6\u00a0 Number of dependent projects\n\u00a0 Tensorflow related project\n\u00a0 Sklearn related project\n\u00a0 PyTorch related project\n\u00a0 MxNet related project\n\u00a0 Apache Spark related project\n\u00a0 Jupyter related project\n\u00a0 PaddlePaddle related project\n\u00a0 Pandas related project\n\u00a0 Jax related project\nMachine Learning Frameworks\nGeneral-purpose machine learning and deep learning frameworks.\nTensorflow (\ud83e\udd4755 \u00b7  \u2b50 170K \u00b7 \ud83d\udcc8) - An Open Source Machine Learning Framework for Everyone. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 4.2K \u00b7 \ud83d\udd00 87K \u00b7 \ud83d\udce6 230K \u00b7 \ud83d\udccb 36K - 6% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/tensorflow/tensorflow\n- PyPi (\ud83d\udce5 15M / month \u00b7 \ud83d\udce6 14K \u00b7 \u23f1\ufe0f 18.11.2022):\npip install tensorflow\n- Conda (\ud83d\udce5 3.8M \u00b7 \u23f1\ufe0f 25.09.2022):\nconda install -c conda-forge tensorflow\n- Docker Hub (\ud83d\udce5 70M \u00b7 \u2b50 2.1K \u00b7 \u23f1\ufe0f 24.11.2022):\ndocker pull tensorflow/tensorflow\n\n\nscikit-learn (\ud83e\udd4752 \u00b7  \u2b50 52K) - scikit-learn: machine learning in Python. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 2.8K \u00b7 \ud83d\udd00 24K \u00b7 \ud83d\udce5 830 \u00b7 \ud83d\udce6 420K \u00b7 \ud83d\udccb 10K - 20% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/scikit-learn/scikit-learn\n- PyPi (\ud83d\udce5 35M / month \u00b7 \ud83d\udce6 26K \u00b7 \u23f1\ufe0f 05.08.2022):\npip install scikit-learn\n- Conda (\ud83d\udce5 17M \u00b7 \u23f1\ufe0f 27.10.2022):\nconda install -c conda-forge scikit-learn\n\n\nPyTorch (\ud83e\udd4750 \u00b7  \u2b50 61K) - Tensors and Dynamic neural networks in Python with strong GPU.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 3.7K \u00b7 \ud83d\udd00 17K \u00b7 \ud83d\udce5 8.2K \u00b7 \ud83d\udccb 30K - 34% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/pytorch/pytorch\n- PyPi (\ud83d\udce5 8.8M / month \u00b7 \ud83d\udce6 7.6K \u00b7 \u23f1\ufe0f 28.06.2022):\npip install torch\n- Conda (\ud83d\udce5 21M \u00b7 \u23f1\ufe0f 26.10.2022):\nconda install -c pytorch pytorch\n\n\nKeras (\ud83e\udd4745 \u00b7  \u2b50 57K) - Deep Learning for humans. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 1.1K \u00b7 \ud83d\udd00 19K \u00b7 \ud83d\udccb 12K - 2% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/keras-team/keras\n- PyPi (\ud83d\udce5 9.8M / month \u00b7 \ud83d\udce6 330 \u00b7 \u23f1\ufe0f 13.05.2022):\npip install keras\n- Conda (\ud83d\udce5 2.7M \u00b7 \u23f1\ufe0f 21.11.2022):\nconda install -c conda-forge keras\n\n\nXGBoost (\ud83e\udd4744 \u00b7  \u2b50 23K) - Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 580 \u00b7 \ud83d\udd00 8.5K \u00b7 \ud83d\udce5 5.5K \u00b7 \ud83d\udce6 39K \u00b7 \ud83d\udccb 4.7K - 7% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/dmlc/xgboost\n- PyPi (\ud83d\udce5 8.6M / month \u00b7 \ud83d\udce6 1.4K \u00b7 \u23f1\ufe0f 09.05.2022):\npip install xgboost\n- Conda (\ud83d\udce5 3.4M \u00b7 \u23f1\ufe0f 07.11.2022):\nconda install -c conda-forge xgboost\n\n\njax (\ud83e\udd4744 \u00b7  \u2b50 21K) - Composable transformations of Python+NumPy programs: differentiate,.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 480 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce6 6.1K \u00b7 \ud83d\udccb 3.9K - 29% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/google/jax\n- PyPi (\ud83d\udce5 630K / month \u00b7 \ud83d\udce6 320 \u00b7 \u23f1\ufe0f 28.06.2022):\npip install jax\n- Conda (\ud83d\udce5 530K \u00b7 \u23f1\ufe0f 16.11.2022):\nconda install -c conda-forge jaxlib\n\n\nStatsModels (\ud83e\udd4744 \u00b7  \u2b50 7.9K) - Statsmodels: statistical modeling and econometrics in Python. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 390 \u00b7 \ud83d\udd00 2.6K \u00b7 \ud83d\udce5 26 \u00b7 \ud83d\udce6 74K \u00b7 \ud83d\udccb 5K - 48% open \u00b7 \u23f1\ufe0f 13.11.2022):\ngit clone https://github.com/statsmodels/statsmodels\n- PyPi (\ud83d\udce5 9.5M / month \u00b7 \ud83d\udce6 4.7K \u00b7 \u23f1\ufe0f 08.02.2022):\npip install statsmodels\n- Conda (\ud83d\udce5 7.9M \u00b7 \u23f1\ufe0f 04.11.2022):\nconda install -c conda-forge statsmodels\n\n\nPySpark (\ud83e\udd4843 \u00b7  \u2b50 34K) - Apache Spark Python API. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 2.8K \u00b7 \ud83d\udd00 26K \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/apache/spark\n- PyPi (\ud83d\udce5 28M / month \u00b7 \ud83d\udce6 850 \u00b7 \u23f1\ufe0f 15.06.2022):\npip install pyspark\n- Conda (\ud83d\udce5 2.2M \u00b7 \u23f1\ufe0f 25.10.2022):\nconda install -c conda-forge pyspark\n\n\nPaddlePaddle (\ud83e\udd4842 \u00b7  \u2b50 19K) - PArallel Distributed Deep LEarning: Machine Learning.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 870 \u00b7 \ud83d\udd00 4.8K \u00b7 \ud83d\udce5 15K \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 17K - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/PaddlePaddle/Paddle\n- PyPi (\ud83d\udce5 93K / month \u00b7 \ud83d\udce6 50 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install paddlepaddle\n\n\nLightGBM (\ud83e\udd4842 \u00b7  \u2b50 14K) - A fast, distributed, high performance gradient boosting (GBT, GBDT, GBRT,.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 270 \u00b7 \ud83d\udd00 3.6K \u00b7 \ud83d\udce5 170K \u00b7 \ud83d\udce6 16K \u00b7 \ud83d\udccb 2.9K - 8% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/microsoft/LightGBM\n- PyPi (\ud83d\udce5 6.9M / month \u00b7 \ud83d\udce6 640 \u00b7 \u23f1\ufe0f 07.01.2022):\npip install lightgbm\n- Conda (\ud83d\udce5 1.3M \u00b7 \u23f1\ufe0f 28.10.2022):\nconda install -c conda-forge lightgbm\n\n\nFastai (\ud83e\udd4840 \u00b7  \u2b50 23K) - The fastai deep learning library. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 650 \u00b7 \ud83d\udd00 7.3K \u00b7 \ud83d\udce6 12K \u00b7 \ud83d\udccb 1.7K - 7% open \u00b7 \u23f1\ufe0f 02.11.2022):\ngit clone https://github.com/fastai/fastai\n- PyPi (\ud83d\udce5 370K / month \u00b7 \ud83d\udce6 300 \u00b7 \u23f1\ufe0f 04.07.2022):\npip install fastai\n\n\npytorch-lightning (\ud83e\udd4840 \u00b7  \u2b50 21K \u00b7 \ud83d\udcc9) - Build and train PyTorch models and connect them to.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 800 \u00b7 \ud83d\udd00 2.7K \u00b7 \ud83d\udce5 9.4K \u00b7 \ud83d\udce6 120 \u00b7 \ud83d\udccb 5.7K - 10% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/Lightning-AI/lightning\n- PyPi (\ud83d\udce5 3M / month \u00b7 \ud83d\udce6 400 \u00b7 \u23f1\ufe0f 01.06.2022):\npip install pytorch-lightning\n- Conda (\ud83d\udce5 610K \u00b7 \u23f1\ufe0f 23.09.2022):\nconda install -c conda-forge pytorch-lightning\n\n\nCatboost (\ud83e\udd4840 \u00b7  \u2b50 6.8K \u00b7 \ud83d\udcc8) - A fast, scalable, high performance Gradient Boosting on.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 1K \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce5 100K \u00b7 \ud83d\udccb 1.9K - 23% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/catboost/catboost\n- PyPi (\ud83d\udce5 2.4M / month \u00b7 \ud83d\udce6 240 \u00b7 \u23f1\ufe0f 19.05.2022):\npip install catboost\n- Conda (\ud83d\udce5 1.2M \u00b7 \u23f1\ufe0f 01.11.2022):\nconda install -c conda-forge catboost\n\n\nJina (\ud83e\udd4839 \u00b7  \u2b50 17K) - The most advanced MLOps platform for multimodal AI on the cloud Neural.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 2K \u00b7 \ud83d\udce6 390 \u00b7 \ud83d\udccb 1.7K - 1% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/jina-ai/jina\n- PyPi (\ud83d\udce5 87K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 06.07.2022):\npip install jina\n- Conda (\ud83d\udce5 31K \u00b7 \u23f1\ufe0f 16.08.2022):\nconda install -c conda-forge jina-core\n- Docker Hub (\ud83d\udce5 1.1M \u00b7 \u2b50 7 \u00b7 \u23f1\ufe0f 24.11.2022):\ndocker pull jinaai/jina\n\n\nPyFlink (\ud83e\udd4837 \u00b7  \u2b50 20K) - Apache Flink Python API. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 1.7K \u00b7 \ud83d\udd00 11K \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/apache/flink\n- PyPi (\ud83d\udce5 68K / month \u00b7 \ud83d\udce6 16 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install apache-flink\n\n\nMXNet (\ud83e\udd4837 \u00b7  \u2b50 20K) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 980 \u00b7 \ud83d\udd00 6.9K \u00b7 \ud83d\udce5 26K \u00b7 \ud83d\udccb 9.5K - 18% open \u00b7 \u23f1\ufe0f 26.09.2022):\ngit clone https://github.com/apache/incubator-mxnet\n- PyPi (\ud83d\udce5 400K / month \u00b7 \ud83d\udce6 280 \u00b7 \u23f1\ufe0f 17.05.2022):\npip install mxnet\n- Conda (\ud83d\udce5 8.5K \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 24.10.2022):\nconda install -c anaconda mxnet\n\n\nTheano (\ud83e\udd4837 \u00b7  \u2b50 9.6K \u00b7 \ud83d\udca4) - Theano was a Python library that allows you to define, optimize, and.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 380 \u00b7 \ud83d\udd00 2.5K \u00b7 \ud83d\udce6 13K \u00b7 \ud83d\udccb 2.8K - 24% open \u00b7 \u23f1\ufe0f 23.11.2021):\ngit clone https://github.com/Theano/Theano\n- PyPi (\ud83d\udce5 270K / month \u00b7 \ud83d\udce6 2.8K \u00b7 \u23f1\ufe0f 27.07.2020):\npip install theano\n- Conda (\ud83d\udce5 2.2M \u00b7 \u23f1\ufe0f 16.03.2022):\nconda install -c conda-forge theano\n\n\nFlax (\ud83e\udd4836 \u00b7  \u2b50 3.8K) - Flax is a neural network library for JAX that is designed for.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 430 \u00b7 \ud83d\udce5 42 \u00b7 \ud83d\udce6 1.6K \u00b7 \ud83d\udccb 640 - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/google/flax\n- PyPi (\ud83d\udce5 250K / month \u00b7 \ud83d\udce6 75 \u00b7 \u23f1\ufe0f 21.06.2022):\npip install flax\n- Conda (\ud83d\udce5 14K \u00b7 \u23f1\ufe0f 04.10.2022):\nconda install -c conda-forge flax\n\n\nThinc (\ud83e\udd4836 \u00b7  \u2b50 2.6K) - A refreshing functional take on deep learning, compatible with your favorite.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 25K \u00b7 \ud83d\udccb 140 - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/explosion/thinc\n- PyPi (\ud83d\udce5 4M / month \u00b7 \ud83d\udce6 620 \u00b7 \u23f1\ufe0f 22.06.2022):\npip install thinc\n- Conda (\ud83d\udce5 2.3M \u00b7 \u23f1\ufe0f 15.11.2022):\nconda install -c conda-forge thinc\n\n\nVowpal Wabbit (\ud83e\udd4835 \u00b7  \u2b50 8.1K) - Vowpal Wabbit is a machine learning system which pushes the.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 320 \u00b7 \ud83d\udd00 1.8K \u00b7 \ud83d\udccb 1.2K - 12% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/VowpalWabbit/vowpal_wabbit\n- PyPi (\ud83d\udce5 120K / month \u00b7 \ud83d\udce6 31 \u00b7 \u23f1\ufe0f 06.04.2022):\npip install vowpalwabbit\n- Conda (\ud83d\udce5 91K \u00b7 \u23f1\ufe0f 09.11.2022):\nconda install -c conda-forge vowpalwabbit\n\n\nChainer (\ud83e\udd4835 \u00b7  \u2b50 5.7K) - A flexible framework of neural networks for deep learning. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 320 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce6 2.8K \u00b7 \ud83d\udccb 2K - 0% open \u00b7 \u23f1\ufe0f 17.10.2022):\ngit clone https://github.com/chainer/chainer\n- PyPi (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 400 \u00b7 \u23f1\ufe0f 05.01.2022):\npip install chainer\n- Conda (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 21.01.2022):\nconda install -c conda-forge chainer\n\n\nTuri Create (\ud83e\udd4933 \u00b7  \u2b50 11K \u00b7 \ud83d\udca4) - Turi Create simplifies the development of custom machine.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 85 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce5 7.6K \u00b7 \ud83d\udce6 320 \u00b7 \ud83d\udccb 1.8K - 27% open \u00b7 \u23f1\ufe0f 29.11.2021):\ngit clone https://github.com/apple/turicreate\n- PyPi (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 30.09.2020):\npip install turicreate\n\n\nLudwig (\ud83e\udd4933 \u00b7  \u2b50 8.6K) - Data-centric declarative deep learning framework. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udce6 140 \u00b7 \ud83d\udccb 890 - 25% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/ludwig-ai/ludwig\n- PyPi (\ud83d\udce5 1.5K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 25.06.2022):\npip install ludwig\n\n\nivy (\ud83e\udd4933 \u00b7  \u2b50 7.6K) - The Unified Machine Learning Framework. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 580 \u00b7 \ud83d\udd00 2.5K \u00b7 \ud83d\udccb 3.5K - 16% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/unifyai/ivy\n- PyPi (\ud83d\udce5 250 / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 01.06.2022):\npip install ivy-core\n\n\nmlpack (\ud83e\udd4933 \u00b7  \u2b50 4.1K) - mlpack: a fast, header-only C++ machine learning library. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 300 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udccb 1.5K - 2% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/mlpack/mlpack\n- PyPi (\ud83d\udce5 6K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 28.10.2020):\npip install mlpack\n- Conda (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 11.11.2022):\nconda install -c conda-forge mlpack\n\n\ntensorflow-upstream (\ud83e\udd4933 \u00b7  \u2b50 620) - TensorFlow ROCm port. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 4.2K \u00b7 \ud83d\udd00 74 \u00b7 \ud83d\udce5 20 \u00b7 \ud83d\udccb 340 - 19% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/ROCmSoftwarePlatform/tensorflow-upstream\n- PyPi (\ud83d\udce5 2.9K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 05.06.2022):\npip install tensorflow-rocm\n\n\ntensorpack (\ud83e\udd4932 \u00b7  \u2b50 6.2K) - A Neural Net Training Interface on TensorFlow, with focus.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 58 \u00b7 \ud83d\udd00 1.8K \u00b7 \ud83d\udce5 140 \u00b7 \ud83d\udce6 1.1K \u00b7 \ud83d\udccb 1.4K - 0% open \u00b7 \u23f1\ufe0f 04.05.2022):\ngit clone https://github.com/tensorpack/tensorpack\n- PyPi (\ud83d\udce5 15K / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 22.01.2021):\npip install tensorpack\n- Conda (\ud83d\udce5 5.3K \u00b7 \u23f1\ufe0f 06.02.2022):\nconda install -c conda-forge tensorpack\n\n\neinops (\ud83e\udd4932 \u00b7  \u2b50 6K) - Deep learning operations reinvented (for pytorch, tensorflow, jax and others). MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udccb 130 - 25% open \u00b7 \u23f1\ufe0f 09.11.2022):\ngit clone https://github.com/arogozhnikov/einops\n- PyPi (\ud83d\udce5 1.9M / month \u00b7 \ud83d\udce6 260 \u00b7 \u23f1\ufe0f 04.03.2022):\npip install einops\n- Conda (\ud83d\udce5 51K \u00b7 \u23f1\ufe0f 04.03.2022):\nconda install -c conda-forge einops\n\n\nSonnet (\ud83e\udd4931 \u00b7  \u2b50 9.4K) - TensorFlow-based neural network library. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 1.3K \u00b7 \ud83d\udce6 940 \u00b7 \ud83d\udccb 180 - 15% open \u00b7 \u23f1\ufe0f 02.11.2022):\ngit clone https://github.com/deepmind/sonnet\n- PyPi (\ud83d\udce5 19K / month \u00b7 \ud83d\udce6 52 \u00b7 \u23f1\ufe0f 27.03.2020):\npip install dm-sonnet\n- Conda (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 14.11.2020):\nconda install -c conda-forge sonnet\n\n\nskorch (\ud83e\udd4931 \u00b7  \u2b50 4.8K) - A scikit-learn compatible neural network library that wraps.. BSD-3  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 52 \u00b7 \ud83d\udd00 330 \u00b7 \ud83d\udce6 600 \u00b7 \ud83d\udccb 460 - 11% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/skorch-dev/skorch\n- PyPi (\ud83d\udce5 59K / month \u00b7 \ud83d\udce6 41 \u00b7 \u23f1\ufe0f 31.10.2021):\npip install skorch\n- Conda (\ud83d\udce5 670K \u00b7 \u23f1\ufe0f 30.11.2021):\nconda install -c conda-forge skorch\n\n\ndyNET (\ud83e\udd4931 \u00b7  \u2b50 3.3K) - DyNet: The Dynamic Neural Network Toolkit. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 700 \u00b7 \ud83d\udce5 7.9K \u00b7 \ud83d\udce6 230 \u00b7 \ud83d\udccb 930 - 28% open \u00b7 \u23f1\ufe0f 14.08.2022):\ngit clone https://github.com/clab/dynet\n- PyPi (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 28 \u00b7 \u23f1\ufe0f 21.10.2020):\npip install dyNET\n\n\nCNTK (\ud83e\udd4930 \u00b7  \u2b50 17K) - Microsoft Cognitive Toolkit (CNTK), an open source deep-learning toolkit. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 270 \u00b7 \ud83d\udd00 4.4K \u00b7 \ud83d\udce5 14K \u00b7 \ud83d\udccb 3.4K - 24% open \u00b7 \u23f1\ufe0f 23.09.2022):\ngit clone https://github.com/microsoft/CNTK\n- PyPi (\ud83d\udce5 900 / month \u00b7 \ud83d\udce6 18 \u00b7 \u23f1\ufe0f 09.12.2020):\npip install cntk\n\n\nIgnite (\ud83e\udd4930 \u00b7  \u2b50 4.1K) - High-level library to help with training and evaluating neural.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 560 \u00b7 \ud83d\udccb 1.2K - 12% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/pytorch/ignite\n- PyPi (\ud83d\udce5 81K / month \u00b7 \u23f1\ufe0f 08.11.2022):\npip install pytorch-ignite\n- Conda (\ud83d\udce5 110K \u00b7 \u23f1\ufe0f 05.09.2022):\nconda install -c pytorch ignite\n\n\nNeural Network Libraries (\ud83e\udd4930 \u00b7  \u2b50 2.6K) - Neural Network Libraries. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 69 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce5 540 \u00b7 \ud83d\udccb 92 - 40% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/sony/nnabla\n- PyPi (\ud83d\udce5 2.6K / month \u00b7 \ud83d\udce6 51 \u00b7 \u23f1\ufe0f 19.06.2022):\npip install nnabla\n\n\nHaiku (\ud83e\udd4930 \u00b7  \u2b50 2.3K) - JAX-based neural network library. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 68 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 630 \u00b7 \ud83d\udccb 240 - 38% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/deepmind/dm-haiku\n- PyPi (\ud83d\udce5 130K / month \u00b7 \ud83d\udce6 42 \u00b7 \u23f1\ufe0f 04.07.2022):\npip install dm-haiku\n- Conda (\ud83d\udce5 6.9K \u00b7 \u23f1\ufe0f 21.09.2022):\nconda install -c conda-forge dm-haiku\n\n\nktrain (\ud83e\udd4929 \u00b7  \u2b50 1.1K) - ktrain is a Python library that makes deep learning and AI more.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 350 \u00b7 \ud83d\udccb 430 - 0% open \u00b7 \u23f1\ufe0f 08.11.2022):\ngit clone https://github.com/amaiya/ktrain\n- PyPi (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 20.05.2022):\npip install ktrain\n\n\nTowhee (\ud83e\udd4927 \u00b7  \u2b50 1.6K) - Towhee is a framework that is dedicated to making neural data.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce5 250 \u00b7 \ud83d\udccb 520 - 2% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/towhee-io/towhee\n- PyPi (\ud83d\udce5 670 / month \u00b7 \u23f1\ufe0f 07.07.2022):\npip install towhee\n\n\nNeural Tangents (\ud83e\udd4926 \u00b7  \u2b50 1.9K) - Fast and Easy Infinite Neural Networks in Python. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 210 \u00b7 \ud83d\udce5 260 \u00b7 \ud83d\udce6 54 \u00b7 \ud83d\udccb 130 - 38% open \u00b7 \u23f1\ufe0f 18.10.2022):\ngit clone https://github.com/google/neural-tangents\n- PyPi (\ud83d\udce5 4.9K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 23.02.2022):\npip install neural-tangents\n\n\nGeomstats (\ud83e\udd4926 \u00b7  \u2b50 860) - Computations and statistics on manifolds with geometric structures. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 72 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udccb 470 - 37% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/geomstats/geomstats\n- PyPi (\ud83d\udce5 760 / month \u00b7 \u23f1\ufe0f 22.04.2022):\npip install geomstats\n- Conda (\ud83d\udce5 810 \u00b7 \u23f1\ufe0f 01.06.2022):\nconda install -c conda-forge geomstats\n\n\nxLearn (\ud83e\udd4925 \u00b7  \u2b50 3K) - High performance, easy-to-use, and scalable machine learning (ML).. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 530 \u00b7 \ud83d\udce5 3.5K \u00b7 \ud83d\udce6 99 \u00b7 \ud83d\udccb 310 - 62% open \u00b7 \u23f1\ufe0f 05.06.2022):\ngit clone https://github.com/aksnzhy/xlearn\n- PyPi (\ud83d\udce5 4.1K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 04.12.2018):\npip install xlearn\n\n\nfklearn (\ud83e\udd4925 \u00b7  \u2b50 1.4K) - fklearn: Functional Machine Learning. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 13 \u00b7 \ud83d\udccb 59 - 61% open \u00b7 \u23f1\ufe0f 21.10.2022):\ngit clone https://github.com/nubank/fklearn\n- PyPi (\ud83d\udce5 2.7K / month \u00b7 \u23f1\ufe0f 30.12.2021):\npip install fklearn\n\n\nmace (\ud83e\udd4922 \u00b7  \u2b50 4.7K) - MACE is a deep learning inference framework optimized for mobile.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 64 \u00b7 \ud83d\udd00 810 \u00b7 \ud83d\udce5 1.4K \u00b7 \ud83d\udccb 670 - 8% open \u00b7 \u23f1\ufe0f 30.05.2022):\ngit clone https://github.com/XiaoMi/mace\n\n\nObjax (\ud83e\udd4922 \u00b7  \u2b50 720) - Objax is a machine learning framework that provides an Object.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 67 \u00b7 \ud83d\udce6 25 \u00b7 \ud83d\udccb 110 - 43% open \u00b7 \u23f1\ufe0f 30.08.2022):\ngit clone https://github.com/google/objax\n- PyPi (\ud83d\udce5 1.7K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 31.01.2022):\npip install objax\n\n\nThunderSVM (\ud83e\udd4920 \u00b7  \u2b50 1.4K \u00b7 \ud83d\udca4) - ThunderSVM: A Fast SVM Library on GPUs and CPUs. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce5 2.5K \u00b7 \ud83d\udccb 210 - 29% open \u00b7 \u23f1\ufe0f 09.04.2022):\ngit clone https://github.com/Xtra-Computing/thundersvm\n- PyPi (\ud83d\udce5 330 / month \u00b7 \u23f1\ufe0f 13.03.2020):\npip install thundersvm\n\n\nNeoML (\ud83e\udd4920 \u00b7  \u2b50 700) - Machine learning framework for both deep learning and traditional.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 32 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udccb 78 - 37% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/neoml-lib/neoml\n- PyPi (\ud83d\udce5 75 / month \u00b7 \u23f1\ufe0f 31.05.2022):\npip install neoml\n\n\nchefboost (\ud83e\udd4919 \u00b7  \u2b50 370) - A Lightweight Decision Tree Framework supporting regular algorithms:.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 92 \u00b7 \ud83d\udce6 29 \u00b7 \ud83d\udccb 31 - 16% open \u00b7 \u23f1\ufe0f 21.05.2022):\ngit clone https://github.com/serengil/chefboost\n- PyPi (\ud83d\udce5 1.6K / month \u00b7 \u23f1\ufe0f 16.02.2022):\npip install chefboost\n\n\nThunderGBM (\ud83e\udd4917 \u00b7  \u2b50 650) - ThunderGBM: Fast GBDTs and Random Forests on GPUs. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 84 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 75 - 44% open \u00b7 \u23f1\ufe0f 13.09.2022):\ngit clone https://github.com/Xtra-Computing/thundergbm\n- PyPi (\ud83d\udce5 130 / month \u00b7 \u23f1\ufe0f 01.05.2020):\npip install thundergbm\n\n\nelegy (\ud83e\udd4917 \u00b7  \u2b50 420) - A High Level API for Deep Learning in JAX. MIT  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 26 \u00b7 \ud83d\udccb 100 - 35% open \u00b7 \u23f1\ufe0f 23.05.2022):\ngit clone https://github.com/poets-ai/elegy\n- PyPi (\ud83d\udce5 330 / month \u00b7 \u23f1\ufe0f 22.04.2022):\npip install elegy\n\n\nShow 10 hidden projects...\n\ndlib (\ud83e\udd4838 \u00b7  \u2b50 12K) - A toolkit for making real world machine learning and data analysis.. \u2757\ufe0fBSL-1.0\nMindsDB (\ud83e\udd4834 \u00b7  \u2b50 11K) - In-Database Machine Learning. \u2757\ufe0fGPL-3.0 \nTFlearn (\ud83e\udd4932 \u00b7  \u2b50 9.6K \u00b7 \ud83d\udc80) - Deep learning library featuring a higher-level API for TensorFlow. MIT \nNuPIC (\ud83e\udd4928 \u00b7  \u2b50 6.3K \u00b7 \ud83d\udc80) - Numenta Platform for Intelligent Computing is an implementation.. \u2757\ufe0fAGPL-3.0\nLasagne (\ud83e\udd4928 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udc80) - Lightweight library to build and train neural networks in Theano. MIT\nSHOGUN (\ud83e\udd4926 \u00b7  \u2b50 2.9K \u00b7 \ud83d\udc80) - Unified and efficient Machine Learning. BSD-3\nNeuPy (\ud83e\udd4925 \u00b7  \u2b50 730 \u00b7 \ud83d\udc80) - NeuPy is a Tensorflow based python library for prototyping and building.. MIT\nneon (\ud83e\udd4922 \u00b7  \u2b50 3.9K \u00b7 \ud83d\udc80) - Intel Nervana reference deep learning framework committed to best.. Apache-2\nTorchbearer (\ud83e\udd4921 \u00b7  \u2b50 630 \u00b7 \ud83d\udc80) - torchbearer: A model fitting library for PyTorch. MIT \nStarSpace (\ud83e\udd4916 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udc80) - Learning embeddings for classification, retrieval and ranking. MIT\n\nData Visualization\nGeneral-purpose and task-specific data visualization libraries.\nMatplotlib (\ud83e\udd4749 \u00b7  \u2b50 16K) - matplotlib: plotting with Python. Python-2.0\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 1.4K \u00b7 \ud83d\udd00 6.6K \u00b7 \ud83d\udce6 660K \u00b7 \ud83d\udccb 9.4K - 20% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/matplotlib/matplotlib\n- PyPi (\ud83d\udce5 32M / month \u00b7 \ud83d\udce6 55K \u00b7 \u23f1\ufe0f 08.10.2022):\npip install matplotlib\n- Conda (\ud83d\udce5 15M \u00b7 \u23f1\ufe0f 04.11.2022):\nconda install -c conda-forge matplotlib\n\n\nBokeh (\ud83e\udd4743 \u00b7  \u2b50 17K) - Interactive Data Visualization in the browser, from Python. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 620 \u00b7 \ud83d\udd00 4K \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 7.1K - 9% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/bokeh/bokeh\n- PyPi (\ud83d\udce5 3.6M / month \u00b7 \ud83d\udce6 3.6K \u00b7 \u23f1\ufe0f 05.07.2022):\npip install bokeh\n- Conda (\ud83d\udce5 9.3M \u00b7 \u23f1\ufe0f 15.11.2022):\nconda install -c conda-forge bokeh\n\n\nSeaborn (\ud83e\udd4742 \u00b7  \u2b50 10K) - Statistical data visualization in Python. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce5 240 \u00b7 \ud83d\udccb 2.2K - 4% open \u00b7 \u23f1\ufe0f 14.11.2022):\ngit clone https://github.com/mwaskom/seaborn\n- PyPi (\ud83d\udce5 8.6M / month \u00b7 \ud83d\udce6 9.4K \u00b7 \u23f1\ufe0f 27.06.2022):\npip install seaborn\n- Conda (\ud83d\udce5 5.2M \u00b7 \u23f1\ufe0f 18.10.2022):\nconda install -c conda-forge seaborn\n\n\nPlotly (\ud83e\udd4741 \u00b7  \u2b50 12K) - The interactive graphing library for Python (includes Plotly Express). MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 2.2K \u00b7 \ud83d\udce6 13 \u00b7 \ud83d\udccb 2.5K - 51% open \u00b7 \u23f1\ufe0f 27.10.2022):\ngit clone https://github.com/plotly/plotly.py\n- PyPi (\ud83d\udce5 8.5M / month \u00b7 \ud83d\udce6 4.1K \u00b7 \u23f1\ufe0f 24.06.2022):\npip install plotly\n- Conda (\ud83d\udce5 3.4M \u00b7 \u23f1\ufe0f 29.10.2022):\nconda install -c conda-forge plotly\n- npm (\ud83d\udce5 45K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 12.01.2021):\nnpm install plotlywidget\n\n\ndash (\ud83e\udd4740 \u00b7  \u2b50 18K) - Analytical Web Apps for Python, R, Julia, and Jupyter. No JavaScript Required. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 1.8K \u00b7 \ud83d\udce6 37K \u00b7 \ud83d\udccb 1.4K - 49% open \u00b7 \u23f1\ufe0f 07.11.2022):\ngit clone https://github.com/plotly/dash\n- PyPi (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 1.2K \u00b7 \u23f1\ufe0f 13.06.2022):\npip install dash\n- Conda (\ud83d\udce5 710K \u00b7 \u23f1\ufe0f 03.11.2022):\nconda install -c conda-forge dash\n\n\npandas-profiling (\ud83e\udd4739 \u00b7  \u2b50 9.9K) - Create HTML profiling reports from pandas DataFrame.. MIT  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce6 9.7K \u00b7 \ud83d\udccb 630 - 21% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/ydataai/pandas-profiling\n- PyPi (\ud83d\udce5 1M / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 27.09.2021):\npip install pandas-profiling\n- Conda (\ud83d\udce5 310K \u00b7 \u23f1\ufe0f 23.11.2022):\nconda install -c conda-forge pandas-profiling\n\n\nAltair (\ud83e\udd4739 \u00b7  \u2b50 7.9K) - Declarative statistical visualization library for Python. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 700 \u00b7 \ud83d\udce6 38K \u00b7 \ud83d\udccb 1.7K - 14% open \u00b7 \u23f1\ufe0f 18.11.2022):\ngit clone https://github.com/altair-viz/altair\n- PyPi (\ud83d\udce5 9.2M / month \u00b7 \ud83d\udce6 340 \u00b7 \u23f1\ufe0f 29.12.2021):\npip install altair\n- Conda (\ud83d\udce5 1.5M \u00b7 \u23f1\ufe0f 29.12.2021):\nconda install -c conda-forge altair\n\n\nPyQtGraph (\ud83e\udd4836 \u00b7  \u2b50 3K) - Fast data visualization and GUI tools for scientific / engineering.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 970 \u00b7 \ud83d\udccb 1.1K - 29% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/pyqtgraph/pyqtgraph\n- PyPi (\ud83d\udce5 150K / month \u00b7 \ud83d\udce6 820 \u00b7 \u23f1\ufe0f 04.03.2022):\npip install pyqtgraph\n- Conda (\ud83d\udce5 320K \u00b7 \u23f1\ufe0f 03.10.2022):\nconda install -c conda-forge pyqtgraph\n\n\nUMAP (\ud83e\udd4835 \u00b7  \u2b50 5.9K) - Uniform Manifold Approximation and Projection. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 690 \u00b7 \ud83d\udce6 6.7K \u00b7 \ud83d\udccb 670 - 54% open \u00b7 \u23f1\ufe0f 11.11.2022):\ngit clone https://github.com/lmcinnes/umap\n- PyPi (\ud83d\udce5 810K / month \u00b7 \ud83d\udce6 330 \u00b7 \u23f1\ufe0f 13.04.2022):\npip install umap-learn\n- Conda (\ud83d\udce5 1.5M \u00b7 \u23f1\ufe0f 14.04.2022):\nconda install -c conda-forge umap-learn\n\n\nHoloViews (\ud83e\udd4835 \u00b7  \u2b50 2.3K) - With Holoviews, your data visualizes itself. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udccb 2.9K - 32% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/holoviz/holoviews\n- PyPi (\ud83d\udce5 520K / month \u00b7 \ud83d\udce6 220 \u00b7 \u23f1\ufe0f 07.07.2022):\npip install holoviews\n- Conda (\ud83d\udce5 980K \u00b7 \u23f1\ufe0f 04.11.2022):\nconda install -c conda-forge holoviews\n- npm (\ud83d\udce5 1K / month \u00b7 \u23f1\ufe0f 24.05.2020):\nnpm install @pyviz/jupyterlab_pyviz\n\n\npyecharts (\ud83e\udd4834 \u00b7  \u2b50 13K) - Python Echarts Plotting Library. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 2.7K \u00b7 \ud83d\udce6 2.6K \u00b7 \ud83d\udccb 1.6K - 2% open \u00b7 \u23f1\ufe0f 30.08.2022):\ngit clone https://github.com/pyecharts/pyecharts\n- PyPi (\ud83d\udce5 74K / month \u00b7 \ud83d\udce6 220 \u00b7 \u23f1\ufe0f 16.11.2021):\npip install pyecharts\n\n\nplotnine (\ud83e\udd4834 \u00b7  \u2b50 3.3K) - A grammar of graphics for Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 99 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udccb 530 - 13% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/has2k1/plotnine\n- PyPi (\ud83d\udce5 440K / month \u00b7 \ud83d\udce6 220 \u00b7 \u23f1\ufe0f 01.07.2022):\npip install plotnine\n- Conda (\ud83d\udce5 220K \u00b7 \u23f1\ufe0f 10.10.2022):\nconda install -c conda-forge plotnine\n\n\nVisPy (\ud83e\udd4834 \u00b7  \u2b50 3K) - High-performance interactive 2D/3D data visualization library. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 600 \u00b7 \ud83d\udce6 910 \u00b7 \ud83d\udccb 1.4K - 22% open \u00b7 \u23f1\ufe0f 14.11.2022):\ngit clone https://github.com/vispy/vispy\n- PyPi (\ud83d\udce5 50K / month \u00b7 \ud83d\udce6 100 \u00b7 \u23f1\ufe0f 04.07.2022):\npip install vispy\n- Conda (\ud83d\udce5 310K \u00b7 \u23f1\ufe0f 14.11.2022):\nconda install -c conda-forge vispy\n- npm (\ud83d\udce5 21 / month \u00b7 \u23f1\ufe0f 15.03.2020):\nnpm install vispy\n\n\nFiftyOne (\ud83e\udd4834 \u00b7  \u2b50 2.2K) - Visualize, create, and debug image and video datasets.. Apache-2   \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 63 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 200 \u00b7 \ud83d\udccb 1K - 35% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/voxel51/fiftyone\n- PyPi (\ud83d\udce5 48K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 24.06.2022):\npip install fiftyone\n\n\nGraphviz (\ud83e\udd4834 \u00b7  \u2b50 1.3K) - Simple Python interface for Graphviz. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 37K \u00b7 \ud83d\udccb 140 - 4% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/xflr6/graphviz\n- PyPi (\ud83d\udce5 8.9M / month \u00b7 \ud83d\udce6 3K \u00b7 \u23f1\ufe0f 16.04.2022):\npip install graphviz\n- Conda (\ud83d\udce5 31K \u00b7 \u23f1\ufe0f 10.08.2022):\nconda install -c anaconda python-graphviz\n\n\nwordcloud (\ud83e\udd4832 \u00b7  \u2b50 9.1K) - A little word cloud generator in Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 65 \u00b7 \ud83d\udd00 2.2K \u00b7 \ud83d\udccb 500 - 25% open \u00b7 \u23f1\ufe0f 10.11.2022):\ngit clone https://github.com/amueller/word_cloud\n- PyPi (\ud83d\udce5 920K / month \u00b7 \ud83d\udce6 740 \u00b7 \u23f1\ufe0f 27.06.2022):\npip install wordcloud\n- Conda (\ud83d\udce5 350K \u00b7 \u23f1\ufe0f 25.08.2022):\nconda install -c conda-forge wordcloud\n\n\ndatashader (\ud83e\udd4832 \u00b7  \u2b50 2.9K) - Quickly and accurately render even the largest data. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 51 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udce6 1.6K \u00b7 \ud83d\udccb 520 - 23% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/holoviz/datashader\n- PyPi (\ud83d\udce5 51K / month \u00b7 \ud83d\udce6 96 \u00b7 \u23f1\ufe0f 21.06.2022):\npip install datashader\n- Conda (\ud83d\udce5 440K \u00b7 \u23f1\ufe0f 18.11.2022):\nconda install -c conda-forge datashader\n\n\nPyVista (\ud83e\udd4832 \u00b7  \u2b50 1.6K \u00b7 \ud83d\udcc9) - 3D plotting and mesh analysis through a streamlined interface.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udce5 680 \u00b7 \ud83d\udccb 1K - 32% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/pyvista/pyvista\n- PyPi (\ud83d\udce5 84K / month \u00b7 \ud83d\udce6 110 \u00b7 \u23f1\ufe0f 30.06.2022):\npip install pyvista\n- Conda (\ud83d\udce5 260K \u00b7 \u23f1\ufe0f 03.11.2022):\nconda install -c conda-forge pyvista\n\n\nD-Tale (\ud83e\udd4830 \u00b7  \u2b50 3.7K) - Visualizer for pandas data structures. \u2757\ufe0fLGPL-2.1  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce6 550 \u00b7 \ud83d\udccb 490 - 9% open \u00b7 \u23f1\ufe0f 04.11.2022):\ngit clone https://github.com/man-group/dtale\n- PyPi (\ud83d\udce5 210K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 17.06.2022):\npip install dtale\n- Conda (\ud83d\udce5 170K \u00b7 \u23f1\ufe0f 04.11.2022):\nconda install -c conda-forge dtale\n\n\nbqplot (\ud83e\udd4830 \u00b7  \u2b50 3.4K) - Plotting library for IPython/Jupyter notebooks. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 59 \u00b7 \ud83d\udd00 470 \u00b7 \ud83d\udce6 35 \u00b7 \ud83d\udccb 600 - 39% open \u00b7 \u23f1\ufe0f 29.09.2022):\ngit clone https://github.com/bqplot/bqplot\n- PyPi (\ud83d\udce5 140K / month \u00b7 \ud83d\udce6 97 \u00b7 \u23f1\ufe0f 11.02.2022):\npip install bqplot\n- Conda (\ud83d\udce5 1.1M \u00b7 \u23f1\ufe0f 02.09.2022):\nconda install -c conda-forge bqplot\n- npm (\ud83d\udce5 4.9K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 02.09.2022):\nnpm install bqplot\n\n\nhvPlot (\ud83e\udd4830 \u00b7  \u2b50 670) - A high-level plotting API for pandas, dask, xarray, and networkx built on.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 39 \u00b7 \ud83d\udd00 76 \u00b7 \ud83d\udce6 2K \u00b7 \ud83d\udccb 570 - 39% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/holoviz/hvplot\n- PyPi (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 65 \u00b7 \u23f1\ufe0f 23.06.2022):\npip install hvplot\n- Conda (\ud83d\udce5 270K \u00b7 \u23f1\ufe0f 26.08.2022):\nconda install -c conda-forge hvplot\n\n\nPerspective (\ud83e\udd4929 \u00b7  \u2b50 5K) - A data visualization and analytics component, especially.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 72 \u00b7 \ud83d\udd00 540 \u00b7 \ud83d\udce6 6 \u00b7 \ud83d\udccb 580 - 16% open \u00b7 \u23f1\ufe0f 20.11.2022):\ngit clone https://github.com/finos/perspective\n- PyPi (\ud83d\udce5 2.4K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 06.06.2022):\npip install perspective-python\n- Conda (\ud83d\udce5 210K \u00b7 \u23f1\ufe0f 09.10.2022):\nconda install -c conda-forge perspective\n- npm (\ud83d\udce5 810 / month \u00b7 \u23f1\ufe0f 07.10.2022):\nnpm install @finos/perspective-jupyterlab\n\n\nmissingno (\ud83e\udd4929 \u00b7  \u2b50 3.4K \u00b7 \ud83d\udca4) - Missing data visualization module for Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 430 \u00b7 \ud83d\udce6 9.2K \u00b7 \ud83d\udccb 120 - 6% open \u00b7 \u23f1\ufe0f 27.02.2022):\ngit clone https://github.com/ResidentMario/missingno\n- PyPi (\ud83d\udce5 850K / month \u00b7 \ud83d\udce6 120 \u00b7 \u23f1\ufe0f 27.02.2022):\npip install missingno\n- Conda (\ud83d\udce5 240K \u00b7 \u23f1\ufe0f 15.02.2020):\nconda install -c conda-forge missingno\n\n\npythreejs (\ud83e\udd4929 \u00b7  \u2b50 840) - A Jupyter - Three.js bridge. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 21 \u00b7 \ud83d\udccb 220 - 25% open \u00b7 \u23f1\ufe0f 25.08.2022):\ngit clone https://github.com/jupyter-widgets/pythreejs\n- PyPi (\ud83d\udce5 68K / month \u00b7 \ud83d\udce6 42 \u00b7 \u23f1\ufe0f 26.02.2021):\npip install pythreejs\n- Conda (\ud83d\udce5 440K \u00b7 \u23f1\ufe0f 06.09.2022):\nconda install -c conda-forge pythreejs\n- npm (\ud83d\udce5 4.7K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 24.08.2022):\nnpm install jupyter-threejs\n\n\ndata-validation (\ud83e\udd4929 \u00b7  \u2b50 680) - Library for exploring and validating machine learning.. Apache-2  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 25 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce5 370 \u00b7 \ud83d\udce6 570 \u00b7 \ud83d\udccb 170 - 22% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/tensorflow/data-validation\n- PyPi (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 27 \u00b7 \u23f1\ufe0f 29.06.2022):\npip install tensorflow-data-validation\n\n\nmpld3 (\ud83e\udd4927 \u00b7  \u2b50 2.2K) - D3 Renderings of Matplotlib Graphics. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 51 \u00b7 \ud83d\udd00 350 \u00b7 \ud83d\udce6 30 \u00b7 \ud83d\udccb 360 - 59% open \u00b7 \u23f1\ufe0f 03.08.2022):\ngit clone https://github.com/mpld3/mpld3\n- PyPi (\ud83d\udce5 270K / month \u00b7 \ud83d\udce6 400 \u00b7 \u23f1\ufe0f 27.05.2022):\npip install mpld3\n- Conda (\ud83d\udce5 160K \u00b7 \u23f1\ufe0f 27.05.2022):\nconda install -c conda-forge mpld3\n- npm (\ud83d\udce5 340 / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 27.05.2022):\nnpm install mpld3\n\n\nAutoViz (\ud83e\udd4927 \u00b7  \u2b50 1K) - Automatically Visualize any dataset, any size with a single line of.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 300 \u00b7 \ud83d\udccb 61 - 4% open \u00b7 \u23f1\ufe0f 26.10.2022):\ngit clone https://github.com/AutoViML/AutoViz\n- PyPi (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 17.06.2022):\npip install autoviz\n- Conda (\ud83d\udce5 22K \u00b7 \u23f1\ufe0f 03.10.2022):\nconda install -c conda-forge autoviz\n\n\nChartify (\ud83e\udd4926 \u00b7  \u2b50 3.2K) - Python library that makes it easy for data scientists to create.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udce6 69 \u00b7 \ud83d\udccb 74 - 58% open \u00b7 \u23f1\ufe0f 18.10.2022):\ngit clone https://github.com/spotify/chartify\n- PyPi (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 02.11.2020):\npip install chartify\n- Conda (\ud83d\udce5 23K \u00b7 \u23f1\ufe0f 07.11.2020):\nconda install -c conda-forge chartify\n\n\nopenTSNE (\ud83e\udd4926 \u00b7  \u2b50 1.1K) - Extensible, parallel implementations of t-SNE. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 410 \u00b7 \ud83d\udccb 110 - 5% open \u00b7 \u23f1\ufe0f 09.11.2022):\ngit clone https://github.com/pavlin-policar/openTSNE\n- PyPi (\ud83d\udce5 97K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 18.03.2022):\npip install opentsne\n- Conda (\ud83d\udce5 170K \u00b7 \u23f1\ufe0f 28.10.2022):\nconda install -c conda-forge opentsne\n\n\nlets-plot (\ud83e\udd4926 \u00b7  \u2b50 810) - An open-source plotting library for statistical data. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 39 \u00b7 \ud83d\udce5 340 \u00b7 \ud83d\udce6 18 \u00b7 \ud83d\udccb 300 - 24% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/JetBrains/lets-plot\n- PyPi (\ud83d\udce5 3K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 20.06.2022):\npip install lets-plot\n\n\nHyperTools (\ud83e\udd4925 \u00b7  \u2b50 1.8K \u00b7 \ud83d\udca4) - A Python toolbox for gaining geometric insights into high-.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce5 23 \u00b7 \ud83d\udce6 220 \u00b7 \ud83d\udccb 200 - 34% open \u00b7 \u23f1\ufe0f 12.02.2022):\ngit clone https://github.com/ContextLab/hypertools\n- PyPi (\ud83d\udce5 890 / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 12.02.2022):\npip install hypertools\n\n\nHiPlot (\ud83e\udd4923 \u00b7  \u2b50 2.4K) - HiPlot makes understanding high dimensional data easy. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 120 \u00b7 \ud83d\udce6 5 \u00b7 \ud83d\udccb 82 - 14% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/facebookresearch/hiplot\n- PyPi (\ud83d\udce5 38K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install hiplot\n- Conda (\ud83d\udce5 110K \u00b7 \u23f1\ufe0f 31.05.2022):\nconda install -c conda-forge hiplot\n\n\nSweetviz (\ud83e\udd4923 \u00b7  \u2b50 2.2K) - Visualize and compare datasets, target values and associations, with one.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 210 \u00b7 \ud83d\udccb 100 - 30% open \u00b7 \u23f1\ufe0f 08.06.2022):\ngit clone https://github.com/fbdesignpro/sweetviz\n- PyPi (\ud83d\udce5 75K / month \u00b7 \ud83d\udce6 8 \u00b7 \u23f1\ufe0f 14.06.2022):\npip install sweetviz\n- Conda (\ud83d\udce5 16K \u00b7 \u23f1\ufe0f 15.06.2022):\nconda install -c conda-forge sweetviz\n\n\nPopmon (\ud83e\udd4923 \u00b7  \u2b50 400) - Monitor the stability of a Pandas or Spark dataframe. MIT  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 32 \u00b7 \ud83d\udce5 35 \u00b7 \ud83d\udce6 17 \u00b7 \ud83d\udccb 46 - 28% open \u00b7 \u23f1\ufe0f 19.10.2022):\ngit clone https://github.com/ing-bank/popmon\n- PyPi (\ud83d\udce5 33K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 21.06.2022):\npip install popmon\n\n\nvega (\ud83e\udd4923 \u00b7  \u2b50 330) - IPython/Jupyter notebook module for Vega and Vega-Lite. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 59 \u00b7 \ud83d\udccb 95 - 13% open \u00b7 \u23f1\ufe0f 01.10.2022):\ngit clone https://github.com/vega/ipyvega\n- PyPi (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 84 \u00b7 \u23f1\ufe0f 10.02.2022):\npip install vega\n- Conda (\ud83d\udce5 520K \u00b7 \u23f1\ufe0f 10.02.2022):\nconda install -c conda-forge vega\n\n\nPandas-Bokeh (\ud83e\udd4922 \u00b7  \u2b50 820 \u00b7 \ud83d\udca4) - Bokeh Plotting Backend for Pandas and GeoPandas. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udccb 100 - 33% open \u00b7 \u23f1\ufe0f 25.03.2022):\ngit clone https://github.com/PatrikHlobil/Pandas-Bokeh\n- PyPi (\ud83d\udce5 23K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 11.04.2021):\npip install pandas-bokeh\n\n\npython-ternary (\ud83e\udd4922 \u00b7  \u2b50 610) - Ternary plotting library for python with matplotlib. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce5 18 \u00b7 \ud83d\udce6 110 \u00b7 \ud83d\udccb 140 - 28% open \u00b7 \u23f1\ufe0f 06.11.2022):\ngit clone https://github.com/marcharper/python-ternary\n- PyPi (\ud83d\udce5 58K / month \u00b7 \ud83d\udce6 21 \u00b7 \u23f1\ufe0f 17.02.2021):\npip install python-ternary\n- Conda (\ud83d\udce5 69K \u00b7 \u23f1\ufe0f 17.02.2021):\nconda install -c conda-forge python-ternary\n\n\nPlotly-Resampler (\ud83e\udd4921 \u00b7  \u2b50 580) - Visualize large time series data with plotly.py. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 34 \u00b7 \ud83d\udccb 70 - 30% open \u00b7 \u23f1\ufe0f 08.11.2022):\ngit clone https://github.com/predict-idlab/plotly-resampler\n- PyPi (\ud83d\udce5 27K / month \u00b7 \u23f1\ufe0f 29.06.2022):\npip install plotly-resampler\n- Conda (\ud83d\udce5 9.8K \u00b7 \u23f1\ufe0f 25.08.2022):\nconda install -c conda-forge plotly-resampler\n\n\nPyWaffle (\ud83e\udd4921 \u00b7  \u2b50 520) - Make Waffle Charts in Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 98 \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 18 - 22% open \u00b7 \u23f1\ufe0f 08.06.2022):\ngit clone https://github.com/gyli/PyWaffle\n- PyPi (\ud83d\udce5 10K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 08.06.2022):\npip install pywaffle\n- Conda (\ud83d\udce5 7.7K \u00b7 \u23f1\ufe0f 05.06.2022):\nconda install -c conda-forge pywaffle\n\n\njoypy (\ud83e\udd4921 \u00b7  \u2b50 450 \u00b7 \ud83d\udca4) - Joyplots in Python with matplotlib & pandas. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 47 \u00b7 \ud83d\udce6 210 \u00b7 \ud83d\udccb 48 - 22% open \u00b7 \u23f1\ufe0f 19.12.2021):\ngit clone https://github.com/leotac/joypy\n- PyPi (\ud83d\udce5 18K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 19.12.2021):\npip install joypy\n- Conda (\ud83d\udce5 17K \u00b7 \u23f1\ufe0f 28.12.2020):\nconda install -c conda-forge joypy\n\n\nShow 14 hidden projects...\n\ncartopy (\ud83e\udd4832 \u00b7  \u2b50 1.1K) - Cartopy - a cartographic python library with matplotlib support. \u2757\ufe0fLGPL-3.0\nCufflinks (\ud83e\udd4929 \u00b7  \u2b50 2.7K \u00b7 \ud83d\udc80) - Productivity Tools for Plotly + Pandas. MIT \nFacets Overview (\ud83e\udd4928 \u00b7  \u2b50 7K \u00b7 \ud83d\udc80) - Visualizations for machine learning datasets. Apache-2 \nMulticore-TSNE (\ud83e\udd4924 \u00b7  \u2b50 1.7K \u00b7 \ud83d\udc80) - Parallel t-SNE implementation with Python and Torch.. BSD-3 \nPandasGUI (\ud83e\udd4923 \u00b7  \u2b50 2.8K \u00b7 \ud83d\udca4) - A GUI for Pandas DataFrames. \u2757\ufe0fMIT-0 \nPDPbox (\ud83e\udd4923 \u00b7  \u2b50 710 \u00b7 \ud83d\udc80) - python partial dependence plot toolbox. MIT\npivottablejs (\ud83e\udd4922 \u00b7  \u2b50 500 \u00b7 \ud83d\udc80) - Dragndrop Pivot Tables and Charts for Jupyter/IPython.. MIT \nivis (\ud83e\udd4919 \u00b7  \u2b50 280) - Dimensionality reduction in very large datasets using Siamese.. Apache-2 \nanimatplot (\ud83e\udd4917 \u00b7  \u2b50 390 \u00b7 \ud83d\udc80) - A python package for animating plots build on matplotlib. MIT\npdvega (\ud83e\udd4917 \u00b7  \u2b50 340 \u00b7 \ud83d\udc80) - Interactive plotting for Pandas using Vega-Lite. MIT\ndata-describe (\ud83e\udd4917 \u00b7  \u2b50 290 \u00b7 \ud83d\udca4) - datadescribe: Pythonic EDA Accelerator for Data Science. Apache-2\nvegafusion (\ud83e\udd4917 \u00b7  \u2b50 120) - Serverside acceleration for the Vega visualization grammar. \u2757\ufe0fAGPL-3.0\nnx-altair (\ud83e\udd4915 \u00b7  \u2b50 200 \u00b7 \ud83d\udc80) - Draw interactive NetworkX graphs with Altair. MIT \nnptsne (\ud83e\udd4912 \u00b7  \u2b50 29 \u00b7 \ud83d\udc80) - nptsne is a numpy compatible python binary package that offers a.. Apache-2\n\nText Data & NLP\nLibraries for processing, cleaning, manipulating, and analyzing text data as well as libraries for NLP tasks such as language detection, fuzzy matching, classification, seq2seq learning, conversational AI, keyword extraction, and translation.\ntransformers (\ud83e\udd4750 \u00b7  \u2b50 75K) - Transformers: State-of-the-art Machine Learning for.. Apache-2  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 1.6K \u00b7 \ud83d\udd00 17K \u00b7 \ud83d\udce5 620 \u00b7 \ud83d\udce6 41K \u00b7 \ud83d\udccb 11K - 5% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/huggingface/transformers\n- PyPi (\ud83d\udce5 8.4M / month \u00b7 \ud83d\udce6 980 \u00b7 \u23f1\ufe0f 21.06.2022):\npip install transformers\n- Conda (\ud83d\udce5 610K \u00b7 \u23f1\ufe0f 03.11.2022):\nconda install -c conda-forge transformers\n\n\nspaCy (\ud83e\udd4744 \u00b7  \u2b50 25K) - Industrial-strength Natural Language Processing (NLP) in Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 700 \u00b7 \ud83d\udd00 4K \u00b7 \ud83d\udce5 3.1K \u00b7 \ud83d\udce6 46K \u00b7 \ud83d\udccb 5.3K - 1% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/explosion/spaCy\n- PyPi (\ud83d\udce5 4.4M / month \u00b7 \ud83d\udce6 2.4K \u00b7 \u23f1\ufe0f 05.04.2022):\npip install spacy\n- Conda (\ud83d\udce5 2.9M \u00b7 \u23f1\ufe0f 16.11.2022):\nconda install -c conda-forge spacy\n\n\nnltk (\ud83e\udd4744 \u00b7  \u2b50 11K) - Suite of libraries and programs for symbolic and statistical natural.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 430 \u00b7 \ud83d\udd00 2.7K \u00b7 \ud83d\udce6 160K \u00b7 \ud83d\udccb 1.7K - 14% open \u00b7 \u23f1\ufe0f 05.11.2022):\ngit clone https://github.com/nltk/nltk\n- PyPi (\ud83d\udce5 12M / month \u00b7 \ud83d\udce6 12K \u00b7 \u23f1\ufe0f 09.02.2022):\npip install nltk\n- Conda (\ud83d\udce5 1.6M \u00b7 \u23f1\ufe0f 17.11.2022):\nconda install -c conda-forge nltk\n\n\nfairseq (\ud83e\udd4739 \u00b7  \u2b50 20K \u00b7 \ud83d\udcc8) - Facebook AI Research Sequence-to-Sequence Toolkit written in.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 410 \u00b7 \ud83d\udd00 5K \u00b7 \ud83d\udce5 280 \u00b7 \ud83d\udce6 1K \u00b7 \ud83d\udccb 3.8K - 22% open \u00b7 \u23f1\ufe0f 08.11.2022):\ngit clone https://github.com/facebookresearch/fairseq\n- PyPi (\ud83d\udce5 60K / month \u00b7 \ud83d\udce6 39 \u00b7 \u23f1\ufe0f 27.06.2022):\npip install fairseq\n- Conda (\ud83d\udce5 22K \u00b7 \u23f1\ufe0f 13.07.2022):\nconda install -c conda-forge fairseq\n\n\nRasa (\ud83e\udd4739 \u00b7  \u2b50 15K) - Open source machine learning framework to automate text- and voice-.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 560 \u00b7 \ud83d\udd00 4.2K \u00b7 \ud83d\udccb 6.7K - 10% open \u00b7 \u23f1\ufe0f 18.11.2022):\ngit clone https://github.com/RasaHQ/rasa\n- PyPi (\ud83d\udce5 170K / month \u00b7 \ud83d\udce6 60 \u00b7 \u23f1\ufe0f 06.07.2022):\npip install rasa\n\n\ngensim (\ud83e\udd4739 \u00b7  \u2b50 14K \u00b7 \ud83d\udcc9) - Topic Modelling for Humans. \u2757\ufe0fLGPL-2.1\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 430 \u00b7 \ud83d\udd00 4.3K \u00b7 \ud83d\udce5 4K \u00b7 \ud83d\udce6 38K \u00b7 \ud83d\udccb 1.8K - 21% open \u00b7 \u23f1\ufe0f 03.11.2022):\ngit clone https://github.com/RaRe-Technologies/gensim\n- PyPi (\ud83d\udce5 4.8M / month \u00b7 \ud83d\udce6 2.9K \u00b7 \u23f1\ufe0f 01.05.2022):\npip install gensim\n- Conda (\ud83d\udce5 920K \u00b7 \u23f1\ufe0f 29.07.2022):\nconda install -c conda-forge gensim\n\n\nflair (\ud83e\udd4738 \u00b7  \u2b50 12K) - A very simple framework for state-of-the-art Natural Language Processing.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 2K \u00b7 \ud83d\udce6 1.7K \u00b7 \ud83d\udccb 2K - 4% open \u00b7 \u23f1\ufe0f 20.11.2022):\ngit clone https://github.com/flairNLP/flair\n- PyPi (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 76 \u00b7 \u23f1\ufe0f 20.05.2022):\npip install flair\n- Conda (\ud83d\udce5 14K \u00b7 \u23f1\ufe0f 21.05.2022):\nconda install -c conda-forge python-flair\n\n\nAllenNLP (\ud83e\udd4737 \u00b7  \u2b50 11K) - An open-source NLP research library, built on PyTorch. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 260 \u00b7 \ud83d\udd00 2.2K \u00b7 \ud83d\udce5 47 \u00b7 \ud83d\udce6 2.9K \u00b7 \ud83d\udccb 2.6K - 3% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/allenai/allennlp\n- PyPi (\ud83d\udce5 99K / month \u00b7 \ud83d\udce6 180 \u00b7 \u23f1\ufe0f 14.04.2022):\npip install allennlp\n- Conda (\ud83d\udce5 91K \u00b7 \u23f1\ufe0f 15.07.2022):\nconda install -c conda-forge allennlp\n\n\nsentence-transformers (\ud83e\udd4737 \u00b7  \u2b50 8.9K) - Multilingual Sentence & Image Embeddings with BERT. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce6 4.7K \u00b7 \ud83d\udccb 1.6K - 52% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/UKPLab/sentence-transformers\n- PyPi (\ud83d\udce5 2M / month \u00b7 \ud83d\udce6 130 \u00b7 \u23f1\ufe0f 26.06.2022):\npip install sentence-transformers\n- Conda (\ud83d\udce5 51K \u00b7 \u23f1\ufe0f 27.06.2022):\nconda install -c conda-forge sentence-transformers\n\n\nspark-nlp (\ud83e\udd4736 \u00b7  \u2b50 3K \u00b7 \ud83d\udcc9) - State of the Art Natural Language Processing. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 610 \u00b7 \ud83d\udce6 200 \u00b7 \ud83d\udccb 740 - 4% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/JohnSnowLabs/spark-nlp\n- PyPi (\ud83d\udce5 2.8M / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 01.07.2022):\npip install spark-nlp\n\n\nfastText (\ud83e\udd4834 \u00b7  \u2b50 24K \u00b7 \ud83d\udca4) - Library for fast text representation and classification. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 59 \u00b7 \ud83d\udd00 4.5K \u00b7 \ud83d\udce6 3.5K \u00b7 \ud83d\udccb 1.1K - 45% open \u00b7 \u23f1\ufe0f 04.03.2022):\ngit clone https://github.com/facebookresearch/fastText\n- PyPi (\ud83d\udce5 970K / month \u00b7 \ud83d\udce6 190 \u00b7 \u23f1\ufe0f 28.04.2020):\npip install fasttext\n- Conda (\ud83d\udce5 43K \u00b7 \u23f1\ufe0f 01.11.2022):\nconda install -c conda-forge fasttext\n\n\nParlAI (\ud83e\udd4834 \u00b7  \u2b50 9.6K) - A framework for training and evaluating AI models on a variety of.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce6 95 \u00b7 \ud83d\udccb 1.5K - 6% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/facebookresearch/ParlAI\n- PyPi (\ud83d\udce5 3.3K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 30.03.2022):\npip install parlai\n\n\nstanza (\ud83e\udd4834 \u00b7  \u2b50 6.4K) - Official Stanford NLP Python Library for Many Human Languages. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 54 \u00b7 \ud83d\udd00 820 \u00b7 \ud83d\udce6 1.3K \u00b7 \ud83d\udccb 730 - 9% open \u00b7 \u23f1\ufe0f 15.09.2022):\ngit clone https://github.com/stanfordnlp/stanza\n- PyPi (\ud83d\udce5 190K / month \u00b7 \ud83d\udce6 70 \u00b7 \u23f1\ufe0f 23.04.2022):\npip install stanza\n- Conda (\ud83d\udce5 6K \u00b7 \u23f1\ufe0f 14.09.2022):\nconda install -c stanfordnlp stanza\n\n\nsentencepiece (\ud83e\udd4834 \u00b7  \u2b50 6.3K) - Unsupervised text tokenizer for Neural Network-based text.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 69 \u00b7 \ud83d\udd00 840 \u00b7 \ud83d\udce5 22K \u00b7 \ud83d\udce6 20K \u00b7 \ud83d\udccb 570 - 5% open \u00b7 \u23f1\ufe0f 09.09.2022):\ngit clone https://github.com/google/sentencepiece\n- PyPi (\ud83d\udce5 7.4M / month \u00b7 \ud83d\udce6 410 \u00b7 \u23f1\ufe0f 18.06.2021):\npip install sentencepiece\n- Conda (\ud83d\udce5 270K \u00b7 \u23f1\ufe0f 08.04.2022):\nconda install -c conda-forge sentencepiece\n\n\nOpenNMT (\ud83e\udd4834 \u00b7  \u2b50 5.8K) - Open Source Neural Machine Translation in PyTorch. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 2.1K \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 1.4K - 7% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/OpenNMT/OpenNMT-py\n- PyPi (\ud83d\udce5 4.3K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 14.09.2021):\npip install OpenNMT-py\n\n\ntorchtext (\ud83e\udd4834 \u00b7  \u2b50 3.1K) - Data loaders and abstractions for text and NLP. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 750 \u00b7 \ud83d\udccb 760 - 38% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/pytorch/text\n- PyPi (\ud83d\udce5 410K / month \u00b7 \ud83d\udce6 440 \u00b7 \u23f1\ufe0f 28.06.2022):\npip install torchtext\n\n\nTokenizers (\ud83e\udd4833 \u00b7  \u2b50 6K) - Fast State-of-the-Art Tokenizers optimized for Research and.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 61 \u00b7 \ud83d\udd00 510 \u00b7 \ud83d\udce6 52 \u00b7 \ud83d\udccb 700 - 31% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/huggingface/tokenizers\n- PyPi (\ud83d\udce5 8.2M / month \u00b7 \ud83d\udce6 130 \u00b7 \u23f1\ufe0f 13.04.2022):\npip install tokenizers\n- Conda (\ud83d\udce5 560K \u00b7 \u23f1\ufe0f 28.10.2022):\nconda install -c conda-forge tokenizers\n\n\nNeMo (\ud83e\udd4833 \u00b7  \u2b50 5.1K) - NeMo: a toolkit for conversational AI. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 190 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udce5 10K \u00b7 \ud83d\udccb 1.4K - 5% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/NVIDIA/NeMo\n- PyPi (\ud83d\udce5 16K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 01.07.2022):\npip install nemo-toolkit\n\n\nTensorFlow Text (\ud83e\udd4833 \u00b7  \u2b50 1K) - Making text a first-class citizen in TensorFlow. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 98 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 2.5K \u00b7 \ud83d\udccb 250 - 39% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/tensorflow/text\n- PyPi (\ud83d\udce5 3M / month \u00b7 \ud83d\udce6 83 \u00b7 \u23f1\ufe0f 18.05.2022):\npip install tensorflow-text\n\n\nDeepPavlov (\ud83e\udd4832 \u00b7  \u2b50 5.9K) - An open source library for deep learning end-to-end dialog.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 73 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 300 \u00b7 \ud83d\udccb 620 - 8% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/deepmipt/DeepPavlov\n- PyPi (\ud83d\udce5 8.3K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 31.05.2022):\npip install deeppavlov\n\n\njellyfish (\ud83e\udd4832 \u00b7  \u2b50 1.7K) - a python library for doing approximate and phonetic matching of.. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 4.6K \u00b7 \ud83d\udccb 120 - 10% open \u00b7 \u23f1\ufe0f 07.11.2022):\ngit clone https://github.com/jamesturk/jellyfish\n- PyPi (\ud83d\udce5 2.6M / month \u00b7 \ud83d\udce6 410 \u00b7 \u23f1\ufe0f 07.01.2022):\npip install jellyfish\n- Conda (\ud83d\udce5 390K \u00b7 \u23f1\ufe0f 28.10.2022):\nconda install -c conda-forge jellyfish\n\n\nsnowballstemmer (\ud83e\udd4832 \u00b7  \u2b50 600) - Snowball compiler and stemming algorithms. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 4 \u00b7 \ud83d\udccb 82 - 40% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/snowballstem/snowball\n- PyPi (\ud83d\udce5 8.1M / month \u00b7 \ud83d\udce6 6.7K \u00b7 \u23f1\ufe0f 16.11.2021):\npip install snowballstemmer\n- Conda (\ud83d\udce5 5.5M \u00b7 \u23f1\ufe0f 17.11.2021):\nconda install -c conda-forge snowballstemmer\n\n\nhaystack (\ud83e\udd4831 \u00b7  \u2b50 6.1K) - Haystack is an open source NLP framework that leverages pre-trained.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 150 \u00b7 \ud83d\udd00 940 \u00b7 \ud83d\udce5 15 \u00b7 \ud83d\udccb 1.7K - 16% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/deepset-ai/haystack\n- PyPi (\ud83d\udce5 1K / month \u00b7 \ud83d\udce6 85 \u00b7 \u23f1\ufe0f 15.12.2021):\npip install haystack\n\n\nDedupe (\ud83e\udd4831 \u00b7  \u2b50 3.6K) - A python library for accurate and scalable fuzzy matching, record.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 67 \u00b7 \ud83d\udd00 480 \u00b7 \ud83d\udccb 780 - 8% open \u00b7 \u23f1\ufe0f 31.10.2022):\ngit clone https://github.com/dedupeio/dedupe\n- PyPi (\ud83d\udce5 310K / month \u00b7 \ud83d\udce6 48 \u00b7 \u23f1\ufe0f 06.07.2022):\npip install dedupe\n- Conda (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 02.11.2022):\nconda install -c conda-forge dedupe\n\n\nnlpaug (\ud83e\udd4830 \u00b7  \u2b50 3.6K) - Data augmentation for NLP. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 410 \u00b7 \ud83d\udce6 460 \u00b7 \ud83d\udccb 200 - 22% open \u00b7 \u23f1\ufe0f 07.07.2022):\ngit clone https://github.com/makcedward/nlpaug\n- PyPi (\ud83d\udce5 190K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 07.07.2022):\npip install nlpaug\n- Conda (\ud83d\udce5 5.8K \u00b7 \u23f1\ufe0f 07.07.2022):\nconda install -c conda-forge nlpaug\n\n\nTextDistance (\ud83e\udd4830 \u00b7  \u2b50 3K) - Compute distance between sequences. 30+ algorithms, pure python.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udce5 870 \u00b7 \ud83d\udce6 3.1K \u00b7 \u23f1\ufe0f 18.09.2022):\ngit clone https://github.com/life4/textdistance\n- PyPi (\ud83d\udce5 630K / month \u00b7 \ud83d\udce6 43 \u00b7 \u23f1\ufe0f 29.06.2022):\npip install textdistance\n- Conda (\ud83d\udce5 260K \u00b7 \u23f1\ufe0f 18.09.2022):\nconda install -c conda-forge textdistance\n\n\nSciSpacy (\ud83e\udd4830 \u00b7  \u2b50 1.3K) - A full spaCy pipeline and models for scientific/biomedical documents. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udce6 540 \u00b7 \ud83d\udccb 270 - 10% open \u00b7 \u23f1\ufe0f 06.11.2022):\ngit clone https://github.com/allenai/scispacy\n- PyPi (\ud83d\udce5 38K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 10.03.2022):\npip install scispacy\n\n\nSumy (\ud83e\udd4829 \u00b7  \u2b50 3K) - Module for automatic summarization of text documents and HTML pages. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 480 \u00b7 \ud83d\udce6 1.5K \u00b7 \ud83d\udccb 110 - 13% open \u00b7 \u23f1\ufe0f 23.10.2022):\ngit clone https://github.com/miso-belica/sumy\n- PyPi (\ud83d\udce5 19K / month \u00b7 \ud83d\udce6 100 \u00b7 \u23f1\ufe0f 21.04.2022):\npip install sumy\n- Conda (\ud83d\udce5 3.2K \u00b7 \u23f1\ufe0f 25.10.2022):\nconda install -c conda-forge sumy\n\n\nfastNLP (\ud83e\udd4829 \u00b7  \u2b50 2.7K) - fastNLP: A Modularized and Extensible NLP Framework. Currently still.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 61 \u00b7 \ud83d\udd00 440 \u00b7 \ud83d\udce5 66 \u00b7 \ud83d\udce6 100 \u00b7 \ud83d\udccb 200 - 25% open \u00b7 \u23f1\ufe0f 31.10.2022):\ngit clone https://github.com/fastnlp/fastNLP\n- PyPi (\ud83d\udce5 3K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 04.02.2019):\npip install fastnlp\n\n\nCLTK (\ud83e\udd4829 \u00b7  \u2b50 750) - The Classical Language Toolkit. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce5 25 \u00b7 \ud83d\udce6 210 \u00b7 \ud83d\udccb 530 - 5% open \u00b7 \u23f1\ufe0f 16.10.2022):\ngit clone https://github.com/cltk/cltk\n- PyPi (\ud83d\udce5 1.3K / month \u00b7 \ud83d\udce6 42 \u00b7 \u23f1\ufe0f 09.06.2022):\npip install cltk\n\n\nT5 (\ud83e\udd4828 \u00b7  \u2b50 4.5K) - Code for the paper Exploring the Limits of Transfer Learning with a.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 53 \u00b7 \ud83d\udd00 610 \u00b7 \ud83d\udce6 120 \u00b7 \ud83d\udccb 400 - 15% open \u00b7 \u23f1\ufe0f 10.11.2022):\ngit clone https://github.com/google-research/text-to-text-transfer-transformer\n- PyPi (\ud83d\udce5 8.8K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 18.10.2021):\npip install t5\n\n\nvaderSentiment (\ud83e\udd4828 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udca4) - VADER Sentiment Analysis. VADER (Valence Aware Dictionary.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 900 \u00b7 \ud83d\udce6 4.4K \u00b7 \ud83d\udccb 110 - 31% open \u00b7 \u23f1\ufe0f 01.04.2022):\ngit clone https://github.com/cjhutto/vaderSentiment\n- PyPi (\ud83d\udce5 150K / month \u00b7 \ud83d\udce6 170 \u00b7 \u23f1\ufe0f 22.05.2020):\npip install vadersentiment\n- Conda (\ud83d\udce5 10K \u00b7 \u23f1\ufe0f 22.03.2021):\nconda install -c conda-forge vadersentiment\n\n\nftfy (\ud83e\udd4828 \u00b7  \u2b50 3.4K) - Fixes mojibake and other glitches in Unicode text, after the fact. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 7.6K \u00b7 \ud83d\udccb 130 - 9% open \u00b7 \u23f1\ufe0f 25.10.2022):\ngit clone https://github.com/rspeer/python-ftfy\n- PyPi (\ud83d\udce5 2.7M / month \u00b7 \ud83d\udce6 490 \u00b7 \u23f1\ufe0f 09.02.2022):\npip install ftfy\n- Conda (\ud83d\udce5 210K \u00b7 \u23f1\ufe0f 13.03.2022):\nconda install -c conda-forge ftfy\n\n\ntextacy (\ud83e\udd4828 \u00b7  \u2b50 2K \u00b7 \ud83d\udca4) - NLP, before and after spaCy. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 32 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udccb 250 - 11% open \u00b7 \u23f1\ufe0f 06.03.2022):\ngit clone https://github.com/chartbeat-labs/textacy\n- PyPi (\ud83d\udce5 32K / month \u00b7 \ud83d\udce6 100 \u00b7 \u23f1\ufe0f 06.12.2021):\npip install textacy\n- Conda (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 06.02.2022):\nconda install -c conda-forge textacy\n\n\nPyTextRank (\ud83e\udd4828 \u00b7  \u2b50 1.9K) - Python implementation of TextRank algorithms (textgraphs) for phrase.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 330 \u00b7 \ud83d\udce6 310 \u00b7 \ud83d\udccb 92 - 21% open \u00b7 \u23f1\ufe0f 27.07.2022):\ngit clone https://github.com/DerwenAI/pytextrank\n- PyPi (\ud83d\udce5 76K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 06.03.2022):\npip install pytextrank\n\n\nspacy-transformers (\ud83e\udd4828 \u00b7  \u2b50 1.2K) - Use pretrained transformers like BERT, XLNet and GPT-2.. MIT spacy\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 710 \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/explosion/spacy-transformers\n- PyPi (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 22 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install spacy-transformers\n- Conda (\ud83d\udce5 6.6K \u00b7 \u23f1\ufe0f 13.08.2022):\nconda install -c conda-forge spacy-transformers\n\n\nCiphey (\ud83e\udd4927 \u00b7  \u2b50 11K) - Automatically decrypt encryptions without knowing the key or cipher, decode.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 46 \u00b7 \ud83d\udd00 680 \u00b7 \ud83d\udccb 290 - 16% open \u00b7 \u23f1\ufe0f 28.06.2022):\ngit clone https://github.com/Ciphey/Ciphey\n- PyPi (\ud83d\udce5 28K / month \u00b7 \u23f1\ufe0f 06.06.2021):\npip install ciphey\n- Docker Hub (\ud83d\udce5 17K \u00b7 \u2b50 9 \u00b7 \u23f1\ufe0f 27.05.2022):\ndocker pull remnux/ciphey\n\n\nenglish-words (\ud83e\udd4927 \u00b7  \u2b50 8.4K) - A text file containing 479k English words for all your.. Unlicense\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 1.5K \u00b7 \ud83d\udccb 100 - 68% open \u00b7 \u23f1\ufe0f 08.11.2022):\ngit clone https://github.com/dwyl/english-words\n- PyPi (\ud83d\udce5 130K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 29.01.2022):\npip install english-words\n\n\nDeepKE (\ud83e\udd4927 \u00b7  \u2b50 1.5K) - An Open Toolkit for Knowledge Graph Extraction and Construction.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 400 \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/zjunlp/deepke\n- PyPi (\ud83d\udce5 2.1K / month \u00b7 \u23f1\ufe0f 05.07.2022):\npip install deepke\n\n\nscattertext (\ud83e\udd4926 \u00b7  \u2b50 2K) - Beautiful visualizations of how language differs among document.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 310 \u00b7 \ud83d\udccb 92 - 19% open \u00b7 \u23f1\ufe0f 11.11.2022):\ngit clone https://github.com/JasonKessler/scattertext\n- PyPi (\ud83d\udce5 5.7K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 26.03.2022):\npip install scattertext\n- Conda (\ud83d\udce5 71K \u00b7 \u23f1\ufe0f 11.11.2022):\nconda install -c conda-forge scattertext\n\n\nPyText (\ud83e\udd4925 \u00b7  \u2b50 6.4K \u00b7 \ud83d\udcc9) - A natural language modeling framework based on PyTorch. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 230 \u00b7 \ud83d\udd00 800 \u00b7 \ud83d\udce5 310 \u00b7 \ud83d\udccb 220 - 66% open \u00b7 \u23f1\ufe0f 17.10.2022):\ngit clone https://github.com/facebookresearch/pytext\n- PyPi (\ud83d\udce5 180 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 08.06.2020):\npip install pytext-nlp\n\n\nrubrix (\ud83e\udd4925 \u00b7  \u2b50 1.4K) - Open-source tool for data-centric NLP. Argilla helps domain experts.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udccb 720 - 12% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/recognai/rubrix\n- PyPi (\ud83d\udce5 910 / month \u00b7 \u23f1\ufe0f 08.06.2022):\npip install rubrix\n- Conda (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 06.10.2022):\nconda install -c conda-forge rubrix\n\n\nOpenPrompt (\ud83e\udd4924 \u00b7  \u2b50 2.1K) - An Open-Source Framework for Prompt-Learning. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udce6 27 \u00b7 \ud83d\udccb 180 - 18% open \u00b7 \u23f1\ufe0f 09.11.2022):\ngit clone https://github.com/thunlp/OpenPrompt\n- PyPi (\ud83d\udce5 1.7K / month \u00b7 \u23f1\ufe0f 06.07.2022):\npip install openprompt\n\n\npromptsource (\ud83e\udd4924 \u00b7  \u2b50 900) - Toolkit for creating, sharing and using natural language.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 59 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udce6 16 \u00b7 \ud83d\udccb 160 - 14% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/bigscience-workshop/promptsource\n- PyPi (\ud83d\udce5 5.5K / month \u00b7 \u23f1\ufe0f 18.04.2022):\npip install promptsource\n\n\ngpt-2-simple (\ud83e\udd4923 \u00b7  \u2b50 3.1K) - Python package to easily retrain OpenAIs GPT-2 text-.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 600 \u00b7 \ud83d\udce5 360 \u00b7 \ud83d\udccb 250 - 60% open \u00b7 \u23f1\ufe0f 22.05.2022):\ngit clone https://github.com/minimaxir/gpt-2-simple\n- PyPi (\ud83d\udce5 8.2K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 18.10.2021):\npip install gpt-2-simple\n\n\nlightseq (\ud83e\udd4923 \u00b7  \u2b50 2.5K) - LightSeq: A High Performance Library for Sequence Processing and.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udce5 650 \u00b7 \ud83d\udccb 230 - 56% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/bytedance/lightseq\n- PyPi (\ud83d\udce5 5.7K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 26.01.2022):\npip install lightseq\n\n\nfast-bert (\ud83e\udd4923 \u00b7  \u2b50 1.8K) - Super easy library for BERT based NLP models. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 36 \u00b7 \ud83d\udd00 340 \u00b7 \ud83d\udccb 250 - 62% open \u00b7 \u23f1\ufe0f 27.09.2022):\ngit clone https://github.com/utterworks/fast-bert\n- PyPi (\ud83d\udce5 1.6K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 03.06.2022):\npip install fast-bert\n\n\nSockeye (\ud83e\udd4923 \u00b7  \u2b50 1.1K) - Sequence-to-sequence framework with a focus on Neural Machine.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 58 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce5 15 \u00b7 \ud83d\udccb 290 - 3% open \u00b7 \u23f1\ufe0f 06.11.2022):\ngit clone https://github.com/awslabs/sockeye\n- PyPi (\ud83d\udce5 690 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 05.05.2022):\npip install sockeye\n\n\nqdrant (\ud83e\udd4922 \u00b7  \u2b50 3.1K) - Qdrant - Vector Search Engine for the next generation of AI.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 330 - 7% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/qdrant/qdrant\n\n\nTexthero (\ud83e\udd4922 \u00b7  \u2b50 2.6K) - Text preprocessing, representation and visualization from zero to hero. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce5 96 \u00b7 \ud83d\udccb 140 - 56% open \u00b7 \u23f1\ufe0f 28.10.2022):\ngit clone https://github.com/jbesomi/texthero\n- PyPi (\ud83d\udce5 26K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 01.07.2021):\npip install texthero\n\n\njiant (\ud83e\udd4922 \u00b7  \u2b50 1.4K) - jiant is an nlp toolkit. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 59 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 550 - 11% open \u00b7 \u23f1\ufe0f 17.10.2022):\ngit clone https://github.com/nyu-mll/jiant\n- PyPi (\ud83d\udce5 99 / month \u00b7 \u23f1\ufe0f 10.05.2021):\npip install jiant\n\n\nFARM (\ud83e\udd4921 \u00b7  \u2b50 1.6K) - Fast & easy transfer learning for NLP. Harvesting language models.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 37 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udccb 440 - 8% open \u00b7 \u23f1\ufe0f 31.08.2022):\ngit clone https://github.com/deepset-ai/FARM\n- PyPi (\ud83d\udce5 3.4K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 10.06.2021):\npip install farm\n- Conda (\ud83d\udce5 1.9K \u00b7 \u23f1\ufe0f 14.06.2021):\nconda install -c conda-forge farm\n\n\ndetoxify (\ud83e\udd4921 \u00b7  \u2b50 500) - Trained models & code to predict toxic comments on all 3 Jigsaw.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 69 \u00b7 \ud83d\udce5 100K \u00b7 \ud83d\udce6 150 \u00b7 \ud83d\udccb 43 - 53% open \u00b7 \u23f1\ufe0f 15.11.2022):\ngit clone https://github.com/unitaryai/detoxify\n- PyPi (\ud83d\udce5 44K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 12.04.2022):\npip install detoxify\n\n\nsmall-text (\ud83e\udd4921 \u00b7  \u2b50 360) - Active Learning for Text Classification in Python. MIT  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 39 \u00b7 \ud83d\udce6 14 \u00b7 \ud83d\udccb 23 - 26% open \u00b7 \u23f1\ufe0f 13.11.2022):\ngit clone https://github.com/webis-de/small-text\n- PyPi (\ud83d\udce5 400 / month \u00b7 \u23f1\ufe0f 14.06.2022):\npip install small-text\n- Conda (\ud83d\udce5 1.1K \u00b7 \u23f1\ufe0f 14.10.2022):\nconda install -c conda-forge small-text\n\n\nhappy-transformer (\ud83e\udd4921 \u00b7  \u2b50 350) - A package built on top of Hugging Faces transformers.. Apache-2 huggingface\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 43 \u00b7 \ud83d\udce6 97 \u00b7 \ud83d\udccb 110 - 12% open \u00b7 \u23f1\ufe0f 31.10.2022):\ngit clone https://github.com/EricFillion/happy-transformer\n- PyPi (\ud83d\udce5 4.3K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 06.02.2022):\npip install happytransformer\n\n\nNLP Architect (\ud83e\udd4920 \u00b7  \u2b50 2.9K) - A model library for exploring state-of-the-art deep learning.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 38 \u00b7 \ud83d\udd00 450 \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 130 - 16% open \u00b7 \u23f1\ufe0f 07.11.2022):\ngit clone https://github.com/IntelLabs/nlp-architect\n- PyPi (\ud83d\udce5 100 / month \u00b7 \u23f1\ufe0f 12.04.2020):\npip install nlp-architect\n\n\nfinetune (\ud83e\udd4920 \u00b7  \u2b50 660) - Scikit-learn style model finetuning for NLP. MPL-2.0  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 71 \u00b7 \ud83d\udce6 9 \u00b7 \ud83d\udccb 140 - 16% open \u00b7 \u23f1\ufe0f 16.06.2022):\ngit clone https://github.com/IndicoDataSolutions/finetune\n- PyPi (\ud83d\udce5 49 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 20.12.2021):\npip install finetune\n\n\nTextBox (\ud83e\udd4919 \u00b7  \u2b50 420) - TextBox 2.0 is a text generation library with pre-trained language models. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 74 \u00b7 \ud83d\udce6 5 \u00b7 \ud83d\udccb 24 - 16% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/RUCAIBox/TextBox\n- PyPi (\ud83d\udce5 42 / month \u00b7 \u23f1\ufe0f 15.04.2021):\npip install textbox\n\n\nfastT5 (\ud83e\udd4918 \u00b7  \u2b50 380 \u00b7 \ud83d\udca4) - boost inference speed of T5 models by 5x & reduce the model size.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 45 \u00b7 \ud83d\udce6 24 \u00b7 \ud83d\udccb 53 - 24% open \u00b7 \u23f1\ufe0f 05.04.2022):\ngit clone https://github.com/Ki6an/fastT5\n- PyPi (\ud83d\udce5 1.2K / month \u00b7 \u23f1\ufe0f 05.04.2022):\npip install fastt5\n\n\nOpenNRE (\ud83e\udd4916 \u00b7  \u2b50 3.8K) - An Open-Source Package for Neural Relation Extraction (NRE). MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udccb 360 - 4% open \u00b7 \u23f1\ufe0f 03.11.2022):\ngit clone https://github.com/thunlp/OpenNRE\n\n\nTranslate (\ud83e\udd4915 \u00b7  \u2b50 770) - Translate - a PyTorch Language Library. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 87 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udccb 55 - 50% open \u00b7 \u23f1\ufe0f 10.06.2022):\ngit clone https://github.com/pytorch/translate\n- PyPi (\ud83d\udce5 6 / month \u00b7 \u23f1\ufe0f 01.05.2018):\npip install pytorch-translate\n\n\nVizSeq (\ud83e\udd4914 \u00b7  \u2b50 410) - An Analysis Toolkit for Natural Language Generation (Translation,.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 51 \u00b7 \ud83d\udce6 6 \u00b7 \ud83d\udccb 16 - 43% open \u00b7 \u23f1\ufe0f 20.07.2022):\ngit clone https://github.com/facebookresearch/vizseq\n- PyPi (\ud83d\udce5 120 / month \u00b7 \u23f1\ufe0f 07.08.2020):\npip install vizseq\n\n\nShow 38 hidden projects...\n\nChatterBot (\ud83e\udd4736 \u00b7  \u2b50 13K \u00b7 \ud83d\udc80) - ChatterBot is a machine learning, conversational dialog engine.. BSD-3\nTextBlob (\ud83e\udd4834 \u00b7  \u2b50 8.4K \u00b7 \ud83d\udc80) - Simple, Pythonic, text processing--Sentiment analysis, part-of-.. MIT\nfuzzywuzzy (\ud83e\udd4833 \u00b7  \u2b50 8.8K \u00b7 \ud83d\udc80) - Fuzzy String Matching in Python. \u2757\ufe0fGPL-2.0\nGluonNLP (\ud83e\udd4830 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udc80) - Toolkit that enables easy text preprocessing, datasets.. Apache-2 \nneuralcoref (\ud83e\udd4828 \u00b7  \u2b50 2.6K \u00b7 \ud83d\udc80) - Fast Coreference Resolution in spaCy with Neural Networks. MIT\npolyglot (\ud83e\udd4927 \u00b7  \u2b50 2.1K \u00b7 \ud83d\udc80) - Multilingual text (NLP) processing toolkit. \u2757\ufe0fGPL-3.0\nlangid (\ud83e\udd4927 \u00b7  \u2b50 2K \u00b7 \ud83d\udc80) - Stand-alone language identification system. BSD-3\nflashtext (\ud83e\udd4926 \u00b7  \u2b50 5.3K \u00b7 \ud83d\udc80) - Extract Keywords from sentence or Replace keywords in sentences. MIT\nunderthesea (\ud83e\udd4926 \u00b7  \u2b50 1K) - Underthesea - Vietnamese NLP Toolkit. \u2757\ufe0fGPL-3.0\nSnips NLU (\ud83e\udd4925 \u00b7  \u2b50 3.7K \u00b7 \ud83d\udc80) - Snips Python library to extract meaning from text. Apache-2\nsense2vec (\ud83e\udd4925 \u00b7  \u2b50 1.4K \u00b7 \ud83d\udc80) - Contextually-keyed word vectors. MIT\ntextgenrnn (\ud83e\udd4924 \u00b7  \u2b50 4.8K \u00b7 \ud83d\udc80) - Easily train your own text-generating neural network of any.. MIT \nMatchZoo (\ud83e\udd4924 \u00b7  \u2b50 3.7K \u00b7 \ud83d\udc80) - Facilitating the design, comparison and sharing of deep.. Apache-2 \npytorch-nlp (\ud83e\udd4924 \u00b7  \u2b50 2.1K \u00b7 \ud83d\udc80) - Basic Utilities for PyTorch Natural Language Processing.. BSD-3 \nwhoosh (\ud83e\udd4924 \u00b7  \u2b50 330 \u00b7 \ud83d\udca4) - Pure-Python full-text search library. \u2757\ufe0fBSD-1-Clause\nKashgari (\ud83e\udd4923 \u00b7  \u2b50 2.3K \u00b7 \ud83d\udc80) - Kashgari is a production-level NLP Transfer learning.. Apache-2 \nYouTokenToMe (\ud83e\udd4923 \u00b7  \u2b50 840 \u00b7 \ud83d\udc80) - Unsupervised text tokenizer focused on computational efficiency. MIT\npySBD (\ud83e\udd4923 \u00b7  \u2b50 520 \u00b7 \ud83d\udc80) - pySBD (Python Sentence Boundary Disambiguation) is a rule-based sentence.. MIT\nDeepMatcher (\ud83e\udd4922 \u00b7  \u2b50 4.5K \u00b7 \ud83d\udc80) - Python package for performing Entity and Text Matching using.. BSD-3\nTexar (\ud83e\udd4922 \u00b7  \u2b50 2.3K \u00b7 \ud83d\udc80) - Toolkit for Machine Learning, Natural Language Processing, and.. Apache-2 \nanaGo (\ud83e\udd4922 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Bidirectional LSTM-CRF and ELMo for Named-Entity Recognition,.. MIT \nDELTA (\ud83e\udd4921 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - DELTA is a deep learning based natural language and speech.. Apache-2 \nstop-words (\ud83e\udd4921 \u00b7  \u2b50 140 \u00b7 \ud83d\udc80) - Get list of common stop words in various languages in Python. BSD-3\npyfasttext (\ud83e\udd4920 \u00b7  \u2b50 230 \u00b7 \ud83d\udc80) - Yet another Python binding for fastText. \u2757\ufe0fGPL-3.0\ntextpipe (\ud83e\udd4919 \u00b7  \u2b50 300 \u00b7 \ud83d\udc80) - Textpipe: clean and extract metadata from text. MIT\nNeuroNER (\ud83e\udd4918 \u00b7  \u2b50 1.6K \u00b7 \ud83d\udc80) - Named-entity recognition using neural networks. Easy-to-use and.. MIT\ntextaugment (\ud83e\udd4918 \u00b7  \u2b50 290) - TextAugment: Text Augmentation Library. MIT\nnboost (\ud83e\udd4917 \u00b7  \u2b50 640 \u00b7 \ud83d\udc80) - NBoost is a scalable, search-api-boosting platform for deploying.. Apache-2\nskift (\ud83e\udd4917 \u00b7  \u2b50 230) - scikit-learn wrappers for Python fastText. MIT \nnumerizer (\ud83e\udd4916 \u00b7  \u2b50 190) - A Python module to convert natural language numerics into ints and.. MIT\nCamphr (\ud83e\udd4915 \u00b7  \u2b50 340 \u00b7 \ud83d\udc80) - Camphr - NLP libary for creating pipeline components. Apache-2 spacy\nNeuralQA (\ud83e\udd4915 \u00b7  \u2b50 220 \u00b7 \ud83d\udc80) - NeuralQA: A Usable Library for Question Answering on Large Datasets.. MIT\nspacy-dbpedia-spotlight (\ud83e\udd4915 \u00b7  \u2b50 83) - A spaCy wrapper for DBpedia Spotlight. MIT spacy\nBLINK (\ud83e\udd4914 \u00b7  \u2b50 970 \u00b7 \ud83d\udc80) - Entity Linker solution. MIT\nHeadliner (\ud83e\udd4914 \u00b7  \u2b50 230 \u00b7 \ud83d\udc80) - Easy training and deployment of seq2seq models. MIT\nONNX-T5 (\ud83e\udd4914 \u00b7  \u2b50 210 \u00b7 \ud83d\udc80) - Summarization, translation, sentiment-analysis, text-generation.. Apache-2\nTransferNLP (\ud83e\udd4913 \u00b7  \u2b50 290 \u00b7 \ud83d\udc80) - NLP library designed for reproducible experimentation.. MIT \ntextvec (\ud83e\udd4912 \u00b7  \u2b50 180) - Text vectorization tool to outperform TFIDF for classification tasks. MIT \n\nImage Data\nLibraries for image & video processing, manipulation, and augmentation as well as libraries for computer vision tasks such as facial recognition, object detection, and classification.\nPillow (\ud83e\udd4747 \u00b7  \u2b50 10K) - The friendly PIL fork (Python Imaging Library). \u2757\ufe0fPIL\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 420 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce6 910K \u00b7 \ud83d\udccb 2.7K - 4% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/python-pillow/Pillow\n- PyPi (\ud83d\udce5 51M / month \u00b7 \ud83d\udce6 63K \u00b7 \u23f1\ufe0f 29.10.2022):\npip install Pillow\n- Conda (\ud83d\udce5 21M \u00b7 \u23f1\ufe0f 28.10.2022):\nconda install -c conda-forge pillow\n\n\nscikit-image (\ud83e\udd4744 \u00b7  \u2b50 5.1K) - Image processing in Python. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 580 \u00b7 \ud83d\udd00 2.1K \u00b7 \ud83d\udce6 120K \u00b7 \ud83d\udccb 2.5K - 25% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/scikit-image/scikit-image\n- PyPi (\ud83d\udce5 5.9M / month \u00b7 \ud83d\udce6 9.4K \u00b7 \u23f1\ufe0f 12.06.2022):\npip install scikit-image\n- Conda (\ud83d\udce5 4.2M \u00b7 \u23f1\ufe0f 30.10.2022):\nconda install -c conda-forge scikit-image\n\n\ntorchvision (\ud83e\udd4742 \u00b7  \u2b50 13K) - Datasets, Transforms and Models specific to Computer Vision. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 510 \u00b7 \ud83d\udd00 6.3K \u00b7 \ud83d\udce5 16K \u00b7 \ud83d\udccb 2.8K - 29% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/pytorch/vision\n- PyPi (\ud83d\udce5 7.5M / month \u00b7 \ud83d\udce6 3.7K \u00b7 \u23f1\ufe0f 28.06.2022):\npip install torchvision\n- Conda (\ud83d\udce5 440K \u00b7 \u23f1\ufe0f 24.07.2022):\nconda install -c conda-forge torchvision\n\n\nPyTorch Image Models (\ud83e\udd4739 \u00b7  \u2b50 22K) - PyTorch image models, scripts, pretrained weights --.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 86 \u00b7 \ud83d\udd00 3.7K \u00b7 \ud83d\udce5 2.4M \u00b7 \ud83d\udce6 6K \u00b7 \ud83d\udccb 630 - 12% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/rwightman/pytorch-image-models\n- PyPi (\ud83d\udce5 1.4M / month \u00b7 \ud83d\udce6 110 \u00b7 \u23f1\ufe0f 15.05.2022):\npip install timm\n- Conda (\ud83d\udce5 37K \u00b7 \u23f1\ufe0f 24.11.2022):\nconda install -c conda-forge timm\n\n\nMMDetection (\ud83e\udd4738 \u00b7  \u2b50 22K \u00b7 \ud83d\udcc8) - OpenMMLab Detection Toolbox and Benchmark. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 380 \u00b7 \ud83d\udd00 8.1K \u00b7 \ud83d\udce6 730 \u00b7 \ud83d\udccb 6.6K - 9% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/open-mmlab/mmdetection\n- PyPi (\ud83d\udce5 89K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 01.06.2022):\npip install mmdet\n\n\nMoviePy (\ud83e\udd4737 \u00b7  \u2b50 9.8K) - Video editing with Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 150 \u00b7 \ud83d\udd00 1.3K \u00b7 \ud83d\udce6 19K \u00b7 \ud83d\udccb 1.3K - 24% open \u00b7 \u23f1\ufe0f 10.10.2022):\ngit clone https://github.com/Zulko/moviepy\n- PyPi (\ud83d\udce5 2.4M / month \u00b7 \ud83d\udce6 780 \u00b7 \u23f1\ufe0f 05.10.2020):\npip install moviepy\n- Conda (\ud83d\udce5 140K \u00b7 \u23f1\ufe0f 07.10.2022):\nconda install -c conda-forge moviepy\n\n\nimageio (\ud83e\udd4737 \u00b7  \u2b50 1.1K) - Python library for reading and writing image data. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 94 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce5 410 \u00b7 \ud83d\udce6 72K \u00b7 \ud83d\udccb 500 - 13% open \u00b7 \u23f1\ufe0f 07.11.2022):\ngit clone https://github.com/imageio/imageio\n- PyPi (\ud83d\udce5 13M / month \u00b7 \ud83d\udce6 2.6K \u00b7 \u23f1\ufe0f 30.05.2022):\npip install imageio\n- Conda (\ud83d\udce5 3.9M \u00b7 \u23f1\ufe0f 24.11.2022):\nconda install -c conda-forge imageio\n\n\nAlbumentations (\ud83e\udd4836 \u00b7  \u2b50 11K) - Fast image augmentation library and an easy-to-use wrapper.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce6 10K \u00b7 \ud83d\udccb 710 - 43% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/albumentations-team/albumentations\n- PyPi (\ud83d\udce5 560K / month \u00b7 \ud83d\udce6 220 \u00b7 \u23f1\ufe0f 15.06.2022):\npip install albumentations\n- Conda (\ud83d\udce5 75K \u00b7 \u23f1\ufe0f 20.09.2022):\nconda install -c conda-forge albumentations\n\n\nKornia (\ud83e\udd4834 \u00b7  \u2b50 7.4K) - Open Source Differentiable Computer Vision Library. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 740 \u00b7 \ud83d\udce5 480 \u00b7 \ud83d\udccb 680 - 30% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/kornia/kornia\n- PyPi (\ud83d\udce5 970K / month \u00b7 \ud83d\udce6 58 \u00b7 \u23f1\ufe0f 17.05.2022):\npip install kornia\n- Conda (\ud83d\udce5 49K \u00b7 \u23f1\ufe0f 13.10.2022):\nconda install -c conda-forge kornia\n\n\nImageHash (\ud83e\udd4834 \u00b7  \u2b50 2.6K) - A Python Perceptual Image Hashing Module. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce6 6.5K \u00b7 \ud83d\udccb 120 - 9% open \u00b7 \u23f1\ufe0f 28.09.2022):\ngit clone https://github.com/JohannesBuchner/imagehash\n- PyPi (\ud83d\udce5 1.3M / month \u00b7 \ud83d\udce6 340 \u00b7 \u23f1\ufe0f 15.07.2021):\npip install ImageHash\n- Conda (\ud83d\udce5 260K \u00b7 \u23f1\ufe0f 28.09.2022):\nconda install -c conda-forge imagehash\n\n\nWand (\ud83e\udd4834 \u00b7  \u2b50 1.2K) - The ctypes-based simple ImageMagick binding for Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce5 8.5K \u00b7 \ud83d\udce6 13K \u00b7 \ud83d\udccb 390 - 4% open \u00b7 \u23f1\ufe0f 13.10.2022):\ngit clone https://github.com/emcconville/wand\n- PyPi (\ud83d\udce5 490K / month \u00b7 \ud83d\udce6 690 \u00b7 \u23f1\ufe0f 17.08.2021):\npip install wand\n- Conda (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 22.08.2022):\nconda install -c conda-forge wand\n\n\ndetectron2 (\ud83e\udd4833 \u00b7  \u2b50 23K) - Detectron2 is a platform for object detection, segmentation.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 220 \u00b7 \ud83d\udd00 6.2K \u00b7 \ud83d\udce6 800 \u00b7 \ud83d\udccb 3.2K - 9% open \u00b7 \u23f1\ufe0f 11.11.2022):\ngit clone https://github.com/facebookresearch/detectron2\n- PyPi (\ud83d\udce5 3 / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 06.02.2020):\npip install detectron2\n- Conda (\ud83d\udce5 100K \u00b7 \u23f1\ufe0f 25.04.2022):\nconda install -c conda-forge detectron2\n\n\nInsightFace (\ud83e\udd4833 \u00b7  \u2b50 13K) - State-of-the-art 2D and 3D Face Analysis Project. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 49 \u00b7 \ud83d\udd00 4.1K \u00b7 \ud83d\udce6 210 \u00b7 \ud83d\udccb 2.1K - 56% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/deepinsight/insightface\n- PyPi (\ud83d\udce5 24K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 29.01.2022):\npip install insightface\n\n\nPaddleDetection (\ud83e\udd4833 \u00b7  \u2b50 9.1K) - Object Detection toolkit based on PaddlePaddle. It.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 2.3K \u00b7 \ud83d\udce6 42 \u00b7 \ud83d\udccb 4.2K - 20% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/PaddlePaddle/PaddleDetection\n- PyPi (\ud83d\udce5 1.6K / month \u00b7 \u23f1\ufe0f 24.04.2022):\npip install paddledet\n\n\nFace Recognition (\ud83e\udd4832 \u00b7  \u2b50 47K) - The worlds simplest facial recognition api for Python and.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 54 \u00b7 \ud83d\udd00 13K \u00b7 \ud83d\udce5 470 \u00b7 \ud83d\udccb 1.3K - 54% open \u00b7 \u23f1\ufe0f 10.06.2022):\ngit clone https://github.com/ageitgey/face_recognition\n- PyPi (\ud83d\udce5 52K / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 20.02.2020):\npip install face_recognition\n- Conda (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 30.04.2021):\nconda install -c conda-forge face_recognition\n\n\nPaddleSeg (\ud83e\udd4832 \u00b7  \u2b50 6K) - Easy-to-use image segmentation library with awesome pre-.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 84 \u00b7 \ud83d\udd00 1.3K \u00b7 \ud83d\udce6 730 \u00b7 \ud83d\udccb 1.4K - 45% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/PaddlePaddle/PaddleSeg\n- PyPi (\ud83d\udce5 3.6K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 20.04.2022):\npip install paddleseg\n\n\nGluonCV (\ud83e\udd4832 \u00b7  \u2b50 5.4K) - Gluon CV Toolkit. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udce6 920 \u00b7 \ud83d\udccb 830 - 7% open \u00b7 \u23f1\ufe0f 11.08.2022):\ngit clone https://github.com/dmlc/gluon-cv\n- PyPi (\ud83d\udce5 610K / month \u00b7 \ud83d\udce6 59 \u00b7 \u23f1\ufe0f 07.07.2022):\npip install gluoncv\n\n\nopencv-python (\ud83e\udd4832 \u00b7  \u2b50 3.1K) - Automated CI toolchain to produce precompiled opencv-python,.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 40 \u00b7 \ud83d\udd00 610 \u00b7 \ud83d\udccb 600 - 9% open \u00b7 \u23f1\ufe0f 29.08.2022):\ngit clone https://github.com/opencv/opencv-python\n- PyPi (\ud83d\udce5 6.4M / month \u00b7 \ud83d\udce6 9.4K \u00b7 \u23f1\ufe0f 08.06.2022):\npip install opencv-python\n\n\ndeepface (\ud83e\udd4831 \u00b7  \u2b50 5K) - A Lightweight Face Recognition and Facial Attribute Analysis (Age, Gender,.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 890 \u00b7 \ud83d\udccb 560 - 1% open \u00b7 \u23f1\ufe0f 24.10.2022):\ngit clone https://github.com/serengil/deepface\n- PyPi (\ud83d\udce5 62K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 10.05.2022):\npip install deepface\n\n\nimutils (\ud83e\udd4831 \u00b7  \u2b50 4.2K \u00b7 \ud83d\udca4) - A series of convenience functions to make basic image processing.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udce6 29K \u00b7 \ud83d\udccb 230 - 65% open \u00b7 \u23f1\ufe0f 27.01.2022):\ngit clone https://github.com/PyImageSearch/imutils\n- PyPi (\ud83d\udce5 340K / month \u00b7 \ud83d\udce6 780 \u00b7 \u23f1\ufe0f 15.01.2021):\npip install imutils\n- Conda (\ud83d\udce5 110K \u00b7 \u23f1\ufe0f 06.11.2022):\nconda install -c conda-forge imutils\n\n\nvit-pytorch (\ud83e\udd4828 \u00b7  \u2b50 12K) - Implementation of Vision Transformer, a simple way to achieve.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 2K \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 210 - 48% open \u00b7 \u23f1\ufe0f 29.10.2022):\ngit clone https://github.com/lucidrains/vit-pytorch\n- PyPi (\ud83d\udce5 21K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 30.06.2022):\npip install vit-pytorch\n\n\nsahi (\ud83e\udd4828 \u00b7  \u2b50 2.2K) - Framework agnostic sliced/tiled inference + interactive ui + error analysis.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 330 \u00b7 \ud83d\udce5 9.2K \u00b7 \ud83d\udce6 180 \u00b7 \u23f1\ufe0f 15.11.2022):\ngit clone https://github.com/obss/sahi\n- PyPi (\ud83d\udce5 86K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 25.06.2022):\npip install sahi\n- Conda (\ud83d\udce5 23K \u00b7 \u23f1\ufe0f 16.11.2022):\nconda install -c conda-forge sahi\n\n\nlightly (\ud83e\udd4828 \u00b7  \u2b50 1.9K) - A python library for self-supervised learning on images. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 65 \u00b7 \ud83d\udccb 340 - 22% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/lightly-ai/lightly\n- PyPi (\ud83d\udce5 3.3K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install lightly\n\n\nmahotas (\ud83e\udd4828 \u00b7  \u2b50 780) - Computer Vision in Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 32 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 900 \u00b7 \ud83d\udccb 82 - 23% open \u00b7 \u23f1\ufe0f 14.11.2022):\ngit clone https://github.com/luispedro/mahotas\n- PyPi (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 120 \u00b7 \u23f1\ufe0f 28.06.2022):\npip install mahotas\n- Conda (\ud83d\udce5 350K \u00b7 \u23f1\ufe0f 05.11.2022):\nconda install -c conda-forge mahotas\n\n\nCellProfiler (\ud83e\udd4828 \u00b7  \u2b50 730) - An open-source application for biological image analysis. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 330 \u00b7 \ud83d\udce5 4.2K \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 3.1K - 6% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/CellProfiler/CellProfiler\n- PyPi (\ud83d\udce5 520 / month \u00b7 \u23f1\ufe0f 22.07.2021):\npip install cellprofiler\n\n\ndoctr (\ud83e\udd4927 \u00b7  \u2b50 1.4K) - docTR (Document Text Recognition) - a seamless, high-.. Apache-2  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udce5 850K \u00b7 \ud83d\udce6 40 \u00b7 \ud83d\udccb 220 - 16% open \u00b7 \u23f1\ufe0f 12.10.2022):\ngit clone https://github.com/mindee/doctr\n- PyPi (\ud83d\udce5 5K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 22.03.2022):\npip install python-doctr\n\n\nAugmentor (\ud83e\udd4926 \u00b7  \u2b50 4.8K) - Image augmentation library in Python for machine learning. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 850 \u00b7 \ud83d\udce6 500 \u00b7 \ud83d\udccb 200 - 63% open \u00b7 \u23f1\ufe0f 23.09.2022):\ngit clone https://github.com/mdbloice/Augmentor\n- PyPi (\ud83d\udce5 26K / month \u00b7 \ud83d\udce6 29 \u00b7 \u23f1\ufe0f 27.04.2022):\npip install Augmentor\n\n\nfacenet-pytorch (\ud83e\udd4926 \u00b7  \u2b50 3.2K \u00b7 \ud83d\udca4) - Pretrained Pytorch face detection (MTCNN) and facial.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 700 \u00b7 \ud83d\udce5 490K \u00b7 \ud83d\udce6 920 \u00b7 \ud83d\udccb 160 - 41% open \u00b7 \u23f1\ufe0f 13.12.2021):\ngit clone https://github.com/timesler/facenet-pytorch\n- PyPi (\ud83d\udce5 18K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 10.03.2021):\npip install facenet-pytorch\n\n\nvidgear (\ud83e\udd4926 \u00b7  \u2b50 2.5K) - A High-performance cross-platform Video Processing Python framework.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce5 680 \u00b7 \ud83d\udce6 240 \u00b7 \ud83d\udccb 240 - 3% open \u00b7 \u23f1\ufe0f 06.07.2022):\ngit clone https://github.com/abhiTronix/vidgear\n- PyPi (\ud83d\udce5 5.1K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install vidgear\n\n\nNorfair (\ud83e\udd4926 \u00b7  \u2b50 1.7K) - Lightweight Python library for adding real-time multi-object tracking.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce5 230 \u00b7 \ud83d\udccb 100 - 5% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/tryolabs/norfair\n- PyPi (\ud83d\udce5 5.2K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 30.05.2022):\npip install norfair\n\n\nImage Deduplicator (\ud83e\udd4925 \u00b7  \u2b50 4.3K) - Finding duplicate images made easy!. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 390 \u00b7 \ud83d\udce6 29 \u00b7 \ud83d\udccb 120 - 39% open \u00b7 \u23f1\ufe0f 15.11.2022):\ngit clone https://github.com/idealo/imagededup\n- PyPi (\ud83d\udce5 1.2K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 22.11.2020):\npip install imagededup\n\n\nsegmentation_models (\ud83e\udd4925 \u00b7  \u2b50 4.1K) - Segmentation models with pretrained backbones. Keras.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 940 \u00b7 \ud83d\udccb 500 - 47% open \u00b7 \u23f1\ufe0f 29.07.2022):\ngit clone https://github.com/qubvel/segmentation_models\n- PyPi (\ud83d\udce5 21K / month \u00b7 \ud83d\udce6 24 \u00b7 \u23f1\ufe0f 10.01.2020):\npip install segmentation_models\n\n\nlayout-parser (\ud83e\udd4925 \u00b7  \u2b50 3.3K) - A Unified Toolkit for Deep Learning Based Document Image.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce6 110 \u00b7 \ud83d\udccb 110 - 54% open \u00b7 \u23f1\ufe0f 06.08.2022):\ngit clone https://github.com/Layout-Parser/layout-parser\n- PyPi (\ud83d\udce5 44K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 06.04.2022):\npip install layoutparser\n\n\npytorchvideo (\ud83e\udd4925 \u00b7  \u2b50 2.7K) - A deep learning library for video understanding research. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udccb 170 - 40% open \u00b7 \u23f1\ufe0f 02.11.2022):\ngit clone https://github.com/facebookresearch/pytorchvideo\n- PyPi (\ud83d\udce5 18K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 20.01.2022):\npip install pytorchvideo\n\n\npyvips (\ud83e\udd4925 \u00b7  \u2b50 460) - python binding for libvips using cffi. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 42 \u00b7 \ud83d\udce6 390 \u00b7 \ud83d\udccb 310 - 36% open \u00b7 \u23f1\ufe0f 06.11.2022):\ngit clone https://github.com/libvips/pyvips\n- PyPi (\ud83d\udce5 21K / month \u00b7 \ud83d\udce6 40 \u00b7 \u23f1\ufe0f 12.06.2022):\npip install pyvips\n- Conda (\ud83d\udce5 41K \u00b7 \u23f1\ufe0f 29.10.2022):\nconda install -c conda-forge pyvips\n\n\nMMF (\ud83e\udd4924 \u00b7  \u2b50 5.1K) - A modular framework for vision & language multimodal research from.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 880 \u00b7 \ud83d\udce6 13 \u00b7 \ud83d\udccb 670 - 35% open \u00b7 \u23f1\ufe0f 19.10.2022):\ngit clone https://github.com/facebookresearch/mmf\n- PyPi (\ud83d\udce5 250 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 12.06.2020):\npip install mmf\n\n\ndeep-daze (\ud83e\udd4923 \u00b7  \u2b50 4.4K \u00b7 \ud83d\udca4) - Simple command line tool for text to image generation using.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce6 47 \u00b7 \ud83d\udccb 170 - 56% open \u00b7 \u23f1\ufe0f 13.03.2022):\ngit clone https://github.com/lucidrains/deep-daze\n- PyPi (\ud83d\udce5 1.9K / month \u00b7 \u23f1\ufe0f 13.03.2022):\npip install deep-daze\n\n\nvissl (\ud83e\udd4923 \u00b7  \u2b50 2.9K) - VISSL is FAIRs library of extensible, modular and scalable components.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udce6 13 \u00b7 \ud83d\udccb 160 - 37% open \u00b7 \u23f1\ufe0f 12.10.2022):\ngit clone https://github.com/facebookresearch/vissl\n- PyPi (\ud83d\udce5 360 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 02.11.2021):\npip install vissl\n\n\ntensorflow-graphics (\ud83e\udd4923 \u00b7  \u2b50 2.7K) - TensorFlow Graphics: Differentiable Graphics Layers.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 37 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udccb 230 - 60% open \u00b7 \u23f1\ufe0f 11.11.2022):\ngit clone https://github.com/tensorflow/graphics\n- PyPi (\ud83d\udce5 4.3K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 03.12.2021):\npip install tensorflow-graphics\n\n\nicevision (\ud83e\udd4923 \u00b7  \u2b50 780) - An Agnostic Computer Vision Framework - Pluggable to any Training.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 41 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udccb 560 - 9% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/airctic/icevision\n- PyPi (\ud83d\udce5 3.7K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 10.02.2022):\npip install icevision\n\n\npycls (\ud83e\udd4921 \u00b7  \u2b50 2K) - Codebase for Image Classification Research, written in PyTorch. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 81 - 30% open \u00b7 \u23f1\ufe0f 12.07.2022):\ngit clone https://github.com/facebookresearch/pycls\n- PyPi (\ud83d\udce5 150K / month \u00b7 \u23f1\ufe0f 05.09.2020):\npip install pycls\n\n\nkubric (\ud83e\udd4921 \u00b7  \u2b50 1.7K) - A data generation pipeline for creating semi-realistic synthetic.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 160 - 28% open \u00b7 \u23f1\ufe0f 21.09.2022):\ngit clone https://github.com/google-research/kubric\n- PyPi (\ud83d\udce5 3.7K / month \u00b7 \u23f1\ufe0f 06.07.2022):\npip install kubric-nightly\n\n\nscenic (\ud83e\udd4921 \u00b7  \u2b50 1.6K) - Scenic: A Jax Library for Computer Vision Research and Beyond. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 54 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce6 28 \u00b7 \ud83d\udccb 89 - 41% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/google-research/scenic\n\n\nClassy Vision (\ud83e\udd4921 \u00b7  \u2b50 1.5K) - An end-to-end PyTorch framework for image and video.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 77 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udccb 120 - 45% open \u00b7 \u23f1\ufe0f 27.09.2022):\ngit clone https://github.com/facebookresearch/ClassyVision\n- PyPi (\ud83d\udce5 2K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 09.07.2021):\npip install classy_vision\n- Conda (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 22.03.2022):\nconda install -c conda-forge classy_vision\n\n\nPySlowFast (\ud83e\udd4920 \u00b7  \u2b50 5.3K) - PySlowFast: video understanding codebase from FAIR for.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udce6 10 \u00b7 \ud83d\udccb 590 - 54% open \u00b7 \u23f1\ufe0f 27.09.2022):\ngit clone https://github.com/facebookresearch/SlowFast\n- PyPi (\ud83d\udce5 21 / month \u00b7 \u23f1\ufe0f 15.01.2020):\npip install pyslowfast\n\n\nffcv (\ud83e\udd4920 \u00b7  \u2b50 2.3K) - FFCV: Fast Forward Computer Vision (and other ML workloads!). Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 200 - 26% open \u00b7 \u23f1\ufe0f 21.07.2022):\ngit clone https://github.com/libffcv/ffcv\n- PyPi (\ud83d\udce5 660 / month \u00b7 \u23f1\ufe0f 28.01.2022):\npip install ffcv\n\n\ndetecto (\ud83e\udd4920 \u00b7  \u2b50 560 \u00b7 \ud83d\udca4) - Build fully-functioning computer vision models with PyTorch. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 97 \u00b7 \ud83d\udce6 110 \u00b7 \ud83d\udccb 98 - 37% open \u00b7 \u23f1\ufe0f 09.02.2022):\ngit clone https://github.com/alankbi/detecto\n- PyPi (\ud83d\udce5 3.3K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 02.02.2022):\npip install detecto\n- Conda (\ud83d\udce5 1.8K \u00b7 \u23f1\ufe0f 02.02.2022):\nconda install -c conda-forge detecto\n\n\nDE\u2af6TR (\ud83e\udd4919 \u00b7  \u2b50 10K \u00b7 \ud83d\udca4) - End-to-End Object Detection with Transformers. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 25 \u00b7 \ud83d\udd00 1.8K \u00b7 \ud83d\udccb 470 - 40% open \u00b7 \u23f1\ufe0f 07.03.2022):\ngit clone https://github.com/facebookresearch/detr\n\n\nShow 16 hidden projects...\n\nglfw (\ud83e\udd4835 \u00b7  \u2b50 9.9K \u00b7 \ud83d\udcc9) - A multi-platform library for OpenGL, OpenGL ES, Vulkan, window and.. \u2757\ufe0fZlib\nimgaug (\ud83e\udd4834 \u00b7  \u2b50 13K \u00b7 \ud83d\udc80) - Image augmentation for machine learning experiments. MIT\nimageai (\ud83e\udd4830 \u00b7  \u2b50 7.4K \u00b7 \ud83d\udc80) - A python library built to empower developers to build applications.. MIT\nPyTorch3D (\ud83e\udd4829 \u00b7  \u2b50 6.8K) - PyTorch3D is FAIRs library of reusable components for.. \u2757Unlicensed \nFace Alignment (\ud83e\udd4927 \u00b7  \u2b50 6K \u00b7 \ud83d\udc80) - 2D and 3D Face alignment library build using pytorch. BSD-3 \nchainercv (\ud83e\udd4927 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - ChainerCV: a Library for Deep Learning in Computer Vision. MIT\nPillow-SIMD (\ud83e\udd4925 \u00b7  \u2b50 1.9K) - The friendly PIL fork. \u2757\ufe0fPIL\nmtcnn (\ud83e\udd4925 \u00b7  \u2b50 1.9K \u00b7 \ud83d\udc80) - MTCNN face detection implementation for TensorFlow, as a PIP.. MIT \nImage Super-Resolution (\ud83e\udd4923 \u00b7  \u2b50 3.9K \u00b7 \ud83d\udc80) - Super-scale your images and run experiments with.. Apache-2 \nLuminoth (\ud83e\udd4923 \u00b7  \u2b50 2.4K \u00b7 \ud83d\udc80) - Deep Learning toolkit for Computer Vision. BSD-3 \nnude.py (\ud83e\udd4921 \u00b7  \u2b50 870 \u00b7 \ud83d\udc80) - Nudity detection with Python. MIT\nimage-match (\ud83e\udd4920 \u00b7  \u2b50 2.8K \u00b7 \ud83d\udc80) - Quickly search over billions of images. Apache-2\nCaer (\ud83e\udd4918 \u00b7  \u2b50 660 \u00b7 \ud83d\udc80) - A lightweight Computer Vision library. Scale your models, not boilerplate. MIT\nsolt (\ud83e\udd4917 \u00b7  \u2b50 260) - Streaming over lightweight data transformations. MIT\nTorch Points 3D (\ud83e\udd4916 \u00b7  \u2b50 110 \u00b7 \ud83d\udca4) - Pytorch framework for doing deep learning on point.. BSD-3 \nHugsVision (\ud83e\udd4914 \u00b7  \u2b50 170 \u00b7 \ud83d\udca4) - HugsVision is a easy to use huggingface wrapper for state-of-.. MIT huggingface\n\nGraph Data\nLibraries for graph processing, clustering, embedding, and machine learning tasks.\nnetworkx (\ud83e\udd4744 \u00b7  \u2b50 12K) - Network Analysis in Python. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 630 \u00b7 \ud83d\udd00 2.8K \u00b7 \ud83d\udce5 60 \u00b7 \ud83d\udce6 120K \u00b7 \ud83d\udccb 3.1K - 12% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/networkx/networkx\n- PyPi (\ud83d\udce5 21M / month \u00b7 \ud83d\udce6 13K \u00b7 \u23f1\ufe0f 14.06.2022):\npip install networkx\n- Conda (\ud83d\udce5 8.9M \u00b7 \u23f1\ufe0f 02.11.2022):\nconda install -c conda-forge networkx\n\n\nPyTorch Geometric (\ud83e\udd4738 \u00b7  \u2b50 16K) - Graph Neural Network Library for PyTorch. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 340 \u00b7 \ud83d\udd00 3K \u00b7 \ud83d\udccb 2.9K - 23% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/pyg-team/pytorch_geometric\n- PyPi (\ud83d\udce5 120K / month \u00b7 \ud83d\udce6 50 \u00b7 \u23f1\ufe0f 12.03.2022):\npip install torch-geometric\n- Conda (\ud83d\udce5 14K \u00b7 \u23f1\ufe0f 19.08.2022):\nconda install -c conda-forge pytorch_geometric\n\n\ndgl (\ud83e\udd4737 \u00b7  \u2b50 11K) - Python package built to ease deep learning on graph, on top of existing DL.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 2.6K \u00b7 \ud83d\udce6 39 \u00b7 \ud83d\udccb 2K - 16% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/dmlc/dgl\n- PyPi (\ud83d\udce5 34K / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 16.03.2022):\npip install dgl\n\n\nogb (\ud83e\udd4829 \u00b7  \u2b50 1.5K) - Benchmark datasets, data loaders, and evaluators for graph machine learning. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 340 \u00b7 \ud83d\udce6 500 \u00b7 \ud83d\udccb 240 - 1% open \u00b7 \u23f1\ufe0f 02.11.2022):\ngit clone https://github.com/snap-stanford/ogb\n- PyPi (\ud83d\udce5 22K / month \u00b7 \ud83d\udce6 18 \u00b7 \u23f1\ufe0f 23.02.2022):\npip install ogb\n- Conda (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 03.11.2022):\nconda install -c conda-forge ogb\n\n\npygraphistry (\ud83e\udd4827 \u00b7  \u2b50 1.8K) - PyGraphistry is a Python library to quickly load, shape,.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 80 \u00b7 \ud83d\udccb 250 - 47% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/graphistry/pygraphistry\n- PyPi (\ud83d\udce5 2.9K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 02.07.2022):\npip install graphistry\n\n\nPaddle Graph Learning (\ud83e\udd4827 \u00b7  \u2b50 1.4K) - Paddle Graph Learning (PGL) is an efficient and.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 280 \u00b7 \ud83d\udce6 35 \u00b7 \ud83d\udccb 160 - 38% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/PaddlePaddle/PGL\n- PyPi (\ud83d\udce5 5.3K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 21.04.2022):\npip install pgl\n\n\nSpektral (\ud83e\udd4826 \u00b7  \u2b50 2.2K) - Graph Neural Networks with Keras and Tensorflow 2. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 240 - 19% open \u00b7 \u23f1\ufe0f 19.10.2022):\ngit clone https://github.com/danielegrattarola/spektral\n- PyPi (\ud83d\udce5 5.4K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 09.04.2022):\npip install spektral\n\n\npytorch_geometric_temporal (\ud83e\udd4825 \u00b7  \u2b50 1.8K) - PyTorch Geometric Temporal: Spatiotemporal Signal.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udccb 130 - 7% open \u00b7 \u23f1\ufe0f 25.10.2022):\ngit clone https://github.com/benedekrozemberczki/pytorch_geometric_temporal\n- PyPi (\ud83d\udce5 3.1K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 04.04.2022):\npip install torch-geometric-temporal\n\n\nPyKEEN (\ud83e\udd4825 \u00b7  \u2b50 1K) - A Python library for learning and evaluating knowledge graph embeddings. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce5 140 \u00b7 \ud83d\udccb 460 - 16% open \u00b7 \u23f1\ufe0f 20.11.2022):\ngit clone https://github.com/pykeen/pykeen\n- PyPi (\ud83d\udce5 3.3K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 24.05.2022):\npip install pykeen\n\n\nPyTorch-BigGraph (\ud83e\udd4824 \u00b7  \u2b50 3.1K) - Generate embeddings from large-scale graph-structured.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 420 \u00b7 \ud83d\udce5 140 \u00b7 \ud83d\udccb 190 - 28% open \u00b7 \u23f1\ufe0f 09.09.2022):\ngit clone https://github.com/facebookresearch/PyTorch-BigGraph\n- PyPi (\ud83d\udce5 210K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 01.05.2019):\npip install torchbiggraph\n\n\nNode2Vec (\ud83e\udd4923 \u00b7  \u2b50 990) - Implementation of the node2vec algorithm. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udccb 82 - 1% open \u00b7 \u23f1\ufe0f 19.10.2022):\ngit clone https://github.com/eliorc/node2vec\n- PyPi (\ud83d\udce5 100K / month \u00b7 \ud83d\udce6 16 \u00b7 \u23f1\ufe0f 30.04.2022):\npip install node2vec\n- Conda (\ud83d\udce5 23K \u00b7 \u23f1\ufe0f 25.04.2020):\nconda install -c conda-forge node2vec\n\n\ngraph4nlp (\ud83e\udd4922 \u00b7  \u2b50 1.5K) - Graph4nlp is the library for the easy use of Graph Neural.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udccb 170 - 6% open \u00b7 \u23f1\ufe0f 13.11.2022):\ngit clone https://github.com/graph4ai/graph4nlp\n- PyPi (\ud83d\udce5 190 / month \u00b7 \u23f1\ufe0f 20.01.2022):\npip install graph4nlp\n\n\ntorch-cluster (\ud83e\udd4922 \u00b7  \u2b50 590) - PyTorch Extension Library of Optimized Graph Cluster.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 26 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udccb 110 - 20% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/rusty1s/pytorch_cluster\n- PyPi (\ud83d\udce5 15K / month \u00b7 \ud83d\udce6 30 \u00b7 \u23f1\ufe0f 11.03.2022):\npip install torch-cluster\n- Conda (\ud83d\udce5 47K \u00b7 \u23f1\ufe0f 25.10.2022):\nconda install -c conda-forge pytorch_cluster\n\n\njraph (\ud83e\udd4919 \u00b7  \u2b50 1.1K) - A Graph Neural Network Library in Jax. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 66 \u00b7 \ud83d\udce6 36 \u00b7 \ud83d\udccb 41 - 36% open \u00b7 \u23f1\ufe0f 31.08.2022):\ngit clone https://github.com/deepmind/jraph\n- PyPi (\ud83d\udce5 3.4K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 06.06.2022):\npip install jraph\n- Conda (\ud83d\udce5 1.2K \u00b7 \u23f1\ufe0f 31.10.2021):\nconda install -c conda-forge jraph\n\n\nkglib (\ud83e\udd4918 \u00b7  \u2b50 530) - TypeDB-ML is the Machine Learning integrations library for TypeDB. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 94 \u00b7 \ud83d\udce5 210 \u00b7 \ud83d\udccb 61 - 18% open \u00b7 \u23f1\ufe0f 09.11.2022):\ngit clone https://github.com/vaticle/kglib\n- PyPi (\ud83d\udce5 25 / month \u00b7 \u23f1\ufe0f 19.08.2020):\npip install grakn-kglib\n\n\nGraphEmbedding (\ud83e\udd4916 \u00b7  \u2b50 3.1K) - Implementation and experiments of graph embedding algorithms. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 890 \u00b7 \ud83d\udce6 22 \u00b7 \ud83d\udccb 70 - 64% open \u00b7 \u23f1\ufe0f 21.06.2022):\ngit clone https://github.com/shenweichen/GraphEmbedding\n\n\nOpenKE (\ud83e\udd4915 \u00b7  \u2b50 3.3K) - An Open-Source Package for Knowledge Embedding (KE). MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 920 \u00b7 \ud83d\udccb 360 - 1% open \u00b7 \u23f1\ufe0f 03.11.2022):\ngit clone https://github.com/thunlp/OpenKE\n\n\nGraphGym (\ud83e\udd4915 \u00b7  \u2b50 1.2K) - Platform for designing and evaluating Graph Neural Networks (GNN). MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce5 18 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 35 - 22% open \u00b7 \u23f1\ufe0f 25.08.2022):\ngit clone https://github.com/snap-stanford/GraphGym\n- PyPi (\ud83d\udce5 63 / month \u00b7 \u23f1\ufe0f 24.03.2022):\npip install graphgym\n\n\nAutoGL (\ud83e\udd4915 \u00b7  \u2b50 860 \u00b7 \ud83d\udca4) - An autoML framework & toolkit for machine learning on graphs. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udccb 26 - 42% open \u00b7 \u23f1\ufe0f 19.04.2022):\ngit clone https://github.com/THUMNLab/AutoGL\n- PyPi (\ud83d\udce5 5 / month \u00b7 \u23f1\ufe0f 23.12.2020):\npip install auto-graph-learning\n\n\nOpenNE (\ud83e\udd4914 \u00b7  \u2b50 1.6K) - An Open-Source Package for Network Embedding (NE). MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 480 \u00b7 \ud83d\udccb 100 - 4% open \u00b7 \u23f1\ufe0f 02.11.2022):\ngit clone https://github.com/thunlp/OpenNE\n\n\nptgnn (\ud83e\udd4913 \u00b7  \u2b50 360 \u00b7 \ud83d\udca4) - A PyTorch Graph Neural Network Library. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 41 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 7 - 28% open \u00b7 \u23f1\ufe0f 01.02.2022):\ngit clone https://github.com/microsoft/ptgnn\n- PyPi (\ud83d\udce5 41 / month \u00b7 \u23f1\ufe0f 21.10.2021):\npip install ptgnn\n\n\nShow 15 hidden projects...\n\nigraph (\ud83e\udd4732 \u00b7  \u2b50 1K) - Python interface for igraph. \u2757\ufe0fGPL-2.0\nStellarGraph (\ud83e\udd4828 \u00b7  \u2b50 2.6K \u00b7 \ud83d\udc80) - StellarGraph - Machine Learning on Graphs. Apache-2 \npygal (\ud83e\udd4827 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udca4) - PYthon svg GrAph plotting Library. \u2757\ufe0fLGPL-3.0\nKarate Club (\ud83e\udd4826 \u00b7  \u2b50 1.8K) - Karate Club: An API Oriented Open-source Python Framework for.. \u2757\ufe0fGPL-3.0\nAmpliGraph (\ud83e\udd4824 \u00b7  \u2b50 1.9K \u00b7 \ud83d\udc80) - Python library for Representation Learning on Knowledge.. Apache-2 \nDIG (\ud83e\udd4923 \u00b7  \u2b50 1.3K) - A library for graph deep learning research. \u2757\ufe0fGPL-3.0\nDeepWalk (\ud83e\udd4921 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udc80) - DeepWalk - Deep Learning for Graphs. \u2757\ufe0fGPL-3.0\ngraph-nets (\ud83e\udd4920 \u00b7  \u2b50 5.2K \u00b7 \ud83d\udc80) - Build Graph Nets in Tensorflow. Apache-2 \ndeepsnap (\ud83e\udd4919 \u00b7  \u2b50 440 \u00b7 \ud83d\udc80) - Python library assists deep learning on graphs. MIT\npyRDF2Vec (\ud83e\udd4919 \u00b7  \u2b50 170) - Python Implementation and Extension of RDF2Vec. MIT\nSematch (\ud83e\udd4917 \u00b7  \u2b50 400 \u00b7 \ud83d\udc80) - semantic similarity framework for knowledge graph. Apache-2\nDeepGraph (\ud83e\udd4917 \u00b7  \u2b50 270 \u00b7 \ud83d\udc80) - Analyze Data with Pandas-based Networks. Documentation:. BSD-3 \nEuler (\ud83e\udd4916 \u00b7  \u2b50 2.8K \u00b7 \ud83d\udc80) - A distributed graph deep learning framework. Apache-2 \nGraphSAGE (\ud83e\udd4915 \u00b7  \u2b50 2.9K \u00b7 \ud83d\udc80) - Representation learning on large graphs using stochastic.. MIT \nGraphVite (\ud83e\udd4913 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - GraphVite: A General and High-performance Graph Embedding.. Apache-2\n\nAudio Data\nLibraries for audio analysis, manipulation, transformation, and extraction, as well as speech recognition and music generation tasks.\nespnet (\ud83e\udd4736 \u00b7  \u2b50 5.7K) - End-to-End Speech Processing Toolkit. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 310 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce5 77 \u00b7 \ud83d\udce6 91 \u00b7 \ud83d\udccb 2K - 18% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/espnet/espnet\n- PyPi (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 28.05.2022):\npip install espnet\n\n\nlibrosa (\ud83e\udd4734 \u00b7  \u2b50 5.5K) - Python library for audio and music analysis. ISC\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 850 \u00b7 \ud83d\udccb 1K - 4% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/librosa/librosa\n- PyPi (\ud83d\udce5 1.3M / month \u00b7 \ud83d\udce6 1.2K \u00b7 \u23f1\ufe0f 27.06.2022):\npip install librosa\n- Conda (\ud83d\udce5 550K \u00b7 \u23f1\ufe0f 27.06.2022):\nconda install -c conda-forge librosa\n\n\nspeechbrain (\ud83e\udd4734 \u00b7  \u2b50 4.9K) - A PyTorch-based Speech Toolkit. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 190 \u00b7 \ud83d\udd00 920 \u00b7 \ud83d\udce6 320 \u00b7 \ud83d\udccb 890 - 22% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/speechbrain/speechbrain\n- PyPi (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 26.06.2022):\npip install speechbrain\n\n\ntorchaudio (\ud83e\udd4734 \u00b7  \u2b50 1.9K) - Data manipulation and transformation for audio signal.. BSD-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 490 \u00b7 \ud83d\udccb 740 - 26% open \u00b7 \u23f1\ufe0f 19.11.2022):\ngit clone https://github.com/pytorch/audio\n- PyPi (\ud83d\udce5 600K / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 28.06.2022):\npip install torchaudio\n\n\nMagenta (\ud83e\udd4833 \u00b7  \u2b50 18K) - Magenta: Music and Art Generation with Machine Intelligence. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 150 \u00b7 \ud83d\udd00 3.7K \u00b7 \ud83d\udce6 390 \u00b7 \ud83d\udccb 940 - 37% open \u00b7 \u23f1\ufe0f 04.10.2022):\ngit clone https://github.com/magenta/magenta\n- PyPi (\ud83d\udce5 5.2K / month \u00b7 \ud83d\udce6 38 \u00b7 \u23f1\ufe0f 12.11.2020):\npip install magenta\n\n\nSpeechRecognition (\ud83e\udd4832 \u00b7  \u2b50 6.6K) - Speech recognition module for Python, supporting several.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 48 \u00b7 \ud83d\udd00 2.2K \u00b7 \ud83d\udccb 540 - 47% open \u00b7 \u23f1\ufe0f 07.11.2022):\ngit clone https://github.com/Uberi/speech_recognition\n- PyPi (\ud83d\udce5 420K / month \u00b7 \ud83d\udce6 720 \u00b7 \u23f1\ufe0f 05.12.2017):\npip install SpeechRecognition\n- Conda (\ud83d\udce5 150K \u00b7 \u23f1\ufe0f 15.11.2022):\nconda install -c conda-forge speechrecognition\n\n\nPydub (\ud83e\udd4832 \u00b7  \u2b50 6.5K) - Manipulate audio with a simple and easy high level interface. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 94 \u00b7 \ud83d\udd00 860 \u00b7 \ud83d\udce6 15K \u00b7 \ud83d\udccb 530 - 50% open \u00b7 \u23f1\ufe0f 15.10.2022):\ngit clone https://github.com/jiaaro/pydub\n- PyPi (\ud83d\udce5 3.4M / month \u00b7 \ud83d\udce6 900 \u00b7 \u23f1\ufe0f 10.03.2021):\npip install pydub\n- Conda (\ud83d\udce5 34K \u00b7 \u23f1\ufe0f 13.03.2021):\nconda install -c conda-forge pydub\n\n\nspleeter (\ud83e\udd4829 \u00b7  \u2b50 21K) - Deezer source separation library including pretrained models. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 2.3K \u00b7 \ud83d\udce5 2M \u00b7 \ud83d\udccb 710 - 23% open \u00b7 \u23f1\ufe0f 07.09.2022):\ngit clone https://github.com/deezer/spleeter\n- PyPi (\ud83d\udce5 8.5K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 10.06.2022):\npip install spleeter\n- Conda (\ud83d\udce5 71K \u00b7 \u23f1\ufe0f 30.06.2020):\nconda install -c conda-forge spleeter\n\n\nCoqui TTS (\ud83e\udd4828 \u00b7  \u2b50 7.1K) - - a deep learning toolkit for Text-to-Speech, battle-.. MPL-2.0  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 780 \u00b7 \ud83d\udce5 350K \u00b7 \ud83d\udccb 450 - 4% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/coqui-ai/TTS\n- PyPi (\ud83d\udce5 7.9K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 21.06.2022):\npip install tts\n- Conda (\ud83d\udce5 5.6K \u00b7 \u23f1\ufe0f 15.12.2021):\nconda install -c conda-forge tts\n\n\npyAudioAnalysis (\ud83e\udd4828 \u00b7  \u2b50 5K) - Python Audio Analysis Library: Feature Extraction,.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 320 \u00b7 \ud83d\udccb 300 - 59% open \u00b7 \u23f1\ufe0f 18.09.2022):\ngit clone https://github.com/tyiannak/pyAudioAnalysis\n- PyPi (\ud83d\udce5 9.8K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 07.02.2022):\npip install pyAudioAnalysis\n\n\npython-soundfile (\ud83e\udd4828 \u00b7  \u2b50 500) - SoundFile is an audio library based on libsndfile, CFFI, and.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 81 \u00b7 \ud83d\udce5 7.2K \u00b7 \ud83d\udce6 15K \u00b7 \ud83d\udccb 190 - 41% open \u00b7 \u23f1\ufe0f 27.09.2022):\ngit clone https://github.com/bastibe/python-soundfile\n- PyPi (\ud83d\udce5 1M / month \u00b7 \u23f1\ufe0f 27.09.2022):\npip install soundfile\n- Conda:\nconda install -c anaconda pysoundfile\n\n\naudioread (\ud83e\udd4828 \u00b7  \u2b50 410) - cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udccb 85 - 40% open \u00b7 \u23f1\ufe0f 18.11.2022):\ngit clone https://github.com/beetbox/audioread\n- PyPi (\ud83d\udce5 1.3M / month \u00b7 \ud83d\udce6 330 \u00b7 \u23f1\ufe0f 20.10.2020):\npip install audioread\n- Conda (\ud83d\udce5 540K \u00b7 \u23f1\ufe0f 29.10.2022):\nconda install -c conda-forge audioread\n\n\nPorcupine (\ud83e\udd4927 \u00b7  \u2b50 2.8K) - On-device wake word detection powered by deep learning. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 400 \u00b7 \ud83d\udce6 10 \u00b7 \ud83d\udccb 410 - 0% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/Picovoice/Porcupine\n- PyPi (\ud83d\udce5 1.3K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 28.06.2022):\npip install pvporcupine\n\n\naudiomentations (\ud83e\udd4927 \u00b7  \u2b50 1.2K) - A Python library for audio data augmentation. Inspired by.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 180 \u00b7 \ud83d\udccb 140 - 28% open \u00b7 \u23f1\ufe0f 07.11.2022):\ngit clone https://github.com/iver56/audiomentations\n- PyPi (\ud83d\udce5 4.4K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 15.06.2022):\npip install audiomentations\n\n\nMadmom (\ud83e\udd4926 \u00b7  \u2b50 990 \u00b7 \ud83d\udca4) - Python audio and music signal processing library. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 240 \u00b7 \ud83d\udccb 270 - 22% open \u00b7 \u23f1\ufe0f 06.01.2022):\ngit clone https://github.com/CPJKU/madmom\n- PyPi (\ud83d\udce5 4.8K / month \u00b7 \ud83d\udce6 27 \u00b7 \u23f1\ufe0f 14.11.2018):\npip install madmom\n\n\ntinytag (\ud83e\udd4926 \u00b7  \u2b50 570) - Read audio and music meta data and duration of MP3, OGG, OPUS, MP4, M4A,.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 25 \u00b7 \ud83d\udd00 90 \u00b7 \ud83d\udce6 620 \u00b7 \ud83d\udccb 96 - 14% open \u00b7 \u23f1\ufe0f 04.11.2022):\ngit clone https://github.com/devsnd/tinytag\n- PyPi (\ud83d\udce5 19K / month \u00b7 \ud83d\udce6 70 \u00b7 \u23f1\ufe0f 12.03.2022):\npip install tinytag\n\n\nDDSP (\ud83e\udd4925 \u00b7  \u2b50 2.3K) - DDSP: Differentiable Digital Signal Processing. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udce6 32 \u00b7 \ud83d\udccb 150 - 20% open \u00b7 \u23f1\ufe0f 04.10.2022):\ngit clone https://github.com/magenta/ddsp\n- PyPi (\ud83d\udce5 3.2K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 25.05.2022):\npip install ddsp\n- Conda (\ud83d\udce5 12K \u00b7 \u23f1\ufe0f 08.06.2020):\nconda install -c conda-forge ddsp\n\n\nDeepSpeech (\ud83e\udd4923 \u00b7  \u2b50 20K \u00b7 \ud83d\udcc9) - DeepSpeech is an open source embedded (offline, on-.. MPL-2.0 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 3.6K):\ngit clone https://github.com/mozilla/DeepSpeech\n- PyPi (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 40 \u00b7 \u23f1\ufe0f 19.12.2020):\npip install deepspeech\n- Conda (\ud83d\udce5 1.2K \u00b7 \u23f1\ufe0f 29.07.2021):\nconda install -c conda-forge deepspeech\n\n\nkapre (\ud83e\udd4922 \u00b7  \u2b50 870) - kapre: Keras Audio Preprocessors. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce5 22 \u00b7 \ud83d\udce6 1.9K \u00b7 \ud83d\udccb 95 - 13% open \u00b7 \u23f1\ufe0f 04.07.2022):\ngit clone https://github.com/keunwoochoi/kapre\n- PyPi (\ud83d\udce5 3.7K / month \u00b7 \ud83d\udce6 14 \u00b7 \u23f1\ufe0f 21.01.2022):\npip install kapre\n\n\nnnAudio (\ud83e\udd4921 \u00b7  \u2b50 760) - Audio processing by using pytorch 1D convolution network. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 72 \u00b7 \ud83d\udce6 68 \u00b7 \ud83d\udccb 53 - 22% open \u00b7 \u23f1\ufe0f 09.10.2022):\ngit clone https://github.com/KinWaiCheuk/nnAudio\n- PyPi (\ud83d\udce5 2.4K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 24.12.2021):\npip install nnAudio\n\n\nJulius (\ud83e\udd4918 \u00b7  \u2b50 300) - Fast PyTorch based DSP for audio and 1D signals. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 19 \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 11 - 18% open \u00b7 \u23f1\ufe0f 19.09.2022):\ngit clone https://github.com/adefossez/julius\n- PyPi (\ud83d\udce5 29K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 20.10.2021):\npip install julius\n\n\nShow 8 hidden projects...\n\naubio (\ud83e\udd4828 \u00b7  \u2b50 2.8K \u00b7 \ud83d\udca4) - a library for audio and music analysis. \u2757\ufe0fGPL-3.0\nEssentia (\ud83e\udd4926 \u00b7  \u2b50 2.2K) - C++ library for audio and music analysis, description and.. \u2757\ufe0fAGPL-3.0\npython_speech_features (\ud83e\udd4923 \u00b7  \u2b50 2.2K \u00b7 \ud83d\udc80) - This library provides common speech features for ASR.. MIT\nDejavu (\ud83e\udd4922 \u00b7  \u2b50 5.9K \u00b7 \ud83d\udc80) - Audio fingerprinting and recognition in Python. MIT\nTTS (\ud83e\udd4921 \u00b7  \u2b50 6.4K \u00b7 \ud83d\udc80) - Deep learning for Text to Speech (Discussion forum:.. MPL-2.0\nTimeSide (\ud83e\udd4921 \u00b7  \u2b50 340) - Scalable audio processing framework written in Python with a.. \u2757\ufe0fAGPL-3.0\nMuda (\ud83e\udd4917 \u00b7  \u2b50 210 \u00b7 \ud83d\udc80) - A library for augmenting annotated audio data. ISC\ntextlesslib (\ud83e\udd499 \u00b7  \u2b50 370 \u00b7 \ud83d\udca4) - Library for Textless Spoken Language Processing. MIT \n\nGeospatial Data\nLibraries to load, process, analyze, and write geographic data as well as libraries for spatial analysis, map visualization, and geocoding.\npydeck (\ud83e\udd4742 \u00b7  \u2b50 10K) - WebGL2 powered visualization framework. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 210 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce6 4.9K \u00b7 \ud83d\udccb 2.6K - 7% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/visgl/deck.gl\n- PyPi (\ud83d\udce5 930K / month \u00b7 \ud83d\udce6 24 \u00b7 \u23f1\ufe0f 25.10.2021):\npip install pydeck\n- Conda (\ud83d\udce5 230K \u00b7 \u23f1\ufe0f 04.11.2022):\nconda install -c conda-forge pydeck\n- npm (\ud83d\udce5 360K / month \u00b7 \ud83d\udce6 420 \u00b7 \u23f1\ufe0f 15.11.2022):\nnpm install deck.gl\n\n\nfolium (\ud83e\udd4739 \u00b7  \u2b50 6K) - Python Data. Leaflet.js Maps. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 150 \u00b7 \ud83d\udd00 2.1K \u00b7 \ud83d\udce6 19K \u00b7 \ud83d\udccb 1.1K - 21% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/python-visualization/folium\n- PyPi (\ud83d\udce5 860K / month \u00b7 \ud83d\udce6 680 \u00b7 \u23f1\ufe0f 19.11.2021):\npip install folium\n- Conda (\ud83d\udce5 1.4M \u00b7 \u23f1\ufe0f 07.10.2022):\nconda install -c conda-forge folium\n\n\nRasterio (\ud83e\udd4738 \u00b7  \u2b50 1.8K) - Rasterio reads and writes geospatial raster datasets. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 490 \u00b7 \ud83d\udce5 760 \u00b7 \ud83d\udce6 5.9K \u00b7 \ud83d\udccb 1.6K - 9% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/rasterio/rasterio\n- PyPi (\ud83d\udce5 1.5M / month \u00b7 \ud83d\udce6 800 \u00b7 \u23f1\ufe0f 06.07.2022):\npip install rasterio\n- Conda (\ud83d\udce5 1.9M \u00b7 \u23f1\ufe0f 17.11.2022):\nconda install -c conda-forge rasterio\n\n\nShapely (\ud83e\udd4837 \u00b7  \u2b50 3.1K) - Manipulation and analysis of geometric objects. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 490 \u00b7 \ud83d\udce5 330 \u00b7 \ud83d\udce6 35K \u00b7 \ud83d\udccb 960 - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/shapely/shapely\n- PyPi (\ud83d\udce5 8.1M / month \u00b7 \u23f1\ufe0f 03.08.2022):\npip install shapely\n- Conda (\ud83d\udce5 4.9M \u00b7 \u23f1\ufe0f 15.11.2022):\nconda install -c conda-forge shapely\n\n\ngeopy (\ud83e\udd4836 \u00b7  \u2b50 3.8K) - Geocoding library for Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 600 \u00b7 \ud83d\udccb 270 - 9% open \u00b7 \u23f1\ufe0f 13.11.2022):\ngit clone https://github.com/geopy/geopy\n- PyPi (\ud83d\udce5 4.5M / month \u00b7 \ud83d\udce6 3.9K \u00b7 \u23f1\ufe0f 11.07.2021):\npip install geopy\n- Conda (\ud83d\udce5 870K \u00b7 \u23f1\ufe0f 13.11.2022):\nconda install -c conda-forge geopy\n\n\nGeoPandas (\ud83e\udd4836 \u00b7  \u2b50 3.4K) - Python tools for geographic data. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 760 \u00b7 \ud83d\udce5 1.7K \u00b7 \ud83d\udccb 1.4K - 31% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/geopandas/geopandas\n- PyPi (\ud83d\udce5 2.9M / month \u00b7 \ud83d\udce6 1.2K \u00b7 \u23f1\ufe0f 21.06.2022):\npip install geopandas\n- Conda (\ud83d\udce5 2.2M \u00b7 \u23f1\ufe0f 04.11.2022):\nconda install -c conda-forge geopandas\n\n\npyproj (\ud83e\udd4836 \u00b7  \u2b50 820 \u00b7 \ud83d\udcc9) - Python interface to PROJ (cartographic projections and coordinate.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 55 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 17K \u00b7 \ud83d\udccb 530 - 3% open \u00b7 \u23f1\ufe0f 14.11.2022):\ngit clone https://github.com/pyproj4/pyproj\n- PyPi (\ud83d\udce5 5M / month \u00b7 \ud83d\udce6 1.7K \u00b7 \u23f1\ufe0f 22.04.2022):\npip install pyproj\n- Conda (\ud83d\udce5 4.7M \u00b7 \u23f1\ufe0f 28.10.2022):\nconda install -c conda-forge pyproj\n\n\nipyleaflet (\ud83e\udd4833 \u00b7  \u2b50 1.3K) - A Jupyter - Leaflet.js bridge. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 81 \u00b7 \ud83d\udd00 350 \u00b7 \ud83d\udce6 3.2K \u00b7 \ud83d\udccb 540 - 39% open \u00b7 \u23f1\ufe0f 27.10.2022):\ngit clone https://github.com/jupyter-widgets/ipyleaflet\n- PyPi (\ud83d\udce5 170K / month \u00b7 \ud83d\udce6 110 \u00b7 \u23f1\ufe0f 07.07.2022):\npip install ipyleaflet\n- Conda (\ud83d\udce5 920K \u00b7 \u23f1\ufe0f 19.10.2022):\nconda install -c conda-forge ipyleaflet\n- npm (\ud83d\udce5 58K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 19.10.2022):\nnpm install jupyter-leaflet\n\n\nFiona (\ud83e\udd4833 \u00b7  \u2b50 980 \u00b7 \ud83d\udca4) - Fiona reads and writes geographic data files. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 66 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 10K \u00b7 \ud83d\udccb 710 - 12% open \u00b7 \u23f1\ufe0f 01.03.2022):\ngit clone https://github.com/Toblerity/Fiona\n- PyPi (\ud83d\udce5 2.9M / month \u00b7 \ud83d\udce6 790 \u00b7 \u23f1\ufe0f 10.06.2022):\npip install fiona\n- Conda (\ud83d\udce5 3.7M \u00b7 \u23f1\ufe0f 04.11.2022):\nconda install -c conda-forge fiona\n\n\nArcGIS API (\ud83e\udd4929 \u00b7  \u2b50 1.5K) - Documentation and samples for ArcGIS API for Python. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 940 \u00b7 \ud83d\udce5 6.4K \u00b7 \ud83d\udccb 540 - 10% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/Esri/arcgis-python-api\n- PyPi (\ud83d\udce5 57K / month \u00b7 \ud83d\udce6 26 \u00b7 \u23f1\ufe0f 02.06.2022):\npip install arcgis\n- Docker Hub (\ud83d\udce5 7.5K \u00b7 \u2b50 37 \u00b7 \u23f1\ufe0f 17.06.2022):\ndocker pull esridocker/arcgis-api-python-notebook\n\n\ngeojson (\ud83e\udd4928 \u00b7  \u2b50 760) - Python bindings and utilities for GeoJSON. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 11K \u00b7 \ud83d\udccb 87 - 26% open \u00b7 \u23f1\ufe0f 13.11.2022):\ngit clone https://github.com/jazzband/geojson\n- PyPi (\ud83d\udce5 850K / month \u00b7 \ud83d\udce6 1.1K \u00b7 \u23f1\ufe0f 09.08.2019):\npip install geojson\n- Conda (\ud83d\udce5 620K \u00b7 \u23f1\ufe0f 11.08.2019):\nconda install -c conda-forge geojson\n\n\nPySAL (\ud83e\udd4926 \u00b7  \u2b50 1.1K) - PySAL: Python Spatial Analysis Library Meta-Package. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 77 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udccb 610 - 1% open \u00b7 \u23f1\ufe0f 23.07.2022):\ngit clone https://github.com/pysal/pysal\n- PyPi (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 32 \u00b7 \u23f1\ufe0f 30.01.2022):\npip install pysal\n- Conda (\ud83d\udce5 460K \u00b7 \u23f1\ufe0f 01.08.2022):\nconda install -c conda-forge pysal\n\n\nGeoViews (\ud83e\udd4926 \u00b7  \u2b50 440) - Simple, concise geographical visualization in Python. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 68 \u00b7 \ud83d\udce6 510 \u00b7 \ud83d\udccb 310 - 35% open \u00b7 \u23f1\ufe0f 18.11.2022):\ngit clone https://github.com/holoviz/geoviews\n- PyPi (\ud83d\udce5 7.4K / month \u00b7 \ud83d\udce6 28 \u00b7 \u23f1\ufe0f 08.03.2022):\npip install geoviews\n- Conda (\ud83d\udce5 140K \u00b7 \u23f1\ufe0f 08.03.2022):\nconda install -c conda-forge geoviews\n\n\nEarthPy (\ud83e\udd4925 \u00b7  \u2b50 410 \u00b7 \ud83d\udca4) - A package built to support working with spatial data using open.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 41 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 230 - 8% open \u00b7 \u23f1\ufe0f 20.12.2021):\ngit clone https://github.com/earthlab/earthpy\n- PyPi (\ud83d\udce5 6.2K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 01.10.2021):\npip install earthpy\n- Conda (\ud83d\udce5 55K \u00b7 \u23f1\ufe0f 04.10.2021):\nconda install -c conda-forge earthpy\n\n\nShow 8 hidden projects...\n\nGeocoder (\ud83e\udd4932 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Python Geocoder. MIT\nSatpy (\ud83e\udd4930 \u00b7  \u2b50 880) - Python package for earth-observing satellite data processing. \u2757\ufe0fGPL-3.0\nSentinelsat (\ud83e\udd4926 \u00b7  \u2b50 830) - Search and download Copernicus Sentinel satellite images. \u2757\ufe0fGPL-3.0\npymap3d (\ud83e\udd4924 \u00b7  \u2b50 290) - pure-Python (Numpy optional) 3D coordinate conversions for geospace ecef.. BSD-2\nprettymaps (\ud83e\udd4923 \u00b7  \u2b50 8.9K) - A small set of Python functions to draw pretty maps from.. \u2757\ufe0fAGPL-3.0\ngmaps (\ud83e\udd4923 \u00b7  \u2b50 750 \u00b7 \ud83d\udc80) - Google maps for Jupyter notebooks. BSD-3 \nMapbox GL (\ud83e\udd4923 \u00b7  \u2b50 620 \u00b7 \ud83d\udc80) - Use Mapbox GL JS to visualize data in a Python Jupyter notebook. MIT \ngeoplotlib (\ud83e\udd4921 \u00b7  \u2b50 980 \u00b7 \ud83d\udc80) - python toolbox for visualizing geographical data and making maps. MIT\n\nFinancial Data\nLibraries for algorithmic stock/crypto trading, risk analytics, backtesting, technical analysis, and other tasks on financial data.\nyfinance (\ud83e\udd4737 \u00b7  \u2b50 8K) - Download market data from Yahoo! Finances API. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 65 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce6 15K \u00b7 \ud83d\udccb 890 - 49% open \u00b7 \u23f1\ufe0f 19.11.2022):\ngit clone https://github.com/ranaroussi/yfinance\n- PyPi (\ud83d\udce5 590K / month \u00b7 \ud83d\udce6 140 \u00b7 \u23f1\ufe0f 16.06.2022):\npip install yfinance\n- Conda (\ud83d\udce5 62K \u00b7 \u23f1\ufe0f 10.07.2021):\nconda install -c ranaroussi yfinance\n\n\nQlib (\ud83e\udd4731 \u00b7  \u2b50 10K) - Qlib is an AI-oriented quantitative investment platform, which aims to.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 1.8K \u00b7 \ud83d\udce5 330 \u00b7 \ud83d\udce6 28 \u00b7 \ud83d\udccb 690 - 32% open \u00b7 \u23f1\ufe0f 20.11.2022):\ngit clone https://github.com/microsoft/qlib\n- PyPi (\ud83d\udce5 3K / month \u00b7 \u23f1\ufe0f 15.06.2022):\npip install pyqlib\n\n\nta (\ud83e\udd4829 \u00b7  \u2b50 3.3K) - Technical Analysis Library using Pandas and Numpy. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 740 \u00b7 \ud83d\udce6 1.5K \u00b7 \ud83d\udccb 220 - 54% open \u00b7 \u23f1\ufe0f 23.08.2022):\ngit clone https://github.com/bukosabino/ta\n- PyPi (\ud83d\udce5 93K / month \u00b7 \ud83d\udce6 34 \u00b7 \u23f1\ufe0f 16.04.2022):\npip install ta\n- Conda (\ud83d\udce5 9K \u00b7 \u23f1\ufe0f 23.08.2022):\nconda install -c conda-forge ta\n\n\nIB-insync (\ud83e\udd4829 \u00b7  \u2b50 2K) - Python sync/async framework for Interactive Brokers API. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 510 \u00b7 \ud83d\udccb 440 - 1% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/erdewit/ib_insync\n- PyPi (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 22 \u00b7 \u23f1\ufe0f 28.11.2021):\npip install ib_insync\n- Conda (\ud83d\udce5 24K \u00b7 \u23f1\ufe0f 19.11.2022):\nconda install -c conda-forge ib-insync\n\n\nffn (\ud83e\udd4827 \u00b7  \u2b50 1.4K) - ffn - a financial function library for Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 250 \u00b7 \ud83d\udccb 100 - 19% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/pmorissette/ffn\n- PyPi (\ud83d\udce5 210K / month \u00b7 \ud83d\udce6 25 \u00b7 \u23f1\ufe0f 21.04.2021):\npip install ffn\n- Conda (\ud83d\udce5 2K \u00b7 \u23f1\ufe0f 22.04.2021):\nconda install -c conda-forge ffn\n\n\nbt (\ud83e\udd4926 \u00b7  \u2b50 1.5K) - bt - flexible backtesting for Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 340 \u00b7 \ud83d\udce6 150 \u00b7 \ud83d\udccb 310 - 22% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/pmorissette/bt\n- PyPi (\ud83d\udce5 5K / month \u00b7 \ud83d\udce6 21 \u00b7 \u23f1\ufe0f 21.04.2021):\npip install bt\n- Conda (\ud83d\udce5 9.7K \u00b7 \u23f1\ufe0f 12.11.2022):\nconda install -c conda-forge bt\n\n\nTensorTrade (\ud83e\udd4925 \u00b7  \u2b50 4K) - An open source reinforcement learning framework for training,.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 61 \u00b7 \ud83d\udd00 930 \u00b7 \ud83d\udce6 36 \u00b7 \ud83d\udccb 240 - 17% open \u00b7 \u23f1\ufe0f 23.08.2022):\ngit clone https://github.com/tensortrade-org/tensortrade\n- PyPi (\ud83d\udce5 430 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 10.05.2021):\npip install tensortrade\n- Conda (\ud83d\udce5 1.9K \u00b7 \u23f1\ufe0f 10.05.2021):\nconda install -c conda-forge tensortrade\n\n\nstockstats (\ud83e\udd4924 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udcc8) - Supply a wrapper StockDataFrame based on the.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udce6 560 \u00b7 \ud83d\udccb 94 - 17% open \u00b7 \u23f1\ufe0f 19.11.2022):\ngit clone https://github.com/jealous/stockstats\n- PyPi (\ud83d\udce5 7.4K / month \u00b7 \ud83d\udce6 29 \u00b7 \u23f1\ufe0f 07.01.2022):\npip install stockstats\n\n\nCrypto Signals (\ud83e\udd4923 \u00b7  \u2b50 4.2K) - Github.com/CryptoSignal - Trading & Technical Analysis Bot -.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udccb 260 - 22% open \u00b7 \u23f1\ufe0f 09.08.2022):\ngit clone https://github.com/CryptoSignal/crypto-signal\n- Docker Hub (\ud83d\udce5 140K \u00b7 \u2b50 8 \u00b7 \u23f1\ufe0f 03.09.2020):\ndocker pull shadowreaver/crypto-signal\n\n\ntf-quant-finance (\ud83e\udd4922 \u00b7  \u2b50 3.4K) - High-performance TensorFlow library for quantitative.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 43 \u00b7 \ud83d\udd00 460 \u00b7 \ud83d\udccb 49 - 48% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/google/tf-quant-finance\n- PyPi (\ud83d\udce5 740 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 31.05.2022):\npip install tf-quant-finance\n\n\nfinmarketpy (\ud83e\udd4919 \u00b7  \u2b50 3K \u00b7 \ud83d\udca4) - Python library for backtesting trading strategies & analyzing.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 450 \u00b7 \ud83d\udce5 42 \u00b7 \ud83d\udce6 5 \u00b7 \ud83d\udccb 26 - 88% open \u00b7 \u23f1\ufe0f 05.04.2022):\ngit clone https://github.com/cuemacro/finmarketpy\n- PyPi (\ud83d\udce5 100 / month \u00b7 \u23f1\ufe0f 07.10.2021):\npip install finmarketpy\n\n\nShow 14 hidden projects...\n\nzipline (\ud83e\udd4733 \u00b7  \u2b50 16K \u00b7 \ud83d\udc80) - Zipline, a Pythonic Algorithmic Trading Library. Apache-2\npyfolio (\ud83e\udd4830 \u00b7  \u2b50 4.7K \u00b7 \ud83d\udc80) - Portfolio and risk analytics in Python. Apache-2\nbacktrader (\ud83e\udd4829 \u00b7  \u2b50 9.6K \u00b7 \ud83d\udc80) - Python Backtesting library for trading strategies. \u2757\ufe0fGPL-3.0\narch (\ud83e\udd4829 \u00b7  \u2b50 1K) - ARCH models in Python. \u2757\ufe0fNCSA\nAlpha Vantage (\ud83e\udd4827 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udc80) - A python wrapper for Alpha Vantage API for financial data. MIT\nAlphalens (\ud83e\udd4827 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udc80) - Performance analysis of predictive (alpha) stock factors. Apache-2\nEnigma Catalyst (\ud83e\udd4926 \u00b7  \u2b50 2.4K \u00b7 \ud83d\udc80) - An Algorithmic Trading Library for Crypto-Assets in.. Apache-2\nempyrical (\ud83e\udd4926 \u00b7  \u2b50 990 \u00b7 \ud83d\udc80) - Common financial risk and performance metrics. Used by zipline.. Apache-2\nPyAlgoTrade (\ud83e\udd4924 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udc80) - Python Algorithmic Trading Library. Apache-2\nFinTA (\ud83e\udd4923 \u00b7  \u2b50 1.8K \u00b7 \ud83d\udcc8) - Common financial technical indicators implemented in Pandas. \u2757\ufe0fLGPL-3.0\nBacktesting.py (\ud83e\udd4920 \u00b7  \u2b50 3K \u00b7 \ud83d\udca4) - Backtest trading strategies in Python. \u2757\ufe0fAGPL-3.0\nFinQuant (\ud83e\udd4919 \u00b7  \u2b50 860 \u00b7 \ud83d\udc80) - A program for financial portfolio management, analysis and.. MIT\nsurpriver (\ud83e\udd4912 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Find big moving stocks before they move using machine.. \u2757\ufe0fGPL-3.0\npyrtfolio (\ud83e\udd497 \u00b7  \u2b50 120 \u00b7 \ud83d\udc80) - Python package to generate stock portfolios. \u2757\ufe0fGPL-3.0\n\nTime Series Data\nLibraries for forecasting, anomaly detection, feature extraction, and machine learning on time-series and sequential data.\nProphet (\ud83e\udd4736 \u00b7  \u2b50 15K) - Tool for producing high quality forecasts for time series data that has.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 4.3K \u00b7 \ud83d\udce5 1K \u00b7 \ud83d\udccb 1.9K - 14% open \u00b7 \u23f1\ufe0f 21.09.2022):\ngit clone https://github.com/facebook/prophet\n- PyPi (\ud83d\udce5 1.5M / month \u00b7 \ud83d\udce6 130 \u00b7 \u23f1\ufe0f 05.09.2020):\npip install fbprophet\n- Conda (\ud83d\udce5 210K \u00b7 \u23f1\ufe0f 10.09.2022):\nconda install -c conda-forge prophet\n\n\nsktime (\ud83e\udd4735 \u00b7  \u2b50 5.9K) - A unified framework for machine learning with time series. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 950 \u00b7 \ud83d\udce5 76 \u00b7 \ud83d\udce6 700 \u00b7 \ud83d\udccb 1.5K - 32% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/alan-turing-institute/sktime\n- PyPi (\ud83d\udce5 400K / month \u00b7 \ud83d\udce6 26 \u00b7 \u23f1\ufe0f 29.06.2022):\npip install sktime\n- Conda (\ud83d\udce5 85K \u00b7 \u23f1\ufe0f 05.10.2022):\nconda install -c conda-forge sktime-all-extras\n\n\nNeuralProphet (\ud83e\udd4733 \u00b7  \u2b50 2.6K) - NeuralProphet: A simple forecasting package. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 350 \u00b7 \ud83d\udce6 140 \u00b7 \ud83d\udccb 380 - 28% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/ourownstory/neural_prophet\n- PyPi (\ud83d\udce5 100K / month \u00b7 \u23f1\ufe0f 22.03.2022):\npip install neuralprophet\n\n\npmdarima (\ud83e\udd4832 \u00b7  \u2b50 1.3K) - A statistical library designed to fill the void in Pythons time series.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 2.8K \u00b7 \ud83d\udccb 300 - 10% open \u00b7 \u23f1\ufe0f 03.11.2022):\ngit clone https://github.com/alkaline-ml/pmdarima\n- PyPi (\ud83d\udce5 1.7M / month \u00b7 \ud83d\udce6 57 \u00b7 \u23f1\ufe0f 22.02.2022):\npip install pmdarima\n- Conda (\ud83d\udce5 140K \u00b7 \u23f1\ufe0f 24.08.2022):\nconda install -c conda-forge pmdarima\n\n\nSTUMPY (\ud83e\udd4831 \u00b7  \u2b50 2.4K) - STUMPY is a powerful and scalable Python library for modern time series.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 300 \u00b7 \ud83d\udccb 360 - 12% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/TDAmeritrade/stumpy\n- PyPi (\ud83d\udce5 190K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 31.03.2022):\npip install stumpy\n- Conda (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 31.03.2022):\nconda install -c conda-forge stumpy\n\n\nDarts (\ud83e\udd4830 \u00b7  \u2b50 5K) - A python library for easy manipulation and forecasting of time series. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 69 \u00b7 \ud83d\udd00 540 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 760 - 28% open \u00b7 \u23f1\ufe0f 20.11.2022):\ngit clone https://github.com/unit8co/darts\n- PyPi (\ud83d\udce5 8.1K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 22.06.2022):\npip install u8darts\n- Conda (\ud83d\udce5 18K \u00b7 \u23f1\ufe0f 05.10.2022):\nconda install -c conda-forge u8darts-all\n- Docker Hub (\ud83d\udce5 360 \u00b7 \u23f1\ufe0f 04.10.2022):\ndocker pull unit8/darts\n\n\nGluonTS (\ud83e\udd4830 \u00b7  \u2b50 3.2K) - Probabilistic time series modeling in Python. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 97 \u00b7 \ud83d\udd00 640 \u00b7 \ud83d\udccb 780 - 31% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/awslabs/gluon-ts\n- PyPi (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 30.06.2022):\npip install gluonts\n- Conda (\ud83d\udce5 190 \u00b7 \u23f1\ufe0f 14.10.2021):\nconda install -c anaconda gluonts\n\n\npytorch-forecasting (\ud83e\udd4830 \u00b7  \u2b50 2.4K) - Time series forecasting with PyTorch. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 380 \u00b7 \ud83d\udccb 540 - 52% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/jdb78/pytorch-forecasting\n- PyPi (\ud83d\udce5 130K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 23.05.2022):\npip install pytorch-forecasting\n- Conda (\ud83d\udce5 32K \u00b7 \u23f1\ufe0f 23.05.2022):\nconda install -c conda-forge pytorch-forecasting\n\n\ntslearn (\ud83e\udd4830 \u00b7  \u2b50 2.3K) - A machine learning toolkit dedicated to time-series data. BSD-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 40 \u00b7 \ud83d\udd00 300 \u00b7 \ud83d\udce6 620 \u00b7 \ud83d\udccb 290 - 35% open \u00b7 \u23f1\ufe0f 27.10.2022):\ngit clone https://github.com/tslearn-team/tslearn\n- PyPi (\ud83d\udce5 140K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 16.08.2021):\npip install tslearn\n- Conda (\ud83d\udce5 400K \u00b7 \u23f1\ufe0f 15.01.2022):\nconda install -c conda-forge tslearn\n\n\ntsfresh (\ud83e\udd4829 \u00b7  \u2b50 6.9K) - Automatic extraction of relevant features from time series:. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udccb 510 - 12% open \u00b7 \u23f1\ufe0f 18.11.2022):\ngit clone https://github.com/blue-yonder/tsfresh\n- PyPi (\ud83d\udce5 320K / month \u00b7 \ud83d\udce6 60 \u00b7 \u23f1\ufe0f 21.12.2021):\npip install tsfresh\n- Conda (\ud83d\udce5 360K \u00b7 \u23f1\ufe0f 21.12.2021):\nconda install -c conda-forge tsfresh\n\n\nStatsForecast (\ud83e\udd4828 \u00b7  \u2b50 1.6K) - Lightning fast forecasting with statistical and econometric.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 92 \u00b7 \ud83d\udccb 120 - 40% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/Nixtla/statsforecast\n- PyPi (\ud83d\udce5 240K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 27.06.2022):\npip install statsforecast\n- Conda (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 15.11.2022):\nconda install -c conda-forge statsforecast\n\n\npyts (\ud83e\udd4926 \u00b7  \u2b50 1.4K) - A Python package for time series classification. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce6 280 \u00b7 \ud83d\udccb 68 - 55% open \u00b7 \u23f1\ufe0f 16.06.2022):\ngit clone https://github.com/johannfaouzi/pyts\n- PyPi (\ud83d\udce5 91K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 31.10.2021):\npip install pyts\n- Conda (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 31.10.2021):\nconda install -c conda-forge pyts\n\n\nStreamz (\ud83e\udd4926 \u00b7  \u2b50 1.1K) - Real-time stream processing for python. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 46 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce6 340 \u00b7 \ud83d\udccb 250 - 41% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/python-streamz/streamz\n- PyPi (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 35 \u00b7 \u23f1\ufe0f 04.10.2021):\npip install streamz\n- Conda (\ud83d\udce5 460K \u00b7 \u23f1\ufe0f 28.07.2022):\nconda install -c conda-forge streamz\n\n\nuber/orbit (\ud83e\udd4924 \u00b7  \u2b50 1.5K) - A Python package for Bayesian forecasting with object-oriented.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 380 - 15% open \u00b7 \u23f1\ufe0f 14.09.2022):\ngit clone https://github.com/uber/orbit\n- PyPi (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 28.04.2022):\npip install orbit-ml\n- Conda (\ud83d\udce5 1.9K \u00b7 \u23f1\ufe0f 08.03.2022):\nconda install -c conda-forge orbit-ml\n\n\nNeuralForecast (\ud83e\udd4923 \u00b7  \u2b50 970) - Scalable and user friendly neural forecasting algorithms for.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 88 \u00b7 \ud83d\udce6 5 \u00b7 \ud83d\udccb 120 - 16% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/Nixtla/neuralforecast\n- PyPi (\ud83d\udce5 4.2K / month \u00b7 \u23f1\ufe0f 02.06.2022):\npip install neuralforecast\n- Conda (\ud83d\udce5 3.3K \u00b7 \u23f1\ufe0f 09.11.2022):\nconda install -c conda-forge neuralforecast\n\n\nTSFEL (\ud83e\udd4922 \u00b7  \u2b50 570 \u00b7 \ud83d\udca4) - An intuitive library to extract features from time series. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 44 \u00b7 \ud83d\udccb 62 - 29% open \u00b7 \u23f1\ufe0f 16.03.2022):\ngit clone https://github.com/fraunhoferportugal/tsfel\n- PyPi (\ud83d\udce5 8.1K / month \u00b7 \u23f1\ufe0f 14.02.2021):\npip install tsfel\n\n\ngreykite (\ud83e\udd4921 \u00b7  \u2b50 1.6K) - A flexible, intuitive and fast forecasting library. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 84 \u00b7 \ud83d\udce6 12 \u00b7 \ud83d\udccb 79 - 20% open \u00b7 \u23f1\ufe0f 31.08.2022):\ngit clone https://github.com/linkedin/greykite\n- PyPi (\ud83d\udce5 23K / month \u00b7 \u23f1\ufe0f 15.12.2021):\npip install greykite\n\n\nseglearn (\ud83e\udd4921 \u00b7  \u2b50 530) - Python module for machine learning time series:. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 62 \u00b7 \ud83d\udce6 17 \u00b7 \ud83d\udccb 29 - 20% open \u00b7 \u23f1\ufe0f 27.08.2022):\ngit clone https://github.com/dmbee/seglearn\n- PyPi (\ud83d\udce5 3.7K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 13.03.2021):\npip install seglearn\n\n\nAuto TS (\ud83e\udd4919 \u00b7  \u2b50 510) - Automatically build ARIMA, SARIMAX, VAR, FB Prophet and XGBoost.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 92 \u00b7 \ud83d\udccb 78 - 10% open \u00b7 \u23f1\ufe0f 16.08.2022):\ngit clone https://github.com/AutoViML/Auto_TS\n- PyPi (\ud83d\udce5 6.5K / month \u00b7 \u23f1\ufe0f 31.01.2022):\npip install auto-ts\n\n\natspy (\ud83e\udd4915 \u00b7  \u2b50 460 \u00b7 \ud83d\udca4) - AtsPy: Automated Time Series Models in Python (by @firmai). MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 87 \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 22 - 90% open \u00b7 \u23f1\ufe0f 18.12.2021):\ngit clone https://github.com/firmai/atspy\n- PyPi (\ud83d\udce5 310 / month \u00b7 \u23f1\ufe0f 24.04.2020):\npip install atspy\n\n\nShow 8 hidden projects...\n\nPyFlux (\ud83e\udd4924 \u00b7  \u2b50 2K \u00b7 \ud83d\udc80) - Open source time series library for Python. BSD-3\nluminol (\ud83e\udd4921 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - Anomaly Detection and Correlation library. Apache-2\npydlm (\ud83e\udd4920 \u00b7  \u2b50 430 \u00b7 \ud83d\udc80) - A python library for Bayesian time series modeling. BSD-3\ntick (\ud83e\udd4920 \u00b7  \u2b50 400 \u00b7 \ud83d\udc80) - Module for statistical learning, with a particular emphasis on time-.. BSD-3\nADTK (\ud83e\udd4919 \u00b7  \u2b50 880 \u00b7 \ud83d\udc80) - A Python toolkit for rule-based/unsupervised anomaly detection in time.. MPL-2.0\nmatrixprofile-ts (\ud83e\udd4919 \u00b7  \u2b50 690 \u00b7 \ud83d\udc80) - A Python library for detecting patterns and anomalies.. Apache-2\ntsflex (\ud83e\udd4917 \u00b7  \u2b50 190) - Flexible time series feature extraction & processing. MIT\ntsaug (\ud83e\udd4913 \u00b7  \u2b50 270 \u00b7 \ud83d\udc80) - A Python package for time series augmentation. Apache-2\n\nMedical Data\nLibraries for processing and analyzing medical data such as MRIs, EEGs, genomic data, and other medical imaging formats.\nMNE (\ud83e\udd4737 \u00b7  \u2b50 2.1K) - MNE: Magnetoencephalography (MEG) and Electroencephalography (EEG) in Python. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 320 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 2K \u00b7 \ud83d\udccb 4.3K - 10% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/mne-tools/mne-python\n- PyPi (\ud83d\udce5 42K / month \u00b7 \ud83d\udce6 220 \u00b7 \u23f1\ufe0f 12.05.2022):\npip install mne\n- Conda (\ud83d\udce5 250K \u00b7 \u23f1\ufe0f 11.11.2022):\nconda install -c conda-forge mne\n\n\nNIPYPE (\ud83e\udd4735 \u00b7  \u2b50 650) - Workflows and interfaces for neuroimaging packages. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 510 \u00b7 \ud83d\udce6 1.1K \u00b7 \ud83d\udccb 1.3K - 29% open \u00b7 \u23f1\ufe0f 17.10.2022):\ngit clone https://github.com/nipy/nipype\n- PyPi (\ud83d\udce5 57K / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 06.06.2022):\npip install nipype\n- Conda (\ud83d\udce5 520K \u00b7 \u23f1\ufe0f 06.11.2022):\nconda install -c conda-forge nipype\n\n\nMONAI (\ud83e\udd4834 \u00b7  \u2b50 3.6K) - AI Toolkit for Healthcare Imaging. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 680 \u00b7 \ud83d\udce6 590 \u00b7 \ud83d\udccb 2.1K - 11% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/Project-MONAI/MONAI\n- PyPi (\ud83d\udce5 44K / month \u00b7 \ud83d\udce6 20 \u00b7 \u23f1\ufe0f 13.06.2022):\npip install monai\n- Conda (\ud83d\udce5 6.7K \u00b7 \u23f1\ufe0f 24.10.2022):\nconda install -c conda-forge monai\n\n\nLifelines (\ud83e\udd4834 \u00b7  \u2b50 2K) - Survival analysis in Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 510 \u00b7 \ud83d\udce6 1.2K \u00b7 \ud83d\udccb 890 - 26% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/CamDavidsonPilon/lifelines\n- PyPi (\ud83d\udce5 480K / month \u00b7 \ud83d\udce6 110 \u00b7 \u23f1\ufe0f 26.06.2022):\npip install lifelines\n- Conda (\ud83d\udce5 230K \u00b7 \u23f1\ufe0f 17.11.2022):\nconda install -c conda-forge lifelines\n\n\nNilearn (\ud83e\udd4834 \u00b7  \u2b50 900) - Machine learning for NeuroImaging in Python. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 470 \u00b7 \ud83d\udce5 73 \u00b7 \ud83d\udce6 1.8K \u00b7 \ud83d\udccb 1.7K - 16% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/nilearn/nilearn\n- PyPi (\ud83d\udce5 35K / month \u00b7 \ud83d\udce6 240 \u00b7 \u23f1\ufe0f 13.04.2022):\npip install nilearn\n- Conda (\ud83d\udce5 200K \u00b7 \u23f1\ufe0f 24.08.2022):\nconda install -c conda-forge nilearn\n\n\nHail (\ud83e\udd4833 \u00b7  \u2b50 840) - Scalable genomic data analysis. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 85 \u00b7 \ud83d\udccb 2.1K - 2% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/hail-is/hail\n- PyPi (\ud83d\udce5 46K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 07.07.2022):\npip install hail\n\n\nNiBabel (\ud83e\udd4833 \u00b7  \u2b50 500) - Python package to access a cacophony of neuro-imaging file formats. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 94 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udccb 470 - 30% open \u00b7 \u23f1\ufe0f 20.11.2022):\ngit clone https://github.com/nipy/nibabel\n- PyPi (\ud83d\udce5 220K / month \u00b7 \ud83d\udce6 1K \u00b7 \u23f1\ufe0f 18.06.2022):\npip install nibabel\n- Conda (\ud83d\udce5 500K \u00b7 \u23f1\ufe0f 31.08.2022):\nconda install -c conda-forge nibabel\n\n\nDIPY (\ud83e\udd4830 \u00b7  \u2b50 550) - DIPY is the paragon 3D/4D+ imaging library in Python. Contains generic.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udce6 630 \u00b7 \ud83d\udccb 830 - 18% open \u00b7 \u23f1\ufe0f 02.11.2022):\ngit clone https://github.com/dipy/dipy\n- PyPi (\ud83d\udce5 13K / month \u00b7 \ud83d\udce6 80 \u00b7 \u23f1\ufe0f 11.03.2022):\npip install dipy\n- Conda (\ud83d\udce5 340K \u00b7 \u23f1\ufe0f 15.03.2022):\nconda install -c conda-forge dipy\n\n\nDeepVariant (\ud83e\udd4925 \u00b7  \u2b50 2.7K) - DeepVariant is an analysis pipeline that uses a deep neural.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 640 \u00b7 \ud83d\udce5 4.2K \u00b7 \ud83d\udccb 540 - 1% open \u00b7 \u23f1\ufe0f 17.10.2022):\ngit clone https://github.com/google/deepvariant\n- Conda (\ud83d\udce5 46K \u00b7 \u23f1\ufe0f 05.06.2022):\nconda install -c bioconda deepvariant\n\n\npyRiemann (\ud83e\udd4924 \u00b7  \u2b50 440) - Python machine learning package based on sklearn API for multivariate.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 96 - 16% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/pyRiemann/pyRiemann\n- PyPi (\ud83d\udce5 23K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 27.06.2021):\npip install pyriemann\n\n\nMedical Detection Toolkit (\ud83e\udd4915 \u00b7  \u2b50 1.2K \u00b7 \ud83d\udca4) - The Medical Detection Toolkit contains 2D + 3D.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udccb 130 - 33% open \u00b7 \u23f1\ufe0f 04.04.2022):\ngit clone https://github.com/MIC-DKFZ/medicaldetectiontoolkit\n\n\nShow 9 hidden projects...\n\nNiftyNet (\ud83e\udd4925 \u00b7  \u2b50 1.3K \u00b7 \ud83d\udc80) - [unmaintained] An open-source convolutional neural.. Apache-2 \nMedPy (\ud83e\udd4923 \u00b7  \u2b50 440) - Medical image processing in Python. \u2757\ufe0fGPL-3.0\nNIPY (\ud83e\udd4923 \u00b7  \u2b50 320 \u00b7 \ud83d\udc80) - Neuroimaging in Python FMRI analysis package. BSD-3\nDLTK (\ud83e\udd4922 \u00b7  \u2b50 1.3K \u00b7 \ud83d\udc80) - Deep Learning Toolkit for Medical Image Analysis. Apache-2 \nBrainiak (\ud83e\udd4921 \u00b7  \u2b50 290 \u00b7 \ud83d\udc80) - Brain Imaging Analysis Kit. Apache-2\nGlow (\ud83e\udd4919 \u00b7  \u2b50 220) - An open-source toolkit for large-scale genomic analysis. Apache-2\nMedicalTorch (\ud83e\udd4916 \u00b7  \u2b50 790 \u00b7 \ud83d\udc80) - A medical imaging framework for Pytorch. Apache-2 \nDeepNeuro (\ud83e\udd4913 \u00b7  \u2b50 110 \u00b7 \ud83d\udc80) - A deep learning python package for neuroimaging data. Made by:. MIT\nMedicalNet (\ud83e\udd4912 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Many studies have shown that the performance on deep learning is.. MIT\n\nTabular Data\nLibraries for processing tabular and structured data.\ncarefree-learn (\ud83e\udd4722 \u00b7  \u2b50 380) - Deep Learning PyTorch. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 1 \u00b7 \ud83d\udd00 35 \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/carefree0910/carefree-learn\n- PyPi (\ud83d\udce5 1.1K / month \u00b7 \u23f1\ufe0f 20.06.2022):\npip install carefree-learn\n\n\npytorch_tabular (\ud83e\udd4917 \u00b7  \u2b50 780) - A standard framework for modelling Deep Learning Models.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 83 \u00b7 \ud83d\udccb 79 - 30% open \u00b7 \u23f1\ufe0f 02.11.2022):\ngit clone https://github.com/manujosephv/pytorch_tabular\n- PyPi (\ud83d\udce5 1.7K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 01.09.2021):\npip install pytorch_tabular\n\n\ndeltapy (\ud83e\udd4911 \u00b7  \u2b50 460 \u00b7 \ud83d\udca4) - DeltaPy - Tabular Data Augmentation (by @firmai). MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 46 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 3 - 66% open \u00b7 \u23f1\ufe0f 01.03.2022):\ngit clone https://github.com/firmai/deltapy\n- PyPi (\ud83d\udce5 61 / month \u00b7 \u23f1\ufe0f 09.04.2020):\npip install deltapy\n\n\nShow 2 hidden projects...\n\nmiceforest (\ud83e\udd4821 \u00b7  \u2b50 200) - Multiple Imputation with LightGBM in Python. MIT\nupgini (\ud83e\udd4919 \u00b7  \u2b50 160) - Free automated data enrichment library for machine learning searches.. BSD-3\n\nOptical Character Recognition\nLibraries for optical character recognition (OCR) and text extraction from images or videos.\nPaddleOCR (\ud83e\udd4738 \u00b7  \u2b50 27K) - Awesome multilingual OCR toolkits based on PaddlePaddle.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 5.5K \u00b7 \ud83d\udce6 960 \u00b7 \ud83d\udccb 6K - 22% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/PaddlePaddle/PaddleOCR\n- PyPi (\ud83d\udce5 45K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 10.05.2022):\npip install paddleocr\n\n\nEasyOCR (\ud83e\udd4735 \u00b7  \u2b50 16K) - Ready-to-use OCR with 80+ supported languages and all popular writing.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 2.3K \u00b7 \ud83d\udce5 2.7M \u00b7 \ud83d\udce6 1.8K \u00b7 \ud83d\udccb 680 - 19% open \u00b7 \u23f1\ufe0f 18.11.2022):\ngit clone https://github.com/JaidedAI/EasyOCR\n- PyPi (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 37 \u00b7 \u23f1\ufe0f 20.09.2022):\npip install easyocr\n\n\nTesseract (\ud83e\udd4833 \u00b7  \u2b50 4.5K) - Python-tesseract is an optical character recognition (OCR) tool.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 43 \u00b7 \ud83d\udd00 630 \u00b7 \ud83d\udccb 320 - 6% open \u00b7 \u23f1\ufe0f 19.11.2022):\ngit clone https://github.com/madmaze/pytesseract\n- PyPi (\ud83d\udce5 660K / month \u00b7 \ud83d\udce6 960 \u00b7 \u23f1\ufe0f 19.02.2022):\npip install pytesseract\n- Conda (\ud83d\udce5 540K \u00b7 \u23f1\ufe0f 15.03.2022):\nconda install -c conda-forge pytesseract\n\n\nOCRmyPDF (\ud83e\udd4829 \u00b7  \u2b50 7.7K) - OCRmyPDF adds an OCR text layer to scanned PDF files, allowing them.. MPL-2.0\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 74 \u00b7 \ud83d\udd00 630 \u00b7 \ud83d\udccb 910 - 10% open \u00b7 \u23f1\ufe0f 04.10.2022):\ngit clone https://github.com/ocrmypdf/OCRmyPDF\n- PyPi (\ud83d\udce5 24K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 04.07.2022):\npip install ocrmypdf\n- Conda (\ud83d\udce5 32K \u00b7 \u23f1\ufe0f 04.10.2022):\nconda install -c conda-forge ocrmypdf\n\n\nMMOCR (\ud83e\udd4828 \u00b7  \u2b50 3K) - OpenMMLab Text Detection, Recognition and Understanding Toolbox. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 67 \u00b7 \ud83d\udd00 550 \u00b7 \ud83d\udce6 33 \u00b7 \ud83d\udccb 780 - 16% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/open-mmlab/mmocr\n- PyPi (\ud83d\udce5 14K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 05.05.2022):\npip install mmocr\n\n\ntesserocr (\ud83e\udd4828 \u00b7  \u2b50 1.7K) - A Python wrapper for the tesseract-ocr API. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 730 \u00b7 \ud83d\udccb 250 - 31% open \u00b7 \u23f1\ufe0f 26.08.2022):\ngit clone https://github.com/sirfz/tesserocr\n- PyPi (\ud83d\udce5 47K / month \u00b7 \ud83d\udce6 67 \u00b7 \u23f1\ufe0f 19.06.2021):\npip install tesserocr\n- Conda (\ud83d\udce5 93K \u00b7 \u23f1\ufe0f 06.11.2022):\nconda install -c conda-forge tesserocr\n\n\nkeras-ocr (\ud83e\udd4922 \u00b7  \u2b50 1.1K) - A packaged and flexible version of the CRAFT text detector and.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 280 \u00b7 \ud83d\udce5 380K \u00b7 \ud83d\udccb 180 - 40% open \u00b7 \u23f1\ufe0f 19.05.2022):\ngit clone https://github.com/faustomorales/keras-ocr\n- PyPi (\ud83d\udce5 5.8K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 19.05.2022):\npip install keras-ocr\n- Conda (\ud83d\udce5 120 \u00b7 \u23f1\ufe0f 14.01.2022):\nconda install -c anaconda keras-ocr\n\n\npdftabextract (\ud83e\udd4921 \u00b7  \u2b50 2K) - A set of tools for extracting tables from PDF files helping to.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 350 \u00b7 \ud83d\udce6 42 \u00b7 \ud83d\udccb 21 - 14% open \u00b7 \u23f1\ufe0f 24.06.2022):\ngit clone https://github.com/WZBSocialScienceCenter/pdftabextract\n- PyPi (\ud83d\udce5 420 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 09.01.2018):\npip install pdftabextract\n\n\ncalamari (\ud83e\udd4919 \u00b7  \u2b50 940) - Line based ATR Engine based on OCRopy. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udccb 250 - 19% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/Calamari-OCR/calamari\n- PyPi (\ud83d\udce5 910 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 13.11.2018):\npip install calamari_ocr\n\n\nMozart (\ud83e\udd4910 \u00b7  \u2b50 420) - An optical music recognition (OMR) system. Converts sheet music.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 59 \u00b7 \ud83d\udccb 13 - 30% open \u00b7 \u23f1\ufe0f 24.08.2022):\ngit clone https://github.com/aashrafh/Mozart\n\n\nShow 2 hidden projects...\n\nattention-ocr (\ud83e\udd4921 \u00b7  \u2b50 930 \u00b7 \ud83d\udc80) - A Tensorflow model for text recognition (CNN + seq2seq.. MIT \ndoc2text (\ud83e\udd4920 \u00b7  \u2b50 1.3K \u00b7 \ud83d\udc80) - Detect text blocks and OCR poorly scanned PDFs in bulk. Python.. MIT\n\nData Containers & Structures\nGeneral-purpose data containers & structures as well as utilities & extensions for pandas.\n\ud83d\udd17\u00a0best-of-python - Data Containers ( \u2b50 2.6K)  - Collection of data-container, dataframe, and pandas-..\nData Loading & Extraction\nLibraries for loading, collecting, and extracting data from a variety of data sources and formats.\n\ud83d\udd17\u00a0best-of-python - Data Extraction ( \u2b50 2.6K)  - Collection of data-loading and -extraction libraries.\nWeb Scraping & Crawling\nLibraries for web scraping, crawling, downloading, and mining as well as libraries.\n\ud83d\udd17\u00a0best-of-web-python - Web Scraping ( \u2b50 1.7K)  - Collection of web-scraping and crawling libraries.\nData Pipelines & Streaming\nLibraries for data batch- and stream-processing, workflow automation, job scheduling, and other data pipeline tasks.\n\ud83d\udd17\u00a0best-of-python - Data Pipelines ( \u2b50 2.6K)  - Libraries for data batch- and stream-processing,..\nDistributed Machine Learning\nLibraries that provide capabilities to distribute and parallelize machine learning tasks across large-scale compute infrastructure.\nRay (\ud83e\udd4744 \u00b7  \u2b50 23K) - Ray is a unified framework for scaling AI and Python applications. Ray.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 780 \u00b7 \ud83d\udd00 4K \u00b7 \ud83d\udce6 6.4K \u00b7 \ud83d\udccb 12K - 22% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/ray-project/ray\n- PyPi (\ud83d\udce5 2.2M / month \u00b7 \ud83d\udce6 280 \u00b7 \u23f1\ufe0f 09.06.2022):\npip install ray\n- Conda (\ud83d\udce5 78K \u00b7 \u23f1\ufe0f 18.11.2022):\nconda install -c conda-forge ray-tune\n\n\ndask (\ud83e\udd4743 \u00b7  \u2b50 11K) - Parallel computing with task scheduling. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 570 \u00b7 \ud83d\udd00 1.6K \u00b7 \ud83d\udce6 42K \u00b7 \ud83d\udccb 4.7K - 17% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/dask/dask\n- PyPi (\ud83d\udce5 7.6M / month \u00b7 \ud83d\udce6 2.7K \u00b7 \u23f1\ufe0f 24.06.2022):\npip install dask\n- Conda (\ud83d\udce5 7.3M \u00b7 \u23f1\ufe0f 18.11.2022):\nconda install -c conda-forge dask\n\n\ndask.distributed (\ud83e\udd4740 \u00b7  \u2b50 1.4K \u00b7 \ud83d\udcc9) - A distributed task scheduler for Dask. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 300 \u00b7 \ud83d\udd00 660 \u00b7 \ud83d\udce6 26K \u00b7 \ud83d\udccb 3.3K - 38% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/dask/distributed\n- PyPi (\ud83d\udce5 4.1M / month \u00b7 \ud83d\udce6 1.2K \u00b7 \u23f1\ufe0f 24.06.2022):\npip install distributed\n- Conda (\ud83d\udce5 8.7M \u00b7 \u23f1\ufe0f 18.11.2022):\nconda install -c conda-forge distributed\n\n\nhorovod (\ud83e\udd4738 \u00b7  \u2b50 13K \u00b7 \ud83d\udcc8) - Distributed training framework for TensorFlow, Keras, PyTorch,.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 2.1K \u00b7 \ud83d\udce6 700 \u00b7 \ud83d\udccb 2.1K - 15% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/horovod/horovod\n- PyPi (\ud83d\udce5 88K / month \u00b7 \ud83d\udce6 30 \u00b7 \u23f1\ufe0f 21.06.2022):\npip install horovod\n\n\nDeepSpeed (\ud83e\udd4835 \u00b7  \u2b50 8.2K) - DeepSpeed is a deep learning optimization library that makes.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 950 \u00b7 \ud83d\udce6 500 \u00b7 \ud83d\udccb 1.2K - 48% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/microsoft/DeepSpeed\n- PyPi (\ud83d\udce5 560K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 25.05.2022):\npip install deepspeed\n- Docker Hub (\ud83d\udce5 14K \u00b7 \u2b50 3 \u00b7 \u23f1\ufe0f 02.09.2022):\ndocker pull deepspeed/deepspeed\n\n\nBigDL (\ud83e\udd4835 \u00b7  \u2b50 4.1K) - Fast, distributed, secure AI for Big Data. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 170 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 40 \u00b7 \ud83d\udccb 1.7K - 37% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/intel-analytics/BigDL\n- PyPi (\ud83d\udce5 3.8K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 07.07.2022):\npip install bigdl\n- Maven (\ud83d\udce6 4 \u00b7 \u23f1\ufe0f 20.04.2021):\n```\n\n\ncom.intel.analytics.bigdl\nbigdl-SPARK_2.4\n[VERSION]\n```\n\nmetrics (\ud83e\udd4834 \u00b7  \u2b50 1.2K) - Machine learning metrics for distributed, scalable PyTorch.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udce5 1.2K \u00b7 \ud83d\udce6 5.8K \u00b7 \ud83d\udccb 500 - 11% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/Lightning-AI/metrics\n- PyPi (\ud83d\udce5 3.9K / month \u00b7 \ud83d\udce6 14 \u00b7 \u23f1\ufe0f 28.04.2018):\npip install metrics\n- Conda (\ud83d\udce5 580K \u00b7 \u23f1\ufe0f 17.11.2022):\nconda install -c conda-forge torchmetrics\n\n\nH2O-3 (\ud83e\udd4833 \u00b7  \u2b50 6.1K) - H2O is an Open Source, Distributed, Fast & Scalable Machine Learning.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 1.9K \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/h2oai/h2o-3\n- PyPi (\ud83d\udce5 420K / month \u00b7 \ud83d\udce6 76 \u00b7 \u23f1\ufe0f 26.05.2022):\npip install h2o\n\n\nFairScale (\ud83e\udd4833 \u00b7  \u2b50 1.9K) - PyTorch extensions for high performance and large scale training. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 64 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 930 \u00b7 \ud83d\udccb 330 - 19% open \u00b7 \u23f1\ufe0f 21.10.2022):\ngit clone https://github.com/facebookresearch/fairscale\n- PyPi (\ud83d\udce5 760K / month \u00b7 \ud83d\udce6 20 \u00b7 \u23f1\ufe0f 09.03.2022):\npip install fairscale\n- Conda (\ud83d\udce5 71K \u00b7 \u23f1\ufe0f 20.06.2022):\nconda install -c conda-forge fairscale\n\n\nSynapseML (\ud83e\udd4829 \u00b7  \u2b50 3.8K) - Simple and Distributed Machine Learning. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 720 \u00b7 \ud83d\udccb 630 - 41% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/microsoft/SynapseML\n- PyPi (\ud83d\udce5 78K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 12.01.2022):\npip install synapseml\n\n\nElephas (\ud83e\udd4829 \u00b7  \u2b50 1.6K) - Distributed Deep learning with Keras & Spark. MIT keras \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 300 \u00b7 \ud83d\udce6 61 \u00b7 \ud83d\udccb 170 - 10% open \u00b7 \u23f1\ufe0f 31.08.2022):\ngit clone https://github.com/maxpumperla/elephas\n- PyPi (\ud83d\udce5 78K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 30.03.2022):\npip install elephas\n- Conda (\ud83d\udce5 10K \u00b7 \u23f1\ufe0f 02.06.2021):\nconda install -c conda-forge elephas\n\n\nmpi4py (\ud83e\udd4829 \u00b7  \u2b50 590) - Python bindings for MPI. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 84 \u00b7 \ud83d\udce5 7.6K \u00b7 \ud83d\udccb 95 - 9% open \u00b7 \u23f1\ufe0f 18.11.2022):\ngit clone https://github.com/mpi4py/mpi4py\n- PyPi (\ud83d\udce5 250K / month \u00b7 \ud83d\udce6 620 \u00b7 \u23f1\ufe0f 25.11.2021):\npip install mpi4py\n- Conda (\ud83d\udce5 1.5M \u00b7 \u23f1\ufe0f 03.11.2022):\nconda install -c conda-forge mpi4py\n\n\nColossalAI (\ud83e\udd4827 \u00b7  \u2b50 6.7K) - Colossal-AI: A Unified Deep Learning System for Big Model Era. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 81 \u00b7 \ud83d\udd00 620 \u00b7 \ud83d\udce6 140 \u00b7 \ud83d\udccb 270 - 37% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/hpcaitech/colossalai\n\n\nTensorFlowOnSpark (\ud83e\udd4827 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udca4) - TensorFlowOnSpark brings TensorFlow programs to.. Apache-2  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 960 \u00b7 \ud83d\udccb 360 - 2% open \u00b7 \u23f1\ufe0f 21.04.2022):\ngit clone https://github.com/yahoo/TensorFlowOnSpark\n- PyPi (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 21.04.2022):\npip install tensorflowonspark\n- Conda (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 21.08.2022):\nconda install -c conda-forge tensorflowonspark\n\n\ndask-ml (\ud83e\udd4827 \u00b7  \u2b50 830) - Scalable Machine Learning with Dask. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 76 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 690 \u00b7 \ud83d\udccb 490 - 50% open \u00b7 \u23f1\ufe0f 19.10.2022):\ngit clone https://github.com/dask/dask-ml\n- PyPi (\ud83d\udce5 55K / month \u00b7 \ud83d\udce6 57 \u00b7 \u23f1\ufe0f 27.05.2022):\npip install dask-ml\n- Conda (\ud83d\udce5 610K \u00b7 \u23f1\ufe0f 27.05.2022):\nconda install -c conda-forge dask-ml\n\n\npetastorm (\ud83e\udd4926 \u00b7  \u2b50 1.5K) - Petastorm library enables single machine or distributed training.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 45 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce5 340 \u00b7 \ud83d\udce6 85 \u00b7 \ud83d\udccb 300 - 51% open \u00b7 \u23f1\ufe0f 14.09.2022):\ngit clone https://github.com/uber/petastorm\n- PyPi (\ud83d\udce5 52K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 19.02.2022):\npip install petastorm\n\n\nanalytics-zoo (\ud83e\udd4925 \u00b7  \u2b50 2.5K) - Distributed Tensorflow, Keras and PyTorch on Apache.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 720 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 1.4K - 39% open \u00b7 \u23f1\ufe0f 15.11.2022):\ngit clone https://github.com/intel-analytics/analytics-zoo\n- PyPi (\ud83d\udce5 760 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 07.07.2022):\npip install analytics-zoo\n\n\nMesh (\ud83e\udd4925 \u00b7  \u2b50 1.3K) - Mesh TensorFlow: Model Parallelism Made Easier. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 48 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 740 \u00b7 \ud83d\udccb 110 - 87% open \u00b7 \u23f1\ufe0f 04.10.2022):\ngit clone https://github.com/tensorflow/mesh\n- PyPi (\ud83d\udce5 19K / month \u00b7 \ud83d\udce6 32 \u00b7 \u23f1\ufe0f 15.05.2022):\npip install mesh-tensorflow\n\n\nHivemind (\ud83e\udd4925 \u00b7  \u2b50 1.2K) - Decentralized deep learning in PyTorch. Built to train models on.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 70 \u00b7 \ud83d\udce6 22 \u00b7 \ud83d\udccb 140 - 31% open \u00b7 \u23f1\ufe0f 01.11.2022):\ngit clone https://github.com/learning-at-home/hivemind\n- PyPi (\ud83d\udce5 3.6K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 20.06.2022):\npip install hivemind\n\n\nMMLSpark (\ud83e\udd4924 \u00b7  \u2b50 3.8K) - Simple and Distributed Machine Learning. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 720 \u00b7 \ud83d\udccb 630 - 41% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/microsoft/SynapseML\n- PyPi (\u23f1\ufe0f 18.03.2020):\npip install mmlspark\n\n\nApache Singa (\ud83e\udd4921 \u00b7  \u2b50 2.7K) - a distributed deep learning platform. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 79 \u00b7 \ud83d\udd00 880 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 100 - 37% open \u00b7 \u23f1\ufe0f 01.06.2022):\ngit clone https://github.com/apache/singa\n- Conda (\ud83d\udce5 550 \u00b7 \u23f1\ufe0f 09.08.2021):\nconda install -c nusdbsystem singa\n- Docker Hub (\ud83d\udce5 2.2K \u00b7 \u2b50 4 \u00b7 \u23f1\ufe0f 31.05.2022):\ndocker pull apache/singa\n\n\nSubmit it (\ud83e\udd4920 \u00b7  \u2b50 740) - Python 3.6+ toolbox for submitting jobs to Slurm. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 81 \u00b7 \ud83d\udccb 82 - 40% open \u00b7 \u23f1\ufe0f 28.09.2022):\ngit clone https://github.com/facebookincubator/submitit\n- PyPi (\ud83d\udce5 36K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 07.04.2022):\npip install submitit\n- Conda (\ud83d\udce5 12K \u00b7 \u23f1\ufe0f 10.02.2021):\nconda install -c conda-forge submitit\n\n\nBytePS (\ud83e\udd4919 \u00b7  \u2b50 3.3K \u00b7 \ud83d\udca4) - A high performance and generic framework for distributed DNN.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 460 \u00b7 \ud83d\udccb 260 - 38% open \u00b7 \u23f1\ufe0f 10.02.2022):\ngit clone https://github.com/bytedance/byteps\n- PyPi (\ud83d\udce5 59 / month \u00b7 \u23f1\ufe0f 02.08.2021):\npip install byteps\n- Docker Hub (\ud83d\udce5 1.3K \u00b7 \u23f1\ufe0f 03.03.2020):\ndocker pull bytepsimage/tensorflow\n\n\nparallelformers (\ud83e\udd4918 \u00b7  \u2b50 550) - Parallelformers: An Efficient Model Parallelization.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 38 \u00b7 \ud83d\udce6 12 \u00b7 \ud83d\udccb 35 - 51% open \u00b7 \u23f1\ufe0f 27.07.2022):\ngit clone https://github.com/tunib-ai/parallelformers\n- PyPi (\ud83d\udce5 5.9K / month \u00b7 \u23f1\ufe0f 29.12.2021):\npip install parallelformers\n\n\nmesh-transformer-jax (\ud83e\udd4916 \u00b7  \u2b50 4.6K \u00b7 \ud83d\udca4) - Model parallel transformers in JAX and Haiku. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 640 \u00b7 \ud83d\udccb 190 - 16% open \u00b7 \u23f1\ufe0f 28.01.2022):\ngit clone https://github.com/kingoflolz/mesh-transformer-jax\n\n\nmoolib (\ud83e\udd4912 \u00b7  \u2b50 340) - A library for distributed ML training with PyTorch. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 15 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 17 - 35% open \u00b7 \u23f1\ufe0f 07.11.2022):\ngit clone https://github.com/facebookresearch/moolib\n\n\nShow 10 hidden projects...\n\nDEAP (\ud83e\udd4832 \u00b7  \u2b50 4.9K) - Distributed Evolutionary Algorithms in Python. \u2757\ufe0fLGPL-3.0\nipyparallel (\ud83e\udd4830 \u00b7  \u2b50 2.3K) - IPython Parallel: Interactive Parallel Computing in.. \u2757Unlicensed \nTensorFrames (\ud83e\udd4921 \u00b7  \u2b50 760 \u00b7 \ud83d\udc80) - [DEPRECATED] Tensorflow wrapper for DataFrames on.. Apache-2  \nlaunchpad (\ud83e\udd4921 \u00b7  \u2b50 280) - Launchpad is a library that simplifies writing distributed.. Apache-2 \nsk-dist (\ud83e\udd4920 \u00b7  \u2b50 280 \u00b7 \ud83d\udc80) - Distributed scikit-learn meta-estimators in PySpark. Apache-2  \nsomoclu (\ud83e\udd4919 \u00b7  \u2b50 240) - Massively parallel self-organizing maps: accelerate training on multicore.. MIT\nFiber (\ud83e\udd4918 \u00b7  \u2b50 990 \u00b7 \ud83d\udc80) - Distributed Computing for AI Made Simple. Apache-2\nbluefog (\ud83e\udd4916 \u00b7  \u2b50 280) - Distributed and decentralized training framework for PyTorch.. Apache-2 \nLazyCluster (\ud83e\udd4914 \u00b7  \u2b50 44 \u00b7 \ud83d\udc80) - Distributed machine learning made simple. Apache-2\nautodist (\ud83e\udd4912 \u00b7  \u2b50 120 \u00b7 \ud83d\udc80) - Simple Distributed Deep Learning on TensorFlow. Apache-2 \n\nHyperparameter Optimization & AutoML\nLibraries for hyperparameter optimization, automl and neural architecture search.\nOptuna (\ud83e\udd4740 \u00b7  \u2b50 7.2K) - A hyperparameter optimization framework. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 220 \u00b7 \ud83d\udd00 770 \u00b7 \ud83d\udce6 4.7K \u00b7 \ud83d\udccb 1.3K - 7% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/optuna/optuna\n- PyPi (\ud83d\udce5 2.1M / month \u00b7 \ud83d\udce6 240 \u00b7 \u23f1\ufe0f 13.06.2022):\npip install optuna\n- Conda (\ud83d\udce5 350K \u00b7 \u23f1\ufe0f 13.10.2022):\nconda install -c conda-forge optuna\n\n\nNNI (\ud83e\udd4736 \u00b7  \u2b50 12K) - An open source AutoML toolkit for automate machine learning lifecycle,.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce6 320 \u00b7 \ud83d\udccb 1.8K - 15% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/microsoft/nni\n- PyPi (\ud83d\udce5 27K / month \u00b7 \ud83d\udce6 30 \u00b7 \u23f1\ufe0f 22.06.2022):\npip install nni\n\n\nAutoKeras (\ud83e\udd4734 \u00b7  \u2b50 8.7K) - AutoML library for deep learning. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce5 9.8K \u00b7 \ud83d\udce6 390 \u00b7 \ud83d\udccb 850 - 12% open \u00b7 \u23f1\ufe0f 10.11.2022):\ngit clone https://github.com/keras-team/autokeras\n- PyPi (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 30.04.2022):\npip install autokeras\n\n\nauto-sklearn (\ud83e\udd4733 \u00b7  \u2b50 6.6K) - Automated Machine Learning with scikit-learn. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 88 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udce5 39 \u00b7 \ud83d\udce6 350 \u00b7 \ud83d\udccb 940 - 14% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/automl/auto-sklearn\n- PyPi (\ud83d\udce5 38K / month \u00b7 \ud83d\udce6 30 \u00b7 \u23f1\ufe0f 20.09.2022):\npip install auto-sklearn\n- Conda (\ud83d\udce5 12K \u00b7 \u23f1\ufe0f 21.09.2022):\nconda install -c conda-forge auto-sklearn\n\n\nBayesian Optimization (\ud83e\udd4733 \u00b7  \u2b50 6.4K) - A Python implementation of global optimization with.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 36 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce5 110 \u00b7 \ud83d\udce6 1.4K \u00b7 \ud83d\udccb 280 - 6% open \u00b7 \u23f1\ufe0f 27.10.2022):\ngit clone https://github.com/fmfn/BayesianOptimization\n- PyPi (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 91 \u00b7 \u23f1\ufe0f 16.05.2020):\npip install bayesian-optimization\n\n\nfeaturetools (\ud83e\udd4733 \u00b7  \u2b50 6.4K) - An open source python library for automated feature engineering. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 68 \u00b7 \ud83d\udd00 840 \u00b7 \ud83d\udccb 880 - 18% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/alteryx/featuretools\n- PyPi (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 64 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install featuretools\n- Conda (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 22.11.2022):\nconda install -c conda-forge featuretools\n\n\nAutoGluon (\ud83e\udd4733 \u00b7  \u2b50 5.1K) - AutoGluon: AutoML for Image, Text, Time Series, and Tabular.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 95 \u00b7 \ud83d\udd00 660 \u00b7 \ud83d\udce6 190 \u00b7 \ud83d\udccb 800 - 23% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/awslabs/autogluon\n- PyPi (\ud83d\udce5 32K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 07.07.2022):\npip install autogluon\n\n\nKeras Tuner (\ud83e\udd4733 \u00b7  \u2b50 2.6K) - A Hyperparameter Tuning Library for Keras. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 51 \u00b7 \ud83d\udd00 340 \u00b7 \ud83d\udce6 1.8K \u00b7 \ud83d\udccb 420 - 43% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/keras-team/keras-tuner\n- PyPi (\ud83d\udce5 570K / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 25.03.2022):\npip install keras-tuner\n- Conda (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 16.10.2022):\nconda install -c conda-forge keras-tuner\n\n\nBoTorch (\ud83e\udd4733 \u00b7  \u2b50 2.5K) - Bayesian optimization in PyTorch. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 85 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udce6 370 \u00b7 \ud83d\udccb 340 - 21% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/pytorch/botorch\n- PyPi (\ud83d\udce5 170K / month \u00b7 \ud83d\udce6 18 \u00b7 \u23f1\ufe0f 21.04.2022):\npip install botorch\n- Conda (\ud83d\udce5 48K \u00b7 \u23f1\ufe0f 11.11.2022):\nconda install -c conda-forge botorch\n\n\nAx (\ud83e\udd4733 \u00b7  \u2b50 1.9K) - Adaptive Experimentation Platform. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 360 \u00b7 \ud83d\udccb 490 - 11% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/facebook/Ax\n- PyPi (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 15 \u00b7 \u23f1\ufe0f 26.04.2022):\npip install ax-platform\n- Conda (\ud83d\udce5 4.7K \u00b7 \u23f1\ufe0f 13.11.2022):\nconda install -c conda-forge ax-platform\n\n\nHyperopt (\ud83e\udd4832 \u00b7  \u2b50 6.5K \u00b7 \ud83d\udca4) - Distributed Asynchronous Hyperparameter Optimization in Python. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 93 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udce6 8.1K \u00b7 \ud83d\udccb 620 - 61% open \u00b7 \u23f1\ufe0f 29.11.2021):\ngit clone https://github.com/hyperopt/hyperopt\n- PyPi (\ud83d\udce5 1.8M / month \u00b7 \ud83d\udce6 430 \u00b7 \u23f1\ufe0f 17.11.2021):\npip install hyperopt\n- Conda (\ud83d\udce5 610K \u00b7 \u23f1\ufe0f 30.04.2022):\nconda install -c conda-forge hyperopt\n\n\nnevergrad (\ud83e\udd4828 \u00b7  \u2b50 3.4K) - A Python toolbox for performing gradient-free optimization. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 49 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce6 400 \u00b7 \ud83d\udccb 260 - 39% open \u00b7 \u23f1\ufe0f 10.08.2022):\ngit clone https://github.com/facebookresearch/nevergrad\n- PyPi (\ud83d\udce5 33K / month \u00b7 \ud83d\udce6 20 \u00b7 \u23f1\ufe0f 08.03.2022):\npip install nevergrad\n- Conda (\ud83d\udce5 34K \u00b7 \u23f1\ufe0f 14.06.2021):\nconda install -c conda-forge nevergrad\n\n\nHyperas (\ud83e\udd4827 \u00b7  \u2b50 2.1K \u00b7 \ud83d\udca4) - Keras + Hyperopt: A very simple wrapper for convenient.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce6 260 \u00b7 \ud83d\udccb 250 - 37% open \u00b7 \u23f1\ufe0f 19.11.2021):\ngit clone https://github.com/maxpumperla/hyperas\n- PyPi (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 24 \u00b7 \u23f1\ufe0f 28.02.2019):\npip install hyperas\n\n\nmljar-supervised (\ud83e\udd4825 \u00b7  \u2b50 2.3K) - Python package for AutoML on Tabular Data with Feature.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 300 \u00b7 \ud83d\udce6 57 \u00b7 \ud83d\udccb 520 - 21% open \u00b7 \u23f1\ufe0f 03.11.2022):\ngit clone https://github.com/mljar/mljar-supervised\n- PyPi (\ud83d\udce5 6.5K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 02.03.2022):\npip install mljar-supervised\n- Conda (\ud83d\udce5 5.4K \u00b7 \u23f1\ufe0f 17.08.2022):\nconda install -c conda-forge mljar-supervised\n\n\nFEDOT (\ud83e\udd4825 \u00b7  \u2b50 470) - Automated modeling and machine learning framework FEDOT. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 26 \u00b7 \ud83d\udd00 60 \u00b7 \ud83d\udce6 25 \u00b7 \ud83d\udccb 440 - 26% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/nccr-itmo/FEDOT\n- PyPi (\ud83d\udce5 1.2K / month \u00b7 \u23f1\ufe0f 28.03.2022):\npip install fedot\n\n\nTalos (\ud83e\udd4824 \u00b7  \u2b50 1.6K) - Hyperparameter Optimization for TensorFlow, Keras and PyTorch. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 150 \u00b7 \ud83d\udccb 400 - 2% open \u00b7 \u23f1\ufe0f 18.09.2022):\ngit clone https://github.com/autonomio/talos\n- PyPi (\ud83d\udce5 1.2K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 28.05.2022):\npip install talos\n\n\nlazypredict (\ud83e\udd4824 \u00b7  \u2b50 540) - Lazy Predict help build a lot of basic models without much code.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 83 \u00b7 \ud83d\udce6 360 \u00b7 \ud83d\udccb 75 - 52% open \u00b7 \u23f1\ufe0f 28.09.2022):\ngit clone https://github.com/shankarpandala/lazypredict\n- PyPi (\ud83d\udce5 7.7K / month \u00b7 \u23f1\ufe0f 17.02.2021):\npip install lazypredict\n- Conda (\ud83d\udce5 1.2K \u00b7 \u23f1\ufe0f 29.09.2022):\nconda install -c conda-forge lazypredict\n\n\nHpBandSter (\ud83e\udd4923 \u00b7  \u2b50 550 \u00b7 \ud83d\udca4) - a distributed Hyperband implementation on Steroids. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 270 \u00b7 \ud83d\udccb 92 - 61% open \u00b7 \u23f1\ufe0f 22.04.2022):\ngit clone https://github.com/automl/HpBandSter\n- PyPi (\ud83d\udce5 18K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 06.11.2018):\npip install hpbandster\n- Conda (\ud83d\udce5 4.3K \u00b7 \u23f1\ufe0f 11.12.2020):\nconda install -c conda-forge hpbandster\n\n\nfeaturewiz (\ud83e\udd4923 \u00b7  \u2b50 330) - Use advanced feature engineering strategies and select best.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 64 \u00b7 \ud83d\udce6 23 \u00b7 \ud83d\udccb 53 - 1% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/AutoViML/featurewiz\n- PyPi (\ud83d\udce5 13K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install featurewiz\n\n\nHyperactive (\ud83e\udd4922 \u00b7  \u2b50 420) - An optimization and data collection toolbox for convenient and fast.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 36 \u00b7 \ud83d\udce5 100 \u00b7 \ud83d\udce6 16 \u00b7 \ud83d\udccb 50 - 16% open \u00b7 \u23f1\ufe0f 19.11.2022):\ngit clone https://github.com/SimonBlanke/Hyperactive\n- PyPi (\ud83d\udce5 770 / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 04.05.2022):\npip install hyperactive\n\n\nNeuraxle (\ud83e\udd4921 \u00b7  \u2b50 550) - The worlds cleanest AutoML library - Do hyperparameter tuning with.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 54 \u00b7 \ud83d\udce6 35 \u00b7 \ud83d\udccb 320 - 19% open \u00b7 \u23f1\ufe0f 16.08.2022):\ngit clone https://github.com/Neuraxio/Neuraxle\n- PyPi (\ud83d\udce5 420 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 15.04.2022):\npip install neuraxle\n\n\nDragonfly (\ud83e\udd4920 \u00b7  \u2b50 740) - An open source python library for scalable Bayesian optimisation. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 210 \u00b7 \ud83d\udccb 58 - 65% open \u00b7 \u23f1\ufe0f 01.10.2022):\ngit clone https://github.com/dragonfly/dragonfly\n- PyPi (\ud83d\udce5 38K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 03.07.2020):\npip install dragonfly-opt\n\n\nAuto ViML (\ud83e\udd4919 \u00b7  \u2b50 380) - Automatically Build Multiple ML Models with a Single Line of Code... Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 82 \u00b7 \ud83d\udce6 20 \u00b7 \ud83d\udccb 22 - 18% open \u00b7 \u23f1\ufe0f 16.08.2022):\ngit clone https://github.com/AutoViML/Auto_ViML\n- PyPi (\ud83d\udce5 370 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 01.06.2022):\npip install autoviml\n\n\nigel (\ud83e\udd4918 \u00b7  \u2b50 3K \u00b7 \ud83d\udca4) - a delightful machine learning tool that allows you to train, test, and use.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce5 33 \u00b7 \ud83d\udccb 50 - 12% open \u00b7 \u23f1\ufe0f 06.02.2022):\ngit clone https://github.com/nidhaloff/igel\n- PyPi (\ud83d\udce5 130 / month \u00b7 \u23f1\ufe0f 19.11.2021):\npip install igel\n\n\nAlphaPy (\ud83e\udd4918 \u00b7  \u2b50 820 \u00b7 \ud83d\udca4) - Automated Machine Learning [AutoML] with Python, scikit-learn,.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 41 - 29% open \u00b7 \u23f1\ufe0f 23.04.2022):\ngit clone https://github.com/ScottfreeLLC/AlphaPy\n- PyPi (\ud83d\udce5 50 / month \u00b7 \u23f1\ufe0f 29.08.2020):\npip install alphapy\n\n\nopytimizer (\ud83e\udd4918 \u00b7  \u2b50 540) - Opytimizer is a Python library consisting of meta-heuristic.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 33 \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 06.10.2022):\ngit clone https://github.com/gugarosa/opytimizer\n- PyPi (\ud83d\udce5 910 / month \u00b7 \u23f1\ufe0f 04.05.2022):\npip install opytimizer\n\n\nshap-hypetune (\ud83e\udd4917 \u00b7  \u2b50 400) - A python package for simultaneous Hyperparameters Tuning and.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 50 \u00b7 \ud83d\udce6 9 \u00b7 \ud83d\udccb 17 - 5% open \u00b7 \u23f1\ufe0f 24.08.2022):\ngit clone https://github.com/cerlymarco/shap-hypetune\n- PyPi (\ud83d\udce5 4K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 16.01.2022):\npip install shap-hypetune\n\n\nmodel_search (\ud83e\udd4911 \u00b7  \u2b50 3.2K \u00b7 \ud83d\udca4) - AutoML algorithms for model architecture search at scale. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 1 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udccb 52 - 71% open \u00b7 \u23f1\ufe0f 09.02.2022):\ngit clone https://github.com/google/model_search\n\n\nShow 24 hidden projects...\n\nTPOT (\ud83e\udd4832 \u00b7  \u2b50 8.8K) - A Python Automated Machine Learning tool that optimizes machine.. \u2757\ufe0fLGPL-3.0 \nscikit-optimize (\ud83e\udd4831 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udc80) - Sequential model-based optimization with a.. BSD-3\nGPyOpt (\ud83e\udd4827 \u00b7  \u2b50 840 \u00b7 \ud83d\udc80) - Gaussian Process Optimization using GPy. BSD-3\nOrion (\ud83e\udd4827 \u00b7  \u2b50 250) - Asynchronous Distributed Hyperparameter Optimization. BSD-3\nSMAC3 (\ud83e\udd4826 \u00b7  \u2b50 760) - SMAC3: A Versatile Bayesian Optimization Package for.. \u2757\ufe0fBSD-1-Clause\nAdaNet (\ud83e\udd4824 \u00b7  \u2b50 3.4K \u00b7 \ud83d\udc80) - Fast and flexible AutoML with learning guarantees. Apache-2 \nMLBox (\ud83e\udd4923 \u00b7  \u2b50 1.4K \u00b7 \ud83d\udc80) - MLBox is a powerful Automated Machine Learning python library. \u2757\ufe0fBSD-1-Clause\nlightwood (\ud83e\udd4923 \u00b7  \u2b50 300) - Lightwood is Legos for Machine Learning. \u2757\ufe0fGPL-3.0 \nauto_ml (\ud83e\udd4922 \u00b7  \u2b50 1.6K \u00b7 \ud83d\udc80) - [UNMAINTAINED] Automated machine learning for analytics & production. MIT\nTest Tube (\ud83e\udd4922 \u00b7  \u2b50 730 \u00b7 \ud83d\udc80) - Python library to easily log experiments and parallelize.. MIT\noptunity (\ud83e\udd4922 \u00b7  \u2b50 400 \u00b7 \ud83d\udc80) - optimization routines for hyperparameter tuning. BSD-3\nsklearn-deap (\ud83e\udd4920 \u00b7  \u2b50 710 \u00b7 \ud83d\udc80) - Use evolutionary algorithms instead of gridsearch in.. MIT \nAuto Tune Models (\ud83e\udd4918 \u00b7  \u2b50 520 \u00b7 \ud83d\udc80) - Auto Tune Models - A multi-tenant, multi-data system for.. MIT\nSherpa (\ud83e\udd4918 \u00b7  \u2b50 320 \u00b7 \ud83d\udc80) - Hyperparameter optimization that enables researchers to.. \u2757\ufe0fGPL-3.0\nAdvisor (\ud83e\udd4917 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Open-source implementation of Google Vizier for hyper parameters.. Apache-2\nParfit (\ud83e\udd4917 \u00b7  \u2b50 200 \u00b7 \ud83d\udc80) - A package for parallelizing the fit and flexibly scoring of.. MIT \nautoml-gs (\ud83e\udd4916 \u00b7  \u2b50 1.8K \u00b7 \ud83d\udc80) - Provide an input CSV and a target field to predict, generate a.. MIT\nHyperparameterHunter (\ud83e\udd4916 \u00b7  \u2b50 700 \u00b7 \ud83d\udc80) - Easy hyperparameter optimization and automatic result.. MIT\nXcessiv (\ud83e\udd4915 \u00b7  \u2b50 1.3K \u00b7 \ud83d\udc80) - A web-based application for quick, scalable, and automated.. Apache-2\nENAS (\ud83e\udd4913 \u00b7  \u2b50 2.6K \u00b7 \ud83d\udc80) - PyTorch implementation of Efficient Neural Architecture Search via.. Apache-2\nAuptimizer (\ud83e\udd4913 \u00b7  \u2b50 190 \u00b7 \ud83d\udc80) - An automatic ML model optimization tool. \u2757\ufe0fGPL-3.0\nDevol (\ud83e\udd4911 \u00b7  \u2b50 940 \u00b7 \ud83d\udc80) - Genetic neural architecture search with Keras. MIT\nHypermax (\ud83e\udd4911 \u00b7  \u2b50 100 \u00b7 \ud83d\udc80) - Better, faster hyper-parameter optimization. BSD-3\nHypertunity (\ud83e\udd499 \u00b7  \u2b50 120 \u00b7 \ud83d\udc80) - A toolset for black-box hyperparameter optimisation. Apache-2\n\nReinforcement Learning\nLibraries for building and evaluating reinforcement learning & agent-based systems.\nOpenAI Gym (\ud83e\udd4741 \u00b7  \u2b50 29K \u00b7 \ud83d\udcc9) - A toolkit for developing and comparing reinforcement learning.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 380 \u00b7 \ud83d\udd00 8K \u00b7 \ud83d\udce6 34K \u00b7 \ud83d\udccb 1.7K - 1% open \u00b7 \u23f1\ufe0f 25.10.2022):\ngit clone https://github.com/openai/gym\n- PyPi (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 2.5K \u00b7 \u23f1\ufe0f 07.06.2022):\npip install gym\n- Conda (\ud83d\udce5 160K \u00b7 \u23f1\ufe0f 10.07.2022):\nconda install -c conda-forge gym\n\n\nTF-Agents (\ud83e\udd4734 \u00b7  \u2b50 2.4K) - TF-Agents: A reliable, scalable and easy to use TensorFlow.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 660 \u00b7 \ud83d\udce6 960 \u00b7 \ud83d\udccb 590 - 25% open \u00b7 \u23f1\ufe0f 19.11.2022):\ngit clone https://github.com/tensorflow/agents\n- PyPi (\ud83d\udce5 120K / month \u00b7 \u23f1\ufe0f 23.10.2022):\npip install tf-agents\n\n\nDopamine (\ud83e\udd4729 \u00b7  \u2b50 9.9K) - Dopamine is a research framework for fast prototyping of.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 1.3K \u00b7 \ud83d\udccb 170 - 50% open \u00b7 \u23f1\ufe0f 20.09.2022):\ngit clone https://github.com/google/dopamine\n- PyPi (\ud83d\udce5 32K / month \u00b7 \ud83d\udce6 37 \u00b7 \u23f1\ufe0f 20.05.2022):\npip install dopamine-rl\n\n\nFinRL (\ud83e\udd4729 \u00b7  \u2b50 6.3K) - FinRL: Financial Reinforcement Learning. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 79 \u00b7 \ud83d\udd00 1.5K \u00b7 \ud83d\udce6 17 \u00b7 \ud83d\udccb 470 - 17% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/AI4Finance-Foundation/FinRL\n- PyPi (\ud83d\udce5 420 / month \u00b7 \u23f1\ufe0f 08.01.2022):\npip install finrl\n\n\nAcme (\ud83e\udd4729 \u00b7  \u2b50 2.9K) - A library of reinforcement learning components and agents. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 80 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udce6 110 \u00b7 \ud83d\udccb 230 - 16% open \u00b7 \u23f1\ufe0f 10.11.2022):\ngit clone https://github.com/deepmind/acme\n- PyPi (\ud83d\udce5 3.5K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 10.02.2022):\npip install dm-acme\n- Conda (\ud83d\udce5 4.9K \u00b7 \u23f1\ufe0f 09.12.2021):\nconda install -c conda-forge dm-acme\n\n\nTensorLayer (\ud83e\udd4827 \u00b7  \u2b50 7.1K \u00b7 \ud83d\udca4) - Deep Learning and Reinforcement Learning Library for.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 1.6K \u00b7 \ud83d\udce5 1.4K \u00b7 \ud83d\udccb 470 - 6% open \u00b7 \u23f1\ufe0f 23.04.2022):\ngit clone https://github.com/tensorlayer/tensorlayer\n- PyPi (\ud83d\udce5 2.1K / month \u00b7 \ud83d\udce6 40 \u00b7 \u23f1\ufe0f 15.02.2022):\npip install tensorlayer\n\n\nViZDoom (\ud83e\udd4827 \u00b7  \u2b50 1.4K) - Doom-based AI Research Platform for Reinforcement Learning from Raw.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 340 \u00b7 \ud83d\udce5 12K \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 440 - 20% open \u00b7 \u23f1\ufe0f 03.11.2022):\ngit clone https://github.com/mwydmuch/ViZDoom\n- PyPi (\ud83d\udce5 920 / month \u00b7 \ud83d\udce6 14 \u00b7 \u23f1\ufe0f 18.04.2022):\npip install vizdoom\n\n\nPARL (\ud83e\udd4926 \u00b7  \u2b50 2.8K) - A high-performance distributed training framework for Reinforcement.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 35 \u00b7 \ud83d\udd00 760 \u00b7 \ud83d\udce6 98 \u00b7 \ud83d\udccb 450 - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/PaddlePaddle/PARL\n- PyPi (\ud83d\udce5 620 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 13.05.2022):\npip install parl\n\n\ngarage (\ud83e\udd4925 \u00b7  \u2b50 1.6K) - A toolkit for reproducible reinforcement learning research. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 78 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udce6 58 \u00b7 \ud83d\udccb 1K - 20% open \u00b7 \u23f1\ufe0f 20.05.2022):\ngit clone https://github.com/rlworkgroup/garage\n- PyPi (\ud83d\udce5 520 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 23.03.2021):\npip install garage\n\n\nStable Baselines (\ud83e\udd4924 \u00b7  \u2b50 3.7K) - A fork of OpenAI Baselines, implementations of reinforcement.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 700 \u00b7 \ud83d\udccb 940 - 12% open \u00b7 \u23f1\ufe0f 04.09.2022):\ngit clone https://github.com/hill-a/stable-baselines\n- PyPi (\ud83d\udce5 7.4K / month \u00b7 \ud83d\udce6 34 \u00b7 \u23f1\ufe0f 06.04.2021):\npip install stable-baselines\n\n\nTensorForce (\ud83e\udd4923 \u00b7  \u2b50 3.2K \u00b7 \ud83d\udca4) - Tensorforce: a TensorFlow library for applied.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 520 \u00b7 \ud83d\udccb 650 - 4% open \u00b7 \u23f1\ufe0f 10.02.2022):\ngit clone https://github.com/tensorforce/tensorforce\n- PyPi (\ud83d\udce5 1K / month \u00b7 \u23f1\ufe0f 30.08.2021):\npip install tensorforce\n\n\nRLax (\ud83e\udd4922 \u00b7  \u2b50 940) - A library of reinforcement learning building blocks in JAX. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 68 \u00b7 \ud83d\udce6 83 \u00b7 \ud83d\udccb 28 - 46% open \u00b7 \u23f1\ufe0f 02.11.2022):\ngit clone https://github.com/deepmind/rlax\n- PyPi (\ud83d\udce5 3.6K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 24.02.2022):\npip install rlax\n\n\nReAgent (\ud83e\udd4921 \u00b7  \u2b50 3.3K) - A platform for Reasoning systems (Reinforcement Learning,.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 150 \u00b7 \ud83d\udd00 470 \u00b7 \ud83d\udccb 140 - 47% open \u00b7 \u23f1\ufe0f 15.11.2022):\ngit clone https://github.com/facebookresearch/ReAgent\n- PyPi (\ud83d\udce5 16 / month \u00b7 \u23f1\ufe0f 27.05.2020):\npip install reagent\n\n\nCoach (\ud83e\udd4921 \u00b7  \u2b50 2.2K) - Reinforcement Learning Coach by Intel AI Lab enables easy.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 35 \u00b7 \ud83d\udd00 440 \u00b7 \ud83d\udccb 270 - 32% open \u00b7 \u23f1\ufe0f 08.11.2022):\ngit clone https://github.com/IntelLabs/coach\n- PyPi (\ud83d\udce5 190 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 10.10.2019):\npip install rl_coach\n\n\nPFRL (\ud83e\udd4920 \u00b7  \u2b50 940) - PFRL: a PyTorch-based deep reinforcement learning library. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 120 \u00b7 \ud83d\udce6 62 \u00b7 \ud83d\udccb 67 - 40% open \u00b7 \u23f1\ufe0f 21.09.2022):\ngit clone https://github.com/pfnet/pfrl\n- PyPi (\ud83d\udce5 390 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 07.07.2021):\npip install pfrl\n\n\nrliable (\ud83e\udd4913 \u00b7  \u2b50 520) - [NeurIPS21 Outstanding Paper] Library for reliable evaluation on RL.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 32 \u00b7 \ud83d\udce6 27 \u00b7 \u23f1\ufe0f 14.09.2022):\ngit clone https://github.com/google-research/rliable\n- [PyPi](https://pypi.org/project/rliable):\n```\npip install rliable\n```\n\n\nShow 7 hidden projects...\n\nbaselines (\ud83e\udd4729 \u00b7  \u2b50 13K \u00b7 \ud83d\udc80) - OpenAI Baselines: high-quality implementations of reinforcement.. MIT\nkeras-rl (\ud83e\udd4828 \u00b7  \u2b50 5.3K \u00b7 \ud83d\udc80) - Deep Reinforcement Learning for Keras. MIT \nChainerRL (\ud83e\udd4923 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - ChainerRL is a deep reinforcement learning library built on top of.. MIT\nTRFL (\ud83e\udd4922 \u00b7  \u2b50 3.1K \u00b7 \ud83d\udc80) - TensorFlow Reinforcement Learning. Apache-2 \nSerpentAI (\ud83e\udd4919 \u00b7  \u2b50 6.4K \u00b7 \ud83d\udc80) - Game Agent Framework. Helping you create AIs / Bots that learn to.. MIT\nDeepMind Lab (\ud83e\udd4917 \u00b7  \u2b50 6.8K) - A customisable 3D platform for agent-based AI research. \u2757Unlicensed\nMaze (\ud83e\udd4915 \u00b7  \u2b50 220 \u00b7 \ud83d\udcc8) - Maze Applied Reinforcement Learning Framework. \u2757\ufe0fCustom \n\nRecommender Systems\nLibraries for building and evaluating recommendation systems.\nRecommenders (\ud83e\udd4735 \u00b7  \u2b50 15K) - Best Practices on Recommendation Systems. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 2.5K \u00b7 \ud83d\udce5 280 \u00b7 \ud83d\udce6 45 \u00b7 \ud83d\udccb 730 - 19% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/microsoft/recommenders\n- PyPi (\ud83d\udce5 34K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 01.04.2022):\npip install recommenders\n\n\nTF Recommenders (\ud83e\udd4731 \u00b7  \u2b50 1.5K) - TensorFlow Recommenders is a library for building.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 39 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 330 - 53% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/tensorflow/recommenders\n- PyPi (\ud83d\udce5 680K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 23.08.2021):\npip install tensorflow-recommenders\n\n\nscikit-surprise (\ud83e\udd4830 \u00b7  \u2b50 5.6K) - A Python scikit for building and analyzing recommender.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 44 \u00b7 \ud83d\udd00 960 \u00b7 \ud83d\udccb 370 - 18% open \u00b7 \u23f1\ufe0f 31.10.2022):\ngit clone https://github.com/NicolasHug/Surprise\n- PyPi (\ud83d\udce5 120K / month \u00b7 \ud83d\udce6 49 \u00b7 \u23f1\ufe0f 19.07.2020):\npip install scikit-surprise\n- Conda (\ud83d\udce5 270K \u00b7 \u23f1\ufe0f 31.10.2022):\nconda install -c conda-forge scikit-surprise\n\n\nimplicit (\ud83e\udd4830 \u00b7  \u2b50 3K) - Fast Python Collaborative Filtering for Implicit Feedback Datasets. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 560 \u00b7 \ud83d\udce5 190 \u00b7 \ud83d\udce6 710 \u00b7 \ud83d\udccb 440 - 16% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/benfred/implicit\n- PyPi (\ud83d\udce5 140K / month \u00b7 \ud83d\udce6 32 \u00b7 \u23f1\ufe0f 29.01.2022):\npip install implicit\n- Conda (\ud83d\udce5 430K \u00b7 \u23f1\ufe0f 29.01.2022):\nconda install -c conda-forge implicit\n\n\nlightfm (\ud83e\udd4829 \u00b7  \u2b50 4.2K) - A Python implementation of LightFM, a hybrid recommendation algorithm. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 44 \u00b7 \ud83d\udd00 650 \u00b7 \ud83d\udce6 850 \u00b7 \ud83d\udccb 470 - 25% open \u00b7 \u23f1\ufe0f 19.07.2022):\ngit clone https://github.com/lyst/lightfm\n- PyPi (\ud83d\udce5 410K / month \u00b7 \ud83d\udce6 45 \u00b7 \u23f1\ufe0f 27.11.2020):\npip install lightfm\n- Conda (\ud83d\udce5 140K \u00b7 \u23f1\ufe0f 09.03.2022):\nconda install -c conda-forge lightfm\n\n\nTF Ranking (\ud83e\udd4829 \u00b7  \u2b50 2.6K) - Learning to Rank in TensorFlow. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 440 \u00b7 \ud83d\udccb 310 - 23% open \u00b7 \u23f1\ufe0f 26.10.2022):\ngit clone https://github.com/tensorflow/ranking\n- PyPi (\ud83d\udce5 96K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 16.11.2021):\npip install tensorflow_ranking\n\n\nRecBole (\ud83e\udd4828 \u00b7  \u2b50 2.3K) - A unified, comprehensive and efficient recommendation library. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 420 \u00b7 \ud83d\udccb 550 - 15% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/RUCAIBox/RecBole\n- PyPi (\ud83d\udce5 2.4K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 25.02.2022):\npip install recbole\n- Conda (\ud83d\udce5 2.4K \u00b7 \u23f1\ufe0f 05.10.2022):\nconda install -c aibox recbole\n\n\ntorchrec (\ud83e\udd4924 \u00b7  \u2b50 1.2K) - Pytorch domain library for recommendation systems. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udccb 120 - 59% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/pytorch/torchrec\n- PyPi (\ud83d\udce5 310 / month \u00b7 \u23f1\ufe0f 12.05.2022):\npip install torchrec-nightly-cpu\n\n\nCornac (\ud83e\udd4923 \u00b7  \u2b50 660) - A Comparative Framework for Multimodal Recommender Systems. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 110 - 7% open \u00b7 \u23f1\ufe0f 18.10.2022):\ngit clone https://github.com/PreferredAI/cornac\n- PyPi (\ud83d\udce5 41K / month \u00b7 \ud83d\udce6 15 \u00b7 \u23f1\ufe0f 19.02.2022):\npip install cornac\n- Conda (\ud83d\udce5 260K \u00b7 \u23f1\ufe0f 10.11.2022):\nconda install -c conda-forge cornac\n\n\nrecmetrics (\ud83e\udd4918 \u00b7  \u2b50 440 \u00b7 \ud83d\udca4) - A library of metrics for evaluating recommender systems. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 85 \u00b7 \ud83d\udce6 33 \u00b7 \ud83d\udccb 21 - 42% open \u00b7 \u23f1\ufe0f 17.04.2022):\ngit clone https://github.com/statisticianinstilettos/recmetrics\n- PyPi (\ud83d\udce5 4.4K / month \u00b7 \u23f1\ufe0f 26.04.2022):\npip install recmetrics\n\n\nCase Recommender (\ud83e\udd4917 \u00b7  \u2b50 430 \u00b7 \ud83d\udca4) - Case Recommender: A Flexible and Extensible Python.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 80 \u00b7 \ud83d\udce6 10 \u00b7 \ud83d\udccb 27 - 25% open \u00b7 \u23f1\ufe0f 25.11.2021):\ngit clone https://github.com/caserec/CaseRecommender\n- PyPi (\ud83d\udce5 86 / month \u00b7 \u23f1\ufe0f 25.11.2021):\npip install caserecommender\n\n\nShow 6 hidden projects...\n\ntensorrec (\ud83e\udd4924 \u00b7  \u2b50 1.2K \u00b7 \ud83d\udc80) - A TensorFlow recommendation algorithm and framework in.. Apache-2 \nfastFM (\ud83e\udd4921 \u00b7  \u2b50 1K \u00b7 \ud83d\udc80) - fastFM: A Library for Factorization Machines. BSD-3\nlkpy (\ud83e\udd4919 \u00b7  \u2b50 220) - Python recommendation toolkit. MIT\nSpotlight (\ud83e\udd4918 \u00b7  \u2b50 2.8K \u00b7 \ud83d\udc80) - Deep recommender models using PyTorch. MIT \nCollie (\ud83e\udd4917 \u00b7  \u2b50 94) - A library for preparing, training, and evaluating scalable deep.. BSD-3 \nOpenRec (\ud83e\udd4916 \u00b7  \u2b50 400 \u00b7 \ud83d\udc80) - OpenRec is an open-source and modular library for neural network-.. Apache-2\n\nPrivacy Machine Learning\nLibraries for encrypted and privacy-preserving machine learning using methods like federated learning & differential privacy.\nPySyft (\ud83e\udd4736 \u00b7  \u2b50 8.4K) - Data science on data without acquiring a copy. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 480 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udccb 3.4K - 5% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/OpenMined/PySyft\n- PyPi (\ud83d\udce5 4.7K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 29.06.2022):\npip install syft\n\n\nOpacus (\ud83e\udd4829 \u00b7  \u2b50 1.3K) - Training PyTorch models with differential privacy. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 65 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce5 51 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 220 - 22% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/pytorch/opacus\n- PyPi (\ud83d\udce5 13K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 06.05.2022):\npip install opacus\n- Conda (\ud83d\udce5 5.7K \u00b7 \u23f1\ufe0f 09.09.2022):\nconda install -c conda-forge opacus\n\n\nFATE (\ud83e\udd4826 \u00b7  \u2b50 4.7K) - An Industrial Grade Federated Learning Framework. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udccb 1.4K - 38% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/FederatedAI/FATE\n- PyPi (\ud83d\udce5 11 / month \u00b7 \u23f1\ufe0f 06.05.2020):\npip install ETAF\n\n\nTensorFlow Privacy (\ud83e\udd4826 \u00b7  \u2b50 1.7K) - Library for training machine learning models with.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 380 \u00b7 \ud83d\udce5 88 \u00b7 \ud83d\udccb 180 - 50% open \u00b7 \u23f1\ufe0f 08.11.2022):\ngit clone https://github.com/tensorflow/privacy\n- PyPi (\ud83d\udce5 39K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 22.02.2022):\npip install tensorflow-privacy\n\n\nTFEncrypted (\ud83e\udd4925 \u00b7  \u2b50 1.1K) - A Framework for Encrypted Machine Learning in TensorFlow. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 63 \u00b7 \ud83d\udccb 430 - 33% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/tf-encrypted/tf-encrypted\n- PyPi (\ud83d\udce5 880 / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 07.03.2022):\npip install tf-encrypted\n\n\nCrypTen (\ud83e\udd4924 \u00b7  \u2b50 1.2K) - A framework for Privacy Preserving Machine Learning. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce6 22 \u00b7 \ud83d\udccb 190 - 17% open \u00b7 \u23f1\ufe0f 10.06.2022):\ngit clone https://github.com/facebookresearch/CrypTen\n- PyPi (\ud83d\udce5 190 / month \u00b7 \u23f1\ufe0f 09.09.2021):\npip install crypten\n\n\nShow 1 hidden projects...\n\nPipelineDP (\ud83e\udd4921 \u00b7  \u2b50 240) - PipelineDP is a Python framework for applying differentially.. Apache-2\n\nWorkflow & Experiment Tracking\nLibraries to organize, track, and visualize machine learning experiments.\nTensorboard (\ud83e\udd4743 \u00b7  \u2b50 6K) - TensorFlows Visualization Toolkit. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 290 \u00b7 \ud83d\udd00 1.6K \u00b7 \ud83d\udce6 130K \u00b7 \ud83d\udccb 1.8K - 34% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/tensorflow/tensorboard\n- PyPi (\ud83d\udce5 18M / month \u00b7 \ud83d\udce6 2.4K \u00b7 \u23f1\ufe0f 08.06.2022):\npip install tensorboard\n- Conda (\ud83d\udce5 3.5M \u00b7 \u23f1\ufe0f 09.11.2022):\nconda install -c conda-forge tensorboard\n\n\nmlflow (\ud83e\udd4741 \u00b7  \u2b50 13K) - Open source platform for the machine learning lifecycle. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 510 \u00b7 \ud83d\udd00 3K \u00b7 \ud83d\udccb 2.7K - 35% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/mlflow/mlflow\n- PyPi (\ud83d\udce5 11M / month \u00b7 \ud83d\udce6 330 \u00b7 \u23f1\ufe0f 29.06.2022):\npip install mlflow\n- Conda (\ud83d\udce5 1.1M \u00b7 \u23f1\ufe0f 16.11.2022):\nconda install -c conda-forge mlflow\n\n\nDVC (\ud83e\udd4741 \u00b7  \u2b50 11K) - Data Version Control | Git for Data & Models | ML Experiments Management. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 280 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udce5 110K \u00b7 \ud83d\udce6 5.4K \u00b7 \ud83d\udccb 4K - 16% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/iterative/dvc\n- PyPi (\ud83d\udce5 1.4M / month \u00b7 \ud83d\udce6 47 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install dvc\n- Conda (\ud83d\udce5 1.3M \u00b7 \u23f1\ufe0f 15.11.2022):\nconda install -c conda-forge dvc\n\n\nwandb client (\ud83e\udd4737 \u00b7  \u2b50 5K) - A tool for visualizing and tracking your machine learning.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 380 \u00b7 \ud83d\udce6 13K \u00b7 \ud83d\udccb 2.1K - 26% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/wandb/client\n- PyPi (\ud83d\udce5 1.5M / month \u00b7 \ud83d\udce6 270 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install wandb\n- Conda (\ud83d\udce5 130K \u00b7 \u23f1\ufe0f 04.11.2022):\nconda install -c conda-forge wandb\n\n\nSageMaker SDK (\ud83e\udd4737 \u00b7  \u2b50 1.7K) - A library for training and deploying machine learning.. Apache-2  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 290 \u00b7 \ud83d\udd00 880 \u00b7 \ud83d\udce6 1.8K \u00b7 \ud83d\udccb 1.2K - 37% open \u00b7 \u23f1\ufe0f 15.11.2022):\ngit clone https://github.com/aws/sagemaker-python-sdk\n- PyPi (\ud83d\udce5 9.7M / month \u00b7 \ud83d\udce6 52 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install sagemaker\n- Conda (\ud83d\udce5 460K \u00b7 \u23f1\ufe0f 03.11.2022):\nconda install -c conda-forge sagemaker-python-sdk\n\n\nPyCaret (\ud83e\udd4836 \u00b7  \u2b50 6.6K) - An open-source, low-code machine learning library in Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 1.5K \u00b7 \ud83d\udce5 620 \u00b7 \ud83d\udce6 2.8K \u00b7 \ud83d\udccb 1.9K - 16% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/pycaret/pycaret\n- PyPi (\ud83d\udce5 980K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 06.06.2022):\npip install pycaret\n- Conda (\ud83d\udce5 23K \u00b7 \u23f1\ufe0f 18.04.2022):\nconda install -c conda-forge pycaret\n\n\nAzureML SDK (\ud83e\udd4835 \u00b7  \u2b50 3.5K) - Python notebooks with ML and deep learning examples with Azure.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 61 \u00b7 \ud83d\udd00 2.2K \u00b7 \ud83d\udce5 480 \u00b7 \ud83d\udccb 1.4K - 23% open \u00b7 \u23f1\ufe0f 08.11.2022):\ngit clone https://github.com/Azure/MachineLearningNotebooks\n- PyPi (\ud83d\udce5 2.3M / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 27.06.2022):\npip install azureml-sdk\n\n\ntensorboardX (\ud83e\udd4834 \u00b7  \u2b50 7.5K) - tensorboard for pytorch (and chainer, mxnet, numpy, ...). MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 73 \u00b7 \ud83d\udd00 870 \u00b7 \ud83d\udce5 350 \u00b7 \ud83d\udce6 24K \u00b7 \ud83d\udccb 440 - 16% open \u00b7 \u23f1\ufe0f 04.09.2022):\ngit clone https://github.com/lanpa/tensorboardX\n- PyPi (\ud83d\udce5 1.9M / month \u00b7 \ud83d\udce6 890 \u00b7 \u23f1\ufe0f 05.06.2022):\npip install tensorboardX\n- Conda (\ud83d\udce5 880K \u00b7 \u23f1\ufe0f 07.06.2022):\nconda install -c conda-forge tensorboardx\n\n\nClearML (\ud83e\udd4834 \u00b7  \u2b50 3.8K) - ClearML - Auto-Magical CI/CD to streamline your ML workflow... Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 58 \u00b7 \ud83d\udd00 500 \u00b7 \ud83d\udce5 570 \u00b7 \ud83d\udce6 340 \u00b7 \ud83d\udccb 670 - 45% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/allegroai/clearml\n- PyPi (\ud83d\udce5 470K / month \u00b7 \ud83d\udce6 8 \u00b7 \u23f1\ufe0f 04.07.2022):\npip install clearml\n- Docker Hub (\ud83d\udce5 30K \u00b7 \u23f1\ufe0f 05.10.2020):\ndocker pull allegroai/trains\n\n\nsnakemake (\ud83e\udd4834 \u00b7  \u2b50 1.5K) - This is the development home of the workflow management system.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 270 \u00b7 \ud83d\udd00 380 \u00b7 \ud83d\udce6 1.3K \u00b7 \ud83d\udccb 1.2K - 60% open \u00b7 \u23f1\ufe0f 10.11.2022):\ngit clone https://github.com/snakemake/snakemake\n- PyPi (\ud83d\udce5 66K / month \u00b7 \ud83d\udce6 210 \u00b7 \u23f1\ufe0f 30.06.2022):\npip install snakemake\n- Conda (\ud83d\udce5 590K \u00b7 \u23f1\ufe0f 12.11.2022):\nconda install -c bioconda snakemake\n\n\nMetaflow (\ud83e\udd4832 \u00b7  \u2b50 6.2K) - Build and manage real-life data science projects with ease!. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 59 \u00b7 \ud83d\udd00 560 \u00b7 \ud83d\udce6 340 \u00b7 \ud83d\udccb 490 - 48% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/Netflix/metaflow\n- PyPi (\ud83d\udce5 61K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 17.06.2022):\npip install metaflow\n- Conda (\ud83d\udce5 85K \u00b7 \u23f1\ufe0f 04.11.2022):\nconda install -c conda-forge metaflow\n\n\nVisualDL (\ud83e\udd4832 \u00b7  \u2b50 4.5K) - Deep Learning Visualization Toolkit. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 32 \u00b7 \ud83d\udd00 600 \u00b7 \ud83d\udce5 240 \u00b7 \ud83d\udce6 1.5K \u00b7 \ud83d\udccb 440 - 22% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/PaddlePaddle/VisualDL\n- PyPi (\ud83d\udce5 71K / month \u00b7 \ud83d\udce6 25 \u00b7 \u23f1\ufe0f 01.07.2022):\npip install visualdl\n\n\naim (\ud83e\udd4831 \u00b7  \u2b50 2.9K) - Aim easy-to-use and performant open-source ML experiment tracker. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 47 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 730 - 24% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/aimhubio/aim\n- PyPi (\ud83d\udce5 26K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 07.07.2022):\npip install aim\n- Conda (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 15.10.2021):\nconda install -c conda-forge aim\n\n\nsacred (\ud83e\udd4830 \u00b7  \u2b50 4K) - Sacred is a tool to help you configure, organize, log and reproduce.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 350 \u00b7 \ud83d\udce6 1.7K \u00b7 \ud83d\udccb 540 - 16% open \u00b7 \u23f1\ufe0f 17.10.2022):\ngit clone https://github.com/IDSIA/sacred\n- PyPi (\ud83d\udce5 53K / month \u00b7 \ud83d\udce6 100 \u00b7 \u23f1\ufe0f 14.12.2020):\npip install sacred\n- Conda (\ud83d\udce5 1.9K \u00b7 \u23f1\ufe0f 14.11.2021):\nconda install -c conda-forge sacred\n\n\nml-metadata (\ud83e\udd4829 \u00b7  \u2b50 500) - For recording and retrieving metadata associated with ML.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce5 1.7K \u00b7 \ud83d\udce6 260 \u00b7 \ud83d\udccb 95 - 27% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/google/ml-metadata\n- PyPi (\ud83d\udce5 680K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 21.06.2022):\npip install ml-metadata\n\n\nNeptune.ai (\ud83e\udd4829 \u00b7  \u2b50 350) - Experiment tracking tool and model registry. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 38 \u00b7 \ud83d\udd00 35 \u00b7 \ud83d\udccb 180 - 13% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/neptune-ai/neptune-client\n- PyPi (\ud83d\udce5 530K / month \u00b7 \ud83d\udce6 28 \u00b7 \u23f1\ufe0f 01.07.2022):\npip install neptune-client\n- Conda (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 23.11.2022):\nconda install -c conda-forge neptune-client\n\n\nCatalyst (\ud83e\udd4928 \u00b7  \u2b50 3K \u00b7 \ud83d\udca4) - Accelerated deep learning R&D. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udce6 650 \u00b7 \ud83d\udccb 340 - 1% open \u00b7 \u23f1\ufe0f 29.04.2022):\ngit clone https://github.com/catalyst-team/catalyst\n- PyPi (\ud83d\udce5 45K / month \u00b7 \ud83d\udce6 29 \u00b7 \u23f1\ufe0f 29.04.2022):\npip install catalyst\n\n\nGuild AI (\ud83e\udd4927 \u00b7  \u2b50 750) - Experiment tracking, ML developer tools. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 68 \u00b7 \ud83d\udce5 7 \u00b7 \ud83d\udce6 61 \u00b7 \ud83d\udccb 390 - 45% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/guildai/guildai\n- PyPi (\ud83d\udce5 3.1K / month \u00b7 \u23f1\ufe0f 11.05.2022):\npip install guildai\n\n\nTNT (\ud83e\udd4926 \u00b7  \u2b50 1.4K) - A lightweight library for PyTorch training tools and utilities. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 74 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udccb 62 - 4% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/pytorch/tnt\n- PyPi (\ud83d\udce5 6.3K / month \u00b7 \ud83d\udce6 37 \u00b7 \u23f1\ufe0f 29.07.2018):\npip install torchnet\n\n\nlivelossplot (\ud83e\udd4925 \u00b7  \u2b50 1.2K \u00b7 \ud83d\udca4) - Live training loss plot in Jupyter Notebook for Keras,.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce6 890 \u00b7 \ud83d\udccb 76 - 7% open \u00b7 \u23f1\ufe0f 04.04.2022):\ngit clone https://github.com/stared/livelossplot\n- PyPi (\ud83d\udce5 46K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 04.04.2022):\npip install livelossplot\n\n\nLabml (\ud83e\udd4924 \u00b7  \u2b50 1.2K) - Monitor deep learning model training and hardware usage from your mobile.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 87 \u00b7 \ud83d\udce6 57 \u00b7 \ud83d\udccb 35 - 51% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/labmlai/labml\n- PyPi (\ud83d\udce5 2K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install labml\n\n\nlore (\ud83e\udd4920 \u00b7  \u2b50 1.5K) - Lore makes machine learning approachable for Software Engineers and.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 20 \u00b7 \ud83d\udccb 45 - 57% open \u00b7 \u23f1\ufe0f 27.09.2022):\ngit clone https://github.com/instacart/lore\n- PyPi (\ud83d\udce5 330 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 02.02.2022):\npip install lore\n\n\nkeepsake (\ud83e\udd4918 \u00b7  \u2b50 1.6K) - Version control for machine learning. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 64 \u00b7 \ud83d\udccb 190 - 65% open \u00b7 \u23f1\ufe0f 24.05.2022):\ngit clone https://github.com/replicate/keepsake\n- PyPi (\ud83d\udce5 270 / month \u00b7 \u23f1\ufe0f 11.03.2021):\npip install keepsake\n\n\nShow 16 hidden projects...\n\nkaggle (\ud83e\udd4829 \u00b7  \u2b50 5K \u00b7 \ud83d\udc80) - Official Kaggle API. Apache-2\nknockknock (\ud83e\udd4925 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udc80) - Knock Knock: Get notified when your training ends with only two.. MIT\nSKLL (\ud83e\udd4925 \u00b7  \u2b50 530) - SciKit-Learn Laboratory (SKLL) makes it easy to run machine.. \u2757\ufe0fBSD-1-Clause \nhiddenlayer (\ud83e\udd4921 \u00b7  \u2b50 1.7K \u00b7 \ud83d\udc80) - Neural network graphs and training metrics for.. MIT   \nTensorWatch (\ud83e\udd4920 \u00b7  \u2b50 3.3K \u00b7 \ud83d\udc80) - Debugging, monitoring and visualization for Python Machine.. MIT\nTensorBoard Logger (\ud83e\udd4920 \u00b7  \u2b50 620 \u00b7 \ud83d\udc80) - Log TensorBoard events without touching TensorFlow. MIT\nStudio.ml (\ud83e\udd4920 \u00b7  \u2b50 380 \u00b7 \ud83d\udc80) - Studio: Simplify and expedite model building process. Apache-2\nquinn (\ud83e\udd4920 \u00b7  \u2b50 370 \u00b7 \ud83d\udc80) - pyspark methods to enhance developer productivity. Apache-2 \ngokart (\ud83e\udd4920 \u00b7  \u2b50 270) - Gokart solves reproducibility, task dependencies, constraints of good code,.. MIT\nMXBoard (\ud83e\udd4919 \u00b7  \u2b50 330 \u00b7 \ud83d\udc80) - Logging MXNet data for visualization in TensorBoard. Apache-2 \ndatmo (\ud83e\udd4917 \u00b7  \u2b50 340 \u00b7 \ud83d\udc80) - Open source production model management tool for data scientists. MIT\nchitra (\ud83e\udd4916 \u00b7  \u2b50 210) - A multi-functional library for full-stack Deep Learning. Simplifies.. Apache-2\nsteppy (\ud83e\udd4915 \u00b7  \u2b50 130 \u00b7 \ud83d\udc80) - Lightweight, Python library for fast and reproducible experimentation. MIT\ncaliban (\ud83e\udd4914 \u00b7  \u2b50 440 \u00b7 \ud83d\udc80) - Research workflows made easy, locally and in the Cloud. Apache-2\nModelChimp (\ud83e\udd4913 \u00b7  \u2b50 120 \u00b7 \ud83d\udc80) - Experiment tracking for machine and deep learning projects. BSD-2\ntraintool (\ud83e\udd498 \u00b7  \u2b50 11 \u00b7 \ud83d\udc80) - Train off-the-shelf machine learning models in one.. Apache-2   \n\nModel Serialization & Deployment\nLibraries to serialize models to files, convert between a variety of model formats, and optimize models for deployment.\nonnx (\ud83e\udd4741 \u00b7  \u2b50 14K) - Open standard for machine learning interoperability. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 260 \u00b7 \ud83d\udd00 3.1K \u00b7 \ud83d\udce5 18K \u00b7 \ud83d\udce6 9.4K \u00b7 \ud83d\udccb 2.2K - 15% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/onnx/onnx\n- PyPi (\ud83d\udce5 2M / month \u00b7 \ud83d\udce6 390 \u00b7 \u23f1\ufe0f 18.06.2022):\npip install onnx\n- Conda (\ud83d\udce5 580K \u00b7 \u23f1\ufe0f 28.10.2022):\nconda install -c conda-forge onnx\n\n\nCore ML Tools (\ud83e\udd4731 \u00b7  \u2b50 3K) - Core ML tools contain supporting tools for Core ML model.. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 470 \u00b7 \ud83d\udce5 4.6K \u00b7 \ud83d\udce6 1.1K \u00b7 \ud83d\udccb 1K - 16% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/apple/coremltools\n- PyPi (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 150 \u00b7 \u23f1\ufe0f 07.06.2022):\npip install coremltools\n- Conda (\ud83d\udce5 40K \u00b7 \u23f1\ufe0f 15.10.2021):\nconda install -c conda-forge coremltools\n\n\nhuggingface_hub (\ud83e\udd4731 \u00b7  \u2b50 590) - All the open source things related to the Hugging Face Hub. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 76 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 360 - 23% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/huggingface/huggingface_hub\n- PyPi (\ud83d\udce5 6.9M / month \u00b7 \ud83d\udce6 87 \u00b7 \u23f1\ufe0f 21.06.2022):\npip install huggingface_hub\n- Conda (\ud83d\udce5 540K \u00b7 \u23f1\ufe0f 16.11.2022):\nconda install -c conda-forge huggingface_hub\n\n\ntriton (\ud83e\udd4830 \u00b7  \u2b50 4.3K) - Development repository for the Triton language and compiler. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 65 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 330 - 40% open \u00b7 \u23f1\ufe0f 20.11.2022):\ngit clone https://github.com/openai/triton\n- PyPi (\ud83d\udce5 190K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 04.07.2022):\npip install triton\n\n\nBentoML (\ud83e\udd4829 \u00b7  \u2b50 4.3K) - Unified Model Serving Framework. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 480 \u00b7 \ud83d\udce5 1.6K \u00b7 \ud83d\udccb 760 - 13% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/bentoml/BentoML\n- PyPi (\ud83d\udce5 36K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 01.07.2022):\npip install bentoml\n\n\nHummingbird (\ud83e\udd4829 \u00b7  \u2b50 3K) - Hummingbird compiles trained ML models into tensor computation for.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 35 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce5 190 \u00b7 \ud83d\udce6 46 \u00b7 \ud83d\udccb 260 - 17% open \u00b7 \u23f1\ufe0f 10.11.2022):\ngit clone https://github.com/microsoft/hummingbird\n- PyPi (\ud83d\udce5 36K / month \u00b7 \u23f1\ufe0f 25.04.2022):\npip install hummingbird-ml\n- Conda (\ud83d\udce5 18K \u00b7 \u23f1\ufe0f 11.11.2022):\nconda install -c conda-forge hummingbird-ml\n\n\nTorchServe (\ud83e\udd4829 \u00b7  \u2b50 3K) - Serve, optimize and scale PyTorch models in production. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 650 \u00b7 \ud83d\udce5 2.3K \u00b7 \ud83d\udccb 1.1K - 17% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/pytorch/serve\n- PyPi (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 13.05.2022):\npip install torchserve\n- Conda (\ud83d\udce5 48K \u00b7 \u23f1\ufe0f 14.11.2022):\nconda install -c pytorch torchserve\n- Docker Hub (\ud83d\udce5 1.1M \u00b7 \u2b50 16 \u00b7 \u23f1\ufe0f 14.11.2022):\ndocker pull pytorch/torchserve\n\n\ncortex (\ud83e\udd4825 \u00b7  \u2b50 7.8K) - Production infrastructure for machine learning at scale. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 600 \u00b7 \ud83d\udccb 1.1K - 10% open \u00b7 \u23f1\ufe0f 23.09.2022):\ngit clone https://github.com/cortexlabs/cortex\n- PyPi (\ud83d\udce5 1.7K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 10.01.2022):\npip install cortex\n\n\nmmdnn (\ud83e\udd4825 \u00b7  \u2b50 5.6K) - MMdnn is a set of tools to help users inter-operate among different deep.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 86 \u00b7 \ud83d\udd00 970 \u00b7 \ud83d\udce5 3.6K \u00b7 \ud83d\udce6 94 \u00b7 \ud83d\udccb 620 - 53% open \u00b7 \u23f1\ufe0f 22.09.2022):\ngit clone https://github.com/Microsoft/MMdnn\n- PyPi (\ud83d\udce5 430 / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 24.07.2020):\npip install mmdnn\n\n\nm2cgen (\ud83e\udd4825 \u00b7  \u2b50 2.3K) - Transform ML models into a native code (Java, C, Python, Go, JavaScript,.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce5 42 \u00b7 \ud83d\udce6 76 \u00b7 \ud83d\udccb 100 - 30% open \u00b7 \u23f1\ufe0f 05.10.2022):\ngit clone https://github.com/BayesWitnesses/m2cgen\n- PyPi (\ud83d\udce5 58K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 26.04.2022):\npip install m2cgen\n\n\nhls4ml (\ud83e\udd4924 \u00b7  \u2b50 730) - Machine learning on FPGAs using HLS. Apache-2  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 47 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udccb 340 - 42% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/fastmachinelearning/hls4ml\n- PyPi (\ud83d\udce5 750 / month \u00b7 \u23f1\ufe0f 12.11.2021):\npip install hls4ml\n- Conda (\ud83d\udce5 4.6K \u00b7 \u23f1\ufe0f 12.11.2021):\nconda install -c conda-forge hls4ml\n\n\nsklearn-porter (\ud83e\udd4923 \u00b7  \u2b50 1.2K) - Transpile trained scikit-learn estimators to C, Java,.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 45 \u00b7 \ud83d\udccb 76 - 55% open \u00b7 \u23f1\ufe0f 22.05.2022):\ngit clone https://github.com/nok/sklearn-porter\n- PyPi (\ud83d\udce5 370 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 18.12.2019):\npip install sklearn-porter\n\n\nnebullvm (\ud83e\udd4920 \u00b7  \u2b50 1.5K) - Accelerate AI models inference leveraging best-of-breed.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 68 \u00b7 \ud83d\udce6 4 \u00b7 \ud83d\udccb 75 - 38% open \u00b7 \u23f1\ufe0f 11.11.2022):\ngit clone https://github.com/nebuly-ai/nebullvm\n- PyPi (\ud83d\udce5 500 / month \u00b7 \u23f1\ufe0f 28.06.2022):\npip install nebullvm\n\n\nShow 7 hidden projects...\n\nLarq Compute Engine (\ud83e\udd4921 \u00b7  \u2b50 210) - Highly optimized inference engine for Binarized.. Apache-2\nOMLT (\ud83e\udd4920 \u00b7  \u2b50 170) - Represent trained machine learning models as Pyomo optimization formulations. BSD-3\npytorch2keras (\ud83e\udd4919 \u00b7  \u2b50 820 \u00b7 \ud83d\udc80) - PyTorch to Keras model convertor. MIT\ntfdeploy (\ud83e\udd4916 \u00b7  \u2b50 350 \u00b7 \ud83d\udc80) - Deploy tensorflow graphs for fast evaluation and export to.. BSD-3 \nmodelkit (\ud83e\udd4915 \u00b7  \u2b50 140) - Toolkit for developing and maintaining ML models. MIT\nbackprop (\ud83e\udd4913 \u00b7  \u2b50 230 \u00b7 \ud83d\udc80) - Backprop makes it simple to use, finetune, and deploy state-of-.. Apache-2\nml-ane-transformers (\ud83e\udd4910 \u00b7  \u2b50 480 \u00b7 \ud83d\udc23) - Reference implementation of the Transformer.. \u2757Unlicensed \n\nModel Interpretability\nLibraries to visualize, explain, debug, evaluate, and interpret machine learning models.\nshap (\ud83e\udd4739 \u00b7  \u2b50 18K) - A game theoretic approach to explain the output of any machine learning model. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 2.6K \u00b7 \ud83d\udce6 7.3K \u00b7 \ud83d\udccb 2.1K - 70% open \u00b7 \u23f1\ufe0f 16.06.2022):\ngit clone https://github.com/slundberg/shap\n- PyPi (\ud83d\udce5 4.6M / month \u00b7 \ud83d\udce6 280 \u00b7 \u23f1\ufe0f 16.06.2022):\npip install shap\n- Conda (\ud83d\udce5 1.6M \u00b7 \u23f1\ufe0f 20.06.2022):\nconda install -c conda-forge shap\n\n\narviz (\ud83e\udd4734 \u00b7  \u2b50 1.3K) - Exploratory analysis of Bayesian models with Python. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce5 110 \u00b7 \ud83d\udce6 3K \u00b7 \ud83d\udccb 800 - 22% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/arviz-devs/arviz\n- PyPi (\ud83d\udce5 910K / month \u00b7 \ud83d\udce6 100 \u00b7 \u23f1\ufe0f 13.05.2022):\npip install arviz\n- Conda (\ud83d\udce5 1M \u00b7 \u23f1\ufe0f 16.11.2022):\nconda install -c conda-forge arviz\n\n\nNetron (\ud83e\udd4733 \u00b7  \u2b50 21K) - Visualizer for neural network, deep learning, and machine.. MIT  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 2.3K \u00b7 \ud83d\udce5 33K \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 880 - 3% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/lutzroeder/netron\n- PyPi (\ud83d\udce5 9.3K / month \u00b7 \ud83d\udce6 67 \u00b7 \u23f1\ufe0f 04.07.2022):\npip install netron\n\n\nInterpretML (\ud83e\udd4733 \u00b7  \u2b50 5.1K) - Fit interpretable models. Explain blackbox machine learning. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 620 \u00b7 \ud83d\udce6 310 \u00b7 \ud83d\udccb 330 - 35% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/interpretml/interpret\n- PyPi (\ud83d\udce5 140K / month \u00b7 \ud83d\udce6 16 \u00b7 \u23f1\ufe0f 23.09.2021):\npip install interpret\n\n\nCaptum (\ud83e\udd4731 \u00b7  \u2b50 3.6K) - Model interpretability and understanding for PyTorch. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 94 \u00b7 \ud83d\udd00 370 \u00b7 \ud83d\udce6 780 \u00b7 \ud83d\udccb 420 - 30% open \u00b7 \u23f1\ufe0f 18.11.2022):\ngit clone https://github.com/pytorch/captum\n- PyPi (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 23 \u00b7 \u23f1\ufe0f 03.03.2022):\npip install captum\n- Conda (\ud83d\udce5 4.2K \u00b7 \u23f1\ufe0f 04.03.2022):\nconda install -c conda-forge captum\n\n\nModel Analysis (\ud83e\udd4731 \u00b7  \u2b50 1.2K) - Model analysis tools for TensorFlow. Apache-2  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 52 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udccb 79 - 36% open \u00b7 \u23f1\ufe0f 18.11.2022):\ngit clone https://github.com/tensorflow/model-analysis\n- PyPi (\ud83d\udce5 820K / month \u00b7 \ud83d\udce6 21 \u00b7 \u23f1\ufe0f 16.05.2022):\npip install tensorflow-model-analysis\n\n\ndtreeviz (\ud83e\udd4830 \u00b7  \u2b50 2.3K) - A python library for decision tree visualization and model interpretation. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udce6 540 \u00b7 \ud83d\udccb 130 - 23% open \u00b7 \u23f1\ufe0f 29.10.2022):\ngit clone https://github.com/parrt/dtreeviz\n- PyPi (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 14 \u00b7 \u23f1\ufe0f 29.04.2022):\npip install dtreeviz\n- Conda (\ud83d\udce5 28K \u00b7 \u23f1\ufe0f 05.11.2022):\nconda install -c conda-forge dtreeviz\n\n\nshapash (\ud83e\udd4830 \u00b7  \u2b50 2K) - Shapash makes Machine Learning models transparent and.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 35 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 92 \u00b7 \ud83d\udccb 140 - 14% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/MAIF/shapash\n- PyPi (\ud83d\udce5 14K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 09.05.2022):\npip install shapash\n\n\nAlibi (\ud83e\udd4830 \u00b7  \u2b50 1.9K) - Algorithms for explaining machine learning models. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce6 210 \u00b7 \ud83d\udccb 320 - 38% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/SeldonIO/alibi\n- PyPi (\ud83d\udce5 30K / month \u00b7 \ud83d\udce6 24 \u00b7 \u23f1\ufe0f 18.05.2022):\npip install alibi\n\n\nyellowbrick (\ud83e\udd4829 \u00b7  \u2b50 3.8K) - Visual analysis and diagnostic tools to facilitate machine.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 520 \u00b7 \ud83d\udccb 680 - 12% open \u00b7 \u23f1\ufe0f 21.08.2022):\ngit clone https://github.com/DistrictDataLabs/yellowbrick\n- PyPi (\ud83d\udce5 1M / month \u00b7 \ud83d\udce6 67 \u00b7 \u23f1\ufe0f 19.02.2022):\npip install yellowbrick\n- Conda (\ud83d\udce5 45K \u00b7 \u23f1\ufe0f 22.08.2022):\nconda install -c conda-forge yellowbrick\n\n\nFairness 360 (\ud83e\udd4829 \u00b7  \u2b50 1.9K) - A comprehensive set of fairness metrics for datasets and.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 63 \u00b7 \ud83d\udd00 630 \u00b7 \ud83d\udce6 190 \u00b7 \ud83d\udccb 220 - 62% open \u00b7 \u23f1\ufe0f 04.11.2022):\ngit clone https://github.com/Trusted-AI/AIF360\n- PyPi (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 04.03.2021):\npip install aif360\n- Conda (\ud83d\udce5 4.3K \u00b7 \u23f1\ufe0f 04.09.2022):\nconda install -c conda-forge aif360\n\n\nfairlearn (\ud83e\udd4829 \u00b7  \u2b50 1.4K) - A Python package to assess and improve fairness of machine.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 68 \u00b7 \ud83d\udd00 330 \u00b7 \ud83d\udccb 400 - 42% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/fairlearn/fairlearn\n- PyPi (\ud83d\udce5 120K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 07.07.2021):\npip install fairlearn\n- Conda (\ud83d\udce5 23K \u00b7 \u23f1\ufe0f 07.07.2021):\nconda install -c conda-forge fairlearn\n\n\nexplainerdashboard (\ud83e\udd4829 \u00b7  \u2b50 1.4K) - Quickly build Explainable AI dashboards that show the inner.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 200 \u00b7 \ud83d\udccb 190 - 10% open \u00b7 \u23f1\ufe0f 16.06.2022):\ngit clone https://github.com/oegedijk/explainerdashboard\n- PyPi (\ud83d\udce5 73K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 15.06.2022):\npip install explainerdashboard\n- Conda (\ud83d\udce5 26K \u00b7 \u23f1\ufe0f 15.02.2022):\nconda install -c conda-forge explainerdashboard\n\n\nresponsible-ai-widgets (\ud83e\udd4829 \u00b7  \u2b50 620) - This project provides responsible AI user interfaces.. MIT   \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 40 \u00b7 \ud83d\udccb 280 - 21% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/microsoft/responsible-ai-toolbox\n- PyPi (\ud83d\udce5 9.8K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 10.06.2022):\npip install raiwidgets\n\n\nDoWhy (\ud83e\udd4828 \u00b7  \u2b50 5.4K) - DoWhy is a Python library for causal inference that supports explicit.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 63 \u00b7 \ud83d\udd00 760 \u00b7 \ud83d\udce5 31 \u00b7 \ud83d\udccb 310 - 33% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/py-why/dowhy\n- PyPi (\ud83d\udce5 92K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 20.03.2022):\npip install dowhy\n- Conda (\ud83d\udce5 10K \u00b7 \u23f1\ufe0f 19.07.2022):\nconda install -c conda-forge dowhy\n\n\nevaluate (\ud83e\udd4828 \u00b7  \u2b50 970) - Evaluate: A library for easily evaluating machine learning models.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 73 \u00b7 \ud83d\udce6 420 \u00b7 \ud83d\udccb 150 - 40% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/huggingface/evaluate\n- PyPi (\ud83d\udce5 200K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 16.06.2022):\npip install evaluate\n\n\nCausalNex (\ud83e\udd4827 \u00b7  \u2b50 1.7K) - A Python library that helps data scientists to infer.. Apache-2  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce6 61 \u00b7 \ud83d\udccb 120 - 8% open \u00b7 \u23f1\ufe0f 14.11.2022):\ngit clone https://github.com/quantumblacklabs/causalnex\n- PyPi (\ud83d\udce5 3.5K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 11.11.2021):\npip install causalnex\n\n\nExplainability 360 (\ud83e\udd4926 \u00b7  \u2b50 1.2K) - Interpretability and explainability of data and.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 39 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 64 \u00b7 \ud83d\udccb 75 - 62% open \u00b7 \u23f1\ufe0f 03.11.2022):\ngit clone https://github.com/Trusted-AI/AIX360\n- PyPi (\ud83d\udce5 1.1K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 28.10.2020):\npip install aix360\n\n\nchecklist (\ud83e\udd4925 \u00b7  \u2b50 1.8K) - Beyond Accuracy: Behavioral Testing of NLP models with CheckList. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 180 \u00b7 \ud83d\udccb 100 - 22% open \u00b7 \u23f1\ufe0f 12.08.2022):\ngit clone https://github.com/marcotcr/checklist\n- PyPi (\ud83d\udce5 9.5K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 24.05.2021):\npip install checklist\n- Conda (\ud83d\udce5 4.6K \u00b7 \u23f1\ufe0f 15.07.2021):\nconda install -c conda-forge checklist\n\n\nimodels (\ud83e\udd4925 \u00b7  \u2b50 960) - Interpretable ML package for concise, transparent, and accurate predictive.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 93 \u00b7 \ud83d\udce6 26 \u00b7 \ud83d\udccb 46 - 39% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/csinva/imodels\n- PyPi (\ud83d\udce5 67K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 03.07.2022):\npip install imodels\n\n\nsklearn-evaluation (\ud83e\udd4924 \u00b7  \u2b50 340) - Machine learning model evaluation made easy: plots,.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 36 \u00b7 \ud83d\udce6 54 \u00b7 \ud83d\udccb 64 - 42% open \u00b7 \u23f1\ufe0f 17.11.2022):\ngit clone https://github.com/edublancas/sklearn-evaluation\n- PyPi (\ud83d\udce5 2.6K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install sklearn-evaluation\n\n\nLIT (\ud83e\udd4923 \u00b7  \u2b50 3K \u00b7 \ud83d\udca4) - The Language Interpretability Tool: Interactively analyze NLP models.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 130 - 47% open \u00b7 \u23f1\ufe0f 15.03.2022):\ngit clone https://github.com/PAIR-code/lit\n- PyPi (\ud83d\udce5 1.2K / month \u00b7 \u23f1\ufe0f 21.12.2021):\npip install lit-nlp\n- Conda (\ud83d\udce5 48K \u00b7 \u23f1\ufe0f 09.11.2021):\nconda install -c conda-forge lit-nlp\n\n\nkeract (\ud83e\udd4923 \u00b7  \u2b50 1K) - Layers Outputs and Gradients in Keras. Made easy. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 89 - 3% open \u00b7 \u23f1\ufe0f 03.11.2022):\ngit clone https://github.com/philipperemy/keract\n- PyPi (\ud83d\udce5 4.6K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 19.06.2021):\npip install keract\n\n\nWhat-If Tool (\ud83e\udd4922 \u00b7  \u2b50 760 \u00b7 \ud83d\udca4) - Source code/webpage/demos for the What-If Tool. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 120 - 53% open \u00b7 \u23f1\ufe0f 05.01.2022):\ngit clone https://github.com/PAIR-code/what-if-tool\n- PyPi (\ud83d\udce5 9.5K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 12.10.2021):\npip install witwidget\n- Conda (\ud83d\udce5 1.4M \u00b7 \u23f1\ufe0f 06.01.2022):\nconda install -c conda-forge tensorboard-plugin-wit\n- npm (\ud83d\udce5 2K / month \u00b7 \u23f1\ufe0f 12.10.2021):\nnpm install wit-widget\n\n\niNNvestigate (\ud83e\udd4921 \u00b7  \u2b50 1.1K) - A toolbox to iNNvestigate neural networks predictions!. BSD-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce5 38 \u00b7 \ud83d\udccb 250 - 21% open \u00b7 \u23f1\ufe0f 12.10.2022):\ngit clone https://github.com/albermax/innvestigate\n- PyPi (\ud83d\udce5 450 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 14.11.2020):\npip install innvestigate\n\n\nDiCE (\ud83e\udd4921 \u00b7  \u2b50 960) - Generate Diverse Counterfactual Explanations for any machine.. MIT  \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 140 - 37% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/interpretml/DiCE\n- PyPi (\ud83d\udce5 28K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 02.06.2022):\npip install dice-ml\n\n\ntf-explain (\ud83e\udd4921 \u00b7  \u2b50 950) - Interpretability Methods for tf.keras models with Tensorflow 2.x. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 140 \u00b7 \ud83d\udccb 92 - 44% open \u00b7 \u23f1\ufe0f 30.06.2022):\ngit clone https://github.com/sicara/tf-explain\n- PyPi (\ud83d\udce5 2.3K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 18.11.2021):\npip install tf-explain\n\n\ndeeplift (\ud83e\udd4921 \u00b7  \u2b50 690 \u00b7 \ud83d\udca4) - Public facing deeplift repo. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 63 \u00b7 \ud83d\udccb 86 - 43% open \u00b7 \u23f1\ufe0f 11.11.2021):\ngit clone https://github.com/kundajelab/deeplift\n- PyPi (\ud83d\udce5 340 / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 11.11.2020):\npip install deeplift\n\n\necco (\ud83e\udd4919 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udca4) - Explain, analyze, and visualize NLP language models. Ecco creates.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce5 23 \u00b7 \ud83d\udce6 16 \u00b7 \ud83d\udccb 41 - 31% open \u00b7 \u23f1\ufe0f 18.01.2022):\ngit clone https://github.com/jalammar/ecco\n- PyPi (\ud83d\udce5 760 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 09.01.2022):\npip install ecco\n- Conda (\ud83d\udce5 2.4K \u00b7 \u23f1\ufe0f 10.01.2022):\nconda install -c conda-forge ecco\n\n\nmodel-card-toolkit (\ud83e\udd4919 \u00b7  \u2b50 320) - a tool that leverages rich metadata and lineage.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 65 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 21 - 76% open \u00b7 \u23f1\ufe0f 14.11.2022):\ngit clone https://github.com/tensorflow/model-card-toolkit\n- PyPi (\ud83d\udce5 1K / month \u00b7 \u23f1\ufe0f 28.04.2022):\npip install model-card-toolkit\n\n\nLOFO (\ud83e\udd4917 \u00b7  \u2b50 670 \u00b7 \ud83d\udca4) - Leave One Feature Out Importance. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 71 \u00b7 \ud83d\udce6 22 \u00b7 \ud83d\udccb 20 - 20% open \u00b7 \u23f1\ufe0f 27.04.2022):\ngit clone https://github.com/aerdem4/lofo-importance\n- PyPi (\ud83d\udce5 2.4K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 27.04.2022):\npip install lofo-importance\n\n\nAnchor (\ud83e\udd4916 \u00b7  \u2b50 730) - Code for High-Precision Model-Agnostic Explanations paper. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udccb 74 - 31% open \u00b7 \u23f1\ufe0f 19.07.2022):\ngit clone https://github.com/marcotcr/anchor\n- PyPi (\ud83d\udce5 1.5K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 10.09.2020):\npip install anchor_exp\n\n\nExplainX.ai (\ud83e\udd4915 \u00b7  \u2b50 320) - Explainable AI framework for data scientists. Explain & debug any.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 42 \u00b7 \ud83d\udce5 5 \u00b7 \ud83d\udccb 27 - 37% open \u00b7 \u23f1\ufe0f 15.09.2022):\ngit clone https://github.com/explainX/explainx\n- PyPi (\ud83d\udce5 2K / month \u00b7 \u23f1\ufe0f 04.02.2021):\npip install explainx\n\n\ninterpret-text (\ud83e\udd4914 \u00b7  \u2b50 340 \u00b7 \ud83d\udca4) - A library that incorporates state-of-the-art explainers.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 58 \u00b7 \ud83d\udccb 74 - 78% open \u00b7 \u23f1\ufe0f 06.12.2021):\ngit clone https://github.com/interpretml/interpret-text\n- PyPi (\ud83d\udce5 48 / month \u00b7 \u23f1\ufe0f 07.12.2021):\npip install interpret-text\n\n\nShow 20 hidden projects...\n\nLime (\ud83e\udd4733 \u00b7  \u2b50 10K \u00b7 \ud83d\udc80) - Lime: Explaining the predictions of any machine learning classifier. BSD-2\npyLDAvis (\ud83e\udd4731 \u00b7  \u2b50 1.7K \u00b7 \ud83d\udc80) - Python library for interactive topic model visualization... BSD-3 \nDeep Checks (\ud83e\udd4829 \u00b7  \u2b50 2.2K) - Tests for Continuous Validation of ML Models & Data... \u2757\ufe0fAGPL-3.0\neli5 (\ud83e\udd4827 \u00b7  \u2b50 2.6K \u00b7 \ud83d\udc80) - A library for debugging/inspecting machine learning classifiers and.. MIT\nscikit-plot (\ud83e\udd4827 \u00b7  \u2b50 2.3K \u00b7 \ud83d\udc80) - An intuitive library to add plotting functionality to.. MIT \nLucid (\ud83e\udd4926 \u00b7  \u2b50 4.5K \u00b7 \ud83d\udc80) - A collection of infrastructure and tools for research in.. Apache-2 \nkeras-vis (\ud83e\udd4925 \u00b7  \u2b50 2.9K \u00b7 \ud83d\udc80) - Neural network visualization toolkit for keras. MIT \nDALEX (\ud83e\udd4925 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udcc8) - moDel Agnostic Language for Exploration and eXplanation. \u2757\ufe0fGPL-3.0\nTreeInterpreter (\ud83e\udd4922 \u00b7  \u2b50 720 \u00b7 \ud83d\udc80) - Package for interpreting scikit-learns decision tree.. BSD-3 \nrandom-forest-importances (\ud83e\udd4922 \u00b7  \u2b50 530 \u00b7 \ud83d\udc80) - Code to compute permutation and drop-column.. MIT \naequitas (\ud83e\udd4922 \u00b7  \u2b50 500 \u00b7 \ud83d\udc80) - Bias and Fairness Audit Toolkit. MIT\nSkater (\ud83e\udd4921 \u00b7  \u2b50 1K \u00b7 \ud83d\udca4) - Python Library for Model Interpretation/Explanations. \u2757\ufe0fUPL-1.0\nQuantus (\ud83e\udd4921 \u00b7  \u2b50 260) - Quantus is an eXplainable AI toolkit for responsible evaluation of.. \u2757\ufe0fLGPL-3.0\ntcav (\ud83e\udd4919 \u00b7  \u2b50 550 \u00b7 \ud83d\udc80) - Code for the TCAV ML interpretability project. Apache-2 \nfairness-indicators (\ud83e\udd4919 \u00b7  \u2b50 280) - Tensorflows Fairness Evaluation and Visualization.. Apache-2  \nFlashTorch (\ud83e\udd4917 \u00b7  \u2b50 690 \u00b7 \ud83d\udc80) - Visualization toolkit for neural networks in PyTorch! Demo --. MIT \nXAI (\ud83e\udd4916 \u00b7  \u2b50 870 \u00b7 \ud83d\udc80) - XAI - An eXplainability toolbox for machine learning. MIT\ncontextual-ai (\ud83e\udd4912 \u00b7  \u2b50 82 \u00b7 \ud83d\udca4) - Contextual AI adds explainability to different stages of.. Apache-2\nAttribution Priors (\ud83e\udd4911 \u00b7  \u2b50 110 \u00b7 \ud83d\udc80) - Tools for training explainable models using.. MIT  \nbias-detector (\ud83e\udd4911 \u00b7  \u2b50 40) - Bias Detector is a python package for detecting bias in machine.. MIT\n\nVector Similarity Search (ANN)\nLibraries for Approximate Nearest Neighbor Search and Vector Indexing/Similarity Search.\n\ud83d\udd17\u00a0ANN Benchmarks ( \u2b50 3.1K)  - Benchmarks of approximate nearest neighbor libraries in Python.\nMilvus (\ud83e\udd4738 \u00b7  \u2b50 14K) - Vector database for scalable similarity search and AI applications. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 230 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce5 25K \u00b7 \ud83d\udccb 6.5K - 5% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/milvus-io/milvus\n- PyPi (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 17 \u00b7 \u23f1\ufe0f 02.04.2022):\npip install pymilvus\n- Docker Hub (\ud83d\udce5 2.4M \u00b7 \u2b50 23 \u00b7 \u23f1\ufe0f 24.11.2022):\ndocker pull milvusdb/milvus\n\n\nFaiss (\ud83e\udd4736 \u00b7  \u2b50 19K) - A library for efficient similarity search and clustering of dense vectors. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 2.7K \u00b7 \ud83d\udce6 810 \u00b7 \ud83d\udccb 1.9K - 11% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/facebookresearch/faiss\n- PyPi (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 17 \u00b7 \u23f1\ufe0f 02.04.2022):\npip install pymilvus\n- Conda (\ud83d\udce5 570K \u00b7 \u23f1\ufe0f 02.11.2022):\nconda install -c conda-forge faiss\n\n\nAnnoy (\ud83e\udd4833 \u00b7  \u2b50 10K) - Approximate Nearest Neighbors in C++/Python optimized for memory usage.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 2.4K \u00b7 \ud83d\udccb 360 - 11% open \u00b7 \u23f1\ufe0f 27.10.2022):\ngit clone https://github.com/spotify/annoy\n- PyPi (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 240 \u00b7 \u23f1\ufe0f 18.09.2020):\npip install annoy\n- Conda (\ud83d\udce5 290K \u00b7 \u23f1\ufe0f 31.10.2022):\nconda install -c conda-forge python-annoy\n\n\nNMSLIB (\ud83e\udd4830 \u00b7  \u2b50 2.9K) - Non-Metric Space Library (NMSLIB): An efficient similarity search.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 48 \u00b7 \ud83d\udd00 410 \u00b7 \ud83d\udce6 700 \u00b7 \ud83d\udccb 410 - 15% open \u00b7 \u23f1\ufe0f 31.05.2022):\ngit clone https://github.com/nmslib/nmslib\n- PyPi (\ud83d\udce5 120K / month \u00b7 \ud83d\udce6 52 \u00b7 \u23f1\ufe0f 03.02.2021):\npip install nmslib\n- Conda (\ud83d\udce5 72K \u00b7 \u23f1\ufe0f 30.10.2022):\nconda install -c conda-forge nmslib\n\n\nhnswlib (\ud83e\udd4828 \u00b7  \u2b50 2.2K \u00b7 \ud83d\udca4) - Header-only C++/python library for fast approximate nearest.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 410 \u00b7 \ud83d\udce6 330 \u00b7 \ud83d\udccb 280 - 53% open \u00b7 \u23f1\ufe0f 16.04.2022):\ngit clone https://github.com/nmslib/hnswlib\n- PyPi (\ud83d\udce5 360K / month \u00b7 \ud83d\udce6 28 \u00b7 \u23f1\ufe0f 14.02.2022):\npip install hnswlib\n- Conda (\ud83d\udce5 63K \u00b7 \u23f1\ufe0f 01.11.2022):\nconda install -c conda-forge hnswlib\n\n\nPyNNDescent (\ud83e\udd4828 \u00b7  \u2b50 690) - A Python nearest neighbor descent for approximate nearest neighbors. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 90 \u00b7 \ud83d\udce6 2.4K \u00b7 \ud83d\udccb 110 - 49% open \u00b7 \u23f1\ufe0f 01.11.2022):\ngit clone https://github.com/lmcinnes/pynndescent\n- PyPi (\ud83d\udce5 800K / month \u00b7 \ud83d\udce6 26 \u00b7 \u23f1\ufe0f 14.05.2022):\npip install pynndescent\n- Conda (\ud83d\udce5 1M \u00b7 \u23f1\ufe0f 01.11.2022):\nconda install -c conda-forge pynndescent\n\n\nNGT (\ud83e\udd4923 \u00b7  \u2b50 940) - Nearest Neighbor Search with Neighborhood Graph and Tree for High-.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 96 \u00b7 \ud83d\udccb 100 - 12% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/yahoojapan/NGT\n- PyPi (\ud83d\udce5 16K / month \u00b7 \ud83d\udce6 8 \u00b7 \u23f1\ufe0f 20.06.2022):\npip install ngt\n\n\nShow 4 hidden projects...\n\nMagnitude (\ud83e\udd4924 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - A fast, efficient universal vector embedding utility package. MIT\nNearPy (\ud83e\udd4921 \u00b7  \u2b50 720 \u00b7 \ud83d\udc80) - Python framework for fast (approximated) nearest neighbour search in.. MIT\nN2 (\ud83e\udd4919 \u00b7  \u2b50 530 \u00b7 \ud83d\udc80) - TOROS N2 - lightweight approximate Nearest Neighbor library which runs.. Apache-2\nPySparNN (\ud83e\udd4911 \u00b7  \u2b50 900 \u00b7 \ud83d\udc80) - Approximate Nearest Neighbor Search for Sparse Data in Python!. BSD-3\n\nProbabilistics & Statistics\nLibraries providing capabilities for probabilistic programming/reasoning, bayesian inference, gaussian processes, or statistics.\nPyMC3 (\ud83e\udd4740 \u00b7  \u2b50 7.1K) - Probabilistic Programming in Python: Bayesian Modeling and.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 420 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce5 1.9K \u00b7 \ud83d\udce6 890 \u00b7 \ud83d\udccb 2.9K - 5% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/pymc-devs/pymc\n- PyPi (\ud83d\udce5 380K / month \u00b7 \ud83d\udce6 240 \u00b7 \u23f1\ufe0f 15.03.2022):\npip install pymc3\n- Conda (\ud83d\udce5 470K \u00b7 \u23f1\ufe0f 20.05.2022):\nconda install -c conda-forge pymc3\n\n\ntensorflow-probability (\ud83e\udd4737 \u00b7  \u2b50 3.8K) - Probabilistic reasoning and statistical analysis in.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 460 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udccb 1.3K - 45% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/tensorflow/probability\n- PyPi (\ud83d\udce5 930K / month \u00b7 \ud83d\udce6 340 \u00b7 \u23f1\ufe0f 07.06.2022):\npip install tensorflow-probability\n- Conda (\ud83d\udce5 82K \u00b7 \u23f1\ufe0f 10.11.2022):\nconda install -c conda-forge tensorflow-probability\n\n\nPyro (\ud83e\udd4734 \u00b7  \u2b50 7.7K) - Deep universal probabilistic programming with Python and PyTorch. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 940 \u00b7 \ud83d\udce6 920 \u00b7 \ud83d\udccb 1K - 22% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/pyro-ppl/pyro\n- PyPi (\ud83d\udce5 360K / month \u00b7 \ud83d\udce6 60 \u00b7 \u23f1\ufe0f 24.03.2022):\npip install pyro-ppl\n- Conda (\ud83d\udce5 30K \u00b7 \u23f1\ufe0f 23.11.2022):\nconda install -c conda-forge pyro-ppl\n\n\nGPyTorch (\ud83e\udd4833 \u00b7  \u2b50 2.9K) - A highly efficient and modular implementation of Gaussian Processes.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 440 \u00b7 \ud83d\udce6 820 \u00b7 \ud83d\udccb 1.2K - 25% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/cornellius-gp/gpytorch\n- PyPi (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 41 \u00b7 \u23f1\ufe0f 27.06.2022):\npip install gpytorch\n- Conda (\ud83d\udce5 63K \u00b7 \u23f1\ufe0f 08.09.2022):\nconda install -c conda-forge gpytorch\n\n\nGPflow (\ud83e\udd4832 \u00b7  \u2b50 1.7K) - Gaussian processes in TensorFlow. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 79 \u00b7 \ud83d\udd00 430 \u00b7 \ud83d\udce6 430 \u00b7 \ud83d\udccb 800 - 16% open \u00b7 \u23f1\ufe0f 14.11.2022):\ngit clone https://github.com/GPflow/GPflow\n- PyPi (\ud83d\udce5 88K / month \u00b7 \ud83d\udce6 29 \u00b7 \u23f1\ufe0f 10.05.2022):\npip install gpflow\n- Conda (\ud83d\udce5 17K \u00b7 \u23f1\ufe0f 24.05.2022):\nconda install -c conda-forge gpflow\n\n\nhmmlearn (\ud83e\udd4831 \u00b7  \u2b50 2.7K) - Hidden Markov Models in Python, with scikit-learn like API. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 41 \u00b7 \ud83d\udd00 710 \u00b7 \ud83d\udce6 1.4K \u00b7 \ud83d\udccb 400 - 14% open \u00b7 \u23f1\ufe0f 07.11.2022):\ngit clone https://github.com/hmmlearn/hmmlearn\n- PyPi (\ud83d\udce5 96K / month \u00b7 \ud83d\udce6 130 \u00b7 \u23f1\ufe0f 10.02.2022):\npip install hmmlearn\n- Conda (\ud83d\udce5 150K \u00b7 \u23f1\ufe0f 05.11.2022):\nconda install -c conda-forge hmmlearn\n\n\nfilterpy (\ud83e\udd4831 \u00b7  \u2b50 2.5K) - Python Kalman filtering and optimal estimation library. Implements.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 43 \u00b7 \ud83d\udd00 540 \u00b7 \ud83d\udce6 1.8K \u00b7 \ud83d\udccb 210 - 25% open \u00b7 \u23f1\ufe0f 22.08.2022):\ngit clone https://github.com/rlabbe/filterpy\n- PyPi (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 130 \u00b7 \u23f1\ufe0f 10.10.2018):\npip install filterpy\n- Conda (\ud83d\udce5 170K \u00b7 \u23f1\ufe0f 05.05.2020):\nconda install -c conda-forge filterpy\n\n\npgmpy (\ud83e\udd4831 \u00b7  \u2b50 2.2K) - Python Library for learning (Structure and Parameter), inference.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 650 \u00b7 \ud83d\udce5 180 \u00b7 \ud83d\udce6 440 \u00b7 \ud83d\udccb 810 - 27% open \u00b7 \u23f1\ufe0f 03.11.2022):\ngit clone https://github.com/pgmpy/pgmpy\n- PyPi (\ud83d\udce5 64K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 30.06.2022):\npip install pgmpy\n\n\nemcee (\ud83e\udd4831 \u00b7  \u2b50 1.3K) - The Python ensemble sampling toolkit for affine-invariant MCMC. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 65 \u00b7 \ud83d\udd00 420 \u00b7 \ud83d\udce6 1.6K \u00b7 \ud83d\udccb 270 - 16% open \u00b7 \u23f1\ufe0f 12.10.2022):\ngit clone https://github.com/dfm/emcee\n- PyPi (\ud83d\udce5 97K / month \u00b7 \ud83d\udce6 310 \u00b7 \u23f1\ufe0f 10.05.2022):\npip install emcee\n- Conda (\ud83d\udce5 250K \u00b7 \u23f1\ufe0f 28.09.2022):\nconda install -c conda-forge emcee\n\n\npatsy (\ud83e\udd4831 \u00b7  \u2b50 860) - Describing statistical models in Python using symbolic formulas. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 60K \u00b7 \ud83d\udccb 140 - 48% open \u00b7 \u23f1\ufe0f 09.10.2022):\ngit clone https://github.com/pydata/patsy\n- PyPi (\ud83d\udce5 8.2M / month \u00b7 \ud83d\udce6 2.7K \u00b7 \u23f1\ufe0f 26.09.2021):\npip install patsy\n- Conda (\ud83d\udce5 6.4M \u00b7 \u23f1\ufe0f 09.10.2022):\nconda install -c conda-forge patsy\n\n\npandas-ta (\ud83e\udd4929 \u00b7  \u2b50 3.1K) - Technical Analysis Indicators - Pandas TA is an easy to use.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 45 \u00b7 \ud83d\udd00 660 \u00b7 \ud83d\udce6 940 \u00b7 \ud83d\udccb 450 - 18% open \u00b7 \u23f1\ufe0f 24.09.2022):\ngit clone https://github.com/twopirllc/pandas-ta\n- PyPi (\ud83d\udce5 67K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 28.07.2021):\npip install pandas-ta\n- Conda (\ud83d\udce5 3K \u00b7 \u23f1\ufe0f 05.10.2021):\nconda install -c conda-forge pandas-ta\n\n\nSALib (\ud83e\udd4929 \u00b7  \u2b50 650) - Sensitivity Analysis Library in Python. Contains Sobol, Morris, FAST, and.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 39 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udccb 300 - 13% open \u00b7 \u23f1\ufe0f 29.10.2022):\ngit clone https://github.com/SALib/SALib\n- PyPi (\ud83d\udce5 270K / month \u00b7 \ud83d\udce6 63 \u00b7 \u23f1\ufe0f 22.06.2022):\npip install salib\n- Conda (\ud83d\udce5 99K \u00b7 \u23f1\ufe0f 19.10.2022):\nconda install -c conda-forge salib\n\n\npomegranate (\ud83e\udd4928 \u00b7  \u2b50 3K) - Fast, flexible and easy to use probabilistic modelling in Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 66 \u00b7 \ud83d\udd00 540 \u00b7 \ud83d\udce6 780 \u00b7 \ud83d\udccb 690 - 10% open \u00b7 \u23f1\ufe0f 04.07.2022):\ngit clone https://github.com/jmschrei/pomegranate\n- PyPi (\ud83d\udce5 55K / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 21.02.2022):\npip install pomegranate\n- Conda (\ud83d\udce5 110K \u00b7 \u23f1\ufe0f 19.09.2022):\nconda install -c conda-forge pomegranate\n\n\nbambi (\ud83e\udd4927 \u00b7  \u2b50 850) - BAyesian Model-Building Interface (Bambi) in Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 26 \u00b7 \ud83d\udd00 92 \u00b7 \ud83d\udce6 43 \u00b7 \ud83d\udccb 290 - 21% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/bambinos/bambi\n- PyPi (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 06.06.2022):\npip install bambi\n- Conda (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 29.08.2022):\nconda install -c conda-forge bambi\n\n\nOrbit (\ud83e\udd4924 \u00b7  \u2b50 1.5K) - A Python package for Bayesian forecasting with object-oriented design.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 380 - 15% open \u00b7 \u23f1\ufe0f 14.09.2022):\ngit clone https://github.com/uber/orbit\n- PyPi (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 28.04.2022):\npip install orbit-ml\n\n\nBaal (\ud83e\udd4918 \u00b7  \u2b50 680) - Library to enable Bayesian active learning in your research or labeling.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 64 \u00b7 \ud83d\udccb 90 - 24% open \u00b7 \u23f1\ufe0f 19.11.2022):\ngit clone https://github.com/baal-org/baal\n- PyPi (\ud83d\udce5 570 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 03.05.2022):\npip install baal\n- Conda (\ud83d\udce5 3.9K \u00b7 \u23f1\ufe0f 31.10.2022):\nconda install -c conda-forge baal\n\n\nShow 7 hidden projects...\n\npingouin (\ud83e\udd4929 \u00b7  \u2b50 1.2K) - Statistical package in Python based on Pandas. \u2757\ufe0fGPL-3.0\nEdward (\ud83e\udd4928 \u00b7  \u2b50 4.7K \u00b7 \ud83d\udc80) - A probabilistic programming language in TensorFlow. Deep.. Apache-2 \nPyStan (\ud83e\udd4927 \u00b7  \u2b50 220) - PyStan, a Python interface to Stan, a platform for statistical modeling... ISC\npyhsmm (\ud83e\udd4921 \u00b7  \u2b50 530 \u00b7 \ud83d\udc80) - Bayesian inference in HSMMs and HMMs. MIT\nscikit-posthocs (\ud83e\udd4921 \u00b7  \u2b50 270) - Multiple Pairwise Comparisons (Post Hoc) Tests in Python. MIT \nFunsor (\ud83e\udd4918 \u00b7  \u2b50 200) - Functional tensors for probabilistic programming. Apache-2 \nZhuSuan (\ud83e\udd4916 \u00b7  \u2b50 2.2K \u00b7 \ud83d\udc80) - A probabilistic programming library for Bayesian deep learning,.. MIT \n\nAdversarial Robustness\nLibraries for testing the robustness of machine learning models against attacks with adversarial/malicious examples.\nART (\ud83e\udd4734 \u00b7  \u2b50 3.4K) - Adversarial Robustness Toolbox (ART) - Python Library for Machine Learning.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 910 \u00b7 \ud83d\udce6 270 \u00b7 \ud83d\udccb 740 - 12% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/Trusted-AI/adversarial-robustness-toolbox\n- PyPi (\ud83d\udce5 41K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 01.07.2022):\npip install adversarial-robustness-toolbox\n- Conda (\ud83d\udce5 18K \u00b7 \u23f1\ufe0f 16.11.2022):\nconda install -c conda-forge adversarial-robustness-toolbox\n\n\nTextAttack (\ud83e\udd4830 \u00b7  \u2b50 2.1K) - TextAttack is a Python framework for adversarial attacks, data.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 55 \u00b7 \ud83d\udd00 280 \u00b7 \ud83d\udce6 100 \u00b7 \ud83d\udccb 230 - 10% open \u00b7 \u23f1\ufe0f 06.11.2022):\ngit clone https://github.com/QData/TextAttack\n- PyPi (\ud83d\udce5 9.1K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 25.05.2022):\npip install textattack\n- Conda (\ud83d\udce5 4.5K \u00b7 \u23f1\ufe0f 29.06.2021):\nconda install -c conda-forge textattack\n\n\nFoolbox (\ud83e\udd4828 \u00b7  \u2b50 2.4K) - A Python toolbox to create adversarial examples that fool neural networks.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 32 \u00b7 \ud83d\udd00 400 \u00b7 \ud83d\udce6 340 \u00b7 \ud83d\udccb 360 - 6% open \u00b7 \u23f1\ufe0f 25.05.2022):\ngit clone https://github.com/bethgelab/foolbox\n- PyPi (\ud83d\udce5 7.6K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 02.04.2022):\npip install foolbox\n- Conda (\ud83d\udce5 8.6K \u00b7 \u23f1\ufe0f 30.04.2021):\nconda install -c conda-forge foolbox\n\n\nAdvBox (\ud83e\udd4919 \u00b7  \u2b50 1.3K) - Advbox is a toolbox to generate adversarial examples that fool neural.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udccb 38 - 21% open \u00b7 \u23f1\ufe0f 08.08.2022):\ngit clone https://github.com/advboxes/AdvBox\n- PyPi (\ud83d\udce5 29 / month \u00b7 \u23f1\ufe0f 05.12.2018):\npip install advbox\n\n\nrobustness (\ud83e\udd4919 \u00b7  \u2b50 750 \u00b7 \ud83d\udca4) - A library for experimenting with, training and evaluating neural.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 89 \u00b7 \ud83d\udccb 76 - 26% open \u00b7 \u23f1\ufe0f 14.02.2022):\ngit clone https://github.com/MadryLab/robustness\n- PyPi (\ud83d\udce5 5.3K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 01.12.2020):\npip install robustness\n- Conda (\ud83d\udce5 5.2K \u00b7 \u23f1\ufe0f 30.04.2021):\nconda install -c conda-forge robustness\n\n\nShow 4 hidden projects...\n\nCleverHans (\ud83e\udd4830 \u00b7  \u2b50 5.7K \u00b7 \ud83d\udc80) - An adversarial example library for constructing attacks,.. MIT \nadvertorch (\ud83e\udd4922 \u00b7  \u2b50 1.1K) - A Toolbox for Adversarial Robustness Research. \u2757\ufe0fGPL-3.0 \ntextflint (\ud83e\udd4916 \u00b7  \u2b50 580) - Unified Multilingual Robustness Evaluation Toolkit for Natural.. \u2757\ufe0fGPL-3.0\nAdversary (\ud83e\udd4914 \u00b7  \u2b50 370 \u00b7 \ud83d\udc80) - Tool to generate adversarial text examples and test machine.. MIT\n\nGPU & Accelerator Utilities\nLibraries that require and make use of CUDA/GPU or other accelerator hardware capabilities to optimize machine learning tasks.\nCuPy (\ud83e\udd4738 \u00b7  \u2b50 6.5K) - NumPy & SciPy for GPU. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 320 \u00b7 \ud83d\udd00 640 \u00b7 \ud83d\udce5 49K \u00b7 \ud83d\udce6 1.3K \u00b7 \ud83d\udccb 1.9K - 23% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/cupy/cupy\n- PyPi (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 30.06.2022):\npip install cupy\n- Conda (\ud83d\udce5 2.1M \u00b7 \u23f1\ufe0f 20.11.2022):\nconda install -c conda-forge cupy\n- Docker Hub (\ud83d\udce5 56K \u00b7 \u2b50 8 \u00b7 \u23f1\ufe0f 11.11.2022):\ndocker pull cupy/cupy\n\n\ncuDF (\ud83e\udd4731 \u00b7  \u2b50 5.2K) - cuDF - GPU DataFrame Library. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 260 \u00b7 \ud83d\udd00 650 \u00b7 \ud83d\udccb 5K - 13% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/rapidsai/cudf\n- PyPi (\ud83d\udce5 1.8K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 01.06.2020):\npip install cudf\n\n\ngpustat (\ud83e\udd4731 \u00b7  \u2b50 3.1K) - A simple command-line utility for querying and monitoring GPU status. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 2.4K \u00b7 \ud83d\udccb 99 - 23% open \u00b7 \u23f1\ufe0f 20.11.2022):\ngit clone https://github.com/wookayin/gpustat\n- PyPi (\ud83d\udce5 1M / month \u00b7 \ud83d\udce6 120 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install gpustat\n- Conda (\ud83d\udce5 150K \u00b7 \u23f1\ufe0f 11.10.2022):\nconda install -c conda-forge gpustat\n\n\nPyCUDA (\ud83e\udd4731 \u00b7  \u2b50 1.4K) - CUDA integration for Python, plus shiny features. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 79 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 1.6K \u00b7 \ud83d\udccb 250 - 31% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/inducer/pycuda\n- PyPi (\ud83d\udce5 37K / month \u00b7 \ud83d\udce6 200 \u00b7 \u23f1\ufe0f 24.06.2022):\npip install pycuda\n- Conda (\ud83d\udce5 140K \u00b7 \u23f1\ufe0f 23.11.2022):\nconda install -c conda-forge pycuda\n\n\ncuML (\ud83e\udd4829 \u00b7  \u2b50 3K) - cuML - RAPIDS Machine Learning Library. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 430 \u00b7 \ud83d\udccb 2.1K - 33% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/rapidsai/cuml\n- PyPi (\ud83d\udce5 930 / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 01.06.2020):\npip install cuml\n\n\nArrayFire (\ud83e\udd4828 \u00b7  \u2b50 4K) - ArrayFire: a general purpose GPU library. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 86 \u00b7 \ud83d\udd00 490 \u00b7 \ud83d\udce5 3K \u00b7 \ud83d\udccb 1.6K - 16% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/arrayfire/arrayfire\n- PyPi (\ud83d\udce5 650 / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 22.02.2022):\npip install arrayfire\n\n\nApex (\ud83e\udd4827 \u00b7  \u2b50 6.8K) - A PyTorch Extension: Tools for easy mixed precision and distributed.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 1.3K \u00b7 \ud83d\udccb 1.1K - 55% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/NVIDIA/apex\n- Conda (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 06.04.2022):\nconda install -c conda-forge nvidia-apex\n\n\noptimum (\ud83e\udd4827 \u00b7  \u2b50 790) - Accelerate training and inference of Transformers with easy to use.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 84 \u00b7 \ud83d\udce6 50 \u00b7 \ud83d\udccb 160 - 43% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/huggingface/optimum\n- PyPi (\ud83d\udce5 46K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 13.06.2022):\npip install optimum\n- Conda (\ud83d\udce5 4.8K \u00b7 \u23f1\ufe0f 12.07.2022):\nconda install -c conda-forge optimum\n\n\ncuGraph (\ud83e\udd4925 \u00b7  \u2b50 1.2K) - cuGraph - RAPIDS Graph Analytics Library. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 91 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udccb 1.1K - 18% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/rapidsai/cugraph\n- PyPi (\ud83d\udce5 130 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 01.06.2020):\npip install cugraph\n- Conda (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 29.04.2021):\nconda install -c conda-forge libcugraph\n\n\nDALI (\ud83e\udd4924 \u00b7  \u2b50 4.1K) - A GPU-accelerated library containing highly optimized building blocks.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 79 \u00b7 \ud83d\udd00 530 \u00b7 \ud83d\udccb 1.3K - 17% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/NVIDIA/DALI\n\n\nscikit-cuda (\ud83e\udd4924 \u00b7  \u2b50 920 \u00b7 \ud83d\udca4) - Python interface to GPU-powered libraries. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 46 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udce6 210 \u00b7 \ud83d\udccb 220 - 22% open \u00b7 \u23f1\ufe0f 31.03.2022):\ngit clone https://github.com/lebedov/scikit-cuda\n- PyPi (\ud83d\udce5 550 / month \u00b7 \ud83d\udce6 44 \u00b7 \u23f1\ufe0f 27.05.2019):\npip install scikit-cuda\n\n\nMerlin (\ud83e\udd4924 \u00b7  \u2b50 390) - NVIDIA Merlin is an open source library providing end-to-end GPU-.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 65 \u00b7 \ud83d\udccb 300 - 46% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/NVIDIA-Merlin/Merlin\n- PyPi (\ud83d\udce5 9.7K / month \u00b7 \u23f1\ufe0f 14.06.2022):\npip install merlin-core\n\n\nVulkan Kompute (\ud83e\udd4920 \u00b7  \u2b50 1K) - General purpose GPU compute framework built on Vulkan to.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 69 \u00b7 \ud83d\udce5 210 \u00b7 \ud83d\udce6 5 \u00b7 \ud83d\udccb 180 - 32% open \u00b7 \u23f1\ufe0f 20.11.2022):\ngit clone https://github.com/KomputeProject/kompute\n- PyPi (\ud83d\udce5 82 / month \u00b7 \u23f1\ufe0f 13.04.2022):\npip install kp\n\n\ncuSignal (\ud83e\udd4919 \u00b7  \u2b50 640) - GPU accelerated signal processing. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 42 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udccb 140 - 11% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/rapidsai/cusignal\n\n\nShow 6 hidden projects...\n\nBlazingSQL (\ud83e\udd4922 \u00b7  \u2b50 1.8K \u00b7 \ud83d\udc80) - BlazingSQL is a lightweight, GPU accelerated, SQL engine for.. Apache-2\nGPUtil (\ud83e\udd4922 \u00b7  \u2b50 920 \u00b7 \ud83d\udc80) - A Python module for getting the GPU status from NVIDA GPUs using.. MIT\npy3nvml (\ud83e\udd4922 \u00b7  \u2b50 210 \u00b7 \ud83d\udca4) - Python 3 Bindings for NVML library. Get NVIDIA GPU status inside.. BSD-3\nnvidia-ml-py3 (\ud83e\udd4920 \u00b7  \u2b50 92 \u00b7 \ud83d\udc80) - Python 3 Bindings for the NVIDIA Management Library. BSD-3\nSpeedTorch (\ud83e\udd4915 \u00b7  \u2b50 660 \u00b7 \ud83d\udc80) - Library for faster pinned CPU - GPU transfer in Pytorch. MIT \nipyexperiments (\ud83e\udd4914 \u00b7  \u2b50 150 \u00b7 \ud83d\udca4) - jupyter/ipython experiment containers for GPU and.. Apache-2 \n\nTensorflow Utilities\nLibraries that extend TensorFlow with additional capabilities.\nTensorFlow Datasets (\ud83e\udd4736 \u00b7  \u2b50 3.5K) - TFDS is a collection of datasets ready to use with.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 270 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udccb 1.3K - 50% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/tensorflow/datasets\n- PyPi (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 02.06.2022):\npip install tensorflow-datasets\n- Conda (\ud83d\udce5 10K \u00b7 \u23f1\ufe0f 06.10.2022):\nconda install -c conda-forge tensorflow-datasets\n\n\ntensorflow-hub (\ud83e\udd4736 \u00b7  \u2b50 3.2K) - A library for transfer learning by reusing parts of.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 98 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce6 14K \u00b7 \ud83d\udccb 670 - 2% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/tensorflow/hub\n- PyPi (\ud83d\udce5 4.1M / month \u00b7 \ud83d\udce6 300 \u00b7 \u23f1\ufe0f 14.04.2021):\npip install tensorflow-hub\n- Conda (\ud83d\udce5 72K \u00b7 \u23f1\ufe0f 18.04.2021):\nconda install -c conda-forge tensorflow-hub\n\n\nTF Addons (\ud83e\udd4835 \u00b7  \u2b50 1.6K) - Useful extra functionality for TensorFlow 2.x maintained by.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 590 \u00b7 \ud83d\udce6 7.8K \u00b7 \ud83d\udccb 970 - 25% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/tensorflow/addons\n- PyPi (\ud83d\udce5 1.3M / month \u00b7 \ud83d\udce6 180 \u00b7 \u23f1\ufe0f 14.06.2022):\npip install tensorflow-addons\n\n\ntensor2tensor (\ud83e\udd4833 \u00b7  \u2b50 13K) - Library of deep learning models and datasets designed to.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 3.1K \u00b7 \ud83d\udce6 1.2K \u00b7 \ud83d\udccb 1.3K - 46% open \u00b7 \u23f1\ufe0f 24.10.2022):\ngit clone https://github.com/tensorflow/tensor2tensor\n- PyPi (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 93 \u00b7 \u23f1\ufe0f 17.06.2020):\npip install tensor2tensor\n\n\nTFX (\ud83e\udd4833 \u00b7  \u2b50 1.9K) - TFX is an end-to-end platform for deploying production ML pipelines. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 620 \u00b7 \ud83d\udccb 850 - 26% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/tensorflow/tfx\n- PyPi (\ud83d\udce5 380K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 26.05.2022):\npip install tfx\n\n\nTensorFlow Transform (\ud83e\udd4833 \u00b7  \u2b50 940) - Input pipeline framework. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce6 1.1K \u00b7 \ud83d\udccb 190 - 19% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/tensorflow/transform\n- PyPi (\ud83d\udce5 4.2M / month \u00b7 \ud83d\udce6 56 \u00b7 \u23f1\ufe0f 29.06.2022):\npip install tensorflow-transform\n\n\nTF Model Optimization (\ud83e\udd4832 \u00b7  \u2b50 1.3K) - A toolkit to optimize ML models for deployment for.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 74 \u00b7 \ud83d\udd00 300 \u00b7 \ud83d\udce6 2.3K \u00b7 \ud83d\udccb 340 - 53% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/tensorflow/model-optimization\n- PyPi (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 21 \u00b7 \u23f1\ufe0f 18.03.2022):\npip install tensorflow-model-optimization\n\n\nKeras-Preprocessing (\ud83e\udd4929 \u00b7  \u2b50 1K \u00b7 \ud83d\udca4) - Utilities for working with image data, text data, and.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 52 \u00b7 \ud83d\udd00 440 \u00b7 \ud83d\udccb 200 - 47% open \u00b7 \u23f1\ufe0f 17.02.2022):\ngit clone https://github.com/keras-team/keras-preprocessing\n- PyPi (\ud83d\udce5 8.5M / month \u00b7 \ud83d\udce6 1.5K \u00b7 \u23f1\ufe0f 14.05.2020):\npip install keras-preprocessing\n- Conda (\ud83d\udce5 1.6M \u00b7 \u23f1\ufe0f 15.01.2021):\nconda install -c conda-forge keras-preprocessing\n\n\nTensorFlow I/O (\ud83e\udd4929 \u00b7  \u2b50 590) - Dataset, streaming, and file system extensions.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 95 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udccb 560 - 38% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/tensorflow/io\n- PyPi (\ud83d\udce5 760K / month \u00b7 \ud83d\udce6 25 \u00b7 \u23f1\ufe0f 18.05.2022):\npip install tensorflow-io\n\n\nNeural Structured Learning (\ud83e\udd4928 \u00b7  \u2b50 950) - Training neural models with structured signals. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 36 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 280 \u00b7 \ud83d\udccb 68 - 4% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/tensorflow/neural-structured-learning\n- PyPi (\ud83d\udce5 15K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 18.08.2020):\npip install neural-structured-learning\n\n\nTensorFlow Cloud (\ud83e\udd4925 \u00b7  \u2b50 330) - The TensorFlow Cloud repository provides APIs that.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 72 \u00b7 \ud83d\udce6 180 \u00b7 \ud83d\udccb 87 - 68% open \u00b7 \u23f1\ufe0f 11.10.2022):\ngit clone https://github.com/tensorflow/cloud\n- PyPi (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 17.06.2021):\npip install tensorflow-cloud\n\n\nSaliency (\ud83e\udd4923 \u00b7  \u2b50 840) - Framework-agnostic implementation for state-of-the-art saliency.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 47 \u00b7 \ud83d\udccb 29 - 10% open \u00b7 \u23f1\ufe0f 13.05.2022):\ngit clone https://github.com/PAIR-code/saliency\n- PyPi (\ud83d\udce5 2.1K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 14.06.2022):\npip install saliency\n\n\nTF Compression (\ud83e\udd4922 \u00b7  \u2b50 690) - Data compression in TensorFlow. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udccb 93 - 3% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/tensorflow/compression\n- PyPi (\ud83d\udce5 6.8K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 30.05.2022):\npip install tensorflow-compression\n\n\ntffm (\ud83e\udd4920 \u00b7  \u2b50 780 \u00b7 \ud83d\udca4) - TensorFlow implementation of an arbitrary order Factorization Machine. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 40 - 45% open \u00b7 \u23f1\ufe0f 17.01.2022):\ngit clone https://github.com/geffy/tffm\n- PyPi (\ud83d\udce5 1.5K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 17.01.2022):\npip install tffm\n\n\nShow 2 hidden projects...\n\nefficientnet (\ud83e\udd4925 \u00b7  \u2b50 2K \u00b7 \ud83d\udc80) - Implementation of EfficientNet model. Keras and.. Apache-2 \nTensorNets (\ud83e\udd4920 \u00b7  \u2b50 1K \u00b7 \ud83d\udc80) - High level network definitions with pre-trained weights in.. MIT \n\nJax Utilities\nLibraries that extend Jax with additional capabilities.\nequinox (\ud83e\udd4725 \u00b7  \u2b50 870) - Callable PyTrees and filtered transforms = neural networks in.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 46 \u00b7 \ud83d\udce6 68 \u00b7 \ud83d\udccb 120 - 22% open \u00b7 \u23f1\ufe0f 18.11.2022):\ngit clone https://github.com/patrick-kidger/equinox\n- PyPi (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install equinox\n\n\nevojax (\ud83e\udd4919 \u00b7  \u2b50 580) - EvoJAX: Hardware-accelerated Neuroevolution. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 48 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 14 - 28% open \u00b7 \u23f1\ufe0f 07.11.2022):\ngit clone https://github.com/google/evojax\n- PyPi (\ud83d\udce5 760 / month \u00b7 \u23f1\ufe0f 15.06.2022):\npip install evojax\n- Conda (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 05.10.2022):\nconda install -c conda-forge evojax\n\n\nShow 1 hidden projects...\n\njaxdf (\ud83e\udd499 \u00b7  \u2b50 63) - A JAX-based research framework for writing differentiable.. \u2757\ufe0fLGPL-3.0 \n\nSklearn Utilities\nLibraries that extend scikit-learn with additional capabilities.\nMLxtend (\ud83e\udd4736 \u00b7  \u2b50 4.2K) - A library of extension and helper modules for Pythons data.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 90 \u00b7 \ud83d\udd00 780 \u00b7 \ud83d\udce6 7.3K \u00b7 \ud83d\udccb 450 - 28% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/rasbt/mlxtend\n- PyPi (\ud83d\udce5 1.9M / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 27.05.2022):\npip install mlxtend\n- Conda (\ud83d\udce5 240K \u00b7 \u23f1\ufe0f 17.09.2022):\nconda install -c conda-forge mlxtend\n\n\nimbalanced-learn (\ud83e\udd4734 \u00b7  \u2b50 6.2K) - A Python Package to Tackle the Curse of Imbalanced.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 63 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udce6 13K \u00b7 \ud83d\udccb 530 - 11% open \u00b7 \u23f1\ufe0f 16.05.2022):\ngit clone https://github.com/scikit-learn-contrib/imbalanced-learn\n- PyPi (\ud83d\udce5 3.5M / month \u00b7 \ud83d\udce6 270 \u00b7 \u23f1\ufe0f 16.05.2022):\npip install imbalanced-learn\n- Conda (\ud83d\udce5 300K \u00b7 \u23f1\ufe0f 16.05.2022):\nconda install -c conda-forge imbalanced-learn\n\n\ncategory_encoders (\ud83e\udd4734 \u00b7  \u2b50 2.1K) - A library of sklearn compatible categorical variable.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 370 \u00b7 \ud83d\udce6 4.1K \u00b7 \ud83d\udccb 260 - 23% open \u00b7 \u23f1\ufe0f 20.11.2022):\ngit clone https://github.com/scikit-learn-contrib/category_encoders\n- PyPi (\ud83d\udce5 950K / month \u00b7 \ud83d\udce6 120 \u00b7 \u23f1\ufe0f 02.06.2022):\npip install category_encoders\n- Conda (\ud83d\udce5 200K \u00b7 \u23f1\ufe0f 06.10.2022):\nconda install -c conda-forge category_encoders\n\n\nscikit-learn-intelex (\ud83e\udd4830 \u00b7  \u2b50 840) - Intel(R) Extension for Scikit-learn is a seamless way.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 60 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 3.5K \u00b7 \ud83d\udccb 210 - 53% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/intel/scikit-learn-intelex\n- PyPi (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 16.06.2022):\npip install scikit-learn-intelex\n- Conda (\ud83d\udce5 95K \u00b7 \u23f1\ufe0f 20.09.2022):\nconda install -c conda-forge scikit-learn-intelex\n\n\nscikit-multilearn (\ud83e\udd4827 \u00b7  \u2b50 800) - A scikit-learn based module for multi-label et. al... BSD-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 890 \u00b7 \ud83d\udccb 200 - 53% open \u00b7 \u23f1\ufe0f 09.07.2022):\ngit clone https://github.com/scikit-multilearn/scikit-multilearn\n- PyPi (\ud83d\udce5 100K / month \u00b7 \ud83d\udce6 18 \u00b7 \u23f1\ufe0f 10.12.2018):\npip install scikit-multilearn\n\n\nscikit-lego (\ud83e\udd4925 \u00b7  \u2b50 930) - Extra blocks for scikit-learn pipelines. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 99 \u00b7 \ud83d\udce6 69 \u00b7 \ud83d\udccb 260 - 9% open \u00b7 \u23f1\ufe0f 02.11.2022):\ngit clone https://github.com/koaning/scikit-lego\n- PyPi (\ud83d\udce5 28K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 05.06.2022):\npip install scikit-lego\n- Conda (\ud83d\udce5 28K \u00b7 \u23f1\ufe0f 03.11.2022):\nconda install -c conda-forge scikit-lego\n\n\nscikit-opt (\ud83e\udd4924 \u00b7  \u2b50 3.7K) - Genetic Algorithm, Particle Swarm Optimization, Simulated.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 840 \u00b7 \ud83d\udce6 91 \u00b7 \ud83d\udccb 160 - 32% open \u00b7 \u23f1\ufe0f 15.07.2022):\ngit clone https://github.com/guofei9987/scikit-opt\n- PyPi (\ud83d\udce5 2.7K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 14.01.2022):\npip install scikit-opt\n\n\nsklearn-contrib-lightning (\ud83e\udd4923 \u00b7  \u2b50 1.6K \u00b7 \ud83d\udca4) - Large-scale linear classification, regression and.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 210 \u00b7 \ud83d\udce5 240 \u00b7 \ud83d\udce6 110 \u00b7 \ud83d\udccb 96 - 56% open \u00b7 \u23f1\ufe0f 30.01.2022):\ngit clone https://github.com/scikit-learn-contrib/lightning\n- PyPi (\ud83d\udce5 2K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 30.01.2022):\npip install sklearn-contrib-lightning\n- Conda (\ud83d\udce5 180K \u00b7 \u23f1\ufe0f 31.10.2022):\nconda install -c conda-forge sklearn-contrib-lightning\n\n\niterative-stratification (\ud83e\udd4921 \u00b7  \u2b50 730) - scikit-learn cross validators for iterative.. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 66 \u00b7 \ud83d\udce6 240 \u00b7 \ud83d\udccb 23 - 17% open \u00b7 \u23f1\ufe0f 06.06.2022):\ngit clone https://github.com/trent-b/iterative-stratification\n- PyPi (\ud83d\udce5 67K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 03.10.2021):\npip install iterative-stratification\n\n\ncombo (\ud83e\udd4921 \u00b7  \u2b50 600) - (AAAI 20) A Python Toolbox for Machine Learning Model Combination. BSD-2  xgboost\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 500 \u00b7 \ud83d\udccb 14 - 78% open \u00b7 \u23f1\ufe0f 07.07.2022):\ngit clone https://github.com/yzhao062/combo\n- PyPi (\ud83d\udce5 57K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 02.04.2022):\npip install combo\n\n\nDESlib (\ud83e\udd4918 \u00b7  \u2b50 420) - A Python library for dynamic classifier and ensemble selection. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 73 \u00b7 \ud83d\udce6 35 \u00b7 \ud83d\udccb 150 - 10% open \u00b7 \u23f1\ufe0f 07.06.2022):\ngit clone https://github.com/scikit-learn-contrib/DESlib\n- PyPi (\ud83d\udce5 780 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 08.02.2021):\npip install deslib\n\n\nscikit-tda (\ud83e\udd4916 \u00b7  \u2b50 370 \u00b7 \ud83d\udca4) - Topological Data Analysis for Python. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 45 \u00b7 \ud83d\udce6 36 \u00b7 \ud83d\udccb 19 - 78% open \u00b7 \u23f1\ufe0f 13.03.2022):\ngit clone https://github.com/scikit-tda/scikit-tda\n- PyPi (\ud83d\udce5 810 / month \u00b7 \u23f1\ufe0f 03.08.2021):\npip install scikit-tda\n\n\nShow 7 hidden projects...\n\nscikit-survival (\ud83e\udd4827 \u00b7  \u2b50 860) - Survival analysis built on top of scikit-learn. \u2757\ufe0fGPL-3.0 \nfancyimpute (\ud83e\udd4826 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - Multivariate imputation and matrix completion.. Apache-2 \nsklearn-crfsuite (\ud83e\udd4826 \u00b7  \u2b50 410 \u00b7 \ud83d\udc80) - scikit-learn inspired API for CRFsuite. MIT \nskope-rules (\ud83e\udd4921 \u00b7  \u2b50 490 \u00b7 \ud83d\udc80) - machine learning with logical rules in Python. \u2757\ufe0fBSD-1-Clause \nceler (\ud83e\udd4920 \u00b7  \u2b50 170) - Fast solver for L1-type problems: Lasso, sparse Logisitic regression,.. BSD-3 \nskggm (\ud83e\udd4917 \u00b7  \u2b50 210 \u00b7 \ud83d\udca4) - Scikit-learn compatible estimation of general graphical models. MIT \ndabl (\ud83e\udd4917 \u00b7  \u2b50 120 \u00b7 \ud83d\udc80) - Data Analysis Baseline Library. BSD-3 \n\nPytorch Utilities\nLibraries that extend Pytorch with additional capabilities.\naccelerate (\ud83e\udd4734 \u00b7  \u2b50 3.2K) - A simple way to train and use PyTorch models with multi-.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 73 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 1.5K \u00b7 \ud83d\udccb 420 - 10% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/huggingface/accelerate\n- PyPi (\ud83d\udce5 800K / month \u00b7 \ud83d\udce6 23 \u00b7 \u23f1\ufe0f 15.06.2022):\npip install accelerate\n- Conda (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 13.11.2022):\nconda install -c conda-forge accelerate\n\n\nPML (\ud83e\udd4731 \u00b7  \u2b50 4.9K) - The easiest way to use deep metric learning in your application. Modular,.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 590 \u00b7 \ud83d\udce6 390 \u00b7 \ud83d\udccb 400 - 13% open \u00b7 \u23f1\ufe0f 01.11.2022):\ngit clone https://github.com/KevinMusgrave/pytorch-metric-learning\n- PyPi (\ud83d\udce5 150K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 29.06.2022):\npip install pytorch-metric-learning\n- Conda (\ud83d\udce5 9K \u00b7 \u23f1\ufe0f 01.11.2022):\nconda install -c metric-learning pytorch-metric-learning\n\n\ntorchdiffeq (\ud83e\udd4729 \u00b7  \u2b50 4.3K) - Differentiable ODE solvers with full GPU support and.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 740 \u00b7 \ud83d\udce6 540 \u00b7 \ud83d\udccb 180 - 22% open \u00b7 \u23f1\ufe0f 10.08.2022):\ngit clone https://github.com/rtqichen/torchdiffeq\n- PyPi (\ud83d\udce5 720K / month \u00b7 \ud83d\udce6 20 \u00b7 \u23f1\ufe0f 22.04.2022):\npip install torchdiffeq\n- Conda (\ud83d\udce5 8.4K \u00b7 \u23f1\ufe0f 03.06.2021):\nconda install -c conda-forge torchdiffeq\n\n\nlightning-flash (\ud83e\udd4828 \u00b7  \u2b50 1.6K) - Your PyTorch AI Factory - Flash enables you to easily.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 80 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 490 - 4% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/Lightning-AI/lightning-flash\n- PyPi (\ud83d\udce5 3.8K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 11.05.2022):\npip install lightning-flash\n- Conda (\ud83d\udce5 8.4K \u00b7 \u23f1\ufe0f 08.11.2022):\nconda install -c conda-forge lightning-flash\n\n\npytorch-optimizer (\ud83e\udd4827 \u00b7  \u2b50 2.6K \u00b7 \ud83d\udca4) - torch-optimizer -- collection of optimizers for.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 25 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 740 \u00b7 \ud83d\udccb 54 - 44% open \u00b7 \u23f1\ufe0f 11.11.2021):\ngit clone https://github.com/jettify/pytorch-optimizer\n- PyPi (\ud83d\udce5 58K / month \u00b7 \ud83d\udce6 23 \u00b7 \u23f1\ufe0f 31.10.2021):\npip install torch_optimizer\n- Conda (\ud83d\udce5 5.9K \u00b7 \u23f1\ufe0f 31.10.2021):\nconda install -c conda-forge torch-optimizer\n\n\ntorch-scatter (\ud83e\udd4826 \u00b7  \u2b50 1.1K) - PyTorch Extension Library of Optimized Scatter Operations. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 290 - 7% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/rusty1s/pytorch_scatter\n- PyPi (\ud83d\udce5 38K / month \u00b7 \ud83d\udce6 53 \u00b7 \u23f1\ufe0f 22.10.2021):\npip install torch-scatter\n- Conda (\ud83d\udce5 130K \u00b7 \u23f1\ufe0f 28.07.2022):\nconda install -c conda-forge pytorch_scatter\n\n\ntinygrad (\ud83e\udd4825 \u00b7  \u2b50 9.2K) - You like pytorch? You like micrograd? You love tinygrad!. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 70 \u00b7 \ud83d\udd00 810 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 130 - 14% open \u00b7 \u23f1\ufe0f 15.11.2022):\ngit clone https://github.com/geohot/tinygrad\n\n\nPyTorch Sparse (\ud83e\udd4825 \u00b7  \u2b50 740) - PyTorch Extension Library of Optimized Autograd Sparse.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 120 \u00b7 \ud83d\udccb 220 - 15% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/rusty1s/pytorch_sparse\n- PyPi (\ud83d\udce5 34K / month \u00b7 \ud83d\udce6 47 \u00b7 \u23f1\ufe0f 30.06.2022):\npip install torch-sparse\n- Conda (\ud83d\udce5 150K \u00b7 \u23f1\ufe0f 23.08.2022):\nconda install -c conda-forge pytorch_sparse\n\n\nTabNet (\ud83e\udd4824 \u00b7  \u2b50 1.9K) - PyTorch implementation of TabNet paper :.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 390 \u00b7 \ud83d\udccb 270 - 15% open \u00b7 \u23f1\ufe0f 27.06.2022):\ngit clone https://github.com/dreamquark-ai/tabnet\n- PyPi (\ud83d\udce5 42K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 02.02.2021):\npip install pytorch-tabnet\n- Conda (\ud83d\udce5 2.5K \u00b7 \u23f1\ufe0f 30.12.2021):\nconda install -c conda-forge pytorch-tabnet\n\n\nPytorch Toolbelt (\ud83e\udd4824 \u00b7  \u2b50 1.3K) - PyTorch extensions for fast R&D prototyping and Kaggle.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udccb 27 - 11% open \u00b7 \u23f1\ufe0f 25.10.2022):\ngit clone https://github.com/BloodAxe/pytorch-toolbelt\n- PyPi (\ud83d\udce5 6.2K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 27.06.2022):\npip install pytorch_toolbelt\n\n\nreformer-pytorch (\ud83e\udd4920 \u00b7  \u2b50 1.8K) - Reformer, the efficient Transformer, in Pytorch. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udccb 120 - 11% open \u00b7 \u23f1\ufe0f 24.06.2022):\ngit clone https://github.com/lucidrains/reformer-pytorch\n- PyPi (\ud83d\udce5 1.4K / month \u00b7 \u23f1\ufe0f 06.11.2021):\npip install reformer-pytorch\n\n\nTorch-Struct (\ud83e\udd4919 \u00b7  \u2b50 1K \u00b7 \ud83d\udca4) - Fast, general, and tested differentiable structured.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 85 \u00b7 \ud83d\udccb 54 - 44% open \u00b7 \u23f1\ufe0f 30.01.2022):\ngit clone https://github.com/harvardnlp/pytorch-struct\n- PyPi (\ud83d\udce5 69K / month \u00b7 \u23f1\ufe0f 14.02.2021):\npip install torch-struct\n\n\nPerformer Pytorch (\ud83e\udd4919 \u00b7  \u2b50 890 \u00b7 \ud83d\udca4) - An implementation of Performer, a linear attention-.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 66 \u00b7 \ud83d\udccb 79 - 45% open \u00b7 \u23f1\ufe0f 02.02.2022):\ngit clone https://github.com/lucidrains/performer-pytorch\n- PyPi (\ud83d\udce5 5.7K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 02.02.2022):\npip install performer-pytorch\n\n\nTez (\ud83e\udd4917 \u00b7  \u2b50 1.1K) - Tez is a super-simple and lightweight Trainer for PyTorch. It also.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce6 35 \u00b7 \ud83d\udccb 40 - 55% open \u00b7 \u23f1\ufe0f 16.09.2022):\ngit clone https://github.com/abhishekkrthakur/tez\n- PyPi (\ud83d\udce5 830 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 05.06.2022):\npip install tez\n\n\nTensor Sensor (\ud83e\udd4916 \u00b7  \u2b50 700 \u00b7 \ud83d\udca4) - The goal of this library is to generate more helpful.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 35 \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 24 - 33% open \u00b7 \u23f1\ufe0f 07.04.2022):\ngit clone https://github.com/parrt/tensor-sensor\n- PyPi (\ud83d\udce5 1.8K / month \u00b7 \u23f1\ufe0f 11.12.2021):\npip install tensor-sensor\n- Conda (\ud83d\udce5 1.6K \u00b7 \u23f1\ufe0f 11.12.2021):\nconda install -c conda-forge tensor-sensor\n\n\nmadgrad (\ud83e\udd4915 \u00b7  \u2b50 770 \u00b7 \ud83d\udca4) - MADGRAD Optimization Method. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 55 \u00b7 \ud83d\udce6 37 \u00b7 \ud83d\udccb 9 - 22% open \u00b7 \u23f1\ufe0f 10.03.2022):\ngit clone https://github.com/facebookresearch/madgrad\n- PyPi (\ud83d\udce5 6.2K / month \u00b7 \u23f1\ufe0f 08.03.2022):\npip install madgrad\n\n\nShow 16 hidden projects...\n\npretrainedmodels (\ud83e\udd4731 \u00b7  \u2b50 8.7K \u00b7 \ud83d\udc80) - Pretrained ConvNets for pytorch: NASNet, ResNeXt,.. BSD-3 \npytorch-summary (\ud83e\udd4828 \u00b7  \u2b50 3.7K \u00b7 \ud83d\udc80) - Model summary in PyTorch similar to model.summary().. MIT \nEfficientNet-PyTorch (\ud83e\udd4826 \u00b7  \u2b50 7.2K \u00b7 \ud83d\udc80) - A PyTorch implementation of EfficientNet and.. Apache-2 \nTorchmeta (\ud83e\udd4824 \u00b7  \u2b50 1.7K \u00b7 \ud83d\udc80) - A collection of extensions and data-loaders for few-shot.. MIT \nSRU (\ud83e\udd4923 \u00b7  \u2b50 2.1K \u00b7 \ud83d\udc80) - Training RNNs as Fast as CNNs (https://arxiv.org/abs/1709.02755). MIT \nEfficientNets (\ud83e\udd4923 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Pretrained EfficientNet, EfficientNet-Lite, MixNet,.. Apache-2 \nHigher (\ud83e\udd4922 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - higher is a pytorch library allowing users to obtain higher.. Apache-2 \ntorchsde (\ud83e\udd4922 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - Differentiable SDE solvers with GPU support and efficient.. Apache-2 \nPoutyne (\ud83e\udd4921 \u00b7  \u2b50 530) - A simplified framework and utilities for PyTorch. \u2757\ufe0fLGPL-3.0 \nAdaBound (\ud83e\udd4920 \u00b7  \u2b50 2.9K \u00b7 \ud83d\udc80) - An optimizer that trains as fast as Adam and as good as SGD. Apache-2 \nAntialiased CNNs (\ud83e\udd4920 \u00b7  \u2b50 1.6K \u00b7 \ud83d\udc80) - pip install antialiased-cnns to improve stability and.. \u2757\ufe0fCC BY-NC-SA 4.0 \npytorchviz (\ud83e\udd4918 \u00b7  \u2b50 2.4K \u00b7 \ud83d\udc80) - A small package to create visualizations of PyTorch execution.. MIT\nmicrograd (\ud83e\udd4917 \u00b7  \u2b50 3.3K \u00b7 \ud83d\udc80) - A tiny scalar-valued autograd engine and a neural net library.. MIT \nLambda Networks (\ud83e\udd4917 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Implementation of LambdaNetworks, a new approach to.. MIT \nPywick (\ud83e\udd4915 \u00b7  \u2b50 380 \u00b7 \ud83d\udc80) - High-level batteries-included neural network training library for.. MIT \nTorchDrift (\ud83e\udd4914 \u00b7  \u2b50 260) - Drift Detection for your PyTorch Models. Apache-2 \n\nDatabase Clients\nLibraries for connecting to, operating, and querying databases.\n\ud83d\udd17\u00a0best-of-python - DB Clients ( \u2b50 2.6K)  - Collection of database clients for python.\nOthers\nscipy (\ud83e\udd4749 \u00b7  \u2b50 11K) - Ecosystem of open-source software for mathematics, science, and engineering. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 1.4K \u00b7 \ud83d\udd00 4.5K \u00b7 \ud83d\udce5 360K \u00b7 \ud83d\udce6 600K \u00b7 \ud83d\udccb 8.9K - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/scipy/scipy\n- PyPi (\ud83d\udce5 46M / month \u00b7 \ud83d\udce6 58K \u00b7 \u23f1\ufe0f 20.10.2022):\npip install scipy\n- Conda (\ud83d\udce5 30M \u00b7 \u23f1\ufe0f 09.11.2022):\nconda install -c conda-forge scipy\n\n\nSymPy (\ud83e\udd4747 \u00b7  \u2b50 9.8K) - A computer algebra system written in pure Python. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 1.2K \u00b7 \ud83d\udd00 3.8K \u00b7 \ud83d\udce5 470K \u00b7 \ud83d\udce6 48K \u00b7 \ud83d\udccb 13K - 35% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/sympy/sympy\n- PyPi (\ud83d\udce5 3.3M / month \u00b7 \ud83d\udce6 4.2K \u00b7 \u23f1\ufe0f 20.03.2022):\npip install sympy\n- Conda (\ud83d\udce5 2.6M \u00b7 \u23f1\ufe0f 27.10.2022):\nconda install -c conda-forge sympy\n\n\nStreamlit (\ud83e\udd4741 \u00b7  \u2b50 22K) - Streamlit The fastest way to build data apps in Python. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce6 500 \u00b7 \ud83d\udccb 2.9K - 19% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/streamlit/streamlit\n- PyPi (\ud83d\udce5 990K / month \u00b7 \ud83d\udce6 420 \u00b7 \u23f1\ufe0f 27.07.2022):\npip install streamlit\n\n\nPaddleHub (\ud83e\udd4736 \u00b7  \u2b50 11K) - Awesome pre-trained models toolkit based on PaddlePaddle... Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 68 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce5 580 \u00b7 \ud83d\udce6 1K \u00b7 \ud83d\udccb 1.2K - 42% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/PaddlePaddle/PaddleHub\n- PyPi (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 28.12.2021):\npip install paddlehub\n\n\nGradio (\ud83e\udd4735 \u00b7  \u2b50 11K) - Wrap UIs around any model, share with anyone. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 680 \u00b7 \ud83d\udccb 1.4K - 19% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/gradio-app/gradio\n- PyPi (\ud83d\udce5 910K / month \u00b7 \ud83d\udce6 22 \u00b7 \u23f1\ufe0f 04.07.2022):\npip install gradio\n\n\nPyOD (\ud83e\udd4735 \u00b7  \u2b50 6.5K) - A Comprehensive and Scalable Python Library for Outlier Detection (Anomaly.. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 44 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udce6 1.7K \u00b7 \ud83d\udccb 280 - 50% open \u00b7 \u23f1\ufe0f 24.10.2022):\ngit clone https://github.com/yzhao062/pyod\n- PyPi (\ud83d\udce5 590K / month \u00b7 \ud83d\udce6 34 \u00b7 \u23f1\ufe0f 05.07.2022):\npip install pyod\n- Conda (\ud83d\udce5 46K \u00b7 \u23f1\ufe0f 24.10.2022):\nconda install -c conda-forge pyod\n\n\nDatasette (\ud83e\udd4734 \u00b7  \u2b50 6.7K) - An open source multi-tool for exploring and publishing data. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 71 \u00b7 \ud83d\udd00 460 \u00b7 \ud83d\udce5 41 \u00b7 \ud83d\udce6 790 \u00b7 \ud83d\udccb 1.5K - 29% open \u00b7 \u23f1\ufe0f 19.11.2022):\ngit clone https://github.com/simonw/datasette\n- PyPi (\ud83d\udce5 250K / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 02.05.2022):\npip install datasette\n- Conda (\ud83d\udce5 13K \u00b7 \u23f1\ufe0f 21.11.2022):\nconda install -c conda-forge datasette\n\n\nAutograd (\ud83e\udd4833 \u00b7  \u2b50 6.1K) - Efficiently computes derivatives of numpy code. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 52 \u00b7 \ud83d\udd00 840 \u00b7 \ud83d\udce6 4.2K \u00b7 \ud83d\udccb 400 - 42% open \u00b7 \u23f1\ufe0f 29.09.2022):\ngit clone https://github.com/HIPS/autograd\n- PyPi (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 290 \u00b7 \u23f1\ufe0f 08.04.2022):\npip install autograd\n- Conda (\ud83d\udce5 250K \u00b7 \u23f1\ufe0f 03.10.2022):\nconda install -c conda-forge autograd\n\n\nDeepChem (\ud83e\udd4833 \u00b7  \u2b50 4K) - Democratizing Deep-Learning for Drug Discovery, Quantum Chemistry,.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce6 140 \u00b7 \ud83d\udccb 1.5K - 32% open \u00b7 \u23f1\ufe0f 16.11.2022):\ngit clone https://github.com/deepchem/deepchem\n- PyPi (\ud83d\udce5 9.1K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 06.07.2022):\npip install deepchem\n- Conda (\ud83d\udce5 64K \u00b7 \u23f1\ufe0f 19.01.2022):\nconda install -c conda-forge deepchem\n\n\nPythran (\ud83e\udd4833 \u00b7  \u2b50 1.8K) - Ahead of Time compiler for numeric kernels. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 68 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 340 \u00b7 \ud83d\udccb 780 - 15% open \u00b7 \u23f1\ufe0f 18.11.2022):\ngit clone https://github.com/serge-sans-paille/pythran\n- PyPi (\ud83d\udce5 570K / month \u00b7 \ud83d\udce6 17 \u00b7 \u23f1\ufe0f 14.12.2021):\npip install pythran\n- Conda (\ud83d\udce5 300K \u00b7 \u23f1\ufe0f 26.10.2022):\nconda install -c conda-forge pythran\n\n\ncarla (\ud83e\udd4832 \u00b7  \u2b50 8.5K) - Open-source simulator for autonomous driving research. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 2.6K \u00b7 \ud83d\udce6 290 \u00b7 \ud83d\udccb 4.1K - 17% open \u00b7 \u23f1\ufe0f 20.10.2022):\ngit clone https://github.com/carla-simulator/carla\n- PyPi (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 17.11.2021):\npip install carla\n\n\nRiver (\ud83e\udd4832 \u00b7  \u2b50 3.8K) - Online machine learning in Python. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 88 \u00b7 \ud83d\udd00 420 \u00b7 \ud83d\udce6 180 \u00b7 \ud83d\udccb 380 - 0% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/online-ml/river\n- PyPi (\ud83d\udce5 18K / month \u00b7 \ud83d\udce6 14 \u00b7 \u23f1\ufe0f 06.06.2022):\npip install river\n- Conda (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 31.10.2022):\nconda install -c conda-forge river\n\n\nhdbscan (\ud83e\udd4832 \u00b7  \u2b50 2.3K) - A high performance implementation of HDBSCAN clustering. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 81 \u00b7 \ud83d\udd00 430 \u00b7 \ud83d\udce6 1.7K \u00b7 \ud83d\udccb 460 - 65% open \u00b7 \u23f1\ufe0f 10.11.2022):\ngit clone https://github.com/scikit-learn-contrib/hdbscan\n- PyPi (\ud83d\udce5 470K / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 08.02.2022):\npip install hdbscan\n- Conda (\ud83d\udce5 1.3M \u00b7 \u23f1\ufe0f 02.11.2022):\nconda install -c conda-forge hdbscan\n\n\ndatalad (\ud83e\udd4832 \u00b7  \u2b50 370) - Keep code, data, containers under control with git and git-annex. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 97 \u00b7 \ud83d\udccb 3.8K - 13% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/datalad/datalad\n- PyPi (\ud83d\udce5 10K / month \u00b7 \ud83d\udce6 57 \u00b7 \u23f1\ufe0f 06.07.2022):\npip install datalad\n- Conda (\ud83d\udce5 280K \u00b7 \u23f1\ufe0f 07.11.2022):\nconda install -c conda-forge datalad\n\n\nPennyLane (\ud83e\udd4831 \u00b7  \u2b50 1.6K) - PennyLane is a cross-platform Python library for differentiable.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 420 \u00b7 \ud83d\udce5 62 \u00b7 \ud83d\udccb 940 - 32% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/PennyLaneAI/PennyLane\n- PyPi (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 34 \u00b7 \u23f1\ufe0f 20.06.2022):\npip install pennylane\n- Conda (\ud83d\udce5 6K \u00b7 \u23f1\ufe0f 01.05.2022):\nconda install -c conda-forge pennylane\n\n\nkmodes (\ud83e\udd4831 \u00b7  \u2b50 1.1K) - Python implementations of the k-modes and k-prototypes clustering.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 380 \u00b7 \ud83d\udce6 1.6K \u00b7 \ud83d\udccb 150 - 11% open \u00b7 \u23f1\ufe0f 06.09.2022):\ngit clone https://github.com/nicodv/kmodes\n- PyPi (\ud83d\udce5 470K / month \u00b7 \ud83d\udce6 26 \u00b7 \u23f1\ufe0f 14.04.2022):\npip install kmodes\n- Conda (\ud83d\udce5 20K \u00b7 \u23f1\ufe0f 06.09.2022):\nconda install -c conda-forge kmodes\n\n\nadapter-transformers (\ud83e\udd4831 \u00b7  \u2b50 1.1K) - Huggingface Transformers + Adapters =. Apache-2 huggingface\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 1.4K \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 100 \u00b7 \ud83d\udccb 250 - 17% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/Adapter-Hub/adapter-transformers\n- PyPi (\ud83d\udce5 27K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 18.05.2022):\npip install adapter-transformers\n\n\npyopencl (\ud83e\udd4831 \u00b7  \u2b50 940) - OpenCL integration for Python, plus shiny features. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 92 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 850 \u00b7 \ud83d\udccb 320 - 21% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/inducer/pyopencl\n- PyPi (\ud83d\udce5 37K / month \u00b7 \ud83d\udce6 190 \u00b7 \u23f1\ufe0f 22.06.2022):\npip install pyopencl\n- Conda (\ud83d\udce5 750K \u00b7 \u23f1\ufe0f 22.11.2022):\nconda install -c conda-forge pyopencl\n\n\ntensorly (\ud83e\udd4830 \u00b7  \u2b50 1.3K) - TensorLy: Tensor Learning in Python. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 57 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 310 \u00b7 \ud83d\udccb 210 - 23% open \u00b7 \u23f1\ufe0f 22.11.2022):\ngit clone https://github.com/tensorly/tensorly\n- PyPi (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 30 \u00b7 \u23f1\ufe0f 08.11.2021):\npip install tensorly\n- Conda (\ud83d\udce5 350K \u00b7 \u23f1\ufe0f 09.12.2021):\nconda install -c conda-forge tensorly\n\n\ncausalml (\ud83e\udd4829 \u00b7  \u2b50 3.6K) - Uplift modeling and causal inference with machine learning.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 48 \u00b7 \ud83d\udd00 570 \u00b7 \ud83d\udce6 55 \u00b7 \ud83d\udccb 300 - 23% open \u00b7 \u23f1\ufe0f 10.11.2022):\ngit clone https://github.com/uber/causalml\n- PyPi (\ud83d\udce5 59K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 14.03.2022):\npip install causalml\n\n\nalibi-detect (\ud83e\udd4829 \u00b7  \u2b50 1.6K) - Algorithms for outlier, adversarial and drift detection. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 300 - 34% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/SeldonIO/alibi-detect\n- PyPi (\ud83d\udce5 33K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 01.06.2022):\npip install alibi-detect\n\n\npyjanitor (\ud83e\udd4829 \u00b7  \u2b50 1K) - Clean APIs for data cleaning. Python implementation of R package Janitor. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 250 \u00b7 \ud83d\udccb 510 - 21% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/pyjanitor-devs/pyjanitor\n- PyPi (\ud83d\udce5 39K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 03.05.2022):\npip install pyjanitor\n- Conda (\ud83d\udce5 150K \u00b7 \u23f1\ufe0f 17.10.2022):\nconda install -c conda-forge pyjanitor\n\n\npysc2 (\ud83e\udd4828 \u00b7  \u2b50 7.6K) - StarCraft II Learning Environment. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 36 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce5 30K \u00b7 \ud83d\udce6 450 \u00b7 \ud83d\udccb 280 - 18% open \u00b7 \u23f1\ufe0f 07.08.2022):\ngit clone https://github.com/deepmind/pysc2\n- PyPi (\ud83d\udce5 2.7K / month \u00b7 \ud83d\udce6 26 \u00b7 \u23f1\ufe0f 27.09.2019):\npip install pysc2\n\n\navalanche (\ud83e\udd4828 \u00b7  \u2b50 1.1K) - Avalanche: an End-to-End Library for Continual Learning based on.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 60 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce5 4 \u00b7 \ud83d\udce6 16 \u00b7 \ud83d\udccb 610 - 12% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/ContinualAI/avalanche\n- PyPi (\ud83d\udce5 760 / month \u00b7 \u23f1\ufe0f 14.06.2022):\npip install avalanche-lib\n\n\nMars (\ud83e\udd4927 \u00b7  \u2b50 2.5K) - Mars is a tensor-based unified framework for large-scale data.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 45 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udccb 1.2K - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/mars-project/mars\n- PyPi (\ud83d\udce5 32K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 12.06.2022):\npip install pymars\n\n\nanomalib (\ud83e\udd4927 \u00b7  \u2b50 1.4K) - An anomaly detection library comprising state-of-the-art algorithms.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 4 \u00b7 \ud83d\udccb 320 - 10% open \u00b7 \u23f1\ufe0f 21.11.2022):\ngit clone https://github.com/openvinotoolkit/anomalib\n- PyPi (\ud83d\udce5 2.6K / month \u00b7 \u23f1\ufe0f 05.07.2022):\npip install anomalib\n\n\nTabPy (\ud83e\udd4927 \u00b7  \u2b50 1.3K) - Execute Python code on the fly and display results in Tableau visualizations:. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 46 \u00b7 \ud83d\udd00 500 \u00b7 \ud83d\udce6 99 \u00b7 \ud83d\udccb 300 - 3% open \u00b7 \u23f1\ufe0f 06.10.2022):\ngit clone https://github.com/tableau/TabPy\n- PyPi (\ud83d\udce5 19K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 20.01.2022):\npip install tabpy\n- Conda (\ud83d\udce5 3.4K \u00b7 \u23f1\ufe0f 02.05.2022):\nconda install -c anaconda tabpy-client\n\n\npycm (\ud83e\udd4926 \u00b7  \u2b50 1.3K) - Multi-class confusion matrix library in Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 190 - 6% open \u00b7 \u23f1\ufe0f 17.08.2022):\ngit clone https://github.com/sepandhaghighi/pycm\n- PyPi (\ud83d\udce5 36K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 27.04.2022):\npip install pycm\n\n\nmetric-learn (\ud83e\udd4926 \u00b7  \u2b50 1.3K) - Metric learning algorithms in Python. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 240 \u00b7 \ud83d\udccb 170 - 30% open \u00b7 \u23f1\ufe0f 21.06.2022):\ngit clone https://github.com/scikit-learn-contrib/metric-learn\n- PyPi (\ud83d\udce5 37K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 02.07.2020):\npip install metric-learn\n- Conda (\ud83d\udce5 7.8K \u00b7 \u23f1\ufe0f 02.07.2020):\nconda install -c conda-forge metric-learn\n\n\nTrax (\ud83e\udd4925 \u00b7  \u2b50 7.2K) - Trax Deep Learning with Clear Code and Speed. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 78 \u00b7 \ud83d\udd00 740 \u00b7 \ud83d\udce6 84 \u00b7 \ud83d\udccb 210 - 42% open \u00b7 \u23f1\ufe0f 09.11.2022):\ngit clone https://github.com/google/trax\n- PyPi (\ud83d\udce5 4.2K / month \u00b7 \u23f1\ufe0f 26.10.2021):\npip install trax\n\n\nAugLy (\ud83e\udd4925 \u00b7  \u2b50 4.6K) - A data augmentations library for audio, image, text, and video. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 26 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 46 \u00b7 \ud83d\udccb 70 - 22% open \u00b7 \u23f1\ufe0f 21.09.2022):\ngit clone https://github.com/facebookresearch/AugLy\n- PyPi (\ud83d\udce5 2.1K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 28.03.2022):\npip install augly\n\n\ngplearn (\ud83e\udd4925 \u00b7  \u2b50 1.2K) - Genetic Programming in Python, with a scikit-learn inspired API. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 290 \u00b7 \ud83d\udccb 200 - 9% open \u00b7 \u23f1\ufe0f 04.08.2022):\ngit clone https://github.com/trevorstephens/gplearn\n- PyPi (\ud83d\udce5 4.6K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 03.05.2022):\npip install gplearn\n- Conda (\ud83d\udce5 3.9K \u00b7 \u23f1\ufe0f 04.05.2022):\nconda install -c conda-forge gplearn\n\n\nPySwarms (\ud83e\udd4925 \u00b7  \u2b50 1K) - A research toolkit for particle swarm optimization in Python. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 44 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce6 200 \u00b7 \ud83d\udccb 210 - 5% open \u00b7 \u23f1\ufe0f 03.07.2022):\ngit clone https://github.com/ljvmiranda921/pyswarms\n- PyPi (\ud83d\udce5 7.7K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 03.01.2021):\npip install pyswarms\n\n\nPrince (\ud83e\udd4924 \u00b7  \u2b50 900) - Python factor analysis library (PCA, CA, MCA, MFA, FAMD). MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 260 \u00b7 \ud83d\udccb 110 - 37% open \u00b7 \u23f1\ufe0f 07.09.2022):\ngit clone https://github.com/MaxHalford/prince\n- PyPi (\ud83d\udce5 25K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 06.10.2020):\npip install prince\n- Conda (\ud83d\udce5 13K \u00b7 \u23f1\ufe0f 30.04.2021):\nconda install -c conda-forge prince-factor-analysis\n\n\nAstroML (\ud83e\udd4923 \u00b7  \u2b50 860) - Machine learning, statistics, and data mining for astronomy and.. BSD-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 280 \u00b7 \ud83d\udccb 160 - 39% open \u00b7 \u23f1\ufe0f 03.10.2022):\ngit clone https://github.com/astroML/astroML\n- PyPi (\ud83d\udce5 1.2K / month \u00b7 \ud83d\udce6 33 \u00b7 \u23f1\ufe0f 01.03.2022):\npip install astroML\n- Conda (\ud83d\udce5 34K \u00b7 \u23f1\ufe0f 02.03.2022):\nconda install -c conda-forge astroml\n\n\nfindspark (\ud83e\udd4923 \u00b7  \u2b50 460 \u00b7 \ud83d\udca4) - Find pyspark to make it importable. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 70 \u00b7 \ud83d\udce6 2.9K \u00b7 \ud83d\udccb 23 - 52% open \u00b7 \u23f1\ufe0f 11.02.2022):\ngit clone https://github.com/minrk/findspark\n- PyPi (\ud83d\udce5 2.2M / month \u00b7 \ud83d\udce6 140 \u00b7 \u23f1\ufe0f 11.02.2022):\npip install findspark\n- Conda (\ud83d\udce5 740K \u00b7 \u23f1\ufe0f 11.02.2022):\nconda install -c conda-forge findspark\n\n\nMONAILabel (\ud83e\udd4923 \u00b7  \u2b50 330) - MONAI Label is an intelligent open source image labeling and.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 37 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce5 30K \u00b7 \ud83d\udccb 330 - 17% open \u00b7 \u23f1\ufe0f 24.11.2022):\ngit clone https://github.com/Project-MONAI/MONAILabel\n- PyPi (\ud83d\udce5 560 / month \u00b7 \u23f1\ufe0f 03.07.2022):\npip install monailabel-weekly\n\n\nFeature Engine (\ud83e\udd4922 \u00b7  \u2b50 1.1K) - Feature engineering package with sklearn like functionality. BSD-3\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 36 \u00b7 \ud83d\udd00 240 \u00b7 \u23f1\ufe0f 05.07.2022):\ngit clone https://github.com/solegalli/feature_engine\n- PyPi (\ud83d\udce5 150K / month \u00b7 \u23f1\ufe0f 24.10.2022):\npip install feature_engine\n- Conda (\ud83d\udce5 21K \u00b7 \u23f1\ufe0f 23.11.2022):\nconda install -c conda-forge feature_engine\n\n\nBioPandas (\ud83e\udd4922 \u00b7  \u2b50 540) - Working with molecular structures in pandas DataFrames. BSD-3 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 49 - 40% open \u00b7 \u23f1\ufe0f 06.08.2022):\ngit clone https://github.com/rasbt/biopandas\n- PyPi (\ud83d\udce5 10K / month \u00b7 \ud83d\udce6 16 \u00b7 \u23f1\ufe0f 13.05.2022):\npip install biopandas\n- Conda (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 13.05.2022):\nconda install -c conda-forge biopandas\n\n\nStreamAlert (\ud83e\udd4921 \u00b7  \u2b50 2.7K) - StreamAlert is a serverless, realtime data analysis framework.. Apache-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udccb 340 - 24% open \u00b7 \u23f1\ufe0f 20.07.2022):\ngit clone https://github.com/airbnb/streamalert\n\n\ndstack (\ud83e\udd4921 \u00b7  \u2b50 410) - An open-source tool for teams to build reproducible ML workflows. MPL-2.0\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 22 \u00b7 \ud83d\udccb 130 - 25% open \u00b7 \u23f1\ufe0f 23.11.2022):\ngit clone https://github.com/dstackai/dstack\n- PyPi (\ud83d\udce5 460 / month \u00b7 \u23f1\ufe0f 29.06.2022):\npip install dstack\n\n\nbenchmark_VAE (\ud83e\udd4920 \u00b7  \u2b50 1.1K) - Unifying Generative Autoencoder implementations in.. Apache-2 \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 87 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 27 - 22% open \u00b7 \u23f1\ufe0f 20.10.2022):\ngit clone https://github.com/clementchadebec/benchmark_VAE\n- PyPi (\ud83d\udce5 340 / month \u00b7 \u23f1\ufe0f 05.07.2022):\npip install pythae\n\n\npykale (\ud83e\udd4920 \u00b7  \u2b50 370) - Knowledge-Aware machine LEarning (KALE): accessible machine learning.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 49 \u00b7 \ud83d\udccb 93 - 6% open \u00b7 \u23f1\ufe0f 16.10.2022):\ngit clone https://github.com/pykale/pykale\n- PyPi (\ud83d\udce5 100 / month \u00b7 \u23f1\ufe0f 12.04.2022):\npip install pykale\n\n\nimpyute (\ud83e\udd4920 \u00b7  \u2b50 330 \u00b7 \ud83d\udca4) - Data imputations library to preprocess datasets with missing data. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 46 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 64 - 42% open \u00b7 \u23f1\ufe0f 06.11.2021):\ngit clone https://github.com/eltonlaw/impyute\n- PyPi (\ud83d\udce5 4.6K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 29.04.2019):\npip install impyute\n\n\nSUOD (\ud83e\udd4919 \u00b7  \u2b50 340) - (MLSys 21) An Acceleration System for Large-scare Unsupervised Heterogeneous.. BSD-2\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 43 \u00b7 \ud83d\udce6 450 \u00b7 \ud83d\udccb 9 - 66% open \u00b7 \u23f1\ufe0f 07.07.2022):\ngit clone https://github.com/yzhao062/SUOD\n- PyPi (\ud83d\udce5 43K / month \u00b7 \u23f1\ufe0f 01.10.2021):\npip install suod\n\n\napricot (\ud83e\udd4917 \u00b7  \u2b50 450 \u00b7 \ud83d\udca4) - apricot implements submodular optimization for the purpose of.. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 46 \u00b7 \ud83d\udce5 19 \u00b7 \ud83d\udce6 33 \u00b7 \ud83d\udccb 29 - 34% open \u00b7 \u23f1\ufe0f 18.11.2021):\ngit clone https://github.com/jmschrei/apricot\n- PyPi (\ud83d\udce5 530 / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 28.09.2020):\npip install apricot-select\n\n\nKD-Lib (\ud83e\udd4916 \u00b7  \u2b50 450) - A Pytorch Knowledge Distillation library for benchmarking and.. MIT \n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 40 \u00b7 \ud83d\udccb 61 - 21% open \u00b7 \u23f1\ufe0f 14.10.2022):\ngit clone https://github.com/SforAiDl/KD_Lib\n- PyPi (\ud83d\udce5 42 / month \u00b7 \u23f1\ufe0f 18.05.2022):\npip install KD-Lib\n\n\ntraingenerator (\ud83e\udd4913 \u00b7  \u2b50 1.2K) - A web app to generate template code for machine learning. MIT\n\n\nGitHub (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udccb 16 - 81% open \u00b7 \u23f1\ufe0f 30.06.2022):\ngit clone https://github.com/jrieke/traingenerator\n\n\nShow 17 hidden projects...\n\nagate (\ud83e\udd4831 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - A Python data analysis library that is optimized for humans instead of.. MIT\nCython BLIS (\ud83e\udd4831 \u00b7  \u2b50 190) - Fast matrix-multiplication as a self-contained Python library no.. BSD-3\ncleanlab (\ud83e\udd4829 \u00b7  \u2b50 4.2K) - The standard data-centric AI package for data quality and machine.. \u2757\ufe0fAGPL-3.0\npyclustering (\ud83e\udd4927 \u00b7  \u2b50 1K \u00b7 \ud83d\udc80) - pyclustering is a Python, C++ data mining library. BSD-3\nminisom (\ud83e\udd4926 \u00b7  \u2b50 1.2K) - MiniSom is a minimalistic implementation of the Self Organizing.. \u2757\ufe0fCC-BY-3.0\nmodAL (\ud83e\udd4924 \u00b7  \u2b50 1.9K \u00b7 \ud83d\udc80) - A modular active learning framework for Python. MIT \nmlens (\ud83e\udd4923 \u00b7  \u2b50 760 \u00b7 \ud83d\udc80) - ML-Ensemble high performance ensemble learning. MIT\nvecstack (\ud83e\udd4922 \u00b7  \u2b50 670 \u00b7 \ud83d\udc80) - Python package for stacking (machine learning technique). MIT\nmetricflow (\ud83e\udd4921 \u00b7  \u2b50 710) - MetricFlow allows you to define, build, and maintain metrics in.. \u2757\ufe0fAGPL-3.0\nrrcf (\ud83e\udd4921 \u00b7  \u2b50 410 \u00b7 \ud83d\udc80) - Implementation of the Robust Random Cut Forest algorithm for anomaly.. MIT\nopyrator (\ud83e\udd4920 \u00b7  \u2b50 2.7K \u00b7 \ud83d\udc80) - Turns your machine learning code into microservices with web API,.. MIT\nscikit-rebate (\ud83e\udd4919 \u00b7  \u2b50 370 \u00b7 \ud83d\udc80) - A scikit-learn-compatible Python implementation of.. MIT \npandas-ml (\ud83e\udd4919 \u00b7  \u2b50 300 \u00b7 \ud83d\udc80) - pandas, scikit-learn, xgboost and seaborn integration. BSD-3  \npymdp (\ud83e\udd4919 \u00b7  \u2b50 230) - A Python implementation of active inference for Markov Decision Processes. MIT\nbaikal (\ud83e\udd4918 \u00b7  \u2b50 590 \u00b7 \ud83d\udc80) - A graph-based functional API for building complex scikit-learn.. BSD-3\nNeuralCompression (\ud83e\udd4915 \u00b7  \u2b50 290) - A collection of tools for neural compression enthusiasts. MIT\nnylon (\ud83e\udd4911 \u00b7  \u2b50 78 \u00b7 \ud83d\udc80) - An intelligent, flexible grammar of machine learning. MIT\n\nRelated Resources\nPapers With Code: Discover ML papers, code, and evaluation tables.\nSotabench: Discover & compare open-source ML models.\nGoogle Dataset Search: Dataset search engine by Google.\nDataset List: List of the biggest ML datasets from across the web.\nAwesome Public Datasets: A topic-centric list of open datasets.\nBest-of lists: Discover other best-of lists with awesome open-source projects on all kinds of topics.\nbest-of-python-dev: A ranked list of awesome python developer tools and libraries.\nbest-of-web-python: A ranked list of awesome python libraries for web development.\nContribution\nContributions are encouraged and always welcome! If you like to add or update projects, choose one of the following ways:\nOpen an issue by selecting one of the provided categories from the issue page and fill in the requested information.\nModify the projects.yaml with your additions or changes, and submit a pull request. This can also be done directly via the Github UI.\nIf you like to contribute to or share suggestions regarding the project metadata collection or markdown generation, please refer to the best-of-generator repository. If you like to create your own best-of list, we recommend to follow this guide.\nFor more information on how to add or update projects, please read the contribution guidelines. By participating in this project, you agree to abide by its Code of Conduct.\nLicense",
	"data-analysis data-science data-visualization deep-learning deploy gradio gradio-interface interface machine-learning models python python-notebook ui ui-components": "\n\nWelcome to Gradio\nQuickly create beautiful user interfaces around your machine learning models. Gradio (pronounced GRAY-dee-oh) makes it easy for you to demo your model in your browser or let people \"try it out\" by dragging-and-dropping in their own images, pasting text, recording their own voice, etc. and seeing what the model outputs.  \nGradio is useful for:\nDemoing your machine learning models for clients / collaborators / users / students\nDeploying your models quickly with automatic shareable links and getting feedback on model performance\nDebugging your model interactively during development using built-in manipulation and interpretation tools\nYou can find an interactive version of the following Getting Started at https://gradio.app/getting_started.\nGetting Started\nPrerequisite: Python 3.7+ and that's it! \nQuick Start\nTo get Gradio running with a simple \"Hello, World\" example, follow these three steps:\n1. Install Gradio from pip.\nbash\npip install gradio\n2. Run the code below as a Python script or in a Python notebook (or in a  colab notebook).\npython\nimport gradio as gr\ndef greet(name):\n    return \"Hello \" + name + \"!!\"\niface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\niface.launch()\n3. The interface below will appear automatically within the Python notebook, or pop in a browser on  http://localhost:7860  if running from a script.\nUnderstanding the Interface class\nGradio can wrap almost any Python function with an easy-to-use user interface. In the example above, we saw a simple text-based function. But the function could be anything from image enhancer to a tax calculator to (most commonly) the prediction function of a pretrained machine learning model.\nThe core  Interface  class is initialized with three parameters:\nfn: the function to wrap\ninputs: the input component type(s), e.g. \"image\" or \"audio\" (see docs for complete list)\noutputs: the output component type(s) e.g. \"image\" or \"label\" (see docs for complete list)\nWith these three arguments, we can quickly create interfaces and  launch()  them. But what if you want to change how the UI components look or behave?\nCustomizable Components\nLet's say we want to customize the input text field - for example, we wanted it to be larger and have a text hint. If we use the actual input class for  Textbox  instead of using the string shortcut, we have access to much more customizability. To see a list of all the components we support and how you can customize them, check out the Docs.\npython\nimport gradio as gr\ndef greet(name):\n    return \"Hello \" + name + \"!\"\niface = gr.Interface(\n    fn=greet,\n    inputs=gr.inputs.Textbox(lines=2, placeholder=\"Name Here...\"),\n    outputs=\"text\",\n)\niface.launch()\nMultiple Inputs and Outputs\nLet's say we had a much more complex function, with multiple inputs and outputs. In the example below, we have a function that takes a string, boolean, and number, and returns a string and number. Take a look how we pass a list of input and output components.\npython\nimport gradio as gr\ndef greet(name, is_morning, temperature):\n    salutation = \"Good morning\" if is_morning else \"Good evening\"\n    greeting = \"%s %s. It is %s degrees today\" % (salutation, name, temperature)\n    celsius = (temperature - 32) * 5 / 9\n    return greeting, round(celsius, 2)\niface = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"checkbox\", gr.inputs.Slider(0, 100)],\n    outputs=[\"text\", \"number\"],\n)\niface.launch()\nWe simply wrap the components in a list. Each component in the inputs list corresponds to one of the parameters of the function, in order. Each component in the outputs list corresponds to one of the values returned by the function, again in order. \nWorking with Images\nLet's try an image-to-image function. When using the  Image  component, your function will receive a numpy array of your specified size, with the shape  (width, height, 3), where the last dimension represents the RGB values. We'll return an image as well in the form of a numpy array.\npython\nimport numpy as np\nimport gradio as gr\ndef sepia(input_img):\n    sepia_filter = np.array(\n        [[0.393, 0.769, 0.189], [0.349, 0.686, 0.168], [0.272, 0.534, 0.131]]\n    )\n    sepia_img = input_img.dot(sepia_filter.T)\n    sepia_img /= sepia_img.max()\n    return sepia_img\niface = gr.Interface(sepia, gr.inputs.Image(shape=(200, 200)), \"image\")\niface.launch()\nAdditionally, our  Image  input interface comes with an 'edit' button which opens tools for cropping, flipping, rotating, drawing over, and applying filters to images. We've found that manipulating images in this way will often reveal hidden flaws in a model.\nIn addition to images, Gradio supports other media input types, such as audio or video uploads, as well as many output components. Read about these in the Docs.\nWorking with DataFrames and Graphs\nYou can use Gradio to support inputs and outputs from your typical data libraries, such as numpy arrays, pandas dataframes, and plotly graphs. Take a look at the demo below (ignore the complicated data manipulation in the function!)\npython\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport gradio as gr\ndef sales_projections(employee_data):\n    sales_data = employee_data.iloc[:, 1:4].astype(\"int\").to_numpy()\n    regression_values = np.apply_along_axis(\n        lambda row: np.array(np.poly1d(np.polyfit([0, 1, 2], row, 2))), 0, sales_data\n    )\n    projected_months = np.repeat(\n        np.expand_dims(np.arange(3, 12), 0), len(sales_data), axis=0\n    )\n    projected_values = np.array(\n        [\n            month * month * regression[0] + month * regression[1] + regression[2]\n            for month, regression in zip(projected_months, regression_values)\n        ]\n    )\n    plt.plot(projected_values.T)\n    plt.legend(employee_data[\"Name\"])\n    return employee_data, plt.gcf(), regression_values\niface = gr.Interface(\n    sales_projections,\n    gr.inputs.Dataframe(\n        headers=[\"Name\", \"Jan Sales\", \"Feb Sales\", \"Mar Sales\"],\n        default=[[\"Jon\", 12, 14, 18], [\"Alice\", 14, 17, 2], [\"Sana\", 8, 9.5, 12]],\n    ),\n    [\"dataframe\", \"plot\", \"numpy\"],\n    description=\"Enter sales figures for employees to predict sales trajectory over year.\",\n)\niface.launch()\nExample Inputs\nYou can provide example data that a user can easily load into the model. This can be helpful to demonstrate the types of inputs the model expects, as well as to provide a way to explore your dataset in conjunction with your model. To load example data, you provide a nested list to the  examples=  keyword argument of the Interface constructor. Each sublist within the outer list represents a data sample, and each element within the sublist represents an input for each input component. The format of example data for each component is specified in the  Docs.\npython\nimport gradio as gr\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.inputs.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    examples=[\n        [5, \"add\", 3],\n        [4, \"divide\", 2],\n        [-4, \"multiply\", 2.5],\n        [0, \"subtract\", 1.2],\n    ],\n    title=\"test calculator\",\n    description=\"heres a sample toy calculator. enjoy!\",\n    flagging_options=[\"this\", \"or\", \"that\"],\n)\niface.launch()\nYou can load a large dataset into the examples to browse and interact with the dataset through Gradio. The examples will be automatically paginated (you can configure this through the examples_per_page argument of Interface) and you can use CTRL + arrow keys to navigate through the examples quickly.\nLive Interfaces\nYou can make interfaces automatically refresh by setting live=True in the interface. Now the interface will recalculate as soon as the user input changes.\npython\nimport gradio as gr\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.inputs.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    live=True,\n)\niface.launch()\nNote there is no submit button, because the interface resubmits automatically on change.\nUsing State\nYour function may use data that persists beyond a single function call. If the data is something accessible to all function calls and all users, you can create a global variable outside the function call and access it inside the function. For example, you may load a large model outside the function and use it inside the function so that every function call does not need to reload the model.\nAnother type of data persistence Gradio supports is session state, where data persists across multiple submits within a page load. However, data is not shared between different users of your model. To store data in a session state, you need to do three things: (1) Pass in an extra parameter into your function, which represents the state of the interface. (2) At the end of the function, return the updated value of the state as an extra return value (3) Add the 'state' input and 'state' output components when creating your Interface. See the chatbot example below: \npython\nimport random\nimport gradio as gr\ndef chat(message, history):\n    history = history or []\n    if message.startswith(\"How many\"):\n        response = random.randint(1, 10)\n    elif message.startswith(\"How\"):\n        response = random.choice([\"Great\", \"Good\", \"Okay\", \"Bad\"])\n    elif message.startswith(\"Where\"):\n        response = random.choice([\"Here\", \"There\", \"Somewhere\"])\n    else:\n        response = \"I don't know\"\n    history.append((message, response))\n    html = \"\"\n    for user_msg, resp_msg in history:\n        html += f\"{user_msg}\"\n        html += f\"{resp_msg}\"\n    html += \"\"\n    return html, history\niface = gr.Interface(\n    chat,\n    [\"text\", \"state\"],\n    [\"html\", \"state\"],\n    css=\"\"\"\n    .chatbox {display:flex;flex-direction:column}\n    .user_msg, .resp_msg {padding:4px;margin-bottom:4px;border-radius:4px;width:80%}\n    .user_msg {background-color:cornflowerblue;color:white;align-self:start}\n    .resp_msg {background-color:lightgray;align-self:self-end}\n\"\"\",\n    allow_screenshot=False,\n    allow_flagging=\"never\",\n)\niface.launch()\nNotice how the state persists across submits within each page, but the state is not shared between the two pages. Some more points to note: you can pass in a default value to the state parameter, which is used as the initial value of the state. The state must be a something that can be serialized to a JSON format (e.g. a dictionary, a list, or a single value. Typically, objects will not work).\nFlagging\nUnderneath the output interfaces, there is a button marked \"Flag\". When a user testing your model sees input with interesting output, such as erroneous or unexpected model behaviour, they can flag the input for the interface creator to review. Within the directory provided by the  flagging_dir=  argument to the Interface constructor, a CSV file will log the flagged inputs. If the interface involves file data, such as for Image and Audio components, folders will be created to store those flagged data as well.\nFor example, with the calculator interface shown above, we would have the flagged data stored in the flagged directory shown below:\ndirectory\n+-- calculator.py\n+-- flagged/\n|   +-- logs.csv\nflagged/logs.csv\ncsv\nnum1,operation,num2,Output\n5,add,7,12\n6,subtract,1.5,4.5\nWith the sepia interface shown above, we would have the flagged data stored in the flagged directory shown below:\ndirectory\n+-- sepia.py\n+-- flagged/\n|   +-- logs.csv\n|   +-- im/\n|   |   +-- 0.png\n|   |   +-- 1.png\n|   +-- Output/\n|   |   +-- 0.png\n|   |   +-- 1.png\nflagged/logs.csv\ncsv\nim,Output\nim/0.png,Output/0.png\nim/1.png,Output/1.png\nYou can review these flagged inputs by manually exploring the flagging directory, or load them into the examples of the Gradio interface by pointing the  examples=  argument to the flagged directory. If you wish for the user to provide a reason for flagging, you can pass a list of strings to the flagging_options argument of Interface. Users will have to select one of the strings when flagging, which will be saved as an additional column to the CSV.\nSharing Interfaces Publicly\nInterfaces can be easily shared publicly by setting share=True in the launch() method. Like this:\npython\ngr.Interface(classify_image, \"image\", \"label\").launch(share=True)\nThis generates a public, shareable link that you can send to anybody! When you send this link, the user on the other side can try out the model in their browser. Because the processing happens on your device (as long as your device stays on!), you don't have to worry about any packaging any dependencies. If you're working out of colab notebook, a share link is always automatically created. It usually looks something like this:  XXXXX.gradio.app. Although the link is served through a gradio link, we are only a proxy for your local server, and do not store any data sent through the interfaces.\nKeep in mind, however, that these links are publicly accessible, meaning that anyone can use your model for prediction! Therefore, make sure not to expose any sensitive information through the functions you write, or allow any critical changes to occur on your device. If you set share=False (the default), only a local link is created, which can be shared by  port-forwarding  with specific users. \nShare links expire after 72 hours. For permanent hosting, see Hosting Gradio Apps on Spaces below.\nHosting Gradio Apps on Spaces\nHuggingface provides the infrastructure to permanently host your Gradio model on the internet, for free! You can either drag and drop a folder containing your Gradio model and all related files, or you can point HF Spaces to your Git repository and HP Spaces will pull the Gradio interface from there. See Huggingface Spaces for more information. \nAdvanced Features\nHere, we go through several advanced functionalities that your Gradio demo can include without you needing to write much more code!\nAuthentication\nYou may wish to put an authentication page in front of your interface to limit who can open your interface. With the auth= keyword argument in the launch() method, you can pass a list of acceptable username/password tuples; or, for more complex authentication handling, you can even pass a function that takes a username and password as arguments, and returns True to allow authentication, False otherwise. Here's an example that provides password-based authentication for a single user named \"admin\":\npython\ngr.Interface(fn=classify_image, inputs=image, outputs=label).launch(auth=(\"admin\", \"pass1234\"))\nInterpreting your Predictions\nMost models are black boxes such that the internal logic of the function is hidden from the end user. To encourage transparency, we've made it very easy to add interpretation to your model by  simply setting the interpretation keyword in the Interface class to default. This allows your users to understand what parts of the input are responsible for the output. Take a look at the simple interface below which shows an image classifier that also includes interpretation:\npython\nimport requests\nimport tensorflow as tf\nimport gradio as gr\ninception_net = tf.keras.applications.MobileNetV2()  # load the model\nDownload human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\ndef classify_image(inp):\n    inp = inp.reshape((-1, 224, 224, 3))\n    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n    prediction = inception_net.predict(inp).flatten()\n    return {labels[i]: float(prediction[i]) for i in range(1000)}\nimage = gr.inputs.Image(shape=(224, 224))\nlabel = gr.outputs.Label(num_top_classes=3)\ngr.Interface(\n    fn=classify_image, inputs=image, outputs=label, interpretation=\"default\"\n).launch()\nIn addition to default, Gradio also includes Shapley-based interpretation, which provides more accurate interpretations, albeit usually with a slower runtime. To use this, simply set the interpretation parameter to \"shap\" (note: also make sure the python package shap is installed). Optionally, you can modify the the num_shap parameter, which controls the tradeoff between accuracy and runtime (increasing this value generally increases accuracy). Here is an example:\npython\ngr.Interface(fn=classify_image, inputs=image, outputs=label, interpretation=\"shap\", num_shap=5).launch()\nThis will work for any function, even if internally, the model is a complex neural network or some other black box. If you use Gradio's default or shap interpretation, the output component must be a Label. All common input components are supported. Here is an example with text input.\npython\nimport re\nimport gradio as gr\nmale_words, female_words = [\"he\", \"his\", \"him\"], [\"she\", \"hers\", \"her\"]\ndef gender_of_sentence(sentence):\n    male_count = len([word for word in sentence.split() if word.lower() in male_words])\n    female_count = len(\n        [word for word in sentence.split() if word.lower() in female_words]\n    )\n    total = max(male_count + female_count, 1)\n    return {\"male\": male_count / total, \"female\": female_count / total}\niface = gr.Interface(\n    fn=gender_of_sentence,\n    inputs=gr.inputs.Textbox(default=\"She went to his house to get her keys.\"),\n    outputs=\"label\",\n    interpretation=\"default\",\n)\niface.launch()\nSo what is happening under the hood? With these interpretation methods, Gradio runs the prediction multiple times with modified versions of the input. Based on the results, you'll see that the interface automatically highlights the parts of the text (or image, etc.) that contributed increased the likelihood of the class as red. The intensity of color corresponds to the importance of that part of the input. The parts that decrease the class confidence are highlighted blue.\nYou can also write your own interpretation function. The demo below adds custom interpretation to the previous demo. This function will take the same inputs as the main wrapped function. The output of this interpretation function will be used to highlight the input of each input interface - therefore the number of outputs here corresponds to the number of input interfaces. To see the format for interpretation for each input interface, check the Docs.\npython\nimport re\nimport gradio as gr\nmale_words, female_words = [\"he\", \"his\", \"him\"], [\"she\", \"hers\", \"her\"]\ndef gender_of_sentence(sentence):\n    male_count = len([word for word in sentence.split() if word.lower() in male_words])\n    female_count = len(\n        [word for word in sentence.split() if word.lower() in female_words]\n    )\n    total = max(male_count + female_count, 1)\n    return {\"male\": male_count / total, \"female\": female_count / total}\ndef interpret_gender(sentence):\n    result = gender_of_sentence(sentence)\n    is_male = result[\"male\"] > result[\"female\"]\n    interpretation = []\n    for word in re.split(\"( )\", sentence):\n        score = 0\n        token = word.lower()\n        if (is_male and token in male_words) or (not is_male and token in female_words):\n            score = 1\n        elif (is_male and token in female_words) or (\n            not is_male and token in male_words\n        ):\n            score = -1\n        interpretation.append((word, score))\n    return interpretation\niface = gr.Interface(\n    fn=gender_of_sentence,\n    inputs=gr.inputs.Textbox(default=\"She went to his house to get her keys.\"),\n    outputs=\"label\",\n    interpretation=interpret_gender,\n    enable_queue=True,\n)\niface.launch()\nThemes and Custom Styling\nIf you'd like to change how your interface looks, you can select a different theme by simply passing in the theme parameter, like so:\npython\ngr.Interface(fn=classify_image, inputs=image, outputs=label, theme=\"huggingface\").launch()\nHere are the themes we currently support: \"default\", \"huggingface\", \"grass\", \"peach\", and the dark themes corresponding to each of these: \"darkdefault\", \"darkhuggingface\", \"darkgrass\", \"darkpeach\".\nIf you'd like to have more fine-grained control over any aspect of the app, you can also write your own css or pass in a css file, with the css parameter of the Interface class.\nCustom Flagging Options\nIn some cases, you might like to provide your users or testers with more than just a binary option to flag a sample. You can provide flagging_options that they select from a dropdown each time they click the flag button. This lets them provide additional feedback every time they flag a sample.\nHere's an example:\npython\ngr.Interface(fn=classify_image, inputs=image, outputs=label, flagging_options=[\"incorrect\", \"ambiguous\", \"offensive\", \"other\"]).launch()\nLoading Hugging Face Models and Spaces\nGradio integrates nicely with the Hugging Face Hub, allowing you to load models and Spaces with just one line of code. To use this, simply use the load() method in the Interface class. So:\nTo load any model from the Hugging Face Hub and create an interface around it, you pass \"model/\" or \"huggingface/\" followed by the model name, like these examples:\npython\ngr.Interface.load(\"huggingface/gpt2\").launch();\npython\ngr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\", \n    inputs=gr.inputs.Textbox(lines=5, label=\"Input Text\")  # customizes the input component\n).launch()\nTo load any Space from the Hugging Face Hub and recreate it locally (so that you can customize the inputs and outputs for example), you pass \"spaces/\" followed by the model name:\npython\ngr.Interface.load(\"spaces/eugenesiow/remove-bg\", inputs=\"webcam\", title=\"Remove your webcam background!\").launch()\nOne of the great things about loading Hugging Face models or spaces using Gradio is that you can then immediately use the resulting Interface object just like function in your Python code (this works for every type of model/space: text, images, audio, video, and even multimodal models):\npython\nio = gr.Interface.load(\"models/EleutherAI/gpt-neo-2.7B\")\nio(\"It was the best of times\")  # outputs model completion\nPutting Interfaces in Parallel and Series\nGradio also lets you mix interfaces very easily using the gradio.Parallel and gradio.Series classes. Parallel lets you put two similar models (if they have the same input type) in parallel to compare model predictions:\npython\ngenerator1 = gr.Interface.load(\"huggingface/gpt2\")\ngenerator2 = gr.Interface.load(\"huggingface/EleutherAI/gpt-neo-2.7B\")\ngenerator3 = gr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\")\ngr.Parallel(generator1, generator2, generator3).launch()\nSeries lets you put models and spaces in series, piping the output of one model into the input of the next model. \npython\ngenerator = gr.Interface.load(\"huggingface/gpt2\")\ntranslator = gr.Interface.load(\"huggingface/t5-small\")\ngr.Series(generator, translator).launch()  # this demo generates text, then translates it to German, and outputs the final result.\nAnd of course, you can also mix Parallel and Series together whenever that makes sense!\nQueuing to Manage Long Inference Times\nIf many people are using your interface or if the inference time of your function is long (> 1min), simply set the enable_queue parameter in the launch method to True to prevent timeouts.\npython\ngr.Interface(fn=classify_image, inputs=image, outputs=label).launch(enable_queue=True)\nThis sets up a queue of workers to handle the predictions and return the response to the front end. This is strongly recommended if you are planning on uploading your demo to Hugging Face Spaces (as described above) so that you can manage a large number of users simultaneously using your demo.\nSystem Requirements:\nGradio requires Python 3.7+ and has been tested on the latest versions of Windows, MacOS, and various common Linux distributions (e.g. Ubuntu). For Python package requirements, please see the setup.py file.\nContributing:\nIf you would like to contribute and your contribution is small, you can directly open a pull request (PR). If you would like to contribute a larger feature, we recommend first creating an issue with a proposed design for discussion. Please see our contributing guidelines for more info.\nLicense:\nGradio is licensed under the Apache License 2.0\nSee more:\nYou can find many more examples as well as more info on usage on our website: www.gradio.app\nSee, also, the accompanying paper: \"Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild\", ICML HILL 2019, and please use the citation below.\n@article{abid2019gradio,\ntitle={Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild},\nauthor={Abid, Abubakar and Abdalla, Ali and Abid, Ali and Khan, Dawood and Alfozan, Abdulrahman and Zou, James},\njournal={arXiv preprint arXiv:1906.02569},\nyear={2019}\n}",
	"big-data-analytics data-analysis data-exploration data-profiling data-quality data-science deep-learning eda exploration exploratory-data-analysis hacktoberfest html-report jupyter jupyter-notebook machine-learning pandas pandas-dataframe pandas-profiling python statistics": "pandas-profiling\nDocumentation\n  |\n  Slack\n  | \n  Stack Overflow\n  |\n  Latest changelog\nDo you like this project? Show us your love and give feedback!\npandas-profiling generates profile reports from a pandas DataFrame. The pandas df.describe() function is handy yet a little basic for exploratory data analysis. pandas-profiling extends pandas DataFrame with df.profile_report(), which automatically generates a standardized univariate and multivariate report for data understanding.\nFor each column, the following information (whenever relevant for the column type) is presented in an interactive HTML report:\nType inference: detect the types of columns in a DataFrame\nEssentials: type, unique values, indication of missing values\nQuantile statistics: minimum value, Q1, median, Q3, maximum, range, interquartile range\nDescriptive statistics: mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness\nMost frequent and extreme values\nHistograms: categorical and numerical\nCorrelations: high correlation warnings, based on different correlation metrics (Spearman, Pearson, Kendall, Cram\u00e9r\u2019s V, Phik)\nMissing values: through counts, matrix and heatmap\nDuplicate rows: list of the most common duplicated rows\nText analysis: most common categories (uppercase, lowercase, separator), scripts (Latin, Cyrillic) and blocks (ASCII, Cyrilic)\nFile and Image analysis: file sizes, creation dates, dimensions, indication of truncated images and existence of EXIF metadata\nThe report contains three additional sections:\nOverview: mostly global details about the dataset (number of records, number of variables, overall missigness and duplicates, memory footprint)\nAlerts: a comprehensive and automatic list of potential data quality issues (high correlation, skewness, uniformity, zeros, missing values, constant values, between others)\nReproduction: technical details about the analysis (time, version and configuration)\n\u26a1 Looking for a Spark backend to profile large datasets? It's work in progress.\n\u231b Interested in uncovering temporal patterns? Check out popmon.\n\u25b6\ufe0f Quickstart\nStart by loading your pandas DataFrame as you normally would, e.g. by using:\npython\nimport numpy as np\nimport pandas as pd\nfrom pandas_profiling import ProfileReport\ndf = pd.DataFrame(np.random.rand(100, 5), columns=[\"a\", \"b\", \"c\", \"d\", \"e\"])\nTo generate the standard profiling report, merely run:\npython\nprofile = ProfileReport(df, title=\"Pandas Profiling Report\")\nUsing inside Jupyter Notebooks\nThere are two interfaces to consume the report inside a Jupyter notebook: through widgets and through an embedded HTML report.\nThe above is achieved by simply displaying the report as a set of widgets. In a Jupyter Notebook, run:\npython\nprofile.to_widgets()\nThe HTML report can be directly embedded in a cell in a similar fashion:\npython\nprofile.to_notebook_iframe()\nExporting the report to a file\nTo generate a HTML report file, save the ProfileReport to an object and use the to_file() function:\npython\nprofile.to_file(\"your_report.html\")\nAlternatively, the report's data can be obtained as a JSON file:\npython\nAs a JSON string\njson_data = profile.to_json()\nAs a file\nprofile.to_file(\"your_report.json\")\nUsing in the command line\nFor standard formatted CSV files (which can be read directly by pandas without additional settings), the pandas_profiling executable can be used in the command line. The example below generates a report named Example Profiling Report, using a configuration file called default.yaml, in the file report.html by processing a data.csv dataset.\nsh\npandas_profiling --title \"Example Profiling Report\" --config_file default.yaml data.csv report.html\nAdditional details on the CLI are available on the documentation.\n\ud83d\udc40 Examples\nThe following example reports showcase the potentialities of the package across a wide range of dataset and data types:\nCensus Income (US Adult Census data relating income with other demographic properties)\nNASA Meteorites (comprehensive set of meteorite landing - object properties and locations)\nTitanic (the \"Wonderwall\" of datasets)\nNZA (open data from the Dutch Healthcare Authority)\nStata Auto (1978 Automobile data)\nColors (a simple colors dataset)\nVektis (Vektis Dutch Healthcare data)\nUCI Bank Dataset (marketing dataset from a bank)\nRussian Vocabulary (100 most common Russian words, showcasing unicode text analysis)\nWebsite Inaccessibility (website accessibility analysis, showcasing support for URL data)\nOrange prices and Coal prices (simple pricing evolution datasets, showcasing the theming options)\n\ud83d\udee0\ufe0f Installation\nAdditional details, including information about widget support, are available on the documentation.\nUsing pip\nYou can install using the pip package manager by running:\nsh\npip install -U pandas-profiling\nExtras\nThe package declares \"extras\", sets of additional dependencies.\n[notebook]: support for rendering the report in Jupyter notebook widgets.\n[unicode]: support for more detailed Unicode analysis, at the expense of additional disk space.\nInstall these with e.g.\nsh\npip install -U pandas-profiling[notebook,unicode]\nUsing conda\nYou can install using the conda package manager by running:\nsh\nconda install -c conda-forge pandas-profiling\nFrom source (development)\nDownload the source code by cloning the repository or click on Download ZIP to download the latest stable version.\nInstall it by navigating to the proper directory and running:\nsh\npip install -e .\nThe profiling report is written in HTML and CSS, which means a modern browser is required. \nYou need Python 3 to run the package. Other dependencies can be found in the requirements files:\n| Filename | Requirements|\n|----------|-------------|\n| requirements.txt | Package requirements|\n| requirements-dev.txt  |  Requirements for development|\n| requirements-test.txt | Requirements for testing|\n| setup.py | Requirements for widgets etc. |\n\ud83d\udcdd Use cases\nThe documentation includes guides, tips and tricks for tackling common use cases:\n| Use case                                                                                                                            | Description |\n|-------------------------------------------------------------------------------------------------------------------------------------|--|\n| Profiling large datasets                            | Tips on how to prepare data and configure pandas-profiling for working with large datasets |\n| Handling sensitive data                       | Generating reports which are mindful about sensitive data in the input dataset |\n| Comparing datasets                        | Comparing multiple version of the same dataset |\n| Dataset metadata and data dictionaries               | Complementing the report with dataset details and column-specific data dictionaries |\n| Customizing the report's appearance | Changing the appearance of the report's page and of the contained visualizations |\n\ud83d\udd17 Integrations\nTo maximize its usefulness in real world contexts, pandas-profiling has a set of implicit and explicit integrations with a variety of other actors in the Data Science ecosystem: \n| Integration type | Description |\n|---|---|\n| Other DataFrame libraries | How to compute the profiling of data stored in libraries other than pandas |\n| Great Expectations | Generating Great Expectations expectations suites directly from a profiling report |\n| Interactive applications | Embedding profiling reports in Streamlit, Dash or Panel applications |\n| Pipelines | Integration with DAG workflow execution tools like Airflow or Kedro |\n| Cloud services | Using pandas-profiling in hosted computation services like Lambda, Google Cloud or Kaggle |\n| IDEs | Using pandas-profiling directly from integrated development environments such as PyCharm |\n\ud83d\ude4b Support\nNeed help? Want to share a perspective? Report a bug? Ideas for collaborations? Reach out via the following channels:\nStack Overflow: ideal for asking questions on how to use the package\nGitHub Issues: bugs, proposals for changes, feature requests\nSlack: general chat, questions, collaborations\nEmail: project collaborations or sponsoring\n\u2757 Before reporting an issue on GitHub, check out Common Issues.\n\ud83e\udd1d\ud83c\udffd Contributing\nLearn how to get involved in the Contribution Guide.\nA low-threshold place to ask questions or start contributing is the Data Centric AI Community's Slack.",
	"data-analysis data-science data-wrangling datacleaning datacleansing datajournalism datamining java journalism opendata reconciliation wikidata": "OpenRefine\nOpenRefine is a Java-based power tool that allows you to load data, understand it,\nclean it up, reconcile it, and augment it with data coming from\nthe web. All from a web browser and the comfort and privacy of your own computer.\nDownload\nOpenRefine Releases\nSnapshot releases\nLatest development version, packaged for:\n* Linux\n* MacOS\n* Windows without embedded JRE\n* Windows with embedded JRE\nRun from source\nIf you have cloned this repository to your computer, you can run OpenRefine with:\n./refine on Mac OS and Linux\nrefine.bat on Windows\nThis requires JDK 11, Apache Maven and NPM.\nDocumentation and Videos\nUser Manual\nFAQ\nOfficial Website and tutorial videos\nContributing to the project\nDevelopers Guide & Architecture\nContributing Guide\nProject Governance\nContact us\nMailing List\nTwitter\nGitter\nMatrix (bridged from Gitter)\nLicensing and legal issues\nOpenRefine is open source software and is licensed under the BSD license\nlocated in the LICENSE.txt. See the folder licenses for information on open source\nlibraries that OpenRefine depends on.\nCredits\nThis software was created by Metaweb Technologies, Inc. and originally written\nand conceived by David Huynh dfhuynh@google.com. Metaweb Technologies, Inc.\nwas acquired by Google, Inc. in July 2010 and the product was renamed Google Refine.\nIn October 2012, it was renamed OpenRefine as it transitioned to a\ncommunity-supported product.\nSee CONTRIBUTING.md for instructions on how to contribute yourself.",
	"airbyte bigquery change-data-capture data data-analysis data-collection data-engineering data-ingestion data-integration elt etl java pipeline python redshift snowflake": "Introduction\nData integration is made simple, secure, and extensible.\nThe new open-source standard to sync data from applications, APIs & databases to warehouses, lakes & other destinations.\nAirbyte is on a mission to make data integration pipelines a commodity.\nMaintenance-free connectors you can use in minutes. Just authenticate your sources and warehouse, and get connectors that adapt to schema and API changes for you.\nBuilding new connectors made trivial. We make it very easy to add new connectors that you need, using the language of your choice, by offering scheduling and orchestration.\nDesigned to cover the long tail of connectors and needs. Benefit from the community's battle-tested connectors and adapt them to your specific needs.\nYour data stays in your cloud. Have full control over your data, and the costs of your data transfers.\nNo more security compliance process to go through as Airbyte is self-hosted.\nNo more pricing indexed on volume, as cloud-based solutions offer.\nHere's a list of our connectors with their health status.\nQuick start\nbash\ngit clone https://github.com/airbytehq/airbyte.git\ncd airbyte\ndocker-compose up\nNow visit http://localhost:8000. You will be asked for a username (default: airbyte) and password (default: password). You should update these values by changing BASIC_AUTH_USERNAME and BASIC_AUTH_PASSWORD in your local .env file.\nHere is a step-by-step guide showing you how to load data from an API into a file, all on your computer.\nFeatures\nBuilt for extensibility: Adapt an existing connector to your needs or build a new one with ease.\nOptional normalized schemas: Entirely customizable, start with raw data or from some suggestion of normalized data.\nFull-grade scheduler: Automate your replications with the frequency you need.\nReal-time monitoring: We log all errors in full detail to help you understand.\nIncremental updates: Automated replications are based on incremental updates to reduce your data transfer costs.\nManual full refresh: Sometimes, you need to re-sync all your data to start again.\nDebugging autonomy: Modify and debug pipelines as you see fit, without waiting.\nSee more on our website.\nContributing\nWe love contributions to Airbyte, big or small.\nSee our Contributing guide on how to get started. Not sure where to start? We\u2019ve listed some good first issues to start with. If you have any questions, please open a draft PR or visit our slack channel where the core team can help answer your questions.\nNote that you are able to create connectors using the language you want, as Airbyte connections run as Docker containers.\nAlso, we will never ask you to maintain your connector. The goal is that the Airbyte team and the community help maintain it, let's call it crowdsourced maintenance!\nCommunity support\nFor general help using Airbyte, please refer to the official Airbyte documentation. For additional help, you can use one of these channels to ask a question:\nSlack (For live discussion with the Community and Airbyte team)\nForum (For deeper conversations about features, connectors, or problems)\nGitHub (Bug reports, Contributions)\nTwitter (Get the news fast)\nWeekly office hours (Live informal 30-minute video call sessions with the Airbyte team)\nReporting Vulnerabilities\n\u26a0\ufe0f Please do not file GitHub issues or post on our public forum for security vulnerabilities as they are public! \u26a0\ufe0f\nAirbyte takes security issues very seriously. If you have any concerns about Airbyte or believe you have uncovered a vulnerability, please get in touch via the e-mail address security@airbyte.io. In the message, try to provide a description of the issue and ideally a way of reproducing it. The security team will get back to you as soon as possible.\nNote that this security address should be used only for undisclosed vulnerabilities. Dealing with fixed issues or general questions on how to use the security features should be handled regularly via the user and the dev lists. Please report any security problems to us before disclosing it publicly.\nRoadmap\nCheck out our roadmap to get informed on what we are currently working on, and what we have in mind for the next weeks, months, and years.\nLicense\nSee the LICENSE file for licensing information, and our FAQ for any questions you may have on that topic.",
	"algorithms data-analysis data-science docker ipynb kaggle-inclass machine-learning math matplotlib numpy pandas plotly python scikit-learn scipy seaborn vowpal-wabbit": "\nmlcourse.ai \u2013 Open Machine Learning Course\n\n\n\n\nmlcourse.ai is an open Machine Learning course by OpenDataScience (ods.ai), led by Yury Kashnitsky (yorko). Having both a Ph.D. degree in applied math and a Kaggle Competitions Master tier, Yury aimed at designing an ML course with a perfect balance between theory and practice. Thus, the course meets you with math formulae in lectures, and a lot of practice in a form of assignments and  Kaggle Inclass competitions. Currently, the course is in a self-paced mode. Here we guide you through the self-paced mlcourse.ai.\nBonus:\nAdditionally, you can purchase a Bonus Assignments pack with the best non-demo versions of mlcourse.ai assignments. Select the \"Bonus Assignments\" tier. Refer to the details of the deal on the main page mlcourse.ai.\nMirrors (:uk:-only): mlcourse.ai (main site), Kaggle Dataset (same notebooks as Kaggle Notebooks)\nSelf-paced passing\nYou are guided through 10 weeks of mlcourse.ai. For each week, from Pandas to Gradient Boosting, instructions are given on which articles to read, lectures to watch, what assignments to accomplish.\nArticles\nThis is the list of published articles on medium.com :uk:, habr.com :ru:. Also notebooks in Chinese are mentioned :cn: and links to Kaggle Notebooks (in English) are given. Icons are clickable.\nExploratory Data Analysis with Pandas :uk: :ru: :cn:, Kaggle Notebook\nVisual Data Analysis with Python :uk: :ru: :cn:, Kaggle Notebooks: part1, part2\nClassification, Decision Trees and k Nearest Neighbors :uk: :ru: :cn:, Kaggle Notebook\nLinear Classification and Regression :uk: :ru: :cn:, Kaggle Notebooks: part1, part2, part3, part4, part5\nBagging and Random Forest :uk: :ru: :cn:, Kaggle Notebooks: part1, part2, part3\nFeature Engineering and Feature Selection :uk: :ru: :cn:, Kaggle Notebook\nUnsupervised Learning: Principal Component Analysis and Clustering :uk: :ru: :cn:, Kaggle Notebook\nVowpal Wabbit: Learning with Gigabytes of Data :uk: :ru: :cn:, Kaggle Notebook\nTime Series Analysis with Python, part 1 :uk: :ru: :cn:. Predicting future with Facebook Prophet, part 2 :uk:, :cn: Kaggle Notebooks: part1, part2\nGradient Boosting :uk: :ru:, :cn:, Kaggle Notebook\nLectures\nVideolectures are uploaded to this YouTube playlist.\nIntroduction, video, slides\nExploratory data analysis with Pandas, video\nVisualization, main plots for EDA, video\nDecision trees: theory and practical part\nLogistic regression: theoretical foundations, practical part (baselines in the \"Alice\" competition)\nEnsembles and Random Forest \u2013 part 1. Classification metrics \u2013 part 2. Example of a business task, predicting a customer payment \u2013 part 3\nLinear regression and regularization - theory, LASSO & Ridge, LTV prediction - practice\nUnsupervised learning - Principal Component Analysis and Clustering\nStochastic Gradient Descent for classification and regression - part 1, part 2 TBA\nTime series analysis with Python (ARIMA, Prophet) - video\nGradient boosting: basic ideas - part 1, key ideas behind Xgboost, LightGBM, and CatBoost + practice - part 2\nAssignments\nThe following are demo-assignments. Additionally, within the \"Bonus Assignments\" tier you can get access to non-demo assignments.\nExploratory data analysis with Pandas, nbviewer, Kaggle Notebook, solution\nAnalyzing cardiovascular disease data, nbviewer, Kaggle Notebook, solution\nDecision trees with a toy task and the UCI Adult dataset, nbviewer, Kaggle Notebook, solution\nSarcasm detection, Kaggle Notebook, solution. Linear Regression as an optimization problem, nbviewer, Kaggle Notebook\nLogistic Regression and Random Forest in the credit scoring problem, nbviewer, Kaggle Notebook, solution\nExploring OLS, Lasso and Random Forest in a regression task, nbviewer, Kaggle Notebook, solution\nUnsupervised learning, nbviewer, Kaggle Notebook, solution\nImplementing online regressor, nbviewer, Kaggle Notebook, solution\nTime series analysis, nbviewer, Kaggle Notebook, solution\nBeating baseline in a competition, Kaggle Notebook\nBonus assignments\nAdditionally, you can purchase a Bonus Assignments pack with the best non-demo versions of mlcourse.ai assignments. Select the \"Bonus Assignments\" tier on Patreon or a similar tier on Boosty (rus).\nDetails of the deal\nmlcourse.ai is still in self-paced mode but we offer you Bonus Assignments with solutions for a contribution of $17/month. The idea is that you pay for ~1-5 months while studying the course materials, but a single contribution is still fine and opens your access to the bonus pack.\nNote: the first payment is charged at the moment of joining the Tier Patreon, and the next payment is charged on the 1st day of the next month, thus it's better to purchase the pack in the 1st half of the month.\nmlcourse.ai is never supposed to go fully monetized (it's created in the wonderful open ODS.ai community and will remain open and free) but it'd help to cover some operational costs, and Yury also put in quite some effort into assembling all the best assignments into one pack. Please note that unlike the rest of the course content, Bonus Assignments are copyrighted. Informally, Yury's fine if you share the pack with 2-3 friends but public sharing of the Bonus Assignments pack is prohibited.\nThe bonus pack contains 10 assignments, in some of them you are challenged to beat a baseline in a Kaggle competition under thorough guidance (\"Alice\" and \"Medium\") or implement an algorithm from scratch -- efficient stochastic gradient descent classifier and gradient boosting.\nKaggle competitions\nCatch Me If You Can: Intruder Detection through Webpage Session Tracking. Kaggle Inclass\nPredicting popularity of a Medium article. Kaggle Inclass\nDotA 2 winner prediction. Kaggle Inclass\nCiting mlcourse.ai\nIf you happen to cite mlcourse.ai in your work, you can use this BibTeX record:\n@misc{mlcourse_ai,\n    author = {Kashnitsky, Yury},\n    title = {mlcourse.ai \u2013 Open Machine Learning Course},\n    year = {2020},\n    publisher = {GitHub},\n    journal = {GitHub repository},\n    howpublished = {\\url{https://github.com/Yorko/mlcourse.ai}},\n}\nCommunity\nDiscussions are held in the #mlcourse_ai_eng channel of the OpenDataScience (ods.ai) Slack team (however, as of Sept. 2022, ODS Slack can't invite new users, and only 90-day history is retained, transition to Matrix is in progress).\nThe course is free but you can support organizers by making a pledge on Patreon (monthly support) or a one-time payment on Ko-fi.",
	"data-analysis exercise pandas practice tutorial": "Pandas Exercises\nFed up with a ton of tutorials but no easy way to find exercises I decided to create a repo just with exercises to practice pandas.\nDon't get me wrong, tutorials are great resources, but to learn is to do. So unless you practice you won't learn.\nThere will be three different types of files:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01. Exercise instructions\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a02. Solutions without code\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a03. Solutions with code and comments\nMy suggestion is that you learn a topic in a tutorial, video or documentation and then do the first exercises.\nLearn one more topic and do more exercises. If you are stuck, don't go directly to the solution with code files. Check the solutions only and try to get the correct answer.\nSuggestions and collaborations are more than welcome.\ud83d\ude42 Please open an issue or make a PR indicating the exercise and your problem/solution.\nLessons\n|                                                 |                                                |                   |\n|:-----------------------------------------------:|:----------------------------------------------:|:-----------------:|\n|Getting and knowing      | Merge                                |Time Series|\n|Filtering and Sorting  | Stats                                |Deleting       |\n|Grouping                            | Visualization                |Indexing           |\n|Apply                                  | Creating Series and DataFrames                   |Exporting|\nGetting and knowing\nChipotle\nOccupation\nWorld Food Facts\nFiltering and Sorting\nChipotle\nEuro12\nFictional Army\nGrouping\nAlcohol Consumption\nOccupation\nRegiment\nApply\nStudents Alcohol Consumption\nUS_Crime_Rates \nMerge\nAuto_MPG\nFictitious Names\nHouse Market \nStats\nUS_Baby_Names\nWind_Stats\nVisualization\nChipotle\nTitanic Disaster\nScores\nOnline Retail\nTips \nCreating Series and DataFrames\nPokemon \nTime Series\nApple_Stock\nGetting_Financial_Data\nInvestor_Flow_of_Funds_US \nDeleting\nIris\nWine \nVideo Solutions\nVideo tutorials of data scientists working through the above exercises:\nData Talks - Pandas Learning By Doing",
	"apache-doris business-intelligence data-analysis data-visualization echarts kettle superset tableau": "\u4eba\u4eba\u53ef\u7528\u7684\u5f00\u6e90\u6570\u636e\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177\n\u4ec0\u4e48\u662f DataEase\uff1f\nDataEase \u662f\u5f00\u6e90\u7684\u6570\u636e\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177\uff0c\u5e2e\u52a9\u7528\u6237\u5feb\u901f\u5206\u6790\u6570\u636e\u5e76\u6d1e\u5bdf\u4e1a\u52a1\u8d8b\u52bf\uff0c\u4ece\u800c\u5b9e\u73b0\u4e1a\u52a1\u7684\u6539\u8fdb\u4e0e\u4f18\u5316\u3002DataEase \u652f\u6301\u4e30\u5bcc\u7684\u6570\u636e\u6e90\u8fde\u63a5\uff0c\u80fd\u591f\u901a\u8fc7\u62d6\u62c9\u62fd\u65b9\u5f0f\u5feb\u901f\u5236\u4f5c\u56fe\u8868\uff0c\u5e76\u53ef\u4ee5\u65b9\u4fbf\u7684\u4e0e\u4ed6\u4eba\u5206\u4eab\u3002\nDataEase \u7684\u529f\u80fd\u5305\u62ec\uff1a\n\u56fe\u8868\u5c55\u793a\uff1a\u652f\u6301 PC \u7aef\u3001\u79fb\u52a8\u7aef\u3001\u5927\u5c4f;\n\u56fe\u8868\u5236\u4f5c\uff1a\u652f\u6301\u4e30\u5bcc\u7684\u56fe\u8868\u7c7b\u578b(Apache ECharts / AntV)\u3001\u652f\u6301\u62d6\u62c9\u62fd\u65b9\u5f0f\u5feb\u901f\u5236\u4f5c\u4eea\u8868\u677f;\n\u6570\u636e\u5f15\u64ce\uff1a\u652f\u6301\u76f4\u8fde\u6a21\u5f0f\u3001\u672c\u5730\u6a21\u5f0f(\u57fa\u4e8e Apache Doris / Kettle \u5b9e\u73b0);\n\u6570\u636e\u8fde\u63a5\uff1a\u652f\u6301\u6570\u636e\u4ed3\u5e93/\u6570\u636e\u6e56\u3001OLAP \u6570\u636e\u5e93\u3001OLTP \u6570\u636e\u5e93\u3001Excel \u6570\u636e\u6587\u4ef6\u3001API \u7b49\u5404\u79cd\u6570\u636e\u6e90\u3002\nDataEase \u7684\u4f18\u52bf\n\u5f00\u6e90\u5f00\u653e\uff1a\u96f6\u95e8\u69db\uff0c\u7ebf\u4e0a\u5feb\u901f\u83b7\u53d6\u548c\u5b89\u88c5\uff1b\u5feb\u901f\u83b7\u53d6\u7528\u6237\u53cd\u9988\u3001\u6309\u6708\u53d1\u5e03\u65b0\u7248\u672c\uff1b\n\u7b80\u5355\u6613\u7528\uff1a\u6781\u6613\u4e0a\u624b\uff0c\u901a\u8fc7\u9f20\u6807\u70b9\u51fb\u548c\u62d6\u62fd\u5373\u53ef\u5b8c\u6210\u5206\u6790\uff1b\n\u79d2\u7ea7\u54cd\u5e94\uff1a\u96c6\u6210 Apache Doris\uff0c\u8d85\u5927\u6570\u636e\u91cf\u4e0b\u79d2\u7ea7\u67e5\u8be2\u8fd4\u56de\u5ef6\u65f6\uff1b\n\u5b89\u5168\u5206\u4eab\uff1a\u652f\u6301\u591a\u79cd\u6570\u636e\u5206\u4eab\u65b9\u5f0f\uff0c\u786e\u4fdd\u6570\u636e\u5b89\u5168\u3002\nDataEase \u652f\u6301\u7684\u6570\u636e\u6e90\n\u66f4\u591a\u6570\u636e\u6e90\u652f\u6301\u6301\u7eed\u589e\u52a0\u4e2d...\nDataEase \u6a21\u677f\u5e02\u573a\n\u6a21\u677f\u5e02\u573a\n\u66f4\u591a\u4f18\u8d28\u6a21\u677f\u6301\u7eed\u589e\u52a0\u4e2d...\n\u5feb\u901f\u5f00\u59cb\n\u5728\u7ebf\u4f53\u9a8c\n\u73af\u5883\u5730\u5740\uff1ahttps://dataease.fit2cloud.com/\n\u7528\u6237\u540d\uff1ademo\n\u5bc6\u7801\uff1adataease\n\u4e00\u952e\u5b89\u88c5\n\u4ec5\u9700\u4e24\u6b65\u5feb\u901f\u5b89\u88c5 DataEase\uff1a\n\u51c6\u5907\u4e00\u53f0\u4e0d\u5c0f\u4e8e 8 G\u5185\u5b58\u7684 64\u4f4d Linux \u4e3b\u673a\uff1b\n\u4ee5 root \u7528\u6237\u6267\u884c\u5982\u4e0b\u547d\u4ee4\u4e00\u952e\u5b89\u88c5 DataEase\u3002\nsh\ncurl -sSL https://github.com/dataease/dataease/releases/latest/download/quick_start.sh | sh\n\u5b66\u4e60\u8d44\u6599\n\u5728\u7ebf\u6587\u6863\n\u6559\u5b66\u89c6\u9891\n\u5728\u7ebf\u5b66\u4e60\u73ed\n\u52a0\u5165\u5fae\u4fe1\u4ea4\u6d41\u7fa4\nDataEase \u7684\u6280\u672f\u6808\n\u524d\u7aef\uff1aVue.js\u3001Element\n\u56fe\u5e93\uff1aApache ECharts\u3001AntV\n\u540e\u7aef\uff1aSpring Boot\n\u4e2d\u95f4\u4ef6\uff1aMySQL\n\u6570\u636e\u5904\u7406\uff1aKettle\u3001Apache Doris\n\u57fa\u7840\u8bbe\u65bd\uff1aDocker\nStar History\nLicense\nCopyright (c) 2014-2022 \u98de\u81f4\u4e91 FIT2CLOUD, All rights reserved.\nLicensed under The GNU General Public License version 3 (GPLv3)  (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\nhttps://www.gnu.org/licenses/gpl-3.0.html\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
	"data-analysis go golang graph matrix scientific-computing statistics": "Gonum\nInstallation\nThe core packages of the Gonum suite are written in pure Go with some assembly.\nInstallation is done using go get.\ngo get -u gonum.org/v1/gonum/...\nSupported Go versions\nGonum supports and tests using the gc compiler on the two most recent Go releases on Linux (386, amd64 and arm64), macOS and Windows (both on amd64).\nNote that floating point behavior may differ between compiler versions and between architectures due to differences in floating point operation implementations.\nRelease schedule\nThe Gonum modules are released on a six-month release schedule, aligned with the Go releases.\ni.e.: when Go-1.x is released, Gonum-v0.n.0 is released around the same time.\nSix months after, Go-1.x+1 is released, and Gonum-v0.n+1.0 as well.\nThe release schedule, based on the current Go release schedule is thus:\nGonum-v0.n.0: February\nGonum-v0.n+1.0: August\nBuild tags\nThe Gonum packages use a variety of build tags to set non-standard build conditions.\nBuilding Gonum applications will work without knowing how to use these tags, but they can be used during testing and to control the use of assembly and CGO code.\nThe current list of non-internal tags is as follows:\nsafe \u2014 do not use assembly or unsafe\nbounds \u2014 use bounds checks even in internal calls\nnoasm \u2014 do not use assembly implementations\ntomita \u2014 use Tomita, Tanaka, Takahashi pivot choice for maximimal clique calculation, otherwise use random pivot (only in topo package)\nIssues \nIf you find any bugs, feel free to file an issue on the github issue tracker. Discussions on API changes, added features, code review, or similar requests are preferred on the gonum-dev Google Group.\nhttps://groups.google.com/forum/#!forum/gonum-dev\nLicense\nOriginal code is licensed under the Gonum License found in the LICENSE file. Portions of the code are subject to the additional licenses found in THIRD_PARTY_LICENSES. All third party code is licensed either under a BSD or MIT license.\nCode in graph/formats/dot is dual licensed Public Domain Dedication and Gonum License, and users are free to choose the license which suits their needs for this code.\nThe W3C test suites in graph/formats/rdf are distributed under both the W3C Test Suite License and the W3C 3-clause BSD License.",
	"data-mining decision-trees distributed gbdt gbm gbrt gradient-boosting kaggle lightgbm machine-learning microsoft parallel python r": "Light Gradient Boosting Machine\nLightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\nFaster training speed and higher efficiency.\nLower memory usage.\nBetter accuracy.\nSupport of parallel, distributed, and GPU learning.\nCapable of handling large-scale data.\nFor further details, please refer to Features.\nBenefiting from these advantages, LightGBM is being widely-used in many winning solutions of machine learning competitions.\nComparison experiments on public datasets show that LightGBM can outperform existing boosting frameworks on both efficiency and accuracy, with significantly lower memory consumption. What's more, distributed learning experiments show that LightGBM can achieve a linear speed-up by using multiple machines for training in specific settings.\nGet Started and Documentation\nOur primary documentation is at https://lightgbm.readthedocs.io/ and is generated from this repository. If you are new to LightGBM, follow the installation instructions on that site.\nNext you may want to read:\nExamples showing command line usage of common tasks.\nFeatures and algorithms supported by LightGBM.\nParameters is an exhaustive list of customization you can make.\nDistributed Learning and GPU Learning can speed up computation.\nLaurae++ interactive documentation is a detailed guide for hyperparameters.\nFLAML provides automated tuning for LightGBM (code examples).\nOptuna Hyperparameter Tuner provides automated tuning for LightGBM hyperparameters (code examples).\nUnderstanding LightGBM Parameters (and How to Tune Them using Neptune).\nDocumentation for contributors:\nHow we update readthedocs.io.\nCheck out the Development Guide.\nNews\nPlease refer to changelogs at GitHub releases page.\nSome old update logs are available at Key Events page.\nExternal (Unofficial) Repositories\nFLAML (AutoML library for hyperparameter optimization): https://github.com/microsoft/FLAML\nOptuna (hyperparameter optimization framework): https://github.com/optuna/optuna\nJulia-package: https://github.com/IQVIA-ML/LightGBM.jl\nJPMML (Java PMML converter): https://github.com/jpmml/jpmml-lightgbm\nNyoka (Python PMML converter): https://github.com/SoftwareAG/nyoka\nTreelite (model compiler for efficient deployment): https://github.com/dmlc/treelite\nlleaves (LLVM-based model compiler for efficient inference): https://github.com/siboehm/lleaves\nHummingbird (model compiler into tensor computations): https://github.com/microsoft/hummingbird\ncuML Forest Inference Library (GPU-accelerated inference): https://github.com/rapidsai/cuml\ndaal4py (Intel CPU-accelerated inference): https://github.com/intel/scikit-learn-intelex/tree/master/daal4py\nm2cgen (model appliers for various languages): https://github.com/BayesWitnesses/m2cgen\nleaves (Go model applier): https://github.com/dmitryikh/leaves\nONNXMLTools (ONNX converter): https://github.com/onnx/onnxmltools\nSHAP (model output explainer): https://github.com/slundberg/shap\nShapash (model visualization and interpretation): https://github.com/MAIF/shapash\ndtreeviz (decision tree visualization and model interpretation): https://github.com/parrt/dtreeviz\nSynapseML (LightGBM on Spark): https://github.com/microsoft/SynapseML\nKubeflow Fairing (LightGBM on Kubernetes): https://github.com/kubeflow/fairing\nKubeflow Operator (LightGBM on Kubernetes): https://github.com/kubeflow/xgboost-operator\nlightgbm_ray (LightGBM on Ray): https://github.com/ray-project/lightgbm_ray\nMars (LightGBM on Mars): https://github.com/mars-project/mars\nML.NET (.NET/C#-package): https://github.com/dotnet/machinelearning\nLightGBM.NET (.NET/C#-package): https://github.com/rca22/LightGBM.Net\nRuby gem: https://github.com/ankane/lightgbm-ruby\nLightGBM4j (Java high-level binding): https://github.com/metarank/lightgbm4j\nlightgbm-rs (Rust binding): https://github.com/vaaaaanquish/lightgbm-rs\nMLflow (experiment tracking, model monitoring framework): https://github.com/mlflow/mlflow\n{treesnip} (R {parsnip}-compliant interface): https://github.com/curso-r/treesnip\n{mlr3extralearners} (R {mlr3}-compliant interface): https://github.com/mlr-org/mlr3extralearners\nlightgbm-transform (feature transformation binding): https://github.com/microsoft/lightgbm-transform\nSupport\nAsk a question on Stack Overflow with the lightgbm tag, we monitor this for new questions.\nOpen bug reports and feature requests (not questions) on GitHub issues.\nHow to Contribute\nCheck CONTRIBUTING page.\nMicrosoft Open Source Code of Conduct\nThis project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.\nReference Papers\nGuolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu. \"LightGBM: A Highly Efficient Gradient Boosting Decision Tree\". Advances in Neural Information Processing Systems 30 (NIPS 2017), pp. 3149-3157.\nQi Meng, Guolin Ke, Taifeng Wang, Wei Chen, Qiwei Ye, Zhi-Ming Ma, Tie-Yan Liu. \"A Communication-Efficient Parallel Algorithm for Decision Tree\". Advances in Neural Information Processing Systems 29 (NIPS 2016), pp. 1279-1287.\nHuan Zhang, Si Si and Cho-Jui Hsieh. \"GPU Acceleration for Large-scale Tree Boosting\". SysML Conference, 2018.\nNote: If you use LightGBM in your GitHub projects, please add lightgbm in the requirements.txt.\nLicense\nThis project is licensed under the terms of the MIT license. See LICENSE for additional details.",
	"data-mining data-science document-similarity fasttext gensim information-retrieval machine-learning natural-language-processing neural-network nlp python topic-modeling word-embeddings word-similarity word2vec": "gensim \u2013 Topic Modelling in Python\nGensim is a Python library for topic modelling, document indexing\nand similarity retrieval with large corpora. Target audience is the\nnatural language processing (NLP) and information retrieval (IR)\ncommunity.\n\u26a0\ufe0f  Please sponsor Gensim to help sustain this open source project \u2764\ufe0f\nFeatures\nAll algorithms are memory-independent w.r.t. the corpus size\n    (can process input larger than RAM, streamed, out-of-core),\nIntuitive interfaces\neasy to plug in your own input corpus/datastream (trivial\n    streaming API)\neasy to extend with other Vector Space algorithms (trivial\n    transformation API)\nEfficient multicore implementations of popular algorithms, such as\n    online Latent Semantic Analysis (LSA/LSI/SVD), Latent\n    Dirichlet Allocation (LDA), Random Projections (RP),\n    Hierarchical Dirichlet Process (HDP) or word2vec deep\n    learning.\nDistributed computing: can run Latent Semantic Analysis and\n    Latent Dirichlet Allocation on a cluster of computers.\nExtensive documentation and Jupyter Notebook tutorials.\nIf this feature list left you scratching your head, you can first read\nmore about the Vector Space Model and unsupervised document analysis\non Wikipedia.\nInstallation\nThis software depends on NumPy and Scipy, two Python packages for\nscientific computing. You must have them installed prior to installing\ngensim.\nIt is also recommended you install a fast BLAS library before installing\nNumPy. This is optional, but using an optimized BLAS such as MKL, ATLAS or\nOpenBLAS is known to improve performance by as much as an order of\nmagnitude. On OSX, NumPy picks up its vecLib BLAS automatically,\nso you don\u2019t need to do anything special.\nInstall the latest version of gensim:\nbash\n    pip install --upgrade gensim\nOr, if you have instead downloaded and unzipped the source tar.gz\npackage:\nbash\n    python setup.py install\nFor alternative modes of installation, see the documentation.\nGensim is being continuously tested under all\nsupported Python versions.\nSupport for Python 2.7 was dropped in gensim 4.0.0 \u2013 install gensim 3.8.3 if you must use Python 2.7.\nHow come gensim is so fast and memory efficient? Isn\u2019t it pure Python, and isn\u2019t Python slow and greedy?\nMany scientific algorithms can be expressed in terms of large matrix\noperations (see the BLAS note above). Gensim taps into these low-level\nBLAS libraries, by means of its dependency on NumPy. So while\ngensim-the-top-level-code is pure Python, it actually executes highly\noptimized Fortran/C under the hood, including multithreading (if your\nBLAS is so configured).\nMemory-wise, gensim makes heavy use of Python\u2019s built-in generators and\niterators for streamed data processing. Memory efficiency was one of\ngensim\u2019s design goals, and is a central feature of gensim, rather than\nsomething bolted on as an afterthought.\nDocumentation\nQuickStart\nTutorials\nOfficial API Documentation\nSupport\nFor commercial support, please see Gensim sponsorship.\nAsk open-ended questions on the public Gensim Mailing List.\nRaise bugs on Github but please make sure you follow the issue template. Issues that are not bugs or fail to provide the requested details will be closed without inspection.\nAdopters\n| Company | Logo | Industry | Use of Gensim |\n|---------|------|----------|---------------|\n| RARE Technologies |  | ML & NLP consulting | Creators of Gensim \u2013\u00a0this is us! |\n| Amazon |   | Retail |  Document similarity. |\n| National Institutes of Health |  | Health | Processing grants and publications with word2vec. |\n| Cisco Security |  | Security |  Large-scale fraud detection. |\n| Mindseye |  | Legal | Similarities in legal documents. |\n| Channel 4 |  | Media | Recommendation engine. |\n| Talentpair |  | HR | Candidate matching in high-touch recruiting. |\n| Juju  |  | HR | Provide non-obvious related job suggestions. |\n| Tailwind |  | Media | Post interesting and relevant content to Pinterest. |\n| Issuu |  | Media | Gensim's LDA module lies at the very core of the analysis we perform on each uploaded publication to figure out what it's all about. |\n| Search Metrics |  | Content Marketing | Gensim word2vec used for entity disambiguation in Search Engine Optimisation. |\n| 12K Research | | Media |   Document similarity analysis on media articles. |\n| Stillwater Supercomputing |  | Hardware | Document comprehension and association with word2vec. |\n| SiteGround |   | Web hosting | An ensemble search engine which uses different embeddings models and similarities, including word2vec, WMD, and LDA. |\n| Capital One |  | Finance | Topic modeling for customer complaints exploration. |\nCiting gensim\nWhen citing gensim in academic papers and theses, please use this\nBibTeX entry:\n@inproceedings{rehurek_lrec,\n      title = {{Software Framework for Topic Modelling with Large Corpora}},\n      author = {Radim {\\v R}eh{\\r u}{\\v r}ek and Petr Sojka},\n      booktitle = {{Proceedings of the LREC 2010 Workshop on New\n           Challenges for NLP Frameworks}},\n      pages = {45--50},\n      year = 2010,\n      month = May,\n      day = 22,\n      publisher = {ELRA},\n      address = {Valletta, Malta},\n      note={\\url{http://is.muni.cz/publication/884893/en}},\n      language={English}\n}",
	"awesome awesome-list data-mining deep-learning explainability interpretability large-scale-machine-learning large-scale-ml machine-learning machine-learning-operations ml-operations ml-ops mlops privacy-preserving privacy-preserving-machine-learning privacy-preserving-ml production-machine-learning production-ml responsible-ai": "Awesome Production Machine Learning\nThis repository contains a curated list of awesome open source libraries that will help you deploy, monitor, version, scale and secure your production machine learning \ud83d\ude80\nQuick links to sections in this page\n| | | |\n|-|-|-|\n|\ud83d\udd0d Explaining Predictions & Models |\ud83d\udd0f Privacy Preserving ML | \ud83d\udcdc Model & Data Versioning|\n|\ud83c\udfc1 Model Training Orchestration|\ud83d\udcaa Model Serving & Monitoring|\ud83e\udd16 Neural Architecture Search|\n| \ud83d\udcd3 Data Science Notebook | \ud83d\udcca Industry-strength Visualisation | \ud83d\udd20 Industry-strength NLP |\n| \ud83e\uddf5 Data Pipeline | \ud83c\udff7\ufe0f Data Labelling |  \ud83d\udcc5 Metadata Management  |\n| \ud83d\udce1 Functions as a Service| \ud83d\uddfa\ufe0f Computation Distribution | \ud83d\udce5 Model Serialisation |\n| \ud83e\uddee Optimized Computation| \ud83d\udcb8 Data Stream Processing | :red_circle: Outlier & Anomaly Detection |\n| \ud83c\udf00 Feature Engineering | \ud83c\udf81 Feature Store | \u2694 Adversarial Robustness |\n|\ud83d\udcbe Data Storage Optimization | \ud83d\udcb0 Commercial Platform |\n10 Min Video Overview\n    This 10 minute video provides an overview of the motivations for machine learning operations as well as a high level overview on some of the tools in this repo. This newer video covers the an updated 2022 version of the state of MLOps\n\nWant to receive recurrent updates on this repo and other advancements?\n     You can join the Machine Learning Engineer newsletter. Join over 10,000 ML professionals and enthusiasts who receive weekly curated articles & tutorials on production Machine Learning.\n\n\n\n\n\n\n\n     Also check out the Awesome Artificial Intelligence Guidelines List, where we aim to map the landscape of \"Frameworks\", \"Codes of Ethics\", \"Guidelines\", \"Regulations\", etc related to Artificial Intelligence.\n\nMain Content\nExplaining Black Box Models and Datasets\nAequitas  - An open-source bias audit toolkit for data scientists, machine learning researchers, and policymakers to audit machine learning models for discrimination and bias, and to make informed and equitable decisions around developing and deploying predictive risk-assessment tools.\nAlibi  - Alibi is an open source Python library aimed at machine learning model inspection and interpretation. The initial focus on the library is on black-box, instance based model explanations.\nanchor  - Code for the paper \"High precision model agnostic explanations\", a model-agnostic system that explains the behaviour of complex models with high-precision rules called anchors.\ncaptum  - model interpretability and understanding library for PyTorch developed by Facebook. It contains general purpose implementations of integrated gradients, saliency maps, smoothgrad, vargrad and others for PyTorch models.\ncasme  - Example of using classifier-agnostic saliency map extraction on ImageNet presented on the paper \"Classifier-agnostic saliency map extraction\".\nContrastiveExplanation (Foil Trees)  - Python script for model agnostic contrastive/counterfactual explanations for machine learning. Accompanying code for the paper \"Contrastive Explanations with Local Foil Trees\".\nDeepLIFT  - Codebase that contains the methods in the paper \"Learning important features through propagating activation differences\". Here is the slides and the video of the 15 minute talk given at ICML.\nDeepVis Toolbox  - This is the code required to run the Deep Visualization Toolbox, as well as to generate the neuron-by-neuron visualizations using regularized optimization. The toolbox and methods are described casually here and more formally in this paper.\nELI5  - \"Explain Like I'm 5\" is a Python package which helps to debug machine learning classifiers and explain their predictions.\nFACETS  - Facets contains two robust visualizations to aid in understanding and analyzing machine learning datasets. Get a sense of the shape of each feature of your dataset using Facets Overview, or explore individual observations using Facets Dive.\nFairness Indicators  - The tool supports teams in evaluating, improving, and comparing models for fairness concerns in partnership with the broader Tensorflow toolkit.\nFairlearn  - Fairlearn is a python toolkit to assess and mitigate unfairness in machine learning models.\nFairML  - FairML is a python toolbox auditing the machine learning models for bias.\nfairness  - This repository is meant to facilitate the benchmarking of fairness aware machine learning algorithms based on this paper.\nGEBI - Global Explanations for Bias Identification  - An attention-based summarized post-hoc explanations for detection and identification of bias in data. We propose a global explanation and introduce a step-by-step framework on how to detect and test bias. Python package for image data.\nAI Explainability 360  - Interpretability and explainability of data and machine learning models including a comprehensive set of algorithms that cover different dimensions of explanations along with proxy explainability metrics.\nAI Fairness 360  - A comprehensive set of fairness metrics for datasets and machine learning models, explanations for these metrics, and algorithms to mitigate bias in datasets and models.\niNNvestigate  - An open-source library for analyzing Keras models visually by methods such as DeepTaylor-Decomposition, PatternNet, Saliency Maps, and Integrated Gradients.\nIntegrated-Gradients  - This repository provides code for implementing integrated gradients for networks with image inputs.\nInterpretML  - InterpretML is an open-source package for training interpretable models and explaining blackbox systems.\nkeras-vis  -  keras-vis is a high-level toolkit for visualizing and debugging your trained keras neural net models. Currently supported visualizations include: Activation maximization, Saliency maps, Class activation maps.\nL2X  - Code for replicating the experiments in the paper \"Learning to Explain: An Information-Theoretic Perspective on Model Interpretation\" at ICML 2018.\nLightly  - A python framework for self-supervised learning on images. The learned representations can be used to analyze the distribution in unlabeled data and rebalance datasets.\nLightwood  -  A Pytorch based framework that breaks down machine learning problems into smaller blocks that can be glued together seamlessly with an objective to build predictive models with one line of code.\nLIME  - Local Interpretable Model-agnostic Explanations for machine learning models.\nLOFO Importance  - LOFO (Leave One Feature Out) Importance calculates the importances of a set of features based on a metric of choice, for a model of choice, by iteratively removing each feature from the set, and evaluating the performance of the model, with a validation scheme of choice, based on the chosen metric.\nMindsDB  -   MindsDB is an Explainable AutoML framework for developers. With MindsDB you can build, train and use state of the art ML models in as simple as one line of code.\nmljar-supervised  - An Automated Machine Learning (AutoML) python package for tabular data. It can handle: Binary Classification, MultiClass Classification and Regression. It provides feature engineering, explanations and markdown reports.\nNETRON  - Viewer for neural network, deep learning and machine learning models.\npyBreakDown  - A model agnostic tool for decomposition of predictions from black boxes. Break Down Table shows contributions of every variable to a final prediction.\nresponsibly  - Toolkit for auditing and mitigating bias and fairness of machine learning systems\nSHAP  - SHapley Additive exPlanations is a unified approach to explain the output of any machine learning model.\nSHAPash  - Shapash is a Python library that provides several types of visualization that display explicit labels that everyone can understand.\nSkater  - Skater is a unified framework to enable Model Interpretation for all forms of model to help one build an Interpretable machine learning system often needed for real world use-cases.\nWhatIf  - An easy-to-use interface for expanding understanding of a black-box classification or regression ML model.\nTensorflow's cleverhans  - An adversarial example library for constructing attacks, building defenses, and benchmarking both. A python library to benchmark system's vulnerability to adversarial examples.\ntensorflow's lucid  - Lucid is a collection of infrastructure and tools for research in neural network interpretability.\ntensorflow's Model Analysis  - TensorFlow Model Analysis (TFMA) is a library for evaluating TensorFlow models. It allows users to evaluate their models on large amounts of data in a distributed manner, using the same metrics defined in their trainer.\nthemis-ml  - themis-ml is a Python library built on top of pandas and sklearn that implements fairness-aware machine learning algorithms.\nThemis  - Themis is a testing-based approach for measuring discrimination in a software system.\nTreeInterpreter  - Package for interpreting scikit-learn's decision tree and random forest predictions. Allows decomposing each prediction into bias and feature contribution components as described here.\nwoe  - Tools for WoE Transformation mostly used in ScoreCard Model for credit rating\nXAI - eXplainableAI  - An eXplainability toolbox for machine learning.\nPrivacy Preserving ML\nFlower  - Flower is a Federated Learning Framework with a unified approach. It enables the federation of any ML workload, with any ML framework, and any programming language.\nGoogle's Differential Privacy  - This is a C++ library of \u03b5-differentially private algorithms, which can be used to produce aggregate statistics over numeric data sets containing private or sensitive information.\nIntel Homomorphic Encryption Backend  - The Intel HE transformer for nGraph is a Homomorphic Encryption (HE) backend to the Intel nGraph Compiler, Intel's graph compiler for Artificial Neural Networks.\nMicrosoft SEAL  - Microsoft SEAL is an easy-to-use open-source (MIT licensed) homomorphic encryption library developed by the Cryptography Research group at Microsoft.\nOpenFL  - OpenFL is a Python framework for Federated Learning. OpenFL is designed to be a flexible, extensible and easily learnable tool for data scientists. OpenFL is developed by Intel Internet of Things Group (IOTG) and Intel Labs.\nPySyft  - A Python library for secure, private Deep Learning. PySyft decouples private data from model training, using Multi-Party Computation (MPC) within PyTorch.\nRosetta - A privacy-preserving framework based on TensorFlow with customized backend Operations using Multi-Party Computation (MPC). Rosetta reuses the APIs of TensorFlow and allows to transfer original TensorFlow codes into a privacy-preserving manner with minimal changes.\nSubstra - Substra is an open-source framework for privacy-preserving, traceable and collaborative Machine Learning.\nTensorflow Privacy  - A Python library that includes implementations of TensorFlow optimizers for training machine learning models with differential privacy.\nTF Encrypted  - A Framework for Confidential Machine Learning on Encrypted Data in TensorFlow.\nModel and Data Versioning\nAim  - A super-easy way to record, search and compare AI experiments.\nCatalyst  - High-level utils for PyTorch DL & RL research. It was developed with a focus on reproducibility, fast experimentation and code/ideas reusing.\nClearML  - Auto-Magical Experiment Manager & Version Control for AI (previously Trains).\nD6tflow  - A python library that allows for building complex data science workflows on Python.\nData Version Control (DVC)  - A git fork that allows for version management of models.\nDeepkit  - An open-source platform and cross-platform desktop application to execute, track, and debug modern machine learning experiments.\nDolt  - Dolt is a SQL database that you can fork, clone, branch, merge, push and pull just like a git repository.\nFlor  - Easy to use logger and automatic version controller made for data scientists who write ML code.\nGuild AI  - Open source toolkit that automates and optimizes machine learning experiments.\nDeeplake  - Store, access & manage datasets with version-control for PyTorch/TensorFlow locally or on any cloud with scalable data pipelines.\nHangar  - Version control for tensor data, git-like semantics on numerical data with high speed and efficiency.\nKeepsake  - Version control for machine learning.\nlakeFS  - Repeatable, atomic and versioned data lake on top of object storage.\nMLflow  - Open source platform to manage the ML lifecycle, including experimentation, reproducibility and deployment.\nModelDB  - An open-source system to version machine learning models including their ingredients code, data, config, and environment and to track ML metadata across the model lifecycle.\nModelStore  - An open-source Python library that allows you to version, export, and save a machine learning model to your cloud storage provider.\normb  - Docker for Your ML/DL Models Based on OCI Artifacts.\nPachyderm  - Open source distributed processing framework build on Kubernetes focused mainly on dynamic building of production machine learning pipelines - (Video).\nPolyaxon  - A platform for reproducible and scalable machine learning and deep learning on kubernetes - (Video).\nQuilt  - Versioning, reproducibility and deployment of data and models.\nSacred  - Tool to help you configure, organize, log and reproduce machine learning experiments.\nStudio  - Model management framework which minimizes the overhead involved with scheduling, running, monitoring and managing artifacts of your machine learning experiments.\nTerminusDB  - A graph database management system that stores data like git.\nModel Training Orchestration\nAccelerate  - Accelerate abstracts exactly and only the boilerplate code related to multi-GPU/TPU/mixed-precision and leaves the rest of your code unchanged.\nCML  - Continuous Machine Learning (CML) is an open-source library for implementing continuous integration & delivery (CI/CD) in machine learning projects.\nDetermined  - Deep learning training platform with integrated support for distributed training, hyperparameter tuning, and model management (supports Tensorflow and Pytorch).\nenvd  - Machine learning development environment for data science and AI/ML engineering teams.\nFlyte  - Lyft\u2019s Cloud Native Machine Learning and Data Processing Platform - (Demo).\nHopsworks  - Hopsworks is a data-intensive platform for the design and operation of machine learning pipelines that includes a Feature Store - (Video).\nKubeflow  - A cloud native platform for machine learning based on Google\u2019s internal machine learning pipelines.\nMLeap  - Standardisation of pipeline and model serialization for Spark, Tensorflow and sklearn.\nNVIDIA TensorRT  - TensorRT is a C++ library for high performance inference on NVIDIA GPUs and deep learning accelerators.\nOnepanel  - Production scale vision AI platform, with fully integrated components for model building, automated labeling, data processing and model training pipelines.\nOpen Platform for AI  - Platform that provides complete AI model training and resource management capabilities.\nPyCaret ) - low-code library for training and deploying models (scikit-learn, XGBoost, LightGBM, spaCy)\nSkaffold  - Skaffold is a command line tool that facilitates continuous development for Kubernetes applications. You can iterate on your application source code locally then deploy to local or remote Kubernetes clusters.\nTensorflow Extended (TFX)  - Production oriented configuration framework for ML based on TensorFlow, incl. monitoring and model version management.\nTonY  - TonY is a framework to natively run deep learning jobs on Apache Hadoop. It currently supports TensorFlow, PyTorch, MXNet and Horovod.\nZenML  - ZenML is an extensible, open-source MLOps framework to create reproducible ML pipelines with a focus on automated metadata tracking, caching, and many integrations to other tools.\nModel Serving and Monitoring\nBackprop  - Backprop makes it simple to use, finetune, and deploy state-of-the-art ML models.\nBentoML  - BentoML is an open source framework for high performance ML model serving.\nCortex  - Cortex is an open source platform for deploying machine learning models\u2014trained with any framework\u2014as production web services. No DevOps required.\nDeepchecks  - Deepchecks is an open source package for comprehensively validating your machine learning models and data with minimal effort during development, deployment or in production.\nDeepDetect  - Machine Learning production server for TensorFlow, XGBoost and Cafe models written in C++ and maintained by Jolibrain.\nEvidently  - Evidently helps analyze machine learning models during development, validation, or production monitoring. The tool generates interactive reports from pandas DataFrame.\nForestFlow - Cloud-native machine learning model server.\nJina  - Cloud native search framework that   supports to use deep learning/state of the art AI models for search.\nKFServing  - Serverless framework to deploy and monitor machine learning models in Kubernetes - (Video).\nm2cgen  - A lightweight library which allows to transpile trained classic machine learning models into a native code of C, Java, Go, R, PHP, Dart, Haskell, Rust and many other programming languages.\nMLEM  - Version and deploy your ML models following GitOps principles.\nMLServer  - An inference server for your machine learning models, including support for multiple frameworks, multi-model serving and more.\nmltrace  - a lightweight, open-source Python tool to get \"bolt-on\" observability in ML pipelines.\nMLWatcher  - MLWatcher is a python agent that records a large variety of time-serie metrics of your running ML classification algorithm. It enables you to monitor in real time.\nModel Server for Apache MXNet (MMS)  - A model server for Apache MXNet from Amazon Web Services that is able to run MXNet models as well as Gluon models (Amazon's SageMaker runs a custom version of MMS under the hood).\nNannyML  - An open source library to estimate post-deployment model performance (without access to targets). Capable of fully capturing the impact of data drift on performance.\nMosec  - A rust-powered and multi-stage pipelined model server which offers dynamic batching and more. Super easy to implement and deploy as micro-services.\nOpenScoring  - REST web service for the true real-time scoring (< 1 ms) of Scikit-Learn, R and Apache Spark models.\nPandas Profiling - Creates HTML profiling reports from pandas DataFrame objects. It extends the pandas DataFrame with df.profile_report() for quick data analysis.\nPredictionIO  - An open source Machine Learning Server built on top of a state-of-the-art open source stack for developers and data scientists to create predictive engines for any machine learning task.\nRedis-AI  - A Redis module for serving tensors and executing deep learning models. Expect changes in the API and internals.\nSeldon Core  - Open source platform for deploying and monitoring machine learning models in kubernetes - (Video).\nskops  - skops is a Python library helping you share your scikit-learn based models and put them in production.\nTempo  - Open source SDK that provides a unified interface to multiple MLOps projects that enable data scientists to deploy and productionise machine learning systems.\nTensorflow Serving  - High-performant framework to serve Tensorflow models via grpc protocol able to handle 100k requests per second per core.\nTorchServe  - TorchServe is a flexible and easy to use tool for serving PyTorch models.\nTransformer-deploy  - Transformer-deploy is an efficient, scalable and enterprise-grade CPU/GPU inference server for Hugging Face transformer models.\nTriton Inference Server  - Triton is a high performance open source serving software to deploy AI models from any framework on GPU & CPU while maximizing utilization.\nWhyLogs  - Lightweight solution for profiling and monitoring your ML data pipeline end-to-end\nAdversarial Robustness\nAdvBox  - A toolbox to generate adversarial examples that fool neural networks in PaddlePaddle, PyTorch, Caffe2, MxNet, Keras, TensorFlow, and Advbox can benchmark the robustness of machine learning models.\nAdversarial DNN Playground  - think TensorFlow Playground, but for Adversarial Examples! A visualization tool designed for learning and teaching - the attack library is limited in size, but it has a nice front-end to it with buttons you can press!\nAdverTorch  - library for adversarial attacks / defenses specifically for PyTorch.\nAlibi Detect  - alibi-detect is a Python package focused on outlier, adversarial and concept drift detection. The package aims to cover both online and offline detectors for tabular data, text, images and time series. The outlier detection methods should allow the user to identify global, contextual and collective outliers.\nArtificial Adversary  AirBnB's library to generate text that reads the same to a human but passes adversarial classifiers.\nCleverHans  - library for testing adversarial attacks / defenses maintained by some of the most important names in adversarial ML, namely Ian Goodfellow (ex-Google Brain, now Apple) and Nicolas Papernot (Google Brain). Comes with some nice tutorials!\nCounterfit  - Counterfit is a command-line tool and generic automation layer for assessing the security of machine learning systems.\nDEEPSEC  - another systematic tool for attacking and defending deep learning models.\nEvadeML  - benchmarking and visualization tool for adversarial ML maintained by Weilin Xu, a PhD at University of Virginia, working with David Evans. Has a tutorial on re-implementation of one of the most important adversarial defense papers - feature squeezing (same team).\nFoolbox  - second biggest adversarial library. Has an even longer list of attacks - but no defenses or evaluation metrics. Geared more towards computer vision. Code easier to understand / modify than ART - also better for exploring blackbox attacks on surrogate models.\nAdversarial Robustness Toolbox (ART))  - ART provides tools that enable developers and researchers to defend and evaluate Machine Learning models and applications against the adversarial threats of Evasion, Poisoning, Extraction, and Inference.\nMIA  - A library for running membership inference attacks (MIA) against machine learning models.\nNicolas Carlini\u2019s Adversarial ML reading list - not a library, but a curated list of the most important adversarial papers by one of the leading minds in Adversarial ML, Nicholas Carlini. If you want to discover the 10 papers that matter the most - I would start here.\nRobust ML - another robustness resource maintained by some of the leading names in adversarial ML. They specifically focus on defenses, and ones that have published code available next to papers. Practical and useful.\nTextFool  - plausible looking adversarial examples for text generation.\nTrickster  - Library and experiments for attacking machine learning in discrete domains using graph search.\nNeural Architecture Search\nAutokeras  - AutoML library for Keras based on \"Auto-Keras: Efficient Neural Architecture Search with Network Morphism\".\nENAS via Parameter Sharing - Efficient Neural Architecture Search via Parameter Sharing by authors of paper.\nENAS-PyTorch  - Efficient Neural Architecture Search (ENAS) in PyTorch based on this paper.\nENAS-Tensorflow  - Efficient Neural Architecture search via parameter sharing(ENAS) micro search Tensorflow code for windows user.\nKatib  - A Kubernetes-based system for Hyperparameter Tuning and Neural Architecture Search.\nMaggy  - Asynchronous, directed Hyperparameter search and parallel ablation studies on Apache Spark - (Video).\nNeural Architecture Search with Controller RNN  - Basic implementation of Controller RNN from Neural Architecture Search with Reinforcement Learning and Learning Transferable Architectures for Scalable Image Recognition.\nNeural Network Intelligence  - NNI (Neural Network Intelligence) is a toolkit to help users run automated machine learning (AutoML) experiments.\nData Science Notebook\nApache Zeppelin  - Web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Scala and more.\nBinder  - Binder hosts notebooks in an executable environment (for free).\nH2O Flow - Jupyter notebook-like interface for H2O to create, save and re-use \"flows\".\nJupyter Notebooks  - Web interface python sandbox environments for reproducible development\nML Workspace  - All-in-one web IDE for machine learning and data science. Combines Jupyter, VS Code, Tensorflow, and many other tools/libraries into one Docker image.\n.NET Interactive  - .NET Interactive takes the power of .NET and embeds it into your interactive experiences.\nPapermill  - Papermill is a library for parameterizing notebooks and executing them like Python scripts.\nPloomber  - Ploomber allows you to develop workflows in Jupyter and execute them in a distributed environment without code changes. It supports Kubernetes, AWS Batch, and Airflow.\nPolynote  - Polynote is an experimental polyglot notebook environment. Currently, it supports Scala and Python (with or without Spark), SQL, and Vega.\nRMarkdown  - The rmarkdown package is a next generation implementation of R Markdown based on Pandoc.\nStencila  - Stencila is a platform for creating, collaborating on, and sharing data driven content. Content that is transparent and reproducible.\nVoil\u00e0  - Voil\u00e0 turns Jupyter notebooks into standalone web applications that can e.g. be used as dashboards.\nIndustrial Strength Visualisation\nAltair - Altair is a declarative statistical visualization library for Python.\nApache ECharts - Apache ECharts is a powerful, interactive charting and data visualization library for browser.\nBokeh  - Bokeh is an interactive visualization library for Python that enables beautiful and meaningful visual presentation of data in modern web browsers.\nGeoplotlib  - geoplotlib is a python toolbox for visualizing geographical data and making maps.\nggplot2  - An implementation of the grammar of graphics for R.\ngradio  - Quickly create and share demos of models - by only writing Python. Debug models interactively in your browser, get feedback from collaborators, and generate public links without deploying anything.\nmatplotlib  - A Python 2D plotting library which produces publication-quality figures in a variety of hardcopy formats and interactive environments across platforms.\nMissingno  - missingno provides a small toolset of flexible and easy-to-use missing data visualizations and utilities that allows you to get a quick visual summary of the completeness (or lack thereof) of your dataset.\nPDPBox  - This repository is inspired by ICEbox. The goal is to visualize the impact of certain features towards model prediction for any supervised learning algorithm.\nPerspective  Streaming pivot visualization via WebAssembly.\nPixiedust  - PixieDust is a productivity tool for Python or Scala notebooks, which lets a developer encapsulate business logic into something easy for your customers to consume.\nPlotly Dash  - Dash is a Python framework for building analytical web applications without the need to write javascript.\nPlotly.py  - An interactive, open source, and browser-based graphing library for Python.\nPlotly.NET  - Plotly.NET provides functions for generating and rendering plotly.js charts in .NET programming languages.\nPyCEbox  - Python Individual Conditional Expectation Plot Toolbox.\npygal  - pygal is a dynamic SVG charting library written in Python.\nRedash  - Redash is anopen source visualisation framework that is built to allow easy access to big datasets leveraging multiple backends.\nseaborn  - Seaborn is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.\nStreamlit  - Streamlit lets you create apps for your machine learning projects with deceptively simple Python scripts. It supports hot-reloading, so your app updates live as you edit and save your file.\nSuperset  - A modern, enterprise-ready business intelligence web application.\nTensorBoard  - A visualization toolkit for machine learning experimentation that makes it easy to host, track, and share ML experiments.\nyellowbrick  - yellowbrick is a matplotlib-based model evaluation plots for scikit-learn and other machine learning libraries.\nIndustrial Strength NLP\nAdaptNLP  - Built atop Zalando Research's Flair and Hugging Face's Transformers library, AdaptNLP provides Machine Learning Researchers and Scientists a modular and adaptive approach to a variety of NLP tasks with an Easy API for training, inference, and deploying NLP-based microservices.\nBlackstone  - Blackstone is a spaCy model and library for processing long-form, unstructured legal text. Blackstone is an experimental research project from the Incorporated Council of Law Reporting for England and Wales' research lab, ICLR&D.\nCTRL  - A Conditional Transformer Language Model for Controllable Generation released by SalesForce.\nFacebook's XLM  - PyTorch original implementation of Cross-lingual Language Model Pretraining which includes BERT, XLM, NMT, XNLI, PKM, etc..\nFlair  - Simple framework for state-of-the-art NLP developed by Zalando which builds directly on PyTorch.\nGithub's Semantic  - Github's text library for parsing, analyzing, and comparing source code across many languages .\nGluonNLP  - GluonNLP is a toolkit that enables easy text preprocessing, datasets loading and neural models building to help you speed up your Natural Language Processing (NLP) research.\nGrover  - Grover is a model for Neural Fake News -- both generation and detection. However, it probably can also be used for other generation tasks.\nKashgari  - Kashgari is a simple and powerful NLP Transfer learning framework, build a state-of-art model in 5 minutes for named entity recognition (NER), part-of-speech tagging (PoS), and text classification tasks.\nOpenAI GPT-2  - OpenAI's code from their paper \"Language Models are Unsupervised Multitask Learners\".\nsense2vec  - A Pytorch library that allows for training and using sense2vec models, which are models that leverage the same approach than word2vec, but also leverage part-of-speech attributes for each token, which allows it to be \"meaning-aware\".\nSnorkel  - Snorkel is a system for quickly generating training data with weak supervision.\nSpaCy  - Industrial-strength natural language processing library built with python and cython by the explosion.ai team.\nStable Baselines  - A fork of OpenAI Baselines, implementations of reinforcement learning algorithms.\nTensorflow Lingvo  - A framework for building neural networks in Tensorflow, particularly sequence models.\nTensorflow Text  - TensorFlow Text provides a collection of text related classes and ops ready to use with TensorFlow 2.0.\nYouTokenToMe  - YouTokenToMe is an unsupervised text tokenizer focused on computational efficiency. It currently implements fast Byte Pair Encoding (BPE).\nTransformers  - Huggingface's library of state-of-the-art pretrained models for Natural Language Processing (NLP).\nData Pipeline\nApache Airflow  - Data Pipeline framework built in Python, including scheduler, DAG definition and a UI for visualisation.\nApache Nifi  - Apache NiFi was made for dataflow. It supports highly configurable directed graphs of data routing, transformation, and system mediation logic.\nArgo Workflows  - Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. Argo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition).\nAzkaban  - Azkaban is a batch workflow job scheduler created at LinkedIn to run Hadoop jobs. Azkaban resolves the ordering through job dependencies and provides an easy to use web user interface to maintain and track your workflows.\nBasin  - Visual programming editor for building Spark and PySpark pipelines.\nBonobo  - ETL framework for Python 3.5+ with focus on simple atomic operations working concurrently on rows of data.\nChronos  - More of a job scheduler for Mesos than ETL pipeline.\nCouler  - Unified interface for constructing and managing machine learning workflows on different workflow engines, such as Argo Workflows, Tekton Pipelines, and Apache Airflow.\nDagster  - A data orchestrator for machine learning, analytics, and ETL.\nDBND  - DBND is an agile pipeline framework that helps data engineering teams track and orchestrate their data processes.\nDBT  - ETL tool for running transformations inside data warehouses.\nFlyte  - Lyft\u2019s Cloud Native Machine Learning and Data Processing Platform - (Demo).\nGenie  - Job orchestration engine to interface and trigger the execution of jobs from Hadoop-based systems.\nGokart  - Wrapper of the data pipeline Luigi.\nKedro  - Kedro is a workflow development tool that helps you build data pipelines that are robust, scalable, deployable, reproducible and versioned. Visualization of the kedro workflows can be done by kedro-viz.\nLuigi  - Luigi is a Python module that helps you build complex pipelines of batch jobs, handling dependency resolution, workflow management, visualisation, etc..\nMetaflow  - A framework for data scientists to easily build and manage real-life data science projects.\nNeuraxle  - A framework for building neat pipelines, providing the right abstractions to chain your data transformation and prediction steps with data streaming, as well as doing hyperparameter searches (AutoML).\nOozie  - Workflow scheduler for Hadoop jobs.\nPipelineX  - Based on Kedro and MLflow. Full comparison is found here.\nPrefect Core  - Workflow management system that makes it easy to take your data pipelines and add semantics like retries, logging, dynamic mapping, caching, failure notifications, and more.\nSETL  - A simple Spark-powered ETL framework that helps you structure your ETL projects, modularize your data transformation logic and speed up your development.\nSnakemake  - Workflow management system for reproducible and scalable data analyses.\nTowhee  - General-purpose machine learning pipeline for generating embedding vectors using one or many ML models.\nData Labelling\nbrat rapid annotation tool  - Web-based text annotation tool for Named-Entity-Recogntion task.\nCOCO Annotator  - Web-based image segmentation tool for object detection, localization and keypoints\nComputer Vision Annotation Tool (CVAT)  - OpenCV's web-based annotation tool for both VIDEOS and images for computer algorithms.\nDoccano  - Open source text annotation tools for humans, providing functionality for sentiment analysis, named entity recognition, and machine translation.\nImageTagger  - Image labelling tool with support for collaboration, supporting bounding box, polygon, line, point labelling, label export, etc.\nImgLab  - Image annotation tool for bounding boxes with auto-suggestion and extensibility for plugins.\nLabel Studio  - Multi-domain data labeling and annotation tool with standardized output format.\nLabelimg  - Open source graphical image annotation tool writen in Python using QT for graphical interface focusing primarily on bounding boxes.\nmakesense.ai  - Free to use online tool for labelling photos. Prepared labels can be downloaded in one of multiple supported formats.\nMedTagger  - A collaborative framework for annotating medical datasets using crowdsourcing.\nOpenLabeling  - Open source tool for labelling images with support for labels, edges, as well as image resizing and zooming in.\nPixelAnnotationTool  - Image annotation tool with ability to \"colour\" on the images to select labels for segmentation. Process is semi-automated with the watershed marked algorithm of OpenCV\nRubrix  - Open-source tool for tracking, exploring, and labeling data for AI projects.\nSemantic Segmentation Editor  - Hitachi's Open source tool for labelling camera and LIDAR data.\nSuperintendent  - superintendent provides an ipywidget-based interactive labelling tool for your data.\nVGG Image Annotator (VIA) - A simple and standalone manual annotation software for image, audio and video. VIA runs in a web browser and does not require any installation or setup.\nMetadata Management\nAmundsen  - Amundsen is a metadata driven application for improving the productivity of data analysts, data scientists and engineers when interacting with data.\nArangoML Pipeline  - ArangoML Pipeline is a common and extensible Metadata Layer for Machine Learning Pipelines which allows Data Scientists and DataOps to manage all information related to their ML pipeline in one place.\nApache Atlas  - Apache Atlas framework is an extensible set of core foundational governance services \u2013 enabling enterprises to effectively and efficiently meet their compliance requirements within Hadoop and allows integration with the whole enterprise data ecosystem.\nDataHub  - DataHub is LinkedIn's generalized metadata search & discovery tool.\nMarquez  - Marquez is an open source metadata service for the collection, aggregation, and visualization of a data ecosystem's metadata.\nMetacat  - Metacat is a unified metadata exploration API service. Metacat focusses on solving these problems: 1) federated views of metadata systems; 2) arbitrary metadata storage about data sets; 3) metadata discovery.\nML Metadata  - a library for recording and retrieving metadata associated with ML developer and data scientist workflows.\nModel Card Toolkit  - streamlines and automates generation of Model Cards.\nData Storage Optimisation\nAlluxio  - A virtual distributed storage system that bridges the gab between computation frameworks and storage systems.\nApache Arrow  - In-memory columnar representation of data compatible with Pandas, Hadoop-based systems, etc..\nApache Druid  - A high performance real-time analytics database. Check this article for introduction.\nApache Ignite  - A memory-centric distributed database, caching, and processing platform for transactional, analytical, and streaming workloads delivering in-memory speeds at petabyte scale - Demo.\nApache Parquet  - On-disk columnar representation of data compatible with Pandas, Hadoop-based systems, etc..\nApache Pinot  - A realtime distributed OLAP datastore. Comparison of the open source OLAP systems for big data: ClickHouse, Druid, and Pinot is found here.\nBayesDB  - A Bayesian database table for querying the probable implications of data as easily as SQL databases query the data itself. - (Video)\nClickHouse  - ClickHouse is an open source column oriented database management system.\nDelta Lake  - Delta Lake is a storage layer that brings scalable, ACID transactions to Apache Spark and other big-data engines.\nEdgeDB  - NoSQL interface for Postgres that allows for object interaction to data stored.\nHopsFS  - HDFS-compatible file system with scale-out strongly consistent metadata.\nInfluxDB  Scalable datastore for metrics, events, and real-time analytics.\nMilvus  Milvus is a cloud-native, open-source vector database built to manage embedding vectors generated by machine learning models and neural networks.\nQdrant  - An open source vector similarity search engine with extended filtering support.\nTimescaleDB  An open-source time-series SQL database optimized for fast ingest and complex queries packaged as a PostgreSQL extension - (Video).\nWeaviate  - A low-latency vector search engine (GraphQL, RESTful) with out-of-the-box support for different media types. Modules include Semantic Search, Q&A, Classification, Customizable Models (PyTorch/TensorFlow/Keras), and more.\nZarr  - Python implementation of chunked, compressed, N-dimensional arrays designed for use in parallel computing.\nFunction as a Service\nApache OpenWhisk  - Open source, distributed serverless platform that executes functions in response to events at any scale.\nFission  - (Early Alpha) Serverless functions as a service framework on Kubernetes.\nHydrosphere Mist  - Serverless proxy for Apache Spark clusters.\nHydrosphere ML Lambda  - Open source model management cluster for deploying, serving and monitoring machine learning models and ad-hoc algorithms with a FaaS architecture.\nKNative Serving  - Kubernetes based serverless microservices with \"scale-to-zero\" functionality.\nNuclio  - A high-performance \"serverless\" framework focused on data, I/O, and compute intensive workloads. It is well integrated with popular data science tools, such as Jupyter and Kubeflow; supports a variety of data and streaming sources; and supports execution over CPUs and GPUs.\nOpenFaaS  - Serverless functions framework with RESTful API on Kubernetes\nComputation Load Distribution\nAnalytics Zoo  - A unified Data Analytics and AI platform for distributed TensorFlow, Keras and PyTorch on Apache Spark/Flink & Ray.\nApache Spark MLlib - Apache Spark's scalable machine learning library in Java, Scala, Python and R.\nBagua  - Bagua is a performant and flexible distributed training framework for PyTorch, providing a faster alternative to PyTorch DDP and Horovod. It supports advanced distributed training algorithms such as quantization and decentralization.\nBeam  Apache Beam is a unified programming model for Batch and Streaming.\nBigDL  - Deep learning framework on top of Spark/Hadoop to distribute data and computations across a HDFS system.\nColossal-AI  - A unified deep learning system for big model era, which helps users to efficiently and quickly deploy large AI model training and inference.\nDask  - Distributed parallel processing framework for Pandas and NumPy computations - (Video).\nDEAP  - A novel evolutionary computation framework for rapid prototyping and testing of ideas. It seeks to make algorithms explicit and data structures transparent. It works in perfect harmony with parallelisation mechanisms such as multiprocessing and SCOOP.\nDeepSpeed  - A deep learning optimization library (lightweight PyTorch wrapper) that makes distributed training easy, efficient, and effective.\nFiber  - Distributed computing library for modern computer clusters from Uber.\nFlashlight  - A fast, flexible machine learning library written entirely in C++ from the Facebook AI Research and the creators of Torch, TensorFlow, Eigen and Deep Speech.\nHivemind  - Decentralized deep learning in PyTorch.\nHorovod  - Uber's distributed training framework for TensorFlow, Keras, and PyTorch.\nNumPyWren  - Scientific computing framework build on top of pywren to enable numpy-like distributed computations.\nPyWren  - Answer the question of the \"cloud button\" for python function execution. It's a framework that abstracts AWS Lambda to enable data scientists to execute any Python function - (Video).\nPyTorch Lightning  - Lightweight PyTorch research framework that allows you to easily scale your models to GPUs and TPUs and use all the latest best practices, without the engineering boilerplate - (Video).\nRay  - Ray is a flexible, high-performance distributed execution framework for machine learning (VIDEO).\nTensorFlowOnSpark  - TensorFlowOnSpark brings TensorFlow programs to Apache Spark clusters.\nVespa  Vespa is an engine for low-latency computation over large data sets.\nModel Serialisation\nJava PMML API - Java libraries for consuming and producing PMML files containing models from different frameworks, including:\npyspark2pmml \nr2pmml \nsklearn2pmml \nsparklyr2pmml \nMMdnn  - Cross-framework solution to convert, visualize and diagnose deep neural network models.\nNeural Network Exchange Format (NNEF) - A standard format to store models across Torch, Caffe, TensorFlow, Theano, Chainer, Caffe2, PyTorch, and MXNet.\nONNX  - Open Neural Network Exchange Format.\nPFA - Created by the same organisation as PMML, the Predicted Format for Analytics is an emerging standard for statistical models and data transformation engines.\nPMML - The Predictive Model Markup Language standard in XML - (Video).\nOptimized Computation\nCuDF  - Built based on the Apache Arrow columnar memory format, cuDF is a GPU DataFrame library for loading, joining, aggregating, filtering, and otherwise manipulating data.\nCuML  - cuML is a suite of libraries that implement machine learning algorithms and mathematical primitives functions that share compatible APIs with other RAPIDS projects.\nCuPy  - An implementation of NumPy-compatible multi-dimensional array on CUDA. CuPy consists of the core multi-dimensional array class, cupy.ndarray, and many functions on it.\nH2O-3  - Fast scalable Machine Learning platform for smarter applications: Deep Learning, Gradient Boosting & XGBoost, Random Forest, Generalized Linear Modeling (Logistic Regression, Elastic Net), K-Means, PCA, Stacked Ensembles, Automatic Machine Learning (AutoML), etc..\nJax  - Composable transformations of Python+NumPy programs: differentiate, vectorize, JIT to GPU/TPU, and more.\nModin  - Speed up your Pandas workflows by changing a single line of code.\nNebullvm  - Easy-to-use library to boost AI inference leveraging multiple deep learning compilers.\nNumba   - A compiler for Python array and numerical functions.\nNumpyGroupies  Optimised tools for group-indexing operations: aggregated sum and more\nOpenVINO\u2122 integration with TensorFlow  - Highly optimized Neural Network inference with Tensorflow on Intel platforms by adding a single line of code.\nVaex  Vaex is a high performance Python library for lazy Out-of-Core DataFrames (similar to Pandas), to visualize and explore big tabular datasets. Vaex uses memory mapping, zero memory copy policy and lazy computations for best performance (no memory wasted).\nVulkan Kompute  - Blazing fast, lightweight and mobile phone-enabled Vulkan compute framework optimized for advanced GPU data processing usecases.\nWeld  High-performance runtime for data analytics applications, Here is an interview with Weld\u2019s main contributor.\nData Stream Processing\nApache Flink  - Open source stream processing framework with powerful stream and batch processing capabilities.\nApache Samza  - Distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management.\nBrooklin  - Distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management.\nFaust  - Streaming library built on top of Python's Asyncio library using the async kafka client inspired by the kafka streaming library.\nApache Spark  - Micro-batch processing for streams using the apache spark framework as a backend supporting stateful exactly-once semantics.\nApache Kafka  - Kafka client library for buliding applications and microservices where the input and output are stored in kafka clusters.\nOutlier and Anomaly Detection\nadtk   - A Python toolkit for rule-based/unsupervised anomaly detection in time series.\nAlibi-Detect  - Algorithms for outlier and adversarial instance detection, concept drift and metrics.\ndBoost  - Outlier detection in heterogeneous datasets using automatic tuple expansion. Check this paper for further details.\nDeequ  - A library built on top of Apache Spark for defining \"unit tests for data\", which measure data quality in large datasets.\nDeep Anomaly Detection with Outlier Exposure  - Outlier Exposure (OE) is a method for improving anomaly detection performance in deep learning models. Paper\nPyOD  - A Python Toolbox for Scalable Outlier Detection (Anomaly Detection).\nSUOD (Scalable Unsupervised Outlier Detection)  - An Acceleration System for Large-scale Anomaly/Outlier Detection.\nTensorflow Data Validation (TFDV)  - Library for exploring and validating machine learning data.\nFeature Engineering\nauto-sklearn  - Framework to automate algorithm and hyperparameter tuning for sklearn.\nAutoGluon  - Automated feature, model, and hyperparameter selection for tabular, image, and text data on top of popular machine learning libraries (Scikit-Learn, LightGBM, CatBoost, PyTorch, MXNet).\nAutoML-GS  - Automatic feature and model search with code generation in Python, on top of common data science libraries (tensorflow, sklearn, etc.).\nautoml   - Automated feature engineering, feature/model selection, hyperparam. optimisation.\nColombus - A scalable framework to perform exploratory feature selection implemented in R.\nFeature Engine  - Feature-engine is a Python library that contains several transformers to engineer features for use in machine learning models.\nFeaturetools  - An open source framework for automated feature engineering.\ngo-featureprocessing  - A feature pre-processing framework in Go that matches functionality of sklearn.\nkeras-tuner  - Keras Tuner is an easy-to-use, distributable hyperparameter optimization framework that solves the pain points of performing a hyperparameter search. Keras Tuner makes it easy to define a search space and leverage included algorithms to find the best hyperparameter values.\nmljar-supervised  - An Automated Machine Learning (AutoML) python package for tabular data. It can handle: Binary Classification, MultiClass Classification and Regression. It provides feature engineering, explanations and markdown reports.\nsklearn-deap  Use evolutionary algorithms instead of gridsearch in scikit-learn.\nTPOT  - Automation of sklearn pipeline creation (including feature selection, pre-processor, etc.).\ntsfresh  - Automatic extraction of relevant features from time series.\nUpgini  - Free automated data & feature enrichment library for machine learning: automatically searches through thousands of ready-to-use features from public and community shared data sources and enriches your training dataset with only the accuracy improving features.\nFeature Store\nButterfree  - A tool for building feature stores which allows you to transform your raw data into beautiful features.\nFeature Store for Machine Learning (FEAST)  - Feast (Feature Store) is a tool for managing and serving machine learning features. Feast is the bridge between models and data.\nFeatureform  - A virtual featurestore. Plug-&-play with your existing infra. Data Scientist approved. Discovery, Governance, Lineage, & Collaboration just a pip install away. Supports pandas, Python, spark, SQL + integrations with major cloud vendors. \nHopsworks Feature Store  - Offline/Online Feature Store for ML (Video).\nIvory  - ivory defines a specification for how to store feature data and provides a set of tools for querying it. It does not provide any tooling for producing feature data in the first place. All ivory commands run as MapReduce jobs so it assumed that feature data is maintained on HDFS.\nVeri  - Veri is a Feature Label Store. Feature Label store allows storing features as keys and labels as values. Querying values is only possible with knn using features. Veri also supports creating sub sample spaces of data by default.\nCommercial Platform\nAmazon SageMaker - End-to-end machine learning development and deployment interface where you are able to build notebooks that use EC2 instances as backend, and then can host models exposed on an API.\nApheris - A platform for federated and privacy-preserving data science that lets you securely collaborate on AI with partners without sharing any data.\nArize AI - ML observability and automated model monitoring to help ML practitioners understand how their models perform in production, troubleshoot issues, and improve model performance. ML teams can upload offline (training or validation) baselines into an evaluation/inference store alongside online production data for model validation, drift detection, data quality checks, and model performance management.\nBigML - A consumable, programmable, and scalable Machine Learning platform that makes it easy to solve and automate classification, regression, time series, etc..\nCensius - Censius is an AI Observability Platform that assists enterprises in continuously monitoring, analyzing, and explaining their production models. It combines monitoring, accountability, and explainability into one Observability Platform.\nCnvrg.io - An end-to-end platform to manage, build and automate machine learning\nComet - Machine learning experiment management. Free for open source and students - (Video).\nD2iQ Kaptain - An end-to-end machine learning platform built for security, scale, and speed, that allows enterprises to develop and deploy machine learning models that runs in the cloud, on premises (incl. air-gapped), in hybrid environments, or on the edge; based on Kubeflow and open-source Kubernetes Universal Declarative Operators (KUDO).\nDAGsHub - Community platform for Open Source ML \u2013 Manage experiments, data & models and create collaborative ML projects easily.\nDatabricks - An integrated end-to-end machine learning environment incorporating managed services for experiment tracking, model training, feature development and management, and feature and model serving.\nDataiku - Collaborative data science platform powering both self-service analytics and the operationalization of machine learning models in production.\nDataRobot - Automated machine learning platform which enables users to build and deploy machine learning models.\nDatatron - Machine Learning Model Governance Platform for all your AI models in production for large Enterprises.\nDeep Cognition Deep Learning Studio - E2E platform for deep learning.\ndeepsense Safety - AI-driven solution to increase worksite safety via safety procedure check, thread detection and hazardous zones monitoring.\ndeepsense Quality - Automating laborious quality control tasks.\nDiffgram - Training Data First platform. Database & Training Data Pipelines for Supervised AI. Integrated with GCP, AWS, Azure and top Annotation Supervision UIs (or use built-in Diffgram UI, or build your own). Plus a growing list of integrated service providers! For Computer Vision, NLP, and Supervised Deep Learning / Machine Learning.\nDomino - An enterprise MLOps platform that supports data scientist collaboration with their preferred tools, languages, and infrastructure, with IT central resource management, governance, and security, without vendor lock-in.\nGoogle Cloud Machine Learning Engine - Managed service that enables developers and data scientists to build and bring machine learning models to production.\nGraphsignal - Machine learning profiler that helps make model training and inference faster and more efficient.\nH2O Driverless AI - Automates key machine learning tasks, delivering automatic feature engineering, model validation, model tuning, model selection and deployment, machine learning interpretability, bring your own recipe, time-series and automatic pipeline generation for model scoring - (Video).\nIBM Watson Studio - Build and scale trusted AI on any cloud. Automate the AI lifecycle for ModelOps.\nIguazio Data Science Platform - Bring your Data Science to life by automating MLOps with end-to-end machine learning pipelines, transforming AI projects into real-world business outcomes, and supporting real-time performance at enterprise scale.\nIterative Studio - Seamless data and model management, experiment tracking, visualization and automation, with Git as the single source of truth.\nKatonic.ai - Automate your cycle of Intelligence with Katonic MLOps Platform.\nLabelbox - Image labelling service with support for semantic segmentation (brush & superpixels), bounding boxes and nested classifications.\nMicrosoft Azure Machine Learning service - Build, train, and deploy models from the cloud to the edge.\nModelOp - An enterprise MLOps platform that automates the governance, management and monitoring of deployed AI, ML models across platforms and teams, resulting in reliable, compliant and scalable AI initiatives.\nMLJAR - Platform for rapid prototyping, developing and deploying machine learning models.\nNeptune.ai  - Neptune is a lightweight solution designed for: 1) experiment tracking; 2) model registry; 3) ML runs live monitoring.\nNimblebox - A full-stack MLOps platform designed to help data scientists and machine learning practitioners around the world discover, create, and launch multi-cloud apps from their web browser.\nProdigy - Active learning-based data annotation. Allows to train a model and pick most 'uncertain' samples for labeling from an unlabeled pool.\nRobust Intelligence - Robust Intelligence is an end-to-end ML integrity solution that proactively eliminates failure at every stage of the model lifecycle. From pre-deployment vulnerability detection and validation to post-deployment monitoring and protection, Robust Intelligence gives teams the confidence to scale models in production across a variety of use cases and modalities.\nScribble Enrich - Customizable, auditable, privacy-aware feature store. It is designed to help mid-sized data teams gain trust in the data that they use for training and analysis, and support emerging needs such drift computation and bias assessment.\nSigOpt - SigOpt is a model development platform that makes it easy to track runs, visualize training, and scale hyperparameter optimization for any type of model built with any library on any infrastructure.\nSkymind - Software distribution designed to help enterprise IT teams manage, deploy, and retrain machine learning models at scale.\nSkytree - End to end machine learning platform - (Video).\nSpell - Flexible end-to-end MLOps / Machine Learning Platform - (Video).\nSuperAnnotate - A complete set of solutions for image and video annotation and an annotation service with integrated tooling, on-demand narrow expertise in various fields, and a custom neural network, automation, and training models powered by AI.\nSuperb AI - ML DataOps platform providing various tools to build, label, manage and iterate on training data.\nSyndicai - Easy-to-use cloud agnostic platform that deploys, manages, and scales any trained AI model in minutes with no configuration & infrastructure setup.\nTalend Studio - Data integration platform that provides various software and services for data integration, data management, enterprise application integration, data quality, cloud storage and Big Data.\nValohai - Machine orchestration, version control and pipeline management for deep learning.\nVertex AI - Vertex AI Workbench is the single environment for data scientists to complete all of their ML work, from experimentation, to deployment, to managing and monitoring models. It is a Jupyter-based fully managed, scalable, enterprise-ready compute infrastructure with security controls and user management capabilities.\nWeights & Biases  - Machine learning experiment tracking, dataset versioning, hyperparameter search, visualization, and collaboration.",
	"data-mining data-science logistic-regression machine-learning machine-learning-algorithms neural-network python scikit-learn": "Python Machine Learning book code repository\nIMPORTANT NOTE (09/21/2017):\nThis GitHub repository contains the code examples of the 1st Edition of Python Machine Learning book. If you are looking for the code examples of the 2nd Edition, please refer to this repository instead. \nWhat you can expect are 400 pages rich in useful material just about everything you need to know to get started with machine learning ... from theory to the actual code that you can directly put into action! This is not yet just another \"this is how scikit-learn works\" book. I aim to explain all the underlying concepts, tell you everything you need to know in terms of best practices and caveats, and\nwe will put those concepts into action mainly using NumPy, scikit-learn, and Theano.\nYou are not sure if this book is for you? Please checkout the excerpts from the Foreword and Preface, or take a look at the FAQ section for further information.\n1st edition, published September 23rd 2015\nPaperback: 454 pages\nPublisher: Packt Publishing\nLanguage: English\nISBN-10: 1783555130\nISBN-13: 978-1783555130\nKindle ASIN: B00YSILNL0\nGerman ISBN-13: 978-3958454224\nJapanese ISBN-13: 978-4844380603\nItalian ISBN-13: 978-8850333974\nChinese (traditional) ISBN-13: 978-9864341405\nChinese (mainland) ISBN-13: 978-7111558804\nKorean ISBN-13: 979-1187497035\nRussian ISBN-13: 978-5970604090\nTable of Contents and Code Notebooks\nSimply click on the ipynb/nbviewer links next to the chapter headlines to view the code examples (currently, the internal document links are only supported by the NbViewer version).\nPlease note that these are just the code examples accompanying the book, which I uploaded for your convenience; be aware that these notebooks may not be useful without the formulae and descriptive text. \nExcerpts from the Foreword and Preface\nInstructions for setting up Python and the Jupiter Notebook \nMachine Learning - Giving Computers the Ability to Learn from Data [dir] [ipynb] [nbviewer]\nTraining Machine Learning Algorithms for Classification [dir] [ipynb] [nbviewer]\nA Tour of Machine Learning Classifiers Using Scikit-Learn [dir] [ipynb] [nbviewer]\nBuilding Good Training Sets \u2013 Data Pre-Processing [dir] [ipynb] [nbviewer]\nCompressing Data via Dimensionality Reduction [dir] [ipynb] [nbviewer]\nLearning Best Practices for Model Evaluation and Hyperparameter Optimization [dir] [ipynb] [nbviewer]\nCombining Different Models for Ensemble Learning [dir] [ipynb] [nbviewer]\nApplying Machine Learning to Sentiment Analysis [dir] [ipynb] [nbviewer]\nEmbedding a Machine Learning Model into a Web Application [dir] [ipynb] [nbviewer]\nPredicting Continuous Target Variables with Regression Analysis [dir] [ipynb] [nbviewer]\nWorking with Unlabeled Data \u2013 Clustering Analysis [dir] [ipynb] [nbviewer]\nTraining Artificial Neural Networks for Image Recognition [dir] [ipynb] [nbviewer]\nParallelizing Neural Network Training via Theano [dir] [ipynb] [nbviewer]\nEquation Reference\n[PDF] [TEX]\nSlides for Teaching\nA big thanks to Dmitriy Dligach for sharing his slides from his machine learning course that is currently offered at Loyola University Chicago. \n- https://github.com/dmitriydligach/PyMLSlides\nAdditional Math and NumPy Resources\nSome readers were asking about Math and NumPy primers, since they were not included due to length limitations. However, I recently put together such resources for another book, but I made these chapters freely available online in hope that they also serve as helpful background material for this book:\nAlgebra Basics [PDF] [EPUB]\nA Calculus and Differentiation Primer [PDF] [EPUB]\nIntroduction to NumPy [PDF] [EPUB] [Code Notebook]\nCiting this Book\nYou are very welcome to re-use the code snippets or other contents from this book\nin scientific publications and other works;\nin this case, I would appreciate citations to the original source:\nBibTeX:\n@Book{raschka2015python,\n author = {Raschka, Sebastian},\n title = {Python Machine Learning},\n publisher = {Packt Publishing},\n year = {2015},\n address = {Birmingham, UK},\n isbn = {1783555130}\n }\nMLA:\nRaschka, Sebastian. Python machine learning. Birmingham, UK: Packt Publishing, 2015. Print.\nFeedback & Reviews\nShort review snippets\nSebastian Raschka\u2019s new book, Python Machine Learning, has just been released. I got a chance to read a review copy and it\u2019s just as I expected - really great! It\u2019s well organized, super easy to follow, and it not only offers a good foundation for smart, non-experts, practitioners will get some ideas and learn new tricks here as well.\n\u2013 Lon Riesberg at Data Elixir\nSuperb job! Thus far, for me it seems to have hit the right balance of theory and practice\u2026math and code! \n\u2013 Brian Thomas\nI've read (virtually) every Machine Learning title based around Scikit-learn and this is hands-down the best one out there. \n\u2013 Jason Wolosonovich\nThe best book I've seen to come out of PACKT Publishing. This is a very well written introduction to machine learning with Python. As others have noted, a perfect mixture of theory and application. \n\u2013 Josh D.\nA book with a blend of qualities that is hard to come by: combines the needed mathematics to control the theory with the applied coding in Python. Also great to see it doesn't waste paper in giving a primer on Python as many other books do just to appeal to the greater audience. You can tell it's been written by knowledgeable writers and not just DIY geeks. \n\u2013 Amazon Customer\nSebastian Raschka created an amazing machine learning tutorial which combines theory with practice. The book explains machine learning from a theoretical perspective and has tons of coded examples to show how you would actually use the machine learning technique. It can be read by a beginner or advanced programmer.\n- William P. Ross, 7 Must Read Python Books\nLonger reviews\nIf you need help to decide whether this book is for you, check out some of the \"longer\" reviews linked below. (If you wrote a review, please let me know, and I'd be happy to add it to the list).\nPython Machine Learning Review by Patrick Hill at the Chartered Institute for IT\nBook Review: Python Machine Learning by Sebastian Raschka by Alex Turner at WhatPixel\nLinks\nebook and paperback at Amazon.com, Amazon.co.uk, Amazon.de\nebook and paperback from Packt (the publisher)\nat other book stores: Google Books, O'Reilly, Safari, Barnes & Noble, Apple iBooks, ...\nsocial platforms: Goodreads\nTranslations\nItalian translation via \"Apogeo\"\nGerman translation via \"mitp Verlag\"\nJapanese translation via \"Impress Top Gear\"\nChinese translation (traditional Chinese)\nChinese translation (simple Chinese)\nKorean translation via \"Kyobo\"\nPolish translation via \"Helion\"\nLiterature References & Further Reading Resources\nErrata\nBonus Notebooks (not in the book)\nLogistic Regression Implementation [dir] [ipynb] [nbviewer]\nA Basic Pipeline and Grid Search Setup [dir] [ipynb] [nbviewer]\nAn Extended Nested Cross-Validation Example [dir] [ipynb] [nbviewer]\nA Simple Barebones Flask Webapp Template [view directory][download as zip-file]\nReading handwritten digits from MNIST into NumPy arrays [GitHub ipynb] [nbviewer]\nScikit-learn Model Persistence using JSON [GitHub ipynb] [nbviewer]\nMultinomial logistic regression / softmax regression [GitHub ipynb] [nbviewer]\n\"Related Content\" (not in the book)\nModel evaluation, model selection, and algorithm selection in machine learning - Part I\nModel evaluation, model selection, and algorithm selection in machine learning - Part II\nModel evaluation, model selection, and algorithm selection in machine learning - Part III\nSciPy 2016\nWe had such a great time at SciPy 2016 in Austin! It was a real pleasure to meet and chat with so many readers of my book. Thanks so much for all the nice words and feedback! And in case you missed it, Andreas Mueller and I gave an Introduction to Machine Learning with Scikit-learn; if you are interested, the video recordings of Part I and Part II are now online!\nPyData Chicago 2016\nI attempted the rather challenging task of introducing scikit-learn & machine learning in just 90 minutes at PyData Chicago 2016. The slides and tutorial material are available at \"Learning scikit-learn -- An Introduction to Machine Learning in Python.\"\nNote\nI have set up a separate library, mlxtend, containing additional implementations of machine learning (and general \"data science\") algorithms. I also added implementations from this book (for example, the decision region plot, the artificial neural network, and sequential feature selection algorithms) with additional functionality.\nTranslations\nDear readers,\nfirst of all, I want to thank all of you for the great support! I am really happy about all the great feedback you sent me so far, and I am glad that the book has been so useful to a broad audience.\nOver the last couple of months, I received hundreds of emails, and I tried to answer as many as possible in the available time I have. To make them useful to other readers as well, I collected many of my answers in the FAQ section (below).\nIn addition, some of you asked me about a platform for readers to discuss the contents of the book. I hope that this would provide an opportunity for you to discuss and share your knowledge with other readers:\nGoogle Groups Discussion Board\n(And I will try my best to answer questions myself if time allows! :))\nThe only thing to do with good advice is to pass it on. It is never of any use to oneself.\n\u2014 Oscar Wilde\nExamples and Applications by Readers\nOnce again, I have to say (big!) THANKS for all the nice feedback about the book. I've received many emails from readers, who\nput the concepts and examples from this book out into the real world and make good use of them in their projects. In this section, I am\nstarting to gather some of these great applications, and I'd be more than happy to add your project to this list -- just shoot me a quick mail!\n40 scripts on Optical Character Recognition by Richard Lyman\nCode experiments by Jeremy Nation\nWhat I Learned Implementing a Classifier from Scratch in Python by Jean-Nicholas Hould\nFAQ\nGeneral Questions\nWhat are machine learning and data science?\nWhy do you and other people sometimes implement machine learning algorithms from scratch?\nWhat learning path/discipline in data science I should focus on?\nAt what point should one start contributing to open source?\nHow important do you think having a mentor is to the learning process?\nWhere are the best online communities centered around data science/machine learning or python?\nHow would you explain machine learning to a software engineer?\nHow would your curriculum for a machine learning beginner look like?\nWhat is the Definition of Data Science?\nHow do Data Scientists perform model selection? Is it different from Kaggle?\nQuestions about the Machine Learning Field\nHow are Artificial Intelligence and Machine Learning related?\nWhat are some real-world examples of applications of machine learning in the field?\nWhat are the different fields of study in data mining?\nWhat are differences in research nature between the two fields: machine learning & data mining?\nHow do I know if the problem is solvable through machine learning?\nWhat are the origins of machine learning?\nHow was classification, as a learning machine, developed?\nWhich machine learning algorithms can be considered as among the best?\nWhat are the broad categories of classifiers?\nWhat is the difference between a classifier and a model?\nWhat is the difference between a parametric learning algorithm and a nonparametric learning algorithm?\nWhat is the difference between a cost function and a loss function in machine learning?\nQuestions about ML Concepts and Statistics\nCost Functions and Optimization\nFitting a model via closed-form equations vs. Gradient Descent vs Stochastic Gradient Descent vs Mini-Batch Learning -- what is the difference?\nHow do you derive the Gradient Descent rule for Linear Regression and Adaline?\nRegression Analysis\nWhat is the difference between Pearson R and Simple Linear Regression?\nTree models\nHow does the random forest model work? How is it different from bagging and boosting in ensemble models?\nWhat are the disadvantages of using classic decision tree algorithm for a large dataset?\nWhy are implementations of decision tree algorithms usually binary, and what are the advantages of the different impurity metrics?\nWhy are we growing decision trees via entropy instead of the classification error?\nWhen can a random forest perform terribly?\nModel evaluation\nWhat is overfitting?\nHow can I avoid overfitting?\nIs it always better to have the largest possible number of folds when performing cross validation?\nWhen training an SVM classifier, is it better to have a large or small number of support vectors?\nHow do I evaluate a model?\nWhat is the best validation metric for multi-class classification?\nWhat factors should I consider when choosing a predictive model technique?\nWhat are the best toy datasets to help visualize and understand classifier behavior?\nHow do I select SVM kernels?\nInterlude: Comparing and Computing Performance Metrics in Cross-Validation -- Imbalanced Class Problems and 3 Different Ways to Compute the F1 Score\nLogistic Regression\nWhat is Softmax regression and how is it related to Logistic regression?\nWhy is logistic regression considered a linear model?\nWhat is the probabilistic interpretation of regularized logistic regression?\nDoes regularization in logistic regression always results in better fit and better generalization?\nWhat is the major difference between naive Bayes and logistic regression?\nWhat exactly is the \"softmax and the multinomial logistic loss\" in the context of machine learning?\nWhat is the relation between Loigistic Regression and Neural Networks and when to use which?\nLogistic Regression: Why sigmoid function?\nIs there an analytical solution to Logistic Regression similar to the Normal Equation for Linear Regression?\nNeural Networks and Deep Learning\nWhat is the difference between deep learning and usual machine learning?\nCan you give a visual explanation for the back propagation algorithm for neural networks?\nWhy did it take so long for deep networks to be invented?\nWhat are some good books/papers for learning deep learning?\nWhy are there so many deep learning libraries?\nWhy do some people hate neural networks/deep learning?\nHow can I know if Deep Learning works better for a specific problem than SVM or random forest?\nWhat is wrong when my neural network's error increases?\nHow do I debug an artificial neural network algorithm?\nWhat is the difference between a Perceptron, Adaline, and neural network model?\nWhat is the basic idea behind the dropout technique?\nOther Algorithms for Supervised Learning\nWhy is Nearest Neighbor a Lazy Algorithm?\nUnsupervised Learning\nWhat are some of the issues with clustering?\nSemi-Supervised Learning\nWhat are the advantages of semi-supervised learning over supervised and unsupervised learning?\nEnsemble Methods\nIs Combining Classifiers with Stacking Better than Selecting the Best One?\nPreprocessing, Feature Selection and Extraction\nWhy do we need to re-use training parameters to transform test data?\nWhat are the different dimensionality reduction methods in machine learning?\nWhat is the difference between LDA and PCA for dimensionality reduction?\nWhen should I apply data normalization/standardization?\nDoes mean centering or feature scaling affect a Principal Component Analysis?\nHow do you attack a machine learning problem with a large number of features?\nWhat are some common approaches for dealing with missing data?\nWhat is the difference between filter, wrapper, and embedded methods for feature selection?\nShould data preparation/pre-processing step be considered one part of feature engineering? Why or why not?\nIs a bag of words feature representation for text classification considered as a sparse matrix?\nNaive Bayes\nWhy is the Naive Bayes Classifier naive?\nWhat is the decision boundary for Naive Bayes?\nCan I use Naive Bayes classifiers for mixed variable types?\nIs it possible to mix different variable types in Naive Bayes, for example, binary and continues features?\nOther\nWhat is Euclidean distance in terms of machine learning?\nWhen should one use median, as opposed to the mean or average?\nProgramming Languages and Libraries for Data Science and Machine Learning\nIs R used extensively today in data science?\nWhat is the main difference between TensorFlow and scikit-learn?\nQuestions about the Book\nCan I use paragraphs and images from the book in presentations or my blog?\nHow is this different from other machine learning books?\nWhich version of Python was used in the code examples?\nWhich technologies and libraries are being used?\nWhich book version/format would you recommend?\nWhy did you choose Python for machine learning?\nWhy do you use so many leading and trailing underscores in the code examples?\nWhat is the purpose of the return self idioms in your code examples?\nAre there any prerequisites and recommended pre-readings?\nHow can I apply SVM to categorical data?\nContact\nI am happy to answer questions! Just write me an email\nor consider asking the question on the Google Groups Email List.\nIf you are interested in keeping in touch, I have quite a lively twitter stream (@rasbt) all about data science and machine learning. I also maintain a blog where I post all of the things I am particularly excited about.",
	"data-mining data-science forecasting machine-learning scikit-learn time-series time-series-analysis time-series-classification time-series-regression": "Welcome to sktime\nA unified interface for machine learning with time series\n:rocket: Version 0.14.0 out now! Check out the release notes here.\nsktime is a library for time series analysis in Python. It provides a unified interface for multiple time series learning tasks. Currently, this includes time series classification, regression, clustering, annotation and forecasting. It comes with time series algorithms and scikit-learn compatible tools to build, tune and validate time series models.\n| Overview | |\n|---|---|\n| CI/CD |     |\n| Code |       |\n| Downloads|    |\n| Community |      |\n| Citation |  |\n:books: Documentation\n| Documentation              |                                                                |\n| -------------------------- | -------------------------------------------------------------- |\n| :star: Tutorials        | New to sktime? Here's everything you need to know!              |\n| :clipboard: Binder Notebooks | Example notebooks to play with in your browser.              |\n| :woman_technologist: User Guides      | How to use sktime and its features.                             |\n| :scissors: Extension Templates | How to build your own estimator using sktime's API.            |\n| :control_knobs: API Reference      | The detailed reference for sktime's API.                        |\n| :tv: Video Tutorial            | Our video tutorial from 2021 PyData Global.      |\n| :hammer_and_wrench: Changelog          | Changes and version history.                                   |\n| :deciduous_tree: Roadmap          | sktime's software and community development plan.                                   |\n| :pencil: Related Software          | A list of related software. |\n:speech_balloon: Where to ask questions\nQuestions and feedback are extremely welcome! Please understand that we won't be able to provide individual support via email. We also believe that help is much more valuable if it's shared publicly, so that more people can benefit from it.\n| Type                            | Platforms                               |\n| ------------------------------- | --------------------------------------- |\n| :bug: Bug Reports              | GitHub Issue Tracker                  |\n| :sparkles: Feature Requests & Ideas | GitHub Issue Tracker                       |\n| :woman_technologist: Usage Questions          | GitHub Discussions \u00b7 Stack Overflow |\n| :speech_balloon: General Discussion        | GitHub Discussions |\n| :factory: Contribution & Development | Slack, contributors channel \u00b7 Discord |\n| :globe_with_meridians: Community collaboration session | Discord - Fridays 1pm UTC, dev/meet-ups channel |\n:dizzy: Features\nOur aim is to make the time series analysis ecosystem more interoperable and usable as a whole. sktime provides a unified interface for distinct but related time series learning tasks. It features dedicated time series algorithms and tools for composite model building including pipelining, ensembling, tuning and reduction that enables users to apply an algorithm for one task to another.\nsktime also provides interfaces to related libraries, for example scikit-learn, statsmodels, tsfresh, PyOD and fbprophet, among others.\nFor deep learning, see our companion package: sktime-dl.\n| Module | Status | Links |\n|---|---|---|\n| Forecasting | stable | Tutorial \u00b7 API Reference \u00b7 Extension Template  |\n| Time Series Classification | stable | Tutorial \u00b7 API Reference \u00b7 Extension Template |\n| Time Series Regression | stable | API Reference |\n| Transformations | stable | API Reference \u00b7 Extension Template  |\n| Time Series Clustering | maturing | Extension Template |\n| Time Series Distances/Kernels | experimental | Extension Template |\n| Annotation | experimental | Extension Template |\n:hourglass_flowing_sand: Install sktime\nFor trouble shooting and detailed installation instructions, see the documentation.\nOperating system: macOS X \u00b7 Linux \u00b7 Windows 8.1 or higher\nPython version: Python 3.7, 3.8, 3.9, and 3.10 (only 64 bit)\nPackage managers: pip \u00b7 conda (via conda-forge)\npip\nUsing pip, sktime releases are available as source packages and binary wheels. You can see all available wheels here.\nbash\npip install sktime\nor, with maximum dependencies,\nbash\npip install sktime[all_extras]\nconda\nYou can also install sktime from conda via the conda-forge channel. For the feedstock including the build recipe and configuration, check out this repository.\nbash\nconda install -c conda-forge sktime\nor, with maximum dependencies,\nbash\nconda install -c conda-forge sktime-all-extras\n:zap: Quickstart\nForecasting\n```python\nfrom sktime.datasets import load_airline\nfrom sktime.forecasting.base import ForecastingHorizon\nfrom sktime.forecasting.model_selection import temporal_train_test_split\nfrom sktime.forecasting.theta import ThetaForecaster\nfrom sktime.performance_metrics.forecasting import mean_absolute_percentage_error\ny = load_airline()\ny_train, y_test = temporal_train_test_split(y)\nfh = ForecastingHorizon(y_test.index, is_relative=False)\nforecaster = ThetaForecaster(sp=12)  # monthly seasonal periodicity\nforecaster.fit(y_train)\ny_pred = forecaster.predict(fh)\nmean_absolute_percentage_error(y_test, y_pred)\n0.08661467738190656\n```\nTime Series Classification\n```python\nfrom sktime.classification.interval_based import TimeSeriesForestClassifier\nfrom sktime.datasets import load_arrow_head\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nX, y = load_arrow_head()\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nclassifier = TimeSeriesForestClassifier()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\naccuracy_score(y_test, y_pred)\n0.8679245283018868\n```\n:wave: How to get involved\nThere are many ways to join the sktime community. We follow the all-contributors specification: all kinds of contributions are welcome - not just code.\n| Documentation              |                                                                |\n| -------------------------- | --------------------------------------------------------------        |\n| :gift_heart: Contribute        | How to contribute to sktime.          |\n| :school_satchel:  Mentoring | New to open source? Apply to our mentoring program! |\n| :date: Meetings | Join our discussions, tutorials, workshops and sprints! |\n| :woman_mechanic:  Developer Guides      | How to further develop sktime's code base.                             |\n| :construction: Enhancement Proposals | Design a new feature for sktime. |\n| :medal_sports: Contributors | A list of all contributors. |\n| :raising_hand: Roles | An overview of our core community roles. |\n| :money_with_wings: Donate | Fund sktime maintenance and development. |\n| :classical_building: Governance | How and by whom decisions are made in sktime's community.   |\n:bulb: Project vision\nby the community, for the community -- developed by a friendly and collaborative community.\nthe right tool for the right task -- helping users to diagnose their learning problem and suitable scientific model types.\nembedded in state-of-art ecosystems and provider of interoperable interfaces -- interoperable with scikit-learn, statsmodels, tsfresh, and other community favourites.\nrich model composition and reduction functionality -- build tuning and feature extraction pipelines, solve forecasting tasks with scikit-learn regressors.\nclean, descriptive specification syntax -- based on modern object-oriented design principles for data science.\nfair model assessment and benchmarking -- build your models, inspect your models, check your models, avoid pitfalls.\neasily extensible -- easy extension templates to add your own algorithms compatible with sktime's API.",
	"awesome-list cyber-security data-mining machine-learning": "Awesome Machine Learning for Cyber Security \nA curated list of amazingly awesome tools and resources related to the use of machine learning for cyber security.\nTable of Contents\nDatasets\nPapers\nBooks\nTalks\nTutorials\nCourses\nMiscellaneous\n\u2191 Contributing\nPlease read CONTRIBUTING if you wish to add tools or resources.\n\u2191 Datasets\nHIKARI-2021 Datasets\nSamples of Security Related Data\nDARPA Intrusion Detection Data Sets [ 1998 / 1999 ]\nStratosphere IPS Data Sets\nOpen Data Sets\nData Capture from National Security Agency\nThe ADFA Intrusion Detection Data Sets\nNSL-KDD Data Sets\nMalicious URLs Data Sets\nMulti-Source Cyber-Security Events\nKDD Cup 1999 Data\nWeb Attack Payloads\nWAF Malicious Queries Data Sets\nMalware Training Data Sets\nAktaion Data Sets\nCRIME Database from DeepEnd Research\nPublicly available PCAP files\n2007 TREC Public Spam Corpus\nDrebin Android Malware Dataset\nPhishingCorpus Datset\nEMBER\nVizsec Research\nSHERLOCK\nProbing / Port Scan - Dataset \nAegean Wireless Intrusion Dataset (AWID)\nBODMAS PE Malware Dataset\n\u2191 Papers\nGenerating Network Intrusion Detection Dataset Based on Real and Encrypted Synthetic Attack Traffic\nFast, Lean, and Accurate: Modeling Password Guessability Using Neural Networks\nOutside the Closed World: On Using Machine Learning for Network Intrusion Detection\nAnomalous Payload-Based Network Intrusion Detection\nMalicious PDF detection using metadata and structural features\nAdversarial support vector machine learning\nExploiting machine learning to subvert your spam filter\nCAMP \u2013 Content Agnostic Malware Protection\nNotos \u2013 Building a Dynamic Reputation System for DNS\nKopis \u2013 Detecting malware domains at the upper dns hierarchy\nPleiades \u2013 From Throw-away Traffic To Bots \u2013 Detecting The Rise Of DGA-based Malware\nEXPOSURE \u2013 Finding Malicious Domains Using Passive DNS Analysis\nPolonium \u2013 Tera-Scale Graph Mining for Malware Detection\nNazca \u2013 Detecting Malware Distribution in Large-Scale Networks\nPAYL \u2013 Anomalous Payload-based Network Intrusion Detection\nAnagram \u2013 A Content Anomaly Detector Resistant to Mimicry Attacks\nApplications of Machine Learning in Cyber Security\nData Mining \u0434\u043b\u044f \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u0441\u0438\u0441\u0442\u0435\u043c \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u0441\u0435\u0442\u0435\u0432\u044b\u0445 \u0430\u0442\u0430\u043a (RUS)\n\u0412\u044b\u0431\u043e\u0440 \u0442\u0435\u0445\u043d\u043e\u043b\u043e\u0433\u0438\u0439 Data Mining \u0434\u043b\u044f \u0441\u0438\u0441\u0442\u0435\u043c \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u0432\u0442\u043e\u0440\u0436\u0435\u043d\u0438\u0439 \u0432 \u043a\u043e\u0440\u043f\u043e\u0440\u0430\u0442\u0438\u0432\u043d\u0443\u044e \u0441\u0435\u0442\u044c (RUS)\n\u041d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0435\u0432\u043e\u0439 \u043f\u043e\u0434\u0445\u043e\u0434 \u043a \u0438\u0435\u0440\u0430\u0440\u0445\u0438\u0447\u0435\u0441\u043a\u043e\u043c\u0443 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u044e \u043a\u043e\u043c\u043f\u044c\u044e\u0442\u0435\u0440\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u0432 \u0437\u0430\u0434\u0430\u0447\u0430\u0445 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0431\u0435\u0437\u043e\u043f\u0430\u0441\u043d\u043e\u0441\u0442\u0438 (RUS)\n\u041c\u0435\u0442\u043e\u0434\u044b \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0443\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u0435 \u0432\u0442\u043e\u0440\u0436\u0435\u043d\u0438\u0439 (RUS)\nDimension Reduction in Network Attacks Detection Systems\nRise of the machines: Machine Learning & its cyber security applications\nMachine Learning in Cyber Security: Age of the Centaurs\nAutomatically Evading Classifiers A Case Study on PDF Malware Classifiers\nWeaponizing Data Science for Social Engineering\u200a\u2014\u200aAutomated E2E Spear Phishing on Twitter\nMachine Learning: A Threat-Hunting Reality Check\nNeural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection\nPractical Secure Aggregation for Privacy-Preserving Machine Learning\nDeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning\neXpose: A Character-Level Convolutional Neural Network with Embeddings For Detecting Malicious URLs, File Paths and Registry Keys\nBig Data Technologies for Security Event Correlation Based on Event Type Accounting (RUS)\nInvestigation of The Use of Neural Networks for Detecting Low-Intensive Dd\u043es-Atak of Applied Level (RUS)\nDetecting Malicious PowerShell Commands using Deep Neural Networks\nMachine Learning DDoS Detection for Consumer Internet of Things Devices\nAnomaly Detection in Computer System\nby Intellectual Analysis of System Journals (RUS)\nEMBER: An Open Dataset for Training Static PE Malware Machine Learning Models\nA state-of-the-art survey of malware detection approaches using data mining techniques.\nInvestigation of malicious portable executable file detection on network using supervised learning techniques.\nMachine Learning in Cybersecurity: A Guide\nOutside the Closed World: On Using Machine Learning For Network Intrusion Detection\nMachine Learning Based Network Vulnerability Analysis of Industrial Internet of Things\nHopper: Modeling and Detecting Lateral Movement\nFinding Effective Security Strategies through Reinforcement Learning and Self-Play\nIntrusion Prevention through Optimal Stopping\n\u2191 Books\nData Mining and Machine Learning in Cybersecurity\nMachine Learning and Data Mining for Computer Security\nNetwork Anomaly Detection: A Machine Learning Perspective\nMachine Learning and Security: Protecting Systems with Data and Algorithms\nIntroduction To Artificial Intelligence For Security Professionals\nMastering Machine Learning for Penetration Testing\nMalware Data Science: Attack Detection and Attribution\n\u2191 Talks\nUsing Machine Learning to Support Information Security\nDefending Networks with Incomplete Information\nApplying Machine Learning to Network Security Monitoring\nMeasuring the IQ of your Threat Intelligence Feeds\nData-Driven Threat Intelligence: Metrics On Indicator Dissemination And Sharing\nApplied Machine Learning for Data Exfil and Other Fun Topics\nSecure Because Math: A Deep-Dive on ML-Based Monitoring\nMachine Duping 101: Pwning Deep Learning Systems\nDelta Zero, KingPhish3r \u2013 Weaponizing Data Science for Social Engineering\nDefeating Machine Learning What Your Security Vendor Is Not Telling You\nCrowdSource: Crowd Trained Machine Learning Model for Malware Capability Det\nDefeating Machine Learning: Systemic Deficiencies for Detecting Malware\nPacket Capture Village \u2013 Theodora Titonis \u2013 How Machine Learning Finds Malware\nBuild an Antivirus in 5 Min \u2013 Fresh Machine Learning #7. A fun video to watch\nHunting for Malware with Machine Learning\nMachine Learning for Threat Detection\nMachine Learning and the Cloud: Disrupting Threat Detection and Prevention\nFraud detection using machine learning & deep learning\nThe Applications Of Deep Learning On Traffic Identification\nDefending Networks With Incomplete Information: A Machine Learning Approach\nMachine Learning & Data Science\nAdvances in Cloud-Scale Machine Learning for Cyber-Defense\nApplied Machine Learning: Defeating Modern Malicious Documents\nAutomated Prevention of Ransomware with Machine Learning and GPOs\nLearning to Detect Malware by Mining the Security Literature\nClarence Chio and Anto Joseph - Practical Machine Learning in Infosecurity\nAdvances in Cloud-Scale Machine Learning for Cyberdefense\nMachine Learning-Based Techniques For Network Intrusion Detection\nPractical Machine Learning in Infosec\nAI and Security\nAI in InfoSec\nBeyond the Blacklists: Detecting Malicious URL Through Machine Learning\nMachine Learning Fueled Cyber Threat Hunting\nWeaponizing Machine Learning: Humanity Was Overrated\nMachine Learning, Offense, and the future of Automation\nBringing Red vs. Blue to Machine Learning\nExplaining Machine Learning with Azure and the Titanic Dataset\nUsing Machines to exploit Machines\nAnalyze active directory event logs using visualize and ML\nHardening Machine Learning Defenses Against Adversarial Attacks\nDeep Neural Networks for Hackers: Methods, Applications, and Open Source Tools\nML in the daily work of a threat hunter\nThe Real Deal About AI: ML for CyberSecurity - Josh Fu\nAutomated Detection of Software Vulnerabilities Using Deep-Learning\nBuilding and Breaking a Machine Learning System - Johann Rehberger\nVulnerabilities of Machine Learning Infrastructure - Sergey Gordeychik\n\u2191 Tutorials\nMachine Learning based Password Strength Classification\nUsing Machine Learning to Detect Malicious URLs\nUsing deep learning to break a Captcha system\nData mining for network security and intrusion detection\nApplying Machine Learning to Improve Your Intrusion Detection System\nAnalyzing BotNets with Suricata & Machine Learning\nfWaf \u2013 Machine learning driven Web Application Firewall\nDeep Session Learning for Cyber Security\nDMachine Learning for Malware Detection\nShadowBrokers Leak: A Machine Learning Approach\nPractical Machine Learning in Infosec - Virtualbox Image and Stuff\nA Machine-Learning Toolkit for Large-scale eCrime Forensics\nWebShells Detection by Machine Learning\nBuilding Machine Learning Models for the SOC\nDetecting Web Attacks With Recurrent Neural Networks\nMachine Learning for Red Teams, Part 1\nDetecting Reverse Shell with Machine Learning\nObfuscated Command Line Detection Using Machine Learning\n\u041e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u0435 \u0432\u0435\u0431-\u0430\u0442\u0430\u043a \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0440\u0435\u043a\u0443\u0440\u0440\u0435\u043d\u0442\u043d\u044b\u0445 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u0435\u0439 (RUS)\nClear and Creepy Danger of Machine Learning: Hacking Passwords\nDiscovering anomalous patterns based on parent-child process relationships\nMachine Learning for Detecting Phishing Websites\nPassword Hunting with ML in Active Directory\n\u041a\u0430\u043a \u0441\u0430\u043c\u043e\u043c\u0443 \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0441\u0438\u0441\u0442\u0435\u043c\u0443 \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u043a\u043e\u043c\u043f\u044c\u044e\u0442\u0435\u0440\u043d\u044b\u0445 \u0430\u0442\u0430\u043a \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f (RUS)\n\u2191 Courses\nData Mining for Cyber Security by Stanford\nData Science and Machine Learning for Infosec\nCybersecurity Data Science on Udemy\nMachine Learning for Red Team Hackers on Udemy\nMachine Learning for Security\n\u2191 Miscellaneous\nSystem predicts 85 percent of cyber-attacks using input from human experts\nA list of open source projects in cyber security using machine learning\nSource code about machine learning and security\nSource code for Mastering Machine Learning for Penetration Testing\nConvolutional neural network for analyzing pentest screenshots\nBig Data and Data Science for Security and Fraud Detection\nStringSifter - a machine learning tool that ranks strings based on their relevance for malware analysis\nLicense\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International license.",
	"algorithm artificial-intelligence caffe cv data-analysis data-mining data-science deep-learning keras machine-learning mathematics matplotlib nlp numpy pandas python pytorch seaborn tensorflow tensorflow2": "Created by\n\u5510\u5b87\u8fea\n\u4eba\u5de5\u667a\u80fd\u5b9e\u6218\u5c31\u4e1a(\u9762\u8bd5)\u5b66\u4e60\u8def\u7ebf\u56fe\n[x] \u8fd9\u4e2a\u9879\u76ee\u662f\u5e72\u4ec0\u4e48\u7684\uff1f\n\u8d44\u6599\u5b58\u5728\u592a\u591a\u6570\u636e\u96c6\uff0c\u767e\u5ea6\u7f51\u76d8\u88ab\u4e3e\u62a5\u540e\u5df2\u7ecf\u65e0\u6cd5\u5206\u4eab\u94fe\u63a5\uff0c\u540e\u7eed\u5c06\u63d0\u4f9b\u8c37\u6b4c\u7f51\u76d8\n\u9886\u53d6\u8d44\u6599\u8bf7\u76f4\u63a5\u52a0\u5fae\u4fe1\uff1aGp00006666 \uff08\u9a8c\u8bc1\u4fe1\u606f\u5907\u6ce8GITHUB\u5373\u53ef\uff09\n\u6574\u7406\u8fd9\u4e2a\u9879\u76ee\u7684\u521d\u8877\u662f\u65b9\u4fbf\u540c\u5b66\u4eec\u5feb\u901f\u5f00\u542f\u4eba\u5de5\u667a\u80fd\u81ea\u5b66\u8ba1\u5212\uff0c\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u5c11\u8d70\u5f2f\u8def\u7528\u6700\u5feb\u7684\u6548\u7387\u5165\u95e8Ai\u5e76\u5f00\u59cb\u5b9e\u6218\u9879\u76ee\uff0c\n\u63d0\u4f9b\u4e86\u8fd1200\u4e2aAi\u5b9e\u6218\u6848\u4f8b\u548c\u9879\u76ee\uff0c\u8fd9\u4e9b\u5e76\u4e0d\u662f\u7f51\u4e0a\u641c\u96c6\u6765\u7684\uff0c\u800c\u662f\u6211\u8fd9\u4e94\u5e74\u7ebf\u4e0a\u7ebf\u4e0b\u6559\u5b66\u6240\u5f00\u53d1\u548c\u79ef\u7d2f\u7684\u6848\u4f8b\u3002\u53ef\u4ee5\u8bf4\u90fd\u662f\n\u53cd\u590d\u8fed\u4ee3\u66f4\u65b0\u51fa\u6765\u7684\uff0c\u9002\u5408\u540c\u5b66\u4eec\u6765\u8fdb\u884c\u5faa\u5e8f\u6e10\u8fdb\u7684\u5b66\u4e60\u4e0e\u7ec3\u624b\u3002\u6765\u7684\u540c\u5b66\u8bb0\u5f97\u70b9\u4e2astar\u6536\u85cf\u4e0b\uff01\n[x] \u914d\u5957\u6559\u6750\u5982\u4f55\u83b7\u53d6\uff1f\n19\u5e74\u5e95\u6211\u51fa\u7248\u4e86\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b\u7684\u914d\u5957\u6559\u6750\u300a\u8ddf\u7740\u8fea\u54e5\u5b66Python\u6570\u636e\u5206\u6790\u4e0e\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u300b\uff0c\n\u98ce\u683c\u4f9d\u65e7\u662f\u901a\u4fd7\u6613\u61c2\uff0c\u5386\u65f6\u4e24\u5e74\u53cd\u590d\u4fee\u6539\u8ba2\u6b63\u5341\u4f59\u6b21\u7ec8\u4e8e\u548c\u5927\u5bb6\u89c1\u9762\u4e86\u3002\n\u4e3a\u4e86\u65b9\u4fbf\u66f4\u591a\u540c\u5b66\u4eec\u80fd\u5feb\u901f\u5f00\u59cb\u5b66\u4e60\u8ba1\u5212\uff0c\u6211\u51b3\u5b9a\u5c06\u672c\u4e66\u7684\u7535\u5b50\u7248\u514d\u8d39\u9001\u7ed9\u5927\u5bb6\u3002\u5e0c\u671b\u5b83\u80fd\u7ed9\u5927\u5bb6\u5e26\u6765\u5b66\u4e60\u7684\u6536\u83b7\uff01\n\u5728\u672c\u9879\u76ee\u4e3b\u9875\u5373\u53ef\u4e0b\u8f7dPDF\u7248\u672c\uff0c\u6559\u6750\u5982\u679c\u559c\u6b22\u4e5f\u53ef\u4ece\u4eac\u4e1c\u8d2d\u4e70\u3002\n\u300a\u8ddf\u7740\u8fea\u54e5\u5b66Python\u6570\u636e\u5206\u6790\u4e0e\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u300bPDF\u539f\u7248\u4e0b\u8f7d \uff1a\n(\u7f51\u76d8\u94fe\u63a5: https://pan.baidu.com/s/19wzJeyPmwTBDp9ASEWBvFQ \u63d0\u53d6\u7801: tece )\n[x] \u6309\u7167\u4ec0\u4e48\u987a\u5e8f\u5f00\u59cb\u5b66\u4e60\uff1f\n\u4e0b\u9762\u76ee\u5f55\u4e5f\u5c31\u662f\u5b66\u4e60\u8def\u7ebf\u8def\u4e86\uff0c\u521d\u5b66\u8005\u5efa\u8bae\u6309\u7167\u76ee\u5f55\u4e2d\u7ed9\u51fa\u7684\u987a\u5e8f\u6765\u8fdb\u884c\u5b66\u4e60\uff0c\u5df2\u7ecf\u5165\u95e8\u7684\u540c\u5b66\u5c31\u53ef\u4ee5\u6309\u7167\u81ea\u5df1\u7684\u559c\u597d\u6765\u9009\u62e9\u4e86\u3002\n[x] \u63d0\u4f9b\u6848\u4f8b\u5982\u4f55\u83b7\u53d6\uff1f\n\u6848\u4f8b\u4e2d\u6d89\u53ca\u7684\u6570\u636e\u90fd\u662f\u771f\u5b9e\u6570\u636e\u96c6\uff0c\u6709\u4e9b\u4f1a\u6bd4\u8f83\u5e9e\u5927\uff0c\u76f4\u63a5\u4e0a\u4f20github\u5927\u5bb6\u4e0b\u8f7d\u8d77\u6765\u4f1a\u975e\u5e38\u6162\uff0c\u6211\u4f1a\u9010\u6e10\u4e0a\u4f20\u5404\u4e2a\u6a21\u5757\n\u7684\u7f51\u76d8\u94fe\u63a5\uff0c\u91cc\u9762\u5305\u62ec\u4e86\u6570\u636e\uff0c\u4ee3\u7801\uff0cPPT\u7b49\u5b66\u4e60\u8d44\u6e90\u3002\u5982\u9700\u914d\u5957\u89c6\u9891\u8bb2\u89e3\u8bf7\u6dfb\u52a0\u5fae\u4fe1\uff1adigexiaozhushou\uff08\u8fea\u54e5\u5c0f\u52a9\u624b\u62fc\u97f3\uff09\n[x] \u5408\u4f5c\u4e0e\u4ea4\u6d41\n\u6709\u5404\u65b9\u9762\u5408\u4f5c\u4ea4\u6d41\u4ee5\u53ca\u9879\u76ee\u95ee\u9898\u90fd\u53ef\u4ee5\u76f4\u63a5\u6dfb\u52a0\u5fae\u4fe1:digexiaozhushou\uff08\u8fea\u54e5\u5c0f\u52a9\u624b\u62fc\u97f3\uff09\n\u76ee\u5f55\n\u5fc5\u5907\u57fa\u7840\u6280\u80fd\n\u5fc5\u5907Python\u57fa\u7840 \n\u5fc5\u5907\u6570\u5b66\u57fa\u7840 \n\u5fc5\u5907Python\u5de5\u5177\u5305 \n\u673a\u5668\u5b66\u4e60\n\u673a\u5668\u5b66\u4e60\u7b97\u6cd5 \n\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5b9e\u9a8c\u5206\u6790 \n\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4ee3\u7801\u590d\u73b0 \n\u673a\u5668\u5b66\u4e60\u7ecf\u5178\u6848\u4f8b\u5b9e\u6218\n\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u96c6\u9526 \n\u6570\u636e\u5206\u6790\u4e0e\u6316\u6398 \n\u6570\u636e\u6316\u6398\u5b9e\u6218 \n\u6570\u636e\u6316\u6398\u7ade\u8d5b\u4f18\u80dc\u89e3\u51b3\u65b9\u6848 \n\u6570\u636e\u5206\u6790\u5b9e\u6218 \n\u6df1\u5ea6\u5b66\u4e60 \n\u6df1\u5ea6\u5b66\u4e60\u5fc5\u5907\u7b97\u6cd5 \n\u6df1\u5ea6\u5b66\u4e60\u5fc5\u5907\u5de5\u5177 \n\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\n\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Tensorflow2 \n\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Pytorch \n\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Keras \n\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Caffe\n\u8ba1\u7b97\u673a\u89c6\u89c9\nOpencv\u56fe\u50cf\u5904\u7406\u5b9e\u6218 \n\u8ba1\u7b97\u673a\u89c6\u89c9\u5b9e\u6218\u9879\u76ee\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff09 \n\u81ea\u7136\u8bed\u8a00\u5904\u7406\n\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5b9e\u6218\u9879\u76ee\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff09 \n\u5fc5\u5907\u57fa\u7840\u6280\u80fd\n\u8981\u5b66\u4eba\u5de5\u667a\u80fd\uff08\u6570\u636e\u79d1\u5b66\uff09\u8fd9\u884c\u8fd8\u662f\u9700\u8981\u4e00\u4e9b\u57fa\u672c\u529f\u7684\uff0c\u6700\u57fa\u7840\u4e5f\u662f\u6700\u6838\u5fc3\u7684\u5c31\u662fPython\u548c\u6570\u5b66\u4e86\uff01\u8fd9\u4e24\u5144\u5f1f\u5165\u95e8\u8d77\u6765\n\u5e76\u4e0d\u96be\uff0c\u5148\u638c\u63e1\u57fa\u7840\u7684\u8fb9\u7528\u8fb9\u5b66\u4e5f\u662f\u53ef\u4ee5\u7684\uff01\n\u5fc5\u5907Python\u57fa\u7840\n\u5982\u679c\u5bf9Python\u4e0d\u719f\u6089\u7684\u540c\u5b66\u4eec\uff0c\u5efa\u8bae\u5148\u770b\u4e00\u4e0b\u6211\u7684Python\u5165\u95e8\u89c6\u9891\u8bfe\u7a0b\uff0c\u53ef\u4ee5\u5feb\u901f\u5165\u95e8\uff01\u4f20\u9001\u95e8\n[x] \u4e3a\u4ec0\u4e48\u662fPython\uff1f\n\u6700\u76f4\u63a5\u7684\u89e3\u91ca\u5c31\u662f\u5927\u5bb6\u90fd\u7528\u5b83\uff01\u4ee5\u524d\u662f\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\uff0c\u540e\u6765\u5927\u5bb6\u66f4\u559c\u6b22\u9762\u5411\u590d\u5236\u7c98\u8d34\u7f16\u7a0b\uff0c\u73b0\u5728\u61d2\u5230\u9762\u5411github\u7f16\u7a0b\uff0c\u786e\u5b9e\u5982\u6b64\uff0c\u8be5\u5077\u61d2\u5c31\u5f97\u5077\u61d2\uff0cPython\u5c31\u662f\u8fd9\u4e2a\u4f5c\u7528\uff01\n\u540e\u7eed\u6240\u6709\u7684\u5b9e\u6218\u5185\u5bb9\u90fd\u662f\u57fa\u4e8ePython\uff0c\u6240\u4ee5\u6ca1\u5f97\u9009\u5566\uff01\n[x] \u9700\u8981\u5b89\u88c5\u4ec0\u4e48\uff1f\nAnaconda\u5c31\u591f\u4e86\uff01Anaconda\u5c31\u591f\u4e86\uff01Anaconda\u5c31\u591f\u4e86\uff01\u597d\u4e86\uff0c\u8bf4\u4e86\u4e09\u904d\u4e86\uff0c\u5177\u4f53\u89e3\u91ca\u5927\u5bb6\u53c2\u8003\u4e0a\u9762\u4f20\u9001\u95e8\u8bfe\u7a0b\u5c31\u597d\n[x] \u7528\u4ec0\u4e48\u7f16\u7a0b\u5de5\u5177\u5f00\u59cb\uff1f\n\u867d\u7136\u5927\u5bb6\u90fd\u6709\u8d81\u624b\u7684\u5175\u5668\uff0c\u4f46\u662f\u6211\u7ed9\u5927\u5bb6\u51c6\u5907\u7684\u7edd\u5927\u591a\u6570\u8bfe\u4ef6\u90fd\u662f\u57fa\u4e8ejupyter notebook\u7684\uff0c\u6240\u4ee5\u8fd9\u4e2a\u80af\u5b9a\u662f\u5fc5\u5907\u7684\uff01\n\u5fc5\u5907Python\u5de5\u5177\u5305\n[x] \u4ec0\u4e48\u662f\u5de5\u5177\u5305\uff1f\n\u5de5\u5177\u5305\u5c31\u662f\u4eba\u5bb6\u628a\u529f\u80fd\u90fd\u5199\u597d\u4e86\uff0c\u54b1\u4eec\u76f4\u63a5\u8c03\u7528\u5c31\u5b8c\u4e8b\u5566\uff01\u6570\u636e\u5904\u7406\uff0c\u5206\u6790\uff0c\u5efa\u6a21\u7b49\u90fd\u6709\u5bf9\u5e94\u7684\u5de5\u5177\u5305\u3002\u5bf9\u4e8e\u5b66\u4e60\u6765\u8bf4\n\u5e76\u4e0d\u7528\u628a\u8fd9\u4e9b\u5de5\u5177\u5305\u80cc\u4e0b\u6765\uff0c\u5148\u719f\u6089\u8d77\u6765\uff0c\u540e\u7eed\u80af\u5b9a\u8fd8\u662f\u8981\u73b0\u7528\u73b0\u67e5\u7684\u3002\n[x] \u54ea\u4e9b\u5de5\u5177\u5305\u662f\u521d\u5b66\u8005\u5fc5\u5907\u7684\u5462\uff1f\n|\u5de5\u5177\u5305\u540d\u79f0|\u529f\u80fd\u6982\u8ff0|\n| --------   | :----:  |\n| Numpy       |\u77e9\u9635\u8ba1\u7b97\u5fc5\u5907\uff01\u5b83\u662f\u540e\u7eed\u4e00\u5207\u8ba1\u7b97\u7684\u6838\u5fc3\uff0c\u6570\u636e\u79d1\u5b66\u9886\u57df\u6838\u5fc3\u5de5\u5177\u5305| \n| Pandas       |\u6570\u636e\u5904\u7406\u5fc5\u5907\uff01\u8bfb\u6570\u636e\uff0c\u5904\u7406\u6570\u636e\uff0c\u5206\u6790\u6570\u636e\uff0c\u975e\u4ed6\u4e0d\u53ef!|\n| Matplotlib    |\u53ef\u89c6\u5316\u5fc5\u5907\uff01\u529f\u80fd\u5341\u5206\u5f3a\u5927\uff0c\u6ca1\u6709\u753b\u4e0d\u51fa\u6765\u7684\u56fe\uff0c\u5206\u6790\u5c55\u793a\u5c31\u9760\u5b83\u4e86\uff01| \n| Seaborn      |\u66f4\u7b80\u5355\u7684\u53ef\u89c6\u5316\u795e\u5668\uff01\u4e00\u884c\u4ee3\u7801\u7ed9\u4f60\u641e\u5b9a\u4e00\u4e2a\u53ef\u89c6\u5316\u5c55\u793a\u7ed3\u679c| \n\u5fc5\u5907\u6570\u5b66\u57fa\u7840\n[x] \u6570\u5b66\u91cd\u8981\u5417\uff1f\u975e\u5b66\u4e0d\u53ef\u5417\uff1f \n\u6570\u5b66\u6709\u591a\u91cd\u8981\u540c\u5b66\u4eec\u80af\u5b9a\u90fd\u5341\u5206\u6e05\u695a\uff0c\u5c24\u5176\u662f\u5728\u4eba\u5de5\u667a\u80fd\uff08\u6570\u636e\u79d1\u5b66\uff09\u9886\u57df\uff0c\u4e0d\u61c2\u6570\u5b66\u60f3\u5fc5\u5bf8\u6b65\u96be\u884c\uff0c\u5f88\u591a\u540c\u5b66\u90fd\u95ee\u8fc7\u6211\u4e00\u4e2a\u95ee\u9898\uff0c\u5de5\u4f5c\u4e2d\u771f\u80fd\u7528\u4e0a\u8fd9\u4e48\u591a\u6570\u5b66\u5417\uff1f\n\u6211\u8ddf\u5927\u5bb6\u6765\u89e3\u91ca\u4e00\u4e0b\uff0c\u4eba\u5de5\u667a\u80fd\u8fd9\u884c\u53d1\u5c55\u76f8\u5f53\u8fc5\u901f\uff0c\u5728\u5b9e\u9645\u5de5\u4f5c\u4e2d\u80af\u5b9a\u8981\u8fb9\u5e72\u8fb9\u5b66\uff0c\u5b66\u4ec0\u4e48\u5462\uff1f\u60f3\u5fc5\u5c31\u662f\u5f53\u4e0b\u7684\u4e00\u4e9b\u4f18\u79c0\u8bba\u6587\u4e86\uff0c\u5982\u679c\u8fde\u57fa\u672c\u7684\u6570\u5b66\u516c\u5f0f\u90fd\u770b\u4e0d\u61c2\uff0c\n\u90a3\u5c31\u4e0d\u7528\u518d\u53bb\u8c08\u4ec0\u4e48\u9ad8\u7aef\u6280\u672f\u4e86\u3002\u505a\u8fd9\u884c\u7684\u540c\u5b66\u4eec\u80af\u5b9a\u90fd\u4f1a\u6709\u8fd9\u6837\u4e00\u4e2a\u60f3\u6cd5\uff0c\u6240\u8c13\u7684\u4eba\u5de5\u667a\u80fd\u5c31\u662f\u5bf9\u6570\u636e\u505a\u5404\u79cd\u5404\u6837\u7684\u6570\u5b66\u8ba1\u7b97\u7f62\u4e86\uff01\n[x] \u5982\u4f55\u5b66\u6570\u5b66\uff1f\u8981\u5b9a\u4e00\u4e2a\u957f\u671f\u8ba1\u5212\u5417\uff1f\n\u5bf9\u4e8e\u6570\u5b66\u6211\u89c9\u5f97\u5e76\u4e0d\u9700\u8981\u4ece\u5934\u5f00\u59cb\u82b1\u5927\u91cf\u65f6\u95f4\u4e00\u6b65\u4e00\u4e2a\u811a\u5370\u53bb\u5b66\u4e60\uff0c\u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff0c\u6211\u548c\u6211\u8eab\u8fb9\u7684\u540c\u4e8b\uff0c\u670b\u53cb\u90fd\u662f\u5e72\u8fd9\u884c\u86ee\u4e45\u7684\u4e86\uff0c\u6570\u5b66\u4e0d\u77e5\u9053\u64b8\u4e86\u591a\u5c11\u904d\u4e86\uff0c\u8003\u7814\u65f6\u5019\u4e5f\u66fe\u5237\u9898\u65e0\u6570\uff0c\n\u4f46\u4e5f\u4f1a\u9047\u5230\u8fd9\u6837\u7684\u95ee\u9898\uff0c\u5f88\u591a\u77e5\u8bc6\u70b9\u5982\u679c\u4e00\u6bb5\u65f6\u95f4\u6ca1\u770b\u5f88\u5feb\u8fd8\u662f\u4f1a\u5fd8\u8bb0\u3002\u6211\u6700\u5e38\u505a\u7684\u4e00\u4ef6\u4e8b\u5c31\u662f\u7528\u5230\u4ec0\u4e48\u67e5\u4ec0\u4e48\uff0c\u67e5\u627e\u7684\u8fc7\u7a0b\u5176\u5b9e\u4e5f\u662f\u5b66\u4e60\u8fdb\u6b65\u8fc7\u7a0b\u3002\u5efa\u8bae\u5927\u5bb6\u53ef\u4ee5\u5feb\u901f\u8fc7\u4e00\u904d\n\u5e38\u7528\u7684\u77e5\u8bc6\u70b9\uff08\u9ad8\u6570\uff0c\u7ebf\u6027\uff0c\u6982\u7387\u8bba\u4e2d\u7684\u57fa\u7840\uff09\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u5343\u4e07\u522b\u53bb\u770b\u5404\u79cd\u89e3\u9898\u8fc7\u7a0b\uff0c\u4e5f\u4e0d\u7528\u7ba1\u5177\u4f53\u6c42\u89e3\u7684\u65b9\u6cd5\uff0c\u8bf4\u767d\u4e86\u5c31\u662f\u53ea\u8981\u7406\u89e3\u4e00\u4e2a\u516c\u5f0f\u662f\u505a\u4ec0\u4e48\u7684\uff0c\u6709\u4ec0\u4e48\u7528\n\u5c31\u8db3\u591f\u4e86\uff0c\u7c7b\u4f3c\u6559\u6750\u4e2d\u7684\u4e60\u9898\uff0c\u7ec3\u4e60\u518c\u4e0a\u7684\u6c42\u89e3\u8fd9\u4e9b\u7edf\u7edf\u4e0d\u9700\u8981\uff0c\u4ee5\u540e\u4e5f\u6839\u672c\u4e0d\u4f1a\u7528\u7b14\u53bb\u7b97\u8fd9\u4e9b\u9ebb\u70e6\u4e8b\uff0c\u628a\u8fd9\u4e2a\u65f6\u95f4\u7701\u4e0b\u6765\u53bb\u5b66\u4e60\u7b97\u6cd5\u66f4\u5212\u5f97\u6765\uff01\n[x] \u4e0b\u9762\u662f\u8bfe\u7a0b\u4e2d\u6240\u8bbe\u8ba1\u7684\u77e5\u8bc6\u70b9\uff0c\u4e5f\u662f\u5fc5\u5907\u57fa\u7840\n|\u77e5\u8bc6\u70b9   |  \u5185\u5bb9  |  \u4f5c\u7528  |\n| --------   | -----:  | :----:  |\n| \u9ad8\u7b49\u6570\u5b66        | \u9ad8\u7b49\u6570\u5b66\u57fa\u7840\uff0c\u5fae\u79ef\u5206\uff0c\u6cf0\u52d2\u516c\u5f0f\u4e0e\u62c9\u683c\u6717\u65e5\uff0c |  \u673a\u5668\u5b66\u4e60\u516c\u5f0f\u63a8\u5bfc\u5fc5\u5907|\n| \u7ebf\u6027\u4ee3\u6570        |\u7ebf\u6027\u4ee3\u6570\u57fa\u7840\uff0c\u7279\u5f81\u503c\u4e0e\u77e9\u9635\u5206\u89e3\uff0c| \u7b97\u6cd5\u6c42\u89e3\u5fc5\u5907|\n| \u6982\u7387\u8bba          |\u6982\u7387\u8bba\u57fa\u7840\uff0c\u968f\u673a\u53d8\u91cf\u4e0e\u6982\u7387\u4f30\u8ba1\uff0c\u5e38\u7528\u5206\u5e03|  \u673a\u5668\u5b66\u4e60\u7ecf\u5e38\u63d0\u8fd9\u4e9b\u8bcd|\n| \u7edf\u8ba1\u5206\u6790         |\u56de\u5f52\u5206\u6790\uff0c\u5047\u8bbe\u68c0\u9a8c\uff0c\u76f8\u5173\u5206\u6790\uff0c\u65b9\u5dee\u5206\u6790|  \u6570\u636e\u5206\u6790\u5fc5\u5907  |\n\u673a\u5668\u5b66\u4e60\n\u4eba\u5de5\u667a\u80fd\u9886\u57df\u6700\u6838\u5fc3\u7684\u5c31\u662f\u673a\u5668\u5b66\u4e60\u4e86\uff0c\u65e0\u8bba\u5927\u5bb6\u540e\u7eed\u60f3\u4ece\u4e8b\u54ea\u4e2a\u65b9\u5411\uff0c\u80af\u5b9a\u90fd\u662f\u5148\u4ece\u673a\u5668\u5b66\u4e60\u5f00\u59cb\uff01\u4e3b\u8981\u5c31\u4e24\u4ef6\u4e8b\uff0c\n\u7b2c\u4e00\u5c31\u662f\u638c\u63e1\u7ecf\u5178\u7b97\u6cd5\u539f\u7406\uff0c\u7b2c\u4e8c\u5c31\u662f\u719f\u7ec3\u5e94\u7528Python\u5de5\u5177\u5305\u8fdb\u884c\u5efa\u6a21\u5b9e\u6218\uff01\n\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\n[x] \u7b97\u6cd5\u8981\u5b66\u4ec0\u4e48\uff1f\n\u7406\u89e3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u662f\u5982\u4f55\u5bf9\u6570\u636e\u8fdb\u884c\u64cd\u4f5c\u4ece\u800c\u5b8c\u6210\u5efa\u6a21\u6c42\u89e3\u8fc7\u7a0b\uff0c\u8bf4\u767d\u4e86\u5c31\u662f\u719f\u6089\u4e0b\u6570\u5b66\u5728\u7b97\u6cd5\u4e2d\u662f\u5982\u4f55\u5e94\u7528\u7684\u3002\u91cd\u5728\u7406\u89e3\u5373\u53ef\uff01\u4e0d\u8981\u5bf9\u4e00\u4e2a\u95ee\u9898\u94bb\u7684\u6ca1\u5b8c\u6ca1\u4e86\uff0c\u8fd9\u6837\u592a\n\u6d6a\u8d39\u65f6\u95f4\u4e86\uff0c\u6ca1\u51c6\u540e\u7eed\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4e00\u4e0b\u5b50\u5c31\u8fce\u5203\u800c\u89e3\u4e86\u3002\u6211\u89c9\u5f97\u5bf9\u7b97\u6cd5\u7684\u5b66\u4e60\u80af\u5b9a\u4e0d\u6b62\u4e00\u904d\uff0c\u5c24\u5176\u662f\u51c6\u5907\u9762\u8bd5\u5c31\u4e1a\u7684\u540c\u5b66\u4eec\uff0c\u4e8c\u5237\uff0c\u4e09\u5237\u90fd\u662f\u5f88\u6b63\u5e38\u7684\u73b0\u8c61\uff08\u66fe\u7ecf\u6709\u540c\u5b66\n\u8ddf\u6211\u8bf4\u9762\u8bd5\u524d\u4e00\u5171\u5237\u4e866\u904d\u8bfe\u7a0b\uff09\n[x] \u6709\u4e86\u6df1\u5ea6\u5b66\u4e60\u8fd8\u9700\u8981\u673a\u5668\u5b66\u4e60\u5417\uff1f\n\u6df1\u5ea6\u5b66\u4e60\u53ef\u4ee5\u8bf4\u662f\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e00\u79cd\uff0c\u5e76\u4e0d\u662f\u6709\u4e86\u795e\u7ecf\u7f51\u7edc\u5176\u4ed6\u7ecf\u5178\u7b97\u6cd5\u5c31\u4e0d\u9700\u8981\u4e86\uff0c\u9700\u8981\u6839\u636e\u4e0d\u540c\u7684\u4efb\u52a1\u548c\u6570\u636e\u6765\u9009\u62e9\u6700\u5408\u9002\u7684\u7b97\u6cd5\uff0c\u5b66\u4e60\u8def\u5f84\u80af\u5b9a\u662f\u5148\u4ece\u673a\u5668\u5b66\u4e60\u5f00\u59cb\uff0c\n\u5176\u5b9e\u638c\u63e1\u4e86\u8fd9\u4e9b\u7ecf\u5178\u7b97\u6cd5\u4e4b\u540e\u518d\u770b\u795e\u7ecf\u7f51\u7edc\u771f\u7684\u5f88\u7b80\u5355\uff01\n[x] \u4e0b\u9762\u662f\u8bfe\u7a0b\u4e2d\u4f1a\u8bb2\u89e3\u7684\u7b97\u6cd5\uff0c\u4e5f\u662f\u5927\u5bb6\u5fc5\u987b\u638c\u63e1\u7684\uff01\u8fd9\u91cc\u6ca1\u6709\u5217\u51fa\u6240\u6709\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u56e0\u4e3a\u6709\u5f88\u591a\u73b0\u5728\u5df2\u7ecf\u4e0d\u5b9e\u7528\u4e86\u3002\n|\u77e5\u8bc6\u70b9   |  \u5185\u5bb9  |  \u6982\u8ff0  |\n| --------   | -----:  | :----:  |\n| \u5206\u7c7b\u7b97\u6cd5        | \u903b\u8f91\u56de\u5f52\uff0c\u51b3\u7b56\u6811\uff0c\u652f\u6301\u5411\u91cf\u673a\uff0c\u96c6\u6210\u7b97\u6cd5\uff0c\u8d1d\u53f6\u65af\u7b97\u6cd5|  \u51c6\u5907\u9762\u8bd5\u7684\u540c\u5b66\u4eec\u5fc5\u987b\u638c\u63e1|\n| \u56de\u5f52\u7b97\u6cd5        |\u7ebf\u6027\u56de\u5f52\uff0c\u51b3\u7b56\u6811\uff0c\u96c6\u6210\u7b97\u6cd5| \u6709\u4e9b\u7b97\u6cd5\u65e2\u80fd\u505a\u5206\u7c7b\u4e5f\u80fd\u505a\u56de\u5f52|\n| \u805a\u7c7b\u7b97\u6cd5     |k-means\uff0cdbscan\u7b49| \u65e0\u76d1\u7763\u662f\u5b9e\u5728\u6ca1\u6807\u7b7e\u7684\u65f6\u5019\u624d\u8003\u8651\u7684|\n| \u964d\u7ef4\u7b97\u6cd5         |\u4e3b\u6210\u5206\u5206\u6790\uff0c\u7ebf\u6027\u5224\u522b\u5206\u6790\u7b49|  \u91cd\u5728\u7406\u89e3\u964d\u7ef4\u7684\u601d\u60f3  |\n| \u8fdb\u9636\u7b97\u6cd5         |GBDT\u63d0\u5347\u7b97\u6cd5\uff0clightgbm\uff0c\uff0cEM\u7b97\u6cd5\uff0c\u9690\u9a6c\u5c14\u79d1\u592b\u6a21\u578b| \u8fdb\u9636\u7b97\u6cd5\u6709\u65f6\u95f4\u7cbe\u529b\u7684\u540c\u5b66\u4eec\u53ef\u4ee5\u6311\u6218|\n\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5b9e\u9a8c\u5206\u6790\n\u901a\u8fc7\u5bf9\u6bd4\u5b9e\u9a8c\u5206\u6790\u7ecf\u5178\u7b97\u6cd5\u5efa\u6a21\u65b9\u6cd5\u53ca\u5176\u53c2\u6570\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u5b9e\u9a8c\u4e0e\u53ef\u89c6\u5316\u5c55\u793a\u7406\u89e3\u7b97\u6cd5\u4e2d\u7684\u53c2\u6570\u4e0e\u5e94\u7528\u5b9e\u4f8b\u3002\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   | :----:  |\n| \u7ebf\u6027\u56de\u5f52\u5b9e\u9a8c\u5206\u6790       |\u638c\u63e1\u4e00\u5143\u4e0e\u591a\u5143\u7ebf\u6027\u56de\u5f52\uff0c\u975e\u7ebf\u6027\u56de\u5f52\u65b9\u6cd5\uff0c\u6b63\u5219\u5316\u60e9\u7f5a\u7684\u4f5c\u7528| \n| \u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5        |\u5e38\u7528\u5206\u7c7b\u4e0e\u56de\u5f52\u7b97\u6cd5\u8bc4\u4f30\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u6570\u636e\u96c6\u5207\u5206\u5b9e\u4f8b|\n| \u903b\u8f91\u56de\u5f52\u5b9e\u9a8c\u5206\u6790    |\u7ecf\u5178\u5206\u7c7b\u6a21\u578b\u6784\u9020\u65b9\u6cd5\uff0c\u51b3\u7b56\u6811\u8fb9\u754c\u7ed8\u5236\u65b9\u6cd5| \n| \u805a\u7c7b\u7b97\u6cd5\u5b9e\u9a8c\u5206\u6790       |\u65e0\u76d1\u7763\u5efa\u6a21\u5b9e\u4f8b\uff0c\u805a\u7c7b\u7b97\u6cd5\u8bc4\u4f30\u65b9\u6cd5\uff0c\u65e0\u76d1\u7763\u7684\u4f5c\u7528\u4e0e\u5e94\u7528\u5b9e\u4f8b| \n| \u51b3\u7b56\u6811\u5b9e\u9a8c\u5206\u6790      |\u6811\u6a21\u578b\u53ef\u89c6\u5316\u5b9e\u4f8b\u4e0e\u6784\u9020\u65b9\u6cd5\uff0c\u6811\u6a21\u578b\u7684\u5206\u7c7b\u4e0e\u56de\u5f52\u5e94\u7528| \n| \u96c6\u6210\u7b97\u6cd5\u5b9e\u9a8c\u5206\u6790       |\u96c6\u6210\u65b9\u6cd5\u5e94\u7528\u5b9e\u4f8b\u4e0e\u6548\u679c\u5206\u6790\uff0c\u5e38\u89c1\u96c6\u6210\u7b56\u7565\u5bf9\u6bd4|\n| \u652f\u6301\u5411\u91cf\u673a\u5b9e\u9a8c\u5206\u6790   |SVM\u6d89\u53ca\u53c2\u6570\u4e0e\u5efa\u6a21\u5bf9\u6bd4\u5b9e\u9a8c| \n| \u5173\u8054\u89c4\u5219\u5b9e\u6218\u5206\u6790      |\u5173\u8054\u89c4\u5219\u5fc5\u5907\u77e5\u8bc6\u70b9\u4e0e\u5efa\u6a21\u5206\u6790\u5b9e\u4f8b|\n\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4ee3\u7801\u590d\u73b0\n\u4e3a\u4e86\u66f4\u597d\u7406\u89e3\u7b97\u6cd5\u7684\u673a\u5236\u4ece\u96f6\u5f00\u59cb\u590d\u73b0\u7ecf\u5178\u7b97\u6cd5\uff0c\u575a\u6301\u4e0d\u6389\u5305\u539f\u5219\uff0c\u4e00\u6b65\u6b65\u5b8c\u6210\u7b97\u6cd5\u6240\u9700\u6240\u6709\u6a21\u5757\u3002\n[x] \u4e3a\u4ec0\u4e48\u8981\u81ea\u5df1\u590d\u73b0\u4ee3\u7801\uff1f\u6709\u4f55\u4ef7\u503c\u5462\uff1f\n\u4e3b\u8981\u76ee\u7684\u662f\u66f4\u597d\u7684\u638c\u63e1\u7b97\u6cd5\u7684\u5de5\u4f5c\u539f\u7406\uff0c\u91cd\u5728\u7ec3\u4e60\uff01\u6709\u65f6\u95f4\u7684\u540c\u5b66\u4eec\u53ef\u4ee5\u81ea\u5df1\u590d\u73b0\u4e00\u904d\uff0c\u65f6\u95f4\u7d27\u7684\u540c\u5b66\u5c31\u4e0d\u5fc5\u4eb2\u529b\u4eb2\u4e3a\u4e86\u3002\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   | :----:  |\n| \u7ebf\u6027\u56de\u5f52\u4ee3\u7801\u5b9e\u73b0       |\u5206\u6a21\u5757\u6784\u5efa\u7b97\u6cd5\u5e38\u7528\u51fd\u6570| \n| \u903b\u8f91\u56de\u5f52\u4ee3\u7801\u5b9e\u73b0       |\u5b9e\u4f8b\u89e3\u8bfb\u903b\u8f91\u56de\u5f52\u5b9e\u73b0\u65b9\u6cd5|\n| Kmeans\u4ee3\u7801\u5b9e\u73b0    |\u975e\u5e38\u7b80\u5355\u6613\u61c2\u7684\u65e0\u76d1\u7763\u7b97\u6cd5| \n| \u51b3\u7b56\u6811\u4ee3\u7801\u5b9e\u73b0      |\u6811\u6a21\u578b\u5176\u5b9e\u5c31\u662f\u9012\u5f52\u5b9e\u73b0| \n| \u795e\u7ecf\u7f51\u7edc\u4ee3\u7801\u5b9e\u73b0      |\u4ee3\u7801\u91cf\u7565\u5927\uff0c\u5efa\u8baedebug\u6a21\u5f0f\u5b66\u4e60| \n| \u8d1d\u53f6\u65af\u4ee3\u7801\u5b9e\u73b0      |\u8d1d\u53f6\u65af\u5728\u6587\u672c\u4efb\u52a1\u4e2d\u8fd8\u662f\u6bd4\u8f83\u597d\u89e3\u91ca|\n| \u5173\u8054\u89c4\u5219\u4ee3\u7801\u5b9e\u73b0   |\u5e38\u7528\u7684\u6570\u636e\u5206\u6790\u7b97\u6cd5| \n| \u6253\u9020\u97f3\u4e50\u63a8\u8350\u7cfb\u7edf    |\u4ece\u96f6\u5f00\u59cb\u6784\u9020\u63a8\u8350\u7cfb\u7edf\u6a21\u578b|\n\u673a\u5668\u5b66\u4e60\u7ecf\u5178\u6848\u4f8b\u5b9e\u6218\n[x] \u5b9e\u6218\u9700\u8981\u638c\u63e1\u54ea\u4e9b\u6280\u80fd\uff1f\n\u5728\u5b9e\u6218\u4e2d\u53ef\u80fd\u628a\u6570\u5b66\u77e5\u8bc6\u70b9\u90fd\u5f31\u5316\u4e86\uff0c\u56e0\u4e3a\u66f4\u591a\u65f6\u5019\u6211\u4eec\u90fd\u662f\u4f7f\u7528\u73b0\u6210\u7684\u5de5\u5177\u5305\u6765\u5b8c\u6210\u4efb\u52a1\uff08\u8c03\u5305\u4fa0\uff09\u3002\u8fd9\u91cc\u9700\u8981\u5927\u5bb6\u638c\u63e1\u7684\u8282\u80fd\u529f\u80fd\u6bd4\u8f83\u591a\uff0c\n\u9996\u5148\u5c31\u662f\u719f\u7ec3\u4f7f\u7528\u8fd9\u4e9b\u5e38\u7528\u5de5\u5177\u5305\u4e86\uff0c\u6570\u636e\u9884\u5904\u7406\uff0c\u7279\u5f81\u5de5\u7a0b\uff0c\u8c03\u53c2\uff0c\u9a8c\u8bc1\u8fd9\u4e9b\u90fd\u662f\u975e\u5e38\u6838\u5fc3\u7684\u6b65\u9aa4\u3002\u6982\u62ec\u6765\u8bf4\u5c31\u662f\u8981\u5b8c\u6210\u4e0d\u540c\u7684\u4efb\u52a1\u6240\u9700\u6d41\u7a0b\u548c\u5957\u8def\u90fd\u662f\u7c7b\u4f3c\u7684\uff0c\n\u4f46\u662f\u4f7f\u7528\u7684\u65b9\u6cd5\u548c\u7b97\u6cd5\u5374\u53ef\u80fd\u4e0d\u540c\uff0c\u8fd9\u5c31\u9700\u8981\u5927\u5bb6\u4e0d\u65ad\u79ef\u7d2f\u6765\u4e30\u5bcc\u5b9e\u6218\u7ecf\u9a8c\u4e86\u3002\u7ed9\u540c\u5b66\u4eec\u63d0\u4f9b\u7684\u8fd9\u4e9b\u6848\u4f8b\u5927\u5bb6\u90fd\u53ef\u4ee5\u5f53\u4f5c\u662f\u81ea\u5df1\u7684\u5b9e\u6218\u6a21\u677f\uff01\n[x] \u8fd9\u4e9b\u6848\u4f8b\u80fd\u8ba9\u6211\u6536\u83b7\u4ec0\u4e48\uff1f\n\u6700\u91cd\u8981\u7684\u5c31\u662f\u5b66\u4f1a\u9488\u5bf9\u4e0d\u540c\u6570\u636e\uff08\u6570\u503c\uff0c\u6587\u672c\uff0c\u56fe\u50cf\uff09\u5982\u4f55\u8fdb\u884c\u9884\u5904\u7406\u4e0e\u5206\u6790\uff0c\u719f\u7ec3\u5e94\u7528\u5de5\u5177\u5305\u4e2d\u5404\u5927\u6838\u5fc3\u51fd\u6570\u8fdb\u884c\u8c03\u53c2\u4e0e\u9884\u5904\u7406\uff0c\u9488\u5bf9\u4e0d\u540c\u4efb\u52a1\u63d0\u51fa\u591a\u79cd\u89e3\u51b3\n\u65b9\u6848\u5e76\u8fdb\u884c\u5b9e\u9a8c\u5206\u6790\u3002\u603b\u7ed3\u8d77\u6765\u5c31\u662f\u591a\u505a\u5b9e\u9a8c\uff0c\u591a\u52a8\u624b\uff0c\u4ee3\u7801\u5199\u7684\u591a\u4e86\u81ea\u7136\u5c31\u719f\u7ec3\u4e86\uff01\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| K\u8fd1\u90bb\u7b97\u6cd5\u5b9e\u6218       |\u673a\u5668\u5b66\u4e60\u5165\u95e8\u6848\u4f8b\uff0c\u638c\u63e1\u5de5\u5177\u5305\u5e94\u7528\u4e8e\u5efa\u6a21\u65b9\u6cd5| \n| \u4ea4\u6613\u6570\u636e\u5f02\u5e38\u68c0\u6d4b      |\u5341\u5206\u91cd\u8981\uff0c\u6570\u636e\u5904\u7406\u548c\u5efa\u6a21\u7b56\u7565\u7684\u8be6\u7ec6\u5206\u6790\u5bf9\u6bd4|\n| \u96c6\u6210\u7b97\u6cd5\u5efa\u6a21\u5b9e\u6218    |\u96c6\u6210\u4e0d\u7528\u6211\u591a\u8bf4\u4e86\uff0c\u5fc5\u5907\u6838\u5fc3\u7b56\u7565| \n| \u57fa\u4e8e\u968f\u673a\u68ee\u6797\u7684\u6c14\u6e29\u9884\u6d4b      |\u968f\u673a\u68ee\u6797\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u6700\u5e38\u7528\u7684\u7b97\u6cd5\uff0c\u8be6\u7ec6\u5206\u6790\u5bf9\u6bd4| \n| \u65b0\u95fb\u5206\u7c7b\u5b9e\u6218      |\u6587\u672c\u6570\u636e\u5206\u6790\u5904\u7406\uff0c\u57fa\u4e8e\u8d1d\u53f6\u65af\u7b97\u6cd5\u5c55\u5f00\u5efa\u6a21\u5b9e\u6218| \n| \u805a\u7c7b\u5b9e\u8df5\u5206\u6790       |\u65e0\u76d1\u7763\u5e94\u7528\u5b9e\u4f8b|\n| \u65f6\u95f4\u5e8f\u5217\u5206\u6790   |\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5236\u4f5c\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5e8f\u5217\u6570\u636e\u8fdb\u884c\u5efa\u6a21| \n| \u7528\u6237\u6d41\u5931\u9884\u8b66      |\u6211\u7ecf\u5e38\u8bf4\u68a6\u5e7b\u897f\u6e38\u7684\u7528\u6237\u6d41\u5931\uff0c\u8fd9\u4e2a\u53ea\u662f\u4e2aDEMO|\n| \u4f7f\u7528lightgbm\u8fdb\u884c\u996d\u5e97\u6d41\u91cf\u9884\u6d4b       |\u53c8\u662f\u4e00\u4e2a\u5927\u6740\u5668\uff0c\u6bd4xgboost\u8fd8\u864e|\n| \u4eba\u53e3\u666e\u67e5\u6570\u636e\u96c6\u9879\u76ee\u5b9e\u6218-\u6536\u5165\u9884\u6d4b   |\u6838\u5fc3\u6a21\u677f\uff0c\u6570\u636e\u5206\u6790\uff0c\u53ef\u89c6\u5316\u5565\u7684\u8be5\u6709\u7684\u90fd\u6709| \n| \u8d1d\u53f6\u65af\u4f18\u5316\u5b9e\u6218      |\u96be\u5ea6\u8f83\u5927\uff0c\u8d1d\u53f6\u65af\u4f18\u5316\u5de5\u5177\u5305\u4f7f\u7528\u5b9e\u4f8b|\n| \u6587\u672c\u7279\u5f81\u65b9\u6cd5\u5bf9\u6bd4   |\u6587\u672c\u6570\u636e\u5e38\u7528\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u5bf9\u6bd4| \n| \u5236\u4f5c\u81ea\u5df1\u5e38\u7528\u5de5\u5177\u5305     |\u81ea\u5df1\u505a\u4e2a\u5305\u73a9\u73a9|\n\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u96c6\u9526\n[x] \u8fd9\u91cc\u8fd8\u7ed9\u5927\u5bb6\u51c6\u5907\u4e86\u4e30\u5bcc\u7684\u5b9e\u6218\u9879\u76ee\uff0c\u975e\u5e38\u9002\u5408\u5927\u5bb6\u6765\u7ec3\u624b\uff01\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| Python\u5b9e\u6218\u5173\u8054\u89c4\u5219       |\u7528\u5de5\u5177\u5305\u6765\u505a\u5173\u8054\u89c4\u5219\u5b9e\u5728\u592a\u8f7b\u677e\u4e86| \n| \u7231\u5f7c\u8fce\u6570\u636e\u96c6\u5206\u6790\u4e0e\u5efa\u6a21     |\u623f\u4ef7\u6570\u636e\u96c6\u5206\u6790\u4e0e\u5efa\u6a21\u5b9e\u4f8b|\n| \u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u9152\u5e97\u63a8\u8350\u7cfb\u7edf    |\u6765\u6784\u5efa\u4e00\u4e2a\u63a8\u8350\u7cfb\u7edf\u5b8c\u6210\u9152\u5e97\u63a8\u8350| \n| \u5546\u54c1\u9500\u552e\u989d\u56de\u5f52\u5206\u6790      |\u9500\u552e\u989d\u9884\u6d4b\uff0c\u5f88\u5e38\u89c4\u7684\u4efb\u52a1\uff0c\u5e38\u89c4\u5957\u8def\u641e\u5b9a| \n| \u7edd\u5730\u6c42\u751f\u6570\u636e\u96c6\u63a2\u7d22\u5206\u6790\u4e0e\u5efa\u6a21      |\u7edd\u5730\u6c42\u751f\u6570\u636e\u96c6\uff0c\u6765\u770b\u770b\u4f60\u7a76\u7adf\u88ab\u4ec0\u4e48\u4eba\u5e72\u6389\u4e86| \n| \u6a21\u578b\u89e3\u91ca\u65b9\u6cd5\u5b9e\u6218       |\u5efa\u6a21\u540e\u5982\u4f55\u6765\u89e3\u91ca\u6a21\u578b\u5462\uff0c\u8fd9\u51e0\u4e2a\u5de5\u5177\u5305\u5e2e\u4f60\u641e\u5b9a|\n| \u81ea\u7136\u8bed\u8a00\u5904\u7406\u5fc5\u5907\u5de5\u5177\u5305\u5b9e\u6218  |NLP\u5e38\u7528\u5de5\u5177\u5305\u89e3\u8bfb\uff0c\u5b9e\u4f8b\u6f14\u793a| \n| \u94f6\u884c\u5ba2\u6237\u8fd8\u6b3e\u53ef\u80fd\u6027\u9884\u6d4b      |\u94f6\u884c\u5ba2\u6237\u6570\u636e\u6765\u9884\u6d4b\u8fd8\u6b3e\u7684\u53ef\u80fd\u6027|\n| \u56fe\u50cf\u7279\u5f81\u805a\u7c7b\u5206\u6790\u5b9e\u8df5       |\u56fe\u50cf\u6570\u636e\u5982\u4f55\u8fdb\u884c\u805a\u7c7b\u5462\uff1f|\n| \u4eba\u53e3\u666e\u67e5\u6570\u636e\u96c6\u9879\u76ee\u5b9e\u6218-\u6536\u5165\u9884\u6d4b   |\u6838\u5fc3\u6a21\u677f\uff0c\u6570\u636e\u5206\u6790\uff0c\u53ef\u89c6\u5316\u5565\u7684\u8be5\u6709\u7684\u90fd\u6709| \n\u6570\u636e\u5206\u6790\u4e0e\u6316\u6398\n\u6570\u636e\u5206\u6790\u8fd9\u4e2a\u8bcd\u5927\u5bb6\u5929\u5929\u90fd\u5728\u542c\uff0c\u8981\u5e72\u4ec0\u4e48\u5462\uff1f\u65e0\u975e\u5c31\u662f\u4ece\u6570\u636e\u4e2d\u83b7\u53d6\u6709\u4ef7\u503c\u7684\u4fe1\u606f\uff0c\u8fd9\u5176\u4e2d\u65b9\u6cd5\u4e0e\u5957\u8def\u8fd8\u662f\u975e\u5e38\u591a\u7684\u3002\n\u8fd9\u4e2a\u65b9\u5411\u4e0d\u9700\u8981\u4ec0\u4e48\u7406\u8bba\u79ef\u7d2f\uff0c\u76f4\u63a5\u4e0a\u6570\u636e\uff0c\u5e72\u5c31\u5f97\u4e86\uff01\u6848\u4f8b\u7684\u79ef\u7d2f\u5c31\u662f\u5b66\u4e60\u8fc7\u7a0b\uff01\n\u6570\u636e\u6316\u6398\u5b9e\u6218\n[x] \u6570\u636e\u6316\u6398\u662f\u4ec0\u4e48\uff1f\u548c\u673a\u5668\u5b66\u4e60\u6709\u4ec0\u4e48\u533a\u522b\uff1f\n\u7b80\u5355\u6765\u8bf4\u6570\u636e\u6316\u6398\u5c31\u662f\u5bf9\u6d77\u91cf\u6570\u636e\u5e94\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u6765\u5f97\u5230\u60f3\u8981\u7684\u7ed3\u679c\u3002\u5728\u6570\u636e\u6316\u6398\u4e2d\u91cd\u70b9\u5e76\u4e0d\u662f\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u9009\u62e9\uff0c\u800c\u662f\u600e\u4e48\u6837\u5bf9\u6570\u636e\u8fdb\u884c\u5904\u7406\u624d\u80fd\u5f97\u5230\u66f4\u597d\u7684\n\u9884\u6d4b\u7ed3\u679c\uff0c\u5728\u8fd9\u91cc\u7279\u5f81\u5de5\u7a0b\u4e0e\u9884\u5904\u7406\u5c06\u6210\u4e3a\u6838\u5fc3\u89e3\u51b3\u65b9\u6848\u3002\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| \u6cf0\u5766\u5c3c\u514b\u53f7\u83b7\u6551\u9884\u6d4b       |\u7ecf\u5178\u7684kaggle\u7ade\u8d5b\u6848\u4f8b\uff0c\u5165\u95e8\u6570\u636e\u6316\u6398\u7684\u7b2c\u4e00\u4e2a\u5b9e\u6218\u9879\u76ee| \n| \u6570\u636e\u7279\u5f81\u6784\u5efa       |\u7279\u5f81\u5de5\u7a0b\u662f\u6570\u636e\u6316\u6398\u7684\u6838\u5fc3\uff0c\u57fa\u4e8esklearn\u8bb2\u89e3\u591a\u79cd\u7279\u5f81\u6784\u5efa\u65b9\u6cd5|\n| \u7528\u6237\u753b\u50cf\u5b9e\u6218    |\u7528\u6237\u753b\u50cf\u60f3\u5fc5\u5927\u5bb6\u90fd\u542c\u8fc7\u4e86\uff0c\u5982\u4f55\u5e94\u7528\u6570\u636e\u6765\u5b8c\u6210\u753b\u50cf\u5462\uff1f| \n| \u96c6\u6210\u7b56\u7565\u5b9e\u4f8b       |\u6570\u636e\u6316\u6398\u4e2d\u9009\u62e9\u901a\u5e38\u90fd\u9009\u62e9\u96c6\u6210\u7b56\u7565\u6765\u66f4\u597d\u7684\u63d0\u5347\u6548\u679c| \n| Xgboost\u5b9e\u6218    |\u96c6\u6210\u4e2d\u7684\u5178\u578b\u4ee3\u8868\uff0c\u7ade\u8d5b\u7684\u5927\u6740\u5668| \n| \u4eac\u4e1c\u8d2d\u4e70\u610f\u5411\u9884\u6d4b       |\u7ecf\u5178\u9884\u6d4b\u95ee\u9898\uff0c\u57fa\u4e8e\u7528\u6237\u5386\u53f2\u884c\u4e3a\u6570\u636e\u5b8c\u6210\u9884\u6d4b\u4efb\u52a1|\n| kaggle\u6570\u636e\u79d1\u5b66\u8c03\u67e5   |\u53ef\u89c6\u5316\u5c55\u793akaggle\u7ade\u8d5b\u4e2d\u53c2\u8d5b\u4eba\u5458\u60c5\u51b5| \n| \u623f\u4ef7\u9884\u6d4b     |\u6570\u636e\u6316\u6398\u5165\u95e8\u7ea7\u522b\u6848\u4f8b\uff0c\u5feb\u901f\u638c\u63e1\u5e38\u89c4\u5957\u8def|\n| \u7535\u529b\u654f\u611f\u7528\u6237\u5206\u6790   |\u7ade\u8d5b\u5b9e\u4f8b\uff0c\u4e3b\u8981\u8bb2\u89e3\u7279\u5f81\u5de5\u7a0b\u7684\u4f5c\u7528| \n| fbprophet\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b     |\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u975e\u5e38\u5b9e\u7528\u7684\u7b97\u6cd5\uff0c\u7528\u8d77\u6765\u975e\u5e38\u7b80\u5355|\n\u6570\u636e\u6316\u6398\u7ade\u8d5b\u4f18\u80dc\u89e3\u51b3\u65b9\u6848\n[x] \u6211\u53c8\u4e0d\u53c2\u52a0\u7ade\u8d5b\uff0c\u4e3a\u4ec0\u4e48\u8981\u770b\u4eba\u5bb6\u7684\u89e3\u51b3\u65b9\u6848\u5462\uff1f\n\u7ed9\u5927\u5bb6\u9009\u62e9\u4e86\u5929\u6c60\uff0ckaggle\uff0c\u878d\u673a\u7b49\u5927\u578b\u7ade\u8d5b\u6848\u4f8b\uff0c\u5e76\u4e14\u63d0\u4f9b\u7684\u4ee3\u7801\u548c\u65b9\u6848\u5747\u4e3a\u7ade\u8d5b\u65f6\u4f18\u80dc\u8005\u7684\u89e3\u51b3\u601d\u8def\u3002\u5c31\u597d\u6bd4\u8981\u5b66\u4e0b\u68cb\u5c31\u5f97\u8ddf\u4e0b\u7684\u6700\u597d\u7684\u73a9\u81ea\u5df1\u624d\u4f1a\u63d0\u5347\uff0c\n\u6848\u4f8b\u4e2d\u5747\u4f1a\u8bb2\u89e3\u4f18\u80dc\u8005\u7684\u601d\u8def\u548c\u6574\u4f53\u89e3\u51b3\u65b9\u6848\u5e76\u63d0\u4f9b\u4ee3\u7801\u5b9e\u73b0\u3002\u975e\u5e38\u6709\u52a9\u4e8e\u5927\u5bb6\u63d0\u5347\uff01\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| \u5feb\u624b\u77ed\u89c6\u9891\u7528\u6237\u6d3b\u8dc3\u5ea6\u5206\u6790       |\u57fa\u4e8e\u7528\u6237\u7684\u884c\u4e3a\u6570\u636e\u6765\u9884\u6d4b\u63a5\u4e0b\u6765\u7684\u6d3b\u8dc3\u7a0b\u5ea6| \n| \u5de5\u4e1a\u5316\u5de5\u751f\u4ea7\u9884\u6d4b       |\u5bf9\u5316\u5de5\u6570\u636e\u8fdb\u884c\u5206\u6790\uff0c\u5efa\u6a21\u9884\u6d4b\u751f\u4ea7\u6548\u7387|\n| \u667a\u6167\u57ce\u5e02-\u9053\u8def\u901a\u884c\u65f6\u95f4\u9884\u6d4b    |\u5f88\u63a5\u5730\u6c14\u7684\u7ade\u8d5b\uff0c\u57fa\u4e8e\u9053\u8def\u6570\u636e\u9884\u6d4b\u901a\u884c\u65f6\u95f4| \n| \u7279\u5f81\u5de5\u7a0b\u5efa\u6a21\u53ef\u89e3\u91ca\u5de5\u5177\u5305      |\u6570\u636e\u6316\u6398\u4e2d\u5f88\u96be\u7684\u4e00\u70b9\u5c31\u662f\u8fdb\u884c\u7279\u5f81\u89e3\u91ca\uff0c\u8fd9\u4e9b\u5de5\u5177\u5305\u975e\u5e38\u5b9e\u7528| \n| \u533b\u5b66\u7cd6\u5c3f\u75c5\u6570\u636e\u547d\u540d\u5b9e\u4f53\u8bc6\u522b    |\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7b97\u6cd5\u8bb2\u89e3\u4e0e\u5e94\u7528\u5b9e\u4f8b\u5206\u6790| \n| \u8d37\u6b3e\u5e73\u53f0\u98ce\u63a7\u6a21\u578b-\u7279\u5f81\u5de5\u7a0b       |\u7528\u56fe\u6a21\u578b\u6765\u6784\u5efa\u7279\u5f81\u5de5\u7a0b\uff0c\u8fd9\u5957\u601d\u8def\u5e94\u7528\u5f88\u5e7f|\n| \u65b0\u95fb\u5173\u952e\u8bcd\u62bd\u53d6\u6a21\u578b  |\u5173\u952e\u8bcd\u62bd\u53d6\u53ef\u4ee5\u8bf4\u662fNLP\u5fc5\u5907\u6280\u80fd\u4e86| \n| \u673a\u5668\u5b66\u4e60\u9879\u76ee\u5b9e\u6218\u6a21\u677f    |\u6a21\u677f\u6765\u4e86\uff0c\u4ee5\u540e\u6709\u4efb\u52a1\u53ef\u4ee5\u5957\u7528\u4e86\uff0c\u65b9\u6cd5\u90fd\u5dee\u4e0d\u591a|\n| \u7535\u529b\u654f\u611f\u7528\u6237\u5206\u6790   |\u7ade\u8d5b\u5b9e\u4f8b\uff0c\u4e3b\u8981\u8bb2\u89e3\u7279\u5f81\u5de5\u7a0b\u7684\u4f5c\u7528| \n\u6570\u636e\u5206\u6790\u5b9e\u6218\n[x] \u6570\u636e\u5206\u6790\u7684\u91cd\u70b9\u53c8\u662f\u4ec0\u4e48\u5462\uff1f\n\u6570\u636e\u6316\u6398\u4e3b\u8981\u662f\u5efa\u6a21\u6765\u8fdb\u884c\u9884\u6d4b\uff0c\u6570\u636e\u5206\u6790\u5219\u91cd\u5728\u53ef\u89c6\u5316\u5c55\u793a\uff0c\u5206\u6790\u5176\u4e2d\u5404\u9879\u6307\u6807\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u7b49\u3002\u7ed9\u5927\u5bb6\u9009\u62e9\u4e86\u4e00\u4e9b\u7ecf\u5178\u5206\u6790\u6848\u4f8b\uff0c\u5f88\u591a\u90fd\u53ef\u4ee5\u76f4\u63a5\u5f53\u4f5c\u6a21\u677f\u6765\u4f7f\u7528\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| \u6563\u70b9\u56fe\u7ed8\u5236\u6280\u5de7       |\u90fd\u8bf4\u4e86\u53ef\u89c6\u5316\u662f\u91cd\u70b9\uff0c\u753b\u56fe\u80af\u5b9a\u5fc5\u987b\u7684\u4e86| \n| \u7ebd\u7ea6\u51fa\u79df\u8f66\u8fd0\u884c\u60c5\u51b5\u5206\u6790\u5efa\u6a21       |\u7528\u4e86\u597d\u591a\u5de5\u5177\u5305\uff0c\u53ef\u4ee5\u719f\u6089\u4e0b\u5bf9\u5730\u7406\u6570\u636e\u5982\u4f55\u8fdb\u884c\u5206\u6790\u4e0e\u5c55\u793a|\n| \u57fa\u4e8e\u7edf\u8ba1\u5206\u6790\u7684\u7535\u5f71\u63a8\u8350\u4efb\u52a1    |\u7edf\u8ba1\u5206\u6790\u5e38\u7528\u65b9\u6cd5\uff0c\u8fd8\u80fd\u505a\u63a8\u8350| \n| \u6570\u636e\u5206\u6790\u4e0e\u673a\u5668\u5b66\u4e60\u6a21\u677f      |\u8fd9\u4e2a\u6a21\u677f\u771f\u7684\u975e\u5e38\u5168\u9762\u4e86\uff0c\u5206\u6790\uff0c\u5c55\u793a\uff0c\u5efa\u6a21\uff0c\u8bc4\u4f30\uff0c\u7b80\u76f4\u4e00\u5957\u9f99\u4e86| \n| \u6570\u636e\u964d\u7ef4    |\u51e0\u79cd\u5e38\u7528\u7684\u964d\u7ef4\u7b97\u6cd5\u5bf9\u6bd4\u5206\u6790\u4e0e\u5c55\u793a| \n| \u5546\u54c1\u53ef\u89c6\u5316\u5c55\u793a\u4e0e\u6587\u672c\u5904\u7406       |\u6587\u672c\u6570\u636e\u9884\u5904\u7406\u4e0e\u53ef\u89c6\u5316\u5c55\u793a|\n| \u591a\u53d8\u91cf\u5206\u6790  |\u591a\u53d8\u91cf\u5206\u6790\u4e5f\u662f\u6570\u636e\u5206\u6790\u4e2d\u5e38\u89c1\u7684\u65b9\u6cd5| \n| \u5546\u54c1\u8ba2\u5355\u6570\u636e\u96c6\u5206\u6790    |\u8ba2\u5355\u6570\u636e\u96c6\u5206\u6790|\n| KIVA\u8d37\u6b3e\u6570\u636e\u5206\u6790   |\u8d37\u6b3e\u6570\u636e\u96c6\u5206\u6790| \n\u6df1\u5ea6\u5b66\u4e60\n[x] \u7ec8\u4e8e\u8bf4\u5230\u6df1\u5ea6\u5b66\u4e60\u4e86\uff0c\u90fd\u9700\u8981\u5b66\u4ec0\u4e48\u5462\uff1f\n\u6df1\u5ea6\u5b66\u4e60\u53ef\u4ee5\u8bf4\u662f\u5f53\u4e0b\u6700\u597d\u7528\u7684\u7b97\u6cd5\u4e86\uff0c\u5404\u4e2a\u9886\u57df\u90fd\u80fd\u5403\u5f97\u5f00\u3002\u5176\u5b9e\u6700\u6838\u5fc3\u7684\u8fd8\u662f\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\uff0c\u56e0\u4e3a\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5\u66f4\u9002\u7528\u4e8e\u56fe\u50cf\u548c\u6587\u672c\u6570\u636e\u3002\n\u4e3b\u8981\u9700\u8981\u638c\u63e1\u7684\u5c31\u662f\u7b97\u6cd5\u548c\u6846\u67b6\u4e86\uff0c\u7b97\u6cd5\u5c31\u662fCNN,RNN\u8fd9\u4e9b\u7ecf\u5178\u7f51\u7edc\u6a21\u578b\uff0c\u6846\u67b6\u5c31\u662f\u5b9e\u6218\u7684\u5de5\u5177\u4e86\u4f8b\u5982tenorflow,Pytorch\u7b49\uff0c\u540e\u9762\u8fd8\u4f1a\u8be6\u7ec6\u8bf4\u3002\n[x] \u6df1\u5ea6\u5b66\u4e60\u542c\u8d77\u6765\u6bd4\u8f83\u9ad8\u5927\u4e0a\uff0c\u662f\u4e0d\u662f\u6bd4\u673a\u5668\u5b66\u4e60\u96be\u5f88\u591a\uff1f\n\u597d\u50cf\u73b0\u5728\u597d\u591a\u5c0f\u4f19\u4f34\u4e00\u62ff\u5230\u4efb\u52a1\uff0c\u7b2c\u4e00\u4e2a\u60f3\u6cd5\u90fd\u662f\u76f4\u63a5\u7528\u6df1\u5ea6\u5b66\u4e60\u505a\u3002\u5982\u679c\u6df1\u5ea6\u5b66\u4e60\u96be\u5ea6\u5927\uff0c\u505a\u8d77\u6765\u9ebb\u70e6\uff0c\u90a3\u8fd8\u80fd\u6709\u8fd9\u4e48\u9ad8\u7684\u70ed\u5ea6\u5417\uff1f\u5176\u5b9e\u6070\u6070\u76f8\u53cd\uff0c\u6211\u89c9\u5f97\u6df1\u5ea6\u5b66\u4e60\n\u771f\u7684\u6bd4\u673a\u5668\u5b66\u4e60\u7b80\u5355\u5f88\u591a\uff0c\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u9700\u8981\u6211\u4eec\u5bf9\u4e0d\u540c\u7684\u6570\u636e\u9009\u62e9\u4e0d\u540c\u7684\u9884\u5904\u7406\u65b9\u6cd5\u548c\u7279\u5f81\u5de5\u7a0b\u6784\u5efa\u65b9\u6cd5\u3002\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5957\u8def\u76f8\u5bf9\u6765\u8bf4\u66f4\u56fa\u5b9a\u4e00\u4e9b\uff0c\u800c\u4e14\u6709\u8fd9\u4e9b\u5f00\u6e90\u6846\u67b6\n\u548c\u5404\u5927\u7ecf\u5178\u7f51\u7edc\u67b6\u6784\uff0c\u6211\u4eec\u901a\u5e38\u9700\u8981\u505a\u7684\u5c31\u662f\u5957\u7528\u5c31\u53ef\u4ee5\u4e86\u3002\u6574\u4f53\u96be\u5ea6\u8981\u6bd4\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u66f4\u5bb9\u6613\u4e00\u4e9b\uff08\u53ea\u662f\u76f8\u5bf9\u6765\u8bf4\uff01\uff09\u3002\n\u6df1\u5ea6\u5b66\u4e60\u5fc5\u5907\u7b97\u6cd5\n[x] \u6df1\u5ea6\u5b66\u4e60\u90fd\u9700\u8981\u5b66\u54ea\u4e9b\u7b97\u6cd5\u5462\uff1f\n|\u7b97\u6cd5\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| \u795e\u7ecf\u7f51\u7edc       |\u795e\u7ecf\u7f51\u7edc\u662f\u6700\u57fa\u7840\u7684\uff0c\u76f8\u5f53\u4e8e\u4e3a\u540e\u9762\u7f51\u7edc\u7684\u5b66\u4e60\u6253\u4e0b\u57fa\u7840| \n| \u5377\u79ef\u795e\u7ecf\u7f51\u7edc       |\u8fd9\u4e2a\u5927\u5bb6\u542c\u8d77\u6765\u5f88\u719f\u6089\u5427\uff0c\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5927\u54e5\u5927\uff01\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u6838\u5fc3\u7f51\u7edc|\n| \u9012\u5f52\u795e\u7ecf\u7f51\u7edc    |\u5317\u4e54\u5cf0\uff0c\u5357\u6155\u5bb9\uff0c\u5b83\u5c31\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u5927\u54e5\u5927\u4e86\uff01| \n| \u5bf9\u6297\u751f\u6210\u7f51\u7edc   |\u73b0\u5728\u6bd4\u8f83\u706b\u7684\u6a21\u578b\uff0c\u73a9\u8d77\u6765\u5f88\u6709\u8da3\uff0c\u53ef\u4ee5\u8fdb\u884c\u5404\u79cd\u56fe\u50cf\u878d\u5408| \n| \u5e8f\u5217\u7f51\u7edc\u6a21\u578b   |NLP\u4e2d\u5e38\u7528\u67b6\u6784\uff0c\u673a\u5668\u5b66\u4e60\u7ffb\u8bd1\u6a21\u578b\uff0c\u5e94\u7528\u70b9\u6bd4\u8f83\u591a| \n| \u5404\u5927\u7ecf\u5178\u7f51\u7edc\u67b6\u6784    |\u521a\u624d\u8bf4\u7684CNN\u548cRNN\u90fd\u662f\u6bd4\u8f83\u57fa\u7840\u7684\u7f51\u7edc\u6a21\u578b\uff0c\u5728\u5176\u57fa\u7840\u4e0a\u8fd8\u6709\u5f88\u591a\u62d3\u5c55\u9700\u8981\u5927\u5bb6\u638c\u63e1| \n\u6df1\u5ea6\u5b66\u4e60\u5fc5\u5907\u5de5\u5177\n[x] \u4ec0\u4e48\u662f\u6846\u67b6\uff1f\u80fd\u5e2e\u6211\u4eec\u505a\u4ec0\u4e48\u5462\uff1f\n\u6846\u67b6\u597d\u6bd4\u8bf4\u4f60\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7f51\u7edc\u6a21\u578b\uff0c\u4f46\u662f\u5982\u679c\u628a\u5176\u4e2d\u5177\u4f53\u7684\u8ba1\u7b97\u8fc7\u7a0b\u5168\u90e8\u81ea\u5df1\u5b8c\u6210\u5c31\u592a\u9ebb\u70e6\u4e86\u3002\u6846\u67b6\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8ba1\u7b97\u65b9\u6cd5\u5e76\u4e14\u4e0d\u9700\u8981\u54b1\u4eec\u6765\u5b8c\u6210\uff0c\u4e00\u5957\u5168\u81ea\u52a8\u7684\u8ba1\u7b97\u3002\n\u76f8\u5f53\u4e8e\u6211\u4eec\u53ea\u9700\u8981\u8bbe\u8ba1\u597d\u7ed3\u6784\uff0c\u5177\u4f53\u7684\u65bd\u5de5\u5c31\u4ea4\u7ed9\u5b83\u4e86\u3002\u8981\u73a9\u6df1\u5ea6\u5b66\u4e60\u5fc5\u5907\u7684\u5c31\u662f\u6846\u67b6\u4e86\u3002\n[x] \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u54ea\u5bb6\u5f3a\uff1f\ntensorflow,Pytorch,keras,caffe\u7b49\uff0c\u6709\u8fd9\u4e48\u591a\u6846\u67b6\uff0c\u6211\u8be5\u9009\u54ea\u4e00\u4e2a\u5462\uff1f\u662f\u4e0d\u662f\u4e0d\u540c\u6846\u67b6\u5dee\u5f02\u5f88\u5927\u5462\uff1f\n\u73b0\u5728\u6700\u4e3b\u6d41\u7684\u5c31\u662ftensorflow\u548cPyTorch\u4e86\uff0c\u76f8\u5f53\u4e8e\u80af\u5fb7\u57fa\u548c\u9ea6\u5f53\u52b3\u5427\u3002\u90fd\u5f88\u5f3a\uff0c\u81f3\u4e8e\u5177\u4f53\u9009\u62e9\u54ea\u4e00\u4e2a\u8fd8\u662f\u53c2\u8003\u5927\u5bb6\u5404\u81ea\u7684\u9879\u76ee\u7ec4\u548c\u4efb\u52a1\u9700\u6c42\u5427\u3002\u5982\u679c\u975e\u8981\u6211\u63a8\u8350\u4e00\u4e2a\n\u6211\u4f1a\u7ed9\u5927\u5bb6\u63a8\u8350PyTorch\uff0c\u56e0\u4e3a\u66f4\u7b80\u6d01\u901a\u4fd7\u3002\u8fd9\u4e9b\u6846\u67b6\u6211\u5168\u90fd\u7528\u8fc7\uff0c\u6700\u4e3b\u8981\u7684\u539f\u56e0\u5c31\u662f\u5de5\u4f5c\u4e2d\u7ecf\u5e38\u9700\u8981\u53c2\u8003\u8bba\u6587\u548c\u5f00\u6e90\u9879\u76ee\uff0c\u4e00\u822c\u522b\u4eba\u8bba\u6587\u4e2d\u6e90\u7801\u7528\u4ec0\u4e48\u6846\u67b6\u6211\u4e5f\u5c31\u63a5\u7740\u8fdb\u884c\n\u4e8c\u6b21\u5f00\u53d1\u4e86\uff0c\u6240\u4ee5\u8fd9\u4e9b\u6846\u67b6\u65e9\u665a\u5927\u5bb6\u90fd\u4f1a\u7528\u4e00\u904d\u7684\uff01\n[x] \u6846\u67b6\u8be5\u600e\u4e48\u5b66\u5462\uff1f\n\u6846\u67b6\u6ca1\u6709\u4ec0\u4e48\u7406\u8bba\u53ef\u8c08\uff0c\u4e5f\u4e0d\u7528\u770b\u5404\u79cd\u957f\u7bc7\u5927\u8bba\uff0c\u76f4\u63a5\u7528\u5c31\u5f97\u4e86\uff01\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u5de5\u5177\u5305\uff0c\u8fb9\u7528\u8fb9\u5b66\uff0c\u6848\u4f8b\u5f53\u6a21\u677f\u6765\u603b\u7ed3\u5c31\u53ef\u4ee5\u4e86\uff01\n[x] \u9488\u5bf9\u4e0d\u540c\u6846\u67b6\uff0c\u5206\u522b\u7ed9\u5927\u5bb6\u51c6\u5907\u4e86\u4e30\u5bcc\u7684\u5b9e\u6218\u9879\u76ee\u548c\u5b66\u4e60\u5185\u5bb9\u3002\n|\u6846\u67b6\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| Caffe\u6846\u67b6       |\u8fdc\u53e4\u65f6\u4ee3\u7684\u795e\u7ea7\u6846\u67b6\uff0c\u73b0\u5728\u6709\u70b9\u8dcc\u843d\u795e\u575b\u4e86\uff0c\u6211\u5b66\u4e60\u7684\u7b2c\u4e00\u4e2a\u6846\u67b6| \n| Tensorflow2\u7248\u672c       |2\u7248\u672c\u505a\u4e86\u5f88\u591a\u6539\u8fdb\uff0c\u7ec8\u4e8e\u66f4\u4eba\u6027\u5316\u4e86\uff0c\u7528\u8d77\u6765\u6bd41\u7248\u672c\u8212\u670d\u591a\u4e86|\n| Keras   |\u4e00\u53e5\u8bdd\u6982\u8ff0\u5c31\u662f\u7b80\u5355\uff01\u7b80\u5355\uff01\u7b80\u5355\uff01\u90fd\u4e0d\u7528\u5b66\uff0c\u770b\u4ee3\u7801\u975e\u5e38\u5bb9\u6613\u7406\u89e3| \n| PyTorch   |\u73b0\u9636\u6bb5\u6700\u706b\u7684\u6846\u67b6\uff0c\u6211\u4f30\u8ba1\u4e5f\u662f\u4eca\u5e74\uff082020\uff09\u6700\u6d41\u884c\u7684\u6846\u67b6\u4e86\uff0c\u63a8\u8350\uff01| \n\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\n\u9488\u5bf9\u5404\u5927\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5747\u7ed9\u5927\u5bb6\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u5b9e\u6218\u6848\u4f8b\uff0c\u7528\u54ea\u4e2a\u5c31\u770b\u5927\u5bb6\u7684\u559c\u597d\u4e86\uff01\n\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Tensorflow2\n[x] \u8bf7\u7ed9\u6211\u4e00\u4e2a\u5b66tensorflow2\u7684\u7406\u7531!\n\u8c37\u6b4c\u51fa\u54c1\u6211\u5c31\u4e0d\u7528\u591a\u89e3\u91ca\u4e86\uff0c\u4eba\u5bb6\u8c37\u6b4c\u90a3\u4e48\u591a\u5f00\u6e90\u9879\u76ee\u80af\u5b9a\u90fd\u662f\u57fa\u4e8eTF\u6846\u67b6\u7684\uff0c\u8981\u5b66\u4e60\u6216\u8005\u53c2\u8003\u4eba\u5bb6\u5f00\u6e90\u9879\u76ee\u548c\u8bba\u6587\u80af\u5b9a\u8981\u5b66TF\u7684\uff0c\u5de5\u4e1a\u754c\u5e94\u7528\u4e5f\u975e\u5e38\u5e7f\u6cdb\u3002\u8fd9\u6ce2\u80af\u5b9a\u4e0d\u4e8f\uff01\n[x] \u7ed9\u5927\u5bb6\u51c6\u5907\u7684\u6848\u4f8b\u5185\u5bb9\uff0c\u501f\u7528\u7a0b\u54ac\u91d1\u7684\u914d\u97f3\uff1a\u4e00\u4e2a\u5b57\uff0c\u5e72!\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| tensorflow\u5b89\u88c5\u4e0e\u7b80\u4ecb       |2\u7248\u672c\u7684\u4ecb\u7ecd\u4e8e\u5b89\u88c5\u65b9\u6cd5\uff0c\u7b80\u5355\u8fc7\u4e00\u4e0b\u5c31\u597d| \n| \u795e\u7ecf\u7f51\u7edc\u539f\u7406\u89e3\u8bfb\u4e0e\u6574\u4f53\u67b6\u6784       |\u590d\u4e60\u4e0b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784|\n| \u642d\u5efa\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u5206\u7c7b\u4e0e\u56de\u5f52\u4efb\u52a1    |\u7528TF\u5b8c\u6210\u57fa\u672c\u7684\u5206\u7c7b\u4e8e\u56de\u5f52\u4efb\u52a1\uff0c\u638c\u63e1\u5176\u5e94\u7528\u65b9\u6cd5| \n| \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u539f\u7406\u4e0e\u53c2\u6570\u89e3\u8bfb     |CNN\u7684\u67b6\u6784\u4e8e\u5176\u4e2d\u6bcf\u4e00\u4e2a\u53c2\u6570\u8be6\u89e3| \n| \u732b\u72d7\u8bc6\u522b\u5b9e\u6218    |\u7ecf\u5178\u7684\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\uff0c\u8fd9\u91cc\u8981\u8bb2\u5f88\u591a\u5185\u5bb9\uff0c\u975e\u5e38\u91cd\u8981| \n| \u56fe\u50cf\u6570\u636e\u589e\u5f3a\u5b9e\u4f8b       |\u6570\u636e\u589e\u5f3a\u53ef\u4ee5\u8bf4\u4e86\u73b0\u5728\u5fc5\u5907\u6280\u80fd\u4e86|\n| \u8bad\u7ec3\u7b56\u7565-\u8fc1\u79fb\u5b66\u4e60\u5b9e\u6218  |\u8fc1\u79fb\u5b66\u4e60\u5e26\u6765\u7684\u6548\u679c\u8fd8\u662f\u76f8\u5f53\u53ef\u4ee5\u7684| \n| \u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u4e0e\u8bcd\u5411\u91cf\u539f\u7406\u89e3\u8bfb    |RNN\u6a21\u578b\u89e3\u8bfb|\n| \u57fa\u4e8eTensorFlow\u5b9e\u73b0word2vec   |\u8bcd\u5411\u91cf\u6a21\u578b\u89e3\u8bfb\uff0c\u5e76\u57fa\u4e8eTF\u6765\u5b9e\u73b0| \n| \u57fa\u4e8eRNN\u6a21\u578b\u8fdb\u884c\u6587\u672c\u5206\u7c7b\u4efb\u52a1  |\u57fa\u4e8eTF\u5b8c\u6210\u6587\u672c\u5206\u7c7b\u4efb\u52a1| \n| tfrecord\u5236\u4f5c\u6570\u636e\u6e90    |\u6570\u636e\u6e90\u5236\u4f5c\u5b9e\u4f8b|\n| \u5c06CNN\u7f51\u7edc\u5e94\u7528\u4e8e\u6587\u672c\u5206\u7c7b\u5b9e\u6218   |CNN\u4e5f\u80fd\u73a9\u6587\u672c\u5206\u7c7b| \n| \u65f6\u95f4\u5e8f\u5217\u9884\u6d4b    |\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5904\u7406\u4e0e\u5efa\u6a21\u5b9e\u4f8b|\n| \u5bf9\u6297\u751f\u6210\u7f51\u7edc\u5b9e\u6218   |GAN\u6765\u5566\uff0c\u8fd9\u4e2a\u53ef\u597d\u73a9\u4e86| \n| \u57fa\u4e8eCycleGan\u5f00\u6e90\u9879\u76ee\u5b9e\u6218\u56fe\u50cf\u878d\u5408  |\u6211\u6700\u559c\u6b22\u73a9\u7684GAN\uff0c\u6548\u679c\u76f8\u5f53\u9017\u4e86\uff01| \n| \u7ecf\u5178\u7f51\u7edc\u67b6\u6784Resnet\u5b9e\u6218    |\u5fc5\u987b\u61c2\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u5b66\u5c31\u5f97\u4e86\uff01|\n\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Pytorch\n[x] \u542c\u8bf4\u5b83\u5f88\u706b\uff0c\u4e3a\u5565\u5462\uff1f\n19\u5e74\u5e95Pytorch\u6846\u67b6\u4f7f\u7528\u4eba\u6570\u5df2\u7ecf\u8d85\u8d8atensorflow\u6210\u4e3a\u5f53\u4e0b\u6700\u706b\u7684\u6846\u67b6\uff0c\u539f\u56e0\u5176\u5b9e\u5f88\u7b80\u5355\uff0c\u5927\u5bb6\u90fd\u559c\u6b22\u7528\u66f4\u7b80\u5355\u6613\u61c2\u7684\u6846\u67b6\u3002\u6574\u4f53\u7684\u611f\u89c9\u786e\u5b9e\u6bd4tensorflow\u597d\u4e0a\u624b\u800c\u4e14\n\u8c03\u8bd5\u8d77\u6765\u5341\u5206\u65b9\u4fbf\uff0c\u4e5f\u662f\u5efa\u8bae\u521d\u5b66\u7684\u540c\u5b66\u4eec\u4f18\u5148\u9009\u62e9Pytorch\u6846\u67b6\u3002\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| PyTorch\u6846\u67b6\u57fa\u672c\u5904\u7406\u64cd\u4f5c       |PyTorch\u7b80\u5355\u719f\u6089\u4e00\u4e0b\u5c31\u597d\uff0c\u4e0a\u624b\u975e\u5e38\u7b80\u5355| \n| \u795e\u7ecf\u7f51\u7edc\u5b9e\u6218\u5206\u7c7b\u4e0e\u56de\u5f52\u4efb\u52a1      |\u7528PyTorch\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u786e\u5b9e\u6bd4TF\u7528\u7684\u987a\u624b|\n| \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u539f\u7406\u4e0e\u53c2\u6570\u89e3\u8bfb    |CNN\u6a21\u578b\u67b6\u6784\u4e0e\u53c2\u6570\u4e66\u89e3\u8bfb| \n| \u56fe\u50cf\u8bc6\u522b\u6838\u5fc3\u6a21\u5757\u5b9e\u6218\u89e3\u8bfb    |\u975e\u5e38\u91cd\u8981\uff0cPyTorch\u4e2d\u7684\u56fe\u50cf\u5904\u7406\u6838\u5fc3\u6a21\u5757| \n| \u8fc1\u79fb\u5b66\u4e60\u7684\u4f5c\u7528\u4e0e\u5e94\u7528\u5b9e\u4f8b  |PyTorch\u4e2d\u52a0\u8f7d\u6a21\u578b\u6765\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60| \n| \u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u4e0e\u8bcd\u5411\u91cf\u539f\u7406\u89e3\u8bfb       |RNN\u6a21\u578b\u67b6\u6784\u89e3\u8bfb|\n| \u65b0\u95fb\u6570\u636e\u96c6\u6587\u672c\u5206\u7c7b\u5b9e\u6218 |\u57fa\u4e8ePyTorch\u6765\u6784\u5efa\u6587\u672c\u5206\u7c7b\u6a21\u578b| \n| \u5bf9\u6297\u751f\u6210\u7f51\u7edc\u67b6\u6784\u539f\u7406\u4e0e\u5b9e\u6218\u89e3\u6790    |GAN\u6a21\u578b\u901a\u4fd7\u89e3\u8bfb|\n| \u57fa\u4e8eCycleGan\u5f00\u6e90\u9879\u76ee\u5b9e\u6218\u56fe\u50cf\u878d\u5408   |PyTorch\u7248\u672c\u7684CYCLEGAN\uff0c\u8fd9\u4e2a\u5f00\u6e90\u9879\u76ee\u5199\u7684\u76f8\u5f53\u68d2| \n| OCR\u6587\u5b57\u8bc6\u522b\u539f\u7406  |OCR\u5176\u5b9e\u539f\u7406\u5f88\u7b80\u5355\uff0c\u9700\u8981\u591a\u4e2a\u6a21\u578b\u534f\u52a9\u5b8c\u6210| \n| OCR\u6587\u5b57\u8bc6\u522b\u9879\u76ee\u5b9e\u6218    |\u6784\u5efaOCR\u7f51\u7edc\u6a21\u578b|\n| \u57fa\u4e8e3D\u5377\u79ef\u7684\u89c6\u9891\u5206\u6790\u4e0e\u52a8\u4f5c\u8bc6\u522b   |\u75283D\u5377\u79ef\u6765\u5904\u7406\u89c6\u9891\u6570\u636e\u5e76\u5b8c\u6210\u884c\u4e3a\u8bc6\u522b| \n| \u57fa\u4e8ePyTorch\u5b9e\u6218BERT\u6a21\u578b    |BERT\u8fd9\u4e2a\u67b6\u6784\u592a\u706b\u4e86\uff0c\u5fc5\u5907\u6a21\u578b\u4e4b\u4e00|\n| PyTorch\u6846\u67b6\u5b9e\u6218\u6a21\u677f\u89e3\u8bfb   |\u63d0\u4f9b\u4e00\u4e2a\u6a21\u677f\uff0c\u4ee5\u540e\u6709\u4efb\u52a1\u53ef\u4ee5\u57fa\u4e8e\u6a21\u677f\u6765\u8fdb\u884c\u6539\u8fdb| \n\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Keras\n[x] Keras\u90fd\u8bf4\u7b80\u5355\uff0c\u6709\u591a\u7b80\u5355\u5462\uff1f\n\u6574\u4f53\u611f\u89c9\u5c31\u662f\u5565\u90fd\u4e0d\u7528\u5b66\uff0c\u4ece\u6848\u4f8b\u5f00\u59cb\u76f4\u63a5\u7528\u5c31\u597d\u4e86\uff0cTF2\u7248\u672c\u5176\u5b9e\u8ddfkeras\u5f88\u50cf\u3002\u9002\u5408\u505a\u5b9e\u9a8c\u5199\u8bba\u6587\uff0c\u7b80\u5355\u5feb\u901f\uff01\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| \u5b89\u88c5\u4e0e\u7b80\u4ecb      |keras\u5b89\u88c5\u4e0e\u4e0a\u624b\u5f88\u5bb9\u6613\uff0c\u57fa\u4e8etf\u6765\u8fdb\u884c| \n| \u642d\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b      |\u642d\u5efa\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6765\u8bd5\u8bd5\u6c34|\n| \u518d\u6218\u5377\u79ef\u795e\u7ecf\u7f51\u7edc    |CNN\u6a21\u578b\u6784\u5efa\u8d77\u6765\u4e5f\u975e\u5e38\u5bb9\u6613| \n| LSTM\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1    |LSTM\u6a21\u578b\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1| \n| \u6587\u672c\u5206\u7c7b\u5b9e\u6218  |\u6587\u672c\u5206\u7c7b\u5b9e\u4f8b| \n| \u591a\u6807\u7b7e\u4e0e\u591a\u8f93\u51fa       |\u591a\u6807\u7b7e\u4efb\u52a1\u5f88\u5e38\u89c1\uff0c\u5f88\u6709\u5b66\u4e60\u4ef7\u503c|\n| \u65b0\u95fb\u6570\u636e\u96c6\u6587\u672c\u5206\u7c7b\u5b9e\u6218 |\u57fa\u4e8ekeras\u7684\u6587\u672c\u5206\u7c7b\u4efb\u52a1| \n| \u6570\u636e\u589e\u5f3a    |\u6570\u636e\u589e\u5f3a\u5b9e\u4f8b\u89e3\u8bfb|\n| \u5bf9\u6297\u751f\u6210\u7f51\u7edc   |GAN\u67b6\u6784\uff0c\u7528keras\u6765\u505a\u66f4\u7b80\u5355| \n| \u8fc1\u79fb\u5b66\u4e60\u4e0eResnet\u6b8b\u5dee\u7f51\u7edc  |resnet\u6a21\u578b\u5927\u5bb6\u4e00\u5b9a\u81ea\u5df1\u52a8\u624b\u73a9\u4e00\u904d| \n| \u5730\u5740\u90ae\u7f16\u591a\u5e8f\u5217\u4efb\u52a1   |\u6587\u672c\u6a21\u578b\u5b9e\u4f8b|\n| seq2seq\u7f51\u7edc\u5b9e\u6218   |\u5e8f\u5217\u7f51\u7edc\u6a21\u578b\u5e94\u7528\u8fd8\u662f\u6bd4\u8f83\u5e7f\u7684| \n| \u5b9e\u6218\u6a21\u677f\u603b\u7ed3    |\u7ed9\u5927\u5bb6\u63d0\u4f9b\u7684keras\u6a21\u677f\uff0c\u518d\u6709\u4efb\u52a1\u76f4\u63a5\u5199\u5c31\u597d|\n\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Caffe\n[x] Caffe\u6846\u67b6\u73b0\u9636\u6bb5\u8fd8\u6709\u5fc5\u8981\u5b66\u4e60\u5417\uff1f\n\u6211\u89c9\u5f97\u73b0\u9636\u6bb5\u5df2\u7ecf\u6709tensorflow\u548cpytorch\u4e86\uff0c\u6682\u65f6\u8f6e\u4e0d\u5230caffe\u767b\u573a\u4e86\uff0c\u521d\u5b66\u7684\u540c\u5b66\u4eec\u5c31\u4e0d\u63a8\u8350\u4e86\u3002\u53ef\u80fd\u6709\u4e9b\u8bba\u6587\u548c\u4efb\u52a1\u8fd8\u662f\u9700\u8981caffe\u6846\u67b6\uff0c\u9700\u8981\u7684\u540c\u5b66\u4eec\u81ea\u53d6\u5c31\u597d\u5566\uff01\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| Caffe\u914d\u7f6e\u6587\u4ef6\u89e3\u8bfb      |Caffe\u6846\u67b6\u5e38\u7528\u914d\u7f6e\u6587\u4ef6\u89e3\u8bfb| \n| \u591a\u79cd\u6570\u636e\u96c6\u6784\u5efa\u65b9\u6cd5    |\u6570\u636e\u96c6\u6784\u5efa\u65b9\u6cd5\uff0c\u8fd9\u4e2a\u5f88\u91cd\u8981|\n| Caffe\u5e38\u7528\u5de5\u5177\u89e3\u8bfb  |\u91cc\u9762\u5185\u7f6e\u4e86\u5f88\u591a\u5c0f\u5de5\u5177\uff0c\u53ef\u4ee5\u5feb\u901f\u5b8c\u6210\u4efb\u52a1| \n| \u4eba\u8138\u68c0\u6d4b\u5b9e\u6218    |\u57fa\u4e8eCaffe\u6846\u67b6\u6784\u5efa\u4eba\u8138\u68c0\u6d4b\u6a21\u578b| \n| \u4eba\u8138\u5173\u952e\u70b9\u5b9a\u4f4d\u5b9e\u6218  |\u57fa\u4e8eCaffe\u6846\u67b6\u5b8c\u6210\u4eba\u8138\u5173\u952e\u70b9\u8bc6\u522b\u6a21\u578b| \n\u8ba1\u7b97\u673a\u89c6\u89c9\n[x] \u8ba1\u7b97\u673a\u89c6\u89c9\u53d1\u5c55\u8fd9\u4e48\u706b\uff0c\u5c31\u4e1a\u9762\u8bd5\u90fd\u9700\u8981\u54ea\u4e9b\u6838\u5fc3\u6280\u80fd\u5462\uff1f\n\u8ba1\u7b97\u673a\u89c6\u89c9\u8fd9\u4e2a\u884c\u4e1a\u6211\u5c31\u4e0d\u7528\u591a\u8bf4\u5566\uff0c\u5f53\u4e0b\u6700\u5403\u9999\u7684\u4e86\u3002\u90a3\u90fd\u9700\u8981\u5b66\u4ec0\u4e48\u5462\uff1f\u6700\u6838\u5fc3\u7684\u5176\u5b9e\u5c31\u4e24\u90e8\u5206\uff0c\u4e00\u4e2a\u662f\u56fe\u50cf\u5904\u7406\uff0c\u53e6\u4e00\u4e2a\u662f\u56fe\u50cf\u5efa\u6a21\u3002\u6240\u8c13\u7684\u56fe\u50cf\u5904\u7406\u5c31\u662fOpencv\n\u90a3\u4e00\u5957\u5566\uff0c\u8fd9\u4e2a\u5de5\u5177\u5305\u7b80\u76f4\u65e0\u654c\u4e86\uff0c\u4f46\u51e1\u4f60\u8981\u7528\u7684\u8fd9\u91cc\u5168\u80fd\u627e\u5230\u3002\u56fe\u50cf\u5efa\u6a21\u4e3b\u8981\u5c31\u662f\u7528\u6df1\u5ea6\u5b66\u4e60\u6765\u5b8c\u6210\u68c0\u6d4b\uff0c\u8bc6\u522b\u7b49\u4efb\u52a1\u3002\u73b0\u9636\u6bb5\u7684\u5b66\u4e60\u6211\u89c9\u5f97\u5173\u4e8e\u4f20\u7edf\u56fe\u50cf\u5904\u7406\u7b97\u6cd5\u53ef\u4ee5\n\u90fd\u4e0d\u7528\u53bb\u770b\u5566\uff0c\u7b80\u5355\u719f\u6089\u4e00\u4e0b\u5c31\u597d\uff0c\u4e3b\u6d41\u7684\u65b9\u5411\u8fd8\u662f\u7528\u6df1\u5ea6\u5b66\u4e60\u6765\u505a\uff0c\u8fd9\u5c31\u9700\u8981\u5927\u5bb6\u591a\u591a\u6700\u65b0\u7684\u9605\u8bfb\u8bba\u6587\u4e86\u3002\nOpencv\u56fe\u50cf\u5904\u7406\u5b9e\u6218\n[x] \u5173\u4e8eopencv\u6211\u8be5\u600e\u4e48\u5b66\u5462\uff1f\n\u5efa\u8bae\u5927\u5bb6\u9009\u62e9Python\u7248\u672c\u6765\u8fdb\u884c\u5b66\u4e60\u548c\u4f7f\u7528\uff0c\u8ddf\u5176\u4ed6\u5de5\u5177\u5305\u4e00\u6837\uff0c\u8c03\u5c31\u5b8c\u4e8b\u4e86\uff01\u9047\u5230\u4e0d\u719f\u6089\u7684\u591a\u67e5API\uff0c\u8fb9\u7528\u8fb9\u5b66\u662f\u6700\u5feb\u7684\u9014\u5f84\u3002Opencv\u4e2d\u57fa\u672c\u6240\u6709\u51fd\u6570\u90fd\u6d89\u53ca\u975e\u5e38\u591a\u7684\n\u6570\u5b66\u516c\u5f0f\uff0c\u8fd9\u4e9b\u5927\u5bb6\u90fd\u53ef\u4ee5\u5148\u653e\u4e00\u653e\uff0c\u5982\u679c\u628a\u6bcf\u4e2a\u7b97\u6cd5\u6bcf\u4e2a\u516c\u5f0f\u90fd\u5b66\u4e00\u904d\u90a3\u5f97\u7334\u5e74\u9a6c\u6708\u4e86\uff0c\u4ee5\u540e\u7528\u5230\u4e86\u518d\u8bf4\u5b8c\u5168\u6765\u5f97\u53ca\u3002\n[x] \u8fd9\u4e9b\u6848\u4f8b\u6211\u9700\u8981\u81ea\u5df1\u52a8\u624b\u5199\u4e00\u904d\u5417\uff1f\n\u7ed9\u5927\u5bb6\u51c6\u5907\u4e86\u975e\u5e38\u591a\u7684\u5b66\u4e60\u8d44\u6e90\u548c\u6848\u4f8b\uff0c\u524d\u671f\u53ea\u9700\u8981\u719f\u6089\u5373\u53ef\uff0c\u5de5\u5177\u5305\u5c31\u662f\u7528\u7684\uff0c\u9762\u5411\u590d\u5236\u7c98\u8d34\u7f16\u7a0b\u4e5f\u662f\u4e00\u9879\u6280\u80fd\uff01\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| Opencv\u7b80\u4ecb\u4e0e\u73af\u5883\u914d\u7f6e      |\u73af\u5883\u5b89\u88c5\u4e0e\u914d\u7f6e| \n| \u56fe\u50cf\u57fa\u672c\u64cd\u4f5c      |\u7528opencv\u5b8c\u6210\u57fa\u672c\u7684\u56fe\u50cf\u5904\u7406\u64cd\u4f5c\uff0c\u7ec3\u624b!|\n| \u9608\u503c\u4e0e\u5e73\u6ed1\u5904\u7406    |\u6700\u5e38\u7528\u7684\u5904\u7406\u64cd\u4f5c\uff0c\u51e0\u884c\u4ee3\u7801\u5c31\u80fd\u641e\u5b9a| \n| \u56fe\u50cf\u5f62\u6001\u5b66\u64cd\u4f5c    |\u8fd9\u51e0\u4e2a\u5f62\u6001\u5b66\u64cd\u4f5c\u719f\u6089\u4e0b\u5373\u53ef| \n| \u56fe\u50cf\u68af\u5ea6\u8ba1\u7b97  |\u56fe\u50cf\u68af\u5ea6\u8ba1\u7b97\u5b9e\u4f8b| \n| \u8fb9\u7f18\u68c0\u6d4b       |\u8fb9\u7f18\u68c0\u6d4b\u7684\u5e94\u7528\u9762\u975e\u5e38\u5e7f|\n| \u56fe\u50cf\u91d1\u5b57\u5854\u4e0e\u8f6e\u5ed3\u68c0\u6d4b |\u8f6e\u5ed3\u68c0\u6d4b\u5b9e\u4f8b\uff0c\u6548\u679c\u8fd8\u662f\u4e0d\u9519\u7684| \n| \u76f4\u65b9\u56fe\u4e0e\u5085\u91cc\u53f6\u53d8\u6362    |\u719f\u6089\u4e0b\u5373\u53ef|\n| \u9879\u76ee\u5b9e\u6218-\u4fe1\u7528\u5361\u6570\u5b57\u8bc6\u522b   |\u52a8\u624b\u505a\u4e00\u4e2a\u5b9e\u6218\u9879\u76ee\uff0c\u5bf9\u4fe1\u7528\u5361\u6570\u5b57\u8fdb\u884c\u68c0\u6d4b\u4e0e\u8bc6\u522b| \n| \u9879\u76ee\u5b9e\u6218-\u6587\u6863\u626b\u63cfOCR\u8bc6\u522b  |\u626b\u63cf\u6587\u6863\u6570\u636e\uff0c\u8fdb\u884cocr\u8bc6\u522b| \n| \u56fe\u50cf\u7279\u5f81-harris   |\u5e38\u7528\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff0c\u7b97\u6cd5\u7b80\u5355\u719f\u6089\u5c31\u53ef\u4ee5|\n| \u56fe\u50cf\u7279\u5f81-sift   |\u6700\u8001\u724c\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u4e86\uff0c\u6570\u5b66\u8fd8\u662f\u86ee\u591a\u7684| \n| \u6848\u4f8b\u5b9e\u6218-\u5168\u666f\u56fe\u50cf\u62fc\u63a5   |\u5168\u666f\u6444\u50cf\u5927\u5bb6\u80af\u5b9a\u90fd\u73a9\u8fc7\uff0c\u600e\u4e48\u5b9e\u73b0\u7684\u5462\uff1f|\n| \u9879\u76ee\u5b9e\u6218-\u505c\u8f66\u573a\u8f66\u4f4d\u8bc6\u522b     |\u91cd\u578b\u9879\u76ee\uff0c\u4ece\u96f6\u5f00\u59cb\u6784\u5efa\u505c\u8f66\u573a\u8f66\u4f4d\u8bc6\u522b\u6a21\u578b| \n| \u9879\u76ee\u5b9e\u6218-\u7b54\u9898\u5361\u8bc6\u522b\u5224\u5377     |\u54b1\u4eec\u4e5f\u6574\u4e00\u4e2a\u81ea\u52a8\u9605\u5377\u7684\u73a9\u73a9|\n| \u80cc\u666f\u5efa\u6a21  |\u5e38\u89c4\u5904\u7406\u65b9\u6cd5| \n| \u5149\u6d41\u4f30\u8ba1    |\u7b80\u5355\u719f\u6089\u5373\u53ef| \n| Opencv\u7684DNN\u6a21\u5757  |\u52a0\u8f7d\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u8bc6\u522b| \n| \u9879\u76ee\u5b9e\u6218-\u76ee\u6807\u8ffd\u8e2a       |\u8ffd\u8e2a\u7684\u6548\u679c\u8fd8\u662f\u86ee\u6709\u610f\u601d\u7684|\n| \u5377\u79ef\u539f\u7406\u4e0e\u64cd\u4f5c |\u5377\u79ef\u5230\u54ea\u90fd\u662f\u6838\u5fc3| \n| \u9879\u76ee\u5b9e\u6218-\u75b2\u52b3\u68c0\u6d4b |\u57fa\u4e8e\u6444\u50cf\u5934\u68c0\u6d4b\u75b2\u52b3|\n\u8ba1\u7b97\u673a\u89c6\u89c9\u5b9e\u6218\u9879\u76ee\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff09\n[x] \u8fd9\u4e9b\u9879\u76ee\u6211\u90fd\u9700\u8981\u638c\u63e1\u5417\uff1f\n\u5bf9\u4e8e\u51c6\u5907\u9762\u8bd5\u5c31\u4e1a\u7684\u540c\u5b66\u4eec\u5efa\u8bae\u90fd\u8fc7\u4e00\u904d\uff0c\u91cc\u9762\u7684\u601d\u60f3\u90fd\u662f\u86ee\u597d\u7684\uff0c\u5927\u90e8\u5206\u90fd\u662f\u57fa\u4e8e\u8bba\u6587\u6765\u8fdb\u884c\u590d\u73b0\uff0c\u6709\u65f6\u95f4\u7684\u540c\u5b66\u6700\u597d\n\u5148\u9605\u8bfb\u4e00\u904d\u8bba\u6587\u518d\u5f00\u59cb\u7814\u7a76\u4ee3\u7801\uff0c\u91cc\u9762\u7684\u4ee3\u7801\u91cf\u90fd\u4f1a\u76f8\u5bf9\u8f83\u5927\uff0c\u5efa\u8bae\u4ecedebug\u6a21\u5f0f\u5165\u624b\uff0c\u4e00\u884c\u4ee3\u7801\u4e00\u884c\u4ee3\u7801\u6765\u770b\uff0c\u6211\u5728\n\u8bb2\u89e3\u8fc7\u7a0b\u4e2d\u4e5f\u4f1a\u8fdb\u5165debug\u6a21\u5f0f\u7ed9\u5927\u5bb6\u9010\u884c\u8fdb\u884c\u8bb2\u89e3\u3002\n[x] \u6709\u6ca1\u6709\u54ea\u4e2a\u662f\u9700\u8981\u91cd\u70b9\u5b66\u4e60\u7684\uff1f\u6700\u597d\u80fd\u5199\u5728\u7b80\u5386\u91cc\u9762\u5462\uff1f\n\u91cd\u70b9\u63a8\u8350Mask-rcnn\u5b9e\u6218\u9879\u76ee\uff0c\u53ef\u4ee5\u8bf4\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u901a\u7528\u9879\u76ee\uff0c\u68c0\u6d4b\uff0c\u8bc6\u522b\uff0c\u5206\u5272\u4e00\u6b65\u5168\u5230\u4f4d\u4e86\uff01\u5e94\u7528\u573a\u666f\u975e\u5e38\n\u5e7f\uff0c\u4e5f\u9002\u5408\u8fdb\u884c\u4e8c\u6b21\u5f00\u53d1\u548c\u6539\u8fdb\uff0c\u5982\u679c\u8981\u5199\u5728\u7b80\u5386\u91cc\u80af\u5b9a\u975e\u5b83\u83ab\u5c5e\u4e86\uff0c\u7b97\u6cd5\u539f\u7406\u548c\u6e90\u7801\u90fd\u9700\u8981\u5927\u5bb6\u719f\u6089\uff0c\u5728\u8bfe\u7a0b\u4e2d\n\u6211\u4f1a\u91cd\u70b9\u8bb2\u89e3\u8be5\u9879\u76ee\uff0c\u5e76\u5e94\u7528\u5230\u81ea\u5df1\u7684\u6570\u636e\u4efb\u52a1\u4e2d\uff01\n|\u9879\u76ee\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| \u56fe\u50cf\u98ce\u683c\u8f6c\u6362\uff08style-transfer\uff09      |\u4e3b\u8981\u6765\u5b66\u4e60\u5176\u601d\u60f3\uff0c\u6548\u679c\u8fd8\u662f\u5f88\u6709\u610f\u601d\u7684| \n| \u56fe\u50cf\u7f3a\u5931\u81ea\u52a8\u8865\u5168      |GAN\u7f51\u7edc\u5e94\u7528\u573a\u666f\u975e\u5e38\u591a\uff0c\u56fe\u50cf\u4e5f\u80fd\u81ea\u5df1\u4fee\u590d|\n| \u8d85\u5206\u8fa8\u7387\u91cd\u6784    |\u8fd1\u51e0\u5e74\u7814\u7a76\u7684\u91cd\u70b9\u9886\u57df\u4e4b\u4e00\uff0c\u8fd9\u7bc7\u8bba\u6587\u7684\u6548\u679c\u5df2\u7ecf\u975e\u5e38\u4e0d\u9519\u4e86| \n| \u7269\u4f53\u68c0\u6d4b\u6846\u67b6-MaskRcnn\u9879\u76ee    |\u8fd9\u4e2a\u5c31\u662f\u6211\u91cd\u70b9\u5f3a\u8c03\u7684\u5f00\u6e90\u9879\u76ee\uff0c\u5fc5\u770b\uff01\u5fc5\u770b\uff01\u5fc5\u770b\uff01| \n| MaskRcnn\u7f51\u7edc\u6846\u67b6\u6e90\u7801\u8be6\u89e3  |\u6e90\u7801\u975e\u5e38\u91cd\u8981\uff0c\u6bcf\u4e00\u884c\u90fd\u9700\u8981\u61c2\uff01| \n| \u57fa\u4e8eMASK-RCNN\u6846\u67b6\u8bad\u7ec3\u81ea\u5df1\u7684\u6570\u636e       |\u5982\u4f55\u6807\u6ce8\u56fe\u50cf\u6570\u636e\u5e76\u8fdb\u884c\u8bad\u7ec3\u5462\uff1f\u8fd9\u91cc\u7ed9\u4f60\u7b54\u6848|\n| \u4eba\u4f53\u59ff\u6001\u8bc6\u522bdemo |MaskRcnn\u5e94\u7528\u573a\u666f\u975e\u5e38\u591a| \n| \u7269\u4f53\u68c0\u6d4bFasterRcnn\u7cfb\u5217    |\u7269\u4f53\u68c0\u6d4b\u7684\u7ecf\u5178\u4e4b\u4f5c\uff0c\u53ef\u4ee5\u5f53\u4f5c\u5b66\u4e60\u8d44\u6e90|\n| \u57fa\u4e8eCycleGan\u5f00\u6e90\u9879\u76ee\u5b9e\u6218\u56fe\u50cf\u878d\u5408   |PyTorch\u7248\u672c\u7684CYCLEGAN\uff0c\u8fd9\u4e2a\u5f00\u6e90\u9879\u76ee\u5199\u7684\u76f8\u5f53\u68d2| \n| OCR\u6587\u5b57\u8bc6\u522b\u539f\u7406  |OCR\u5176\u5b9e\u539f\u7406\u5f88\u7b80\u5355\uff0c\u9700\u8981\u591a\u4e2a\u6a21\u578b\u534f\u52a9\u5b8c\u6210| \n| OCR\u6587\u5b57\u8bc6\u522b\u9879\u76ee\u5b9e\u6218    |\u6784\u5efaOCR\u7f51\u7edc\u6a21\u578b|\n| \u57fa\u4e8e3D\u5377\u79ef\u7684\u89c6\u9891\u5206\u6790\u4e0e\u52a8\u4f5c\u8bc6\u522b   |\u75283D\u5377\u79ef\u6765\u5904\u7406\u89c6\u9891\u6570\u636e\u5e76\u5b8c\u6210\u884c\u4e3a\u8bc6\u522b| \n\u81ea\u7136\u8bed\u8a00\u5904\u7406\n[x] NLP\u5b66\u4e60\u96be\u5ea6\u5927\u4e0d\u5927\uff1f\u5c31\u4e1a\u65b9\u5411\u600e\u4e48\u6837\u5462\uff1f\n\u96be\u5ea6\u53ef\u4ee5\u8bf4\u8fd8\u662f\u86ee\u5927\u7684\uff0c\u5bf9\u4e8e\u56fe\u50cf\u6765\u8bf4\uff0c\u6570\u636e\u90fd\u662f\u56fa\u5b9a\u7684\uff0c\u62cd\u4e86\u4ec0\u4e48\u5c31\u662f\u4ec0\u4e48\uff01\u4f46\u662f\u6587\u672c\u6570\u636e\u5c31\u6ca1\u90a3\u4e48\u56fa\u5b9a\u4e86\uff0c\u4eba\u7c7b\n\u6709\u65f6\u5019\u7406\u89e3\u8d77\u6765\u90fd\u4e0d\u5bb9\u6613\uff0c\u66f4\u4f55\u51b5\u8ba1\u7b97\u673a\u4e86\u3002\u9ad8\u6311\u6218\u4e5f\u662f\u9ad8\u6536\u76ca\uff0cNLP\u53d1\u5c55\u524d\u666f\u8fd8\u662f\u975e\u5e38\u4e0d\u9519\u7684\uff0c\u81f3\u4e8e\u5177\u4f53\u9009\u62e9\u54ea\u4e2a\u65b9\u5411\n\u5176\u5b9e\u8fd8\u662f\u770b\u5927\u5bb6\u7684\u559c\u597d\u4e86\uff01\n\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5b9e\u6218\u9879\u76ee\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff09\n[x] \u8fd9\u4e48\u591a\u9879\u76ee\uff0c\u6709\u6ca1\u6709\u54ea\u4e2a\u662f\u9700\u8981\u91cd\u70b9\u5b66\u4e60\u7684\uff1f\u6700\u597d\u80fd\u5199\u5728\u7b80\u5386\u91cc\u9762\u5462\uff1f\n18\u5e74\u7684\u65f6\u5019\u8c37\u6b4c\u4e00\u7bc7\u8bba\u6587\u6a2a\u7a7a\u51fa\u4e16\uff0cBERT\uff01\u76f8\u5f53\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u901a\u7528\u89e3\u51b3\u6846\u67b6\u4e86\uff0c\u57fa\u672c\u6240\u6709\u4efb\u52a1\u90fd\u80fd\u505a\uff01\n\u8fd9\u4e2a\u9700\u8981\u5927\u5bb6\u91cd\u70b9\u6765\u5b66\u4e60\uff0c\u5e76\u4e14\u53ef\u4ee5\u5f53\u4f5c\u9879\u76ee\u5199\u5728\u7b80\u5386\u91cc\uff0c\u53ef\u4ee5\u8bf4\u662f\u5f53\u4e0bNLP\u5fc5\u5907\u6280\u80fd\u4e4b\u4e00\u5566\uff01\n|\u9879\u76ee\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\n| --------   |:----:  |\n| \u8bed\u8a00\u6a21\u578b      |\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5927\u5bb6\u719f\u6089\u4e0b\uff0c\u540e\u7eed\u8bcd\u5411\u91cf\u7684\u57fa\u7840| \n| \u4f7f\u7528Gemsim\u6784\u5efa\u8bcd\u5411\u91cf      |Gensim\u8fd9\u4e2a\u5305\u5b9e\u5728\u597d\u7528\uff01|\n| \u57fa\u4e8eword2vec\u7684\u5206\u7c7b\u4efb\u52a1   |\u5148\u7528\u8fd9\u4e2a\u4f8b\u5b50\u6765\u7406\u89e3\u4e0a\u5982\u4f55\u4f7f\u7528\u8bcd\u5411\u91cf| \n| NLP-\u6587\u672c\u7279\u5f81\u65b9\u6cd5\u5bf9\u6bd4    |\u6587\u672c\u7279\u5f81\u6784\u9020\u65b9\u6cd5\u8fd9\u4e48\u591a\uff0c\u54ea\u4e00\u4e2a\u66f4\u597d\u7528\u5462\uff1f| \n| LSTM\u60c5\u611f\u5206\u6790  |\u7528\u8fd9\u4e2a\u9879\u76ee\u6765\u7406\u89e3RNN\u6a21\u578b\u6240\u9700\u7684\u8f93\u5165\u957f\u4ec0\u4e48\u6837\u5b50| \n| NLP-\u76f8\u4f3c\u5ea6\u6a21\u578b       |\u6587\u672c\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65b9\u6cd5|\n| \u5bf9\u8bdd\u673a\u5668\u4eba |\u57fa\u4e8etensorlfow\u6846\u67b6\u6784\u5efa\u4e00\u4e2a\u804a\u5929\u673a\u5668\u4eba| \n| \u52a8\u624b\u6253\u9020\u81ea\u5df1\u7684\u8f93\u5165\u6cd5    |\u80fd\u4e0d\u80fd\u6784\u5efa\u4e00\u6b3e\u81ea\u5df1\u7684\u8f93\u5165\u6cd5\u5462\uff1f\u5e2e\u4f60\u641e\u5b9a\uff01|\n| \u673a\u5668\u4eba\u5199\u5510\u8bd7   |\u770b\u770b\u6a21\u578b\u5199\u51fa\u7684\u5510\u8bd7\u548b\u6837\uff01| \n| NMT\u673a\u5668\u7ffb\u8bd1\u6846  |\u5f00\u6e90\u9879\u76ee\uff0c\u53ef\u4ee5\u8fdb\u884c\u4e8c\u6b21\u5f00\u53d1| \n| \u5730\u5740\u90ae\u7f16\u591a\u5e8f\u5217\u4efb\u52a1    |\u7ecf\u5178\u6587\u672c\u5206\u7c7b\u4efb\u52a1|\n| \u81ea\u7136\u8bed\u8a00\u5904\u7406\u901a\u7528\u6846\u67b6BERT\u539f\u7406   |\u8fd9\u4e2a\u5c31\u662f\u4e0a\u9762\u8bf4\u7684BERT\u4e86\uff0c\u91cd\u70b9\uff01\u91cd\u70b9\uff01\u91cd\u70b9\uff01| \n| \u8c37\u6b4c\u5f00\u6e90\u9879\u76eeBERT\u6e90\u7801\u89e3\u8bfb      |\u6e90\u7801\u975e\u5e38\u91cd\u8981\uff0c\u6bcf\u4e00\u884c\u90fd\u9700\u8981\u7406\u89e3| \n| \u57fa\u4e8eBERT\u7684\u4e2d\u6587\u60c5\u611f\u5206\u6790      |\u57fa\u4e8e\u5f00\u6e90\u9879\u76ee\u8fdb\u884c\u6a21\u578b\u5f00\u53d1|\n| \u57fa\u4e8eBERT\u7684\u4e2d\u6587\u547d\u540d\u5b9e\u4f53\u8bc6\u522b   |\u57fa\u4e8e\u5f00\u6e90\u9879\u76ee\u8fdb\u884c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b| \n\u6700\u540e\u5520\u53e8\u51e0\u53e5\n\u901a\u8fc7\u8fd9\u51e0\u5e74\u7684\u7ebf\u4e0a\u8bfe\u7a0b\u8fd8\u6709\u7ebf\u4e0b\u7684\u4f01\u4e1a\u57f9\u8bad\u7ed3\u8bc6\u4e86\u5f88\u591a\u5c0f\u4f19\u4f34\uff0c\u673a\u6784\u548c\u540c\u5b66\u4eec\u7684\u4fe1\u4efb\u662f\u6211\u7ee7\u7eed\u66f4\u65b0\u8bfe\u7a0b\u6700\u5927\u7684\u52a8\u529b\n\u3002\u5927\u5bb6\u8ba4\u8bc6\u6211\u57fa\u672c\u90fd\u662f\u901a\u8fc7\u89c6\u9891\u8bfe\u7a0b\uff0c\u5f88\u5f00\u5fc3\u80fd\u7ed9\u5927\u5bb6\u5e26\u6765\u6536\u83b7\uff0c\u8bb0\u5f97\u6700\u5174\u594b\u7684\u5c31\u662f\u8ddf\u5bb6\u4eba\u5206\u4eab\u53c8\u6709\u5c0f\u4f19\u4f34\u6536\u83b7\noffer\u4e86\u3002\u611f\u8c22\u8fd9\u4e48\u591a\u5c0f\u4f19\u4f34\u7684\u652f\u6301\uff0c\u52a0\u6cb9\uff0c\u4f60\u4eec\u90fd\u662f\u6700\u68d2\u7684\uff01",
	"cdp chrome cli crawler crawling data-mining dsl go golang hacktoberfest hacktoberfest2021 library query-language scraper scraping scraping-websites tool": "Ferret\nTry it!\nDocs\nCLI\nTest runner\nWeb worker\nWhat is it?\nferret is a web scraping system. It aims to simplify data extraction from the web for UI testing, machine learning, analytics and more.\nferret allows users to focus on the data. It abstracts away the technical details and complexity of underlying technologies using its own declarative language. \nIt is extremely portable, extensible, and fast.\nRead the introductory blog post about Ferret here!\nFeatures\nDeclarative language\nSupport of both static and dynamic web pages\nEmbeddable\nExtensible\nDocumentation is available at our website.\nDifferent languages\nFerret for python. Pyfer",
	"association-rules data-mining data-science machine-learning python supervised-learning unsupervised-learning": "Mlxtend (machine learning extensions) is a Python library of useful tools for the day-to-day data science tasks.\nSebastian Raschka 2014-2022\nLinks\nDocumentation: http://rasbt.github.io/mlxtend\nPyPI: https://pypi.python.org/pypi/mlxtend\nChangelog: http://rasbt.github.io/mlxtend/CHANGELOG\nContributing: http://rasbt.github.io/mlxtend/CONTRIBUTING\nQuestions? Check out the GitHub Discussions board\nInstalling mlxtend\nPyPI\nTo install mlxtend, just execute\nbash\npip install mlxtend\nAlternatively, you could download the package manually from the Python Package Index https://pypi.python.org/pypi/mlxtend, unzip it, navigate into the package, and use the command:\nbash\npython setup.py install\nConda\nIf you use conda, to install mlxtend just execute\nbash\nconda install -c conda-forge mlxtend\nDev Version\nThe mlxtend version on PyPI may always be one step behind; you can install the latest development version from the GitHub repository by executing\nbash\npip install git+git://github.com/rasbt/mlxtend.git#egg=mlxtend\nOr, you can fork the GitHub repository from https://github.com/rasbt/mlxtend and install mlxtend from your local drive via\nbash\npython setup.py install\nExamples\npython\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport itertools\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom mlxtend.classifier import EnsembleVoteClassifier\nfrom mlxtend.data import iris_data\nfrom mlxtend.plotting import plot_decision_regions\nInitializing Classifiers\nclf1 = LogisticRegression(random_state=0)\nclf2 = RandomForestClassifier(random_state=0)\nclf3 = SVC(random_state=0, probability=True)\neclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[2, 1, 1], voting='soft')\nLoading some example data\nX, y = iris_data()\nX = X[:,[0, 2]]\nPlotting Decision Regions\ngs = gridspec.GridSpec(2, 2)\nfig = plt.figure(figsize=(10, 8))\nfor clf, lab, grd in zip([clf1, clf2, clf3, eclf],\n                         ['Logistic Regression', 'Random Forest', 'RBF kernel SVM', 'Ensemble'],\n                         itertools.product([0, 1], repeat=2)):\n    clf.fit(X, y)\n    ax = plt.subplot(gs[grd[0], grd[1]])\n    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n    plt.title(lab)\nplt.show()\nIf you use mlxtend as part of your workflow in a scientific publication, please consider citing the mlxtend repository with the following DOI:\n@article{raschkas_2018_mlxtend,\n  author       = {Sebastian Raschka},\n  title        = {MLxtend: Providing machine learning and data science \n                  utilities and extensions to Python\u2019s\n                  scientific computing stack},\n  journal      = {The Journal of Open Source Software},\n  volume       = {3},\n  number       = {24},\n  month        = apr,\n  year         = 2018,\n  publisher    = {The Open Journal},\n  doi          = {10.21105/joss.00638},\n  url          = {http://joss.theoj.org/papers/10.21105/joss.00638}\n}\nRaschka, Sebastian (2018) MLxtend: Providing machine learning and data science utilities and extensions to Python's scientific computing stack.\nJ Open Source Softw 3(24).\nLicense\nThis project is released under a permissive new BSD open source license (LICENSE-BSD3.txt) and commercially usable. There is no warranty; not even for merchantability or fitness for a particular purpose.\nIn addition, you may use, copy, modify and redistribute all artistic creative works (figures and images) included in this distribution under the directory\naccording to the terms and conditions of the Creative Commons Attribution 4.0 International License.  See the file LICENSE-CC-BY.txt for details. (Computer-generated graphics such as the plots produced by matplotlib fall under the BSD license mentioned above).\nContact\nThe best way to ask questions is via the GitHub Discussions channel. In case you encounter usage bugs, please don't hesitate to use the GitHub's issue tracker directly. ",
	"classification clustering data-mining data-science data-visualization decision-trees machine-learning numpy orange orange3 pandas plotting python random-forest regression scikit-learn scipy visual-programming visualization": "Orange Data Mining\nOrange is a data mining and visualization toolbox for novice and expert alike. To explore data with Orange, one requires no programming or in-depth mathematical knowledge. We believe that workflow-based data science tools democratize data science by hiding complex underlying mechanics and exposing intuitive concepts. Anyone who owns data, or is motivated to peek into data, should have the means to do so.\nInstalling\nEasy installation\nFor easy installation, Download the latest released Orange version from our website. To install an add-on, head to Options -> Add-ons... in the menu bar.\nInstalling with Conda\nFirst, install Miniconda for your OS. \nThen, create a new conda environment, and install orange3:\nShell\nAdd conda-forge to your channels for access to the latest release\nconda config --add channels conda-forge\nPerhaps enforce strict conda-forge priority\nconda config --set channel_priority strict\nCreate and activate an environment for Orange\nconda create python=3 --yes --name orange3\nconda activate orange3\nInstall Orange\nconda install orange3\nFor installation of an add-on, use:\nShell\nconda install orange3-\nSee specific add-on repositories for details.\nInstalling with pip\nWe recommend using our standalone installer or conda, but Orange is also installable with pip. You will need a C/C++ compiler (on Windows we suggest using Microsoft Visual Studio Build Tools).\nInstalling with winget (Windows only)\nTo install Orange with winget, run:\nShell\nwinget install --id  UniversityofLjubljana.Orange\nRunning\nEnsure you've activated the correct virtual environment. If following the above conda instructions:\nShell\nconda activate orange3 \nRun orange-canvas or python3 -m Orange.canvas. Add --help for a list of program options.\nStarting up for the first time may take a while.\nDeveloping\nWant to write a widget? Use the Orange3 example add-on template.\nWant to get involved? Join us on Discord, introduce yourself in #general! \nTake a look at our contributing guide and style guidelines.\nCheck out our widget development docs for a comprehensive guide on writing Orange widgets.\nThe Orange ecosystem\nThe development of core Orange is primarily split into three repositories:\nbiolab/orange-canvas-core implements the canvas,\nbiolab/orange-widget-base is a handy widget GUI library,\nbiolab/orange3 brings it all together and implements the base data mining toolbox. \nAdditionally, add-ons implement additional widgets for more specific use cases. Anyone can write an add-on. Some of our first-party add-ons:\nbiolab/orange3-text\nbiolab/orange3-bioinformatics\nbiolab/orange3-timeseries \nbiolab/orange3-single-cell \nbiolab/orange3-imageanalytics \nbiolab/orange3-educational \nbiolab/orange3-geo \nbiolab/orange3-associate \nbiolab/orange3-network\nbiolab/orange3-explain\nSetting up for core Orange development\nFirst, fork the repository by pressing the fork button in the top-right corner of this page.\nSet your GitHub username,\nShell\nexport MY_GITHUB_USERNAME=replaceme\ncreate a conda environment, clone your fork, and install it:\nShell\nconda create python=3 --yes --name orange3\nconda activate orange3\ngit clone ssh://git@github.com/$MY_GITHUB_USERNAME/orange3\npip install -e orange3\nNow you're ready to work with git. See GitHub's guides on pull requests, forks if you're unfamiliar. If you're having trouble, get in touch on Discord.\nRunning\nRun Orange with python -m Orange.canvas (after activating the conda environment).\npython -m Orange.canvas -l 2 --no-splash --no-welcome will skip the splash screen and welcome window, and output more debug info. Use -l 4 for more.\nAdd --clear-widget-settings to clear the widget settings before start.\nTo explore the dark side of the Orange, try --style=fusion:breeze-dark\nArgument --help lists all available options.\nTo run tests, use unittest Orange.tests Orange.widgets.tests\nSetting up for development of all components\nShould you wish to contribute Orange's base components (the widget base and the canvas), you must also clone these two repositories from Github instead of installing them as dependencies of Orange3.\nFirst, fork all the repositories to which you want to contribute. \nSet your GitHub username,\nShell\nexport MY_GITHUB_USERNAME=replaceme\ncreate a conda environment, clone your forks, and install them:\nShell\nconda create python=3 --yes --name orange3\nconda activate orange3\ngit clone ssh://git@github.com/$MY_GITHUB_USERNAME/orange-widget-base\npip install -e orange-widget-base\ngit clone ssh://git@github.com/$MY_GITHUB_USERNAME/orange-canvas-core\npip install -e orange-canvas-core\ngit clone ssh://git@github.com/$MY_GITHUB_USERNAME/orange3\npip install -e orange3\nRepeat for any add-on repositories\nIt's crucial to install orange-base-widget and orange-canvas-core before orange3 to ensure that orange3 will use your local versions.",
	"artificial-intelligence awesome awesome-list bayes data-analysis data-mining data-science data-visualization datascience deep-learning deeplearning machine-learning python statistics": "Awesome Data Science with Python\nA curated list of awesome resources for practicing data science using Python, including not only libraries, but also links to tutorials, code snippets, blog posts and talks.  \nCore\npandas - Data structures built on top of numpy.\nscikit-learn - Core ML library.\nmatplotlib - Plotting library.\nseaborn - Data visualization library based on matplotlib.\ndatatile - Basic statistics using DataFrameSummary(df).summary().\npandas_profiling - Descriptive statistics using ProfileReport.\nsklearn_pandas - Helpful DataFrameMapper class.\nmissingno - Missing data visualization.\nrainbow-csv - Plugin to display .csv files with nice colors.\nEnvironment and Jupyter\nGeneral Jupyter Tricks\nFixing environment: link\nPython debugger (pdb) - blog post, video, cheatsheet\ncookiecutter-data-science - Project template for data science projects.\nnteract - Open Jupyter Notebooks with doubleclick.\npapermill - Parameterize and execute Jupyter notebooks, tutorial.\nnbdime - Diff two notebook files, Alternative GitHub App: ReviewNB.\nRISE - Turn Jupyter notebooks into presentations.\nqgrid - Pandas DataFrame sorting.\npivottablejs - Drag n drop Pivot Tables and Charts for jupyter notebooks.\nitables - Interactive tables in Jupyter.\njupyter-datatables - Interactive tables in Jupyter.\ndebugger - Visual debugger for Jupyter.\nnbcommands - View and search notebooks from terminal.\nhandcalcs - More convenient way of writing mathematical equations in Jupyter.\nnotebooker - Productionize and schedule Jupyter Notebooks.\nbamboolib - Intuitive GUI for tables.\nvoila - Turn Jupyter notebooks into standalone web applications.\nvoila-gridstack - Voila grid layout.\nPandas Tricks, Alternatives and Additions\nPandas Tricks\nUsing df.pipe() (video)\npandasvault - Large collection of pandas tricks.\nmodin - Parallelization library for faster pandas DataFrame.\nvaex - Out-of-Core DataFrames.\npandarallel - Parallelize pandas operations.\nxarray - Extends pandas to n-dimensional arrays.\nswifter - Apply any function to a pandas dataframe faster. \npandas_flavor - Write custom accessors like .str and .dt. \npandas-log - Find business logic issues and performance issues in pandas.\npandapy - Additional features for pandas.\nlux - Dataframe visualization within Jupyter.\ndtale - View and analyze Pandas data structures, integrating with Jupyter.\npolars - Multi-threaded alternative to pandas.\nduckdb - Efficiently run SQL queries on pandas DataFrame.\nScikit-Learn Alternatives\nscikit-learn-intelex - Intel extension for scikit-learn for speed.\nHelpful\ndrawdata - Quickly draw some points and export them as csv, website.\ntqdm - Progress bars for for-loops. Also supports pandas apply().\nicecream - Simple debugging output.\nloguru - Python logging.\npyprojroot - Helpful here() command from R.\nintake - Loading datasets made easier, talk. \nExtraction\ntextract - Extract text from any document.\ncamelot - Extract text from PDF.\nBig Data\nspark - DataFrame for big data, cheatsheet, tutorial.\nsparkit-learn, spark-deep-learning - ML frameworks for spark.\nkoalas - Pandas API on Apache Spark.\ndask, dask-ml - Pandas DataFrame for big data and machine learning library, resources, talk1, talk2, notebooks, videos.\ndask-gateway - Managing dask clusters.\nturicreate - Helpful SFrame class for out-of-memory dataframes.\nh2o - Helpful H2OFrame class for out-of-memory dataframes.\ndatatable - Data Table for big data support.\ncuDF - GPU DataFrame Library, Intro.\nray - Flexible, high-performance distributed execution framework.\nmars - Tensor-based unified framework for large-scale data computation.\nbottleneck - Fast NumPy array functions written in C. \nbolz - A columnar data container that can be compressed.\ncupy - NumPy-like API accelerated with CUDA.\npetastorm - Data access library for parquet files by Uber.\nzarr - Distributed numpy arrays.\nNVTabular - Feature engineering and preprocessing library for tabular data by nvidia.\ntensorstore - Reading and writing large multi-dimensional arrays (Google).\nDistributed Systems\nnextflow - Run scripts and workflow graphs in Docker image using Google Life Sciences, AWS Batch, Website.\ndsub - Run batch computing tasks in Docker image in the Google Cloud.\nCommand line tools, CSV\nni - Command line tool for big data.\nxsv - Command line tool for indexing, slicing, analyzing, splitting and joining CSV files.\ncsvkit - Another command line tool for CSV files.\ncsvsort - Sort large csv files.\ntsv-utils - Tools for working with CSV files by ebay.\ncheat - Make cheatsheets for command line commands.\nClassical Statistics\nCorrelation\nphik - Correlation between categorical, ordinal and interval variables.\nPackages\nstatsmodels - Statistical tests.\nlinearmodels - Instrumental variable and panel data models.\npingouin - Statistical tests. Pairwise correlation between columns of pandas DataFrame \nscipy.stats - Statistical tests.\nscikit-posthocs - Statistical post-hoc tests for pairwise multiple comparisons. \nBland-Altman Plot 1, 2 - Plot for agreement between two methods of measurement.\nANOVA, Tutorials: One-way, Two-way, Type 1,2,3 explained.\nStatistical Tests\ntest_proportions_2indep - Proportion test.\nG-Test - Alternative to chi-square test, power_divergence.\nComparing Two Populations\ntorch-two-sample - Friedman-Rafsky Test: Compare two population based on a multivariate generalization of the Runstest. Explanation, Application \nInterim Analyses / Sequential Analysis / Stopping\nSquential Analysis - Wikipedia.\nTreatment Effects Monitoring - Design and Analysis of Clinical Trials PennState.\nsequential - Exact Sequential Analysis for Poisson and Binomial Data (R package).\nconfseq - Uniform boundaries, confidence sequences, and always-valid p-values.\nVisualizations\nGreat Overview over Visualizations\nDependent Propabilities\nNull Hypothesis Significance Testing (NHST) and Sample Size Calculation\nCorrelation\nCohen's d\nConfidence Interval\nEquivalence, non-inferiority and superiority testing\nBayesian two-sample t test\nDistribution of p-values when comparing two groups\nUnderstanding the t-distribution and its normal approximation \nTalks\nInverse Propensity Weighting\nDealing with Selection Bias By Propensity Based Feature Selection \nTexts\nModes, Medians and Means: A Unifying Perspective \nUsing Norms to Understand Linear Regression \nVerifying the Assumptions of Linear Models\nMediation and Moderation Intro\nMontgomery et al. - How conditioning on post-treatment variables can ruin your experiment and what to do about it\nGreenland - Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations\nBlume - Second-generation p-values: Improved rigor, reproducibility, & transparency in statistical analyses\nLindel\u00f8v - Common statistical tests are linear models \nChatruc - The Central Limit Theorem and its misuse\nAl-Saleh - Properties of the Standard Deviation that are Rarely Mentioned in Classrooms \nWainer - The Most Dangerous Equation \nGigerenzer - The Bias Bias in Behavioral Economics\nCook - Estimating the chances of something that hasn\u2019t happened yet \nEpidemiology\nR Epidemics Consortium - Large tool suite for working with epidemiological data (R packages). Github \nincidence2 - Computation, handling, visualisation and simple modelling of incidence (R package).\nEpiEstim - Estimate time varying instantaneous reproduction number R during epidemics (R package) paper.\nresearchpy - Helpful summary_cont() function for summary statistics (Table 1).\nzEpid - Epidemiology analysis package, Tutorial.\ntipr - Sensitivity analyses for unmeasured confounders (R package).\nExploration and Cleaning\nChecklist.\npandasgui - GUI for viewing, plotting and analyzing Pandas DataFrames.\njanitor - Clean messy column names.\npandera - Data / Schema validation.\nimpyute - Imputations.\nfancyimpute - Matrix completion and imputation algorithms.\nimbalanced-learn - Resampling for imbalanced datasets.\ntspreprocess - Time series preprocessing: Denoising, Compression, Resampling.\nKaggler - Utility functions (OneHotEncoder(min_obs=100))\npyupset - Visualizing intersecting sets.\npyemd - Earth Mover's Distance / Wasserstein distance, similarity between histograms. OpenCV implementation, POT implementation \nlittleballoffur - Sampling from graphs.\nNoisy Labels\ncleanlab - Machine learning with noisy labels, finding mislabeled data, and uncertainty quantification. Also see awesome list below.\ndoubtlab - Find bad or noisy labels.\nTrain / Test Split\niterative-stratification - Stratification of multilabel data.\nFeature Engineering\nTalk\nsklearn - Pipeline, examples.\npdpipe - Pipelines for DataFrames.\nscikit-lego - Custom transformers for pipelines.\nskoot - Pipeline helper functions.\ncategorical-encoding - Categorical encoding of variables, vtreat (R package).\ndirty_cat - Encoding dirty categorical variables.\npatsy - R-like syntax for statistical models.\nmlxtend - LDA.\nfeaturetools - Automated feature engineering, example.\ntsfresh - Time series feature engineering.\npypeln - Concurrent data pipelines.\nfeature_engine - Encoders, transformers, etc.\nNVTabular - Feature engineering and preprocessing library for tabular data by nvidia.\nComputer Vision\nIntro to Computer Vision \nImage Cleanup\nFiji - General purpose tool. Image viewer and image processing package.\nnapari - Multi-dimensional image viewer.\nfiftyone - Viewer and tool for building high-quality datasets and computer vision models.\nDivNoising - Unsupervised denoising method.\naydin - Image denoising.\nunprocessing - Image denoising by reverting the image processing pipeline.\nMicroscopy / Segmentation\nDatasets\njump-cellpainting - Cellpainting dataset.\nMedMNIST - Datasets for 2D and 3D Biomedical Image Classification.\nCytoImageNet - Huge diverse dataset like ImageNet but for cell images.\ncellpose dataset - Cell images.\nHaghighi - Gene Expression and Morphology Profiles.\nbroadinstitute/lincs-profiling-complementarity - Cellpainting vs. L1000 assay.\nPackages\nAwesome Cytodata\nBD Spectrum Viewer - Calculate spectral overlap, bleed through for fluorescence microscopy dyes.\nTree of Microscopy - Review of cell segmentation algorithms, Paper.\ncellpose - Cell segmentation. Paper, Dataset.\nskimage - Illumination correction (CLAHE).\ncidre - Illumination correction method for optical microscopy.\nBaSiCPy - Background and Shading Correction of Optical Microscopy Images, BaSiC.\nashlar - Whole-slide microscopy image stitching and registration.\nCSBDeep - Image denoising, restoration and object detection, Project page.\nmcmicro - Multiple-choice microscopy pipeline, Paper.\nUnMicst - Identifying Cells and Segmenting Tissue.\nstardist - Object Detection with Star-convex Shapes.\nnnUnet - 3D biomedical image segmentation.\natomai - Deep and Machine Learning for Microscopy.\nallencell - Tools for the 3D segmentation of intracellular structures.\nDomain Adaptation / Batch-Effect Correction\nTran - A benchmark of batch-effect correction methods for single-cell RNA sequencing data, Code.\nR Tutorial on correcting batch effects.\nharmonypy - Fuzzy k-means and locally linear adjustments.\npyliger - Batch-effect correction, Example, R package.\nnimfa - Nonnegative matrix factorization.\nscgen - Batch removal. Doc.\nCORAL - Correcting for Batch Effects Using Wasserstein Distance, Code, Paper. \nadapt - Aweseome Domain Adaptation Python Toolbox.\npytorch-adapt - Various neural network models for domain adaptation.\nFeature Engineering Images\nskimage - Regionprops: area, eccentricity, extent.\nmahotas - Zernike, Haralick, LBP, and TAS features.\npyradiomics - Radiomics features from medical imaging.\npyefd - Elliptical feature descriptor, approximating a contour with a Fourier series.\nFeature Selection\nOverview Paper, Talk, Repo \nBlog post series - 1, 2, 3, 4\nTutorials - 1, 2\nsklearn - Feature selection.\neli5 - Feature selection using permutation importance.\nscikit-feature - Feature selection algorithms.\nstability-selection - Stability selection.\nscikit-rebate - Relief-based feature selection algorithms.\nscikit-genetic - Genetic feature selection.\nboruta_py - Feature selection, explaination, example.\nBoruta-Shap - Boruta feature selection algorithm + shapley values.\nlinselect - Feature selection package.\nmlxtend - Exhaustive feature selection. \nBoostARoota - Xgboost feature selection algorithm.\nINVASE - Instance-wise Variable Selection using Neural Networks.\nSubTab - Subsetting Features of Tabular Data for Self-Supervised Representation Learning, AstraZeneca.\nmrmr - Maximum Relevance and Minimum Redundancy Feature Selection, Website.\narfs - All Relevant Feature Selection.\nVSURF - Variable Selection Using Random Forests (R package) doc.\nFeatureSelectionGA - Feature Selection using Genetic Algorithm.\nSubset Selection\napricot - Selecting subsets of data sets to train machine learning models quickly.\nducks - Index data for fast lookup by any combination of fields.\nDimensionality Reduction / Representation Learning\nSelection\nCheck also the Clustering section and self-supervised learning section for ideas!\nReview \nPCA - link \nAutoencoder - link\nIsomaps - link \nLLE - link\nForce-directed graph drawing - link \nMDS - link\nDiffusion Maps - link\nt-SNE - link \nNeRV - link, paper\nMDR - link\nUMAP - link\nRandom Projection - link\nIvis - link \nSimCLR - link \nNeural-network based\nesvit - Vision Transformers for Representation Learning (Microsoft).\nMCML - Semi-supervised dimensionality reduction of Multi-Class, Multi-Label data (sequencing data) paper.\nPackages\nDangers of PCA (paper).\nTalk, tsne intro. \nsklearn.manifold and sklearn.decomposition - PCA, t-SNE, MDS, Isomaps and others.\nAdditional plots for PCA - Factor Loadings, Cumulative Variance Explained, Correlation Circle Plot, Tweet\nsklearn.random_projection - Johnson-Lindenstrauss lemma, Gaussian random projection, Sparse random projection.\nsklearn.cross_decomposition - Partial least squares, supervised estimators for dimensionality reduction and regression.\nprince - Dimensionality reduction, factor analysis (PCA, MCA, CA, FAMD).\nFaster t-SNE implementations: lvdmaaten, MulticoreTSNE, FIt-SNE\numap - Uniform Manifold Approximation and Projection, talk, explorer, explanation, parallel version.\nhumap - Hierarchical UMAP.\nsleepwalk - Explore embeddings, interactive visualization (R package).\nsomoclu - Self-organizing map.\nscikit-tda - Topological Data Analysis, paper, talk, talk, paper.\ngiotto-tda - Topological Data Analysis.\nivis - Dimensionality reduction using Siamese Networks.\ntrimap - Dimensionality reduction using triplets.\nscanpy - Force-directed graph drawing, Diffusion Maps.\ndirepack - Projection pursuit, Sufficient dimension reduction, Robust M-estimators.\nDBS - DatabionicSwarm (R package).\ncontrastive - Contrastive PCA.\nscPCA - Sparse contrastive PCA (R package).\ntmap - Visualization library for large, high-dimensional data sets.\nlollipop - Linear Optimal Low Rank Projection.\nlinearsdr - Linear Sufficient Dimension Reduction (R package).\nPHATE - Tool for visualizing high dimensional data.\nTraining-related\niterative-stratification - Cross validators with stratification for multilabel data. \nlivelossplot - Live training loss plot in Jupyter Notebook. \nVisualization\nAll charts, Austrian monuments.\nBetter heatmaps and correlation plots.\nExample notebooks for interactive visualizations(Plotly,Seaborn, Holoviz, Altair)\ncufflinks - Dynamic visualization library, wrapper for plotly, medium, example.\nphyst - Better histograms, talk, notebook.\nfast-histogram - Fast histograms.\nmatplotlib_venn - Venn diagrams, alternative.\njoypy - Draw stacked density plots (=ridge plots), Ridge plots in seaborn.\nmosaic plots - Categorical variable visualization, example.\nscikit-plot - ROC curves and other visualizations for ML models.\nyellowbrick - Visualizations for ML models (similar to scikit-plot).\nbokeh - Interactive visualization library, Examples, Examples.\nlets-plot - Plotting library.\nanimatplot - Animate plots build on matplotlib.\nplotnine - ggplot for Python.\naltair - Declarative statistical visualization library.\nbqplot - Plotting library for IPython/Jupyter Notebooks.\nhvplot - High-level plotting library built on top of holoviews.\ndtreeviz - Decision tree visualization and model interpretation.\nchartify - Generate charts.\nVivaGraphJS - Graph visualization (JS package).\npm - Navigatable 3D graph visualization (JS package), example.\npython-ternary - Triangle plots.\nfalcon - Interactive visualizations for big data.\nhiplot - High dimensional Interactive Plotting.\nvisdom - Live Visualizations.\nmpl-scatter-density - Scatter density plots. Alternative to 2d-histograms. \nComplexHeatmap - Complex heatmaps for multidimensional genomic data (R package).\nlargeVis - Visualize embeddings (t-SNE etc.) (R package).\nproplot - Matplotlib wrapper.\nmorpheus - Broad Institute tool matrix visualization and analysis software. Source, Tutorial: 1, 2, Code.\nColors\npalettable - Color palettes from colorbrewer2.\ncolorcet - Collection of perceptually uniform colormaps.\nNamed Colors Wheel - Color wheel for all named HTML colors.\nDashboards\nsuperset - Dashboarding solution by Apache.\nstreamlit - Dashboarding solution. Resources, Gallery Components, bokeh-events.\nmercury - Convert Python notebook to web app, Example.\ndash - Dashboarding solution by plot.ly. Resources.\nvisdom - Dashboarding library by facebook.\npanel - Dashboarding solution.\naltair example - Video.\nvoila - Turn Jupyter notebooks into standalone web applications.\nvoila-gridstack - Voila grid layout.\nUI\ngradio - Create UIs for your machine learning model.\nSurvey Tools\nsamplics - Sampling techniques for complex survey designs.\nGeographical Tools\nfolium - Plot geographical maps using the Leaflet.js library, jupyter plugin.\ngmaps - Google Maps for Jupyter notebooks.\nstadiamaps - Plot geographical maps.\ndatashader - Draw millions of points on a map.\nsklearn - BallTree, Example.\npynndescent - Nearest neighbor descent for approximate nearest neighbors.\ngeocoder - Geocoding of addresses, IP addresses.\nConversion of different geo formats: talk, repo\ngeopandas - Tools for geographic data\nLow Level Geospatial Tools (GEOS, GDAL/OGR, PROJ.4)\nVector Data (Shapely, Fiona, Pyproj)\nRaster Data (Rasterio)\nPlotting (Descartes, Catropy)\nPredict economic indicators from Open Street Map ipynb.\nPySal - Python Spatial Analysis Library.\ngeography - Extract countries, regions and cities from a URL or text.\ncartogram - Distorted maps based on population.\nRecommender Systems\nExamples: 1, 2, 2-ipynb, 3.\nsurprise - Recommender, talk.\nturicreate - Recommender.\nimplicit - Fast Collaborative Filtering for Implicit Feedback Datasets.\nspotlight - Deep recommender models using PyTorch.\nlightfm - Recommendation algorithms for both implicit and explicit feedback.\nfunk-svd - Fast SVD.\npywFM - Factorization.\nDecision Tree Models\nIntro to Decision Trees and Random Forests, Intro to Gradient Boosting 1, 2, Decision Tree Visualization \nlightgbm - Gradient boosting (GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, doc.\nxgboost - Gradient boosting (GBDT, GBRT or GBM) library, doc, Methods for CIs: link1, link2.\ncatboost - Gradient boosting.\nh2o -  Gradient boosting and general machine learning framework.\nsnapml - Gradient boosting and general machine learning framework by IBM, for CPU and GPU. PyPI \npycaret - Wrapper for xgboost, lightgbm, catboost etc.\nthundergbm - GBDTs and Random Forest.\nh2o - Gradient boosting.\nforestci - Confidence intervals for random forests.\nscikit-garden - Quantile Regression.\ngrf - Generalized random forest.\ndtreeviz - Decision tree visualization and model interpretation.\nNuance - Decision tree visualization.\nrfpimp - Feature Importance for RandomForests using Permuation Importance.\nWhy the default feature importance for random forests is wrong: link\ntreeinterpreter - Interpreting scikit-learn's decision tree and random forest predictions.\nbartpy - Bayesian Additive Regression Trees.\ninfiniteboost - Combination of RFs and GBDTs.\nmerf - Mixed Effects Random Forest for Clustering, video\nrrcf - Robust Random Cut Forest algorithm for anomaly detection on streams.\ngroot - Robust decision trees.\nlinear-tree - Trees with linear models at the leaves.\nNatural Language Processing (NLP) / Text Processing\ntalk-nb, nb2, talk.\nText classification Intro, Preprocessing blog post.\ngensim - NLP, doc2vec, word2vec, text processing, topic modelling (LSA, LDA), Example, Coherence Model for evaluation.\nEmbeddings - GloVe ([1], [2]), StarSpace, wikipedia2vec, visualization.\nmagnitude - Vector embedding utility package.\npyldavis - Visualization for topic modelling.\nspaCy - NLP.\nNTLK - NLP, helpful KMeansClusterer with cosine_distance.\npytext - NLP from Facebook.\nfastText - Efficient text classification and representation learning.\nannoy - Approximate nearest neighbor search.\nfaiss - Approximate nearest neighbor search.\npysparnn - Approximate nearest neighbor search.\ninfomap - Cluster (word-)vectors to find topics, example.\ndatasketch - Probabilistic data structures for large data (MinHash, HyperLogLog).\nflair - NLP Framework by Zalando.\nstanfordnlp - NLP Library.\nChatistics - Turn Messenger, Hangouts, WhatsApp and Telegram chat logs into DataFrames.\ntextvec - Supervised text vectorization tool.\ntextdistance - Collection for comparing distances between two or more sequences.\nPapers\nSearch Engine Correlation \nBiology / Bioinformatics\nBiostatistics / Robust statistics\nMinCovDet - Robust estimator of covariance, RMPV, Paper, App1, App2.\nwinsorize - Simple adjustment of outliers.\nmoderated z-score - Weighted average of z-scores based on Spearman correlation.\nSequencing\nSingle cell tutorial.\ncellxgene - Interactive explorer for single-cell transcriptomics data.\nscanpy - Analyze single-cell gene expression data, tutorial.\nbesca - Beyond single-cell analysis.\njanggu - Deep Learning for Genomics.\ngdsctools - Drug responses in the context of the Genomics of Drug Sensitivity in Cancer project, ANOVA, IC50, MoBEM, doc.\nImage-related\nSee also Microscopy Section above.\nOverview over cell segmentation algorithms\npython_for_microscopists - Notebooks and associated youtube channel for a variety of image processing tasks.\nmahotas - Image processing (Bioinformatics), example. \nimagepy - Software package for bioimage analysis.\nscimap - Spatial Single-Cell Analysis Toolkit.\nCellProfiler - Biological image analysis. \nimglyb - Viewer for large images, talk, slides.\nmicroscopium - Unsupervised clustering of images + viewer, talk.\ncytokit - Analyzing properties of cells in fluorescent microscopy datasets.\nZeroCostDL4Mic - Deep-Learning in Microscopy.\nDrug discovery\nTDC - Drug Discovery and Development.\nDeepPurpose - Deep Learning Based Molecular Modeling and Prediction Toolkit.\nCourses\nmit6874 - Computational Systems Biology: Deep Learning in the Life Sciences.\nImage Processing\nTalk\ncv2 - OpenCV, classical algorithms: Gaussian Filter, Morphological Transformations.\nscikit-image - Image processing.\nNeural Networks\nConvolutional Neural Networks for Visual Recognition - Stanford CS class.\nConvNet Shape Calculator - Calculate output dimensions of Conv2D layer.\nGreat Gradient Descent Article.\nIntro to semi-supervised learning.\nTutorials & Viewer\nfast.ai course - Lessons 1-7, Lessons 8-14\nTensorflow without a PhD - Neural Network course by Google.\nFeature Visualization: Blog, PPT\nTensorflow Playground\nVisualization of optimization algorithms, Another visualization \ncutouts-explorer - Image Viewer.\nImage Related\nimgaug - More sophisticated image preprocessing.\nAugmentor - Image augmentation library.\nkeras preprocessing - Preprocess images.\nalbumentations - Wrapper around imgaug and other libraries.\naugmix - Image augmentation from Google.\nkornia - Image augmentation, feature extraction and loss functions.\naugly - Image, audio, text, video augmentation from Facebook.\nLossfunction Related\nSegLoss - List of loss functions for medical image segmentation.\nActivation Functions\nrational_activations - Rational activation functions.\nText Related\nktext - Utilities for pre-processing text for deep learning in Keras. \ntextgenrnn - Ready-to-use LSTM for text generation.\nctrl - Text generation.\nNeural network and deep learning frameworks\nOpenMMLab - Framework for segmentation, classification and lots of other computer vision tasks.\ncaffe - Deep learning framework, pretrained models.\nmxnet - Deep learning framework, book.\nLibs General\nkeras - Neural Networks on top of tensorflow, examples.\nkeras-contrib - Keras community contributions.\nkeras-tuner - Hyperparameter tuning for Keras.\nhyperas - Keras + Hyperopt: Convenient hyperparameter optimization wrapper.\nelephas - Distributed Deep learning with Keras & Spark.\ntflearn - Neural Networks on top of tensorflow.\ntensorlayer - Neural Networks on top of tensorflow, tricks.\ntensorforce - Tensorflow for applied reinforcement learning.\nautokeras - AutoML for deep learning.\nPlotNeuralNet - Plot neural networks.\nlucid - Neural network interpretability, Activation Maps.\ntcav - Interpretability method.\nAdaBound - Optimizer that trains as fast as Adam and as good as SGD, alt.\nfoolbox - Adversarial examples that fool neural networks.\nhiddenlayer - Training metrics.\nimgclsmob - Pretrained models.\nnetron - Visualizer for deep learning and machine learning models.\nffcv - Fast dataloder.\nLibs Pytorch\nGood Pytorch Introduction \nskorch - Scikit-learn compatible neural network library that wraps pytorch, talk, slides.\nfastai - Neural Networks in pytorch.\ntimm - Pytorch image models.\nignite - Highlevel library for pytorch.\ntorchcv - Deep Learning in Computer Vision.\npytorch-optimizer - Collection of optimizers for pytorch.\npytorch-lightning - Wrapper around PyTorch.\nlightly - MoCo, SimCLR, SimSiam, Barlow Twins, BYOL, NNCLR.\nMONAI - Deep learning in healthcare imaging.\nkornia - Image transformations, epipolar geometry, depth estimation.\ntorchinfo - Nice model summary.\nlovely-tensors - Inspect tensors, mean, std, inf values.\nDistributed Libs\nflexflow - Distributed TensorFlow Keras and PyTorch.\nhorovod - Distributed training framework for TensorFlow, Keras, PyTorch, and Apache MXNet.\nArchitecture Visualization\nAwesome List.\nnetron - Viewer for neural networks.\nvisualkeras - Visualize Keras networks.\nObject detection / Instance Segmentation\nGood Yolo Explanation\nsegmentation_models - Segmentation models with pretrained backbones: Unet, FPN, Linknet, PSPNet.\nyolact - Fully convolutional model for real-time instance segmentation.\nEfficientDet Pytorch, EfficientDet Keras - Scalable and Efficient Object Detection.\ndetectron2 - Object Detection (Mask R-CNN) by Facebook.\nsimpledet - Object Detection and Instance Recognition.\nCenterNet - Object detection.\nFCOS - Fully Convolutional One-Stage Object Detection.\nnorfair - Real-time 2D object tracking.\nDetic -  Detector with image classes that can use image-level labels (facebookresearch).\nEasyCV - Image segmentation, classification, metric-learning, object detection, pose estimation.\nImage Annotation\ncvat - Image annotation tool.\npigeon - Create annotations from within a Jupyter notebook.\nImage Classification\nnfnets - Neural network. \nefficientnet - Neural network. \npycls - Pytorch image classification networks: ResNet, ResNeXt, EfficientNet, and RegNet (by Facebook).\nApplications and Snippets\nSPADE - Semantic Image Synthesis.\nEntity Embeddings of Categorical Variables, code, kaggle\nImage Super-Resolution - Super-scaling using a Residual Dense Network.\nCell Segmentation - Talk, Blog Posts: 1, 2\ndeeplearning-models - Deep learning models.\nVariational Autoencoders (VAEs)\nVariational Autoencoder Explanation Video\ndisentanglement_lib - BetaVAE, FactorVAE, BetaTCVAE, DIP-VAE.\nladder-vae-pytorch - Ladder Variational Autoencoders (LVAE).\nbenchmark_VAE - Unifying Generative Autoencoder implementations.\nGenerative Adversarial Networks (GANs)\nAwesome GAN Applications\nThe GAN Zoo - List of Generative Adversarial Networks.\nCycleGAN and Pix2pix - Various image-to-image tasks.\nTensorflow GAN implementations\nPytorch GAN implementations\nPytorch GAN implementations\nStudioGAN - Pytorch GAN implementations.\nTransformers\nSegFormer - Simple and Efficient Design for Semantic Segmentation with Transformers.\nesvit - Efficient self-supervised Vision Transformers.\nnystromformer - More efficient transformer because of approximate self-attention.\nDeep learning on structured data\nGreat overview for deep learning for tabular data \nGraph-Based Neural Networks\nHow to do Deep Learning on Graphs with Graph Convolutional Networks\nIntroduction To Graph Convolutional Networks\nAn attempt at demystifying graph deep learning\nogb - Open Graph Benchmark, Benchmark datasets.\nnetworkx - Graph library.\ncugraph - RAPIDS, Graph library on the GPU.\npytorch-geometric - Various methods for deep learning on graphs.\ndgl - Deep Graph Library.\ngraph_nets - Build graph networks in Tensorflow, by deepmind.\nModel conversion\nhummingbird - Compile trained ML models into tensor computations (by Microsoft).\nGPU\ncuML - RAPIDS, Run traditional tabular ML tasks on GPUs, Intro.\nthundergbm - GBDTs and Random Forest.\nthundersvm - Support Vector Machines.\nLegate Numpy - Distributed Numpy array multiple using GPUs by Nvidia (not released yet) video.\nRegression\nUnderstanding SVM Regression: slides, forum, paper \npyearth - Multivariate Adaptive Regression Splines (MARS), tutorial.\npygam - Generalized Additive Models (GAMs), Explanation.\nGLRM - Generalized Low Rank Models.\ntweedie - Specialized distribution for zero inflated targets, Talk.\nMAPIE - Estimating prediction intervals.\nRegressio - Regression and Spline models.\nPolynomials\northopy - Orthogonal polynomials in all shapes and sizes.\nClassification\nTalk, Notebook\nBlog post: Probability Scoring\nAll classification metrics\nDESlib - Dynamic classifier and ensemble selection.\nhuman-learn - Create and tune classifier based on your rule set.\nMetric Learning\nContrastive Representation Learning \nmetric-learn - Supervised and weakly-supervised metric learning algorithms.\npytorch-metric-learning - Pytorch metric learning.\ndeep_metric_learning - Methods for deep metric learning.\nivis - Metric learning using siamese neural networks.\ntensorflow similarity - Metric learning.\nDistance Functions\nscipy.spatial - All kinds of distance metrics.\npyemd - Earth Mover's Distance / Wasserstein distance, similarity between histograms. OpenCV implementation, POT implementation \ndcor  - Distance correlation and related Energy statistics.\nGeomLoss - Kernel norms, Hausdorff divergences, Debiased Sinkhorn divergences (=approximation of Wasserstein distance).\nSelf-supervised Learning\nlightly - MoCo, SimCLR, SimSiam, Barlow Twins, BYOL, NNCLR.\nvissl - Self-Supervised Learning with PyTorch: RotNet, Jigsaw, NPID, ClusterFit, PIRL, SimCLR, MoCo, DeepCluster, SwAV.\nClustering\nOverview of clustering algorithms applied image data (= Deep Clustering).\nClustering with Deep Learning: Taxonomy and New Methods.\nHierarchical Cluster Analysis (R Tutorial) - Dendrogram, Tanglegram\nhdbscan - Clustering algorithm, talk, blog.\npyclustering - All sorts of clustering algorithms.\nFCPS -  Fundamental Clustering Problems Suite (R package).\nGaussianMixture - Generalized k-means clustering using a mixture of Gaussian distributions, video.\nnmslib - Similarity search library and toolkit for evaluation of k-NN methods.\nbuckshotpp - Outlier-resistant and scalable clustering algorithm.\nmerf - Mixed Effects Random Forest for Clustering, video\ntree-SNE - Hierarchical clustering algorithm based on t-SNE.\nMiniSom - Pure Python implementation of the Self Organizing Maps.\ndistribution_clustering, paper, related paper, alt.\nphenograph - Clustering by community detection.\nFastPG - Clustering of single cell data (RNA). Improvement of phenograph, Paper.\nHypHC - Hyperbolic Hierarchical Clustering.\nBanditPAM - Improved k-Medoids Clustering.\ndendextend - Comparing dendrograms (R package).\nDeepDPM - Deep Clustering With An Unknown Number of Clusters.\nClustering Evalutation\nWagner, Wagner - Comparing Clusterings - An Overview\n* Adjusted Rand Index\n* Normalized Mutual Information\n* Adjusted Mutual Information\n* Fowlkes-Mallows Score\n* Silhouette Coefficient\n* Variation of Information, Julia\n* Pair Confusion Matrix\n* Consensus Score - The similarity of two sets of biclusters.\nAssessing the quality of a clustering (video) \nfpc - Various methods for clustering and cluster validation (R package).\n* Minimum distance between any two clusters\n* Distance between centroids\n* p-separation index: Like minimum distance. Look at the average distance to nearest point in different cluster for p=10% \"border\" points in any cluster. Measuring density, measuring mountains vs valleys\n* Estimate density by weighted count of close points \nOther measures:\n* Within-cluster average distance\n* Mean of within-cluster average distance over nearest-cluster average distance (silhouette score)\n* Within-cluster similarity measure to normal/uniform\n* Within-cluster (squared) distance to centroid (this is the k-Means loss function)\n* Correlation coefficient between distance we originally had to the distance the are induced by the clustering (Huberts Gamma)\n* Entropy of cluster sizes\n* Average largest within-cluster gap\n* Variation of clusterings on bootstrapped data\nMulti-label classification\nscikit-multilearn - Multi-label classification, talk.\nSignal Processing and Filtering\nStanford Lecture Series on Fourier Transformation, Youtube, Lecture Notes.\nVisual fourier explanation.\nThe Scientist & Engineer's Guide to Digital Signal Processing (1999).\nKalman Filter article.\nKalman Filter book - Focuses on intuition using Jupyter Notebooks. Includes Baysian and various Kalman filters.\nInteractive Tool for FIR and IIR filters, Examples.\nfilterpy - Kalman filtering and optimal estimation library.\nGeometry\ngeomstats - Computations and statistics on manifolds with geometric structures.\nTime Series\nstatsmodels - Time series analysis, seasonal decompose example, SARIMA, granger causality.\nkats - Time series prediction library by Facebook.\nprophet - Time series prediction library by Facebook.\nneural_prophet - Time series prediction built on Pytorch.\npyramid, pmdarima - Wrapper for (Auto-) ARIMA.\nmodeltime - Time series forecasting framework (R package).\npyflux - Time series prediction algorithms (ARIMA, GARCH, GAS, Bayesian).\natspy - Automated Time Series Models.\npm-prophet - Time series prediction and decomposition library.\nhtsprophet - Hierarchical Time Series Forecasting using Prophet.\nnupic - Hierarchical Temporal Memory (HTM) for Time Series Prediction and Anomaly Detection.\ntensorflow - LSTM and others, examples: link, link, link, Explain LSTM, seq2seq: 1, 2, 3, 4\ntspreprocess - Preprocessing: Denoising, Compression, Resampling.\ntsfresh - Time series feature engineering.\ntsfel - Time series feature extraction.\nthunder - Data structures and algorithms for loading, processing, and analyzing time series data.\ngatspy - General tools for Astronomical Time Series, talk.\ngendis - shapelets, example.\ntslearn - Time series clustering and classification, TimeSeriesKMeans, TimeSeriesKMeans.\npastas - Simulation of time series.\nfastdtw - Dynamic Time Warp Distance.\nfable - Time Series Forecasting (R package).\npydlm - Bayesian time series modeling (R package, Blog post)\nPyAF - Automatic Time Series Forecasting.\nluminol - Anomaly Detection and Correlation library from Linkedin.\nmatrixprofile-ts - Detecting patterns and anomalies, website, ppt, alternative.\nstumpy - Another matrix profile library.\nobspy - Seismology package. Useful classic_sta_lta function.\nRobustSTL - Robust Seasonal-Trend Decomposition.\nseglearn - Time Series library.\npyts - Time series transformation and classification, Imaging time series.\nTurn time series into images and use Neural Nets: example, example.\nsktime, sktime-dl - Toolbox for (deep) learning with time series. \nadtk - Time Series Anomaly Detection.\nrocket - Time Series classification using random convolutional kernels.\nluminaire - Anomaly Detection for time series.\netna - Time Series library.\nChaos Genius - ML powered analytics engine for outlier/anomaly detection and root cause analysis.\nTime Series Evaluation\nTimeSeriesSplit - Sklearn time series split.\ntscv - Evaluation with gap.\nFinancial Data and Trading\nTutorial on using cvxpy: 1, 2\npandas-datareader - Read stock data.\nyfinance - Read stock data from Yahoo Finance.\nfindatapy - Read stock data from various sources.\nta - Technical analysis library.\nbacktrader - Backtesting for trading strategies.\nsurpriver - Find high moving stocks before they move using anomaly detection and machine learning.\nffn - Financial functions.\nbt - Backtesting algorithms.\nalpaca-trade-api-python - Commission-free trading through API.\neiten - Eigen portfolios, minimum variance portfolios and other algorithmic investing strategies.\ntf-quant-finance - Quantitative finance tools in tensorflow, by Google.\nquantstats - Portfolio management.\nRiskfolio-Lib - Portfolio optimization and strategic asset allocation.\nOpenBBTerminal - Terminal.\nmplfinance - Financial markets data visualization.\nQuantopian Stack\npyfolio - Portfolio and risk analytics.\nzipline - Algorithmic trading.\nalphalens - Performance analysis of predictive stock factors.\nempyrical - Financial risk metrics.\ntrading_calendars - Calendars for various securities exchanges.\nSurvival Analysis\nTime-dependent Cox Model in R.\nlifelines - Survival analysis, Cox PH Regression, talk, talk2.\nscikit-survival - Survival analysis.\nxgboost - \"objective\": \"survival:cox\" NHANES example\nsurvivalstan - Survival analysis, intro.\nconvoys - Analyze time lagged conversions.\nRandomSurvivalForests (R packages: randomForestSRC, ggRandomForests).\npysurvival - Survival analysis.\nDeepSurvivalMachines - Fully Parametric Survival Regression.\nauton-survival - Regression, Counterfactual Estimation, Evaluation and Phenotyping with Censored Time-to-Events.\nOutlier Detection & Anomaly Detection\nsklearn - Isolation Forest and others.\npyod - Outlier Detection / Anomaly Detection.\neif - Extended Isolation Forest.\nAnomalyDetection - Anomaly detection (R package).\nluminol - Anomaly Detection and Correlation library from Linkedin.\nDistances for comparing histograms and detecting outliers - Talk: Kolmogorov-Smirnov, Wasserstein, Energy Distance (Cramer), Kullback-Leibler divergence.\nbanpei - Anomaly detection library based on singular spectrum transformation.\ntelemanom - Detect anomalies in multivariate time series data using LSTMs.\nluminaire - Anomaly Detection for time series.\nConcept Drift & Domain Shift\nTorchDrift - Drift Detection for PyTorch Models.\nalibi-detect - Algorithms for outlier, adversarial and drift detection.\nevidently - Evaluate and monitor ML models from validation to production.\nLipton et al. - Detecting and Correcting for Label Shift with Black Box Predictors.\nBu et al. - A pdf-Free Change Detection Test Based on Density Difference Estimation.\nRanking\nlightning - Large-scale linear classification, regression and ranking.\nScoring\nSLIM - Scoring systems for classification, Supersparse linear integer models.\nCausal Inference\nCS 594 Causal Inference and Learning\nStatistical Rethinking - Video Lecture Series, Bayesian Statistics, Causal Models, R, python, numpyro1, numpyro2, tensorflow-probability.\nPython Causality Handbook\ndowhy - Estimate causal effects.\nCausalImpact - Causal Impact Analysis (R package).\ncausallib - Modular causal inference analysis and model evaluations by IBM, examples.\ncausalml - Causal inference by Uber.\nupliftml - Causal inference by Booking.com.\nEconML - Heterogeneous Treatment Effects Estimation by Microsoft.\ncausality - Causal analysis using observational datasets.\nDoubleML - Machine Learning + Causal inference, Tweet, Presentation, Paper.\nPapers\nBours - Confounding\nBours - Effect Modification and Interaction \nProbabilistic Modeling and Bayes\nIntro, Guide\nPyMC3 - Bayesian modelling, intro\nnumpyro - Probabilistic programming with numpy, built on pyro.\npomegranate - Probabilistic modelling, talk.\npmlearn - Probabilistic machine learning.\narviz - Exploratory analysis of Bayesian models.\nzhusuan - Bayesian deep learning, generative models.\nedward - Probabilistic modeling, inference, and criticism, Mixture Density Networks (MNDs), MDN Explanation.\nPyro - Deep Universal Probabilistic Programming.\ntensorflow probability - Deep learning and probabilistic modelling, talk1, notebook talk1, talk2, example.\nbambi - High-level Bayesian model-building interface on top of PyMC3.\nneural-tangents - Infinite Neural Networks.\nbnlearn - Bayesian networks, parameter learning, inference and sampling methods.\nGaussian Processes\nVisualization, Article\nGPyOpt - Gaussian process optimization. \nGPflow - Gaussian processes (Tensorflow).\ngpytorch - Gaussian processes (Pytorch).\nStacking Models and Ensembles\nModel Stacking Blog Post\nmlxtend - EnsembleVoteClassifier, StackingRegressor, StackingCVRegressor for model stacking.\nvecstack - Stacking ML models.\nStackNet - Stacking ML models.\nmlens - Ensemble learning.\ncombo - Combining ML models (stacking, ensembling).\nModel Evaluation\npycm - Multi-class confusion matrix.\npandas_ml - Confusion matrix.\nPlotting learning curve: link.\nyellowbrick - Learning curve.\npyroc - Receiver Operating Characteristic (ROC) curves.\nModel Uncertainty\nawesome-conformal-prediction - Uncertainty quantification.\nuncertainty-toolbox - Predictive uncertainty quantification, calibration, metrics, and visualization.\nInterpretable Classifiers and Regressors\nskope-rules - Interpretable classifier, IF-THEN rules.\nsklearn-expertsys - Interpretable classifiers, Bayesian Rule List classifier.\nModel Explanation, Interpretability, Feature Importance\nPrinceton - Reproducibility Crisis in ML\u2011based Science \nBook, Examples\nshap - Explain predictions of machine learning models, talk, Good Shap intro.\ntreeinterpreter - Interpreting scikit-learn's decision tree and random forest predictions.\nlime - Explaining the predictions of any machine learning classifier, talk, Warning (Myth 7).\nlime_xgboost - Create LIMEs for XGBoost.\neli5 - Inspecting machine learning classifiers and explaining their predictions.\nlofo-importance - Leave One Feature Out Importance, talk, examples: 1, 2, 3.\npybreakdown - Generate feature contribution plots.\npycebox - Individual Conditional Expectation Plot Toolbox.\npdpbox - Partial dependence plot toolbox, example.\npartial_dependence - Visualize and cluster partial dependence.\nskater - Unified framework to enable model interpretation.\nanchor - High-Precision Model-Agnostic Explanations for classifiers.\nl2x - Instancewise feature selection as methodology for model interpretation.\ncontrastive_explanation - Contrastive explanations.\nDrWhy - Collection of tools for explainable AI.\nlucid - Neural network interpretability.\nxai - An eXplainability toolbox for machine learning.\ninnvestigate - A toolbox to investigate neural network predictions.\ndalex - Explanations for ML models (R package).\ninterpretml - Fit interpretable models, explain models.\nshapash - Model interpretability.\nimodels - Interpretable ML package.\ncaptum - Model interpretability and understanding for PyTorch.\nAutomated Machine Learning\nAdaNet - Automated machine learning based on tensorflow.\ntpot - Automated machine learning tool, optimizes machine learning pipelines.\nauto_ml - Automated machine learning for analytics & production.\nautokeras - AutoML for deep learning.\nnni - Toolkit for neural architecture search and hyper-parameter tuning by Microsoft.\nautoml-gs - Automated machine learning.\nmljar - Automated machine learning.\nautoml_zero - Automatically discover computer programs that can solve machine learning tasks from Google.\nAlphaPy - Automated Machine Learning using scikit-learn xgboost, LightGBM and others.\nGraph Representation Learning\nKarate Club - Unsupervised learning on graphs. \nPytorch Geometric - Graph representation learning with PyTorch. \nDLG - Graph representation learning with TensorFlow. \nConvex optimization\ncvxpy - Modeling language for convex optimization problems. Tutorial: 1, 2 \nEvolutionary Algorithms & Optimization\ndeap - Evolutionary computation framework (Genetic Algorithm, Evolution strategies).\nevol - DSL for composable evolutionary algorithms, talk.\nplatypus - Multiobjective optimization.\nautograd - Efficiently computes derivatives of numpy code.\nnevergrad - Derivation-free optimization.\ngplearn - Sklearn-like interface for genetic programming.\nblackbox - Optimization of expensive black-box functions.\nOptometrist algorithm - paper.\nDeepSwarm - Neural architecture search.\nevotorch - Evolutionary computation library built on Pytorch.\nHyperparameter Tuning\nsklearn - GridSearchCV, RandomizedSearchCV.\nsklearn-deap - Hyperparameter search using genetic algorithms.\nhyperopt - Hyperparameter optimization.\nhyperopt-sklearn - Hyperopt + sklearn.\noptuna - Hyperparamter optimization, Talk.\nskopt - BayesSearchCV for Hyperparameter search.\ntune - Hyperparameter search with a focus on deep learning and deep reinforcement learning.\nhypergraph - Global optimization methods and hyperparameter optimization.\nbbopt - Black box hyperparameter optimization.\ndragonfly - Scalable Bayesian optimisation.\nbotorch - Bayesian optimization in PyTorch.\nax - Adaptive Experimentation Platform by Facebook.\nlightning-hpo - Hyperparameter optimization based on optuna.\nIncremental Learning, Online Learning\nsklearn - PassiveAggressiveClassifier, PassiveAggressiveRegressor.\nriver - Online machine learning.\nKaggler - Online Learning algorithms.\nonelearn - Online Random Forests.\nActive Learning\nTalk\nmodAL - Active learning framework.\nReinforcement Learning\nYouTube, YouTube\nIntro to Monte Carlo Tree Search (MCTS) - 1, 2, 3\nAlphaZero methodology - 1, 2, 3, Cheat Sheet\nRLLib - Library for reinforcement learning.\nHorizon - Facebook RL framework.\nDeployment and Lifecycle Management\nWorkflow Scheduling and Orchestration\nairflow - Schedule and monitor workflows.\nprefect - Python specific workflow scheduling.\ndagster - Development, production and observation of data assets.\nploomber - Workflow orchestration.\nkestra - Workflow orchestration.\ncml - CI/CD for Machine Learning Projects.\nrocketry - Task scheduling.\nContainerization and Docker\nReduce size of docker images (video)\nOptimize Docker Image Size\ncog - Facilitates building Docker images.\nDependency Management\ndephell - Dependency management.\npoetry - Dependency management.\npyup - Dependency management.\npypi-timemachine - Install packages with pip as if you were in the past.\nData Versioning, Databases, Pipelines and Model Serving\ndvc - Version control for large files.\nhangar - Version control for tensor data.\nkedro - Build data pipelines.\nfeast - Feature store. Video.\npinecone - Database for vector search applications.\ntruss - Serve ML models.\nmilvus - Vector database for similarity search.\nmlem - Version and deploy your ML models following GitOps principles.\nData Science Related\nm2cgen - Transpile trained ML models into other languages.\nsklearn-porter - Transpile trained scikit-learn estimators to C, Java, JavaScript and others.\nmlflow - Manage the machine learning lifecycle, including experimentation, reproducibility and deployment.\nmodelchimp - Experiment Tracking.\nskll - Command-line utilities to make it easier to run machine learning experiments.\nBentoML - Package and deploy machine learning models for serving in production.\ndagster - Tool with focus on dependency graphs.\nknockknock - Be notified when your training ends.\nmetaflow - Lifecycle Management Tool by Netflix.\ncortex - Deploy machine learning models.\nNeptune - Experiment tracking and model registry.\nclearml - Experiment Manager, MLOps and Data-Management.\npolyaxon - MLOps.\nsematic - Deploy machine learning models.\nzenml - MLOPs.\nMath and Background\nAll kinds of math and statistics resources\nGilbert Strang - Linear Algebra\nGilbert Strang - Matrix Methods in Data Analysis, Signal Processing, and Machine Learning\nOther\ndaft - Render probabilistic graphical models using matplotlib.\nunyt - Working with units.\nscrapy - Web scraping library.\nVowpalWabbit - ML Toolkit from Microsoft.\nPython Record Linkage Toolkit - link records in or between data sources. \nGeneral Python Programming\nmore_itertools - Extension of itertools.\nfuncy - Fancy and practical functional tools.\ndateparser - A better date parser.\njellyfish - Approximate string matching. \ncoloredlogs - Colored logging output.  \nResources\nDistill.pub - Blog. \nMachine Learning Videos\nData Science Notebooks\nRecommender Systems (Microsoft)\nDatascience Cheatsheets \nGuidelines\ndatasharing - Guide to data sharing.\nBooks\nChan - Introduction to Probability for Data Science\nColonescu - Principles of Econometrics with R \nOther Awesome Lists\nAwesome Adversarial Machine Learning \nAwesome AI Booksmarks \nAwesome AI on Kubernetes \nAwesome Big Data \nAwesome Business Machine Learning \nAwesome Causality \nAwesome Community Detection \nAwesome CSV\nAwesome Cytodata\nAwesome Data Science with Ruby \nAwesome Dash \nAwesome Decision Trees \nAwesome Deep Learning \nAwesome ETL \nAwesome Financial Machine Learning \nAwesome Fraud Detection \nAwesome GAN Applications \nAwesome Graph Classification \nAwesome Industry Machine Learning\nAwesome Gradient Boosting \nAwesome Learning with Label Noise\nAwesome Machine Learning \nAwesome Machine Learning Books\nAwesome Machine Learning Interpretability \nAwesome Machine Learning Operations \nAwesome Metric Learning\nAwesome Monte Carlo Tree Search \nAwesome Neural Network Visualization\nAwesome Online Machine Learning\nAwesome Pipeline\nAwesome Public APIs\nAwesome Python \nAwesome Python Data Science \nAwesome Python Data Science\nAwesome Python Data Science\nAwesome Pytorch\nAwesome Quantitative Finance\nAwesome Recommender Systems\nAwesome Semantic Segmentation\nAwesome Sentence Embedding\nAwesome Time Series\nAwesome Time Series Anomaly Detection\nAwesome Visual Attentions\nAwesome Visual Transformer \nLectures\nNYU Deep Learning SP21 - Youtube Playlist. \nThings I google a lot\nColor codes\nFrequency codes for time series\nDate parsing codes\nFeature Calculators tsfresh \nContributing\nDo you know a package that should be on this list? Did you spot a package that is no longer maintained and should be removed from this list? Then feel free to read the contribution guidelines and submit your pull request or create a new issue.\nLicense",
	"apriori classification clustering data-mining feature-engineering flink flink-machine-learning flink-ml fm graph-algorithms graph-embedding kafka machine-learning recommender recommender-system regression statistics word2vec xgboost": "English| \u7b80\u4f53\u4e2d\u6587\nAlink\nAlink\u662f\u57fa\u4e8eFlink\u7684\u901a\u7528\u7b97\u6cd5\u5e73\u53f0,\u7531\u963f\u91cc\u5df4\u5df4\u8ba1\u7b97\u5e73\u53f0PAI\u56e2\u961f\u7814\u53d1,\u6b22\u8fce\u5927\u5bb6\u52a0\u5165Alink\u5f00\u6e90\u7528\u6237\u9489\u9489\u7fa4\u8fdb\u884c\u4ea4\u6d41\u3002\nAlink\u7ec4\u4ef6\u5217\u8868\uff1ahttp://alinklab.cn/manual/index.html\nAlink\u6559\u7a0b\uff1ahttp://alinklab.cn/tutorial/index.html\nAlink\u63d2\u4ef6\u4e0b\u8f7d\u5668\uff1ahttps://www.yuque.com/pinshu/alink_guide/plugin_downloader\nAlink\u6559\u7a0b\nAlink\u6559\u7a0b\uff08Java\u7248\uff09\uff1ahttp://alinklab.cn/tutorial/book_java.html\nAlink\u6559\u7a0b\uff08Python\u7248\uff09\uff1ahttp://alinklab.cn/tutorial/book_python.html\n\u6e90\u4ee3\u7801\u5730\u5740\uff1ahttps://github.com/alibaba/Alink/tree/master/tutorial\nJava\u7248\u7684\u6570\u636e\u548c\u8d44\u6599\u94fe\u63a5\uff1ahttp://alinklab.cn/tutorial/book_java_00_reference.html\nPython\u7248\u7684\u6570\u636e\u548c\u8d44\u6599\u94fe\u63a5\uff1ahttp://alinklab.cn/tutorial/book_python_00_reference.html\nAlink\u6559\u7a0b(Java\u7248)\u4ee3\u7801\u7684\u8fd0\u884c\u653b\u7565  http://alinklab.cn/tutorial/book_java_00_code_help.html\nAlink\u6559\u7a0b(Python\u7248)\u4ee3\u7801\u7684\u8fd0\u884c\u653b\u7565  http://alinklab.cn/tutorial/book_python_00_code_help.html\n\u5f00\u6e90\u7b97\u6cd5\u5217\u8868\nPyAlink \u4f7f\u7528\u622a\u56fe\n\u5feb\u901f\u5f00\u59cb\nPyAlink \u4f7f\u7528\u4ecb\u7ecd\n\u4f7f\u7528\u524d\u51c6\u5907\uff1a\n\u5305\u540d\u548c\u7248\u672c\u8bf4\u660e\uff1a\nPyAlink \u6839\u636e Alink \u6240\u652f\u6301\u7684 Flink \u7248\u672c\u63d0\u4f9b\u4e0d\u540c\u7684 Python \u5305\uff1a\n\u5176\u4e2d\uff0cpyalink \u5305\u5bf9\u5e94\u4e3a Alink \u6240\u652f\u6301\u7684\u6700\u65b0 Flink \u7248\u672c\uff0c\u5f53\u524d\u4e3a 1.13\uff0c\u800c pyalink-flink-*** \u4e3a\u65e7\u7248\u672c\u7684 Flink \u7248\u672c\uff0c\u5f53\u524d\u63d0\u4f9b pyalink-flink-1.12, pyalink-flink-1.11, pyalink-flink-1.10 \u548c pyalink-flink-1.9\u3002\nPython \u5305\u7684\u7248\u672c\u53f7\u4e0e Alink \u7684\u7248\u672c\u53f7\u4e00\u81f4\uff0c\u4f8b\u59821.6.0\u3002\n\u5b89\u88c5\u6b65\u9aa4\uff1a\n\u786e\u4fdd\u4f7f\u7528\u73af\u5883\u4e2d\u6709Python3\uff0c\u7248\u672c\u9650\u4e8e 3.6\uff0c3.7 \u548c 3.8\u3002\n\u786e\u4fdd\u4f7f\u7528\u73af\u5883\u4e2d\u5b89\u88c5\u6709 Java 8\u3002\n\u4f7f\u7528 pip \u547d\u4ee4\u8fdb\u884c\u5b89\u88c5\uff1a\n  pip install pyalink\u3001pip install pyalink-flink-1.12\u3001pip install pyalink-flink-1.11\u3001pip install pyalink-flink-1.10 \u6216\u8005 pip install pyalink-flink-1.9\u3002\n\u5b89\u88c5\u6ce8\u610f\u4e8b\u9879\uff1a\npyalink \u548c pyalink-flink- \u4e0d\u80fd\u540c\u65f6\u5b89\u88c5\uff0c\u4e5f\u4e0d\u80fd\u4e0e\u65e7\u7248\u672c\u540c\u65f6\u5b89\u88c5\u3002\n\u5982\u679c\u4e4b\u524d\u5b89\u88c5\u8fc7 pyalink \u6216\u8005 pyalink-flink-\uff0c\u8bf7\u4f7f\u7528pip uninstall pyalink \u6216\u8005 pip uninstall pyalink-flink-*** \u5378\u8f7d\u4e4b\u524d\u7684\u7248\u672c\u3002\n\u51fa\u73b0pip\u5b89\u88c5\u7f13\u6162\u6216\u4e0d\u6210\u529f\u7684\u60c5\u51b5\uff0c\u53ef\u4ee5\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0\u4fee\u6539pip\u6e90\uff0c\u6216\u8005\u76f4\u63a5\u4f7f\u7528\u4e0b\u9762\u7684\u94fe\u63a5\u4e0b\u8f7d whl \u5305\uff0c\u7136\u540e\u4f7f\u7528 pip \u5b89\u88c5\uff1a\nFlink 1.13\uff1a\u94fe\u63a5 (MD5: ed775a565071b181bbc708dd775a665b)\nFlink 1.12\uff1a\u94fe\u63a5 (MD5: 95a98d056cfdb68245cfe4ee982112d1)\nFlink 1.11\uff1a\u94fe\u63a5 (MD5: 8d88d16b01bc58bc932d46c607123670)\nFlink 1.10\uff1a\u94fe\u63a5 (MD5: 7b8477fe7cfb38e9e06b8b5e7c3eca4d)\nFlink 1.9: \u94fe\u63a5 (MD5: 404f0c6f7ea061ca8ad5de5278f0fa8b)\n\u5982\u679c\u6709\u591a\u4e2a\u7248\u672c\u7684 Python\uff0c\u53ef\u80fd\u9700\u8981\u4f7f\u7528\u7279\u5b9a\u7248\u672c\u7684 pip\uff0c\u6bd4\u5982 pip3\uff1b\u5982\u679c\u4f7f\u7528 Anaconda\uff0c\u5219\u9700\u8981\u5728 Anaconda \u547d\u4ee4\u884c\u4e2d\u8fdb\u884c\u5b89\u88c5\u3002\n\u5f00\u59cb\u4f7f\u7528\uff1a\n\u53ef\u4ee5\u901a\u8fc7 Jupyter Notebook \u6765\u5f00\u59cb\u4f7f\u7528 PyAlink\uff0c\u80fd\u83b7\u5f97\u66f4\u597d\u7684\u4f7f\u7528\u4f53\u9a8c\u3002\n\u4f7f\u7528\u6b65\u9aa4\uff1a\n1. \u5728\u547d\u4ee4\u884c\u4e2d\u542f\u52a8Jupyter\uff1ajupyter notebook\uff0c\u5e76\u65b0\u5efa Python 3 \u7684 Notebook \u3002\n2. \u5bfc\u5165 pyalink \u5305\uff1afrom pyalink.alink import \u3002\n3. \u4f7f\u7528\u65b9\u6cd5\u521b\u5efa\u672c\u5730\u8fd0\u884c\u73af\u5883\uff1a\nuseLocalEnv(parallism, flinkHome=None, config=None)\u3002\n\u5176\u4e2d\uff0c\u53c2\u6570 parallism \u8868\u793a\u6267\u884c\u6240\u4f7f\u7528\u7684\u5e76\u884c\u5ea6\uff1bflinkHome \u4e3a flink \u7684\u5b8c\u6574\u8def\u5f84\uff0c\u4e00\u822c\u60c5\u51b5\u4e0d\u9700\u8981\u8bbe\u7f6e\uff1bconfig\u4e3aFlink\u6240\u63a5\u53d7\u7684\u914d\u7f6e\u53c2\u6570\u3002\u8fd0\u884c\u540e\u51fa\u73b0\u5982\u4e0b\u6240\u793a\u7684\u8f93\u51fa\uff0c\u8868\u793a\u521d\u59cb\u5316\u8fd0\u884c\u73af\u5883\u6210\u529f\uff1a\nJVM listening on **\n4. \u5f00\u59cb\u7f16\u5199 PyAlink \u4ee3\u7801\uff0c\u4f8b\u5982\uff1a\npython\nsource = CsvSourceBatchOp()\\\n    .setSchemaStr(\"sepal_length double, sepal_width double, petal_length double, petal_width double, category string\")\\\n    .setFilePath(\"https://alink-release.oss-cn-beijing.aliyuncs.com/data-files/iris.csv\")\nres = source.select([\"sepal_length\", \"sepal_width\"])\ndf = res.collectToDataframe()\nprint(df)\n\u7f16\u5199\u4ee3\u7801\uff1a\n\u5728 PyAlink \u4e2d\uff0c\u7b97\u6cd5\u7ec4\u4ef6\u63d0\u4f9b\u7684\u63a5\u53e3\u57fa\u672c\u4e0e Java API \u4e00\u81f4\uff0c\u5373\u901a\u8fc7\u9ed8\u8ba4\u6784\u9020\u65b9\u6cd5\u521b\u5efa\u4e00\u4e2a\u7b97\u6cd5\u7ec4\u4ef6\uff0c\u7136\u540e\u901a\u8fc7 setXXX \u8bbe\u7f6e\u53c2\u6570\uff0c\u901a\u8fc7 link/linkTo/linkFrom \u4e0e\u5176\u4ed6\u7ec4\u4ef6\u76f8\u8fde\u3002\n\u8fd9\u91cc\u5229\u7528 Jupyter Notebook \u7684\u81ea\u52a8\u8865\u5168\u673a\u5236\u53ef\u4ee5\u63d0\u4f9b\u4e66\u5199\u4fbf\u5229\u3002\n\u5bf9\u4e8e\u6279\u5f0f\u4f5c\u4e1a\uff0c\u53ef\u4ee5\u901a\u8fc7\u6279\u5f0f\u7ec4\u4ef6\u7684 print/collectToDataframe/collectToDataframes \u7b49\u65b9\u6cd5\u6216\u8005 BatchOperator.execute() \u6765\u89e6\u53d1\u6267\u884c\uff1b\u5bf9\u4e8e\u6d41\u5f0f\u4f5c\u4e1a\uff0c\u5219\u901a\u8fc7 StreamOperator.execute() \u6765\u542f\u52a8\u4f5c\u4e1a\u3002\n\u66f4\u591a\u7528\u6cd5\uff1a\nDataFrame \u4e0e Operator \u4e92\u8f6c\nStreamOperator \u6570\u636e\u9884\u89c8\nUDF/UDTF/SQL \u4f7f\u7528\n\u4e0e PyFlink \u4e00\u540c\u4f7f\u7528\nPyAlink \u5e38\u89c1\u95ee\u9898\nJava \u63a5\u53e3\u4f7f\u7528\u4ecb\u7ecd\n\u793a\u4f8b\u4ee3\u7801\njava\nString URL = \"https://alink-release.oss-cn-beijing.aliyuncs.com/data-files/iris.csv\";\nString SCHEMA_STR = \"sepal_length double, sepal_width double, petal_length double, petal_width double, category string\";\nBatchOperator data = new CsvSourceBatchOp()\n        .setFilePath(URL)\n        .setSchemaStr(SCHEMA_STR);\nVectorAssembler va = new VectorAssembler()\n        .setSelectedCols(new String[]{\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"})\n        .setOutputCol(\"features\");\nKMeans kMeans = new KMeans().setVectorCol(\"features\").setK(3)\n        .setPredictionCol(\"prediction_result\")\n        .setPredictionDetailCol(\"prediction_detail\")\n        .setReservedCols(\"category\")\n        .setMaxIter(100);\nPipeline pipeline = new Pipeline().add(va).add(kMeans);\npipeline.fit(data).transform(data).print();\nFlink-1.13 \u7684 Maven \u4f9d\u8d56\nxml\n\ncom.alibaba.alink\nalink_core_flink-1.13_2.11\n1.6.0\n\n\norg.apache.flink\nflink-streaming-scala_2.11\n1.13.0\n\n\norg.apache.flink\nflink-table-planner_2.11\n1.13.0\n\n\norg.apache.flink\nflink-clients_2.11\n1.13.0\n\nFlink-1.12 \u7684 Maven \u4f9d\u8d56\nxml\n\ncom.alibaba.alink\nalink_core_flink-1.12_2.11\n1.6.0\n\n\norg.apache.flink\nflink-streaming-scala_2.11\n1.12.1\n\n\norg.apache.flink\nflink-table-planner_2.11\n1.12.1\n\n\norg.apache.flink\nflink-clients_2.11\n1.12.1\n\nFlink-1.11 \u7684 Maven \u4f9d\u8d56\nxml\n\ncom.alibaba.alink\nalink_core_flink-1.11_2.11\n1.6.0\n\n\norg.apache.flink\nflink-streaming-scala_2.11\n1.11.0\n\n\norg.apache.flink\nflink-table-planner_2.11\n1.11.0\n\n\norg.apache.flink\nflink-clients_2.11\n1.11.0\n\nFlink-1.10 \u7684 Maven \u4f9d\u8d56\nxml\n\ncom.alibaba.alink\nalink_core_flink-1.10_2.11\n1.6.0\n\n\norg.apache.flink\nflink-streaming-scala_2.11\n1.10.0\n\n\norg.apache.flink\nflink-table-planner_2.11\n1.10.0\n\nFlink-1.9 \u7684 Maven \u4f9d\u8d56\nxml\n\ncom.alibaba.alink\nalink_core_flink-1.9_2.11\n1.6.0\n\n\norg.apache.flink\nflink-streaming-scala_2.11\n1.9.0\n\n\norg.apache.flink\nflink-table-planner_2.11\n1.9.0\n\n\u5feb\u901f\u5f00\u59cb\u5728\u96c6\u7fa4\u4e0a\u8fd0\u884cAlink\u7b97\u6cd5\n\u51c6\u5907Flink\u96c6\u7fa4\nshell\n  wget https://archive.apache.org/dist/flink/flink-1.13.0/flink-1.13.0-bin-scala_2.11.tgz\n  tar -xf flink-1.13.0-bin-scala_2.11.tgz && cd flink-1.13.0\n  ./bin/start-cluster.sh\n\u51c6\u5907Alink\u7b97\u6cd5\u5305\nshell\n  git clone https://github.com/alibaba/Alink.git\n  # add provided in pom.xml of alink_examples.\n  cd Alink && mvn -Dmaven.test.skip=true clean package shade:shade\n\u8fd0\u884cJava\u793a\u4f8b\nshell\n  ./bin/flink run -p 1 -c com.alibaba.alink.ALSExample [path_to_Alink]/examples/target/alink_examples-1.5-SNAPSHOT.jar\n  # ./bin/flink run -p 1 -c com.alibaba.alink.GBDTExample [path_to_Alink]/examples/target/alink_examples-1.5-SNAPSHOT.jar\n  # ./bin/flink run -p 1 -c com.alibaba.alink.KMeansExample [path_to_Alink]/examples/target/alink_examples-1.5-SNAPSHOT.jar\n\u90e8\u7f72\n\u96c6\u7fa4\u90e8\u7f72",
	"accountability awesome awesome-list data-mining data-science explainable-ml fairness fatml iml interpretability interpretable-ai interpretable-deep-learning interpretable-machine-learning interpretable-ml machine-learning machine-learning-interpretability python r transparency xai": "awesome-machine-learning-interpretability \nA curated, but probably biased and incomplete, list of awesome machine learning interpretability resources.\nIf you want to contribute to this list (and please do!) read over the contribution guidelines, send a pull request, or contact me @jpatrickhall.\nAn incomplete, imperfect blueprint for a more human-centered, lower-risk machine learning. The resources in this repository can be used to do many of these things today. The resources in this repository should not be considered legal compliance advice.\nImage credit: H2O.ai Machine Learning Interpretability team, https://github.com/h2oai/mli-resources.\nTable of Contents\nComprehensive Software Examples and Tutorials\nExplainability- or Fairness-Enhancing Software Packages\nBrowser\nPython\nR\nMachine learning environment management tools\nFree Books\nGovernment and Regulatory Documents\nOther Interpretability and Fairness Resources and Lists\nReview and General Papers\nClasses\nInterpretable (\"Whitebox\") or Fair Modeling Packages\nC/C++\nPython\nR\nAI Incident Tracker\nComprehensive Software Examples and Tutorials\nCOMPAS Analysis Using Aequitas\nExplaining Quantitative Measures of Fairness (with SHAP)\nGetting a Window into your Black Box Model\nFrom GLM to GBM Part 1\nFrom GLM to GBM Part 2\nIML\nInterpretable Machine Learning with Python\nInterpreting Machine Learning Models with the iml Package\nInterpretable Machine Learning using Counterfactuals\nMachine Learning Explainability by Kaggle Learn\nModel Interpretability with DALEX\nModel Interpretation series by Dipanjan (DJ) Sarkar:\nThe Importance of Human Interpretable Machine Learning\nModel Interpretation Strategies\nHands-on Machine Learning Model Interpretation\nInterpreting Deep Learning Models for Computer Vision\nPartial Dependence Plots in R\nSaliency Maps for Deep Learning\nVisualizing ML Models with LIME\nVisualizing and debugging deep convolutional networks\nWhat does a CNN see?\nExplainability- or Fairness-Enhancing Software Packages\nBrowser\nDiscriLens\nmanifold\nTensorBoard Projector\nWhat-if Tool\nPython\nacd\naequitas\nAI Fairness 360\nAI Explainability 360\nALEPython\nAletheia\nallennlp\nalgofairness\nAlibi\nanchor\nBlackBoxAuditing\ncasme\nCausal Discovery Toolbox\ncaptum\ncausalml\ncdt15\nchecklist\ncontextual-AI\nContrastiveExplanation (Foil Trees)\ncounterfit\ndalex\ndebiaswe\nDeepExplain\ndeeplift\ndeepvis\nDiCE\nDoWhy\necco\neli5\nexplainerdashboard\nfairml\nfairlearn\nfairness-comparison\nfairness_measures_code\nfoolbox\nGrad-CAM (GitHub topic)\ngplearn\nhate-functional-tests\nimodels\niNNvestigate neural nets\nIntegrated-Gradients\ninterpret\ninterpret_with_rules\nimodels\nKeras-vis\nkeract\nL2X\nlime\nLiFT\nlit\nlofo-importance\nlrp_toolbox\nMindsDB\nMLextend\nml-fairness-gym\nml_privacy_meter\nOptBinning\nparity-fairness\nPDPbox\npyBreakDown\nPyCEbox\npyGAM\npymc3\npytorch-innvestigate\nrationale\nresponsibly\nrevise-tool\nrobustness\nRISE\nsage\nSALib\nscikit-fairness\nshap\nshapley\nSkater\ntensorfow/cleverhans\ntensorflow/lucid\ntensorflow/fairness-indicators\ntensorflow/model-analysis\ntensorflow/model-card-toolkit\ntensorflow/model-remediation\ntensorflow/privacy\ntensorflow/tcav\ntensorfuzz\nTensorWatch\nTextFooler\ntf-explain\nThemis\nthemis-ml\ntreeinterpreter\nwoe\nxai\nxdeep\nyellowbrick\nR\naif360\nALEPlot\nDrWhyAI\nDALEX\nDALEXtra\nEloML\nExplainPrediction\nfastshap\nfairness\nfairmodels\nfeatureImportance\nflashlight\nforestmodel\nfscaret\niBreakDown\nICEbox\niml\ningredients\nintepret\nlightgbmExplainer\nlime\nlive\nmcr\nmodelDown\nmodelOriented\nmodelStudio\npdp\nshapFlex\nshapleyR\nshapper\nsmbinning\nvip\nxgboostExplainer\nMachine learning environment management tools\ndvc\ngigantum\nmlflow\nmlmd\nmodeldb\nwhylabs\nFree Books\nAn Introduction to Machine Learning Interpretability\nExplanatory Model Analysis\nFairness and Machine Learning\nInterpretable Machine Learning\nResponsible Machine Learning (requires email for now)\nGovernment and Regulatory Documents\n12 CFR Part 1002 - Equal Credit Opportunity Act (Regulation B)\nA Regulatory Framework for AI: Recommendations for PIPEDA Reform\nAI Principles: Recommendations on the Ethical Use of Artificial Intelligence by the Department of Defense\nTHE AIM INITIATIVE\nAiming for truth, fairness, and equity in your company\u2019s use of AI\nAlgorithmic Accountability Act of 2019\nALGORITHM CHARTER FOR AOTEAROA NEW ZEALAND\nArtificial Intelligence (AI) in the Securities Industry\nArticle 22 EU GDPR\nAssessment List for Trustworthy Artificial Intelligence (ALTAI) for self-assessment - Shaping Europe\u2019s digital future - European Commission\nAudit of Governance and Protection of Department of Defense Artificial Intelligence Data and Technology\nA Primer on Artificial Intelligence in Securities Markets\nBiometric Information Privacy Act\nBooker Wyden Health Care Letters\nCalifornia Consumer Privacy Act (CCPA)\nCalifornia Privacy Rights Act (CPRA)\nConsultation on the OPC\u2019s Proposals for ensuring appropriate regulation of artificial intelligence\nCivil liability regime for artificial intelligence\nData Ethics Framework\nDEVELOPING FINANCIAL SECTOR RESILIENCE IN A DIGITAL WORLD: SELECTED THEMES IN TECHNOLOGY AND RELATED RISKS\nDirective on Automated Decision Making\nExecutive Order on Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government\nEEOC Letter (from U.S. senators re: hiring software)\nFacial Recognition and Biometric Technology Moratorium Act of 2020\nFour Principles of Explainable Artificial Intelligence \nGeneral principles for the use of Artificial Intelligence in the financial sector\nGouvernance des algorithmes d\u2019intelligence artificielle dans le secteur financier (French)\nInnovation spotlight: Providing adverse action notices when using AI/ML models\nOffice of Management and Budget Guidance for Regulation of Artificial Intelligence Applications (Finalized Nov. 2020)\nOn Artificial Intelligence - A European approach to excellence and trust\nOpinion of the German Data Ethics Commission\nPrinciples of Artificial Intelligence Ethics for the Intelligence Community\nProposal for a Regulation laying down harmonised rules on artificial intelligence (Artificial Intelligence Act)\nPsychological Foundations of Explainability and Interpretability in Artificial Intelligence\nQuestions and Answers to Clarify and Provide a Common Interpretation of the Uniform Guidelines on Employee Selection Procedures\nQuestions from the Commission on Protecting Privacy and Preventing Discrimination\nRE: Use of External Consumer Data and Information Sources in Underwriting for Life Insurance\nSingapore Personal Data Protection Commission (PDPC) Model Artificial Intelligence Governance Framework\nSUPERVISORY GUIDANCE ON MODEL RISK MANAGEMENT\nU.K. Information Commissioner's Office (ICO) AI Audting Framework (overview series)\nArtificial Intelligence/Machine Learning (AI/ML)-Based: Software as a Medical Device (SaMD) Action Plan (Updated Jan. 2021)\nU.S. House of Representatives Resolution on AI Strategy\nUsing Artificial Intelligence and Algorithms\nOther Interpretability and Fairness Resources and Lists\n8 Principles of Responsible ML\nACM FAT* 2019 Youtube Playlist\nAdversarial ML Threat Matrix\nAI Tools and Platforms\nAI Ethics Guidelines Global Inventory\nAI Incident Database\nAllenNLP Interpret: A Framework for Explaining Predictions of NLP Models\nAlgorithms and prejudice\nAwesome interpretable machine learning ;)\nAwesome machine learning operations\nAwful AI\nalgoaware\nBIML Interactive Machine Learning Risk Framework\nBeyond Explainability: A Practical Guide to Managing Risk in Machine Learning Models\ncriticalML\nData Feminism\nDealing with Bias and Fairness in AI/ML/Data Science Systems\nDebugging Machine Learning Models (ICLR workshop proceedings)\nDecision Points in AI Governance\nDe-identification Tools\nDeep Insights into Explainability and Interpretability of Machine Learning Algorithms and Applications to Risk Management\nDistill\nFaces in the Wild Benchmark Data\nFairness, Accountability, and Transparency in Machine Learning (FAT/ML) Scholarship\nFrom Principles to Practice: An interdisciplinary framework to operationalise AI ethics\nHow will the GDPR impact machine learning?\nMachine Learning Ethics References\nMachine Learning Interpretability Resources\nMachine Learning: Considerations for fairly and transparently expanding access to credit\nMIT AI Ethics Reading Group\nOn the Responsibility of Technologists: A Prologue and Primer\nprivate-ai-resources\nProblems with Shapley-value-based explanations as feature importance measures\nReal-World Model Debugging Strategies\nResponsibleAI\nRobust ML\nSafe and Reliable Machine Learning\nSample AI Incident Response Checklist\nTen Questions on AI Risk\nTesting and Debugging in Machine Learning\nTroubleshooting Deep Neural Networks\nWarning Signs: The Future of Privacy and Security in an Age of Machine Learning\nWhen Not to Trust Your Explanations\nXAI Resources\nYou Created A Machine Learning Application Now Make Sure It's Secure\nReview and General Papers\n50 Years of Test (Un)fairness: Lessons for Machine Learning\nA Comparative Study of Fairness-Enhancing Interventions in Machine Learning\nA Survey Of Methods For Explaining Black Box Models\nA Marauder\u2019s Map of Security and Privacy in Machine Learning\nChallenges for Transparency\nClosing the AI Accountability Gap\nExplaining by Removing: A Unified Framework for Model Explanation\nExplaining Explanations: An Overview of Interpretability of Machine Learning\nExplanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI\nInterpretable Machine Learning: Definitions, Methods, and Applications\nLimitations of Interpretable Machine Learning\nMachine Learning Explainability in Finance\nOn the Art and Science of Machine Learning Explanations\nPlease Stop Explaining Black Box Models for High-Stakes Decisions\nSoftware Engineering for Machine Learning: A Case Study\nThe Mythos of Model Interpretability\nTowards A Rigorous Science of Interpretable Machine Learning\nToward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims\nThe Security of Machine Learning\nTechniques for Interpretable Machine Learning\nTrends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda\nUnderspecification Presents Challenges for Credibility in Modern Machine Learning\nClasses\nAn Introduction to Data Ethics\nCertified Ethical Emerging Technologist\nFairness in Machine Learning\nFast.ai Data Ethics course\nHuman-Center Machine Learning\nIntroduction to Responsible Machine Learning\nTrustworthy Deep Learning\nInterpretable (\"Whitebox\") or Fair Modeling Packages\nC/C++\nBorn-again Tree Ensembles\nCertifiably Optimal RulE ListS\nPython\nBayesian Case Model\nBayesian Ors-Of-Ands\nBayesian Rule List (BRL)\nExplainable Boosting Machine (EBM)/GA2M\nfair-classification\nFalling Rule List (FRL)\nH2O-3\nPenalized Generalized Linear Models\nMonotonic GBM\nSparse Principal Components (GLRM)\nlearning-fair-representations\nOptimal Sparse Decision Trees\nMonotonic XGBoost\nMultilayer Logical Perceptron (MLLP)\npyGAM\npySS3\nRisk-SLIM\nScikit-learn\nDecision Trees\nGeneralized Linear Models\nSparse Principal Components\nsklearn-expertsys\nskope-rules\nSuper-sparse Linear Integer models (SLIMs)\ntensorflow/lattice\nThis Looks Like That\nR\narules\nCausal SVM\nelasticnet\nExplainable Boosting Machine (EBM)/GA2M\ngam\nglm2\nglmnet\nH2O-3\nPenalized Generalized Linear Models\nMonotonic GBM\nSparse Principal Components (GLRM)\nMonotonic XGBoost\nquantreg\nrpart\nRuleFit\nScalable Bayesian Rule Lists (SBRL)\nAI Incident Tracker\nMar 1988 - A blot on the profession\nJan 2010 - Are Face-Detection Cameras Racist?\nJul 2015 - Google says sorry for racist auto-tag in photo app\nMar 2016 - Here Are the Microsoft Twitter Bot\u2019s Craziest Racist Rants\nJun 2016 - Google faulted for racial bias in image search results for black teenagers\nOct 2016 - 'Rogue' Algorithm Blamed for Historic Crash of the British Pound\nOct 2016 - Crime-prediction tool PredPol amplifies racially biased policing, study shows\nMay 2017 - Houston Schools Must Face Teacher Evaluation Lawsuit\nJun 2017 - When a Computer Program Keeps You in Jail\nJun 2017 - Antitrust: Commission fines Google \u20ac2.42 billion for abusing dominance as search engine by giving illegal advantage to own comparison shopping service\nJul 2017 - \u2018Balls have zero to me to me\u2019: What happened when Facebook\u2019s AI chatbots Bob & Alice created their own language\nJul 2017 - YouTube: Boston Dynamics' Atlas Falls Over After Demo at the Congress of Future Scientists and Technologists\nJul 2017 - Royal Free - Google DeepMind trial failed to comply with data protection law\nNov 2017 - Hackers Say They've Broken Face ID a Week After iPhone X Release\nNov 2017 - India\u2019s Friendly Robot Mitra Not Only Greets VIPs On The Stage, But Also Parties Like A Rockstar (Mitra trips over Ivanka Trump/PM Modi introduction)\nJan 2018 - YouTube: CES 2018: Robot refuses to co-operate with LG chief - BBC News\nFeb 2018 - Study finds gender and skin-type bias in commercial artificial-intelligence systems\nMar 2018 - Self-Driving Uber Car Kills Pedestrian in Arizona, Where Robots Roam\nMar 2018 - AI-Assisted Fake Porn Is Here and We're All F***ed\nJun 2018 - Facebook sent a doctor on a secret mission to ask hospitals to share patient data\nJul 2018 - Amazon\u2019s Face Recognition Falsely Matched 28 Members of Congress With Mugshots\nJul 2018 - IBM\u2019s Watson supercomputer recommended \u2018unsafe and incorrect\u2019 cancer treatments, internal documents show\nOct 2018 - Amazon scraps 'sexist AI' recruiting tool that showed bias against women\nNov 2018 - Facial recognition system in China mistakes bus ad for jaywalker\nDec 2018 - AI start-up that scanned babysitters halts launch following Post Report\nJan 2019 - Cambridge Analytica\u2019s parent pleads guilty to breaking UK data law\nApr 2019 - Facebook Executive Testifies on AI Failure to Detect the Christchurch Mosque Shooting Video\nMay 2019 - Investor Sues After an AI\u2019s Automated Trades Cost Him $20 Million\nMay 2019 - \nMillions of people uploaded photos to the Ever app. Then the company used them to develop facial recognition tools.\nJun 2019 - Google and the University of Chicago Are Sued Over Data Sharing\nAug 2019 - LGBTQ+ creators file lawsuit against YouTube for discrimination\nSep 2019 - The viral selfie app ImageNet Roulette seemed fun \u2013 until it called me a racist slur\nSep 2019 - Scammer Successfully Deepfaked CEO's Voice To Fool Underling Into Transferring $243,000\nOct 2019 - Oh dear... AI models used to flag hate speech online are, er, racist against black people\nOct 2019 - Dissecting racial bias in an algorithm used to manage the health of populations\nNov 2019 - \nNY regulator investigating Apple Card for possible gender bias\nNov 2019 - Chinese-style facial recognition technology is trialled in Australian schools to register pupils - sparking major privacy concerns\nDec 2019 - Tenants sounded the alarm on facial recognition in their buildings. Lawmakers are listening\nDec 2019 - Researchers bypass airport and payment facial recognition systems using masks\nJan 2020 - Atlantic Plaza Towers tenants won a halt to facial recognition in their building: Now they\u2019re calling on a moratorium on all residential use\nJan 2020 - Trivago misled consumers about hotel room rates\nFeb 2020 - An Indian politician is using deepfake technology to win new voters\nFeb 2020 - Suckers List: How Allstate\u2019s Secret Auto Insurance Algorithm Squeezes Big Spenders\nFeb 2020 - Tesla Autopilot gets tricked into accelerating from 35 to 85 mph with modified speed limit sign\nMar 2020 - Netherlands: Court Prohibits Government\u2019s Use of AI Software to Detect Welfare Fraud\nMar 2020 - The End of Starsky Robotics\nApr 2020 - Google apologizes after its Vision AI produced racist results\nApr 2020 - Google\u2019s medical AI was super accurate in a lab. Real life was a different story.\nMay 2020 - Researchers find major demographic differences in speech recognition accuracy\nMay 2020 - Access Denied: Faulty Automated Background Checks Freeze Out Renters\nMay 2020 - A.C.L.U. Accuses Clearview AI of Privacy \u2018Nightmare Scenario\u2019\nMay 2020 - Walmart Employees Are Out to Show Its Anti-Theft AI Doesn't Work\nMay 2020 - Robodebt removed humans from Human Services, and the Government is facing the consequences\nMay 2020 - The Most Devastating Software Mistake Of All Time. Why Is the Imperial Model Under Criticism?\nJun 2020 - Government\u2019s Use of Algorithm Serves Up False Fraud Charges\nJun 2020 - Microsoft's robot editor confuses mixed-race Little Mix singers\nJun 2020 - Tweet: \"This algorithm probably made this mistake ...\" (President Obama de-blurred into white male)\nJun 2020 - Detroit Police Chief: Facial Recognition Software Misidentifies 96% of the Time\nJun 2020 - Wrongfully Accused by an Algorithm\nJun 2020 - An Algorithm that \"Predicts\" Criminality Based on a Face Sparks a Furor\nJun 2020 - PwC facial recognition tool criticised for home working privacy invasion\nJun 2020 - Santa Cruz becomes the first U.S. city to ban predictive policing\nJun 2020 - YouTube Sued for Race Discrimination, Profiting from Hate Speech\nJul 2020 - ISIS 'still evading detection on Facebook', report says\nJul 2020 - Meet the Secret Algorithm That's Keeping Students Out of College\nJul 2020 - Rite Aid deployed facial recognition systems in hundreds of U.S. stores\nJul 2020 - Tweet: \"Oh, dear ...\" (GPT-3 anti-semitism)\nJul 2020 - Google Ad Portal Equated \u201cBlack Girls\u201d with Porn\nJul 2020 - Facial biometrics training dataset leads to BIPA lawsuits against Amazon, Alphabet and Microsoft\nJul 2020 - POLICE SURVEILLED GEORGE FLOYD PROTESTS WITH HELP FROM TWITTER-AFFILIATED STARTUP DATAMINR\nJul 2020 - AI-Powered \u2018Genderify\u2019 Platform Shut Down After Bias-Based Backlash\nAug 2020 - Police use of facial recognition unlawfully breached privacy rights, says Court of Appeal ruling\nAug 2020 - There is nothing 'fair' about judging A-levels by algorithm\nAug 2020 - When algorithms define kids by postcode: UK exam results chaos reveal too much reliance on data analytics\nAug 2020 - Macy\u2019s hit with privacy lawsuit over alleged use of controversial facial recognition software\nAug 2020 - Google\u2019s Advertising Platform Is Blocking Articles About Racism \nAug 2020 - Home Office drops 'racist' algorithm from visa decisions\nAug 2020 - De Blasio Will Reassess NYPD's Use Of Facial Recognition Tech After Protester Arrest\nAug 2020 - Facebook algorithm recommending Holocaust denial and fascist content, report finds\nAug 2020 - Report: AI Company Leaks Over 2.5M Medical Records\nAug 2020 - Watchdog investigates Barclays for spying on staff\nAug 2020 - PopID\u2019s face-based payments pose privacy and security risks\nAug 2020 - Tinder charges older people more\nAug 2020 - Uber and Lyft pricing algorithms charge more in non-white areas\nSep 2020 - Pasco\u2019s sheriff uses data to guess who will commit crime. Then deputies \u2018hunt down\u2019 and harass them\nSep 2020 - The Met Police didn\u2019t check if facial recognition tech was racist before trialling it\nSep 2020 - These students figured out their tests were graded by AI \u2014 and the easy way to cheat\nSep 2020 - Google says Street View maps algorithm error blurred out Hong Kong protest graffiti aimed at Xi Jinping\nSep 2020 - AI attempts to ease fear of robots, blurts out it can\u2019t \u2018avoid destroying humankind\u2019\nSep 2020 - Ola is facing a drivers\u2019 legal challenge over data access rights and algorithmic management\nSep 2020 - Instagram apologizes for removing images of Black British model\nSep 2020 - Tesla owner in Canada charged with \u2018sleeping\u2019 while driving over 90 mph\nSep 2020 - Female historians and male nurses do not exist, Google Translate tells its European users\nSep 2020 - Twitter is looking into why its photo preview appears to favor white faces over Black faces\nSep 2020 - Facebook Live\u2019s New Music Terms of Service Unfairly Impact Artists\nSep 2020 - CoreLogic\u2019s screening algorithm may have discriminated against renters: lawsuit\nSep 2020 - Gradient Photo Editing App Criticized Over 'Racist' AI Face Feature\nSep 2020 - ExamSoft\u2019s remote bar exam sparks privacy and facial recognition concerns\nSep 2020 - \"Trustworthiness\" Study Is Basically Phrenology, Annoying Scientists, Historians, Just About Everyone\nSep 2020 - IBM faces another age-discrimination lawsuit in Austin\nSep 2020 - Your favorite A.I. language tool is toxic\nSep 2020 - Catching Amazon in a lie\nSep 2020 - Tweet: \"A faculty member has been asking how to stop Zoom from removing his head ...\" (Zoom erasing darker-skinned professor's head)\nSep 2020 - Whistleblowers charge CEO of NJ firm with inflating AI capability, calling employees \u201cdirty Indians\u201d\nOct 2020 - Jewish Baby Stroller Image Algorithm\nOct 2020 - Instagram blames GDPR for failure to tackle rampant self-harm and eating-disorder images\nOct 2020 - UK passport photo checker shows bias against dark-skinned women\nOct 2020 - States Say the Online Bar Exam Was a Success. The Test-Taker Who Peed in His Seat Disagrees\nOct 2020 - Tiny Changes Let False Claims About COVID-19, Voting Evade Facebook Fact Checks\nOct 2020 - Leaving Cert: Why the Government deserves an F for algorithms\nOct 2020 - Lawsuit alleges biometric privacy violations from face recognition algorithm training\nOct 2020 - You\u2019re being watched: The dangers of ProctorU\nOct 2020 - Fake naked photos of thousands of women shared online \nOct 2020 - Researchers find evidence of racial, gender, and socioeconomic bias in chest X-ray classifiers\nOct 2020 - Uber sued by drivers over \u2018automated robo-firing'\nOct 2020 - How an Algorithm Blocked Kidney Transplants to Black Patients\nOct 2020 - Australian researchers have shown how you could become invisible to security cameras\nOct 2020 - EPIC files lawsuit to force release of ICE facial recognition documents\nOct 2020 - Researchers take a stand on algorithm design for job centers: Landing a job isn't always the right goal\nOct 2020 - Facebook under fire for boosting right-wing news sources and throttling progressive alternatives\nOct 2020 - AI Camera Ruins Soccer Game For Fans After Mistaking Referee's Bald Head For Ball\nOct 2020 - Researchers made an OpenAI GPT-3 medical chatbot as an experiment. It told a mock patient to kill themselves\nOct 2020 - Top doctors slam Google for not backing up incredible claims of super-human cancer-spotting AI\nNov 2020 - Researchers show that computer vision algorithms pretrained on ImageNet exhibit multiple, distressing biases\nNov 2020 - Trivago loses appeal over misleading website algorithm ruling\nNov 2020 - Research finds gender bias within state funding model\nNov 2020 - Split-Second 'Phantom' Images Can Fool Tesla's Autopilot\nNov 2020 - Boris executes U-turn over controversial house building algorithm\nNov 2020 - Top intel official warns of bias in military algorithms\nNov 2020 - Opinion: Artificial 'Intelligence': Unemployment system denied legitimate COVID-19 claims\nNov 2020 - LAPD ban facial recognition following alleged unauthorised use\nNov 2020 - Instagram removed 80 PER CENT less graphic content about suicide during the first three months of lockdown after 'most of its moderators were sent home due to Covid rules'\nNov 2020 - \nFacebook's AI Mistakenly Bans Ads for Struggling Businesses\nNov 2020 - A Bot Made Frank Sinatra Cover Britney Spears. YouTube Removed It Over Copyright Claims.\nNov 2020 - Net exposure \"94-year-old man was picked up for facial recognition\" The bank involved apologized\nNov 2020 - Walmart Scraps Plan to Have Robots Scan Shelves\nDec 2020 - Concern over potential gender bias in job recruitment algorithms\nDec 2020 - Facial Recognition Company Lied to School District About its Racist Tech\nDec 2020 - China\u2019s Huawei tested A.I. software that could identify Uighur Muslims and alert police, report says\nDec 2020 - We\u2019ve Known Brand Safety Tech Was Bad\u2014Here\u2019s How Bad\nDec 2020 - Hey Alexa, what's my PIN?\nDec 2020 - Waze sent commuters toward California wildfires, drivers say\nDec 2020 - The Death and Life of an Admissions Algorithm\nDec 2020 - Algorithms searching for child abuse could be banned under new EU privacy rules\nDec 2020 - Alibaba \u2018dismayed\u2019 by its cloud unit\u2019s ethnicity detection algorithm\nDec 2020 - Congress wants answers from Google about Timnit Gebru\u2019s firing\nDec 2020 - California Bar Exam Flagged A THIRD Of Applicants As Cheating\nDec 2020 - TikTok videos that promote anorexia are misspelling common hashtags to beat the 'pro-ana' ban\nDec 2020 - Facial Recognition Blamed For False Arrest And Jail Time\nDec 2020 - Girl, 12, is suing social media giant TikTok for alleged misuse of personal information and breaches of data protection laws\nDec 2020 - TikTok Deleted My Account Because I\u2019m a Latina Trans Woman\nDec 2020 - Shopping mall robot fell off the escalator and knocked down passengers\nDec 2020 - Stanford apologizes for coronavirus vaccine plan that left out many front-line doctors\nDec 2020 - The Christchurch Shooter and YouTube\u2019s Radicalization Trap\nJan 2021 - Italian court rules against \u2018discriminatory\u2019 Deliveroo rider-ranking algorithm\nJan 2021 - A business owner who spent nearly $46 million on Facebook advertising says he's been booted from the platform without explanation\nJan 2021 - FTC Orders Photo App to Delete Algorithms Built on Personal Data\nJan 2021 - South Korean AI chatbot pulled from Facebook after hate speech towards minorities\nJan 2021 - Google Hit With $2B Antitrust Suit Over 'Rigging' Its Algorithm\nJan 2021 - Judge Orders NJ Education Department To Turn Over S2 Algorithm\nJan 2021 - When an Israeli Farmer Declared War on an Algorithm\nJan 2021 - Job Screening Service Halts Facial Analysis of Applicants\nJan 2021 - Use of facial recognition tech sparks privacy fears\nJan 2021 - South Korea has used AI to bring a dead superstar's voice back to the stage, but ethical concerns abound\nJan 2021 - SEC Orders BlueCrest to Pay $170 Million to Harmed Fund Investors\nJan 2021 - University of Illinois to Discontinue Remote-Testing Software After Students Complain of Privacy Violation\nJan 2021 - Amazon algorithms boost vaccine misinformation, says study\nJan 2021 - Patent applications listing AI as an inventor run into legal problems\nJan 2021 - BIPOC students face disadvantages with exam monitoring software at the University of Toronto\nJan 2021 - \u2018for Some Reason I\u2019m Covered in Blood\u2019: Gpt-3 Contains Disturbing Bias Against Muslims\nFeb 2021 - Utah audit of Banjo deal highlights concerns with AI, government contracts\nFeb 2021 - Lingerie company Adore Me calls out TikTok for removing videos of Black, plus-size models\nFeb 2021 - \u2018Orwellian\u2019 AI lie detector project challenged in EU court\nFeb 2021 - Clearview AI\u2019s facial recognition technology violated federal and regional laws \u2013 RCI\nFeb 2021 - Beverly Hills cops try to weaponize Instagram\u2019s algorithms in failed attempt to thwart live streamers\nFeb 2021 - AI displays bias and inflexibility in civility detection, study finds\nFeb 2021 - Why Is Facebook Rejecting These Fashion Ads?\nFeb 2021 - Sweden\u2019s data watchdog slaps police for unlawful use of Clearview AI\nFeb 2021 - AI-Wielding Hackers are Here\nFeb 2021 - How Google Scholar Sidelines Research in Non\u2011English Languages\nFeb 2021 - DWP uses excessive surveillance on suspected fraudsters, report finds\nFeb 2021 - Canada Rules Clearview\u2019s AI Scraping is Unlawful\nFeb 2021 - INVESTIGATION: Facebook, Twitter Struggling in Fight against Balkan Content Violations\nFeb 2021 - Google slapped in France over misleading hotel star ratings\nFeb 2021 - Colleagues of mine analyzed A.I.-based job interviews ... (Tweet)\nFeb 2021 - YouTuber blocked for discussing 'black versus white' chess strategy\nFeb 2021 - Teaneck just banned facial recognition technology for police. Here's why\nFeb 2021 - TikTok agrees to pay $92 million to settle teen privacy class-action lawsuit\nFeb 2021 - Google fires top ethical AI expert Margaret Mitchell\nMar 2021 - UP Uses Facial Recognition Technology to Mete Out Discriminatory Treatment\nMar 2021 - Chatbots that resurrect the dead: legal experts weigh in on \u2018disturbing\u2019 technology\nMar 2021 - \u201cIt\u2019s all the real thing,\u201d Tom Cruise insists, looking into the camera ...\nMar 2021 - OpenAI\u2019s state-of-the-art machine vision AI is fooled by handwritten notes\nMar 2021 - Major Universities are Using Race as a \u201cHigh Impact Predictor\u201d of Student Success \u2013 The Markup\nMar 2021 - Instagram Suggested Posts To Users. It Served Up COVID-19 Falsehoods, Study Finds\nMar 2021 - Tenant screening software faces national reckoning\nMar 2021 - Instagram algorithm recommends far-right parties and Covid conspiracy theories to users\nMar 2021 - Google image search cements national stereotypes of 'racy' women\nMar 2021 - Time-Out for Google\nMar 2021 - Apple Censors URLs Containing \u201cAsian\u201d with Adult Filters\nMar 2021 - Underpaid Workers Are Being Forced to Train Biased AI on Mechanical Turk\nMar 2021 - New Study Reveals Coded Language Used to Fuel Anti-Semitism Online\nMar 2021 - Judge tells state to deliver records\nMar 2021 - Pennsylvania Woman Accused of Using Deepfake Technology to Harass Cheerleaders\nMar 2021 - Fears of 'digital dictatorship' as Myanmar deploys artificial intelligence\nMar 2021 - Amazon driver quits, saying the final straw was the company's new AI-powered truck cameras that can sense when workers yawn or don't use a seatbelt\nMar 2021 - INSTA-KID Fury over Facebook plot to make NEW Instagram for under 13s \u2013 as parents brand it \u2018dangerous\u2019\nMar 2021 - How AI lets bigots and trolls flourish while censoring LGBTQ+ voices\nMar 2021 - Music recommendation algorithms are unfair to female artists, but we can change that\nMar 2021 - Couriers say Uber\u2019s \u2018racist\u2019 facial identification tech got them fired\nMar 2021 - Major flaws found in machine learning for COVID-19 diagnosis\nMar 2021 - How a Stabbing in Israel Echoes Through the Fight Over Online Speech\nApr 2021 - Researchers have found that even the best Speech recognition systems are actually biased\nApr 2021 - Research says Facebook's ad algorithm perpetuates gender bias (see also Research Outputs from Auditing for Discrimination in Job Ad Delivery on the USC Information Sciences Institute web site)\nApr 2021 - Google AI chief Samy Bengio resigns over colleagues' firing and racial discrimination\nApr 2021 - How medicine discriminates against non-white people and women\nApr 2021 - In scramble to respond to Covid-19, hospitals turned to models with high risk of bias\nApr 2021 - Home Office algorithm to detect sham marriages may contain built-in discrimination\nApr 2021 - Google translation AI botches legal terms 'enjoin,' 'garnish' -research\nApr 2021 - Some FDA-approved AI medical devices are not \u2018adequately\u2019 evaluated, Stanford study says\nApr 2021 - Instagram apologises for mistake which targeted users with harmful diet content\nApr 2021 - Facebook, Princeton Must Face AI Data Theft Claims\nApr 2021 - Facebook sued for failing to remove anti-Muslim hate speech\nApr 2021 - Post Office scandal: What the Horizon saga is all about\nApr 2021 - Facebook, Twitter, YouTube are pressed on \u2018poisonous\u2019 algorithms\nApr 2021 - BLACK MAN USES PASSPORT PHOTO AS EVIDENCE AI IS \u2018RACIST\u2019 IN VIRAL TIKTOK\nApr 2021 - Twitter allows \u2018Uncle Tim\u2019 to trend for hours after Sen. Tim Scott\u2019s rebuttal, and then took action\nApr 2021 - Suicide Risk Prediction Models Could Perpetuate Racial Disparities\nMay 2021 - Amsterdam Court orders reinstatement of Uber drivers dismissed by algorithm\nMay 2021 - This facial recognition website can turn anyone into a cop \u2014 or a stalker\nMay 2021 - Why you should be very wary of AI that \u2018processes\u2019 college video applications\nMay 2021 - Airbnb pricing algorithm led to increased racial disparities, study finds\nMay 2021 - Uber commits crime using algorithms.\nMay 2021 - Deepfake detectors and datasets exhibit racial and gender bias, USC study shows\nMay 2021 - TikTok\u2019s recommendation algorithm is promoting homophobia and anti-trans violence\nMay 2021 - \u2018Grassroots\u2019 bot campaigns are coming. Governments don\u2019t have a plan to stop them\nMay 2021 - Workplace and algorithm bias kill Palestine content on Facebook and Twitter \nMay 2021 - Suit seeks to limit anti-Muslim speech on Facebook but roots of Islamophobia run far deeper\nMay 2021 - AI emotion-detection software tested on Uyghurs\nMay 2021 - An Insurance Startup Bragged It Uses AI to Detect Fraud. It Didn\u2019t Go Well\nMay 2021 - Google's new AI skincare tool may not work on patients with darker skin tones\nMay 2021 - Minn. Police Use of Facial Recognition Leads to Concerns\nMay 2021 - Facial recognition: Legal complaints lodged against Clearview AI in five countries\nJun 2021 - A Military Drone With A Mind Of Its Own Was Used In Combat, U.N. Says\nJun 2021 - Senate Democrats Urge Google To Investigate Racial Bias In Its Tools And The Company\nJun 2021 - McDonald\u2019s Taking Voiceprints at Drive-Throughs Illinois BIPA Class Action\nJun 2021 - Legal notice to Hyderabad Police Commissioner highlights lack of lawfulness of facial recognition measures\nJun 2021 - ATER ALERT: The Klein Law Firm Announces a Lead Plaintiff Deadline of July 12, 2021 in the Class Action Filed on Behalf of Aterian, Inc. Limited Shareholders\nJun 2021 - Have Google\u2019s Algorithm Updates Broken the Web?\nJun 2021 - How Airbnb failed its own anti-discrimination team\u2014and let racial disparities slip through the cracks\nJun 2021 - Facial Recognition Failures Are Locking People Out of Unemployment Systems",
	"chart charts data-visualization svg visualization": "D3: Data-Driven Documents\nD3 (or D3.js) is a JavaScript library for visualizing data using web standards. D3 helps you bring data to life using SVG, Canvas and HTML. D3 combines powerful visualization and interaction techniques with a data-driven approach to DOM manipulation, giving you the full capabilities of modern browsers and the freedom to design the right visual interface for your data.\nResources\nIntroduction\nAPI Reference\nReleases\nExamples\nWiki\nInstalling\nIf you use npm, npm install d3. You can also download the latest release on GitHub. For vanilla HTML in modern browsers, import D3 from Skypack:\n```html\nFor legacy environments, you can load D3\u2019s UMD bundle from an npm-based CDN such as jsDelivr; a d3 global is exported:html\nYou can also use the standalone D3 microlibraries. For example, d3-selection:html\n```\nD3 is written using ES2015 modules. Create a custom bundle using Rollup, Webpack, or your preferred bundler. To import D3 into an ES2015 application, either import specific symbols from specific D3 modules:\njs\nimport {scaleLinear} from \"d3-scale\";\nOr import everything into a namespace (here, d3):\njs\nimport * as d3 from \"d3\";\nOr using dynamic import:\njs\nconst d3 = await import(\"d3\");\nYou can also import individual modules and combine them into a d3 object using Object.assign:\njs\nconst d3 = await Promise.all([\n  import(\"d3-format\"),\n  import(\"d3-geo\"),\n  import(\"d3-geo-projection\")\n]).then(d3 => Object.assign({}, ...d3));",
	"apache canvas charting-library charts data-visualization data-viz echarts svg visualization": "Apache ECharts\nApache ECharts is a free, powerful charting and visualization library offering an easy way of adding intuitive, interactive, and highly customizable charts to your commercial products. It is written in pure JavaScript and based on zrender, which is a whole new lightweight canvas library.\n\u4e2d\u6587\u5b98\u7f51 | ENGLISH HOMEPAGE\nGet Apache ECharts\nYou may choose one of the following methods:\nDownload from the official website\nnpm install echarts --save\nCDN: jsDelivr CDN\nDocs\nGet Started\nAPI\nOption Manual\nExamples\nGet Help\nGitHub Issues for bug report and feature requests\nEmail dev@echarts.apache.org for general questions\nSubscribe to the mailing list to get updated with the project\nBuild\nBuild echarts source code:\nExecute the instructions in the root directory of the echarts:\n(Node.js is required)\nshell\nInstall the dependencies from NPM:\nnpm install\nRebuild source code immediately in watch mode when changing the source code.\nIt opens the ./test directory and you may open -cases.html to get the list\nof all test cases.\nIf you wish to create a test case, run npm run mktest:help to learn more.\nnpm run dev\nCheck correctness of TypeScript code.\nnpm run checktype\nIf intending to build and get all types of the \"production\" files:\nnpm run release\nThen the \"production\" files are generated in the dist directory.\nContribution\nIf you wish to debug locally or make pull requests, please refer to the contributing document.\nResources\nAwesome ECharts\nhttps://github.com/ecomfe/awesome-echarts\nExtensions\nECharts GL An extension pack of ECharts, which provides 3D plots, globe visualization, and WebGL acceleration.\nLiquidfill \u6c34\u7403\u56fe\nWordcloud \u5b57\u7b26\u4e91\nExtension for Baidu Map \u767e\u5ea6\u5730\u56fe\u6269\u5c55 An extension provides a wrapper of Baidu Map Service SDK.\nvue-echarts ECharts component for Vue.js\necharts-stat Statistics tool for ECharts\nLicense\nECharts is available under the Apache License V2.\nCode of Conduct\nPlease refer to Apache Code of Conduct.\nPaper\nDeqing Li, Honghui Mei, Yi Shen, Shuang Su, Wenli Zhang, Junting Wang, Ming Zu, Wei Chen.\nECharts: A Declarative Framework for Rapid Construction of Web-based Visualization.\nVisual Informatics, 2018.",
	"alerting analytics business-intelligence dashboard data-visualization elasticsearch go grafana hacktoberfest influxdb metrics monitoring mysql postgres prometheus": "The open-source platform for monitoring and observability\nGrafana allows you to query, visualize, alert on and understand your metrics no matter where they are stored. Create, explore, and share dashboards with your team and foster a data-driven culture:\nVisualizations: Fast and flexible client side graphs with a multitude of options. Panel plugins offer many different ways to visualize metrics and logs.\nDynamic Dashboards: Create dynamic & reusable dashboards with template variables that appear as dropdowns at the top of the dashboard.\nExplore Metrics: Explore your data through ad-hoc queries and dynamic drilldown. Split view and compare different time ranges, queries and data sources side by side.\nExplore Logs: Experience the magic of switching from metrics to logs with preserved label filters. Quickly search through all your logs or streaming them live.\nAlerting: Visually define alert rules for your most important metrics. Grafana will continuously evaluate and send notifications to systems like Slack, PagerDuty, VictorOps, OpsGenie.\nMixed Data Sources: Mix different data sources in the same graph! You can specify a data source on a per-query basis. This works for even custom datasources.\nGet started\nGet Grafana\nInstallation guides\nUnsure if Grafana is for you? Watch Grafana in action on play.grafana.org!\nDocumentation\nThe Grafana documentation is available at grafana.com/docs.\nContributing\nIf you're interested in contributing to the Grafana project:\nStart by reading the Contributing guide.\nLearn how to set up your local environment, in our Developer guide.\nExplore our beginner-friendly issues.\nLook through our style guide and Storybook.\nGet involved\nFollow @grafana on Twitter.\nRead and subscribe to the Grafana blog.\nIf you have a specific question, check out our discussion forums.\nFor general discussions, join us on the official Slack team.\nLicense\nGrafana is distributed under AGPL-3.0-only. For Apache-2.0 exceptions, see LICENSING.md.",
	"canvas canvas2d data-visualization game glsl javascript pixi pixijs renderer rendering rendering-2d-graphics rendering-engine webgl": "PixiJS \u2014 The HTML5 Creation Engine\nThis project aims to provide a fast lightweight 2D library that works\nacross all devices. The PixiJS renderer allows everyone to enjoy the power of\nhardware acceleration without prior knowledge of WebGL. Also, it's fast. Really fast.\nIf you want to keep up to date with the latest PixiJS news then feel free to follow us on Twitter @PixiJS\nand we will keep you posted! You can also check back on our site\nas any breakthroughs will be posted up there too!\nWe are now a part of the Open Collective and with your support you can help us make PixiJS even better. To make a donation, simply click the button below and we'll love you forever!\nWhat to Use PixiJS for and When to Use It\nPixiJS is a rendering library that will allow you to create rich, interactive graphics, cross-platform applications, and games without having to dive into the WebGL API or deal with browser and device compatibility.\nPixiJS has full WebGL support and seamlessly falls back to HTML5's canvas if needed. As a framework, PixiJS is a fantastic tool for authoring interactive content, especially with the move away from Adobe Flash in recent years. Use it for your graphics-rich, interactive websites, applications, and HTML5 games.  Out of the box, cross-platform compatibility and graceful degradation mean you have less work to do and have more fun doing it! If you want to create polished and refined experiences relatively quickly, without delving into dense, low-level code, all while avoiding the headaches of browser inconsistencies, then sprinkle your next project with some PixiJS magic!\nBoost your development and feel free to use your imagination!\nLearn\nWebsite: Find out more about PixiJS on the official website.\nGetting started:\nCheck out @kittykatattack's comprehensive tutorial.\nAlso check out @miltoncandelero's PixiJS tutorials aimed toward videogames with recipes, best practices and TypeScript / npm / webpack setup here\nExamples: Get stuck right in and play around with PixiJS code and features right here!\nDocs: Get to know the PixiJS API by checking out the docs.\nGuide: Supplementary guide to the API documentation here.\nWiki: Other misc tutorials and resources are on the Wiki.\nCommunity\nForums: Check out the forum and Stackoverflow, both friendly places to ask your PixiJS questions.\nInspiration: Check out the gallery to see some of the amazing things people have created!\nChat: You can join us on Discord to chat about PixiJS.\nSetup\nIt's easy to get started with PixiJS! Simply download a prebuilt build!\nAlternatively, PixiJS can be installed with npm or simply using a content delivery network (CDN) URL to embed PixiJS directly on your HTML page.\nNote: After v4.5.0, support for the Bower package manager has been dropped. Please see the release notes for more information.\nNPM Install\nsh\nnpm install pixi.js\nThere is no default export. The correct way to import PixiJS is:\njs\nimport * as PIXI from 'pixi.js'\nCDN Install\nVia jsDelivr:\n```html\nOr via unpkg:html\n```\nDemos\nFilters Demo\nRun Pixie Run\nFlash vs HTML\nBunny Demo\nStorm Brewing\nRender Texture Demo\nPrimitives Demo\nMasking Demo\nInteraction Demo\nphotonstorm's Balls Demo\nphotonstorm's Morph Demo\nThanks to @photonstorm for providing\nthose last 2 examples and allowing us to share the source code :)\nContribute\nWant to be part of the PixiJS project? Great! All are welcome! We will get there quicker\ntogether :) Whether you find a bug, have a great feature request or you fancy owning a task\nfrom the road map above feel free to get in touch.\nMake sure to read the Contributing Guide\nbefore submitting changes.\nCurrent features\nWebGL renderer (with automatic smart batching allowing for REALLY fast performance)\nCanvas renderer (Fastest in town!)\nFull scene graph\nSuper easy to use API (similar to the flash display list API)\nSupport for texture atlases\nAsset loader / sprite sheet loader\nAuto-detect which renderer should be used\nFull Mouse and Multi-touch Interaction\nText\nBitmapFont text\nMultiline Text\nRender Texture\nPrimitive Drawing\nMasking\nFilters\nUser Plugins\nBasic Usage Example\njs\nimport { Application, Sprite, Assets } from 'pixi.js';\n// The application will create a renderer using WebGL, if possible,\n// with a fallback to a canvas render. It will also setup the ticker\n// and the root stage PIXI.Container\nconst app = new Application();\n// The application will create a canvas element for you that you\n// can then insert into the DOM\ndocument.body.appendChild(app.view);\n// load the texture we need\nconst texture = await Assets.load('bunny.png');\n// This creates a texture from a 'bunny.png' image\nconst bunny = new Sprite(texture);\n// Setup the position of the bunny\nbunny.x = app.renderer.width / 2;\nbunny.y = app.renderer.height / 2;\n// Rotate around the center\nbunny.anchor.x = 0.5;\nbunny.anchor.y = 0.5;\n// Add the bunny to the scene we are building\napp.stage.addChild(bunny);\n// Listen for frame updates\napp.ticker.add(() => {\n    // each frame we spin the bunny around a bit\n    bunny.rotation += 0.01;\n});\nHow to build\nNote that for most users you don't need to build this project. If all you want is to use PixiJS, then\njust download one of our prebuilt releases. \nThe only time you should need to build PixiJS is if you are developing it.\nIf you don't already have Node.js and NPM, go install them. Then, in the folder where you have cloned\nthe repository, install the build dependencies using npm:\nsh\nnpm install\nThen, to build the source, run:\nsh\nnpm run build\nError installing gl package\nIn most cases installing gl from npm should just work. However, if you run into problems you might need to adjust your system configuration and make sure all your dependencies are up to date\nPlease refer to the gl installation guide for more information.\nError installing canvas package\nThe canvas library currently being used does not have a pre-built version for every environment.\nWhen the package detects an unsupported environment, it will try to build from source.\nTo build from source you will need to make sure you have the following dependencies installed and then reinstall:\nbrew install pkg-config cairo pango libpng jpeg giflib librsvg\nFor non-mac users, please refer to the canvas installation guide for more information.\nHow to generate the documentation\nThe docs can be generated using npm:\nsh\nnpm run docs\nThe documentation uses webdoc in combination with this template pixi-webdoc-template. The configuration file can be found at webdoc.conf.json\nLicense\nThis content is released under the (http://opensource.org/licenses/MIT) MIT License.",
	"chart d3 data-visualization react svg visualization visx vx": "visx\nvisx is a collection of reusable low-level visualization components. visx combines the power of d3\nto generate your visualization with the benefits of react for updating the DOM.\nDocs\n\u2022\nGallery\n\u2022\nBlog\n\u2022\nSlack #visx\n\u2022\nChangelog\n\u2022\nGetting started tutorial\nUsage\nLet's make a simple bar graph.\nFirst we'll install the relevant packages:\nbash\nnpm install --save @visx/mock-data @visx/group @visx/shape @visx/scale\n```javascript\nimport React from 'react';\nimport { letterFrequency } from '@visx/mock-data';\nimport { Group } from '@visx/group';\nimport { Bar } from '@visx/shape';\nimport { scaleLinear, scaleBand } from '@visx/scale';\n// We'll use some mock data from @visx/mock-data for this.\nconst data = letterFrequency;\n// Define the graph dimensions and margins\nconst width = 500;\nconst height = 500;\nconst margin = { top: 20, bottom: 20, left: 20, right: 20 };\n// Then we'll create some bounds\nconst xMax = width - margin.left - margin.right;\nconst yMax = height - margin.top - margin.bottom;\n// We'll make some helpers to get at the data we want\nconst x = d => d.letter;\nconst y = d => +d.frequency * 100;\n// And then scale the graph by our data\nconst xScale = scaleBand({\n  range: [0, xMax],\n  round: true,\n  domain: data.map(x),\n  padding: 0.4,\n});\nconst yScale = scaleLinear({\n  range: [yMax, 0],\n  round: true,\n  domain: [0, Math.max(...data.map(y))],\n});\n// Compose together the scale and accessor functions to get point functions\nconst compose = (scale, accessor) => data => scale(accessor(data));\nconst xPoint = compose(xScale, x);\nconst yPoint = compose(yScale, y);\n// Finally we'll embed it all in an SVG\nfunction BarGraph(props) {\n  return (\n  {data.map((d, i) => {\n    const barHeight = yMax - yPoint(d);\n    return (\n      bar-${i}}>\n\n\n    );\n  })}\n\n);\n}\n// ... somewhere else, render it ...\n// \n```\nFor more examples using visx, check out the gallery.\nMotivation\nGoal\nThe goal is to create a library of components you can use to make both your own reusable chart\nlibrary or your slick custom one-off chart. visx is largely unopinionated and is meant to be built\nupon. Keep your bundle sizes down and use only the packages you need.\nHow?\nUnder the hood, visx is using d3 for the calculations and math. If you're creating your own awesome\nchart library on top of visx, it's easy to create a component api that hides d3 entirely. Meaning\nyour team could create charts as easily as using reusable react components.\nBut why?\nMixing two mental models for updating the DOM is never a good time. Copy and pasting d3 code into\ncomponentDidMount() is just that. This collection of components lets you easily build your own\nreusable visualization charts or library without having to learn d3. No more selections or\nenter()/exit()/update().\nRoadmap\nLots coming soon, check out the roadmap.\nIn the wild\nwilliaster/data-ui\n  (Demo)\ndylanmoz/trello\n  (Demo)\n  (How to Make Beautiful Graphs With vx and React-Motion)\ngkunthara/Crypto-Chart\n  (Tutorial)\nCollapsible tree with react-move by\n  @techniq (Demo)\n  (Radial demo)\n  (More info)\nBitcoin 30-day price by @hshoff\n  (Github)\n  (YouTube)\nEthereum candlestick chart by @hshoff\n  (Github)\nSong data visualization through spotify by @bother7\n  (Demo)\n  (Github)\nInvestment Calculator (website)\nAnimation with react-spring by\n  @drcmda (Demo)\nCode Coverage Dashboard by @ezy\n  (Demo)\n  (Github)\nEthereum Portfolio Toolkit by @JayWelsh\n  (Demo) (Github)\nFamily tree by @vkallore\n  (Github)\nSouth African Coronavirus Data Visuals by @JayWelsh\n  (Demo) (Github)\nCNN: Tracking America's Recovery\nWall Street Journal: Americans Familiarize Themselves with the Word \u2018Forbearance\u2019\n  by @rayshan\n  (Demo)\nDollar to food emoji caculator by @gmlwo530\n  (Demo)\n  (Github)\n[zh-TW] Taiwan Real-time Air Quality Index by\n  @ArvinH(Demo)(Tutorial)\ntokenized BTC on ethereum stacked chart with brush by\n  @sakulstra(Demo)\nEscape From Tarkov Ammo Chart by\n  @codenomial\nPry Finance for Founders (dashboard by @valtism)\nData 2 the People Donation Efficacy Analysis for Downballot Races (Demo) (Github)\nAugora Display information of french deputies (Demo)(Github)\nWHO Coronavirus (COVID-19) Dashboard is built on top of vx, earlier version of visx. (Demo)\nHave a project that's using visx? Open a pull request and we'll add it to the list.\nFAQ\nWhat does visx stand for?\nvisx stands for visualization components.\nDo you plan on supporting animation/transitions?\nA common criticism of visx is it doesn't have animation baked in, but this was a conscious\nchoice. It's a powerful feature to not bake it in.\nImagine your app already bundles react-motion, adding a hypothetical @visx/animation is\nbloat. Since visx is react, it already supports all react animation libs.\nCharting libraries are like style guides. Each org or app will eventually want full control\nover their own implementation.\nvisx makes this easier for everyone. No need to reinvent the wheel each time.\nmore info: https://github.com/airbnb/visx/issues/6\nexamples:\nCollapsible tree with react-move by\n  @techniq (Demo)\n  (Radial demo)\nAnimation with react-spring by @drcmda\n  (Demo)\nDo I have to use every package to make a chart?\nnope! pick and choose the packages you need.\nCan I use this to create my own library of charts for my team?\nPlease do.\nDoes visx work with preact?\nyup! need to alias react + react-dom and use preact-compat.\nI like using d3.\nMe too.\nDevelopment\nPlease see CONTRIBUTING.md\n:v:\nMIT",
	"charting-library charts d3 data-visualization plotly plotly-dash regl visualization webgl": "Plotly.js is a standalone Javascript data visualization library, and it also powers the Python and R modules named plotly in those respective ecosystems (referred to as Plotly.py and Plotly.R).\nPlotly.js can be used to produce dozens of chart types and visualizations, including statistical charts, 3D graphs, scientific charts, SVG and tile maps, financial charts and more.\nContact us for Plotly.js consulting, dashboard development, application integration, and feature additions.\nTable of contents\nLoad as a node module\nLoad via script tag\nBundles\nAlternative ways to load and build plotly.js\nDocumentation\nBugs and feature requests\nContributing\nNotable contributors\nCopyright and license\nCommunity\nLoad as a node module\nInstall a ready-to-use distributed bundle\nsh\nnpm i --save plotly.js-dist-min\nand use import or require in node.js\njs\n// ES6 module\nimport Plotly from 'plotly.js-dist-min'\n// CommonJS\nvar Plotly = require('plotly.js-dist-min')\nYou may also consider using plotly.js-dist if you prefer using an unminified package.\nLoad via script tag\nThe script HTML element\nIn the examples below Plotly object is added to the window scope by script. The newPlot method is then used to draw an interactive figure as described by data and layout into the desired div here named gd. As demonstrated in the example above basic knowledge of html and JSON syntax is enough to get started i.e. with/without JavaScript! To learn and build more with plotly.js please visit plotly.js documentation.\n```html\nAlternatively you may consider using native ES6 import in the script tag.html\nFastly supports Plotly.js with free CDN service. Read more at https://www.fastly.com/open-source.\nUn-minified versions are also available on CDN\nWhile non-minified source files may contain characters outside UTF-8, it is recommended that you specify the charset when loading those bundles.html\n```\nPlease note that as of v2 the \"plotly-latest\" outputs (e.g. https://cdn.plot.ly/plotly-latest.min.js) will no longer be updated on the CDN, and will stay at the last v1 patch v1.58.5. Therefore, to use the CDN with plotly.js v2 and higher, you must specify an exact plotly.js version.\nMathJax\nYou could load either version two or version three of MathJax files, for example:\n```html\nhtml\n```\nWhen using MathJax version 3, it is also possible to use chtml output on the other parts of the page in addition to svg output for the plotly graph.\nPlease refer to devtools/test_dashboard/index-mathjax3chtml.html to see an example.\nBundles\nThere are two kinds of plotly.js bundles:\n1. Complete and partial official bundles that are distributed to npm and the CDN, described in the dist README.\n2. Custom bundles you can create yourself to optimize the size of bundle depending on your needs. Please visit CUSTOM_BUNDLE for more information.\nAlternative ways to load and build plotly.js\nIf your library needs to bundle or directly load plotly.js/lib/index.js or parts of its modules similar to index-basic in some other way than via an official or a custom bundle, or in case you want to tweak the default build configurations of browserify or webpack, etc. then please visit BUILDING.md.\nDocumentation\nOfficial plotly.js documentation is hosted at https://plotly.com/javascript.\nThese pages are generated by the Plotly graphing-library-docs repo built with Jekyll and publicly hosted on GitHub Pages.\nFor more info about contributing to Plotly documentation, please read through contributing guidelines.\nBugs and feature requests\nHave a bug or a feature request? Please open a Github issue keeping in mind the issue guidelines. You may also want to read about how changes get made to Plotly.js\nContributing\nPlease read through our contributing guidelines. Included are directions for opening issues, using plotly.js in your project and notes on development.\nNotable contributors\nPlotly.js is at the core of a large and dynamic ecosystem with many contributors who file issues, reproduce bugs, suggest improvements, write code in this repo (and other upstream or downstream ones) and help users in the Plotly community forum. The following people deserve special recognition for their outsized contributions to this ecosystem:\n|   | GitHub | Twitter | Status |\n|---|--------|---------|--------|\n|Alex C. Johnson| @alexcjohnson | | Active, Maintainer |\n|Mojtaba Samimi | @archmoj | @solarchvision | Active, Maintainer |\n|Antoine Roy-Gobeil | @antoinerg | | Active, Maintainer |\n|Nicolas Kruchten | @nicolaskruchten | @nicolaskruchten | Active, Maintainer |\n|Jon Mease | @jonmmease | @jonmmease | Active |\n|\u00c9tienne T\u00e9treault-Pinard| @etpinard | @etpinard | Hall of Fame |\n|Mikola Lysenko| @mikolalysenko | @MikolaLysenko | Hall of Fame |\n|Ricky Reusser| @rreusser | @rickyreusser | Hall of Fame |\n|Dmitry Yv. | @dy | @DimaYv| Hall of Fame |\n|Robert Monfera| @monfera | @monfera | Hall of Fame |\n|Robert M\u00f6stl | @rmoestl | @rmoestl | Hall of Fame |\n|Nicolas Riesco| @n-riesco | | Hall of Fame |\n|Mikl\u00f3s Tusz| @mdtusz | @mdtusz| Hall of Fame |\n|Chelsea Douglas| @cldougl | | Hall of Fame |\n|Ben Postlethwaite| @bpostlethwaite | | Hall of Fame |\n|Chris Parmer| @chriddyp | | Hall of Fame |\n|Alex Vados| @alexander-daniel | | Hall of Fame |\nCopyright and license\nCode and documentation copyright 2021 Plotly, Inc.\nCode released under the MIT license.\nVersioning\nThis project is maintained under the Semantic Versioning guidelines.\nSee the Releases section of our GitHub project for changelogs for each release version of plotly.js.\nCommunity\nFollow @plotlygraphs on Twitter for the latest Plotly news.\nImplementation help may be found on community.plot.com (tagged plotly-js) or\n  on Stack Overflow (tagged plotly).\nDevelopers should use the keyword plotly on packages which modify or add to the functionality of plotly.js when distributing through npm.",
	"charts data-visualization graphs interactive javascript svg visualization": "A modern JavaScript charting library that allows you to build interactive data visualizations with simple API and 100+ ready-to-use samples. Packed with the features that you expect, ApexCharts includes over a dozen chart types that deliver beautiful, responsive visualizations in your apps and dashboards. ApexCharts is an MIT-licensed open-source project that can be used in commercial and non-commercial projects.\nBrowsers support\n| Firefox | Chrome | Safari |  Edge |  IE11 |\n| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| 31+ \u2714                                                                                                                                                                                                             | 35+ \u2714                                                                                                                                                                                                         | 6+ \u2714                                                                                                                                                                                                          | Edge \u2714                                                                                                                                                                                                 | (IE11) \u2714                                                                                                                                                                  |\nDownload and Installation\nInstalling via npm\nbash\nnpm install apexcharts --save\nDirect ",
	"awesome awesome-list bigdata data data-analytics data-science data-stream data-visualization data-warehouse database distributed-database series-database stream-processing streaming-data visualize-data": "Awesome Big Data\nA curated list of awesome big data frameworks, resources and other awesomeness. Inspired by awesome-php, awesome-python, awesome-ruby, hadoopecosystemtable & big-data.\nYour contributions are always welcome!\nAwesome Big Data\nRDBMS\nFrameworks\nDistributed Programming\nDistributed Filesystem\nDistributed Index\nDocument Data Model\nKey Map Data Model\nKey-value Data Model\nGraph Data Model\nColumnar Databases\nNewSQL Databases\nTime-Series Databases\nSQL-like processing\nData Ingestion\nService Programming\nScheduling\nMachine Learning\nBenchmarking\nSecurity\nSystem Deployment\nApplications\nSearch engine and framework\nMySQL forks and evolutions\nPostgreSQL forks and evolutions\nMemcached forks and evolutions\nEmbedded Databases\nBusiness Intelligence\nData Visualization\nInternet of things and sensor data\nInteresting Readings\nInteresting Papers\n2015 - 2016\n2013 - 2014\n2011 - 2012\n2001 - 2010\nVideos\nBooks\nStreaming\nDistributed systems\nGraph Based approach\nData Visualization\nOther Awesome Lists\nRDBMS\nMySQL The world's most popular open source database.\nPostgreSQL The world's most advanced open source database.\nOracle Database - object-relational database management system.\nTeradata - high-performance MPP data warehouse platform.\nFrameworks\nBistro - general-purpose data processing engine for both batch and stream analytics. It is based on a novel data model, which represents data via functions and processes data via column operations as opposed to having only set operations in conventional approaches like MapReduce or SQL.\nIBM Streams - platform for distributed processing and real-time analytics.  Integrates with many of the popular technologies in the Big Data ecosystem (Kafka, HDFS, Spark, etc.)\nApache Hadoop - framework for distributed processing. Integrates\u00a0MapReduce (parallel processing), YARN (job scheduling) and HDFS (distributed file system).\nTigon - High Throughput Real-time Stream Processing Framework.\nPachyderm - Pachyderm is a data storage platform built on Docker and Kubernetes to provide reproducible data processing and analysis.\nPolyaxon - A platform for reproducible and scalable machine learning and deep learning.\nSmooks - An extensible Java framework for building XML and non-XML (CSV, EDI, Java, etc...) streaming applications.\nDistributed Programming\nAddThis Hydra - distributed data processing and storage system originally developed at AddThis.\nAMPLab SIMR - run Spark on Hadoop MapReduce v1.\nApache APEX - a unified, enterprise platform for big data stream and batch processing.\nApache Beam - an unified model and set of language-specific SDKs for defining and executing data processing workflows.\nApache Crunch - a simple Java API for tasks like joining and data aggregation that are tedious to implement on plain MapReduce.\nApache DataFu - collection of user-defined functions for\u00a0Hadoop and Pig developed by LinkedIn.\nApache Flink - high-performance runtime, and automatic program optimization.\nApache Gearpump - real-time big data streaming engine based on Akka.\nApache Gora - framework for in-memory data model and persistence.\nApache Hama - BSP (Bulk Synchronous Parallel) computing framework.\nApache MapReduce - programming model for processing large data sets with a parallel, distributed algorithm on a cluster.\nApache Pig - high level language to express data analysis programs for Hadoop.\nApache REEF - retainable evaluator execution framework to simplify and unify the lower layers of big data systems.\nApache S4 - framework for stream processing, implementation of S4.\nApache Spark - framework for\u00a0in-memory cluster computing.\nApache Spark Streaming - framework for stream processing, part of Spark.\nApache Storm - framework for stream processing by Twitter also on YARN.\nApache Samza - stream processing framework, based on Kafka and YARN.\nApache Tez - application framework\u00a0for executing a complex DAG (directed acyclic graph) of tasks, built on\u00a0YARN.\nApache Twill - abstraction over YARN that reduces the complexity of developing distributed applications.\nBaidu Bigflow - an interface that allows for writing distributed computing programs providing lots of simple, flexible, powerful APIs to easily handle data of any scale.\nCascalog - data processing and querying library.\nCheetah - High Performance, Custom Data Warehouse on Top of MapReduce.\nConcurrent Cascading - framework for data management/analytics on Hadoop.\nDamballa Parkour - MapReduce library for Clojure.\nDatasalt Pangool - alternative MapReduce paradigm.\nDataTorrent StrAM - real-time engine is designed to enable distributed, asynchronous, real time in-memory big-data computations in as unblocked a way as possible, with minimal overhead and impact on performance.\nFacebook Corona - Hadoop enhancement which removes single point of failure.\nFacebook Peregrine - Map Reduce framework.\nFacebook Scuba - distributed in-memory datastore.\nGoogle Dataflow - create data pipelines to help them\u00e6ingest, transform and analyze data.\nGoogle MapReduce - map reduce framework.\nGoogle MillWheel - fault tolerant stream processing framework.\nIBM Streams - platform for distributed processing and real-time analytics.  Provides toolkits for advanced analytics like geospatial, time series, etc. out of the box.\nJAQL - declarative programming language for working with structured, semi-structured and unstructured data.\nKite - is a set of libraries, tools, examples, and documentation focused on making it easier to build systems on top of the Hadoop ecosystem.\nMetamarkets Druid - framework for real-time analysis of large datasets.\nNetflix PigPen - map-reduce for Clojure which compiles to Apache Pig.\nNokia Disco - MapReduce framework developed by Nokia.\nOnyx - Distributed computation for the cloud.\nPinterest Pinlater - asynchronous job execution system.\nPydoop - Python MapReduce and HDFS API for Hadoop.\nRay - A fast and simple framework for building and running distributed applications. \nRackerlabs Blueflood - multi-tenant distributed metric processing system\nSkale - High performance distributed data processing in NodeJS.\nStratosphere - general purpose cluster computing framework.\nStreamdrill - useful for counting activities of event streams over different time windows and finding the most active one.\nstreamsx.topology - Libraries to enable building IBM Streams application in Java, Python or Scala.\nTuktu - Easy-to-use platform for batch and streaming computation, built using Scala, Akka and Play!\nTwitter Heron - Heron is a realtime, distributed, fault-tolerant stream processing engine from Twitter replacing Storm.\nTwitter Scalding - Scala library for Map Reduce jobs, built on Cascading.\nTwitter Summingbird - Streaming MapReduce with Scalding and Storm, by Twitter.\nTwitter TSAR - TimeSeries AggregatoR by Twitter.\nWallaroo - The ultrafast and elastic data processing engine. Big or fast data - no fuss, no Java needed.\nDistributed Filesystem\nAmbry - a distributed object store that supports storage of trillion of small immutable objects as well as billions of large objects.\nApache HDFS - a way to store large files across multiple machines.\nApache Kudu - Hadoop's storage layer to enable fast analytics on fast data.\nBeeGFS - formerly FhGFS, parallel distributed file system.\nCeph Filesystem - software storage platform designed.\nDisco DDFS - distributed filesystem.\nFacebook Haystack - object storage system.\nGoogle GFS - distributed filesystem.\nGoogle Megastore - scalable, highly available storage.\nGridGain - GGFS, Hadoop compliant in-memory file system.\nLustre file system - high-performance distributed filesystem.\nMicrosoft Azure Data Lake Store - HDFS-compatible storage in Azure cloud\nQuantcast File System QFS - open-source distributed file system.\nRed Hat GlusterFS - scale-out network-attached storage file system.\nSeaweed-FS - simple and highly scalable distributed file system.\nAlluxio - reliable file sharing at memory speed across cluster frameworks.\nTahoe-LAFS - decentralized cloud storage system.\nBaidu File System - distributed filesystem.\nDistributed Index\nPilosa Open source distributed bitmap index that dramatically accelerates queries across multiple, massive data sets. \nDocument Data Model\nActian Versant - commercial object-oriented database management systems .\nCrate Data - is an open source massively scalable data store. It requires zero administration.\nFacebook Apollo - Facebook\u2019s Paxos-like NoSQL database.\njumboDB - document oriented datastore over Hadoop.\nLinkedIn Espresso - horizontally scalable document-oriented NoSQL data store.\nMarkLogic - Schema-agnostic Enterprise NoSQL database technology.\nMicrosoft Azure DocumentDB - NoSQL cloud database service with protocol support for MongoDB \nMongoDB - Document-oriented database system.\nRavenDB - A transactional, open-source Document Database.\nRethinkDB - document database that supports queries like table joins and group by.\nKey Map Data Model\nNote: There is some term confusion in the industry, and two different things are called \"Columnar Databases\". Some, listed here, are distributed, persistent databases built around the \"key-map\" data model: all data has a (possibly composite) key, with which a map of key-value pairs is associated. In some systems, multiple such value maps can be associated with a key, and these maps are referred to as \"column families\" (with value map keys being referred to as \"columns\").\nAnother group of technologies that can also be called \"columnar databases\" is distinguished by how it stores data, on disk or in memory -- rather than storing data the traditional way, where all column values for a given key are stored next to each other, \"row by row\", these systems store all column values next to each other. So more work is needed to get all columns for a given key, but less work is needed to get all values for a given column.\nThe former group is referred to as \"key map data model\" here. The line between these and the Key-value Data Model stores is fairly blurry.\nThe latter, being more about the storage format than about the data model, is listed under Columnar Databases.\nYou can read more about this distinction on Prof. Daniel Abadi's blog: Distinguishing two major types of Column Stores.\nApache Accumulo - distributed key/value store, built on\u00a0Hadoop.\nApache Cassandra - column-oriented distributed datastore, inspired by\u00a0BigTable.\nApache HBase - column-oriented distributed datastore, inspired by BigTable.\nBaidu Tera - an Internet-scale database, inspired by BigTable.\nFacebook HydraBase - evolution of HBase made by Facebook.\nGoogle BigTable - column-oriented distributed datastore.\nGoogle Cloud Datastore - is a fully managed, schemaless database for storing non-relational data over BigTable.\nHypertable - column-oriented distributed datastore, inspired by\u00a0BigTable.\nInfiniDB - is accessed through a MySQL interface and use massive parallel processing to parallelize queries.\nTephra - Transactions for HBase.\nTwitter Manhattan - real-time, multi-tenant distributed database for Twitter scale.\nScyllaDB - column-oriented distributed datastore written in C++, totally compatible with Apache Cassandra.\nKey-value Data Model\nAerospike - NoSQL flash-optimized, in-memory. Open source and \"Server code in 'C' (not Java or Erlang) precisely tuned to avoid context switching and memory copies.\"\nAmazon DynamoDB - distributed key/value store, implementation of\u00a0Dynamo paper.\nBadger - a fast, simple, efficient, and persistent key-value store written natively in Go.\nBolt - an embedded key-value database for Go.\nBTDB - Key Value Database in .Net with Object DB Layer, RPC, dynamic IL and much more\nBuntDB - a fast, embeddable, in-memory key/value database for Go with custom indexing and geospatial support.\nEdis - is a protocol-compatible Server replacement for Redis.\nElephantDB - Distributed database specialized in exporting data from Hadoop.\nEventStore - distributed time series database.\nGhostDB - a distributed, in-memory, general purpose key-value data store that delivers microsecond performance at any scale.\nGraviton - a simple, fast, versioned, authenticated, embeddable key-value store database in pure Go(lang).\nGridDB - suitable for sensor data stored in a timeseries.\nHyperDex - a scalable, next generation key-value and document store with a wide array of features, including consistency, fault tolerance and high performance.\nIgnite - is an in-memory key-value data store providing full SQL-compliant data access that can optionally be backed by disk storage.\nLinkedIn Krati - is a simple persistent data store with very low latency and high throughput.\nLinkedin Voldemort - distributed key/value storage system.\nOracle NoSQL Database - distributed key-value database by Oracle Corporation.\nRedis - in memory key value datastore.\nRiak - a decentralized datastore.\nStorehaus - library to work with asynchronous key value stores, by Twitter.\nSummitDB - an in-memory, NoSQL key/value database, with disk persistance and using the Raft consensus algorithm.\nTarantool - an efficient NoSQL database and a Lua application server.\nTiKV - a distributed key-value database powered by Rust and inspired by Google Spanner and HBase.\nTile38 - a geolocation data store, spatial index, and realtime geofence, supporting a variety of object types including latitude/longitude points, bounding boxes, XYZ tiles, Geohashes, and GeoJSON\nTreodeDB - key-value store that's replicated and sharded and provides atomic multirow writes.\nGraph Data Model\nAgensGraph - a new generation multi-model graph database for the modern complex data environment.\nApache Giraph - implementation of Pregel, based on Hadoop.\nApache Spark Bagel - implementation of Pregel, part of Spark.\nArangoDB - multi model distributed database.\nDGraph - A scalable, distributed, low latency, high throughput graph database aimed at providing Google production level scale and throughput, with low enough latency to be serving real time user queries, over terabytes of structured data.\nEliasDB - a lightweight graph based database that does not require any third-party libraries.\nFacebook TAO - TAO is the distributed data store that is widely used at facebook to store and serve the social graph.\nGCHQ Gaffer - Gaffer by GCHQ is a framework that makes it easy to store large-scale graphs in which the nodes and edges have statistics.\nGoogle Cayley - open-source graph database.\nGoogle Pregel - graph processing framework.\nGraphLab PowerGraph - a core C++ GraphLab API and a collection of high-performance machine learning and data mining toolkits built on top of the GraphLab API.\nGraphX - resilient Distributed Graph System on Spark.\nGremlin - graph traversal Language.\nInfovore - RDF-centric Map/Reduce framework.\nIntel GraphBuilder - tools to construct large-scale graphs on top of Hadoop.\nJanusGraph - open-source, distributed graph database\n  with multiple options for storage backends (Bigtable, HBase, Cassandra, etc.)\n  and indexing backends (Elasticsearch, Solr, Lucene).\nMapGraph - Massively Parallel Graph processing on GPUs.\nMicrosoft Graph Engine - a distributed in-memory data processing engine, underpinned by a strongly-typed in-memory key-value store and a general distributed computation engine.\nNeo4j - graph database written entirely in Java.\nOrientDB - document and graph database.\nPhoebus - framework for large scale graph processing.\nTitan - distributed graph database, built over Cassandra.\nTwitter FlockDB - distributed graph database.\nNodeXL - A free, open-source template for Microsoft\u00ae Excel\u00ae 2007, 2010, 2013 and 2016 that makes it easy to explore network graphs.\nColumnar Databases\nNote please read the note on Key-Map Data Model section.\nColumnar Storage - an explanation of what columnar storage is and when you might want it.\nActian Vector - column-oriented analytic database.\nClickHouse - an open-source column-oriented database management system that allows generating analytical data reports in real time.\nEventQL - a distributed, column-oriented database built for large-scale event collection and analytics.\nMonetDB - column store database.\nParquet - columnar storage format for Hadoop.\nPivotal Greenplum - purpose-built, dedicated analytic data warehouse that offers a columnar engine as well as a traditional row-based one.\nVertica - is designed to manage large, fast-growing volumes of data and provide very fast query performance when used for data warehouses.\nSQream DB - A GPU powered big data database, designed for analytics and data warehousing, with ANSI-92 compliant SQL, suitable for data sets from 10TB to 1PB.\nGoogle BigQuery - Google's cloud offering backed by their pioneering work on Dremel.\nAmazon Redshift - Amazon's cloud offering, also based on a columnar datastore backend.\nIndexR - an open-source columnar storage format for fast & realtime analytic with big data.\nLocustDB - an experimental analytics database aiming to set a new standard for query performance on commodity hardware. \nNewSQL Databases\nActian Ingres - commercially supported, open-source SQL relational database management system.\nActorDB - a distributed SQL database with the scalability of a KV store, while keeping the query capabilities of a relational database.\nAmazon RedShift - data warehouse service, based on PostgreSQL.\nBayesDB - statistic oriented SQL database.\nBedrock - a simple, modular, networked and distributed transaction layer built atop SQLite.\nCitusDB - scales out PostgreSQL through sharding and replication.\nCockroach - Scalable, Geo-Replicated, Transactional Datastore.\nComdb2 - a clustered RDBMS built on optimistic concurrency control techniques.\nDatomic - distributed database designed to enable scalable, flexible and intelligent applications.\nFoundationDB - distributed database, inspired by\u00a0F1.\nGoogle F1 - distributed SQL database built on Spanner.\nGoogle Spanner - globally distributed semi-relational database.\nH-Store - is an experimental main-memory, parallel database management system that is optimized for on-line transaction processing (OLTP) applications.\nHaeinsa - linearly scalable multi-row, multi-table transaction library for HBase based on Percolator.\nHandlerSocket - NoSQL plugin for MySQL/MariaDB.\nInfiniSQL - infinity scalable RDBMS.\nKarelDB - a relational database backed by Apache Kafka.\nMap-D - GPU in-memory database, big data analysis and visualization platform.\nMemSQL - in memory SQL database witho optimized columnar storage on flash.\nNuoDB - SQL/ACID compliant distributed database.\nOracle TimesTen in-Memory Database - in-memory, relational database management system with persistence and recoverability.\nPivotal GemFire XD - Low-latency, in-memory, distributed SQL data store. Provides SQL interface to in-memory table data, persistable in HDFS.\nSAP HANA - is an in-memory, column-oriented, relational database management system.\nSenseiDB - distributed, realtime, semi-structured database.\nSky - database used for flexible, high performance analysis of behavioral data.\nSymmetricDS - open source software for both file and database synchronization.\nTiDB - TiDB is a distributed SQL database. Inspired by the design of Google F1.\nVoltDB - claims to be fastest in-memory database.\nyugabyteDB - open source, high-performance, distributed SQL database compatible with PostgreSQL.\nTime-Series Databases\nAxibase Time Series Database - Integrated time series database on top of HBase with built-in visualization, rule-engine and SQL support.\nChronix - a time series storage built to store time series highly compressed and for fast access times.\nCube - uses MongoDB to store time series data.\nHeroic - is a scalable time series database based on Cassandra and Elasticsearch.\nInfluxDB - a time series database with optimised IO and queries, supports pgsql and influx wire protocols.\nQuestDB - high-performance, open-source SQL database for applications in financial services, IoT, machine learning, DevOps and observability.\nIronDB - scalable, general-purpose time series database.\nKairosdb - similar to OpenTSDB but allows for Cassandra.\nM3DB - a distributed time series database that can be used for storing realtime metrics at long retention.\nNewts - a time series database based on Apache Cassandra.\nTDengine - a time series database in C utilizing unique features of IoT to improve read/write throughput and reduce space needed to store data\nOpenTSDB - distributed time series database on top of HBase.\nPrometheus - a time series database and service monitoring system.\nBeringei - Facebook's in-memory time-series database.\nTrailDB - an efficient tool for storing and querying series of events.\nDruid Column oriented distributed data store ideal for powering interactive applications\nRiak-TS Riak TS is the only enterprise-grade NoSQL time series database optimized specifically for IoT and Time Series data.\nAkumuli Akumuli is a numeric time-series database. It can be used to capture, store and process time-series data in real-time. The word \"akumuli\" can be translated from esperanto as \"accumulate\".\nRhombus A time-series object store for Cassandra that handles all the complexity of building wide row indexes.\nDalmatiner DB Fast distributed metrics database\nBlueflood A distributed system designed to ingest and process time series data\nTimely Timely is a time series database application that provides secure access to time series data based on Accumulo and Grafana.\nSiriDB Highly-scalable, robust and fast, open source time series database with cluster functionality.\nThanos - Thanos is a set of components to create a highly available metric system with unlimited storage capacity using multiple (existing) Prometheus deployments.\nVictoriaMetrics - fast, scalable and resource-effective open-source TSDB compatible with Prometheus. Single-node and cluster versions included\nSQL-like processing\nActian SQL for Hadoop - high performance interactive SQL access to all Hadoop data.\nApache Drill - framework for interactive analysis, inspired by Dremel.\nApache HCatalog - table and storage management layer for Hadoop.\nApache Hive - SQL-like data warehouse system for Hadoop.\nApache Calcite - framework that allows efficient translation of queries involving heterogeneous and federated data.\nApache Phoenix - SQL skin over HBase.\nAster Database - SQL-like analytic processing for MapReduce.\nCloudera Impala - framework for interactive analysis, Inspired by Dremel.\nConcurrent Lingual - SQL-like query language for Cascading.\nDatasalt Splout SQL - full SQL query engine for big datasets.\nDremio - an open-source, SQL-like Data-as-a-Service Platform based on Apache Arrow.\nFacebook PrestoDB - distributed SQL query engine.\nGoogle BigQuery - framework for interactive analysis, implementation of Dremel.\nMaterialize - is a streaming database for real-time applications using SQL for queries and supporting a large fraction of PostgreSQL.\nInvantive SQL - SQL engine for online and on-premise use with integrated local data replication and 70+ connectors.\nPipelineDB - an open-source relational database that runs SQL queries continuously on streams, incrementally storing results in tables.\nPivotal HDB - SQL-like data warehouse system for\u00a0Hadoop.\nRainstorDB - database for storing petabyte-scale volumes of structured and semi-structured data.\nSpark Catalyst - is a Query Optimization Framework for Spark and Shark.\nSparkSQL - Manipulating Structured Data Using Spark.\nSplice Machine - a full-featured SQL-on-Hadoop RDBMS with ACID transactions.\nStinger - interactive query for Hive.\nTajo - distributed data warehouse system on Hadoop.\nTrafodion - enterprise-class SQL-on-HBase solution targeting big data transactional or operational workloads.\nData Ingestion\nredpanda - A Kafka\u00ae replacement for mission critical systems; 10x faster. Written in C++.\nAmazon Kinesis - real-time processing of streaming data at massive scale.\nAmazon Web Services Glue -  serverless fully managed extract, transform, and load (ETL) service\nCensus - A reverse ETL product that let you sync data from your data warehouse to SaaS Applications. No engineering favors required\u2014just SQL.\nApache Chukwa - data collection system.\nApache Flume - service to manage large amount of log data.\nApache Kafka - distributed publish-subscribe messaging system.\nApache NiFi - Apache NiFi is an integrated data logistics platform for automating the movement of data between disparate systems.\nApache Pulsar - a distributed pub-sub messaging platform with a very flexible messaging model and an intuitive client API.\nApache Sqoop - tool to transfer data between Hadoop and a structured datastore.\nEmbulk - open-source bulk data loader that helps data transfer between various databases, storages, file formats, and cloud services.\nFacebook Scribe - streamed log data aggregator.\nFluentd - tool to collect events and logs.\nGazette - Distributed streaming infrastructure built on cloud storage which makes it easy to mix and match batch and streaming paradigms.\nGoogle Photon - geographically distributed system for joining multiple continuously flowing streams of data in real-time with high scalability and low latency.\nHeka - open source stream processing software system.\nHIHO - framework for connecting disparate data sources with Hadoop.\nKestrel - distributed message queue system.\nLinkedIn Databus - stream of change capture events for a database.\nLinkedIn Kamikaze - utility package for compressing sorted integer arrays.\nLinkedIn White Elephant - log aggregator and dashboard.\nLogstash - a tool for managing events and logs.\nNetflix Suro - log agregattor like Storm and Samza based on Chukwa.\nPinterest Secor - is a service implementing Kafka log persistance.\nLinkedin Gobblin - linkedin's universal data ingestion framework.\nSkizze - sketch data store to deal with all problems around counting and sketching using probabilistic data-structures.\nStreamSets Data Collector - continuous big data ingest infrastructure with a simple to use IDE.\nAlooma - data pipeline as a service enabling moving data sources such as MySQL into data warehouses.\nRudderStack - an open source customer data infrastructure (segment, mParticle  alternative) written in go.\nService Programming\nAkka Toolkit - runtime for distributed, and fault tolerant event-driven applications on the JVM.\nApache Avro - data serialization system.\nApache Curator - Java libaries for Apache ZooKeeper.\nApache Karaf - OSGi runtime that runs on top of any OSGi framework.\nApache Thrift - framework to build binary protocols.\nApache Zookeeper - centralized service for process management.\nGoogle Chubby - a lock service for loosely-coupled distributed systems.\nHydrosphere Mist - a service for exposing Apache Spark analytics jobs and machine learning models as realtime, batch or reactive web services.\nLinkedin Norbert - cluster manager.\nMara - A lightweight opinionated ETL framework, halfway between plain scripts and Apache Airflow\nOpenMPI - message passing framework.\nSerf - decentralized solution for service discovery and orchestration.\nSpotify Luigi - a Python package for building complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization, handling failures, command line integration, and much more.\nSpring XD - distributed and extensible system for data ingestion, real time analytics, batch processing, and data export.\nTwitter Elephant Bird - libraries for working with LZOP-compressed data.\nTwitter Finagle - asynchronous network stack for the JVM.\nScheduling\nApache Airflow - a platform to programmatically author, schedule and monitor workflows.\nApache Aurora - is a service scheduler that runs on top of Apache Mesos.\nApache Falcon - data management framework.\nApache Oozie - workflow job scheduler.\nAzure Data Factory - cloud-based pipeline orchestration for on-prem, cloud and HDInsight\nChronos - distributed and fault-tolerant scheduler.\nCronicle - Distributed, easy to install, NodeJS based, task scheduler\nDagster - a data orchestrator for machine learning, analytics, and ETL.\nLinkedin Azkaban - batch workflow job scheduler.\nSchedoscope - Scala DSL for agile scheduling of Hadoop jobs.\nSparrow - scheduling platform.\nMachine Learning\nAzure ML Studio - Cloud-based AzureML, R, Python Machine Learning platform\nbrain - Neural networks in JavaScript.\nOryx - Lambda architecture on Apache Spark, Apache Kafka for real-time large scale machine learning.\nConcurrent Pattern - machine learning library for Cascading.\nconvnetjs - Deep Learning in Javascript. Train Convolutional Neural Networks (or ordinary ones) in your browser.\nDataVec - A vectorization and data preprocessing library for deep learning in Java and Scala. Part of the Deeplearning4j ecosystem. \nDeeplearning4j - Fast, open deep learning for the JVM (Java, Scala, Clojure). A neural network configuration layer powered by a C++ library. Uses Spark and Hadoop to train nets on multiple GPUs and CPUs.\nDecider - Flexible and Extensible Machine Learning in Ruby.\nENCOG - machine learning framework that supports a variety of advanced algorithms, as well as support classes to normalize and process data.\netcML - text classification with machine learning.\nEtsy Conjecture - scalable Machine Learning in Scalding.\nFeast - A feature store for the management, discovery, and access of machine learning features. Feast provides a consistent view of feature data for both model training and model serving.\nGraphLab Create - A machine learning platform in Python with a broad collection of ML toolkits, data engineering, and deployment tools.\nH2O - statistical, machine learning and math runtime with Hadoop. R and Python.\nKarate Club - An unsupervised machine learning library for graph structured data. Python\nKeras - An intuitive neural net API inspired by Torch that runs atop Theano and Tensorflow.\nLambdo - Lambdo is a workflow engine which significantly simplifies the analysis process by unifying feature engineering and machine learning operations.\nLittle Ball of Fur - A subsampling library for graph structured data. Python\nMahout - An Apache-backed machine learning library for Hadoop.\nMLbase - distributed machine learning libraries for the BDAS stack.\nMLPNeuralNet - Fast multilayer perceptron neural network library for iOS and Mac OS X.\nML Workspace - All-in-one web-based IDE specialized for machine learning and data science.\nMOA - MOA performs big data stream mining in real time, and large scale machine learning.\nMonkeyLearn - Text mining made easy. Extract and classify data from text.\nND4J - A matrix library for the JVM. Numpy for Java. \nnupic - Numenta Platform for Intelligent Computing: a brain-inspired machine intelligence platform, and biologically accurate neural network based on cortical learning algorithms.\nPredictionIO - machine learning server buit on Hadoop, Mahout and Cascading.\nPyTorch Geometric Temporal - a temporal extension library for PyTorch Geometric .\nRL4J - Reinforcement learning for Java and Scala. Includes Deep-Q learning and A3C algorithms, and integrates with Open AI's Gym. Runs in the Deeplearning4j ecosystem. \nSAMOA - distributed streaming machine learning framework.\nscikit-learn - scikit-learn: machine learning in Python.\nShapley - A data-driven framework to quantify the value of classifiers in a machine learning ensemble. \nSpark MLlib - a Spark implementation of some common machine learning (ML) functionality.\nSibyl - System for Large Scale Machine Learning at Google.\nTensorFlow - Library from Google for machine learning using data flow graphs.\nTheano - A Python-focused machine learning library supported by the University of Montreal.\nTorch - A deep learning library with a Lua API, supported by NYU and Facebook.\nVelox - System for serving machine learning predictions.\nVowpal Wabbit - learning system sponsored by Microsoft and Yahoo!.\nWEKA - suite of machine learning software.\nBidMach - CPU and GPU-accelerated Machine Learning Library.\nBenchmarking\nApache Hadoop Benchmarking - micro-benchmarks for testing Hadoop performances.\nBerkeley SWIM Benchmark - real-world big data workload benchmark.\nIntel HiBench - a Hadoop benchmark suite.\nPUMA Benchmarking - benchmark suite for MapReduce applications.\nYahoo Gridmix3 - Hadoop cluster benchmarking from Yahoo engineer team.\nDeeplearning4j Benchmarks\nSecurity\nApache Ranger - Central security admin & fine-grained authorization for Hadoop\nApache Eagle - real time monitoring solution\nApache Knox Gateway - single point of secure access for Hadoop clusters.\nApache Sentry - security module for data stored in Hadoop.\nBDA - The vulnerability detector for Hadoop and Spark\nSystem Deployment\nApache Ambari - operational framework for Hadoop mangement.\nApache Bigtop - system deployment framework for the Hadoop ecosystem.\nApache Helix - cluster management framework.\nApache Mesos - cluster manager.\nApache Slider - is a YARN application to deploy existing distributed applications on YARN.\nApache Whirr - set of libraries for running cloud services.\nApache YARN - Cluster manager.\nBrooklyn - library that simplifies application deployment and management.\nBuildoop - Similar to Apache BigTop based on Groovy language.\nCloudera HUE - web application for interacting with Hadoop.\nFacebook Prism - multi datacenters replication system.\nGoogle Borg - job scheduling and monitoring system.\nGoogle Omega - job scheduling and monitoring system.\nHortonworks HOYA - application that can deploy HBase cluster on YARN.\nKubernetes - a system for automating deployment, scaling, and management of containerized applications.\nMarathon - Mesos framework for long-running services.\nLinkis - Linkis helps easily connect to various back-end computation/storage engines.\nApplications\n411 - an web application for alert management resulting from scheduled searches into Elasticsearch.\nAdobe spindle - Next-generation web analytics processing with Scala, Spark, and Parquet.\nApache Metron - a platform that integrates a variety of open source big data technologies in order to offer a centralized tool for security monitoring and analysis.\nApache Nutch - open source web crawler.\nApache OODT - capturing, processing and sharing of data for NASA's scientific archives.\nApache Tika - content analysis toolkit.\nArgus - Time series monitoring and alerting platform.\nAthenaX - a streaming analytics platform that enables users to run production-quality, large scale streaming analytics using Structured Query Language (SQL).\nAtlas - a backend for managing dimensional time series data.\nCountly - open source mobile and web analytics platform, based on Node.js & MongoDB.\nDomino - Run, scale, share, and deploy models \u2014 without any infrastructure.\nEclipse BIRT - Eclipse-based reporting system.\nElastAert - ElastAlert is a simple framework for alerting on anomalies, spikes, or other patterns of interest from data in ElasticSearch.\nEventhub - open source event analytics platform.\nHASH - open source simulation and visualization platform.\nHermes - asynchronous message broker built on top of Kafka.\nHunk - Splunk analytics for Hadoop.\nImhotep - Large scale analytics platform by indeed.\nIndicative - Web & mobile analytics tool, with data warehouse (AWS, BigQuery) integration.\nJupyter - Notebook and project application for interactive data science and scientific computing across all programming languages.\nMADlib - data-processing library of an RDBMS to analyze data.\nKapacitor - an open source framework for processing, monitoring, and alerting on time series data.\nKylin - open source Distributed Analytics Engine from eBay.\nPivotalR - R on Pivotal HD / HAWQ and PostgreSQL.\nRakam - open-source real-time custom analytics platform powered by Postgresql, Kinesis and PrestoDB. \nQubole - auto-scaling Hadoop cluster, built-in data connectors.\nSnappyData - a distributed in-memory data store for real-time operational analytics, delivering stream analytics, OLTP (online transaction processing) and OLAP (online analytical processing) built on Spark in a single integrated cluster.\nSnowplow - enterprise-strength web and event analytics, powered by Hadoop, Kinesis, Redshift and Postgres.\nSparkR - R frontend for Spark.\nSplunk - analyzer for machine-generated data.\nSumo Logic - cloud based analyzer for machine-generated data.\nTalend - unified open source environment for YARN, Hadoop, HBASE, Hive, HCatalog & Pig.\nSearch engine and framework\nApache Lucene - Search engine library.\nApache Solr - Search platform for Apache Lucene.\nElassandra - is a fork of Elasticsearch modified to run on top of Apache Cassandra in a scalable and resilient peer-to-peer architecture.\nElasticSearch - Search and analytics engine based on Apache\u00a0Lucene.\nEnigma.io \u2013 Freemium robust web application for exploring, filtering, analyzing, searching and exporting massive datasets scraped from across the Web.\nGoogle Caffeine - continuous indexing system.\nGoogle Percolator - continuous indexing system.\nHBase Coprocessor - implementation of\u00a0Percolator, part of\u00a0HBase.\nLily HBase Indexer - quickly and easily search for any content stored in HBase.\nLinkedIn Bobo - is a Faceted Search implementation written purely in Java, an extension to Apache Lucene.\nLinkedIn Cleo - is a flexible software library for enabling rapid development of partial, out-of-order and real-time typeahead search.\nLinkedIn Galene - search architecture at LinkedIn.\nLinkedIn Zoie - is a realtime search/indexing system written in Java.\nMG4J - MG4J (Managing Gigabytes for Java) is a full-text search engine for large document collections written in Java. It is highly customisable, high-performance and provides state-of-the-art features and new research algorithms.\nSphinx Search Server - fulltext search engine.\nVespa - is an engine for low-latency computation over large data sets. It stores and indexes your data such that queries, selection and processing over the data can be performed at serving time.\nFacebook Faiss - is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. Faiss is written in C++ with complete wrappers for Python/numpy.\nAnnoy - is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are mmapped into memory so that many processes may share the same data.\nWeaviate - Weaviate is a GraphQL-based semantic search engine with build-in (word) embeddings.\nMySQL forks and evolutions\nAmazon RDS - MySQL databases in Amazon's cloud.\nDrizzle - evolution of MySQL 6.0.\nGoogle Cloud SQL - MySQL databases in Google's cloud.\nMariaDB - enhanced, drop-in replacement for MySQL.\nMySQL Cluster - MySQL implementation using NDB Cluster storage engine.\nPercona Server - enhanced, drop-in replacement for MySQL.\nProxySQL - High Performance Proxy for MySQL.\nTokuDB - TokuDB is a storage engine for MySQL and MariaDB.\nWebScaleSQL - is a collaboration among engineers from several companies that face similar challenges in running MySQL at scale.\nPostgreSQL forks and evolutions\nHadoopDB - hybrid of MapReduce and DBMS.\nIBM Netezza - high-performance data warehouse appliances.\nPostgres-XL - Scalable Open Source PostgreSQL-based Database Cluster.\nRecDB - Open Source Recommendation Engine Built Entirely Inside PostgreSQL.\nStado - open source MPP database system solely targeted at data warehousing and data mart applications.\nYahoo Everest - multi-peta-byte database / MPP derived by PostgreSQL.\nTimescaleDB - An open-source time-series database optimized for fast ingest and complex queries\nPipelineDB - The Streaming SQL Database. An open-source relational database that runs SQL queries continuously on streams, incrementally storing results in tables\nMemcached forks and evolutions\nFacebook McDipper - key/value cache for flash storage.\nFacebook Memcached - fork of Memcache.\nTwemproxy - A fast, light-weight proxy for memcached and redis.\nTwitter Fatcache - key/value cache for flash storage.\nTwitter Twemcache - fork of Memcache.\nEmbedded Databases\nActian PSQL - ACID-compliant DBMS developed by Pervasive Software, optimized for embedding in applications.\nBerkeleyDB - a software library that provides a high-performance embedded database for key/value data.\nHanoiDB - Erlang LSM BTree Storage.\nLevelDB - a fast key-value storage library written at Google that provides an ordered mapping from string keys to string values.\nLMDB - ultra-fast, ultra-compact key-value embedded data store developed by Symas.\nRocksDB - embeddable persistent key-value store for fast storage based on LevelDB.\nBusiness Intelligence\nBIME Analytics - business intelligence platform in the cloud.\nBlazer - business intelligence made simple.\nChartio - lean business intelligence platform to visualize and explore your data.\nCount - notebook-based anlytics and visualisation platform using SQL or drag-and-drop.\ndatapine - self-service business intelligence tool in the cloud.\nDekart - Large scale geospatial analytics for Google BigQuery based on Kepler.gl.\nGoodData - platform for data products and embedded analytics.\nJaspersoft - powerful business intelligence suite.\nJedox Palo - customisable Business Intelligence platform.\nJethrodata - Interactive Big Data Analytics.\nintermix.io - Performance Monitoring for Amazon Redshift\nMetabase - The simplest, fastest way to get business intelligence and analytics to everyone in your company.\nMicrosoft - business intelligence software and platform.\nMicrostrategy - software platforms for business intelligence, mobile intelligence, and network applications.\nNumeracy - Fast, clean SQL client and business intelligence.\nPentaho - business intelligence platform.\nQlik - business intelligence and analytics platform.\nRedash - Open source business intelligence platform, supporting multiple data sources and planned queries.\nSaiku Analytics - Open source analytics platform.\nKnowage - open source business intelligence platform. (former SpagoBi)\nSparklineData SNAP - modern B.I platform powered by Apache Spark.\nTableau - business intelligence platform.\nZoomdata - Big Data Analytics.\nData Visualization\nAirpal - Web UI for PrestoDB.\nAnyChart - fast, simple and flexible JavaScript (HTML5) charting library featuring pure JS API.\nArbor - graph visualization library using web workers and jQuery.\nBanana - visualize logs and time-stamped data stored in Solr. Port of Kibana.\nBloomery - Web UI for Impala.\nBokeh - A powerful Python interactive visualization library that targets modern web browsers for presentation, with the goal of providing elegant, concise construction of novel graphics in the style of D3.js, but also delivering this capability with high-performance interactivity over very large or streaming datasets.\nC3 - D3-based reusable chart library\nCartoDB - open-source or freemium hosting for geospatial databases with powerful front-end editing capabilities and a robust API.\nchartd - responsive, retina-compatible charts with just an img tag.\nChart.js - open source HTML5 Charts visualizations.\nChartist.js - another open source HTML5 Charts visualization.\nCrossfilter -  JavaScript library for exploring large multivariate datasets in the browser. Works well with dc.js and d3.js.\nCubism - JavaScript library for time series visualization.\nCytoscape - JavaScript library for visualizing complex networks.\nDC.js - Dimensional charting built to work natively with crossfilter rendered using d3.js. Excellent for connecting charts/additional metadata to hover events in D3.\nD3 - javaScript library for manipulating documents.\nD3.compose - Compose complex, data-driven visualizations from reusable charts and components.\nD3Plus - A fairly robust set of reusable charts and styles for d3.js.\nDash - Analytical Web Apps for Python, R, Julia, and Jupyter. Built on top of plotly, no JS required\nDekart - Large scale geospatial analytics for Google BigQuery based on Kepler.gl.\nDevExtreme React Chart - High-performance plugin-based React chart for Bootstrap and Material Design.\nEcharts - Baidus enterprise charts.\nEnvisionjs - dynamic HTML5 visualization.\nFnordMetric - write SQL queries that return SVG charts rather than tables\nFrappe Charts - GitHub-inspired simple and modern SVG charts for the web with zero dependencies.\nFreeboard - pen source real-time dashboard builder for IOT and other web mashups.\nGephi - An award-winning open-source platform for visualizing and manipulating large graphs and network connections. It's like Photoshop, but for graphs. Available for Windows and Mac OS X.\nGoogle Charts - simple charting API.\nGrafana - graphite dashboard frontend, editor and graph composer.\nGraphite - scalable Realtime Graphing.\nHighcharts - simple and flexible charting API.\nIPython - provides a rich architecture for interactive computing.\nKibana - visualize logs and time-stamped data\nLumify - open source big data analysis and visualization platform\nMatplotlib - plotting with Python.\nMetricsgraphic.js - a library built on top of D3 that is optimized for time-series data\nNVD3 - chart components for d3.js.\nPeity - Progressive SVG bar, line and pie charts.\nPlot.ly - Easy-to-use web service that allows for rapid creation of complex charts, from heatmaps to histograms. Upload data to create and style charts with Plotly's online spreadsheet. Fork others' plots.\nPlotly.js The open source javascript graphing library that powers plotly.\nRecline - simple but powerful library for building data applications in pure Javascript and HTML.\nRedash - open-source platform to query and visualize data.\nReCharts - A composable charting library built on React components\nShiny - a web application framework for R.\nSigma.js - JavaScript library dedicated to graph drawing.\nSuperset - a data exploration platform designed to be visual, intuitive and interactive, making it easy to slice, dice and visualize data and perform analytics at the speed of thought.\nVega - a visualization grammar.\nZeppelin - a notebook-style collaborative data analysis.\nZing Charts - JavaScript charting library for big data.\nDataSphere Studio - one-stop data application development management portal.\nInternet of things and sensor data\nApache Edgent (Incubating) - a programming model and micro-kernel style runtime that can be embedded in gateways and small footprint edge devices enabling local, real-time, analytics on the edge devices.\nAzure IoT Hub - Cloud-based bi-directional monitoring and messaging hub\nTempoIQ - Cloud-based sensor analytics.\n2lemetry - Platform for Internet of things.\nPubnub - Data stream network\nThingWorx - Rapid development and connection of intelligent systems\nIFTTT - If this then that\nEvrything- Making products smart\nNetLytics - Analytics platform to process network data on Spark.\nAbly - Pub/sub messaging platform for IoT \nInteresting Readings\nBig Data Benchmark - Benchmark of Redshift, Hive, Shark, Impala and Stiger/Tez.\nNoSQL Comparison - Cassandra vs MongoDB vs CouchDB vs Redis vs Riak vs HBase vs Couchbase vs Neo4j vs Hypertable vs ElasticSearch vs Accumulo vs VoltDB vs Scalaris comparison.\nMonitoring Kafka performance - Guide to monitoring Apache Kafka, including native methods for metrics collection.\nMonitoring Hadoop performance - Guide to monitoring Hadoop, with an overview of Hadoop architecture, and native methods for metrics collection.\nMonitoring Cassandra performance - Guide to monitoring Cassandra, including native methods for metrics collection.\nInteresting Papers\n2015 - 2016\n2015 - Facebook - One Trillion Edges: Graph Processing at Facebook-Scale.\n2013 - 2014\n2014 - Stanford - Mining of Massive Datasets.\n2013 - AMPLab - Presto: Distributed Machine Learning and Graph Processing with Sparse Matrices.\n2013 - AMPLab - MLbase: A Distributed Machine-learning System.\n2013 - AMPLab - Shark: SQL and Rich Analytics at Scale.\n2013 - AMPLab - GraphX: A Resilient Distributed Graph System on Spark.\n2013 - Google - HyperLogLog in Practice: Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm.\n2013 - Microsoft - Scalable Progressive Analytics on Big Data in the Cloud.\n2013 - Metamarkets - Druid: A Real-time Analytical Data Store.\n2013 - Google - Online, Asynchronous Schema Change in F1.\n2013 - Google - F1: A Distributed SQL Database That Scales.\n2013 - Google - MillWheel: Fault-Tolerant Stream Processing at Internet Scale.\n2013 - Facebook - Scuba: Diving into Data at Facebook.\n2013 - Facebook - Unicorn: A System for Searching the Social Graph.\n2013 - Facebook - Scaling Memcache at Facebook.\n2011 - 2012\n2012 - Twitter - The Unified Logging Infrastructure\nfor Data Analytics at Twitter.\n2012 - AMPLab - Blink and It\u2019s Done: Interactive Queries on Very Large Data.\n2012 - AMPLab - Fast and Interactive Analytics over Hadoop Data with Spark.\n2012 - AMPLab - Shark: Fast Data Analysis Using Coarse-grained Distributed Memory.\n2012 - Microsoft - Paxos Replicated State Machines as the Basis of a High-Performance Data Store.\n2012 - Microsoft - Paxos Made Parallel.\n2012 - AMPLab - BlinkDB: Queries with Bounded Errors and Bounded Response Times on Very Large Data.\n2012 - Google - Processing a trillion cells per mouse click.\n2012 - Google - Spanner: Google\u2019s Globally-Distributed Database.\n2011 - AMPLab - Scarlett: Coping with Skewed Popularity Content in MapReduce Clusters.\n2011 - AMPLab - Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center.\n2011 - Google - Megastore: Providing Scalable, Highly Available Storage for Interactive Services.\n2001 - 2010\n2010 - Facebook - Finding a needle in Haystack: Facebook\u2019s photo storage.\n2010 - AMPLab - Spark: Cluster Computing with Working Sets.\n2010 - Google - Pregel: A System for Large-Scale Graph Processing.\n2010 - Google - Large-scale Incremental Processing Using Distributed Transactions and Noti\ufb01cations base of Percolator and Caffeine.\n2010 - Google - Dremel: Interactive Analysis of Web-Scale Datasets.\n2010 - Yahoo - S4: Distributed Stream Computing Platform.\n2009 - HadoopDB: An Architectural Hybrid of MapReduce and DBMS Technologies for Analytical Workloads. \n2008 - AMPLab - Chukwa: A large-scale monitoring system.\n2007 - Amazon - Dynamo: Amazon\u2019s Highly Available Key-value Store.\n2006 - Google - The Chubby lock service for loosely-coupled distributed systems.\n2006 - Google - Bigtable: A Distributed Storage System for Structured Data.\n2004 - Google - MapReduce: Simplied Data Processing on Large Clusters.\n2003 - Google - The Google File System.\nVideos\nSpark in Motion - Spark in Motion teaches you how to use Spark for batch and streaming data analytics.\nMachine Learning, Data Science and Deep Learning with Python  - LiveVideo tutorial that covers machine learning, Tensorflow, artificial intelligence, and neural networks.\nData warehouse schema design - dimensional modeling and star schema - Introduction to schema design for data warehouse using the star schema method.\nElasticsearch 7 and Elastic Stack - LiveVideo tutorial that covers searching, analyzing, and visualizing big data on a cluster with Elasticsearch, Logstash, Beats, Kibana, and more.\nBooks\nStreaming\nData Science at Scale with Python and Dask - Data Science at Scale with Python and Dask teaches you how to build distributed data projects that can handle huge amounts of data.\nStreaming Data - Streaming Data introduces the concepts and requirements of streaming and real-time data systems.\nStorm Applied - Storm Applied is a practical guide to using Apache Storm for the real-world tasks associated with processing and analyzing real-time data streams.\nFundamentals of Stream Processing: Application Design, Systems, and Analytics - This comprehensive, hands-on guide combining the fundamental building blocks and emerging research in stream processing is ideal for application designers, system builders, analytic developers, as well as students and researchers in the field.\nStream Data Processing: A Quality of Service Perspective - Presents a new paradigm suitable for stream and complex event processing.\nUnified Log Processing - Unified Log Processing is a practical guide to implementing a unified log of event streams (Kafka or Kinesis) in your business\nKafka Streams in Action - Kafka Streams in Action teaches you everything you need to know to implement stream processing on data flowing into your Kafka platform, allowing you to focus on getting more from your data without sacrificing time or effort.\nBig Data - Big Data teaches you to build big data systems using an architecture that takes advantage of clustered hardware along with new tools designed specifically to capture and analyze web-scale data.\nSpark in Action & Spark in Action 2nd Ed. - Spark in Action teaches you the theory and skills you need to effectively handle batch and streaming data using Spark. Fully updated for Spark 2.0.\nKafka in Action - Kafka in Action is a fast-paced introduction to every aspect of working with Kafka you need to really reap its benefits.\nFusion in Action - Fusion in Action teaches you to build a full-featured data analytics pipeline, including document and data search and distributed data clustering.\nReactive Data Handling - Reactive Data Handling is a collection of five hand-picked chapters, selected by Manuel Bernhardt, that introduce you to building reactive applications capable of handling real-time processing with large data loads--free eBook! \nAzure Data Engineering - A book about data engineering in general and the Azure platform specifically \nGrokking Streaming Systems - Grokking Streaming Systems helps you unravel what streaming systems are, how they work, and whether they\u2019re right for your business. Written to be tool-agnostic, you\u2019ll be able to apply what you learn no matter which framework you choose.\nDistributed systems\nDistributed Systems for fun and profit \u2013 Theory of distributed systems. Include parts about time and ordering, replication and impossibility results.\nGraph Based approach\nGraph-Powered Machine Learning - Alessandro Negro. Combine graph theory and models to improve machine learning projects\nData Visualization\nThe beauty of data visualization\nDesigning Data Visualizations with Noah Iliinsky\nHans Rosling's 200 Countries, 200 Years, 4 Minutes\nIce Bucket Challenge Data Visualization\nOther Awesome Lists\nOther awesome lists awesome-awesomeness.\nEven more lists awesome.\nAnother list? list.\nWTF! awesome-awesome-awesome.\nAnalytics awesome-analytics.\nPublic Datasets awesome-public-datasets.\nGraph Classification awesome-graph-classification.\nNetwork Embedding awesome-network-embedding.\nCommunity Detection awesome-community-detection.\nDecision Tree Papers awesome-decision-tree-papers.\nFraud Detection Papers awesome-fraud-detection-papers.\nGradient Boosting Papers awesome-gradient-boosting-papers.\nMonte Carlo Tree Search Papers awesome-monte-carlo-tree-search-papers.\nKafka awesome-kafka.\nGoogle Bigtable.",
	"data-visualization geospatial-analysis javascript maps python visualization webgl": "deck.gl | Website\n WebGL2-powered, highly performant large-scale data visualization\ndeck.gl is designed to simplify high-performance, WebGL-based visualization of large data sets. Users can quickly get impressive visual results with minimal effort by composing existing layers, or leverage deck.gl's extensible architecture to address custom needs.\ndeck.gl maps data (usually an array of JSON objects) into a stack of visual layers - e.g. icons, polygons, texts; and look at them with views: e.g. map, first-person, orthographic.\ndeck.gl handles a number of challenges out of the box:\nPerformant rendering and updating of large data sets\nInteractive event handling such as picking, highlighting and filtering\nCartographic projections and integration with major basemap providers\nA catalog of proven, well-tested layers\nDeck.gl is designed to be highly customizable. All layers come with flexible APIs to allow programmatic control of each aspect of the rendering. All core classes such are easily extendable by the users to address custom use cases.\nFlavors\nScript Tag\n```html\n```\nGet started\nFull examples\nNPM Module\nbash\nnpm install deck.gl\nPure JS\nGet started\nFull examples\nReact\nGet started\nFull examples\nPython\nbash\npip install pydeck\nGet started\nExamples\nThird-Party Goodies\ndeckgl-typings (Typescript)\nmapdeck (R)\nvega-deck.gl (Vega)\nearthengine-layers (Google Earth Engine)\ndeck.gl-native (C++)\ndeck.gl-raster (Computation on rasters)\nLearning Resources\nAPI documentation for the latest release\nWebsite demos with links to source\nInteractive playground\ndeck.gl Codepen demos\ndeck.gl Observable demos\nvis.gl Medium blog\ndeck.gl Slack workspace\nContributing\ndeck.gl is part of vis.gl, an OpenJS Foundation project. Read the contribution guidelines if you are interested in contributing.\nAttributions\nData sources\nData sources are listed in each example.\nThe deck.gl project is supported by",
	"deep-learning deep-neural-networks distributed machine-learning ml neural-network python tensorflow": "Documentation |\n------------------- |\n |\nTensorFlow is an end-to-end open source platform\nfor machine learning. It has a comprehensive, flexible ecosystem of\ntools,\nlibraries, and\ncommunity resources that lets\nresearchers push the state-of-the-art in ML and developers easily build and\ndeploy ML-powered applications.\nTensorFlow was originally developed by researchers and engineers working on the\nGoogle Brain team within Google's Machine Intelligence Research organization to\nconduct machine learning and deep neural networks research. The system is\ngeneral enough to be applicable in a wide variety of other domains, as well.\nTensorFlow provides stable Python\nand C++ APIs, as well as\nnon-guaranteed backward compatible API for\nother languages.\nKeep up-to-date with release announcements and security updates by subscribing\nto\nannounce@tensorflow.org.\nSee all the mailing lists.\nInstall\nSee the TensorFlow install guide for the\npip package, to\nenable GPU support, use a\nDocker container, and\nbuild from source.\nTo install the current release, which includes support for\nCUDA-enabled GPU cards (Ubuntu and\nWindows):\n$ pip install tensorflow\nOther devices (DirectX and MacOS-metal) are supported using\nDevice plugins.\nA smaller CPU-only package is also available:\n$ pip install tensorflow-cpu\nTo update TensorFlow to the latest version, add --upgrade flag to the above\ncommands.\nNightly binaries are available for testing using the\ntf-nightly and\ntf-nightly-cpu packages on PyPi.\nTry your first TensorFlow program\nshell\n$ python\n```python\nimport tensorflow as tf\ntf.add(1, 2).numpy()\n3\nhello = tf.constant('Hello, TensorFlow!')\nhello.numpy()\nb'Hello, TensorFlow!'\n```\nFor more examples, see the\nTensorFlow tutorials.\nContribution guidelines\nIf you want to contribute to TensorFlow, be sure to review the\ncontribution guidelines. This project adheres to TensorFlow's\ncode of conduct. By participating, you are expected to\nuphold this code.\nWe use GitHub issues for\ntracking requests and bugs, please see\nTensorFlow Discuss\nfor general questions and discussion, and please direct specific questions to\nStack Overflow.\nThe TensorFlow project strives to abide by generally accepted best practices in\nopen-source software development.\nContinuous build status\nYou can find more community-supported platforms and configurations in the\nTensorFlow SIG Build community builds table.\nOfficial Builds\nBuild Type                    | Status                                                                                                                                                                           | Artifacts\n----------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------\nLinux CPU                 |            | PyPI\nLinux GPU                 |  | PyPI\nLinux XLA                 |          | TBA\nmacOS                     |      | PyPI\nWindows CPU               |        | PyPI\nWindows GPU               |        | PyPI\nAndroid                   |                | Download\nRaspberry Pi 0 and 1      |            | Py3\nRaspberry Pi 2 and 3      |            | Py3\nLibtensorflow MacOS CPU   | Status Temporarily Unavailable                                                                                                                                                   | Nightly Binary Official GCS\nLibtensorflow Linux CPU   | Status Temporarily Unavailable                                                                                                                                                   | Nightly Binary Official GCS\nLibtensorflow Linux GPU   | Status Temporarily Unavailable                                                                                                                                                   | Nightly Binary Official GCS\nLibtensorflow Windows CPU | Status Temporarily Unavailable                                                                                                                                                   | Nightly Binary Official GCS\nLibtensorflow Windows GPU | Status Temporarily Unavailable                                                                                                                                                   | Nightly Binary Official GCS\nResources\nTensorFlow.org\nTensorFlow Tutorials\nTensorFlow Official Models\nTensorFlow Examples\nTensorFlow Codelabs\nTensorFlow Blog\nLearn ML with TensorFlow\nTensorFlow Twitter\nTensorFlow YouTube\nTensorFlow model optimization roadmap\nTensorFlow White Papers\nTensorBoard Visualization Toolkit\nTensorFlow Code Search\nLearn more about the\nTensorFlow community and how to\ncontribute.\nCourses\nDeep Learning with Tensorflow from Edx\nDeepLearning.AI TensorFlow Developer Professional Certificate from Coursera\nTensorFlow: Data and Deployment from Coursera\nGetting Started with TensorFlow 2 from Coursera\nTensorFlow: Advanced Techniques from Coursera\nTensorFlow 2 for Deep Learning Specialization from Coursera\nIntro to TensorFlow for A.I, M.L, and D.L from Coursera\nMachine Learning with TensorFlow on GCP from Coursera\nIntro to TensorFlow for Deep Learning from Udacity\nIntroduction to TensorFlow Lite from Udacity\nLicense\nApache License 2.0",
	"bert deep-learning flax hacktoberfest jax language-model language-models machine-learning model-hub natural-language-processing nlp nlp-library pretrained-models python pytorch pytorch-transformers seq2seq speech-recognition tensorflow transformer": "English |\n        \u7b80\u4f53\u4e2d\u6587 |\n        \u7e41\u9ad4\u4e2d\u6587 |\n        \ud55c\uad6d\uc5b4 |\n        Espa\u00f1ol |\n        \u65e5\u672c\u8a9e\nState-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n\ud83e\udd17 Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.\nThese models can be applied on:\n\n\ud83d\udcdd Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.\n\ud83d\uddbc\ufe0f Images, for tasks like image classification, object detection, and segmentation.\n\ud83d\udde3\ufe0f Audio, for tasks like speech recognition and audio classification.\n\nTransformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.\n\ud83e\udd17 Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.\n\ud83e\udd17 Transformers is backed by the three most popular deep learning libraries \u2014 Jax, PyTorch and TensorFlow \u2014 with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.\nOnline demos\nYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.\nHere are a few examples:\nIn Natural Language Processing:\n- Masked word completion with BERT\n- Name Entity Recognition with Electra\n- Text generation with GPT-2\n- Natural Language Inference with RoBERTa\n- Summarization with BART\n- Question answering with DistilBERT\n- Translation with T5\nIn Computer Vision:\n- Image classification with ViT\n- Object Detection with DETR\n- Semantic Segmentation with SegFormer\n- Panoptic Segmentation with DETR\nIn Audio:\n- Automatic Speech Recognition with Wav2Vec2\n- Keyword Spotting with Wav2Vec2\nIn Multimodal tasks:\n- Visual Question Answering with ViLT\nWrite With Transformer, built by the Hugging Face team, is the official demo of this repo\u2019s text generation capabilities.\nIf you are looking for custom support from the Hugging Face team\nQuick tour\nTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:\n```python\n\n\n\nfrom transformers import pipeline\n\n\n\nAllocate a pipeline for sentiment-analysis\n\n\n\nclassifier = pipeline('sentiment-analysis')\nclassifier('We are very happy to introduce pipeline to the transformers repository.')\n[{'label': 'POSITIVE', 'score': 0.9996980428695679}]\n```\n\n\n\nThe second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \"positive\" with a confidence of 99.97%.\nMany tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:\n``` python\n\n\n\nimport requests\nfrom PIL import Image\nfrom transformers import pipeline\n\n\n\nDownload an image with cute cats\n\n\n\nurl = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"\nimage_data = requests.get(url, stream=True).raw\nimage = Image.open(image_data)\n\n\n\nAllocate a pipeline for object detection\n\n\n\nobject_detector = pipeline('object-detection')\nobject_detector(image)\n[{'score': 0.9982201457023621,\n  'label': 'remote',\n  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}},\n {'score': 0.9960021376609802,\n  'label': 'remote',\n  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}},\n {'score': 0.9954745173454285,\n  'label': 'couch',\n  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}},\n {'score': 0.9988006353378296,\n  'label': 'cat',\n  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}},\n {'score': 0.9986783862113953,\n  'label': 'cat',\n  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]\n```\n\n\n\nHere we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:\nYou can learn more about the tasks supported by the pipeline API in this tutorial.\nIn addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:\n```python\n\n\n\nfrom transformers import AutoTokenizer, AutoModel\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = AutoModel.from_pretrained(\"bert-base-uncased\")\ninputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\noutputs = model(**inputs)\n```\n\n\n\nAnd here is the equivalent code for TensorFlow:\n```python\n\n\n\nfrom transformers import AutoTokenizer, TFAutoModel\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = TFAutoModel.from_pretrained(\"bert-base-uncased\")\ninputs = tokenizer(\"Hello world!\", return_tensors=\"tf\")\noutputs = model(**inputs)\n```\n\n\n\nThe tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.\nThe model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.\nWhy should I use transformers?\n\n\nEasy-to-use state-of-the-art models:\n\nHigh performance on natural language understanding & generation, computer vision, and audio tasks.\nLow barrier to entry for educators and practitioners.\nFew user-facing abstractions with just three classes to learn.\nA unified API for using all our pretrained models.\n\n\n\nLower compute costs, smaller carbon footprint:\n\nResearchers can share trained models instead of always retraining.\nPractitioners can reduce compute time and production costs.\nDozens of architectures with over 60,000 pretrained models across all modalities.\n\n\n\nChoose the right framework for every part of a model's lifetime:\n\nTrain state-of-the-art models in 3 lines of code.\nMove a single model between TF2.0/PyTorch/JAX frameworks at will.\nSeamlessly pick the right framework for training, evaluation and production.\n\n\n\nEasily customize a model or an example to your needs:\n\nWe provide examples for each architecture to reproduce the results published by its original authors.\nModel internals are exposed as consistently as possible.\nModel files can be used independently of the library for quick experiments.\n\n\n\nWhy shouldn't I use transformers?\n\nThis library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.\nThe training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).\nWhile we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.\n\nInstallation\nWith pip\nThis repository is tested on Python 3.6+, Flax 0.3.2+, PyTorch 1.3.1+ and TensorFlow 2.3+.\nYou should install \ud83e\udd17 Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.\nFirst, create a virtual environment with the version of Python you're going to use and activate it.\nThen, you will need to install at least one of Flax, PyTorch or TensorFlow.\nPlease refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.\nWhen one of those backends has been installed, \ud83e\udd17 Transformers can be installed using pip as follows:\nbash\npip install transformers\nIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.\nWith conda\nSince Transformers version v4.0.0, we now have a conda channel: huggingface.\n\ud83e\udd17 Transformers can be installed using conda as follows:\nshell script\nconda install -c huggingface transformers\nFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.\n\nNOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.\n\nModel architectures\nAll the model checkpoints provided by \ud83e\udd17 Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.\nCurrent number of checkpoints: \n\ud83e\udd17 Transformers currently provides the following architectures (see here for a high-level summary of each them):\n\nALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.\nAudio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.\nBART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.\nBARThez (from \u00c9cole polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.\nBARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.\nBEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.\nBERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.\nBERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.\nBERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.\nBigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.\nBigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.\nBlenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.\nBlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.\nBLOOM (from BigScience workshop) released by the BigScience Workshop.\nBORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.\nByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.\nCamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin, Benjamin Muller, Pedro Javier Ortiz Su\u00e1rez*, Yoann Dupont, Laurent Romary, \u00c9ric Villemonte de la Clergerie, Djam\u00e9 Seddah and Beno\u00eet Sagot.\nCANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.\nCLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.\nCLIPSeg (from University of G\u00f6ttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo L\u00fcddecke and Alexander Ecker.\nCodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.\nConditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.\nConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.\nConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.\nCPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.\nCTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong and Richard Socher.\nCvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.\nData2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.\nDeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.\nDeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.\nDecision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.\nDeformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.\nDeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Herv\u00e9 J\u00e9gou.\nDETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.\nDialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.\nDiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.\nDistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.\nDiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.\nDonut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.\nDPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas O\u011fuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.\nDPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by Ren\u00e9 Ranftl, Alexey Bochkovskiy, Vladlen Koltun.\nELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.\nEncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.\nERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.\nESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.\nFLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei\nFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, Lo\u00efc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Beno\u00eet Crabb\u00e9, Laurent Besacier, Didier Schwab.\nFLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.\nFNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.\nFunnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.\nGLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.\nGPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.\nGPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.\nGPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel Weinbach\nGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.\nGPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei and Ilya Sutskever.\nGPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.\nGroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.\nHubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.\nI-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.\nImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.\nJukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.\nLayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.\nLayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.\nLayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.\nLayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.\nLED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.\nLeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Herv\u00e9 J\u00e9gou, Matthijs Douze.\nLiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.\nLongformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.\nLongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.\nLUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.\nLXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.\nM-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.\nM2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.\nMarianMT Machine translation models trained using OPUS data by J\u00f6rg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.\nMarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.\nMaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.\nmBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.\nmBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.\nMegatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.\nMegatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.\nmLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.\nMobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.\nMobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.\nMobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.\nMobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.\nMPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.\nMT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.\nMVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.\nNAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.\nNezha (from Huawei Noah\u2019s Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.\nNLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.\nNystr\u00f6mformer (from the University of Wisconsin - Madison) released with the paper Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.\nOPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.\nOWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.\nPegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.\nPEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.\nPerceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier H\u00e9naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, Jo\u00e3o Carreira.\nPhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.\nPLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.\nPoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.\nProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.\nQDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.\nRAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, Sebastian Riedel, Douwe Kiela.\nREALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.\nReformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, \u0141ukasz Kaiser, Anselm Levskaya.\nRegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Doll\u00e1r.\nRemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault F\u00e9vry, Henry Tsai, M. Johnson, Sebastian Ruder.\nResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.\nRoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.\nRoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.\nRoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.\nSegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.\nSEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.\nSEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.\nSpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.\nSpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.\nSplinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.\nSqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.\nSwin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.\nSwin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.\nSwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.\nT5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.\nT5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.\nTable Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.\nTAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, Pawe\u0142 Krzysztof Nowak, Thomas M\u00fcller, Francesco Piccinno and Julian Martin Eisenschlos.\nTAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.\nTime Series Transformer  (from HuggingFace).\nTrajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey Levine\nTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.\nTrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.\nUL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald Metzler\nUniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.\nUniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.\nVAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.\nVideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.\nViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.\nVision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.\nVisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.\nViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, Ross Girshick.\nViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.\nWav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.\nWav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.\nWav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.\nWavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.\nWhisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.\nX-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.\nXGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.\nXLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.\nXLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.\nXLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.\nXLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.\nXLNet (from Google/CMU) released with the paper \u200bXLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.\nXLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.\nXLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.\nYOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.\nYOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.\nWant to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.\n\nTo check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the \ud83e\udd17 Tokenizers library, refer to this table.\nThese implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.\nLearn more\n| Section | Description |\n|-|-|\n| Documentation | Full API documentation and tutorials |\n| Task summary | Tasks supported by \ud83e\udd17 Transformers |\n| Preprocessing tutorial | Using the Tokenizer class to prepare data for the models |\n| Training and fine-tuning | Using the models provided by \ud83e\udd17 Transformers in a PyTorch/TensorFlow training loop and the Trainer API |\n| Quick tour: Fine-tuning/usage scripts | Example scripts for fine-tuning models on a wide range of tasks |\n| Model sharing and uploading | Upload and share your fine-tuned models with the community |\n| Migration | Migrate to \ud83e\udd17 Transformers from pytorch-transformers or pytorch-pretrained-bert |\nCitation\nWe now have a paper you can cite for the \ud83e\udd17 Transformers library:\nbibtex\n@inproceedings{wolf-etal-2020-transformers,\n    title = \"Transformers: State-of-the-Art Natural Language Processing\",\n    author = \"Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R\u00e9mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\",\n    month = oct,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-demos.6\",\n    pages = \"38--45\"\n}",
	"autograd deep-learning gpu machine-learning neural-network numpy python tensor": "PyTorch is a Python package that provides two high-level features:\n- Tensor computation (like NumPy) with strong GPU acceleration\n- Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\nOur trunk health (Continuous Integration signals) can be found at hud.pytorch.org.\nMore About PyTorch\nA GPU-Ready Tensor Library\nDynamic Neural Networks: Tape-Based Autograd\nPython First\nImperative Experiences\nFast and Lean\nExtensions Without Pain\nInstallation\nBinaries\nNVIDIA Jetson Platforms\nFrom Source\nPrerequisites\nInstall Dependencies\nGet the PyTorch Source\nInstall PyTorch\nAdjust Build Options (Optional)\nDocker Image\nUsing pre-built images\nBuilding the image yourself\nBuilding the Documentation\nPrevious Versions\nGetting Started\nResources\nCommunication\nReleases and Contributing\nThe Team\nLicense\nMore About PyTorch\nAt a granular level, PyTorch is a library that consists of the following components:\n| Component | Description |\n| ---- | --- |\n| torch | A Tensor library like NumPy, with strong GPU support |\n| torch.autograd | A tape-based automatic differentiation library that supports all differentiable Tensor operations in torch |\n| torch.jit | A compilation stack (TorchScript) to create serializable and optimizable models from PyTorch code  |\n| torch.nn | A neural networks library deeply integrated with autograd designed for maximum flexibility |\n| torch.multiprocessing | Python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and Hogwild training |\n| torch.utils | DataLoader and other utility functions for convenience |\nUsually, PyTorch is used either as:\nA replacement for NumPy to use the power of GPUs.\nA deep learning research platform that provides maximum flexibility and speed.\nElaborating Further:\nA GPU-Ready Tensor Library\nIf you use NumPy, then you have used Tensors (a.k.a. ndarray).\nPyTorch provides Tensors that can live either on the CPU or the GPU and accelerates the\ncomputation by a huge amount.\nWe provide a wide variety of tensor routines to accelerate and fit your scientific computation needs\nsuch as slicing, indexing, mathematical operations, linear algebra, reductions.\nAnd they are fast!\nDynamic Neural Networks: Tape-Based Autograd\nPyTorch has a unique way of building neural networks: using and replaying a tape recorder.\nMost frameworks such as TensorFlow, Theano, Caffe, and CNTK have a static view of the world.\nOne has to build a neural network and reuse the same structure again and again.\nChanging the way the network behaves means that one has to start from scratch.\nWith PyTorch, we use a technique called reverse-mode auto-differentiation, which allows you to\nchange the way your network behaves arbitrarily with zero lag or overhead. Our inspiration comes\nfrom several research papers on this topic, as well as current and past work such as\ntorch-autograd,\nautograd,\nChainer, etc.\nWhile this technique is not unique to PyTorch, it's one of the fastest implementations of it to date.\nYou get the best of speed and flexibility for your crazy research.\nPython First\nPyTorch is not a Python binding into a monolithic C++ framework.\nIt is built to be deeply integrated into Python.\nYou can use it naturally like you would use NumPy / SciPy / scikit-learn etc.\nYou can write your new neural network layers in Python itself, using your favorite libraries\nand use packages such as Cython and Numba.\nOur goal is to not reinvent the wheel where appropriate.\nImperative Experiences\nPyTorch is designed to be intuitive, linear in thought, and easy to use.\nWhen you execute a line of code, it gets executed. There isn't an asynchronous view of the world.\nWhen you drop into a debugger or receive error messages and stack traces, understanding them is straightforward.\nThe stack trace points to exactly where your code was defined.\nWe hope you never spend hours debugging your code because of bad stack traces or asynchronous and opaque execution engines.\nFast and Lean\nPyTorch has minimal framework overhead. We integrate acceleration libraries\nsuch as Intel MKL and NVIDIA (cuDNN, NCCL) to maximize speed.\nAt the core, its CPU and GPU Tensor and neural network backends\nare mature and have been tested for years.\nHence, PyTorch is quite fast \u2013 whether you run small or large neural networks.\nThe memory usage in PyTorch is extremely efficient compared to Torch or some of the alternatives.\nWe've written custom memory allocators for the GPU to make sure that\nyour deep learning models are maximally memory efficient.\nThis enables you to train bigger deep learning models than before.\nExtensions Without Pain\nWriting new neural network modules, or interfacing with PyTorch's Tensor API was designed to be straightforward\nand with minimal abstractions.\nYou can write new neural network layers in Python using the torch API\nor your favorite NumPy-based libraries such as SciPy.\nIf you want to write your layers in C/C++, we provide a convenient extension API that is efficient and with minimal boilerplate.\nNo wrapper code needs to be written. You can see a tutorial here and an example here.\nInstallation\nBinaries\nCommands to install binaries via Conda or pip wheels are on our website: https://pytorch.org/get-started/locally/\nNVIDIA Jetson Platforms\nPython wheels for NVIDIA's Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX, and Jetson AGX Orin are provided here and the L4T container is published here\nThey require JetPack 4.2 and above, and @dusty-nv and @ptrblck are maintaining them.\nFrom Source\nPrerequisites\nIf you are installing from source, you will need:\n- Python 3.7 or later (for Linux, Python 3.7.6+ or 3.8.1+ is needed)\n- A C++14 compatible compiler, such as clang\nWe highly recommend installing an Anaconda environment. You will get a high-quality BLAS library (MKL) and you get controlled dependency versions regardless of your Linux distro.\nIf you want to compile with CUDA support, install the following (note that CUDA is not supported on macOS)\n- NVIDIA CUDA 10.2 or above\n- NVIDIA cuDNN v7 or above\n- Compiler compatible with CUDA\nNote: You could refer to the cuDNN Support Matrix for cuDNN versions with the various supported CUDA, CUDA driver and NVIDIA hardware\nIf you want to disable CUDA support, export the environment variable USE_CUDA=0.\nOther potentially useful environment variables may be found in setup.py.\nIf you are building for NVIDIA's Jetson platforms (Jetson Nano, TX1, TX2, AGX Xavier), Instructions to install PyTorch for Jetson Nano are available here\nIf you want to compile with ROCm support, install\n- AMD ROCm 4.0 and above installation\n- ROCm is currently supported only for Linux systems.\nIf you want to disable ROCm support, export the environment variable USE_ROCM=0.\nOther potentially useful environment variables may be found in setup.py.\nInstall Dependencies\nCommon\nbash\nconda install astunparse numpy ninja pyyaml setuptools cmake cffi typing_extensions future six requests dataclasses\nOn Linux\nbash\nconda install mkl mkl-include\nCUDA only: Add LAPACK support for the GPU if needed\nconda install -c pytorch magma-cuda110  # or the magma-cuda* that matches your CUDA version from https://anaconda.org/pytorch/repo\nOn MacOS\nbash\nAdd this package on intel x86 processor machines only\nconda install mkl mkl-include\nAdd these packages if torch.distributed is needed\nconda install pkg-config libuv\nOn Windows\nbash\nconda install mkl mkl-include\nAdd these packages if torch.distributed is needed.\nDistributed package support on Windows is a prototype feature and is subject to changes.\nconda install -c conda-forge libuv=1.39\nGet the PyTorch Source\nbash\ngit clone --recursive https://github.com/pytorch/pytorch\ncd pytorch\nif you are updating an existing checkout\ngit submodule sync\ngit submodule update --init --recursive --jobs 0\nInstall PyTorch\nOn Linux\nIf you're compiling for AMD ROCm then first run this command:\nbash\nOnly run this if you're compiling for ROCm\npython tools/amd_build/build_amd.py\nInstall PyTorch\nbash\nexport CMAKE_PREFIX_PATH=${CONDA_PREFIX:-\"$(dirname $(which conda))/../\"}\npython setup.py develop\nNote that if you are using Anaconda, you may experience an error caused by the linker:\nplaintext\nbuild/temp.linux-x86_64-3.7/torch/csrc/stub.o: file not recognized: file format not recognized\ncollect2: error: ld returned 1 exit status\nerror: command 'g++' failed with exit status 1\nThis is caused by ld from the Conda environment shadowing the system ld. You should use a newer version of Python that fixes this issue. The recommended Python version is 3.7.6+ and 3.8.1+.\nOn macOS\nbash\nexport CMAKE_PREFIX_PATH=${CONDA_PREFIX:-\"$(dirname $(which conda))/../\"}\nMACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py develop\nOn Windows\nChoose Correct Visual Studio Version.\nSometimes there are regressions in new versions of Visual Studio, so\nit's best to use the same Visual Studio Version 16.8.5 as Pytorch CI's.\nPyTorch CI uses Visual C++ BuildTools, which come with Visual Studio Enterprise,\nProfessional, or Community Editions. You can also install the build tools from\nhttps://visualstudio.microsoft.com/visual-cpp-build-tools/. The build tools do not\ncome with Visual Studio Code by default.\nIf you want to build legacy python code, please refer to Building on legacy code and CUDA\nCPU-only builds\nIn this mode PyTorch computations will run on your CPU, not your GPU\ncmd\nconda activate\npython setup.py develop\nNote on OpenMP: The desired OpenMP implementation is Intel OpenMP (iomp). In order to link against iomp, you'll need to manually download the library and set up the building environment by tweaking CMAKE_INCLUDE_PATH and LIB. The instruction here is an example for setting up both MKL and Intel OpenMP. Without these configurations for CMake, Microsoft Visual C OpenMP runtime (vcomp) will be used.\nCUDA based build\nIn this mode PyTorch computations will leverage your GPU via CUDA for faster number crunching\nNVTX is needed to build Pytorch with CUDA.\nNVTX is a part of CUDA distributive, where it is called \"Nsight Compute\". To install it onto an already installed CUDA run CUDA installation once again and check the corresponding checkbox.\nMake sure that CUDA with Nsight Compute is installed after Visual Studio.\nCurrently, VS 2017 / 2019, and Ninja are supported as the generator of CMake. If ninja.exe is detected in PATH, then Ninja will be used as the default generator, otherwise, it will use VS 2017 / 2019.\n If Ninja is selected as the generator, the latest MSVC will get selected as the underlying toolchain.\nAdditional libraries such as\nMagma, oneDNN, a.k.a MKLDNN or DNNL, and Sccache are often needed. Please refer to the installation-helper to install them.\nYou can refer to the build_pytorch.bat script for some other environment variables configurations\ncmd\ncmd\n:: Set the environment variables after you have downloaded and unzipped the mkl package,\n:: else CMake would throw an error as Could NOT find OpenMP.\nset CMAKE_INCLUDE_PATH={Your directory}\\mkl\\include\nset LIB={Your directory}\\mkl\\lib;%LIB%\n:: Read the content in the previous section carefully before you proceed.\n:: [Optional] If you want to override the underlying toolset used by Ninja and Visual Studio with CUDA, please run the following script block.\n:: \"Visual Studio 2019 Developer Command Prompt\" will be run automatically.\n:: Make sure you have CMake >= 3.12 before you do this when you use the Visual Studio generator.\nset CMAKE_GENERATOR_TOOLSET_VERSION=14.27\nset DISTUTILS_USE_SDK=1\nfor /f \"usebackq tokens=*\" %i in (\"%ProgramFiles(x86)%\\Microsoft Visual Studio\\Installer\\vswhere.exe\" -version [15^,17^) -products * -latest -property installationPath) do call \"%i\\VC\\Auxiliary\\Build\\vcvarsall.bat\" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%\n:: [Optional] If you want to override the CUDA host compiler\nset CUDAHOSTCXX=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.27.29110\\bin\\HostX64\\x64\\cl.exe\npython setup.py develop\nAdjust Build Options (Optional)\nYou can adjust the configuration of cmake variables optionally (without building first), by doing\nthe following. For example, adjusting the pre-detected directories for CuDNN or BLAS can be done\nwith such a step.\nOn Linux\nbash\nexport CMAKE_PREFIX_PATH=${CONDA_PREFIX:-\"$(dirname $(which conda))/../\"}\npython setup.py build --cmake-only\nccmake build  # or cmake-gui build\nOn macOS\nbash\nexport CMAKE_PREFIX_PATH=${CONDA_PREFIX:-\"$(dirname $(which conda))/../\"}\nMACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only\nccmake build  # or cmake-gui build\nDocker Image\nUsing pre-built images\nYou can also pull a pre-built docker image from Docker Hub and run with docker v19.03+\nbash\ndocker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest\nPlease note that PyTorch uses shared memory to share data between processes, so if torch multiprocessing is used (e.g.\nfor multithreaded data loaders) the default shared memory segment size that container runs with is not enough, and you\nshould increase shared memory size either with --ipc=host or --shm-size command line options to nvidia-docker run.\nBuilding the image yourself\nNOTE: Must be built with a docker version > 18.06\nThe Dockerfile is supplied to build images with CUDA 11.1 support and cuDNN v8.\nYou can pass PYTHON_VERSION=x.y make variable to specify which Python version is to be used by Miniconda, or leave it\nunset to use the default.\nbash\nmake -f docker.Makefile\nimages are tagged as docker.io/${your_docker_username}/pytorch\nBuilding the Documentation\nTo build documentation in various formats, you will need Sphinx and the\nreadthedocs theme.\nbash\ncd docs/\npip install -r requirements.txt\nYou can then build the documentation by running make  from the\ndocs/ folder. Run make to get a list of all available output formats.\nIf you get a katex error run npm install katex.  If it persists, try\nnpm install -g katex\nNote: if you installed nodejs with a different package manager (e.g.,\nconda) then npm will probably install a version of katex that is not\ncompatible with your version of nodejs and doc builds will fail.\nA combination of versions that is known to work is node@6.13.1 and\nkatex@0.13.18. To install the latter with npm you can run\nnpm install -g katex@0.13.18\nPrevious Versions\nInstallation instructions and binaries for previous PyTorch versions may be found\non our website.\nGetting Started\nThree-pointers to get you started:\n- Tutorials: get you started with understanding and using PyTorch\n- Examples: easy to understand PyTorch code across all domains\n- The API Reference\n- Glossary\nResources\nPyTorch.org\nPyTorch Tutorials\nPyTorch Examples\nPyTorch Models\nIntro to Deep Learning with PyTorch from Udacity\nIntro to Machine Learning with PyTorch from Udacity\nDeep Neural Networks with PyTorch from Coursera\nPyTorch Twitter\nPyTorch Blog\nPyTorch YouTube\nCommunication\nForums: Discuss implementations, research, etc. https://discuss.pytorch.org\nGitHub Issues: Bug reports, feature requests, install issues, RFCs, thoughts, etc.\nSlack: The PyTorch Slack hosts a primary audience of moderate to experienced PyTorch users and developers for general chat, online discussions, collaboration, etc. If you are a beginner looking for help, the primary medium is PyTorch Forums. If you need a slack invite, please fill this form: https://goo.gl/forms/PP1AGvNHpSaJP8to1\nNewsletter: No-noise, a one-way email newsletter with important announcements about PyTorch. You can sign-up here: https://eepurl.com/cbG0rv\nFacebook Page: Important announcements about PyTorch. https://www.facebook.com/pytorch\nFor brand guidelines, please visit our website at pytorch.org\nReleases and Contributing\nPyTorch has a 90-day release cycle (major releases). Please let us know if you encounter a bug by filing an issue.\nWe appreciate all contributions. If you are planning to contribute back bug-fixes, please do so without any further discussion.\nIf you plan to contribute new features, utility functions, or extensions to the core, please first open an issue and discuss the feature with us.\nSending a PR without discussion might end up resulting in a rejected PR because we might be taking the core in a different direction than you might be aware of.\nTo learn more about making a contribution to Pytorch, please see our Contribution page.\nThe Team\nPyTorch is a community-driven project with several skillful engineers and researchers contributing to it.\nPyTorch is currently maintained by Adam Paszke, Sam Gross, Soumith Chintala and Gregory Chanan with major contributions coming from hundreds of talented individuals in various forms and means.\nA non-exhaustive but growing list needs to mention: Trevor Killeen, Sasank Chilamkurthy, Sergey Zagoruyko, Adam Lerer, Francisco Massa, Alykhan Tejani, Luca Antiga, Alban Desmaison, Andreas Koepf, James Bradbury, Zeming Lin, Yuandong Tian, Guillaume Lample, Marat Dukhan, Natalia Gimelshein, Christian Sarofeen, Martin Raison, Edward Yang, Zachary Devito.\nNote: This project is unrelated to hughperkins/pytorch with the same name. Hugh is a valuable contributor to the Torch community and has helped with many things Torch and PyTorch.\nLicense\nPyTorch has a BSD-style license, as found in the LICENSE file.",
	"hacktoberfest lstm machine-learning ocr ocr-engine tesseract tesseract-ocr": "Tesseract OCR\n\\\n\\\nTable of Contents\nTesseract OCR\nAbout\nBrief history\nInstalling Tesseract\nRunning Tesseract\nFor developers\nSupport\nLicense\nDependencies\nLatest Version of README\nAbout\nThis package contains an OCR engine - libtesseract and a command line program - tesseract.\nTesseract 4 adds a new neural net (LSTM) based OCR engine which is focused on line recognition, but also still supports the legacy Tesseract OCR engine of Tesseract 3 which works by recognizing character patterns. Compatibility with Tesseract 3 is enabled by using the Legacy OCR Engine mode (--oem 0).\nIt also needs traineddata files which support the legacy engine, for example those from the tessdata repository.\nThe lead developer is Ray Smith. The maintainer is Zdenko Podobny. For a list of contributors see AUTHORS\nand GitHub's log of contributors.\nTesseract has unicode (UTF-8) support, and can recognize more than 100 languages \"out of the box\".\nTesseract supports various image formats including PNG, JPEG and TIFF.\nTesseract supports various output formats: plain text, hOCR (HTML), PDF, invisible-text-only PDF, TSV and ALTO (the last one - since version 4.1.0).\nYou should note that in many cases, in order to get better OCR results, you'll need to improve the quality of the image you are giving Tesseract.\nThis project does not include a GUI application. If you need one, please see the 3rdParty documentation.\nTesseract can be trained to recognize other languages.\nSee Tesseract Training for more information.\nBrief history\nTesseract was originally developed at Hewlett-Packard Laboratories Bristol UK and at Hewlett-Packard Co, Greeley Colorado USA between 1985 and 1994, with some more changes made in 1996 to port to Windows, and some C++izing in 1998. In 2005 Tesseract was open sourced by HP. From 2006 until November 2018 it was developed by Google.\nMajor version 5 is the current stable version and started with release\n5.0.0 on November 30, 2021. Newer minor versions and bugfix versions are available from\nGitHub.\nLatest source code is available from main branch on GitHub.\nOpen issues can be found in issue tracker,\nand planning documentation.\nSee Release Notes\nand Change Log for more details of the releases.\nInstalling Tesseract\nYou can either Install Tesseract via pre-built binary package\nor build it from source.\nA C++ compiler with good C++17 support is required for building Tesseract from source.\nRunning Tesseract\nBasic command line usage:\ntesseract imagename outputbase [-l lang] [--oem ocrenginemode] [--psm pagesegmode] [configfiles...]\nFor more information about the various command line options use tesseract --help or man tesseract.\nExamples can be found in the documentation.\nFor developers\nDevelopers can use libtesseract C or\nC++ API to build their own application. If you need bindings to libtesseract for other programming languages, please see the\nwrapper section in the AddOns documentation.\nDocumentation of Tesseract generated from source code by doxygen can be found on tesseract-ocr.github.io.\nSupport\nBefore you submit an issue, please review the guidelines for this repository.\nFor support, first read the documentation,\nparticularly the FAQ to see if your problem is addressed there.\nIf not, search the Tesseract user forum, the Tesseract developer forum and past issues, and if you still can't find what you need, ask for support in the mailing-lists.\nMailing-lists:\ntesseract-ocr - For tesseract users.\ntesseract-dev - For tesseract developers.\nPlease report an issue only for a bug, not for asking questions.\nLicense\nThe code in this repository is licensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\nNOTE: This software depends on other packages that may be licensed under different open source licenses.\nTesseract uses Leptonica library which essentially\nuses a BSD 2-clause license.\nDependencies\nTesseract uses Leptonica library\nfor opening input images (e.g. not documents like pdf).\nIt is suggested to use leptonica with built-in support for zlib,\npng and\ntiff (for multipage tiff).\nLatest Version of README\nFor the latest online version of the README.md see:\nhttps://github.com/tesseract-ocr/tesseract/blob/main/README.md",
	"face-detection face-recognition machine-learning python": "Face Recognition\nYou can also read a translated version of this file in Chinese \u7b80\u4f53\u4e2d\u6587\u7248 or in Korean \ud55c\uad6d\uc5b4 or in Japanese \u65e5\u672c\u8a9e.\nRecognize and manipulate faces from Python or from the command line with\nthe world's simplest face recognition library.\nBuilt using dlib's state-of-the-art face recognition\nbuilt with deep learning. The model has an accuracy of 99.38% on the\nLabeled Faces in the Wild benchmark.\nThis also provides a simple face_recognition command line tool that lets\nyou do face recognition on a folder of images from the command line!\nFeatures\nFind faces in pictures\nFind all the faces that appear in a picture:\npython\nimport face_recognition\nimage = face_recognition.load_image_file(\"your_file.jpg\")\nface_locations = face_recognition.face_locations(image)\nFind and manipulate facial features in pictures\nGet the locations and outlines of each person's eyes, nose, mouth and chin.\npython\nimport face_recognition\nimage = face_recognition.load_image_file(\"your_file.jpg\")\nface_landmarks_list = face_recognition.face_landmarks(image)\nFinding facial features is super useful for lots of important stuff. But you can also use it for really stupid stuff\nlike applying digital make-up (think 'Meitu'):\nIdentify faces in pictures\nRecognize who appears in each photo.\npython\nimport face_recognition\nknown_image = face_recognition.load_image_file(\"biden.jpg\")\nunknown_image = face_recognition.load_image_file(\"unknown.jpg\")\nbiden_encoding = face_recognition.face_encodings(known_image)[0]\nunknown_encoding = face_recognition.face_encodings(unknown_image)[0]\nresults = face_recognition.compare_faces([biden_encoding], unknown_encoding)\nYou can even use this library with other Python libraries to do real-time face recognition:\nSee this example for the code.\nOnline Demos\nUser-contributed shared Jupyter notebook demo (not officially supported): \nInstallation\nRequirements\nPython 3.3+ or Python 2.7\nmacOS or Linux (Windows not officially supported, but might work)\nInstallation Options:\nInstalling on Mac or Linux\nFirst, make sure you have dlib already installed with Python bindings:\nHow to install dlib from source on macOS or Ubuntu\nThen, make sure you have cmake installed:\nbrew install cmake\nFinally, install this module from pypi using pip3 (or pip2 for Python 2):\nbash\npip3 install face_recognition\nAlternatively, you can try this library with Docker, see this section.\nIf you are having trouble with installation, you can also try out a\npre-configured VM.\nInstalling on an Nvidia Jetson Nano board\nJetson Nano installation instructions\nPlease follow the instructions in the article carefully. There is current a bug in the CUDA libraries on the Jetson Nano that will cause this library to fail silently if you don't follow the instructions in the article to comment out a line in dlib and recompile it.\nInstalling on Raspberry Pi 2+\nRaspberry Pi 2+ installation instructions\nInstalling on FreeBSD\nbash\npkg install graphics/py-face_recognition\nInstalling on Windows\nWhile Windows isn't officially supported, helpful users have posted instructions on how to install this library:\n@masoudr's Windows 10 installation guide (dlib + face_recognition)\nInstalling a pre-configured Virtual Machine image\nDownload the pre-configured VM image (for VMware Player or VirtualBox).\nUsage\nCommand-Line Interface\nWhen you install face_recognition, you get two simple command-line \nprograms:\nface_recognition - Recognize faces in a photograph or folder full for \n   photographs.\nface_detection - Find faces in a photograph or folder full for photographs.\nface_recognition command line tool\nThe face_recognition command lets you recognize faces in a photograph or \nfolder full  for photographs.\nFirst, you need to provide a folder with one picture of each person you\nalready know. There should be one image file for each person with the\nfiles named according to who is in the picture:\nNext, you need a second folder with the files you want to identify:\nThen in you simply run the command face_recognition, passing in\nthe folder of known people and the folder (or single image) with unknown\npeople and it tells you who is in each image:\nbash\n$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/\n/unknown_pictures/unknown.jpg,Barack Obama\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person\nThere's one line in the output for each face. The data is comma-separated\nwith the filename and the name of the person found.\nAn unknown_person is a face in the image that didn't match anyone in\nyour folder of known people.\nface_detection command line tool\nThe face_detection command lets you find the location (pixel coordinatates) \nof any faces in an image.\nJust run the command face_detection, passing in a folder of images \nto check (or a single image):\nbash\n$ face_detection  ./folder_with_pictures/\nexamples/image1.jpg,65,215,169,112\nexamples/image2.jpg,62,394,211,244\nexamples/image2.jpg,95,941,244,792\nIt prints one line for each face that was detected. The coordinates\nreported are the top, right, bottom and left coordinates of the face (in pixels).\nAdjusting Tolerance / Sensitivity\nIf you are getting multiple matches for the same person, it might be that\nthe people in your photos look very similar and a lower tolerance value\nis needed to make face comparisons more strict.\nYou can do that with the --tolerance parameter. The default tolerance\nvalue is 0.6 and lower numbers make face comparisons more strict:\nbash\n$ face_recognition --tolerance 0.54 ./pictures_of_people_i_know/ ./unknown_pictures/\n/unknown_pictures/unknown.jpg,Barack Obama\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person\nIf you want to see the face distance calculated for each match in order\nto adjust the tolerance setting, you can use --show-distance true:\nbash\n$ face_recognition --show-distance true ./pictures_of_people_i_know/ ./unknown_pictures/\n/unknown_pictures/unknown.jpg,Barack Obama,0.378542298956785\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person,None\nMore Examples\nIf you simply want to know the names of the people in each photograph but don't\ncare about file names, you could do this:\nbash\n$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/ | cut -d ',' -f2\nBarack Obama\nunknown_person\nSpeeding up Face Recognition\nFace recognition can be done in parallel if you have a computer with\nmultiple CPU cores. For example, if your system has 4 CPU cores, you can\nprocess about 4 times as many images in the same amount of time by using\nall your CPU cores in parallel.\nIf you are using Python 3.4 or newer, pass in a --cpus  parameter:\nbash\n$ face_recognition --cpus 4 ./pictures_of_people_i_know/ ./unknown_pictures/\nYou can also pass in --cpus -1 to use all CPU cores in your system.\nPython Module\nYou can import the face_recognition module and then easily manipulate\nfaces with just a couple of lines of code. It's super easy!\nAPI Docs: https://face-recognition.readthedocs.io.\nAutomatically find all the faces in an image\npython\nimport face_recognition\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_locations = face_recognition.face_locations(image)\nface_locations is now an array listing the co-ordinates of each face!\nSee this example\n to try it out.\nYou can also opt-in to a somewhat more accurate deep-learning-based face detection model.\nNote: GPU acceleration (via NVidia's CUDA library) is required for good\nperformance with this model. You'll also want to enable CUDA support\nwhen compliling dlib.\npython\nimport face_recognition\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_locations = face_recognition.face_locations(image, model=\"cnn\")\nface_locations is now an array listing the co-ordinates of each face!\nSee this example\n to try it out.\nIf you have a lot of images and a GPU, you can also\nfind faces in batches.\nAutomatically locate the facial features of a person in an image\npython\nimport face_recognition\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_landmarks_list = face_recognition.face_landmarks(image)\nface_landmarks_list is now an array with the locations of each facial feature in each face.\nface_landmarks_list[0]['left_eye'] would be the location and outline of the first person's left eye.\nSee this example\n to try it out.\nRecognize faces in images and identify who they are\npython\nimport face_recognition\npicture_of_me = face_recognition.load_image_file(\"me.jpg\")\nmy_face_encoding = face_recognition.face_encodings(picture_of_me)[0]\nmy_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!\nunknown_picture = face_recognition.load_image_file(\"unknown.jpg\")\nunknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]\nNow we can see the two face encodings are of the same person with compare_faces!\nresults = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)\nif results[0] == True:\n    print(\"It's a picture of me!\")\nelse:\n    print(\"It's not a picture of me!\")\nSee this example\n to try it out.\nPython Code Examples\nAll the examples are available here.\nFace Detection\nFind faces in a photograph\nFind faces in a photograph (using deep learning)\nFind faces in batches of images w/ GPU (using deep learning)\nBlur all the faces in a live video using your webcam (Requires OpenCV to be installed)\nFacial Features\nIdentify specific facial features in a photograph\nApply (horribly ugly) digital make-up\nFacial Recognition\nFind and recognize unknown faces in a photograph based on photographs of known people\nIdentify and draw boxes around each person in a photo\nCompare faces by numeric face distance instead of only True/False matches\nRecognize faces in live video using your webcam - Simple / Slower Version (Requires OpenCV to be installed)\nRecognize faces in live video using your webcam - Faster Version (Requires OpenCV to be installed)\nRecognize faces in a video file and write out new video file (Requires OpenCV to be installed)\nRecognize faces on a Raspberry Pi w/ camera\nRun a web service to recognize faces via HTTP (Requires Flask to be installed)\nRecognize faces with a K-nearest neighbors classifier\nTrain multiple images per person then recognize faces using a SVM\nCreating a Standalone Executable\nIf you want to create a standalone executable that can run without the need to install python or face_recognition, you can use PyInstaller. However, it requires some custom configuration to work with this library. See this issue for how to do it.\nArticles and Guides that cover face_recognition\nMy article on how Face Recognition works: Modern Face Recognition with Deep Learning\nCovers the algorithms and how they generally work\nFace recognition with OpenCV, Python, and deep learning by Adrian Rosebrock\nCovers how to use face recognition in practice\nRaspberry Pi Face Recognition by Adrian Rosebrock\nCovers how to use this on a Raspberry Pi\nFace clustering with Python by Adrian Rosebrock\nCovers how to automatically cluster photos based on who appears in each photo using unsupervised learning\nHow Face Recognition Works\nIf you want to learn how face location and recognition work instead of\ndepending on a black box library, read my article.\nCaveats\nThe face recognition model is trained on adults and does not work very well on children. It tends to mix\n  up children quite easy using the default comparison threshold of 0.6.\nAccuracy may vary between ethnic groups. Please see this wiki page for more details.\nDeployment to Cloud Hosts (Heroku, AWS, etc)\nSince face_recognition depends on dlib which is written in C++, it can be tricky to deploy an app\nusing it to a cloud hosting provider like Heroku or AWS.\nTo make things easier, there's an example Dockerfile in this repo that shows how to run an app built with\nface_recognition in a Docker container. With that, you should be able to deploy\nto any service that supports Docker images.\nYou can try the Docker image locally by running: docker-compose up --build\nThere are also several prebuilt Docker images.\nLinux users with a GPU (drivers >= 384.81) and Nvidia-Docker installed can run the example on the GPU: Open the docker-compose.yml file and uncomment the dockerfile: Dockerfile.gpu and runtime: nvidia lines.\nHaving problems?\nIf you run into problems, please read the Common Errors section of the wiki before filing a github issue.\nThanks\nMany, many thanks to Davis King (@nulhom)\n  for creating dlib and for providing the trained facial feature detection and face encoding models\n  used in this library. For more information on the ResNet that powers the face encodings, check out\n  his blog post.\nThanks to everyone who works on all the awesome Python data science libraries like numpy, scipy, scikit-image,\n  pillow, etc, etc that makes this kind of stuff so easy and fun in Python.\nThanks to Cookiecutter and the\n  audreyr/cookiecutter-pypackage project template\n  for making Python project packaging way more tolerable.",
	"deep-face-swap deep-learning deep-neural-networks deepface deepfakes deeplearning face-swap faceswap fakeapp machine-learning myfakeapp neural-nets neural-networks openfaceswap": "deepfakes_faceswap\nFaceSwap is a tool that utilizes deep learning to recognize and swap faces in pictures and videos.\nEmma Stone/Scarlett Johansson FaceSwap using the Phaze-A model\nJennifer Lawrence/Steve Buscemi FaceSwap using the Villain model\nMake sure you check out INSTALL.md before getting started.\ndeepfakes_faceswap\nManifesto\nFaceSwap has ethical uses.\nHow To setup and run the project\nOverview\nExtract\nTrain\nConvert\nGUI\nGeneral notes:\nHelp I need support!\nDiscord Server\nFaceSwap Forum\nDonate\nPatreon\nOne time Donations\n@torzdf\n@andenixa\nHow to contribute\nFor people interested in the generative models\nFor devs\nFor non-dev advanced users\nFor end-users\nFor haters\nAbout github.com/deepfakes\nWhat is this repo?\nWhy this repo?\nWhy is it named 'deepfakes' if it is not /u/deepfakes?\nWhat if /u/deepfakes feels bad about that?\nAbout machine learning\nHow does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?\nManifesto\nFaceSwap has ethical uses.\nWhen faceswapping was first developed and published, the technology was groundbreaking, it was a huge step in AI development. It was also completely ignored outside of academia because the code was confusing and fragmentary. It required a thorough understanding of complicated AI techniques and took a lot of effort to figure it out. Until one individual brought it together into a single, cohesive collection. It ran, it worked, and as is so often the way with new technology emerging on the internet, it was immediately used to create inappropriate content. Despite the inappropriate uses the software was given originally, it was the first AI code that anyone could download, run and learn by experimentation without having a Ph.D. in math, computer theory, psychology, and more. Before \"deepfakes\" these techniques were like black magic, only practiced by those who could understand all of the inner workings as described in esoteric and endlessly complicated books and papers.\n\"Deepfakes\" changed all that and anyone could participate in AI development. To us, developers, the release of this code opened up a fantastic learning opportunity. It allowed us to build on ideas developed by others, collaborate with a variety of skilled coders, experiment with AI whilst learning new skills and ultimately contribute towards an emerging technology which will only see more mainstream use as it progresses.\nAre there some out there doing horrible things with similar software? Yes. And because of this, the developers have been following strict ethical standards. Many of us don't even use it to create videos, we just tinker with the code to see what it does. Sadly, the media concentrates only on the unethical uses of this software. That is, unfortunately, the nature of how it was first exposed to the public, but it is not representative of why it was created, how we use it now, or what we see in its future. Like any technology, it can be used for good or it can be abused. It is our intention to develop FaceSwap in a way that its potential for abuse is minimized whilst maximizing its potential as a tool for learning, experimenting and, yes, for legitimate faceswapping.\nWe are not trying to denigrate celebrities or to demean anyone. We are programmers, we are engineers, we are Hollywood VFX artists, we are activists, we are hobbyists, we are human beings. To this end, we feel that it's time to come out with a standard statement of what this software is and isn't as far as us developers are concerned.\nFaceSwap is not for creating inappropriate content.\nFaceSwap is not for changing faces without consent or with the intent of hiding its use.\nFaceSwap is not for any illicit, unethical, or questionable purposes.\nFaceSwap exists to experiment and discover AI techniques, for social or political commentary, for movies, and for any number of ethical and reasonable uses.\nWe are very troubled by the fact that FaceSwap can be used for unethical and disreputable things. However, we support the development of tools and techniques that can be used ethically as well as provide education and experience in AI for anyone who wants to learn it hands-on. We will take a zero tolerance approach to anyone using this software for any unethical purposes and will actively discourage any such uses.\nHow To setup and run the project\nFaceSwap is a Python program that will run on multiple Operating Systems including Windows, Linux, and MacOS.\nSee INSTALL.md for full installation instructions. You will need a modern GPU with CUDA support for best performance. AMD GPUs are partially supported.\nOverview\nThe project has multiple entry points. You will have to:\n - Gather photos and/or videos\n - Extract faces from your raw photos\n - Train a model on the faces extracted from the photos/videos\n - Convert your sources with the model\nCheck out USAGE.md for more detailed instructions.\nExtract\nFrom your setup folder, run python faceswap.py extract. This will take photos from src folder and extract faces into extract folder.\nTrain\nFrom your setup folder, run python faceswap.py train. This will take photos from two folders containing pictures of both faces and train a model that will be saved inside the models folder.\nConvert\nFrom your setup folder, run python faceswap.py convert. This will take photos from original folder and apply new faces into modified folder.\nGUI\nAlternatively, you can run the GUI by running python faceswap.py gui\nGeneral notes:\nAll of the scripts mentioned have -h/--help options with arguments that they will accept. You're smart, you can figure out how this works, right?!\nNB: there is a conversion tool for video. This can be accessed by running python tools.py effmpeg -h. Alternatively, you can use ffmpeg to convert video into photos, process images, and convert images back to the video.\nSome tips:\nReusing existing models will train much faster than starting from nothing.\nIf there is not enough training data, start with someone who looks similar, then switch the data.\nHelp I need support!\nDiscord Server\nYour best bet is to join the FaceSwap Discord server where there are plenty of users willing to help. Please note that, like this repo, this is a SFW Server!\nFaceSwap Forum\nAlternatively, you can post questions in the FaceSwap Forum. Please do not post general support questions in this repo as they are liable to be deleted without response.\nDonate\nThe developers work tirelessly to improve and develop FaceSwap. Many hours have been put in to provide the software as it is today, but this is an extremely time-consuming process with no financial reward. If you enjoy using the software, please consider donating to the devs, so they can spend more time implementing improvements.\nPatreon\nThe best way to support us is through our Patreon page:\nOne time Donations\nAlternatively you can give a one off donation to any of our Devs:\n@torzdf\nThere is very little FaceSwap code that hasn't been touched by torzdf. He is responsible for implementing the GUI, FAN aligner, MTCNN detector and porting the Villain, DFL-H128 and DFaker models to FaceSwap, as well as significantly improving many areas of the code.\nBitcoin: bc1qpm22suz59ylzk0j7qk5e4c7cnkjmve2rmtrnc6\nEthereum: 0xd3e954dC241B87C4E8E1A801ada485DC1d530F01\nMonero: 45dLrtQZ2pkHizBpt3P3yyJKkhcFHnhfNYPMSnz3yVEbdWm3Hj6Kr5TgmGAn3Far8LVaQf1th2n3DJVTRkfeB5ZkHxWozSX\nPaypal: \n@andenixa\nCreator of the Unbalanced and OHR models, as well as expanding various capabilities within the training process. Andenixa is currently working on new models and will take requests for donations.\nPaypal: \nHow to contribute\nFor people interested in the generative models\nGo to the 'faceswap-model' to discuss/suggest/commit alternatives to the current algorithm.\nFor devs\nRead this README entirely\nFork the repo\nPlay with it\nCheck issues with the 'dev' tag\nFor devs more interested in computer vision and openCV, look at issues with the 'opencv' tag. Also feel free to add your own alternatives/improvements\nFor non-dev advanced users\nRead this README entirely\nClone the repo\nPlay with it\nCheck issues with the 'advuser' tag\nAlso go to the 'faceswap Forum' and help others.\nFor end-users\nGet the code here and play with it if you can\nYou can also go to the faceswap Forum and help or get help from others.\nBe patient. This is a relatively new technology for developers as well. Much effort is already being put into making this program easy to use for the average user. It just takes time!\nNotice Any issue related to running the code has to be opened in the faceswap Forum!\nFor haters\nSorry, no time for that.\nAbout github.com/deepfakes\nWhat is this repo?\nIt is a community repository for active users.\nWhy this repo?\nThe joshua-wu repo seems not active. Simple bugs like missing http:// in front of urls have not been solved since days.\nWhy is it named 'deepfakes' if it is not /u/deepfakes?\nBecause a typosquat would have happened sooner or later as project grows\nBecause we wanted to recognize the original author\nBecause it will better federate contributors and users\nWhat if /u/deepfakes feels bad about that?\nThis is a friendly typosquat, and it is fully dedicated to the project. If /u/deepfakes wants to take over this repo/user and drive the project, he is welcomed to do so (Raise an issue, and he will be contacted on Reddit). Please do not send /u/deepfakes messages for help with the code you find here.\nAbout machine learning\nHow does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?\nIt's complicated. Here's a good video that makes the process understandable:\nHere's a slightly more in depth video that tries to explain the basic functioning of a neural network:\ntl;dr: training data + trial and error",
	"deep-learning examples machine-learning python tensorflow tutorial": "TensorFlow Examples\nThis tutorial was designed for easily diving into TensorFlow, through examples. For readability, it includes both notebooks and source codes with explanation, for both TF v1 & v2.\nIt is suitable for beginners who want to find clear and concise examples about TensorFlow. Besides the traditional 'raw' TensorFlow implementations, you can also find the latest TensorFlow API practices (such as layers, estimator, dataset, ...).\nUpdate (05/16/2020): Moving all default examples to TF2. For TF v1 examples: check here.\nTutorial index\n0 - Prerequisite\nIntroduction to Machine Learning.\nIntroduction to MNIST Dataset.\n1 - Introduction\nHello World (notebook). Very simple example to learn how to print \"hello world\" using TensorFlow 2.0+.\nBasic Operations (notebook). A simple example that cover TensorFlow 2.0+ basic operations.\n2 - Basic Models\nLinear Regression (notebook). Implement a Linear Regression with TensorFlow 2.0+.\nLogistic Regression (notebook). Implement a Logistic Regression with TensorFlow 2.0+.\nWord2Vec (Word Embedding) (notebook). Build a Word Embedding Model (Word2Vec) from Wikipedia data, with TensorFlow 2.0+.\nGBDT (Gradient Boosted Decision Trees) (notebooks). Implement a Gradient Boosted Decision Trees with TensorFlow 2.0+ to predict house value using Boston Housing dataset.\n3 - Neural Networks\nSupervised\nSimple Neural Network (notebook). Use TensorFlow 2.0 'layers' and 'model' API to build a simple neural network to classify MNIST digits dataset.\nSimple Neural Network (low-level) (notebook). Raw implementation of a simple neural network to classify MNIST digits dataset.\nConvolutional Neural Network (notebook). Use TensorFlow 2.0+ 'layers' and 'model' API to build a convolutional neural network to classify MNIST digits dataset.\nConvolutional Neural Network (low-level) (notebook). Raw implementation of a convolutional neural network to classify MNIST digits dataset.\nRecurrent Neural Network (LSTM) (notebook). Build a recurrent neural network (LSTM) to classify MNIST digits dataset, using TensorFlow 2.0 'layers' and 'model' API.\nBi-directional Recurrent Neural Network (LSTM) (notebook). Build a bi-directional recurrent neural network (LSTM) to classify MNIST digits dataset, using TensorFlow 2.0+ 'layers' and 'model' API.\nDynamic Recurrent Neural Network (LSTM) (notebook). Build a recurrent neural network (LSTM) that performs dynamic calculation to classify sequences of variable length, using TensorFlow 2.0+ 'layers' and 'model' API.\nUnsupervised\nAuto-Encoder (notebook). Build an auto-encoder to encode an image to a lower dimension and re-construct it.\nDCGAN (Deep Convolutional Generative Adversarial Networks) (notebook). Build a Deep Convolutional Generative Adversarial Network (DCGAN) to generate images from noise.\n4 - Utilities\nSave and Restore a model (notebook). Save and Restore a model with TensorFlow 2.0+.\nBuild Custom Layers & Modules (notebook). Learn how to build your own layers / modules and integrate them into TensorFlow 2.0+ Models.\nTensorboard (notebook). Track and visualize neural network computation graph, metrics, weights and more using TensorFlow 2.0+ tensorboard.\n5 - Data Management\nLoad and Parse data (notebook). Build efficient data pipeline with TensorFlow 2.0 (Numpy arrays, Images, CSV files, custom data, ...).\nBuild and Load TFRecords (notebook). Convert data into TFRecords format, and load them with TensorFlow 2.0+.\nImage Transformation (i.e. Image Augmentation) (notebook). Apply various image augmentation techniques with TensorFlow 2.0+, to generate distorted images for training.\n6 - Hardware\nMulti-GPU Training (notebook). Train a convolutional neural network with multiple GPUs on CIFAR-10 dataset.\nTensorFlow v1\nThe tutorial index for TF v1 is available here: TensorFlow v1.15 Examples. Or see below for a list of the examples.\nDataset\nSome examples require MNIST dataset for training and testing. Don't worry, this dataset will automatically be downloaded when running examples.\nMNIST is a database of handwritten digits, for a quick description of that dataset, you can check this notebook.\nOfficial Website: http://yann.lecun.com/exdb/mnist/.\nInstallation\nTo download all the examples, simply clone this repository:\ngit clone https://github.com/aymericdamien/TensorFlow-Examples\nTo run them, you also need the latest version of TensorFlow. To install it:\npip install tensorflow\nor (with GPU support):\npip install tensorflow_gpu\nFor more details about TensorFlow installation, you can check TensorFlow Installation Guide\nTensorFlow v1 Examples - Index\nThe tutorial index for TF v1 is available here: TensorFlow v1.15 Examples.\n0 - Prerequisite\nIntroduction to Machine Learning.\nIntroduction to MNIST Dataset.\n1 - Introduction\nHello World (notebook) (code). Very simple example to learn how to print \"hello world\" using TensorFlow.\nBasic Operations (notebook) (code). A simple example that cover TensorFlow basic operations.\nTensorFlow Eager API basics (notebook) (code). Get started with TensorFlow's Eager API.\n2 - Basic Models\nLinear Regression (notebook) (code). Implement a Linear Regression with TensorFlow.\nLinear Regression (eager api) (notebook) (code). Implement a Linear Regression using TensorFlow's Eager API.\nLogistic Regression (notebook) (code). Implement a Logistic Regression with TensorFlow.\nLogistic Regression (eager api) (notebook) (code). Implement a Logistic Regression using TensorFlow's Eager API.\nNearest Neighbor (notebook) (code). Implement Nearest Neighbor algorithm with TensorFlow.\nK-Means (notebook) (code). Build a K-Means classifier with TensorFlow.\nRandom Forest (notebook) (code). Build a Random Forest classifier with TensorFlow.\nGradient Boosted Decision Tree (GBDT) (notebook) (code). Build a Gradient Boosted Decision Tree (GBDT) with TensorFlow.\nWord2Vec (Word Embedding) (notebook) (code). Build a Word Embedding Model (Word2Vec) from Wikipedia data, with TensorFlow.\n3 - Neural Networks\nSupervised\nSimple Neural Network (notebook) (code). Build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset. Raw TensorFlow implementation.\nSimple Neural Network (tf.layers/estimator api) (notebook) (code). Use TensorFlow 'layers' and 'estimator' API to build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset.\nSimple Neural Network (eager api) (notebook) (code). Use TensorFlow Eager API to build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset.\nConvolutional Neural Network (notebook) (code). Build a convolutional neural network to classify MNIST digits dataset. Raw TensorFlow implementation.\nConvolutional Neural Network (tf.layers/estimator api) (notebook) (code). Use TensorFlow 'layers' and 'estimator' API to build a convolutional neural network to classify MNIST digits dataset.\nRecurrent Neural Network (LSTM) (notebook) (code). Build a recurrent neural network (LSTM) to classify MNIST digits dataset.\nBi-directional Recurrent Neural Network (LSTM) (notebook) (code). Build a bi-directional recurrent neural network (LSTM) to classify MNIST digits dataset.\nDynamic Recurrent Neural Network (LSTM) (notebook) (code). Build a recurrent neural network (LSTM) that performs dynamic calculation to classify sequences of different length.\nUnsupervised\nAuto-Encoder (notebook) (code). Build an auto-encoder to encode an image to a lower dimension and re-construct it.\nVariational Auto-Encoder (notebook) (code). Build a variational auto-encoder (VAE), to encode and generate images from noise.\nGAN (Generative Adversarial Networks) (notebook) (code). Build a Generative Adversarial Network (GAN) to generate images from noise.\nDCGAN (Deep Convolutional Generative Adversarial Networks) (notebook) (code). Build a Deep Convolutional Generative Adversarial Network (DCGAN) to generate images from noise.\n4 - Utilities\nSave and Restore a model (notebook) (code). Save and Restore a model with TensorFlow.\nTensorboard - Graph and loss visualization (notebook) (code). Use Tensorboard to visualize the computation Graph and plot the loss.\nTensorboard - Advanced visualization (notebook) (code). Going deeper into Tensorboard; visualize the variables, gradients, and more...\n5 - Data Management\nBuild an image dataset (notebook) (code). Build your own images dataset with TensorFlow data queues, from image folders or a dataset file.\nTensorFlow Dataset API (notebook) (code). Introducing TensorFlow Dataset API for optimizing the input data pipeline.\nLoad and Parse data (notebook). Build efficient data pipeline (Numpy arrays, Images, CSV files, custom data, ...).\nBuild and Load TFRecords (notebook). Convert data into TFRecords format, and load them.\nImage Transformation (i.e. Image Augmentation) (notebook). Apply various image augmentation techniques, to generate distorted images for training.\n6 - Multi GPU\nBasic Operations on multi-GPU (notebook) (code). A simple example to introduce multi-GPU in TensorFlow.\nTrain a Neural Network on multi-GPU (notebook) (code). A clear and simple TensorFlow implementation to train a convolutional neural network on multiple GPUs.\nMore Examples\nThe following examples are coming from TFLearn, a library that provides a simplified interface for TensorFlow. You can have a look, there are many examples and pre-built operations and layers.\nTutorials\nTFLearn Quickstart. Learn the basics of TFLearn through a concrete machine learning task. Build and train a deep neural network classifier.\nExamples\nTFLearn Examples. A large collection of examples using TFLearn.",
	"hacktoberfest hpc julia julia-language machine-learning numerical programming-language science scientific": "Documentation\nContinuous integration\nCode coverage\nThe Julia Language\nJulia is a high-level, high-performance dynamic language for technical\ncomputing.  The main homepage for Julia can be found at\njulialang.org.  This is the GitHub\nrepository of Julia source code, including instructions for compiling\nand installing Julia, below.\nResources\nHomepage: https://julialang.org\nBinaries: https://julialang.org/downloads/\nSource code: https://github.com/JuliaLang/julia\nDocumentation: https://docs.julialang.org\nPackages: https://julialang.org/packages/\nDiscussion forum: https://discourse.julialang.org\nSlack: https://julialang.slack.com (get an invite from https://julialang.org/slack/)\nYouTube: https://www.youtube.com/user/JuliaLanguage\nCode coverage: https://coveralls.io/r/JuliaLang/julia\nNew developers may find the notes in\nCONTRIBUTING\nhelpful to start contributing to the Julia codebase.\nExternal Resources\nStackOverflow\nTwitter\nLearning resources\nBinary Installation\nIf you would rather not compile the latest Julia from source,\nplatform-specific tarballs with pre-compiled binaries are also\navailable for download. The\ndownloads page also provides details on the\ndifferent tiers of support\nfor OS and platform combinations.\nIf everything works correctly, you will see a Julia banner and an\ninteractive prompt into which you can enter expressions for\nevaluation.  You can read about getting\nstarted in the manual.\nNote: Although some system package managers provide Julia, such\ninstallations are neither maintained nor endorsed by the Julia\nproject. They may be outdated, broken and/or unmaintained. We\nrecommend you use the official Julia binaries instead.\nBuilding Julia\nFirst, make sure you have all the required\ndependencies installed.\nThen, acquire the source code by cloning the git repository:\ngit clone https://github.com/JuliaLang/julia.git\nand then use the command prompt to change into the resulting julia directory. By default you will be building the latest unstable version of\nJulia. However, most users should use the most recent stable version\nof Julia. You can get this version by running:\ngit checkout v1.8.3\nTo build the julia executable, run make from within the julia directory.\nBuilding Julia requires 2GiB of disk space and approximately 4GiB of virtual memory.\nNote: The build process will fail badly if any of the build directory's parent directories have spaces or other shell meta-characters such as $ or : in their names (this is due to a limitation in GNU make).\nOnce it is built, you can run the julia executable. From within the julia directory, run\n./julia\nYour first test of Julia determines whether your build is working\nproperly. From the julia\ndirectory, type make testall. You should see output that\nlists a series of running tests; if they complete without error, you\nshould be in good shape to start using Julia.\nYou can read about getting\nstarted\nin the manual.\nDetailed build instructions, should they be necessary,\nare included in the build documentation.\nUninstalling Julia\nBy default, Julia does not install anything outside the directory it was cloned\ninto and ~/.julia. Julia and the vast majority of Julia packages can be\ncompletely uninstalled by deleting these two directories.\nSource Code Organization\nThe Julia source code is organized as follows:\n| Directory         | Contents                                                           |\n| -                 | -                                                                  |\n| base/           | source code for the Base module (part of Julia's standard library) |\n| stdlib/         | source code for other standard library packages                    |\n| cli/            | source for the command line interface/REPL                         |\n| contrib/        | miscellaneous scripts                                              |\n| deps/           | external dependencies                                              |\n| doc/src/        | source for the user manual                                         |\n| src/            | source for Julia language core                                     |\n| test/           | test suites                                                        |\n| usr/            | binaries and shared libraries loaded by Julia's standard libraries |\nTerminal, Editors and IDEs\nThe Julia REPL is quite powerful. See the section in the manual on\nthe Julia REPL\nfor more details.\nOn Windows we highly recommend running Julia in a modern terminal,\nsuch as Windows Terminal from the Microsoft Store.\nSupport for editing Julia is available for many\nwidely used editors:\nEmacs,\nVim,\nSublime Text, and many\nothers.\nFor users who prefer IDEs, we recommend using VS Code with the\njulia-vscode plugin.\nFor notebook users, Jupyter notebook support is available through the\nIJulia package, and\nthe Pluto.jl package provides Pluto notebooks.",
	"100-days-of-code-log 100daysofcode deep-learning implementation infographics linear-algebra linear-regression logistic-regression machine-learning machine-learning-algorithms naive-bayes-classifier python scikit-learn siraj-raval siraj-raval-challenge support-vector-machines svm tutorial": "100-Days-Of-ML-Code\n100 Days of Machine Learning Coding as proposed by Siraj Raval\nGet the datasets from here\nData PreProcessing | Day 1\nCheck out the code from here.\nSimple Linear Regression | Day 2\nCheck out the code from here.\nMultiple Linear Regression | Day 3\nCheck out the code from here.\nLogistic Regression | Day 4\nLogistic Regression | Day 5\nMoving forward into #100DaysOfMLCode today I dived into the deeper depth of what Logistic Regression actually is and what is the math involved behind it. Learned how cost function is calculated and then how to apply gradient descent algorithm to cost function to minimize the error in prediction.\nDue to less time I will now be posting an infographic on alternate days.\nAlso if someone wants to help me out in documentaion of code and already has some experince in the field and knows Markdown for github please contact me on LinkedIn :) .\nImplementing Logistic Regression | Day 6\nCheck out the Code here\nK Nearest Neighbours | Day 7\nMath Behind Logistic Regression | Day 8\n100DaysOfMLCode To clear my insights on logistic regression I was searching on the internet for some resource or article and I came across this article (https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc) by Saishruthi Swaminathan.\nIt gives a detailed description of Logistic Regression. Do check it out.\nSupport Vector Machines | Day 9\nGot an intution on what SVM is and how it is used to solve Classification problem.\nSVM and KNN | Day 10\nLearned more about how SVM works and implementing the K-NN algorithm.\nImplementation of K-NN | Day 11\nImplemented the K-NN algorithm for classification. #100DaysOfMLCode \nSupport Vector Machine Infographic is halfway complete. Will update it tomorrow.\nSupport Vector Machines | Day 12\nNaive Bayes Classifier | Day 13\nContinuing with #100DaysOfMLCode today I went through the Naive Bayes classifier.\nI am also implementing the SVM in python using scikit-learn. Will update the code soon.\nImplementation of SVM | Day 14\nToday I implemented SVM on linearly related data. Used Scikit-Learn library. In Scikit-Learn we have SVC classifier which we use to achieve this task. Will be using kernel-trick on next implementation.\nCheck the code here.\nNaive Bayes Classifier and Black Box Machine Learning | Day 15\nLearned about different types of naive bayes classifiers. Also started the lectures by Bloomberg. First one in the playlist was Black Box Machine Learning. It gives the whole overview about prediction functions, feature extraction, learning algorithms, performance evaluation, cross-validation, sample bias, nonstationarity, overfitting, and hyperparameter tuning.\nImplemented SVM using Kernel Trick | Day 16\nUsing Scikit-Learn library implemented SVM algorithm along with kernel function which maps our data points into higher dimension to find optimal hyperplane. \nStarted Deep learning Specialization on Coursera | Day 17\nCompleted the whole Week 1 and Week 2 on a single day. Learned Logistic regression as Neural Network. \nDeep learning Specialization on Coursera | Day 18\nCompleted the Course 1 of the deep learning specialization. Implemented a neural net in python.\nThe Learning Problem , Professor Yaser Abu-Mostafa | Day 19\nStarted Lecture 1 of 18 of Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa. It was basically an introduction to the upcoming lectures. He also explained Perceptron Algorithm.\nStarted Deep learning Specialization Course 2 | Day 20\nCompleted the Week 1 of Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization.\nWeb Scraping | Day 21\nWatched some tutorials on how to do web scraping using Beautiful Soup in order to collect data for building a model.\nIs Learning Feasible? | Day 22\nLecture 2 of 18 of Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa. Learned about Hoeffding Inequality.\nDecision Trees | Day 23\nIntroduction To Statistical Learning Theory | Day 24\nLec 3 of Bloomberg ML course introduced some of the core concepts like input space, action space, outcome space, prediction functions, loss functions, and hypothesis spaces.\nImplementing Decision Trees | Day 25\nCheck the code here.\nJumped To Brush up Linear Algebra | Day 26\nFound an amazing channel on youtube 3Blue1Brown. It has a playlist called Essence of Linear Algebra. Started off by completing 4 videos which gave a complete overview of Vectors, Linear Combinations, Spans, Basis Vectors, Linear Transformations and Matrix Multiplication. \nLink to the playlist here.\nJumped To Brush up Linear Algebra | Day 27\nContinuing with the playlist completed next 4 videos discussing topics 3D Transformations, Determinants, Inverse Matrix, Column Space, Null Space and Non-Square Matrices.\nLink to the playlist here.\nJumped To Brush up Linear Algebra | Day 28\nIn the playlist of 3Blue1Brown completed another 3 videos from the essence of linear algebra. \nTopics covered were Dot Product and Cross Product.\nLink to the playlist here.\nJumped To Brush up Linear Algebra | Day 29\nCompleted the whole playlist today, videos 12-14. Really an amazing playlist to refresh the concepts of Linear Algebra.\nTopics covered were the change of basis, Eigenvectors and Eigenvalues, and Abstract Vector Spaces.\nLink to the playlist here.\nEssence of calculus | Day 30\nCompleting the playlist - Essence of Linear Algebra by 3blue1brown a suggestion popped up by youtube regarding a series of videos again by the same channel 3Blue1Brown. Being already impressed by the previous series on Linear algebra I dived straight into it.\nCompleted about 5 videos on topics such as Derivatives, Chain Rule, Product Rule, and derivative of exponential.\nLink to the playlist here.\nEssence of calculus | Day 31\nWatched 2 Videos on topic Implicit Diffrentiation and Limits from the playlist Essence of Calculus.\nLink to the playlist here.\nEssence of calculus | Day 32\nWatched the remaining 4 videos covering topics Like Integration and Higher order derivatives.\nLink to the playlist here.\nRandom Forests | Day 33\nImplementing Random Forests | Day 34\nCheck the code here.\nBut what is a Neural Network? | Deep learning, chapter 1  | Day 35\nAn Amazing Video on neural networks by 3Blue1Brown youtube channel. This video gives a good understanding of Neural Networks and uses Handwritten digit dataset to explain the concept. \nLink To the video.\nGradient descent, how neural networks learn | Deep learning, chapter 2 | Day 36\nPart two of neural networks by 3Blue1Brown youtube channel. This video explains the concepts of Gradient Descent in an interesting way. 169 must watch and highly recommended.\nLink To the video.\nWhat is backpropagation really doing? | Deep learning, chapter 3 | Day 37\nPart three of neural networks by 3Blue1Brown youtube channel. This video mostly discusses the partial derivatives and backpropagation.\nLink To the video.\nBackpropagation calculus | Deep learning, chapter 4 | Day 38\nPart four of neural networks by 3Blue1Brown youtube channel. The goal here is to represent, in somewhat more formal terms, the intuition for how backpropagation works and the video moslty discusses the partial derivatives and backpropagation.\nLink To the video.\nDeep Learning with Python, TensorFlow, and Keras tutorial | Day 39\nLink To the video.\nLoading in your own data - Deep Learning basics with Python, TensorFlow and Keras p.2 | Day 40\nLink To the video.\nConvolutional Neural Networks - Deep Learning basics with Python, TensorFlow and Keras p.3 | Day 41\nLink To the video.\nAnalyzing Models with TensorBoard - Deep Learning with Python, TensorFlow and Keras p.4 | Day 42\nLink To the video.\nK Means Clustering | Day 43\nMoved to Unsupervised Learning and studied about Clustering.\nWorking on my website check it out avikjain.me\nAlso found a wonderful animation that can help to easily understand K - Means Clustering Link\nK Means Clustering Implementation | Day 44\nImplemented K Means Clustering. Check the code here.\nDigging Deeper | NUMPY  | Day 45\nGot a new book \"Python Data Science HandBook\" by JK VanderPlas Check the Jupyter notebooks here.\nStarted with chapter 2 : Introduction to Numpy. Covered topics like Data Types, Numpy arrays and Computations on Numpy arrays.\nCheck the code - \nIntroduction to NumPy\nUnderstanding Data Types in Python\nThe Basics of NumPy Arrays\nComputation on NumPy Arrays: Universal Functions\nDigging Deeper | NUMPY | Day 46\nChapter 2 : Aggregations, Comparisions and Broadcasting\nLink to Notebook:\nAggregations: Min, Max, and Everything In Between\nComputation on Arrays: Broadcasting\nComparisons, Masks, and Boolean Logic\nDigging Deeper | NUMPY | Day 47\nChapter 2 : Fancy Indexing, sorting arrays, Struchered Data\nLink to Notebook:\nFancy Indexing\nSorting Arrays\nStructured Data: NumPy's Structured Arrays\nDigging Deeper | PANDAS | Day 48\nChapter 3 : Data Manipulation with Pandas\n Covered Various topics like Pandas Objects, Data Indexing and Selection, Operating on Data, Handling Missing Data, Hierarchical Indexing, ConCat and Append.\nLink To the Notebooks:\nData Manipulation with Pandas\nIntroducing Pandas Objects\nData Indexing and Selection\nOperating on Data in Pandas\nHandling Missing Data\nHierarchical Indexing\nCombining Datasets: Concat and Append\nDigging Deeper | PANDAS | Day 49\nChapter 3: Completed following topics- Merge and Join, Aggregation and grouping and Pivot Tables.\nCombining Datasets: Merge and Join\nAggregation and Grouping\nPivot Tables\nDigging Deeper | PANDAS | Day 50\nChapter 3: Vectorized Strings Operations, Working with Time Series\nLinks to Notebooks:\nVectorized String Operations\nWorking with Time Series\nHigh-Performance Pandas: eval() and query()\nDigging Deeper | MATPLOTLIB | Day 51\nChapter 4: Visualization with Matplotlib \nLearned about Simple Line Plots, Simple Scatter Plotsand Density and Contour Plots.\nLinks to Notebooks: \nVisualization with Matplotlib\nSimple Line Plots\nSimple Scatter Plots\nVisualizing Errors\nDensity and Contour Plots\nDigging Deeper | MATPLOTLIB | Day 52\nChapter 4: Visualization with Matplotlib \nLearned about Histograms, How to customize plot legends, colorbars, and buliding Multiple Subplots.\nLinks to Notebooks: \nHistograms, Binnings, and Density\nCustomizing Plot Legends\nCustomizing Colorbars\nMultiple Subplots\nText and Annotation\nDigging Deeper | MATPLOTLIB | Day 53\nChapter 4: Covered Three Dimensional Plotting in Mathplotlib.\nLinks to Notebooks:\nThree-Dimensional Plotting in Matplotlib\nHierarchical Clustering | Day 54\nStudied about Hierarchical Clustering.\nCheck out this amazing Visualization.",
	"book chinese computer-vision deep-learning machine-learning natural-language-processing notebook python": "\u52a8\u624b\u5b66\u6df1\u5ea6\u5b66\u4e60\uff08Dive into Deep Learning\uff0cD2L.ai\uff09\n\u7b2c\u4e00\u7248\uff1azh-v1.D2L.ai |  \u7b2c\u4e8c\u7248\u9884\u89c8\u7248\uff1azh.D2L.ai  | \u5b89\u88c5\u548c\u4f7f\u7528\u4e66\u4e2d\u6e90\u4ee3\u7801\uff1a\u7b2c\u4e00\u7248 \u7b2c\u4e8c\u7248 | \u5f53\u524d\u7248\u672c: v2.0.0-beta1\n\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u4f73\u65b9\u6cd5\u662f\u5b66\u4ee5\u81f4\u7528\u3002\n\u672c\u5f00\u6e90\u9879\u76ee\u4ee3\u8868\u4e86\u6211\u4eec\u7684\u4e00\u79cd\u5c1d\u8bd5\uff1a\u6211\u4eec\u5c06\u6559\u7ed9\u8bfb\u8005\u6982\u5ff5\u3001\u80cc\u666f\u77e5\u8bc6\u548c\u4ee3\u7801\uff1b\u6211\u4eec\u5c06\u5728\u540c\u4e00\u4e2a\u5730\u65b9\u9610\u8ff0\u5256\u6790\u95ee\u9898\u6240\u9700\u7684\u6279\u5224\u6027\u601d\u7ef4\u3001\u89e3\u51b3\u95ee\u9898\u6240\u9700\u7684\u6570\u5b66\u77e5\u8bc6\uff0c\u4ee5\u53ca\u5b9e\u73b0\u89e3\u51b3\u65b9\u6848\u6240\u9700\u7684\u5de5\u7a0b\u6280\u80fd\u3002\n\u6211\u4eec\u7684\u76ee\u6807\u662f\u521b\u5efa\u4e00\u4e2a\u4e3a\u5b9e\u73b0\u4ee5\u4e0b\u76ee\u6807\u7684\u7edf\u4e00\u8d44\u6e90\uff1a\n1. \u6240\u6709\u4eba\u5747\u53ef\u5728\u7f51\u4e0a\u514d\u8d39\u83b7\u53d6\uff1b\n1. \u63d0\u4f9b\u8db3\u591f\u7684\u6280\u672f\u6df1\u5ea6\uff0c\u4ece\u800c\u5e2e\u52a9\u8bfb\u8005\u5b9e\u9645\u6210\u4e3a\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u79d1\u5b66\u5bb6\uff1a\u65e2\u7406\u89e3\u6570\u5b66\u539f\u7406\uff0c\u53c8\u80fd\u591f\u5b9e\u73b0\u5e76\u4e0d\u65ad\u6539\u8fdb\u65b9\u6cd5\uff1b\n1. \u5305\u542b\u53ef\u8fd0\u884c\u7684\u4ee3\u7801\uff0c\u4e3a\u8bfb\u8005\u5c55\u793a\u5982\u4f55\u5728\u5b9e\u9645\u4e2d\u89e3\u51b3\u95ee\u9898\u3002\u8fd9\u6837\u4e0d\u4ec5\u76f4\u63a5\u5c06\u6570\u5b66\u516c\u5f0f\u5bf9\u5e94\u6210\u5b9e\u9645\u4ee3\u7801\uff0c\u800c\u4e14\u53ef\u4ee5\u4fee\u6539\u4ee3\u7801\u3001\u89c2\u5bdf\u7ed3\u679c\u5e76\u53ca\u65f6\u83b7\u53d6\u7ecf\u9a8c\uff1b\n1. \u5141\u8bb8\u6211\u4eec\u548c\u6574\u4e2a\u793e\u533a\u4e0d\u65ad\u5feb\u901f\u8fed\u4ee3\u5185\u5bb9\uff0c\u4ece\u800c\u7d27\u8ddf\u4ecd\u5728\u9ad8\u901f\u53d1\u5c55\u7684\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\uff1b\n1. \u7531\u5305\u542b\u6709\u5173\u6280\u672f\u7ec6\u8282\u95ee\u7b54\u7684\u8bba\u575b\u4f5c\u4e3a\u8865\u5145\uff0c\u4f7f\u5927\u5bb6\u53ef\u4ee5\u76f8\u4e92\u7b54\u7591\u5e76\u4ea4\u6362\u7ecf\u9a8c\u3002\n\u5c06\u672c\u4e66\uff08\u4e2d\u82f1\u6587\u7248\uff09\u7528\u4f5c\u6559\u6750\u6216\u53c2\u8003\u4e66\u7684\u5927\u5b66\n\u5982\u679c\u672c\u4e66\u5bf9\u4f60\u6709\u5e2e\u52a9\uff0c\u8bf7Star (\u2605) \u672c\u4ed3\u5e93\u6216\u5f15\u7528\u672c\u4e66\u7684\u82f1\u6587\u7248\uff1a\n@article{zhang2021dive,\n    title={Dive into Deep Learning},\n    author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},\n    journal={arXiv preprint arXiv:2106.11342},\n    year={2021}\n}\n\u672c\u4e66\u7684\u7b2c\u4e8c\u7248\n\u867d\u7136\u7eb8\u8d28\u4e66\u7b2c\u4e00\u7248\u5df2\u7ecf\u51fa\u7248\uff0c\u4f46\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u4f9d\u7136\u5728\u8fc5\u901f\u53d1\u5c55\u3002\u4e3a\u4e86\u5f97\u5230\u6765\u81ea\u66f4\u5e7f\u6cdb\u7684\u82f1\u6587\u5f00\u6e90\u793e\u533a\u7684\u5e2e\u52a9\uff0c\u4ece\u800c\u63d0\u5347\u672c\u4e66\u8d28\u91cf\uff0c\u672c\u4e66\u7684\u7b2c\u4e8c\u7248\u6b63\u5728\u7528\u82f1\u6587\u5199\u3002\u82f1\u6587\u7248\u6b63\u4e0d\u65ad\u88ab\u642c\u56de\u4e2d\u6587\u7248\u4e2d\u3002\n\u76ee\u524d\uff0c\u82f1\u6587\u7248\u5df2\u8d85\u8fc7160\u8282\uff08\u4e2d\u6587\u7248\u517196\u8282\uff09\uff0c\u4f8b\u5982\u589e\u52a0\u4e86\u7406\u8bba\u80cc\u666f\uff08\u5982\u4f18\u5316\u6536\u655b\u5206\u6790\uff09\u3001\u786c\u4ef6\u8bbe\u8ba1\uff08\u5982\u53c2\u6570\u670d\u52a1\u5668\uff09\u3001\u5168\u65b0\u7bc7\u7ae0\uff08\u5982\u6ce8\u610f\u529b\u673a\u5236\u3001\u63a8\u8350\u7cfb\u7edf\u3001\u6df1\u5ea6\u5b66\u4e60\u7684\u6570\u5b66\u3001\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff09\u3001\u5e94\u7528\u79cd\u7c7b\uff08\u5982\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\uff09\u3001\u6a21\u578b\u79cd\u7c7b\uff08\u5982Transformer\u3001BERT\uff09\u7b49\uff0c\u5e76\u4f18\u5316\u91cd\u7ec4\u4e86\u5927\u91cf\u7ae0\u8282\uff08\u5982\u5c06\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7bc7\u7ae0\u6309\u4ece\u9884\u8bad\u7ec3\u8868\u5f81\u3001\u5230\u6a21\u578b\u8bbe\u8ba1\u3001\u518d\u5230\u4e0b\u6e38\u5e94\u7528\u91cd\u6784\uff09\u3002\n\u6b22\u8fce\u5173\u6ce8\u672c\u4e66\u7b2c\u4e8c\u7248\u7684\u82f1\u6587\u5f00\u6e90\u9879\u76ee\u3002\n\u4e2d\u82f1\u6587\u6559\u5b66\u8d44\u6e90\n\u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821 2019 \u5e74\u6625\u5b66\u671f Introduction to Deep Learning \u8bfe\u7a0b\u6559\u6750\uff08\u540c\u65f6\u63d0\u4f9b\u542b\u6559\u5b66\u89c6\u9891\u5730\u5740\u7684\u4e2d\u6587\u7248\u8bfe\u4ef6\uff09\u3002\n\u5b66\u672f\u754c\u63a8\u8350\n\"Dive into this book if you want to dive into deep learning!\"\n\u2014 \u97e9\u5bb6\u709c\uff0cACM \u9662\u58eb\u3001IEEE \u9662\u58eb\uff0c\u7f8e\u56fd\u4f0a\u5229\u8bfa\u4f0a\u5927\u5b66\u9999\u69df\u5206\u6821\u8ba1\u7b97\u673a\u7cfb Michael Aiken Chair \u6559\u6388\n\"This is a highly welcome addition to the machine learning literature.\"\n\u2014 Bernhard Sch\u00f6lkopf\uff0cACM \u9662\u58eb\u3001\u5fb7\u56fd\u56fd\u5bb6\u79d1\u5b66\u9662\u9662\u58eb\uff0c\u5fb7\u56fd\u9a6c\u514b\u65af\u2022\u666e\u6717\u514b\u7814\u7a76\u6240\u667a\u80fd\u7cfb\u7edf\u9662\u9662\u957f\n\"\u4e66\u4e2d\u4ee3\u7801\u53ef\u8c13\u2018\u6240\u5b66\u5373\u6240\u7528\u2019\u3002\"\n\u2014 \u5468\u5fd7\u534e\uff0cACM \u9662\u58eb\u3001IEEE \u9662\u58eb\u3001AAAS \u9662\u58eb\uff0c\u5357\u4eac\u5927\u5b66\u8ba1\u7b97\u673a\u79d1\u5b66\u4e0e\u6280\u672f\u7cfb\u4e3b\u4efb\n\"\u8fd9\u672c\u4e66\u53ef\u4ee5\u5e2e\u52a9\u6df1\u5ea6\u5b66\u4e60\u5b9e\u8df5\u8005\u5feb\u901f\u63d0\u5347\u81ea\u5df1\u7684\u80fd\u529b\u3002\"\n\u2014 \u5f20\u6f7c\uff0cASA \u9662\u58eb\u3001IMS \u9662\u58eb\uff0c\u9999\u6e2f\u79d1\u6280\u5927\u5b66\u8ba1\u7b97\u673a\u7cfb\u548c\u6570\u5b66\u7cfb\u6559\u6388\n\u5de5\u4e1a\u754c\u63a8\u8350\n\"\u4e00\u672c\u4f18\u79c0\u7684\u6df1\u5ea6\u5b66\u4e60\u6559\u6750\uff0c\u503c\u5f97\u4efb\u4f55\u60f3\u4e86\u89e3\u6df1\u5ea6\u5b66\u4e60\u4f55\u4ee5\u5f15\u7206\u4eba\u5de5\u667a\u80fd\u9769\u547d\u7684\u4eba\u5173\u6ce8\u3002\"\n\u2014 \u9ec4\u4ec1\u52cb\uff0cNVIDIA\u521b\u59cb\u4eba & CEO\n\"\u300a\u52a8\u624b\u5b66\u6df1\u5ea6\u5b66\u4e60\u300b\u662f\u6700\u9002\u5408\u5de5\u4e1a\u754c\u7814\u53d1\u5de5\u7a0b\u5e08\u5b66\u4e60\u7684\u3002\u6211\u6beb\u65e0\u4fdd\u7559\u5730\u5411\u5e7f\u5927\u7684\u8bfb\u8005\u4eec\u5f3a\u70c8\u63a8\u8350\u3002\"\n\u2014 \u4f59\u51ef\uff0c\u5730\u5e73\u7ebf\u516c\u53f8\u521b\u59cb\u4eba & CEO\n\"\u5f3a\u70c8\u63a8\u8350\u8fd9\u672c\u4e66\uff01\u6211\u7279\u522b\u8d5e\u8d4f\u8fd9\u79cd\u624b\u8111\u4e00\u4f53\u7684\u5b66\u4e60\u65b9\u5f0f\u3002\"\n\u2014 \u6f06\u8fdc\uff0c\u8682\u8681\u91d1\u670d\u526f\u603b\u88c1\u3001\u9996\u5e2dAI\u79d1\u5b66\u5bb6\n\"\u300a\u52a8\u624b\u5b66\u6df1\u5ea6\u5b66\u4e60\u300b\u662f\u4e00\u672c\u5f88\u5bb9\u6613\u8ba9\u5b66\u4e60\u8005\u4e0a\u763e\u7684\u4e66\u3002\"\n\u2014 \u6c88\u5f3a\uff0c\u5c06\u95e8\u521b\u6295\u521b\u59cb\u5408\u4f19\u4eba\n\u8d21\u732e\n\u611f\u8c22\u793e\u533a\u8d21\u732e\u8005\u4eec\u4e3a\u6bcf\u4e00\u4f4d\u8bfb\u8005\u6539\u8fdb\u8fd9\u672c\u5f00\u6e90\u4e66\u3002\n\u5982\u4f55\u8d21\u732e | \u81f4\u8c22 | \u8ba8\u8bba\u6216\u62a5\u544a\u95ee\u9898 | \u5176\u4ed6",
	"arxiv creating-deepfakes deep-face-swap deep-learning deep-neural-networks deepface deepfacelab deepfakes deeplearning face-swap faceswap fakeapp machine-learning neural-nets neural-networks": "\ufeff\nDeepFaceLab\nhttps://arxiv.org/abs/2005.05535\nthe leading software for creating deepfakes\n\n\n\nMore than 95% of deepfake videos are created with DeepFaceLab.\nDeepFaceLab is used by such popular youtube channels as\n| deeptomcruise| 1facerussia| arnoldschwarzneggar\n|---|---|---|\n| mariahcareyathome?| diepnep| mr__heisenberg| deepcaprio\n|---|---|---|---|\n| VFXChris Ume| Sham00k|\n|---|---|\n| Collider videos| iFake| NextFace|\n|---|---|---|\n| Futuring Machine| RepresentUS| Corridor Crew|\n|---|---|---|\n| DeepFaker| DeepFakes in movie|\n|---|---|\n| DeepFakeCreator| Jarkan|\n|---|---|\nWhat can I do using DeepFaceLab?\nReplace the face\nDe-age the face\n https://www.youtube.com/watch?v=Ddx5B-84ebo\nReplace the head\n https://www.youtube.com/watch?v=xr5FHd0AdlQ\n https://www.youtube.com/watch?v=RTjgkhMugVw\n https://www.youtube.com/watch?v=R9f7WD0gKPo\nManipulate politicians lips\n(voice replacement is not included!)\n(also requires a skill in video editors such as Adobe After Effects or Davinci Resolve)\n https://www.youtube.com/watch?v=IvY-Abd2FfM\n https://www.youtube.com/watch?v=ERQlaJ_czHU\nDeepfake native resolution progress\nUnfortunately, there is no \"make everything ok\" button in DeepFaceLab. You should spend time studying the workflow and growing your skills. A skill in programs such as AfterEffects or Davinci Resolve is also desirable.\nMini tutorial\nReleases\nWindows (magnet link)\nLast release. Use torrent client to download.\nWindows (Mega.nz)\nContains new and prev releases.\nWindows (yandex.ru)\nContains new and prev releases.\nGoogle Colab (github)\nby @chervonij . You can train fakes for free using Google Colab.\nLinux (github)\nby @nagadit\nCentOS Linux (github)\nMay be outdated. By @elemantalcode\nLinks\nGuides and tutorials\nDeepFaceLab guide\nMain guide\nFaceset creation guide\nHow to create the right faceset\nGoogle Colab guide\nGuide how to train the fake on Google Colab\nCompositing\nTo achieve the highest quality, compose deepfake manually in video editors such as Davinci Resolve or Adobe AfterEffects\nDiscussion and suggestions\nSupplementary material\nReady to work facesets\nCelebrity facesets made by community\nPretrained models\nPretrained models made by community\nCommunication groups\nDiscord\nOfficial discord channel. English / Russian.\nTelegram group\nOfficial telegram group. English / Russian. For anonymous communication. Don't forget to hide your phone number\n\u0420\u0443\u0441\u0441\u043a\u0438\u0439 \u0444\u043e\u0440\u0443\u043c\nmrdeepfakes\nthe biggest NSFW English community\nreddit r/DeepFakesSFW/\nPost your deepfakes there !\nreddit r/RUdeepfakes/\n\u041f\u043e\u0441\u0442\u0438\u043c \u0440\u0443\u0441\u0441\u043a\u0438\u0435 \u0434\u0438\u043f\u0444\u0435\u0439\u043a\u0438 \u0441\u044e\u0434\u0430 !\nQQ\u7fa4124500433\n\u4e2d\u6587\u4ea4\u6d41QQ\u7fa4\uff0c\u5546\u52a1\u5408\u4f5c\u627e\u7fa4\u4e3b\ndfldata.xyz\n\u4e2d\u6587\u4ea4\u6d41\u8bba\u575b\uff0c\u514d\u8d39\u8f6f\u4ef6\u6559\u7a0b\u3001\u6a21\u578b\u3001\u4eba\u8138\u6570\u636e\ndeepfaker.xyz\n\u4e2d\u6587\u5b66\u4e60\u7ad9\uff08\u975e\u5b98\u65b9)\nRelated works\nDeepFaceLive\nReal-time face swap for PC streaming or video calls\nneuralchen/SimSwap\nSwapping face using ONE single photo \u4e00\u5f20\u56fe\u514d\u8bad\u7ec3\u6362\u8138\ndeepfakes/faceswap\nSomething that was before DeepFaceLab and still remains in the past\nHow I can help the project?\nSponsor deepfake research and DeepFaceLab development.\nDonate via Yandex.Money\nbitcoin:bc1qkhh7h0gwwhxgg6h6gpllfgstkd645fefrd5s6z\nCollect facesets\nYou can collect faceset of any celebrity that can be used in DeepFaceLab and share it in the community\nStar this repo\nRegister github account and push \"Star\" button.\nMeme zone\ndeepfacelab #deepfakes #faceswap #face-swap #deep-learning #deeplearning #deep-neural-networks #deepface #deep-face-swap #fakeapp #fake-app #neural-networks #neural-nets #tensorflow #cuda #nvidia",
	"deep-learning machine-learning vision": "Caffe\nCaffe is a deep learning framework made with expression, speed, and modularity in mind.\nIt is developed by Berkeley AI Research (BAIR)/The Berkeley Vision and Learning Center (BVLC) and community contributors.\nCheck out the project site for all the details like\nDIY Deep Learning for Vision with Caffe\nTutorial Documentation\nBAIR reference models and the community model zoo\nInstallation instructions\nand step-by-step examples.\nCustom distributions\nIntel Caffe (Optimized for CPU and support for multi-node), in particular Intel\u00ae Xeon processors.\nOpenCL Caffe e.g. for AMD or Intel devices.\nWindows Caffe\nCommunity\nPlease join the caffe-users group or gitter chat to ask questions and talk about methods and models.\nFramework development discussions and thorough bug reports are collected on Issues.\nHappy brewing!\nLicense and Citation\nCaffe is released under the BSD 2-Clause license.\nThe BAIR/BVLC reference models are released for unrestricted use.\nPlease cite Caffe in your publications if it helps your research:\n@article{jia2014caffe,\n  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},\n  Journal = {arXiv preprint arXiv:1408.5093},\n  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},\n  Year = {2014}\n}",
	"coreml deep-learning ios machine-learning ml object-detection onnx pytorch tflite yolo yolov3 yolov4 yolov5": "YOLOv3 \ud83d\ude80 is a family of object detection architectures and models pretrained on the COCO dataset, and represents Ultralytics\n open-source research into future vision AI methods, incorporating lessons learned and best practices evolved over thousands of hours of research and development.\nDocumentation\nSee the YOLOv3 Docs for full documentation on training, testing and deployment.\nQuick Start Examples\nInstall\nPython>=3.6.0 is required with all\nrequirements.txt installed including\nPyTorch>=1.7:\nbash\n$ git clone https://github.com/ultralytics/yolov3\n$ cd yolov3\n$ pip install -r requirements.txt\nInference\nInference with YOLOv3 and PyTorch Hub. Models automatically download\nfrom the latest YOLOv3 release.\n```python\nimport torch\nModel\nmodel = torch.hub.load('ultralytics/yolov3', 'yolov3')  # or yolov3-spp, yolov3-tiny, custom\nImages\nimg = 'https://ultralytics.com/images/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list\nInference\nresults = model(img)\nResults\nresults.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n```\nInference with detect.py\ndetect.py runs inference on a variety of sources, downloading models automatically from\nthe latest YOLOv3 release and saving results to runs/detect.\nbash\n$ python detect.py --source 0  # webcam\n                            img.jpg  # image\n                            vid.mp4  # video\n                            path/  # directory\n                            path/*.jpg  # glob\n                            'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n                            'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\nTraining\nTutorials\n\nTrain Custom Data\u00a0 \ud83d\ude80 RECOMMENDED\nTips for Best Training Results\u00a0 \u2618\ufe0f\n  RECOMMENDED\nWeights & Biases Logging\u00a0 \ud83c\udf1f NEW\nRoboflow for Datasets, Labeling, and Active Learning\u00a0 \ud83c\udf1f NEW\nMulti-GPU Training\nPyTorch Hub\u00a0 \u2b50 NEW\nTorchScript, ONNX, CoreML Export \ud83d\ude80\nTest-Time Augmentation (TTA)\nModel Ensembling\nModel Pruning/Sparsity\nHyperparameter Evolution\nTransfer Learning with Frozen Layers\u00a0 \u2b50 NEW\nTensorRT Deployment\n\nEnvironments\nGet started in seconds with our verified environments. Click each icon below for details.\nIntegrations\n|Weights and Biases|Roboflow \u2b50 NEW|\n|:-:|:-:|\n|Automatically track and visualize all your YOLOv3 training runs in the cloud with Weights & Biases|Label and export your custom datasets directly to YOLOv3 for training with Roboflow |\nWhy YOLOv5\nYOLOv3-P5 640 Figure (click to expand)\nFigure Notes (click to expand)\n\nCOCO AP val denotes mAP@0.5:0.95 metric measured on the 5000-image COCO val2017 dataset over various inference sizes from 256 to 1536.\nGPU Speed measures average inference time per image on COCO val2017 dataset using a AWS p3.2xlarge V100 instance at batch-size 32.\nEfficientDet data from google/automl at batch size 8.\nReproduce by python val.py --task study --data coco.yaml --iou 0.7 --weights yolov5n6.pt yolov5s6.pt yolov5m6.pt yolov5l6.pt yolov5x6.pt\n\nPretrained Checkpoints\n|Model |size(pixels) |mAPval0.5:0.95 |mAPval0.5 |SpeedCPU b1(ms) |SpeedV100 b1(ms) |SpeedV100 b32(ms) |params(M) |FLOPs@640 (B)\n|---                    |---  |---    |---    |---    |---    |---    |---    |---\n|YOLOv5n      |640  |28.4   |46.0   |45 |6.3|0.6|1.9|4.5\n|YOLOv5s      |640  |37.2   |56.0   |98     |6.4    |0.9    |7.2    |16.5\n|YOLOv5m      |640  |45.2   |63.9   |224    |8.2    |1.7    |21.2   |49.0\n|YOLOv5l      |640  |48.8   |67.2   |430    |10.1   |2.7    |46.5   |109.1\n|YOLOv5x      |640  |50.7   |68.9   |766    |12.1   |4.8    |86.7   |205.7\n|                       |     |       |       |       |       |       |       |\n|YOLOv5n6     |1280 |34.0   |50.7   |153    |8.1    |2.1    |3.2    |4.6\n|YOLOv5s6     |1280 |44.5   |63.0   |385    |8.2    |3.6    |16.8   |12.6\n|YOLOv5m6     |1280 |51.0   |69.0   |887    |11.1   |6.8    |35.7   |50.0\n|YOLOv5l6     |1280 |53.6   |71.6   |1784   |15.8   |10.5   |76.8   |111.4\n|YOLOv5x6+ TTA|12801536 |54.755.4 |72.472.3 |3136- |26.2- |19.4- |140.7- |209.8-\nTable Notes (click to expand)\n\nAll checkpoints are trained to 300 epochs with default settings and hyperparameters.\nmAPval values are for single-model single-scale on COCO val2017 dataset.Reproduce by python val.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65\nSpeed averaged over COCO val images using a AWS p3.2xlarge instance. NMS times (~1 ms/img) not included.Reproduce by python val.py --data coco.yaml --img 640 --conf 0.25 --iou 0.45\nTTA Test Time Augmentation includes reflection and scale augmentations.Reproduce by python val.py --data coco.yaml --img 1536 --iou 0.7 --augment\n\nContribute\nWe love your input! We want to make contributing to YOLOv3 as easy and transparent as possible. Please see our Contributing Guide to get started, and fill out the YOLOv3 Survey to send us feedback on your experiences. Thank you to all our contributors!\nContact\nFor YOLOv3 bugs and feature requests please visit GitHub Issues. For business inquiries or\nprofessional support requests please visit https://ultralytics.com/contact.",
	"coursera machine-learning": "\u65af\u5766\u798f\u5927\u5b662014\uff08\u5434\u6069\u8fbe\uff09\u673a\u5668\u5b66\u4e60\u6559\u7a0b\u4e2d\u6587\u7b14\u8bb0\n\u8bfe\u7a0b\u5730\u5740\uff1ahttps://www.coursera.org/course/ml\n\u7b14\u8bb0\u5728\u7ebf\u9605\u8bfb\nMachine Learning(\u673a\u5668\u5b66\u4e60)\u662f\u7814\u7a76\u8ba1\u7b97\u673a\u600e\u6837\u6a21\u62df\u6216\u5b9e\u73b0\u4eba\u7c7b\u7684\u5b66\u4e60\u884c\u4e3a\uff0c\u4ee5\u83b7\u53d6\u65b0\u7684\u77e5\u8bc6\u6216\u6280\u80fd\uff0c\u91cd\u65b0\u7ec4\u7ec7\u5df2\u6709\u7684\u77e5\u8bc6\u7ed3\u6784\u4f7f\u4e4b\u4e0d\u65ad\u6539\u5584\u81ea\u8eab\u7684\u6027\u80fd\u3002\u5b83\u662f\u4eba\u5de5\u667a\u80fd\u7684\u6838\u5fc3\uff0c\u662f\u4f7f\u8ba1\u7b97\u673a\u5177\u6709\u667a\u80fd\u7684\u6839\u672c\u9014\u5f84\uff0c\u5176\u5e94\u7528\u904d\u53ca\u4eba\u5de5\u667a\u80fd\u7684\u5404\u4e2a\u9886\u57df\uff0c\u5b83\u4e3b\u8981\u4f7f\u7528\u5f52\u7eb3\u3001\u7efc\u5408\u800c\u4e0d\u662f\u6f14\u8bd1\u3002\u5728\u8fc7\u53bb\u7684\u5341\u5e74\u4e2d\uff0c\u673a\u5668\u5b66\u4e60\u5e2e\u52a9\u6211\u4eec\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff0c\u6709\u6548\u7684\u8bed\u97f3\u8bc6\u522b\uff0c\u6709\u6548\u7684\u7f51\u7edc\u641c\u7d22\uff0c\u5e76\u6781\u5927\u5730\u63d0\u9ad8\u4e86\u4eba\u7c7b\u57fa\u56e0\u7ec4\u7684\u8ba4\u8bc6\u3002\u673a\u5668\u5b66\u4e60\u662f\u5f53\u4eca\u975e\u5e38\u666e\u904d\uff0c\u4f60\u53ef\u80fd\u4f1a\u4f7f\u7528\u8fd9\u4e00\u5929\u51e0\u5341\u500d\u800c\u4e0d\u81ea\u77e5\u3002\u5f88\u591a\u7814\u7a76\u8005\u4e5f\u8ba4\u4e3a\u8fd9\u662f\u6700\u597d\u7684\u4eba\u5de5\u667a\u80fd\u7684\u53d6\u5f97\u65b9\u5f0f\u3002\u5728\u672c\u8bfe\u4e2d\uff0c\u60a8\u5c06\u5b66\u4e60\u6700\u6709\u6548\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5e76\u83b7\u5f97\u5b9e\u8df5\uff0c\u8ba9\u5b83\u4eec\u4e3a\u81ea\u5df1\u7684\u5de5\u4f5c\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u4f60\u4f1a\u4e0d\u4ec5\u5f97\u5230\u7406\u8bba\u57fa\u7840\u7684\u5b66\u4e60\uff0c\u800c\u4e14\u83b7\u5f97\u90a3\u4e9b\u9700\u8981\u5feb\u901f\u548c\u5f3a\u5927\u7684\u5e94\u7528\u6280\u672f\u89e3\u51b3\u95ee\u9898\u7684\u5b9e\u7528\u6280\u672f\u3002\u6700\u540e\uff0c\u4f60\u4f1a\u5b66\u5230\u4e00\u4e9b\u7845\u8c37\u5229\u7528\u673a\u5668\u5b66\u4e60\u548c\u4eba\u5de5\u667a\u80fd\u7684\u6700\u4f73\u5b9e\u8df5\u521b\u65b0\u3002\n\u672c\u8bfe\u7a0b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e7f\u6cdb\u7684\u4ecb\u7ecd\u673a\u5668\u5b66\u4e60\u3001\u6570\u636e\u6316\u6398\u3001\u7edf\u8ba1\u6a21\u5f0f\u8bc6\u522b\u7684\u8bfe\u7a0b\u3002\u4e3b\u9898\u5305\u62ec\uff1a\n\uff08\u4e00\uff09\u76d1\u7763\u5b66\u4e60\uff08\u53c2\u6570/\u975e\u53c2\u6570\u7b97\u6cd5\uff0c\u652f\u6301\u5411\u91cf\u673a\uff0c\u6838\u51fd\u6570\uff0c\u795e\u7ecf\u7f51\u7edc\uff09\u3002\n\uff08\u4e8c\uff09\u65e0\u76d1\u7763\u5b66\u4e60\uff08\u805a\u7c7b\uff0c\u964d\u7ef4\uff0c\u63a8\u8350\u7cfb\u7edf\uff0c\u6df1\u5165\u5b66\u4e60\u63a8\u8350\uff09\u3002\n\uff08\u4e09\uff09\u5728\u673a\u5668\u5b66\u4e60\u7684\u6700\u4f73\u5b9e\u8df5\uff08\u504f\u5dee/\u65b9\u5dee\u7406\u8bba\uff1b\u5728\u673a\u5668\u5b66\u4e60\u548c\u4eba\u5de5\u667a\u80fd\u521b\u65b0\u8fc7\u7a0b\uff09\u3002\u672c\u8bfe\u7a0b\u8fd8\u5c06\u4f7f\u7528\u5927\u91cf\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u60a8\u8fd8\u5c06\u5b66\u4e60\u5982\u4f55\u8fd0\u7528\u5b66\u4e60\u7b97\u6cd5\u6784\u5efa\u667a\u80fd\u673a\u5668\u4eba\uff08\u611f\u77e5\uff0c\u63a7\u5236\uff09\uff0c\u6587\u672c\u7684\u7406\u89e3\uff08Web\u641c\u7d22\uff0c\u53cd\u5783\u573e\u90ae\u4ef6\uff09\uff0c\u8ba1\u7b97\u673a\u89c6\u89c9\uff0c\u533b\u7597\u4fe1\u606f\uff0c\u97f3\u9891\uff0c\u6570\u636e\u6316\u6398\uff0c\u548c\u5176\u4ed6\u9886\u57df\u3002\n\u672c\u8bfe\u7a0b\u9700\u898110\u5468\u517118\u8282\u8bfe\uff0c\u76f8\u5bf9\u4ee5\u524d\u7684\u673a\u5668\u5b66\u4e60\u89c6\u9891\uff0c\u8fd9\u4e2a\u89c6\u9891\u66f4\u52a0\u6e05\u6670\uff0c\u800c\u4e14\u6bcf\u8bfe\u90fd\u6709ppt\u8bfe\u4ef6\uff0c\u63a8\u8350\u5b66\u4e60\u3002\n\u672c\u4eba2014\u5e74\u4e0b\u534a\u5e74\u5f00\u59cb\u7ffb\u8bd1\u672c\u8bfe\u7a0b\u5b57\u5e55\uff0c\u5e76\u5199\u4e86\u8bfe\u7a0b\u7684\u4e2d\u6587\u7b14\u8bb0\u3002\u7b14\u8bb0\u88ab\u4e0b\u8f7d\u4e86\u51e0\u4e07\u6b21\uff0c\u5e94\u8be5\u5e2e\u52a9\u4e86\u4e0d\u5c11\u4eba\uff0c\u4e5f\u6709\u5f88\u591a\u4eba\u4e00\u76f4\u5728\u5e2e\u52a9\u6211\uff0c\u73b0\u5728\u6211\u628a\u7b14\u8bb0\u7684word\u539f\u7a3f\u548cmarkdown\u539f\u7a3f\u5206\u4eab\u7ed9\u5927\u5bb6\u3002\nmarkdown\u7684\u7b14\u8bb0\u548c\u8bfe\u7a0b\u4e2d\u82f1\u6587\u5b57\u5e55\u6211\u5c06\u653e\u5728github\uff0c\u5e0c\u671b\u5927\u5bb6\u80fd\u7ee7\u7eed\u5b8c\u5584\u3002\u4e3a\u65b9\u4fbf\u6570\u5b66\u516c\u5f0f\u7684\u5728\u7ebf\u663e\u793a\uff0c\u5728\u7ebf\u89c2\u770b\u7684\u662fhtml\u6587\u4ef6\uff0c\u516c\u5f0f\u5df2\u7ecf\u88ab\u8f6c\u4e3a\u56fe\u7247\uff0c\u516c\u5f0f\u6e90\u7801\u5728markdown\u6587\u4ef6\u3002\n\u6700\u540e\u60f3\u5bf9\u5404\u4f4d\u670b\u53cb\u8bf4\uff1a\n\u8d60\u4eba\u73ab\u7470\uff0c\u624b\u6709\u4f59\u9999\uff01\n\u5728\u4eba\u5de5\u667a\u80fd\u7684\u9053\u8def\u4e0a\uff0c\u4f60\u4e0d\u662f\u4e00\u4e2a\u4eba\u5728\u6218\u6597\uff01\n\u9ec4\u6d77\u5e7f\n2018-3-26 \u591c\n\u5fae\u4fe1\u516c\u4f17\u53f7\uff1a\u673a\u5668\u5b66\u4e60\u521d\u5b66\u8005 \n\u6211\u7684\u77e5\u4e4e\n\u53c2\u8003\uff1a\nhttps://www.coursera.org/course/ml \u673a\u5668\u5b66\u4e60\u516c\u5f00\u8bfe\nhttps://mooc.guokr.com/note/12/ \u5c0f\u5c0f\u4eba_V \u7684\u4e2a\u4eba\u7b14\u8bb0\n\u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300b\u674e\u822a   \n\u300a\u673a\u5668\u5b66\u4e60\u8bfe\u300b\u90b9\u535a\n\u5907\u6ce8\uff1a\u5434\u6069\u8fbe\u8001\u5e08\u7684\u6df1\u5ea6\u5b66\u4e60\u8bfe\uff08deepLearning.ai\uff09\u7684\u7b14\u8bb0\u5730\u5740\uff1ahttps://github.com/fengdu78/deeplearning_ai_books\n\u6587\u4ef6\u5939\u8bf4\u660e\uff1a\ndocx\uff1a\u7b14\u8bb0\u7684word\u7248\u672c\nmarkdown\uff1a\u7b14\u8bb0\u7684markdown\u7248\u672c\nhtml\uff1a\u7b14\u8bb0\u7684html\u7248\u672c\nimages\uff1a\u7b14\u8bb0\u7684\u56fe\u7247\nppt\uff1a\u8bfe\u7a0b\u7684\u539f\u7248\u8bfe\u4ef6\nsrt\uff1a\u8bfe\u7a0b\u7684\u4e2d\u82f1\u6587\u5b57\u5e55\uff08mp4\u6587\u4ef6\u9700\u8981\u5728\u767e\u5ea6\u4e91\u4e0b\u8f7d\uff0c\u5927\u5bb6\u53ef\u4ee5\u7528\u8bb0\u4e8b\u672c\u6216\u8005\u5b57\u5e55\u7f16\u8f91\u8f6f\u4ef6\u6765\u7f16\u8f91\u5b57\u5e55\uff0c\u5171\u540c\u5b8c\u5584\u3002\n\u767e\u5ea6\u4e91\u94fe\u63a5\uff1ahttps://pan.baidu.com/s/1h8QjqBlOm0Exh7orm9teMQ \u5bc6\u7801\uff1ad3we\uff0c\u4e0b\u8f7d\u540e\u89e3\u538b\uff09\ncode\uff1a\u8bfe\u7a0b\u7684python\u4ee3\u7801\n\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b\u89c6\u9891\uff1ahttps://www.bilibili.com/video/BV1W34y1i7xK\n\u7b14\u8bb0\u5728\u7ebf\u9605\u8bfb\n\u7b14\u8bb0pdf\u7248\u672c\u4e0b\u8f7d \uff1a\u89c1Github\u6839\u76ee\u5f55\u3002\n\u673a\u5668\u5b66\u4e60qq\u7fa4\uff1a955171419\uff08\u6211\u4eec\u670913\u4e2a\u7fa4\uff0c\u52a0\u8fc7\u4e00\u4e2a\u5c31\u4e0d\u9700\u8981\u52a0\u4e86\uff09\n\u673a\u5668\u5b66\u4e60\u6559\u7a0b\u4e2d\u6587\u7b14\u8bb0\u76ee\u5f55\n\u7b2c\u4e00\u5468\n\u4e00\u3001 \u5f15\u8a00(Introduction) \n1.1 \u6b22\u8fce \n1.2 \u673a\u5668\u5b66\u4e60\u662f\u4ec0\u4e48\uff1f \n1.3 \u76d1\u7763\u5b66\u4e60 \n1.4 \u65e0\u76d1\u7763\u5b66\u4e60 \n\u4e8c\u3001\u5355\u53d8\u91cf\u7ebf\u6027\u56de\u5f52(Linear Regression with One Variable) \n2.1 \u6a21\u578b\u8868\u793a \n2.2 \u4ee3\u4ef7\u51fd\u6570 \n2.3 \u4ee3\u4ef7\u51fd\u6570\u7684\u76f4\u89c2\u7406\u89e3I \n2.4 \u4ee3\u4ef7\u51fd\u6570\u7684\u76f4\u89c2\u7406\u89e3II \n2.5 \u68af\u5ea6\u4e0b\u964d \n2.6 \u68af\u5ea6\u4e0b\u964d\u7684\u76f4\u89c2\u7406\u89e3 \n2.7 \u68af\u5ea6\u4e0b\u964d\u7684\u7ebf\u6027\u56de\u5f52 \n2.8 \u63a5\u4e0b\u6765\u7684\u5185\u5bb9 \n\u4e09\u3001\u7ebf\u6027\u4ee3\u6570\u56de\u987e(Linear Algebra Review) \n3.1 \u77e9\u9635\u548c\u5411\u91cf \n3.2 \u52a0\u6cd5\u548c\u6807\u91cf\u4e58\u6cd5 \n3.3 \u77e9\u9635\u5411\u91cf\u4e58\u6cd5 \n3.4 \u77e9\u9635\u4e58\u6cd5 \n3.5 \u77e9\u9635\u4e58\u6cd5\u7684\u6027\u8d28 \n3.6 \u9006\u3001\u8f6c\u7f6e\n\u7b2c\u4e8c\u5468\n\u56db\u3001\u591a\u53d8\u91cf\u7ebf\u6027\u56de\u5f52(Linear Regression with Multiple Variables) \n4.1 \u591a\u7ef4\u7279\u5f81 \n4.2 \u591a\u53d8\u91cf\u68af\u5ea6\u4e0b\u964d \n4.3 \u68af\u5ea6\u4e0b\u964d\u6cd5\u5b9e\u8df51-\u7279\u5f81\u7f29\u653e \n4.4 \u68af\u5ea6\u4e0b\u964d\u6cd5\u5b9e\u8df52-\u5b66\u4e60\u7387 \n4.5 \u7279\u5f81\u548c\u591a\u9879\u5f0f\u56de\u5f52 \n4.6 \u6b63\u89c4\u65b9\u7a0b \n4.7 \u6b63\u89c4\u65b9\u7a0b\u53ca\u4e0d\u53ef\u9006\u6027\uff08\u9009\u4fee\uff09 \n\u4e94\u3001Octave\u6559\u7a0b(Octave Tutorial) \n5.1 \u57fa\u672c\u64cd\u4f5c \n5.2 \u79fb\u52a8\u6570\u636e \n5.3 \u8ba1\u7b97\u6570\u636e \n5.4 \u7ed8\u56fe\u6570\u636e \n5.5 \u63a7\u5236\u8bed\u53e5\uff1afor\uff0cwhile\uff0cif\u8bed\u53e5 \n5.6 \u5411\u91cf\u5316 88\n5.7 \u5de5\u4f5c\u548c\u63d0\u4ea4\u7684\u7f16\u7a0b\u7ec3\u4e60 \n\u7b2c\u4e09\u5468\n\u516d\u3001\u903b\u8f91\u56de\u5f52(Logistic Regression) \n6.1 \u5206\u7c7b\u95ee\u9898 \n6.2 \u5047\u8bf4\u8868\u793a \n6.3 \u5224\u5b9a\u8fb9\u754c \n6.4 \u4ee3\u4ef7\u51fd\u6570 \n6.5 \u7b80\u5316\u7684\u6210\u672c\u51fd\u6570\u548c\u68af\u5ea6\u4e0b\u964d \n6.6 \u9ad8\u7ea7\u4f18\u5316 \n6.7 \u591a\u7c7b\u522b\u5206\u7c7b\uff1a\u4e00\u5bf9\u591a \n\u4e03\u3001\u6b63\u5219\u5316(Regularization) \n7.1 \u8fc7\u62df\u5408\u7684\u95ee\u9898 \n7.2 \u4ee3\u4ef7\u51fd\u6570 \n7.3 \u6b63\u5219\u5316\u7ebf\u6027\u56de\u5f52 \n7.4 \u6b63\u5219\u5316\u7684\u903b\u8f91\u56de\u5f52\u6a21\u578b \n\u7b2c\u56db\u5468\n\u7b2c\u516b\u3001\u795e\u7ecf\u7f51\u7edc\uff1a\u8868\u8ff0(Neural Networks: Representation) \n8.1 \u975e\u7ebf\u6027\u5047\u8bbe \n8.2 \u795e\u7ecf\u5143\u548c\u5927\u8111 \n8.3 \u6a21\u578b\u8868\u793a1 \n8.4 \u6a21\u578b\u8868\u793a2 \n8.5 \u6837\u672c\u548c\u76f4\u89c2\u7406\u89e31 \n8.6 \u6837\u672c\u548c\u76f4\u89c2\u7406\u89e3II \n8.7 \u591a\u7c7b\u5206\u7c7b \n\u7b2c\u4e94\u5468\n\u4e5d\u3001\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60(Neural Networks: Learning) \n9.1 \u4ee3\u4ef7\u51fd\u6570 \n9.2 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5 \n9.3 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u7684\u76f4\u89c2\u7406\u89e3 \n9.4 \u5b9e\u73b0\u6ce8\u610f\uff1a\u5c55\u5f00\u53c2\u6570 \n9.5 \u68af\u5ea6\u68c0\u9a8c \n9.6 \u968f\u673a\u521d\u59cb\u5316 \n9.7 \u7efc\u5408\u8d77\u6765 \n9.8 \u81ea\u4e3b\u9a7e\u9a76 \n\u7b2c\u516d\u5468\n\u5341\u3001\u5e94\u7528\u673a\u5668\u5b66\u4e60\u7684\u5efa\u8bae(Advice for Applying Machine Learning) \n10.1 \u51b3\u5b9a\u4e0b\u4e00\u6b65\u505a\u4ec0\u4e48 \n10.2 \u8bc4\u4f30\u4e00\u4e2a\u5047\u8bbe \n10.3 \u6a21\u578b\u9009\u62e9\u548c\u4ea4\u53c9\u9a8c\u8bc1\u96c6 \n10.4 \u8bca\u65ad\u504f\u5dee\u548c\u65b9\u5dee \n10.5 \u6b63\u5219\u5316\u548c\u504f\u5dee/\u65b9\u5dee \n10.6 \u5b66\u4e60\u66f2\u7ebf \n10.7 \u51b3\u5b9a\u4e0b\u4e00\u6b65\u505a\u4ec0\u4e48 \n\u5341\u4e00\u3001\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u8bbe\u8ba1(Machine Learning System Design) \n11.1 \u9996\u5148\u8981\u505a\u4ec0\u4e48 \n11.2 \u8bef\u5dee\u5206\u6790 \n11.3 \u7c7b\u504f\u659c\u7684\u8bef\u5dee\u5ea6\u91cf \n11.4 \u67e5\u51c6\u7387\u548c\u67e5\u5168\u7387\u4e4b\u95f4\u7684\u6743\u8861 \n11.5 \u673a\u5668\u5b66\u4e60\u7684\u6570\u636e \n\u7b2c7\u5468\n\u5341\u4e8c\u3001\u652f\u6301\u5411\u91cf\u673a(Support Vector Machines) \n12.1 \u4f18\u5316\u76ee\u6807 \n12.2 \u5927\u8fb9\u754c\u7684\u76f4\u89c2\u7406\u89e3 \n12.3 \u6570\u5b66\u80cc\u540e\u7684\u5927\u8fb9\u754c\u5206\u7c7b\uff08\u9009\u4fee\uff09 \n12.4 \u6838\u51fd\u65701 \n12.5 \u6838\u51fd\u65702 \n12.6 \u4f7f\u7528\u652f\u6301\u5411\u91cf\u673a \n\u7b2c\u516b\u5468\n\u5341\u4e09\u3001\u805a\u7c7b(Clustering) \n13.1 \u65e0\u76d1\u7763\u5b66\u4e60\uff1a\u7b80\u4ecb \n13.2 K-\u5747\u503c\u7b97\u6cd5 \n13.3 \u4f18\u5316\u76ee\u6807 \n13.4 \u968f\u673a\u521d\u59cb\u5316\n13.5 \u9009\u62e9\u805a\u7c7b\u6570 \n\u5341\u56db\u3001\u964d\u7ef4(Dimensionality Reduction) \n14.1 \u52a8\u673a\u4e00\uff1a\u6570\u636e\u538b\u7f29 \n14.2 \u52a8\u673a\u4e8c\uff1a\u6570\u636e\u53ef\u89c6\u5316 \n14.3 \u4e3b\u6210\u5206\u5206\u6790\u95ee\u9898 \n14.4 \u4e3b\u6210\u5206\u5206\u6790\u7b97\u6cd5 \n14.5 \u9009\u62e9\u4e3b\u6210\u5206\u7684\u6570\u91cf \n14.6 \u91cd\u5efa\u7684\u538b\u7f29\u8868\u793a \n14.7 \u4e3b\u6210\u5206\u5206\u6790\u6cd5\u7684\u5e94\u7528\u5efa\u8bae \n\u7b2c\u4e5d\u5468\n\u5341\u4e94\u3001\u5f02\u5e38\u68c0\u6d4b(Anomaly Detection) \n15.1 \u95ee\u9898\u7684\u52a8\u673a \n15.2 \u9ad8\u65af\u5206\u5e03 \n15.3 \u7b97\u6cd5 \n15.4 \u5f00\u53d1\u548c\u8bc4\u4ef7\u4e00\u4e2a\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf \n15.5 \u5f02\u5e38\u68c0\u6d4b\u4e0e\u76d1\u7763\u5b66\u4e60\u5bf9\u6bd4 \n15.6 \u9009\u62e9\u7279\u5f81 \n15.7 \u591a\u5143\u9ad8\u65af\u5206\u5e03\uff08\u9009\u4fee\uff09 \n15.8 \u4f7f\u7528\u591a\u5143\u9ad8\u65af\u5206\u5e03\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\uff08\u9009\u4fee\uff09 \n\u5341\u516d\u3001\u63a8\u8350\u7cfb\u7edf(Recommender Systems) \n16.1 \u95ee\u9898\u5f62\u5f0f\u5316 \n16.2 \u57fa\u4e8e\u5185\u5bb9\u7684\u63a8\u8350\u7cfb\u7edf \n16.3 \u534f\u540c\u8fc7\u6ee4 \n16.4 \u534f\u540c\u8fc7\u6ee4\u7b97\u6cd5 \n16.5 \u5411\u91cf\u5316\uff1a\u4f4e\u79e9\u77e9\u9635\u5206\u89e3 \n16.6 \u63a8\u884c\u5de5\u4f5c\u4e0a\u7684\u7ec6\u8282\uff1a\u5747\u503c\u5f52\u4e00\u5316 \n\u7b2c\u5341\u5468\n\u5341\u4e03\u3001\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60(Large Scale Machine Learning) \n17.1 \u5927\u578b\u6570\u636e\u96c6\u7684\u5b66\u4e60 \n17.2 \u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5 \n17.3 \u5c0f\u6279\u91cf\u68af\u5ea6\u4e0b\u964d \n17.4 \u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6536\u655b \n17.5 \u5728\u7ebf\u5b66\u4e60 \n17.6 \u6620\u5c04\u5316\u7b80\u548c\u6570\u636e\u5e76\u884c \n\u5341\u516b\u3001\u5e94\u7528\u5b9e\u4f8b\uff1a\u56fe\u7247\u6587\u5b57\u8bc6\u522b(Application Example: Photo OCR) \n18.1 \u95ee\u9898\u63cf\u8ff0\u548c\u6d41\u7a0b\u56fe\n18.2 \u6ed1\u52a8\u7a97\u53e3 \n18.3 \u83b7\u53d6\u5927\u91cf\u6570\u636e\u548c\u4eba\u5de5\u6570\u636e \n18.4 \u4e0a\u9650\u5206\u6790\uff1a\u54ea\u90e8\u5206\u7ba1\u9053\u7684\u63a5\u4e0b\u53bb\u505a \n\u5341\u4e5d\u3001\u603b\u7ed3(Conclusion) \n19.1 \u603b\u7ed3\u548c\u81f4\u8c22 \n\u673a\u5668\u5b66\u4e60qq\u7fa4\uff1a955171419\uff08\u6211\u4eec\u670913\u4e2a\u7fa4\uff0c\u52a0\u8fc7\u4e00\u4e2a\u5c31\u4e0d\u9700\u8981\u52a0\u4e86\uff09 ",
	"deep-learning deep-neural-networks machine-learning": "Awesome - Most Cited Deep Learning Papers\n[Notice] This list is not being maintained anymore because of the overwhelming amount of deep learning papers published every day since 2017.\nA curated list of the most cited deep learning papers (2012-2016)\nWe believe that there exist classic deep learning papers which are worth reading regardless of their application domain. Rather than providing overwhelming amount of papers, We would like to provide a curated list of the awesome deep learning papers which are considered as must-reads in certain research domains.\nBackground\nBefore this list, there exist other awesome deep learning lists, for example, Deep Vision and Awesome Recurrent Neural Networks. Also, after this list comes out, another awesome list for deep learning beginners, called Deep Learning Papers Reading Roadmap, has been created and loved by many deep learning researchers.\nAlthough the Roadmap List includes lots of important deep learning papers, it feels overwhelming for me to read them all. As I mentioned in the introduction, I believe that seminal works can give us lessons regardless of their application domain. Thus, I would like to introduce top 100 deep learning papers here as a good starting point of overviewing deep learning researches.\nTo get the news for newly released papers everyday, follow my twitter or facebook page! \nAwesome list criteria\nA list of top 100 deep learning papers published from 2012 to 2016 is suggested.\nIf a paper is added to the list, another paper (usually from *More Papers from 2016\" section) should be removed to keep top 100 papers. (Thus, removing papers is also important contributions as well as adding papers)\nPapers that are important, but failed to be included in the list, will be listed in More than Top 100 section.\nPlease refer to New Papers and Old Papers sections for the papers published in recent 6 months or before 2012.\n(Citation criteria)\n- < 6 months : New Papers (by discussion)\n- 2016 :  +60 citations or \"More Papers from 2016\"\n- 2015 :  +200 citations\n- 2014 :  +400 citations\n- 2013 :  +600 citations\n- 2012 :  +800 citations\n- ~2012 : Old Papers (by discussion)\nPlease note that we prefer seminal deep learning papers that can be applied to various researches rather than application papers. For that reason, some papers that meet the criteria may not be accepted while others can be. It depends on the impact of the paper, applicability to other researches scarcity of the research domain, and so on.\nWe need your contributions!\nIf you have any suggestions (missing papers, new papers, key researchers or typos), please feel free to edit and pull a request.\n(Please read the contributing guide for further instructions, though just letting me know the title of papers can also be a big contribution to us.)\n(Update) You can download all top-100 papers with this and collect all authors' names with this. Also, bib file for all top-100 papers are available. Thanks, doodhwala, Sven and grepinsight!\nCan anyone contribute the code for obtaining the statistics of the authors of Top-100 papers?\nContents\nUnderstanding / Generalization / Transfer\nOptimization / Training Techniques\nUnsupervised / Generative Models\nConvolutional Network Models\nImage Segmentation / Object Detection\nImage / Video / Etc\nNatural Language Processing / RNNs\nSpeech / Other Domain\nReinforcement Learning / Robotics\nMore Papers from 2016\n(More than Top 100)\nNew Papers : Less than 6 months\nOld Papers : Before 2012\nHW / SW / Dataset : Technical reports\nBook / Survey / Review\nVideo Lectures / Tutorials / Blogs\nAppendix: More than Top 100 : More papers not in the list\nUnderstanding / Generalization / Transfer\nDistilling the knowledge in a neural network (2015), G. Hinton et al. [pdf]\nDeep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015), A. Nguyen et al. [pdf]\nHow transferable are features in deep neural networks? (2014), J. Yosinski et al. [pdf]\nCNN features off-the-Shelf: An astounding baseline for recognition (2014), A. Razavian et al. [pdf]\nLearning and transferring mid-Level image representations using convolutional neural networks (2014), M. Oquab et al. [pdf]\nVisualizing and understanding convolutional networks (2014), M. Zeiler and R. Fergus [pdf]\nDecaf: A deep convolutional activation feature for generic visual recognition (2014), J. Donahue et al. [pdf]\nOptimization / Training Techniques\nTraining very deep networks (2015), R. Srivastava et al. [pdf]\nBatch normalization: Accelerating deep network training by reducing internal covariate shift (2015), S. Loffe and C. Szegedy [pdf]\nDelving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015), K. He et al. [pdf]\nDropout: A simple way to prevent neural networks from overfitting (2014), N. Srivastava et al. [pdf]\nAdam: A method for stochastic optimization (2014), D. Kingma and J. Ba [pdf]\nImproving neural networks by preventing co-adaptation of feature detectors (2012), G. Hinton et al. [pdf]\nRandom search for hyper-parameter optimization (2012) J. Bergstra and Y. Bengio [pdf]\nUnsupervised / Generative Models\nPixel recurrent neural networks (2016), A. Oord et al. [pdf]\nImproved techniques for training GANs (2016), T. Salimans et al. [pdf]\nUnsupervised representation learning with deep convolutional generative adversarial networks (2015), A. Radford et al. [pdf]\nDRAW: A recurrent neural network for image generation (2015), K. Gregor et al. [pdf]\nGenerative adversarial nets (2014), I. Goodfellow et al. [pdf]\nAuto-encoding variational Bayes (2013), D. Kingma and M. Welling [pdf]\nBuilding high-level features using large scale unsupervised learning (2013), Q. Le et al. [pdf]\nConvolutional Neural Network Models\nRethinking the inception architecture for computer vision (2016), C. Szegedy et al. [pdf]\nInception-v4, inception-resnet and the impact of residual connections on learning (2016), C. Szegedy et al. [pdf]\nIdentity Mappings in Deep Residual Networks (2016), K. He et al. [pdf]\nDeep residual learning for image recognition (2016), K. He et al. [pdf]\nSpatial transformer network (2015), M. Jaderberg et al., [pdf]\nGoing deeper with convolutions (2015), C. Szegedy et al.  [pdf]\nVery deep convolutional networks for large-scale image recognition (2014), K. Simonyan and A. Zisserman [pdf]\nReturn of the devil in the details: delving deep into convolutional nets (2014), K. Chatfield et al. [pdf]\nOverFeat: Integrated recognition, localization and detection using convolutional networks (2013), P. Sermanet et al. [pdf]\nMaxout networks (2013), I. Goodfellow et al. [pdf]\nNetwork in network (2013), M. Lin et al. [pdf]\nImageNet classification with deep convolutional neural networks (2012), A. Krizhevsky et al. [pdf]\nImage: Segmentation / Object Detection\nYou only look once: Unified, real-time object detection (2016), J. Redmon et al. [pdf]\nFully convolutional networks for semantic segmentation (2015), J. Long et al. [pdf]\nFaster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (2015), S. Ren et al. [pdf]\nFast R-CNN (2015), R. Girshick [pdf]\nRich feature hierarchies for accurate object detection and semantic segmentation (2014), R. Girshick et al. [pdf]\nSpatial pyramid pooling in deep convolutional networks for visual recognition (2014), K. He et al. [pdf]\nSemantic image segmentation with deep convolutional nets and fully connected CRFs, L. Chen et al. [pdf]\nLearning hierarchical features for scene labeling (2013), C. Farabet et al. [pdf]\nImage / Video / Etc\nImage Super-Resolution Using Deep Convolutional Networks (2016), C. Dong et al. [pdf]\nA neural algorithm of artistic style (2015), L. Gatys et al. [pdf]\nDeep visual-semantic alignments for generating image descriptions (2015), A. Karpathy and L. Fei-Fei [pdf]\nShow, attend and tell: Neural image caption generation with visual attention (2015), K. Xu et al. [pdf]\nShow and tell: A neural image caption generator (2015), O. Vinyals et al. [pdf]\nLong-term recurrent convolutional networks for visual recognition and description (2015), J. Donahue et al. [pdf]\nVQA: Visual question answering (2015), S. Antol et al. [pdf]\nDeepFace: Closing the gap to human-level performance in face verification (2014), Y. Taigman et al. [pdf]:\nLarge-scale video classification with convolutional neural networks (2014), A. Karpathy et al. [pdf]\nTwo-stream convolutional networks for action recognition in videos (2014), K. Simonyan et al. [pdf]\n3D convolutional neural networks for human action recognition (2013), S. Ji et al. [pdf]\nNatural Language Processing / RNNs\nNeural Architectures for Named Entity Recognition (2016), G. Lample et al. [pdf]\nExploring the limits of language modeling (2016), R. Jozefowicz et al. [pdf]\nTeaching machines to read and comprehend (2015), K. Hermann et al. [pdf]\nEffective approaches to attention-based neural machine translation (2015), M. Luong et al. [pdf]\nConditional random fields as recurrent neural networks (2015), S. Zheng and S. Jayasumana. [pdf]\nMemory networks (2014), J. Weston et al. [pdf]\nNeural turing machines (2014), A. Graves et al. [pdf]\nNeural machine translation by jointly learning to align and translate (2014), D. Bahdanau et al. [pdf]\nSequence to sequence learning with neural networks (2014), I. Sutskever et al. [pdf]\nLearning phrase representations using RNN encoder-decoder for statistical machine translation (2014), K. Cho et al. [pdf]\nA convolutional neural network for modeling sentences (2014), N. Kalchbrenner et al. [pdf]\nConvolutional neural networks for sentence classification (2014), Y. Kim [pdf]\nGlove: Global vectors for word representation (2014), J. Pennington et al. [pdf]\nDistributed representations of sentences and documents (2014), Q. Le and T. Mikolov [pdf]\nDistributed representations of words and phrases and their compositionality (2013), T. Mikolov et al. [pdf]\nEfficient estimation of word representations in vector space (2013), T. Mikolov et al.  [pdf]\nRecursive deep models for semantic compositionality over a sentiment treebank (2013), R. Socher et al. [pdf]\nGenerating sequences with recurrent neural networks (2013), A. Graves. [pdf]\nSpeech / Other Domain\nEnd-to-end attention-based large vocabulary speech recognition (2016), D. Bahdanau et al. [pdf]\nDeep speech 2: End-to-end speech recognition in English and Mandarin (2015), D. Amodei et al. [pdf]\nSpeech recognition with deep recurrent neural networks (2013), A. Graves [pdf]\nDeep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012), G. Hinton et al. [pdf]\nContext-dependent pre-trained deep neural networks for large-vocabulary speech recognition (2012) G. Dahl et al. [pdf]\nAcoustic modeling using deep belief networks (2012), A. Mohamed et al. [pdf]\nReinforcement Learning / Robotics\nEnd-to-end training of deep visuomotor policies (2016), S. Levine et al. [pdf]\nLearning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection (2016), S. Levine et al. [pdf]\nAsynchronous methods for deep reinforcement learning (2016), V. Mnih et al. [pdf]\nDeep Reinforcement Learning with Double Q-Learning (2016), H. Hasselt et al. [pdf]\nMastering the game of Go with deep neural networks and tree search (2016), D. Silver et al. [pdf]\nContinuous control with deep reinforcement learning (2015), T. Lillicrap et al. [pdf]\nHuman-level control through deep reinforcement learning (2015), V. Mnih et al. [pdf]\nDeep learning for detecting robotic grasps (2015), I. Lenz et al. [pdf]\nPlaying atari with deep reinforcement learning (2013), V. Mnih et al. [pdf])\nMore Papers from 2016\nLayer Normalization (2016), J. Ba et al. [pdf]\nLearning to learn by gradient descent by gradient descent (2016), M. Andrychowicz et al. [pdf]\nDomain-adversarial training of neural networks (2016), Y. Ganin et al. [pdf]\nWaveNet: A Generative Model for Raw Audio (2016), A. Oord et al. [pdf] [web]\nColorful image colorization (2016), R. Zhang et al. [pdf]\nGenerative visual manipulation on the natural image manifold (2016), J. Zhu et al. [pdf]\nTexture networks: Feed-forward synthesis of textures and stylized images (2016), D Ulyanov et al. [pdf]\nSSD: Single shot multibox detector (2016), W. Liu et al. [pdf]\nSqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size (2016), F. Iandola et al. [pdf]\nEie: Efficient inference engine on compressed deep neural network (2016), S. Han et al. [pdf]\nBinarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1 (2016), M. Courbariaux et al. [pdf]\nDynamic memory networks for visual and textual question answering (2016), C. Xiong et al. [pdf]\nStacked attention networks for image question answering (2016), Z. Yang et al. [pdf]\nHybrid computing using a neural network with dynamic external memory (2016), A. Graves et al. [pdf]\nGoogle's neural machine translation system: Bridging the gap between human and machine translation (2016), Y. Wu et al. [pdf]\nNew papers\nNewly published papers (< 6 months) which are worth reading\n- MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (2017), Andrew G. Howard et al. [pdf]\n- Convolutional Sequence to Sequence Learning (2017), Jonas Gehring et al. [pdf]\n- A Knowledge-Grounded Neural Conversation Model (2017), Marjan Ghazvininejad et al. [pdf]\n- Accurate, Large Minibatch SGD:Training ImageNet in 1 Hour (2017), Priya Goyal et al. [pdf]\n- TACOTRON: Towards end-to-end speech synthesis (2017), Y. Wang et al. [pdf]\n- Deep Photo Style Transfer (2017), F. Luan et al. [pdf]\n- Evolution Strategies as a Scalable Alternative to Reinforcement Learning (2017), T. Salimans et al. [pdf]\n- Deformable Convolutional Networks (2017), J. Dai et al. [pdf]\n- Mask R-CNN (2017), K. He et al. [pdf]\n- Learning to discover cross-domain relations with generative adversarial networks (2017), T. Kim et al. [pdf] \n- Deep voice: Real-time neural text-to-speech (2017), S. Arik et al., [pdf]\n- PixelNet: Representation of the pixels, by the pixels, and for the pixels (2017), A. Bansal et al. [pdf]\n- Batch renormalization: Towards reducing minibatch dependence in batch-normalized models (2017), S. Ioffe. [pdf]\n- Wasserstein GAN (2017), M. Arjovsky et al. [pdf]\n- Understanding deep learning requires rethinking generalization (2017), C. Zhang et al. [pdf]\n- Least squares generative adversarial networks (2016), X. Mao et al. [pdf]\nOld Papers\nClassic papers published before 2012\n- An analysis of single-layer networks in unsupervised feature learning (2011), A. Coates et al. [pdf]\n- Deep sparse rectifier neural networks (2011), X. Glorot et al. [pdf]\n- Natural language processing (almost) from scratch (2011), R. Collobert et al. [pdf]\n- Recurrent neural network based language model (2010), T. Mikolov et al. [pdf]\n- Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010), P. Vincent et al. [pdf]\n- Learning mid-level features for recognition (2010), Y. Boureau [pdf]\n- A practical guide to training restricted boltzmann machines (2010), G. Hinton [pdf]\n- Understanding the difficulty of training deep feedforward neural networks (2010), X. Glorot and Y. Bengio [pdf]\n- Why does unsupervised pre-training help deep learning (2010), D. Erhan et al. [pdf]\n- Learning deep architectures for AI (2009), Y. Bengio. [pdf]\n- Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009), H. Lee et al. [pdf]\n- Greedy layer-wise training of deep networks (2007), Y. Bengio et al. [pdf]\n- Reducing the dimensionality of data with neural networks, G. Hinton and R. Salakhutdinov. [pdf]\n- A fast learning algorithm for deep belief nets (2006), G. Hinton et al. [pdf]\n- Gradient-based learning applied to document recognition (1998), Y. LeCun et al. [pdf]\n- Long short-term memory (1997), S. Hochreiter and J. Schmidhuber. [pdf]\nHW / SW / Dataset\nSQuAD: 100,000+ Questions for Machine Comprehension of Text (2016), Rajpurkar et al. [pdf]\nOpenAI gym (2016), G. Brockman et al. [pdf]\nTensorFlow: Large-scale machine learning on heterogeneous distributed systems (2016), M. Abadi et al. [pdf]\nTheano: A Python framework for fast computation of mathematical expressions, R. Al-Rfou et al.\nTorch7: A matlab-like environment for machine learning, R. Collobert et al. [pdf]\nMatConvNet: Convolutional neural networks for matlab (2015), A. Vedaldi and K. Lenc [pdf]\nImagenet large scale visual recognition challenge (2015), O. Russakovsky et al. [pdf]\nCaffe: Convolutional architecture for fast feature embedding (2014), Y. Jia et al. [pdf]\nBook / Survey / Review\nOn the Origin of Deep Learning (2017), H. Wang and Bhiksha Raj. [pdf]\nDeep Reinforcement Learning: An Overview (2017), Y. Li, [pdf]\nNeural Machine Translation and Sequence-to-sequence Models(2017): A Tutorial, G. Neubig. [pdf]\nNeural Network and Deep Learning (Book, Jan 2017), Michael Nielsen. [html]\nDeep learning (Book, 2016), Goodfellow et al. [html]\nLSTM: A search space odyssey (2016), K. Greff et al. [pdf]\nTutorial on Variational Autoencoders (2016), C. Doersch. [pdf]\nDeep learning (2015), Y. LeCun, Y. Bengio and G. Hinton [pdf]\nDeep learning in neural networks: An overview (2015), J. Schmidhuber [pdf]\nRepresentation learning: A review and new perspectives (2013), Y. Bengio et al. [pdf]\nVideo Lectures / Tutorials / Blogs\n(Lectures)\n- CS231n, Convolutional Neural Networks for Visual Recognition, Stanford University [web]\n- CS224d, Deep Learning for Natural Language Processing, Stanford University [web]\n- Oxford Deep NLP 2017, Deep Learning for Natural Language Processing, University of Oxford [web]\n(Tutorials)\n- NIPS 2016 Tutorials, Long Beach [web]\n- ICML 2016 Tutorials, New York City [web]\n- ICLR 2016 Videos, San Juan [web]\n- Deep Learning Summer School 2016, Montreal [web]\n- Bay Area Deep Learning School 2016, Stanford [web]\n(Blogs)\n- OpenAI [web]\n- Distill [web]\n- Andrej Karpathy Blog [web]\n- Colah's Blog [Web]\n- WildML [Web]\n- FastML [web]\n- TheMorningPaper [web]\nAppendix: More than Top 100\n(2016)\n- A character-level decoder without explicit segmentation for neural machine translation (2016), J. Chung et al. [pdf]\n- Dermatologist-level classification of skin cancer with deep neural networks (2017), A. Esteva et al. [html]\n- Weakly supervised object localization with multi-fold multiple instance learning (2017), R. Gokberk et al. [pdf]\n- Brain tumor segmentation with deep neural networks (2017), M. Havaei et al. [pdf]\n- Professor Forcing: A New Algorithm for Training Recurrent Networks (2016), A. Lamb et al. [pdf]\n- Adversarially learned inference (2016), V. Dumoulin et al. [web][pdf]\n- Understanding convolutional neural networks (2016), J. Koushik [pdf]\n- Taking the human out of the loop: A review of bayesian optimization (2016), B. Shahriari et al. [pdf]\n- Adaptive computation time for recurrent neural networks (2016), A. Graves [pdf]\n- Densely connected convolutional networks (2016), G. Huang et al. [pdf]\n- Region-based convolutional networks for accurate object detection and segmentation (2016), R. Girshick et al. \n- Continuous deep q-learning with model-based acceleration (2016), S. Gu et al. [pdf]\n- A thorough examination of the cnn/daily mail reading comprehension task (2016), D. Chen et al. [pdf]\n- Achieving open vocabulary neural machine translation with hybrid word-character models, M. Luong and C. Manning. [pdf]\n- Very Deep Convolutional Networks for Natural Language Processing (2016), A. Conneau et al. [pdf]\n- Bag of tricks for efficient text classification (2016), A. Joulin et al. [pdf]\n- Efficient piecewise training of deep structured models for semantic segmentation (2016), G. Lin et al. [pdf]\n- Learning to compose neural networks for question answering (2016), J. Andreas et al. [pdf]\n- Perceptual losses for real-time style transfer and super-resolution (2016), J. Johnson et al. [pdf]\n- Reading text in the wild with convolutional neural networks (2016), M. Jaderberg et al. [pdf]\n- What makes for effective detection proposals? (2016), J. Hosang et al. [pdf]\n- Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks (2016), S. Bell et al. [pdf].\n- Instance-aware semantic segmentation via multi-task network cascades (2016), J. Dai et al. [pdf]\n- Conditional image generation with pixelcnn decoders (2016), A. van den Oord et al. [pdf]\n- Deep networks with stochastic depth (2016), G. Huang et al., [pdf]\n- Consistency and Fluctuations For Stochastic Gradient Langevin Dynamics (2016), Yee Whye Teh et al. [pdf]\n(2015)\n- Ask your neurons: A neural-based approach to answering questions about images (2015), M. Malinowski et al. [pdf]\n- Exploring models and data for image question answering (2015), M. Ren et al. [pdf]\n- Are you talking to a machine? dataset and methods for multilingual image question (2015), H. Gao et al. [pdf]\n- Mind's eye: A recurrent visual representation for image caption generation (2015), X. Chen and C. Zitnick. [pdf]\n- From captions to visual concepts and back (2015), H. Fang et al. [pdf].\n- Towards AI-complete question answering: A set of prerequisite toy tasks (2015), J. Weston et al. [pdf]\n- Ask me anything: Dynamic memory networks for natural language processing (2015), A. Kumar et al. [pdf]\n- Unsupervised learning of video representations using LSTMs (2015), N. Srivastava et al. [pdf]\n- Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2015), S. Han et al. [pdf]\n- Improved semantic representations from tree-structured long short-term memory networks (2015), K. Tai et al. [pdf]\n- Character-aware neural language models (2015), Y. Kim et al. [pdf]\n- Grammar as a foreign language (2015), O. Vinyals et al. [pdf]\n- Trust Region Policy Optimization (2015), J. Schulman et al. [pdf]\n- Beyond short snippents: Deep networks for video classification (2015) [pdf]\n- Learning Deconvolution Network for Semantic Segmentation (2015), H. Noh et al. [pdf]\n- Learning spatiotemporal features with 3d convolutional networks (2015), D. Tran et al. [pdf]\n- Understanding neural networks through deep visualization (2015), J. Yosinski et al. [pdf]\n- An Empirical Exploration of Recurrent Network Architectures (2015), R. Jozefowicz et al.  [pdf]\n- Deep generative image models using a\ufffc laplacian pyramid of adversarial networks (2015), E.Denton et al. [pdf]\n- Gated Feedback Recurrent Neural Networks (2015), J. Chung et al. [pdf]\n- Fast and accurate deep network learning by exponential linear units (ELUS) (2015), D. Clevert et al. [pdf]\n- Pointer networks (2015), O. Vinyals et al. [pdf]\n- Visualizing and Understanding Recurrent Networks (2015), A. Karpathy et al. [pdf]\n- Attention-based models for speech recognition (2015), J. Chorowski et al. [pdf]\n- End-to-end memory networks (2015), S. Sukbaatar et al. [pdf]\n- Describing videos by exploiting temporal structure (2015), L. Yao et al. [pdf]\n- A neural conversational model (2015), O. Vinyals and Q. Le. [pdf]\n- Improving distributional similarity with lessons learned from word embeddings, O. Levy et al. [[pdf]] (https://www.transacl.org/ojs/index.php/tacl/article/download/570/124)\n- Transition-Based Dependency Parsing with Stack Long Short-Term Memory (2015), C. Dyer et al. [pdf]\n- Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs (2015), M. Ballesteros et al. [pdf]\n- Finding function in form: Compositional character models for open vocabulary word representation (2015), W. Ling et al. [pdf]\n(~2014)\n- DeepPose: Human pose estimation via deep neural networks (2014), A. Toshev and C. Szegedy [pdf]\n- Learning a Deep Convolutional Network for Image Super-Resolution (2014, C. Dong et al. [pdf]\n- Recurrent models of visual attention (2014), V. Mnih et al. [pdf]\n- Empirical evaluation of gated recurrent neural networks on sequence modeling (2014), J. Chung et al. [pdf]\n- Addressing the rare word problem in neural machine translation (2014), M. Luong et al. [pdf]\n- On the properties of neural machine translation: Encoder-decoder approaches (2014), K. Cho et. al.\n- Recurrent neural network regularization (2014), W. Zaremba et al. [pdf]\n- Intriguing properties of neural networks (2014), C. Szegedy et al. [pdf]\n- Towards end-to-end speech recognition with recurrent neural networks (2014), A. Graves and N. Jaitly. [pdf]\n- Scalable object detection using deep neural networks (2014), D. Erhan et al. [pdf]\n- On the importance of initialization and momentum in deep learning (2013), I. Sutskever et al. [pdf]\n- Regularization of neural networks using dropconnect (2013), L. Wan et al. [pdf]\n- Learning Hierarchical Features for Scene Labeling (2013), C. Farabet et al. [pdf]\n- Linguistic Regularities in Continuous Space Word Representations (2013), T. Mikolov et al. [pdf]\n- Large scale distributed deep networks (2012), J. Dean et al. [pdf]\n- A Fast and Accurate Dependency Parser using Neural Networks. Chen and Manning. [pdf]\nAcknowledgement\nThank you for all your contributions. Please make sure to read the contributing guide before you make a pull request.\nLicense\nTo the extent possible under law, Terry T. Um has waived all copyright and related or neighboring rights to this work.",
	"computer-vision deep-learning deep-learning-tutorial deep-neural-networks dnn neural-network object-detection scaled-yolov4 scaledyolov4 yolo yolov3 yolov4": "Yolo v4, v3 and v2 for Windows and Linux\n(neural networks for object detection)\nPaper YOLOv7: https://arxiv.org/abs/2207.02696\nsource code YOLOv7 - Pytorch (use to reproduce results): https://github.com/WongKinYiu/yolov7\nPaper YOLOv4: https://arxiv.org/abs/2004.10934\nsource code YOLOv4 - Darknet (use to reproduce results): https://github.com/AlexeyAB/darknet\nPaper Scaled-YOLOv4 (CVPR 2021): https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Scaled-YOLOv4_Scaling_Cross_Stage_Partial_Network_CVPR_2021_paper.html\nsource code Scaled-YOLOv4 - Pytorch (use to reproduce results): https://github.com/WongKinYiu/ScaledYOLOv4\nYOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors\nPaper: https://arxiv.org/abs/2207.02696\nsource code - Pytorch (use to reproduce results): https://github.com/WongKinYiu/yolov7\nYOLOv7 is more accurate and faster than YOLOv5 by 120% FPS, than YOLOX by 180% FPS, than Dual-Swin-T by 1200% FPS, than ConvNext by 550% FPS, than SWIN-L by 500% FPS, than PPYOLOE-X by 150% FPS.\nYOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56.8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100, batch=1. \nYOLOv7-e6 (55.9% AP, 56 FPS V100 b=1) by +500% FPS faster than SWIN-L C-M-RCNN (53.9% AP, 9.2 FPS A100 b=1)\nYOLOv7-e6 (55.9% AP, 56 FPS V100 b=1) by +550% FPS faster than ConvNeXt-XL C-M-RCNN (55.2% AP, 8.6 FPS A100 b=1)\nYOLOv7-w6 (54.6% AP, 84 FPS V100 b=1) by +120% FPS faster than YOLOv5-X6-r6.1 (55.0% AP, 38 FPS V100 b=1)\nYOLOv7-w6 (54.6% AP, 84 FPS V100 b=1) by +1200% FPS faster than Dual-Swin-T C-M-RCNN (53.6% AP, 6.5 FPS V100 b=1)\nYOLOv7x (52.9% AP, 114 FPS V100 b=1) by +150% FPS faster than PPYOLOE-X (51.9% AP, 45 FPS V100 b=1)\nYOLOv7 (51.2% AP, 161 FPS V100 b=1) by +180% FPS faster than YOLOX-X (51.1% AP, 58 FPS V100 b=1)\nMore details in articles on medium:\nScaled_YOLOv4\nYOLOv4\nManual: https://github.com/AlexeyAB/darknet/wiki\nDiscussion:\nReddit\nGoogle-groups\nDiscord\nAbout Darknet framework: http://pjreddie.com/darknet/\nYOLOv4 model zoo\nRequirements (and how to install dependencies)\nPre-trained models\nFAQ - frequently asked questions\nExplanations in issues\nYolo v4 in other frameworks (TensorRT, TensorFlow, PyTorch, OpenVINO, OpenCV-dnn, TVM,...)\nDatasets\nYolo v4, v3 and v2 for Windows and Linux\n(neural networks for object detection)\nGeForce RTX 2080 Ti\nYoutube video of results\nHow to evaluate AP of YOLOv4 on the MS COCO evaluation server\nHow to evaluate FPS of YOLOv4 on GPU\nPre-trained models\nRequirements for Windows, Linux and macOS\nYolo v4 in other frameworks\nDatasets\nImprovements in this repository\nHow to use on the command line\nFor using network video-camera mjpeg-stream with any Android smartphone\nHow to compile on Linux/macOS (using CMake)\nUsing also PowerShell\nHow to compile on Linux (using make)\nHow to compile on Windows (using CMake)\nHow to compile on Windows (using vcpkg)\nHow to train with multi-GPU\nHow to train (to detect your custom objects)\nHow to train tiny-yolo (to detect your custom objects)\nWhen should I stop training\nCustom object detection\nHow to improve object detection\nHow to mark bounded boxes of objects and create annotation files\nHow to use Yolo as DLL and SO libraries\nCitation\nAP50:95 - FPS (Tesla V100) Paper: https://arxiv.org/abs/2011.08036\nAP50:95 / AP50 - FPS (Tesla V100) Paper: https://arxiv.org/abs/2004.10934\ntkDNN-TensorRT accelerates YOLOv4 ~2x times for batch=1 and 3x-4x times for batch=4.\ntkDNN: https://github.com/ceccocats/tkDNN\nOpenCV: https://gist.github.com/YashasSamaga/48bdb167303e10f4d07b754888ddbdcf\nGeForce RTX 2080 Ti\n| Network Size               | Darknet, FPS (avg) | tkDNN TensorRT FP32, FPS | tkDNN TensorRT FP16, FPS | OpenCV FP16, FPS | tkDNN TensorRT FP16 batch=4, FPS | OpenCV FP16 batch=4, FPS | tkDNN Speedup |\n|:--------------------------:|:------------------:|-------------------------:|-------------------------:|-----------------:|---------------------------------:|-------------------------:|--------------:|\n|320                         | 100                | 116                      | 202                  | 183              | 423                              | 430                  | 4.3x      |\n|416                         | 82                 | 103                      | 162                  | 159              | 284                              | 294                  | 3.6x      |\n|512                         | 69                 | 91                       | 134                      | 138          | 206                              | 216                  | 3.1x      |\n|608                         | 53                 | 62                       | 103                      | 115          | 150                              | 150                  | 2.8x      |\n|Tiny 416                    | 443                | 609                      | 790                  | 773              | 1774                         | 1353                     | 3.5x      |\n|Tiny 416 CPU Core i7 7700HQ | 3.4                | -                        | -                        | 42               | -                                | 39                       | 12x       |\nYolo v4 Full comparison: map_fps\nYolo v4 tiny comparison: tiny_fps\nCSPNet: paper and map_fps comparison: https://github.com/WongKinYiu/CrossStagePartialNetworks\nYolo v3 on MS COCO: Speed / Accuracy (mAP@0.5) chart\nYolo v3 on MS COCO (Yolo v3 vs RetinaNet) - Figure 3: https://arxiv.org/pdf/1804.02767v1.pdf\nYolo v2 on Pascal VOC 2007: https://hsto.org/files/a24/21e/068/a2421e0689fb43f08584de9d44c2215f.jpg\nYolo v2 on Pascal VOC 2012 (comp4): https://hsto.org/files/3a6/fdf/b53/3a6fdfb533f34cee9b52bdd9bb0b19d9.jpg\nYoutube video of results\n|  |   |\n|---|---|\nOthers: https://www.youtube.com/user/pjreddie/videos\nHow to evaluate AP of YOLOv4 on the MS COCO evaluation server\nDownload and unzip test-dev2017 dataset from MS COCO server: http://images.cocodataset.org/zips/test2017.zip\nDownload list of images for Detection tasks and replace the paths with yours: https://raw.githubusercontent.com/AlexeyAB/darknet/master/scripts/testdev2017.txt\nDownload yolov4.weights file 245 MB: yolov4.weights (Google-drive mirror yolov4.weights )\nContent of the file cfg/coco.data should be\nini\nclasses= 80\ntrain  = /trainvalno5k.txt\nvalid = /testdev2017.txt\nnames = data/coco.names\nbackup = backup\neval=coco\nCreate /results/ folder near with ./darknet executable file\nRun validation: ./darknet detector valid cfg/coco.data cfg/yolov4.cfg yolov4.weights\nRename the file  /results/coco_results.json to detections_test-dev2017_yolov4_results.json and compress it to detections_test-dev2017_yolov4_results.zip\nSubmit file detections_test-dev2017_yolov4_results.zip to the MS COCO evaluation server for the test-dev2019 (bbox)\nHow to evaluate FPS of YOLOv4 on GPU\nCompile Darknet with GPU=1 CUDNN=1 CUDNN_HALF=1 OPENCV=1 in the Makefile\nDownload yolov4.weights file 245 MB: yolov4.weights (Google-drive mirror yolov4.weights )\nGet any .avi/.mp4 video file (preferably not more than 1920x1080 to avoid bottlenecks in CPU performance)\nRun one of two commands and look at the AVG FPS:\ninclude video_capturing + NMS + drawing_bboxes:\n    ./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights test.mp4 -dont_show -ext_output\nexclude video_capturing + NMS + drawing_bboxes:\n    ./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights test.mp4 -benchmark\nPre-trained models\nThere are weights-file for different cfg-files (trained for MS COCO dataset):\nFPS on RTX 2070 (R) and Tesla V100 (V):\nyolov4-p6.cfg - 1280x1280 - 72.1% mAP@0.5 (54.0% AP@0.5:0.95) - 32(V) FPS - xxx BFlops (xxx FMA) - 487 MB: yolov4-p6.weights\npre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-p6.conv.289\nyolov4-p5.cfg - 896x896 - 70.0% mAP@0.5 (51.6% AP@0.5:0.95) - 43(V) FPS - xxx BFlops (xxx FMA) - 271 MB: yolov4-p5.weights\npre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-p5.conv.232\nyolov4-csp-x-swish.cfg - 640x640 - 69.9% mAP@0.5 (51.5% AP@0.5:0.95) - 23(R) FPS / 50(V) FPS - 221 BFlops (110 FMA) - 381 MB: yolov4-csp-x-swish.weights\npre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-csp-x-swish.conv.192\nyolov4-csp-swish.cfg - 640x640 - 68.7% mAP@0.5 (50.0% AP@0.5:0.95) - 70(V) FPS - 120 (60 FMA) - 202 MB: yolov4-csp-swish.weights\npre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-csp-swish.conv.164\nyolov4x-mish.cfg - 640x640 - 68.5% mAP@0.5 (50.1% AP@0.5:0.95) - 23(R) FPS / 50(V) FPS - 221 BFlops (110 FMA) - 381 MB: yolov4x-mish.weights\npre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4x-mish.conv.166\nyolov4-csp.cfg - 202 MB: yolov4-csp.weights paper Scaled Yolo v4\njust change width= and height= parameters in yolov4-csp.cfg file and use the same yolov4-csp.weights file for all cases:\n  - width=640 height=640 in cfg: 67.4% mAP@0.5 (48.7% AP@0.5:0.95) - 70(V) FPS - 120 (60 FMA) BFlops\n  - width=512 height=512 in cfg: 64.8% mAP@0.5 (46.2% AP@0.5:0.95) - 93(V) FPS - 77 (39 FMA) BFlops\n  - pre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-csp.conv.142\nyolov4.cfg - 245 MB: yolov4.weights (Google-drive mirror yolov4.weights ) paper Yolo v4\n    just change width= and height= parameters in yolov4.cfg file and use the same yolov4.weights file for all cases:\nwidth=608 height=608 in cfg: 65.7% mAP@0.5 (43.5% AP@0.5:0.95) - 34(R) FPS / 62(V) FPS - 128.5 BFlops\nwidth=512 height=512 in cfg: 64.9% mAP@0.5 (43.0% AP@0.5:0.95) - 45(R) FPS / 83(V) FPS - 91.1 BFlops\nwidth=416 height=416 in cfg: 62.8% mAP@0.5 (41.2% AP@0.5:0.95) - 55(R) FPS / 96(V) FPS - 60.1 BFlops\nwidth=320 height=320 in cfg:   60% mAP@0.5 (  38% AP@0.5:0.95) - 63(R) FPS / 123(V) FPS - 35.5 BFlops\nyolov4-tiny.cfg - 40.2% mAP@0.5 - 371(1080Ti) FPS / 330(RTX2070) FPS - 6.9 BFlops - 23.1 MB: yolov4-tiny.weights\nenet-coco.cfg (EfficientNetB0-Yolov3) - 45.5% mAP@0.5 - 55(R) FPS - 3.7 BFlops - 18.3 MB: enetb0-coco_final.weights\nyolov3-openimages.cfg - 247 MB - 18(R) FPS - OpenImages dataset: yolov3-openimages.weights\nCLICK ME - Yolo v3 models\n\n\ncsresnext50-panet-spp-original-optimal.cfg - 65.4% mAP@0.5 (43.2% AP@0.5:0.95) - 32(R) FPS - 100.5 BFlops - 217 MB: csresnext50-panet-spp-original-optimal_final.weights\n\n\nyolov3-spp.cfg - 60.6% mAP@0.5 - 38(R) FPS - 141.5 BFlops - 240 MB: yolov3-spp.weights\n\n\ncsresnext50-panet-spp.cfg - 60.0% mAP@0.5 - 44 FPS - 71.3 BFlops - 217 MB: csresnext50-panet-spp_final.weights\n\n\nyolov3.cfg - 55.3% mAP@0.5 - 66(R) FPS - 65.9 BFlops - 236 MB: yolov3.weights\n\n\nyolov3-tiny.cfg - 33.1% mAP@0.5 - 345(R) FPS - 5.6 BFlops - 33.7 MB: yolov3-tiny.weights\n\n\nyolov3-tiny-prn.cfg - 33.1% mAP@0.5 - 370(R) FPS - 3.5 BFlops - 18.8 MB: yolov3-tiny-prn.weights\n\n\nCLICK ME - Yolo v2 models\n\nyolov2.cfg (194 MB COCO Yolo v2) - requires 4 GB GPU-RAM: https://pjreddie.com/media/files/yolov2.weights\nyolo-voc.cfg (194 MB VOC Yolo v2) - requires 4 GB GPU-RAM: http://pjreddie.com/media/files/yolo-voc.weights\nyolov2-tiny.cfg (43 MB COCO Yolo v2) - requires 1 GB GPU-RAM: https://pjreddie.com/media/files/yolov2-tiny.weights\nyolov2-tiny-voc.cfg (60 MB VOC Yolo v2) - requires 1 GB GPU-RAM: http://pjreddie.com/media/files/yolov2-tiny-voc.weights\nyolo9000.cfg (186 MB Yolo9000-model) - requires 4 GB GPU-RAM: http://pjreddie.com/media/files/yolo9000.weights\n\nPut it near compiled: darknet.exe\nYou can get cfg-files by path: darknet/cfg/\nRequirements for Windows, Linux and macOS\nCMake >= 3.18: https://cmake.org/download/\nPowershell (already installed on windows): https://docs.microsoft.com/en-us/powershell/scripting/install/installing-powershell\nCUDA >= 10.2: https://developer.nvidia.com/cuda-toolkit-archive (on Linux do Post-installation Actions)\nOpenCV >= 2.4: use your preferred package manager (brew, apt), build from source using vcpkg or download from OpenCV official site (on Windows set system variable OpenCV_DIR = C:\\opencv\\build - where are the include and x64 folders image)\ncuDNN >= 8.0.2 https://developer.nvidia.com/rdp/cudnn-archive (on Linux follow steps described here https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installlinux-tar , on Windows follow steps described here https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installwindows)\nGPU with CC >= 3.0: https://en.wikipedia.org/wiki/CUDA#GPUs_supported\nYolo v4 in other frameworks\nPytorch - Scaled-YOLOv4: https://github.com/WongKinYiu/ScaledYOLOv4\nTensorFlow: pip install yolov4 YOLOv4 on TensorFlow 2.0 / TFlite / Android: https://github.com/hunglc007/tensorflow-yolov4-tflite\n    Official TF models: https://github.com/tensorflow/models/tree/master/official/vision/beta/projects/yolo\n    For YOLOv4 - convert yolov4.weights/cfg files to yolov4.pb by using TNTWEN project, and to yolov4.tflite TensorFlow-lite\nOpenCV the fastest implementation of YOLOv4 for CPU (x86/ARM-Android), OpenCV can be compiled with OpenVINO-backend for running on (Myriad X / USB Neural Compute Stick / Arria FPGA), use yolov4.weights/cfg with: C++ example or Python example\nIntel OpenVINO 2021.2: supports YOLOv4 (NPU Myriad X / USB Neural Compute Stick / Arria FPGA): https://devmesh.intel.com/projects/openvino-yolov4-49c756 read this manual (old manual ) (for Scaled-YOLOv4 models use https://github.com/Chen-MingChang/pytorch_YOLO_OpenVINO_demo )\nPyTorch > ONNX:\nWongKinYiu/PyTorch_YOLOv4\nmaudzung/3D-YOLOv4\nTianxiaomo/pytorch-YOLOv4\nYOLOv5\nONNX on Jetson for YOLOv4: https://developer.nvidia.com/blog/announcing-onnx-runtime-for-jetson/ and https://github.com/ttanzhiqiang/onnx_tensorrt_project\nnVidia Transfer Learning Toolkit (TLT>=3.0) Training and Detection https://docs.nvidia.com/metropolis/TLT/tlt-user-guide/text/object_detection/yolo_v4.html\nTensorRT+tkDNN: https://github.com/ceccocats/tkDNN#fps-results\nDeepstream 5.0 / TensorRT for YOLOv4 https://github.com/NVIDIA-AI-IOT/yolov4_deepstream or https://github.com/marcoslucianops/DeepStream-Yolo read Yolo is natively supported in DeepStream 4.0 and PDF. Additionally jkjung-avt/tensorrt_demos or wang-xinyu/tensorrtx\nTriton Inference Server / TensorRT https://github.com/isarsoft/yolov4-triton-tensorrt\nDirectML https://github.com/microsoft/DirectML/tree/master/Samples/yolov4\nOpenCL (Intel, AMD, Mali GPUs for macOS & GNU/Linux) https://github.com/sowson/darknet\nHIP for Training and Detection on AMD GPU https://github.com/os-hackathon/darknet\nROS (Robot Operating System) https://github.com/engcang/ros-yolo-sort\nXilinx Zynq Ultrascale+ Deep Learning Processor (DPU) ZCU102/ZCU104: https://github.com/Xilinx/Vitis-In-Depth-Tutorial/tree/master/Machine_Learning/Design_Tutorials/07-yolov4-tutorial\nAmazon Neurochip / Amazon EC2 Inf1 instances 1.85 times higher throughput and 37% lower cost per image for TensorFlow based YOLOv4 model, using Keras URL\nTVM - compilation of deep learning models (Keras, MXNet, PyTorch, Tensorflow, CoreML, DarkNet) into minimum deployable modules on diverse hardware backend (CPUs, GPUs, FPGA, and specialized accelerators): https://tvm.ai/about\nTencent/ncnn: the fastest inference of YOLOv4 on mobile phone CPU: https://github.com/Tencent/ncnn\nOpenDataCam - It detects, tracks and counts moving objects by using YOLOv4: https://github.com/opendatacam/opendatacam#-hardware-pre-requisite\nNetron - Visualizer for neural networks: https://github.com/lutzroeder/netron\nDatasets\nMS COCO: use ./scripts/get_coco_dataset.sh to get labeled MS COCO detection dataset\nOpenImages: use python ./scripts/get_openimages_dataset.py for labeling train detection dataset\nPascal VOC: use python ./scripts/voc_label.py for labeling Train/Test/Val detection datasets\nILSVRC2012 (ImageNet classification): use ./scripts/get_imagenet_train.sh (also imagenet_label.sh for labeling valid set)\nGerman/Belgium/Russian/LISA/MASTIF Traffic Sign Datasets for Detection - use this parsers: https://github.com/angeligareta/Datasets2Darknet#detection-task\nList of other datasets: https://github.com/AlexeyAB/darknet/tree/master/scripts#datasets\nImprovements in this repository\ndeveloped State-of-the-Art object detector YOLOv4\nadded State-of-Art models: CSP, PRN, EfficientNet\nadded layers: [conv_lstm], [scale_channels] SE/ASFF/BiFPN, [local_avgpool], [sam], [Gaussian_yolo], [reorg3d] (fixed [reorg]), fixed [batchnorm]\nadded the ability for training recurrent models (with layers conv-lstm[conv_lstm]/conv-rnn[crnn]) for accurate detection on video\nadded data augmentation: [net] mixup=1 cutmix=1 mosaic=1 blur=1. Added activations: SWISH, MISH, NORM_CHAN, NORM_CHAN_SOFTMAX\nadded the ability for training with GPU-processing using CPU-RAM to increase the mini_batch_size and increase accuracy (instead of batch-norm sync)\nimproved binary neural network performance 2x-4x times for Detection on CPU and GPU if you trained your own weights by using this XNOR-net model (bit-1 inference) : https://github.com/AlexeyAB/darknet/blob/master/cfg/yolov3-tiny_xnor.cfg\nimproved neural network performance ~7% by fusing 2 layers into 1: Convolutional + Batch-norm\nimproved performance: Detection 2x times, on GPU Volta/Turing (Tesla V100, GeForce RTX, ...) using Tensor Cores if CUDNN_HALF defined in the Makefile or darknet.sln\nimproved performance ~1.2x times on FullHD, ~2x times on 4K, for detection on the video (file/stream) using darknet detector demo...\nimproved performance 3.5 X times of data augmentation for training (using OpenCV SSE/AVX functions instead of hand-written functions) - removes bottleneck for training on multi-GPU or GPU Volta\nimproved performance of detection and training on Intel CPU with AVX (Yolo v3 ~85%)\noptimized memory allocation during network resizing when random=1\noptimized GPU initialization for detection - we use batch=1 initially instead of re-init with batch=1\nadded correct calculation of mAP, F1, IoU, Precision-Recall using command darknet detector map...\nadded drawing of chart of average-Loss and accuracy-mAP (-map flag) during training\nrun ./darknet detector demo ... -json_port 8070 -mjpeg_port 8090 as JSON and MJPEG server to get results online over the network by using your soft or Web-browser\nadded calculation of anchors for training\nadded example of Detection and Tracking objects: https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp\nrun-time tips and warnings if you use incorrect cfg-file or dataset\nadded support for Windows\nmany other fixes of code...\nAnd added manual - How to train Yolo v4-v2 (to detect your custom objects)\nAlso, you might be interested in using a simplified repository where is implemented INT8-quantization (+30% speedup and -1% mAP reduced): https://github.com/AlexeyAB/yolo2_light\nHow to use on the command line\nIf you use build.ps1 script or the makefile (Linux only) you will find darknet in the root directory.\nIf you use the deprecated Visual Studio solutions, you will find darknet in the directory \\build\\darknet\\x64.\nIf you customize build with CMake GUI, darknet executable will be installed in your preferred folder.\nYolo v4 COCO - image: ./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights -thresh 0.25\nOutput coordinates of objects: ./darknet detector test cfg/coco.data yolov4.cfg yolov4.weights -ext_output dog.jpg\nYolo v4 COCO - video: ./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights -ext_output test.mp4\nYolo v4 COCO - WebCam 0: ./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights -c 0\nYolo v4 COCO for net-videocam - Smart WebCam: ./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights http://192.168.0.80:8080/video?dummy=param.mjpg\nYolo v4 - save result videofile res.avi: ./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights test.mp4 -out_filename res.avi\nYolo v3 Tiny COCO - video: ./darknet detector demo cfg/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights test.mp4\nJSON and MJPEG server that allows multiple connections from your soft or Web-browser ip-address:8070 and 8090: ./darknet detector demo ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights test50.mp4 -json_port 8070 -mjpeg_port 8090 -ext_output\nYolo v3 Tiny on GPU #1: ./darknet detector demo cfg/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights -i 1 test.mp4\nAlternative method Yolo v3 COCO - image: ./darknet detect cfg/yolov4.cfg yolov4.weights -i 0 -thresh 0.25\nTrain on Amazon EC2, to see mAP & Loss-chart using URL like: http://ec2-35-160-228-91.us-west-2.compute.amazonaws.com:8090 in the Chrome/Firefox (Darknet should be compiled with OpenCV):\n    ./darknet detector train cfg/coco.data yolov4.cfg yolov4.conv.137 -dont_show -mjpeg_port 8090 -map\n186 MB Yolo9000 - image: ./darknet detector test cfg/combine9k.data cfg/yolo9000.cfg yolo9000.weights\nRemember to put data/9k.tree and data/coco9k.map under the same folder of your app if you use the cpp api to build an app\nTo process a list of images data/train.txt and save results of detection to result.json file use:\n    ./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights -ext_output -dont_show -out result.json < data/train.txt\nTo process a list of images data/train.txt and save results of detection to result.txt use:\n    ./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights -dont_show -ext_output < data/train.txt > result.txt\nPseudo-labelling - to process a list of images data/new_train.txt and save results of detection in Yolo training format for each image as label .txt (in this way you can increase the amount of training data) use:\n    ./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights -thresh 0.25 -dont_show -save_labels < data/new_train.txt\nTo calculate anchors: ./darknet detector calc_anchors data/obj.data -num_of_clusters 9 -width 416 -height 416\nTo check accuracy mAP@IoU=50: ./darknet detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_7000.weights\nTo check accuracy mAP@IoU=75: ./darknet detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_7000.weights -iou_thresh 0.75\nFor using network video-camera mjpeg-stream with any Android smartphone\nDownload for Android phone mjpeg-stream soft: IP Webcam / Smart WebCam\nSmart WebCam - preferably: https://play.google.com/store/apps/details?id=com.acontech.android.SmartWebCam2\nIP Webcam: https://play.google.com/store/apps/details?id=com.pas.webcam\nConnect your Android phone to computer by WiFi (through a WiFi-router) or USB\nStart Smart WebCam on your phone\nReplace the address below, on shown in the phone application (Smart WebCam) and launch:\nYolo v4 COCO-model: ./darknet detector demo data/coco.data yolov4.cfg yolov4.weights http://192.168.0.80:8080/video?dummy=param.mjpg -i 0\nHow to compile on Linux/macOS (using CMake)\nThe CMakeLists.txt will attempt to find installed optional dependencies like CUDA, cudnn, ZED and build against those. It will also create a shared object library file to use darknet for code development.\nTo update CMake on Ubuntu, it's better to follow guide here: https://apt.kitware.com/ or https://cmake.org/download/\nbash\ngit clone https://github.com/AlexeyAB/darknet\ncd darknet\nmkdir build_release\ncd build_release\ncmake ..\ncmake --build . --target install --parallel 8\nUsing also PowerShell\nInstall: Cmake, CUDA, cuDNN How to install dependencies\nInstall powershell for your OS (Linux or MacOS) (guide here).\nOpen PowerShell type these commands\nPowerShell\ngit clone https://github.com/AlexeyAB/darknet\ncd darknet\n./build.ps1 -UseVCPKG -EnableOPENCV -EnableCUDA -EnableCUDNN\nremove options like -EnableCUDA or -EnableCUDNN if you are not interested into\nremove option -UseVCPKG if you plan to manually provide OpenCV library to darknet or if you do not want to enable OpenCV integration\nadd option -EnableOPENCV_CUDA if you want to build OpenCV with CUDA support - very slow to build! (requires -UseVCPKG)\nIf you open the build.ps1 script at the beginning you will find all available switches.\nHow to compile on Linux (using make)\nJust do make in the darknet directory. (You can try to compile and run it on Google Colab in cloud link (press \u00abOpen in Playground\u00bb button at the top-left corner) and watch the video link )\nBefore make, you can set such options in the Makefile: link\nGPU=1 to build with CUDA to accelerate by using GPU (CUDA should be in /usr/local/cuda)\nCUDNN=1 to build with cuDNN v5-v7 to accelerate training by using GPU (cuDNN should be in /usr/local/cudnn)\nCUDNN_HALF=1 to build for Tensor Cores (on Titan V / Tesla V100 / DGX-2 and later) speedup Detection 3x, Training 2x\nOPENCV=1 to build with OpenCV 4.x/3.x/2.4.x - allows to detect on video files and video streams from network cameras or web-cams\nDEBUG=1 to build debug version of Yolo\nOPENMP=1 to build with OpenMP support to accelerate Yolo by using multi-core CPU\nLIBSO=1 to build a library darknet.so and binary runnable file uselib that uses this library. Or you can try to run so LD_LIBRARY_PATH=./:$LD_LIBRARY_PATH ./uselib test.mp4 How to use this SO-library from your own code - you can look at C++ example: https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp\n    or use in such a way: LD_LIBRARY_PATH=./:$LD_LIBRARY_PATH ./uselib data/coco.names cfg/yolov4.cfg yolov4.weights test.mp4\nZED_CAMERA=1 to build a library with ZED-3D-camera support (should be ZED SDK installed), then run\n    LD_LIBRARY_PATH=./:$LD_LIBRARY_PATH ./uselib data/coco.names cfg/yolov4.cfg yolov4.weights zed_camera\nYou also need to specify for which graphics card the code is generated. This is done by setting ARCH=. If you use a never version than CUDA 11 you further need to edit line 20 from Makefile and remove -gencode arch=compute_30,code=sm_30 \\ as Kepler GPU support was dropped in CUDA 11. You can also drop the general ARCH= and just uncomment ARCH= for your graphics card.\nHow to compile on Windows (using CMake)\nRequires:\nMSVC: https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community\nCMake GUI: Windows win64-x64 Installerhttps://cmake.org/download/\nDownload Darknet zip-archive with the latest commit and uncompress it: master.zip\nIn Windows:\nStart (button) -> All programs -> CMake -> CMake (gui) ->\nlook at image In CMake: Enter input path to the darknet Source, and output path to the Binaries -> Configure (button) -> Optional platform for generator: x64  -> Finish -> Generate -> Open Project ->\nin MS Visual Studio: Select: x64 and Release -> Build -> Build solution\nfind the executable file darknet.exe in the output path to the binaries you specified\nHow to compile on Windows (using vcpkg)\nThis is the recommended approach to build Darknet on Windows.\nInstall Visual Studio 2017 or 2019. In case you need to download it, please go here: Visual Studio Community. Remember to install English language pack, this is mandatory for vcpkg!\nInstall CUDA enabling VS Integration during installation.\nOpen Powershell (Start -> All programs -> Windows Powershell) and type these commands:\nPowerShell\nSet-ExecutionPolicy unrestricted -Scope CurrentUser -Force\ngit clone https://github.com/AlexeyAB/darknet\ncd darknet\n.\\build.ps1 -UseVCPKG -EnableOPENCV -EnableCUDA -EnableCUDNN\n(add option -EnableOPENCV_CUDA if you want to build OpenCV with CUDA support - very slow to build! - or remove options like -EnableCUDA or -EnableCUDNN if you are not interested in them). If you open the build.ps1 script at the beginning you will find all available switches.\nHow to train with multi-GPU\nTrain it first on 1 GPU for like 1000 iterations: darknet.exe detector train cfg/coco.data cfg/yolov4.cfg yolov4.conv.137\nThen stop and by using partially-trained model /backup/yolov4_1000.weights run training with multigpu (up to 4 GPUs): darknet.exe detector train cfg/coco.data cfg/yolov4.cfg /backup/yolov4_1000.weights -gpus 0,1,2,3\nIf you get a Nan, then for some datasets better to decrease learning rate, for 4 GPUs set learning_rate = 0,00065 (i.e. learning_rate = 0.00261 / GPUs). In this case also increase 4x times burn_in = in your cfg-file. I.e. use burn_in = 4000 instead of 1000.\nhttps://groups.google.com/d/msg/darknet/NbJqonJBTSY/Te5PfIpuCAAJ\nHow to train (to detect your custom objects)\n(to train old Yolo v2 yolov2-voc.cfg, yolov2-tiny-voc.cfg, yolo-voc.cfg, yolo-voc.2.0.cfg, ... click by the link)\nTraining Yolo v4 (and v3):\nFor training cfg/yolov4-custom.cfg download the pre-trained weights-file (162 MB): yolov4.conv.137 (Google drive mirror yolov4.conv.137 )\nCreate file yolo-obj.cfg with the same content as in yolov4-custom.cfg (or copy yolov4-custom.cfg to yolo-obj.cfg) and:\nchange line batch to batch=64\nchange line subdivisions to subdivisions=16\nchange line max_batches to (classes*2000, but not less than number of training images and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\nchange line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\nset network size width=416 height=416 or any value multiple of 32: https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L8-L9\nchange line classes=80 to your number of objects in each of 3 [yolo]-layers:\nhttps://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L610\nhttps://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L696\nhttps://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L783\nchange [filters=255] to filters=(classes + 5)x3 in the 3 [convolutional] before each [yolo] layer, keep in mind that it only has to be the last [convolutional] before each of the [yolo] layers.\nhttps://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L603\nhttps://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L689\nhttps://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L776\nwhen using [Gaussian_yolo]  layers, change [filters=57] filters=(classes + 9)x3 in the 3 [convolutional] before each [Gaussian_yolo] layer\nhttps://github.com/AlexeyAB/darknet/blob/6e5bdf1282ad6b06ed0e962c3f5be67cf63d96dc/cfg/Gaussian_yolov3_BDD.cfg#L604\nhttps://github.com/AlexeyAB/darknet/blob/6e5bdf1282ad6b06ed0e962c3f5be67cf63d96dc/cfg/Gaussian_yolov3_BDD.cfg#L696\nhttps://github.com/AlexeyAB/darknet/blob/6e5bdf1282ad6b06ed0e962c3f5be67cf63d96dc/cfg/Gaussian_yolov3_BDD.cfg#L789\nSo if classes=1 then should be filters=18. If classes=2 then write filters=21.\n(Do not write in the cfg-file: filters=(classes + 5)x3)\n(Generally filters depends on the classes, coords and number of masks, i.e. filters=(classes + coords + 1), where mask is indices of anchors. If mask is absence, then filters=(classes + coords + 1)num)\nSo for example, for 2 objects, your file yolo-obj.cfg should differ from yolov4-custom.cfg in such lines in each of 3 [yolo]-layers:\nini\n[convolutional]\nfilters=21\n[region]\nclasses=2\nCreate file obj.names in the directory build\\darknet\\x64\\data\\, with objects names - each in new line\nCreate file obj.data in the directory build\\darknet\\x64\\data\\, containing (where classes = number of objects):\nini\n  classes = 2\n  train  = data/train.txt\n  valid  = data/test.txt\n  names = data/obj.names\n  backup = backup/\nPut image-files (.jpg) of your objects in the directory build\\darknet\\x64\\data\\obj\\\nYou should label each object on images from your dataset. Use this visual GUI-software for marking bounded boxes of objects and generating annotation files for Yolo v2 & v3: https://github.com/AlexeyAB/Yolo_mark\nIt will create .txt-file for each .jpg-image-file - in the same directory and with the same name, but with .txt-extension, and put to file: object number and object coordinates on this image, for each object in new line:\n    \nWhere:\n - integer object number from 0 to (classes-1)\n    - float values relative to width and height of image, it can be equal from (0.0 to 1.0]\nfor example:  =  /  or  =  / \nattention:   - are center of rectangle (are not top-left corner)\nFor example for img1.jpg you will be created img1.txt containing:\ncsv\n  1 0.716797 0.395833 0.216406 0.147222\n  0 0.687109 0.379167 0.255469 0.158333\n  1 0.420312 0.395833 0.140625 0.166667\nCreate file train.txt in directory build\\darknet\\x64\\data\\, with filenames of your images, each filename in new line, with path relative to darknet.exe, for example containing:\ncsv\n  data/obj/img1.jpg\n  data/obj/img2.jpg\n  data/obj/img3.jpg\nDownload pre-trained weights for the convolutional layers and put to the directory build\\darknet\\x64\nfor yolov4.cfg, yolov4-custom.cfg (162 MB): yolov4.conv.137 (Google drive mirror yolov4.conv.137 )\nfor yolov4-tiny.cfg, yolov4-tiny-3l.cfg, yolov4-tiny-custom.cfg (19 MB): yolov4-tiny.conv.29 \nfor csresnext50-panet-spp.cfg (133 MB): csresnext50-panet-spp.conv.112\nfor yolov3.cfg, yolov3-spp.cfg (154 MB): darknet53.conv.74\nfor yolov3-tiny-prn.cfg , yolov3-tiny.cfg (6 MB): yolov3-tiny.conv.11\nfor enet-coco.cfg (EfficientNetB0-Yolov3) (14 MB): enetb0-coco.conv.132\nStart training by using the command line: darknet.exe detector train data/obj.data yolo-obj.cfg yolov4.conv.137\nTo train on Linux use command: ./darknet detector train data/obj.data yolo-obj.cfg yolov4.conv.137 (just use ./darknet instead of darknet.exe)\n(file yolo-obj_last.weights will be saved to the build\\darknet\\x64\\backup\\ for each 100 iterations)\n(file yolo-obj_xxxx.weights will be saved to the build\\darknet\\x64\\backup\\ for each 1000 iterations)\n(to disable Loss-Window use darknet.exe detector train data/obj.data yolo-obj.cfg yolov4.conv.137 -dont_show, if you train on computer without monitor like a cloud Amazon EC2)\n(to see the mAP & Loss-chart during training on remote server without GUI, use command darknet.exe detector train data/obj.data yolo-obj.cfg yolov4.conv.137 -dont_show -mjpeg_port 8090 -map then open URL http://ip-address:8090 in Chrome/Firefox browser)\n8.1. For training with mAP (mean average precisions) calculation for each 4 Epochs (set valid=valid.txt or train.txt in obj.data file) and run: darknet.exe detector train data/obj.data yolo-obj.cfg yolov4.conv.137 -map\nAfter training is complete - get result yolo-obj_final.weights from path build\\darknet\\x64\\backup\\\nAfter each 100 iterations you can stop and later start training from this point. For example, after 2000 iterations you can stop training, and later just start training using: darknet.exe detector train data/obj.data yolo-obj.cfg backup\\yolo-obj_2000.weights\n(in the original repository https://github.com/pjreddie/darknet the weights-file is saved only once every 10 000 iterations if(iterations > 1000))\nAlso you can get result earlier than all 45000 iterations.\nNote: If during training you see nan values for avg (loss) field - then training goes wrong, but if nan is in some other lines - then training goes well.\nNote: If you changed width= or height= in your cfg-file, then new width and height must be divisible by 32.\nNote: After training use such command for detection: darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights\nNote: if error Out of memory occurs then in .cfg-file you should increase subdivisions=16, 32 or 64: link\nHow to train tiny-yolo (to detect your custom objects)\nDo all the same steps as for the full yolo model as described above. With the exception of:\nDownload file with the first 29-convolutional layers of yolov4-tiny: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\n (Or get this file from yolov4-tiny.weights file by using command: darknet.exe partial cfg/yolov4-tiny-custom.cfg yolov4-tiny.weights yolov4-tiny.conv.29 29\nMake your custom model yolov4-tiny-obj.cfg based on cfg/yolov4-tiny-custom.cfg instead of yolov4.cfg\nStart training: darknet.exe detector train data/obj.data yolov4-tiny-obj.cfg yolov4-tiny.conv.29\nFor training Yolo based on other models (DenseNet201-Yolo or ResNet50-Yolo), you can download and get pre-trained weights as showed in this file: https://github.com/AlexeyAB/darknet/blob/master/build/darknet/x64/partial.cmd\nIf you made you custom model that isn't based on other models, then you can train it without pre-trained weights, then will be used random initial weights.\nWhen should I stop training\nUsually sufficient 2000 iterations for each class(object), but not less than number of training images and not less than 6000 iterations in total. But for a more precise definition when you should stop training, use the following manual:\nDuring training, you will see varying indicators of error, and you should stop when no longer decreases 0.XXXXXXX avg:\nRegion Avg IOU: 0.798363, Class: 0.893232, Obj: 0.700808, No Obj: 0.004567, Avg Recall: 1.000000,  count: 8\nRegion Avg IOU: 0.800677, Class: 0.892181, Obj: 0.701590, No Obj: 0.004574, Avg Recall: 1.000000,  count: 8\n9002: 0.211667, 0.60730 avg, 0.001000 rate, 3.868000 seconds, 576128 images\nLoaded: 0.000000 seconds\n9002 - iteration number (number of batch)\n0.60730 avg - average loss (error) - the lower, the better\nWhen you see that average loss 0.xxxxxx avg no longer decreases at many iterations then you should stop training. The final average loss can be from 0.05 (for a small model and easy dataset) to 3.0 (for a big model and a difficult dataset).\nOr if you train with flag -map then you will see mAP indicator Last accuracy mAP@0.5 = 18.50% in the console - this indicator is better than Loss, so train while mAP increases.\nOnce training is stopped, you should take some of last .weights-files from darknet\\build\\darknet\\x64\\backup and choose the best of them:\nFor example, you stopped training after 9000 iterations, but the best result can give one of previous weights (7000, 8000, 9000). It can happen due to over-fitting. Over-fitting - is case when you can detect objects on images from training-dataset, but can't detect objects on any others images. You should get weights from Early Stopping Point:\nTo get weights from Early Stopping Point:\n2.1. At first, in your file obj.data you must specify the path to the validation dataset valid = valid.txt (format of valid.txt as in train.txt), and if you haven't validation images, just copy data\\train.txt to data\\valid.txt.\n2.2 If training is stopped after 9000 iterations, to validate some of previous weights use this commands:\n(If you use another GitHub repository, then use darknet.exe detector recall... instead of darknet.exe detector map...)\ndarknet.exe detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_7000.weights\ndarknet.exe detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_8000.weights\ndarknet.exe detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_9000.weights\nAnd compare last output lines for each weights (7000, 8000, 9000):\nChoose weights-file with the highest mAP (mean average precision) or IoU (intersect over union)\nFor example, bigger mAP gives weights yolo-obj_8000.weights - then use this weights for detection.\nOr just train with -map flag:\ndarknet.exe detector train data/obj.data yolo-obj.cfg yolov4.conv.137 -map\nSo you will see mAP-chart (red-line) in the Loss-chart Window. mAP will be calculated for each 4 Epochs using valid=valid.txt file that is specified in obj.data file (1 Epoch = images_in_train_txt / batch iterations)\n(to change the max x-axis value - change max_batches= parameter to 2000*classes, f.e. max_batches=6000 for 3 classes)\nExample of custom object detection: darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights\nIoU (intersect over union) - average intersect over union of objects and detections for a certain threshold = 0.24\nmAP (mean average precision) - mean value of average precisions for each class, where average precision is average value of 11 points on PR-curve for each possible threshold (each probability of detection) for the same class (Precision-Recall in terms of PascalVOC, where Precision=TP/(TP+FP) and Recall=TP/(TP+FN) ), page-11: http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf\nmAP is default metric of precision in the PascalVOC competition, this is the same as AP50 metric in the MS COCO competition.\nIn terms of Wiki, indicators Precision and Recall have a slightly different meaning than in the PascalVOC competition, but IoU always has the same meaning.\nCustom object detection\nExample of custom object detection: darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights\n|  |  |\n|---|---|\nHow to improve object detection\nBefore training:\nset flag random=1 in your .cfg-file - it will increase precision by training Yolo for different resolutions: link\nincrease network resolution in your .cfg-file (height=608, width=608 or any value multiple of 32) - it will increase precision\ncheck that each object that you want to detect is mandatory labeled in your dataset - no one object in your data set should not be without label. In the most training issues - there are wrong labels in your dataset (got labels by using some conversion script, marked with a third-party tool, ...). Always check your dataset by using: https://github.com/AlexeyAB/Yolo_mark\nmy Loss is very high and mAP is very low, is training wrong? Run training with -show_imgs flag at the end of training command, do you see correct bounded boxes of objects (in windows or in files aug_...jpg)? If no - your training dataset is wrong.\nfor each object which you want to detect - there must be at least 1 similar object in the Training dataset with about the same: shape, side of object, relative size, angle of rotation, tilt, illumination. So desirable that your training dataset include images with objects at different: scales, rotations, lightings, from different sides, on different backgrounds - you should preferably have 2000 different images for each class or more, and you should train 2000*classes iterations or more\ndesirable that your training dataset include images with non-labeled objects that you do not want to detect - negative samples without bounded box (empty .txt files) - use as many images of negative samples as there are images with objects\nWhat is the best way to mark objects: label only the visible part of the object, or label the visible and overlapped part of the object, or label a little more than the entire object (with a little gap)? Mark as you like - how would you like it to be detected.\nfor training with a large number of objects in each image, add the parameter max=200 or higher value in the last [yolo]-layer or [region]-layer in your cfg-file (the global maximum number of objects that can be detected by YoloV3 is 0,0615234375(widthheight) where are width and height are parameters from [net] section in cfg-file)\nfor training for small objects (smaller than 16x16 after the image is resized to 416x416) - set layers = 23 instead of https://github.com/AlexeyAB/darknet/blob/6f718c257815a984253346bba8fb7aa756c55090/cfg/yolov4.cfg#L895\nset stride=4 instead of https://github.com/AlexeyAB/darknet/blob/6f718c257815a984253346bba8fb7aa756c55090/cfg/yolov4.cfg#L892\nset stride=4 instead of https://github.com/AlexeyAB/darknet/blob/6f718c257815a984253346bba8fb7aa756c55090/cfg/yolov4.cfg#L989\nfor training for both small and large objects use modified models:\nFull-model: 5 yolo layers: https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3_5l.cfg\nTiny-model: 3 yolo layers: https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny-3l.cfg\nYOLOv4: 3 yolo layers: https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-custom.cfg\nIf you train the model to distinguish Left and Right objects as separate classes (left/right hand, left/right-turn on road signs, ...) then for disabling flip data augmentation - add flip=0 here: https://github.com/AlexeyAB/darknet/blob/3d2d0a7c98dbc8923d9ff705b81ff4f7940ea6ff/cfg/yolov3.cfg#L17\nGeneral rule - your training dataset should include such a set of relative sizes of objects that you want to detect:\ntrain_network_width * train_obj_width / train_image_width ~= detection_network_width * detection_obj_width / detection_image_width\ntrain_network_height * train_obj_height / train_image_height ~= detection_network_height * detection_obj_height / detection_image_height\nI.e. for each object from Test dataset there must be at least 1 object in the Training dataset with the same class_id and about the same relative size:\nobject width in percent from Training dataset ~= object width in percent from Test dataset\nThat is, if only objects that occupied 80-90% of the image were present in the training set, then the trained network will not be able to detect objects that occupy 1-10% of the image.\nto speedup training (with decreasing detection accuracy) set param stopbackward=1 for layer-136 in cfg-file\neach: model of object, side, illumination, scale, each 30 grad of the turn and inclination angles - these are different objects from an internal perspective of the neural network. So the more different objects you want to detect, the more complex network model should be used.\nto make the detected bounded boxes more accurate, you can add 3 parameters ignore_thresh = .9 iou_normalizer=0.5 iou_loss=giou to each [yolo] layer and train, it will increase mAP@0.9, but decrease mAP@0.5.\nOnly if you are an expert in neural detection networks - recalculate anchors for your dataset for width and height from cfg-file:\ndarknet.exe detector calc_anchors data/obj.data -num_of_clusters 9 -width 416 -height 416\nthen set the same 9 anchors in each of 3 [yolo]-layers in your cfg-file. But you should change indexes of anchors masks= for each [yolo]-layer, so for YOLOv4 the 1st-[yolo]-layer has anchors smaller than 30x30, 2nd smaller than 60x60, 3rd remaining, and vice versa for YOLOv3. Also you should change the filters=(classes + 5)* before each [yolo]-layer. If many of the calculated anchors do not fit under the appropriate layers - then just try using all the default anchors.\nAfter training - for detection:\nIncrease network-resolution by set in your .cfg-file (height=608 and width=608) or (height=832 and width=832) or (any value multiple of 32) - this increases the precision and makes it possible to detect small objects: link\nit is not necessary to train the network again, just use .weights-file already trained for 416x416 resolution\nto get even greater accuracy you should train with higher resolution 608x608 or 832x832, note: if error Out of memory occurs then in .cfg-file you should increase subdivisions=16, 32 or 64: link\nHow to mark bounded boxes of objects and create annotation files\nHere you can find repository with GUI-software for marking bounded boxes of objects and generating annotation files for Yolo v2 - v4: https://github.com/AlexeyAB/Yolo_mark\nWith example of: train.txt, obj.names, obj.data, yolo-obj.cfg, air1-6.txt, bird1-4.txt for 2 classes of objects (air, bird) and train_obj.cmd with example how to train this image-set with Yolo v2 - v4\nDifferent tools for marking objects in images:\nin C++: https://github.com/AlexeyAB/Yolo_mark\nin Python: https://github.com/tzutalin/labelImg\nin Python: https://github.com/Cartucho/OpenLabeling\nin C++: https://www.ccoderun.ca/darkmark/\nin JavaScript: https://github.com/opencv/cvat\nin C++: https://github.com/jveitchmichaelis/deeplabel\nin C#: https://github.com/BMW-InnovationLab/BMW-Labeltool-Lite\nDL-Annotator for Windows ($30): url\nv7labs - the greatest cloud labeling tool ($1.5 per hour): https://www.v7labs.com/\nHow to use Yolo as DLL and SO libraries\non Linux\nusing build.sh or\nbuild darknet using cmake or\nset LIBSO=1 in the Makefile and do make\non Windows\nusing build.ps1 or\nbuild darknet using cmake or\ncompile build\\darknet\\yolo_cpp_dll.sln solution or build\\darknet\\yolo_cpp_dll_no_gpu.sln solution\nThere are 2 APIs:\nC API: https://github.com/AlexeyAB/darknet/blob/master/include/darknet.h\nPython examples using the C API:\nhttps://github.com/AlexeyAB/darknet/blob/master/darknet.py\nhttps://github.com/AlexeyAB/darknet/blob/master/darknet_video.py\nC++ API: https://github.com/AlexeyAB/darknet/blob/master/include/yolo_v2_class.hpp\nC++ example that uses C++ API: https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp\nTo compile Yolo as C++ DLL-file yolo_cpp_dll.dll - open the solution build\\darknet\\yolo_cpp_dll.sln, set x64 and Release, and do the: Build -> Build yolo_cpp_dll\nYou should have installed CUDA 10.2\nTo use cuDNN do: (right click on project) -> properties -> C/C++ -> Preprocessor -> Preprocessor Definitions, and add at the beginning of line: CUDNN;\nTo use Yolo as DLL-file in your C++ console application - open the solution build\\darknet\\yolo_console_dll.sln, set x64 and Release, and do the: Build -> Build yolo_console_dll\nyou can run your console application from Windows Explorer build\\darknet\\x64\\yolo_console_dll.exe\nuse this command: yolo_console_dll.exe data/coco.names yolov4.cfg yolov4.weights test.mp4\nafter launching your console application and entering the image file name - you will see info for each object:\n     \nto use simple OpenCV-GUI you should uncomment line //#define OPENCV in yolo_console_dll.cpp-file: link\nyou can see source code of simple example for detection on the video file: link\nyolo_cpp_dll.dll-API: link\n```cpp\nstruct bbox_t {\n    unsigned int x, y, w, h;    // (x,y) - top-left corner, (w, h) - width & height of bounded box\n    float prob;                    // confidence - probability that the object was found correctly\n    unsigned int obj_id;        // class of object - from range [0, classes-1]\n    unsigned int track_id;        // tracking id for video (0 - untracked, 1 - inf - tracked object)\n    unsigned int frames_counter;// counter of frames on which the object was detected\n};\nclass Detector {\npublic:\n        Detector(std::string cfg_filename, std::string weight_filename, int gpu_id = 0);\n        ~Detector();\n    std::vector detect(std::string image_filename, float thresh = 0.2, bool use_mean = false);\n    std::vector detect(image_t img, float thresh = 0.2, bool use_mean = false);\n    static image_t load_image(std::string image_filename);\n    static void free_image(image_t m);\nifdef OPENCV\n    std::vector detect(cv::Mat mat, float thresh = 0.2, bool use_mean = false);\n    std::shared_ptr mat_to_image_resize(cv::Mat mat) const;\nendif\n};\n```\nCitation\n@misc{bochkovskiy2020yolov4,\n      title={YOLOv4: Optimal Speed and Accuracy of Object Detection}, \n      author={Alexey Bochkovskiy and Chien-Yao Wang and Hong-Yuan Mark Liao},\n      year={2020},\n      eprint={2004.10934},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n@InProceedings{Wang_2021_CVPR,\n    author    = {Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},\n    title     = {{Scaled-YOLOv4}: Scaling Cross Stage Partial Network},\n    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n    month     = {June},\n    year      = {2021},\n    pages     = {13029-13038}\n}",
	"deep-neural-networks latex": "PlotNeuralNet\nLatex code for drawing neural networks for reports and presentation. Have a look into examples to see how they are made. Additionally, lets consolidate any improvements that you make and fix any bugs to help more people with this code.\nExamples\nFollowing are some network representations:\nFCN-8 (view on Overleaf)\nFCN-32 (view on Overleaf)\nHolistically-Nested Edge Detection (view on Overleaf)\nGetting Started\nInstall the following packages on Ubuntu.\nUbuntu 16.04\n    sudo apt-get install texlive-latex-extra\nUbuntu 18.04.2\nBase on this website, please install the following packages.\n    sudo apt-get install texlive-latex-base\n    sudo apt-get install texlive-fonts-recommended\n    sudo apt-get install texlive-fonts-extra\n    sudo apt-get install texlive-latex-extra\nWindows\nDownload and install MikTeX.\nDownload and install bash runner on Windows, recommends Git bash or Cygwin(https://www.cygwin.com/)\nExecute the example as followed.\n    cd pyexamples/\n    bash ../tikzmake.sh test_simple\nTODO\n[X] Python interface\n[ ] Add easy legend functionality\n[ ] Add more layer shapes like TruncatedPyramid, 2DSheet etc\n[ ] Add examples for RNN and likes.\nLatex usage\nSee examples directory for usage.\nPython usage\nFirst, create a new directory and a new Python file:\n$ mkdir my_project\n$ cd my_project\nvim my_arch.py\nAdd the following code to your new file:\npython\nimport sys\nsys.path.append('../')\nfrom pycore.tikzeng import *\ndefined your arch\narch = [\n    to_head( '..' ),\n    to_cor(),\n    to_begin(),\n    to_Conv(\"conv1\", 512, 64, offset=\"(0,0,0)\", to=\"(0,0,0)\", height=64, depth=64, width=2 ),\n    to_Pool(\"pool1\", offset=\"(0,0,0)\", to=\"(conv1-east)\"),\n    to_Conv(\"conv2\", 128, 64, offset=\"(1,0,0)\", to=\"(pool1-east)\", height=32, depth=32, width=2 ),\n    to_connection( \"pool1\", \"conv2\"),\n    to_Pool(\"pool2\", offset=\"(0,0,0)\", to=\"(conv2-east)\", height=28, depth=28, width=1),\n    to_SoftMax(\"soft1\", 10 ,\"(3,0,0)\", \"(pool1-east)\", caption=\"SOFT\"  ),\n    to_connection(\"pool2\", \"soft1\"),\n    to_end()\n    ]\ndef main():\n    namefile = str(sys.argv[0]).split('.')[0]\n    to_generate(arch, namefile + '.tex' )\nif name == 'main':\n    main()\nNow, run the program as follows:\nbash ../tikzmake.sh my_arch",
	"ai computer-vision computervision deep-learning deep-neural-networks deeplearning machine-learning opencv opencv-cpp opencv-library opencv-python opencv-tutorial opencv3": "LearnOpenCV\nThis repo contains code for Computer Vision, Deep learning, and AI articles shared on our blog LearnOpenCV.com.\nWant to become an expert in AI? AI Courses by OpenCV is a great place to start.\nList of Blog Posts\n| Blog Post | |\n| ------------- |:-------------|\n|FCOS - Anchor Free Object Detection Explained|Code|\n| YOLOv6 Custom Dataset Training \u2013 Underwater Trash Detection | Code |\n|What is EXIF Data in Images?|Code|\n|t-SNE: T-Distributed Stochastic Neighbor Embedding Explained|Code|\n|CenterNet: Objects as Points \u2013 Anchor-free Object Detection Explained|Code|\n|YOLOv7 Pose vs MediaPipe in Human Pose Estimation|Code|\n|YOLOv6 Object Detection \u2013 Paper Explanation and Inference|Code|\n|YOLOX Object Detector Paper Explanation and Custom Training|Code|\n|Driver Drowsiness Detection Using Mediapipe In Python|Code|\n|GTC 2022 Big Bang AI announcements: Everything you need to know||\n|NVIDIA GTC 2022 : The most important AI event this Fall||\n|Object Tracking and Reidentification with FairMOT | Code |\n|What is Face Detection? \u2013 The Ultimate Guide for 2022 | Code |\n|Document Scanner: Custom Semantic Segmentation using PyTorch-DeepLabV3|Code|\n|Fine Tuning YOLOv7 on Custom Dataset|Code|\n|Center Stage for Zoom Calls using MediaPipe|Code|\n|Mean Average Precision (mAP) in Object Detection||\n|YOLOv7 Object Detection Paper Explanation and Inference|Code|\n|Pothole Detection using YOLOv4 and Darknet|Code|\n|Automatic Document Scanner using OpenCV|Code|\n|Demystifying GPU architectures for deep learning: Part 2|Code|\n|Demystifying GPU Architectures For Deep Learning|Code|\n|Intersection-over-Union(IoU)-in-Object-Detection-and-Segmentation|Code|\n|Understanding Multiple Object Tracking using DeepSORT|Code|\n|Optical Character Recognition using PaddleOCR|Code|\n|Gesture Control in Zoom Call using Mediapipe|Code|\n|A Deep Dive into Tensorflow Model Optimization|Code|\n|DepthAI Pipeline Overview: Creating a Complex Pipeline|Code|\n|TensorFlow Lite Model Maker: Create Models for On-Device Machine Learning|Code|\n|TensorFlow Lite: Model Optimization for   On Device Machine Learning|Code|\n|Object detection with depth measurement using pre-trained models with OAK-D|Code|\n|Custom Object Detection Training using YOLOv5|Code|\n|Object Detection using Yolov5 and OpenCV DNN (C++/Python)|Code|\n|Create Snapchat/Instagram filters using Mediapipe|Code|\n|AUTOSAR C++ compliant deep learning inference with TensorRT|Code|\n|NVIDIA GTC 2022 Day 4 Highlights: Meet the new Jetson Orin||\n|NVIDIA GTC 2022 Day 3 Highlights: Deep Dive into Hopper architecture||\n|NVIDIA GTC 2022 Day 2 Highlights: Jensen\u2019s Keynote||\n|NVIDIA GTC 2022 Day 1 Highlights: Brilliant Start||\n|Automatic License Plate Recognition using Python|Code|\n|Building a Poor Body Posture Detection and Alert System using MediaPipe|Code|\n|Introduction to MediaPipe|Code|\n|Disparity Estimation using Deep Learning|Code|\n|How to build Chrome Dino game bot using OpenCV Feature Matching|Code|\n|Top 10 Sources to Find Computer Vision and AI Models||\n|Multi-Attribute and Graph-based Object Detection||\n|Plastic Waste Detection with Deep Learning|Code|\n|Ensemble Deep Learning-based Defect Classification and Detection in SEM Images||\n|Building Industrial embedded deep learning inference pipelines with TensorRT|Code|\n|Transfer Learning for Medical Images||\n|Stereo Vision and Depth Estimation using OpenCV AI Kit|Code|\n|Introduction to OpenCV AI Kit and DepthAI|Code|\n|WeChat QR Code Scanner in OpenCV|Code|\n|AI behind the Diwali 2021 \u2018Not just a Cadbury ad\u2019| |\n|Model Selection and Benchmarking with Modelplace.AI|Model Zoo|\n|Real-time style transfer in a zoom meeting|Code|\n| Introduction to OpenVino Deep Learning Workbench | Code |\n| Running OpenVino Models on Intel Integrated GPU | Code |\n|Post Training Quantization with OpenVino Toolkit|Code|\n|Introduction to Intel OpenVINO Toolkit||\n|Human Action Recognition using Detectron2 and LSTM|Code|\n|Pix2Pix:Image-to-Image Translation in PyTorch & TensorFlow|Code|\n|Conditional GAN (cGAN) in PyTorch and TensorFlow|Code|\n|Deep Convolutional GAN in PyTorch and TensorFlow|Code|\n|Introduction to Generative Adversarial Networks (GANs)|Code|\n|Human Pose Estimation using Keypoint RCNN in PyTorch|Code|\n|Non Maximum Suppression: Theory and Implementation in PyTorch|Code|\n|MRNet \u2013 The Multi-Task Approach| Code |\n|Generative and Discriminative Models| |\n|Playing Chrome's T-Rex Game with Facial Gestures| Code |\n|Variational Autoencoder in TensorFlow| Code |\n|Autoencoder in TensorFlow 2: Beginner\u2019s Guide| Code |\n|Deep Learning with OpenCV DNN Module: A Definitive Guide| Code |\n|Depth perception using stereo camera (Python/C++)| Code |\n|Contour Detection using OpenCV (Python/C++)| Code |\n|Super Resolution in OpenCV| Code |\n|Improving Illumination in Night Time Images| Code |\n|Video Classification and Human Activity Recognition | Code |\n|How to use OpenCV DNN Module with Nvidia GPU on Windows | Code |\n|How to use OpenCV DNN Module with NVIDIA GPUs | Code |\n|Code OpenCV in Visual Studio | |\n|Install OpenCV on Windows \u2013 C++ / Python | Code |\n|Face Recognition with ArcFace | Code|\n|Background Subtraction with OpenCV and BGS Libraries | Code |\n|RAFT: Optical Flow estimation using Deep Learning|Code|\n|Making A Low-Cost Stereo Camera Using OpenCV|Code|\n|Optical Flow in OpenCV (C++/Python)|Code|\n|Introduction to Epipolar Geometry and Stereo Vision|Code|\n|Classification With Localization: Convert any keras Classifier to a Detector | Code |\n|Photoshop Filters in OpenCV|Code|\n|Tetris Game using OpenCV Python|Code|\n|Image Classification with OpenCV for Android | Code |\n|Image Classification with OpenCV Java|Code |\n|PyTorch to Tensorflow Model Conversion | Code |\n|Snake Game with OpenCV Python|Code |\n|Stanford MRNet Challenge: Classifying Knee MRIs|Code |\n|Experiment Logging with TensorBoard and wandb|Code |\n|Understanding Lens Distortion|Code |\n|Image Matting with state-of-the-art Method \u201cF, B, Alpha Matting\u201d|Code |\n|Bag Of Tricks For Image Classification - Let's check if it is working or not|Code |\n|Getting Started with OpenCV CUDA Module|Code |\n|Training a Custom Object Detector with DLIB & Making Gesture Controlled Applications|Code |\n|How To Run Inference Using TensorRT C++ API | Code |\n|Using Facial Landmarks for Overlaying Faces with Medical Masks|Code |\n|Tensorboard with PyTorch Lightning|Code |\n|Otsu's Thresholding with OpenCV|Code |\n|PyTorch-to-CoreML-model-conversion | Code |\n|Playing Rock, Paper, Scissors with AI | Code |\n|CNN Receptive Field Computation Using Backprop with TensorFlow|Code|\n|CNN Fully Convolutional Image Classification with TensorFlow | Code |\n|How to convert a model from PyTorch to TensorRT and speed up inference | Code |\n|Efficient image loading|Code |\n|Graph Convolutional Networks: Model Relations In Data|Code|\n|Getting Started with Federated Learning with PyTorch and PySyft|Code|\n|Creating a Virtual Pen & Eraser | Code |\n|Getting Started with PyTorch Lightning|Code|\n|Multi-Label Image Classification with PyTorch: Image Tagging|Code|\n|Funny Mirrors Using OpenCV|code|\n|t-SNE for ResNet feature visualization|Code|\n|Multi-Label Image Classification with Pytorch|Code|\n|CNN Receptive Field Computation Using Backprop|Code|\n|CNN Receptive Field Computation Using Backprop with TensorFlow|Code|\n|Augmented Reality using AruCo Markers in OpenCV(C++ and Python) |Code|\n|Fully Convolutional Image Classification on Arbitrary Sized Image|Code|\n|Camera Calibration using OpenCV |Code|\n|Geometry of Image Formation ||\n|Ensuring Training Reproducibility in Pytorch ||\n|Gaze Tracking ||\n|Simple Background Estimation in Videos Using OpenCV | Code|\n|Applications of Foreground-Background separation with Semantic Segmentation | Code |\n|EfficientNet: Theory + Code | Code |\n|PyTorch for Beginners: Mask R-CNN Instance Segmentation with PyTorch | Code |\n|PyTorch for Beginners: Faster R-CNN Object Detection with PyTorch | Code |\n|PyTorch for Beginners: Semantic Segmentation using torchvision | Code |\n|PyTorch for Beginners: Comparison of pre-trained models for Image Classification | Code |\n|PyTorch for Beginners: Basics | Code |\n|PyTorch Model Inference using ONNX and Caffe2 | Code |\n|Image Classification Using Transfer Learning in PyTorch | Code |\n|Hangman: Creating games in OpenCV | Code |\n|Image Inpainting with OpenCV (C++/Python) | Code |\n|Hough Transform with OpenCV (C++/Python) | Code |\n|Xeus-Cling: Run C++ code in Jupyter Notebook | Code |\n|Gender & Age Classification using OpenCV Deep Learning ( C++/Python ) | Code |\n|Invisibility Cloak using Color Detection and Segmentation with OpenCV | Code |\n|Fast Image Downloader for Open Images V4 (Python) | Code |\n|Deep Learning based Text Detection Using OpenCV (C++/Python) | Code |\n|Video Stabilization Using Point Feature Matching in OpenCV | Code |\n|Training YOLOv3 : Deep Learning based Custom Object Detector | Code |\n|Using OpenVINO with OpenCV | Code |\n|Duplicate Search on Quora Dataset | Code |\n|Shape Matching using Hu Moments (C++/Python) | Code |\n|Install OpenCV 4 on CentOS (C++ and Python) | Code |\n|Install OpenCV 3.4.4 on CentOS (C++ and Python) | Code |\n|Install OpenCV 3.4.4 on Red Hat (C++ and Python) | Code |\n|Install OpenCV 4 on Red Hat (C++ and Python) | Code |\n|Install OpenCV 4 on macOS (C++ and Python) | Code |\n|Install OpenCV 3.4.4 on Raspberry Pi | Code |\n|Install OpenCV 3.4.4 on macOS (C++ and Python) | Code |\n|OpenCV QR Code Scanner (C++ and Python) | Code |\n|Install OpenCV 3.4.4 on Windows (C++ and Python) | Code |\n|Install OpenCV 3.4.4 on Ubuntu 16.04 (C++ and Python) | Code |\n|Install OpenCV 3.4.4 on Ubuntu 18.04 (C++ and Python) | Code |\n|Universal Sentence Encoder | Code |\n|Install OpenCV 4 on Raspberry Pi | Code |\n|Install OpenCV 4 on Windows (C++ and Python) | Code |\n|Hand Keypoint Detection using Deep Learning and OpenCV | Code|\n|Deep learning based Object Detection and Instance Segmentation using Mask R-CNN in OpenCV (Python / C++) | Code |\n|Install OpenCV 4 on Ubuntu 18.04 (C++ and Python) | Code |\n|Install OpenCV 4 on Ubuntu 16.04 (C++ and Python) | Code |\n|Multi-Person Pose Estimation in OpenCV using OpenPose | Code |\n|Heatmap for Logo Detection using OpenCV (Python) | Code|\n|Deep Learning based Object Detection using YOLOv3 with OpenCV ( Python / C++ ) | Code|\n|Convex Hull using OpenCV in Python and C++ | Code|\n|MultiTracker : Multiple Object Tracking using OpenCV (C++/Python) | Code |\n|Convolutional Neural Network based Image Colorization using OpenCV | Code|\n|SVM using scikit-learn|Code|\n|GOTURN: Deep Learning based Object Tracking | Code|\n|Find the Center of a Blob (Centroid) using OpenCV (C++/Python) | Code|\n|Support Vector Machines (SVM)|Code|\n|Batch Normalization in Deep Networks | Code|\n|Deep Learning based Character Classification using Synthetic Dataset | Code|\n|Image Quality Assessment : BRISQUE| Code|\n|Understanding AlexNet||\n|Deep Learning based Text Recognition (OCR) using Tesseract and OpenCV| Code|\n|Deep Learning based Human Pose Estimation using OpenCV ( C++ / Python )| Code|\n|Number of Parameters and Tensor Sizes in a Convolutional Neural Network (CNN)| |\n|How to convert your OpenCV C++ code into a Python module| Code|\n|CV4Faces : Best Project Award 2018| |\n|Facemark : Facial Landmark Detection using OpenCV| Code|\n|Image Alignment (Feature Based) using OpenCV (C++/Python)| Code|\n|Barcode and QR code Scanner using ZBar and OpenCV| Code|\n|Keras Tutorial : Fine-tuning using pre-trained models| Code|\n|OpenCV Transparent API| |\n|Face Reconstruction using EigenFaces (C++/Python)|Code |\n|Eigenface using OpenCV (C++/Python)| Code|\n|Principal Component Analysis| |\n|Keras Tutorial : Transfer Learning using pre-trained models| Code |\n|Keras Tutorial : Using pre-trained Imagenet models| Code |\n|Technical Aspects of a Digital SLR | |\n|Using Harry Potter interactive wand with OpenCV to create magic| |\n|Install OpenCV 3 and Dlib on Windows ( Python only )| |\n|Image Classification using Convolutional Neural Networks in Keras      | Code|\n|Understanding Autoencoders using Tensorflow (Python)      | Code|\n|Best Project Award : Computer Vision for Faces | |\n|Understanding Activation Functions in Deep Learning      | |\n|Image Classification using Feedforward Neural Network in Keras      | Code|\n|Exposure Fusion using OpenCV (C++/Python)      | Code|\n|Understanding Feedforward Neural Networks      | |\n|High Dynamic Range (HDR) Imaging using OpenCV (C++/Python)      | Code|\n|Deep learning using Keras \u2013 The Basics      | Code|\n|Selective Search for Object Detection (C++ / Python) | Code |\n|Installing Deep Learning Frameworks on Ubuntu with CUDA support | |\n|Parallel Pixel Access in OpenCV using forEach | Code |\n|cvui: A GUI lib built on top of OpenCV drawing primitives | Code |\n|Install Dlib on Windows | |\n|Install Dlib on Ubuntu | |\n|Install OpenCV3 on Ubuntu | |\n|Read, Write and Display a video using OpenCV ( C++/ Python ) | Code |\n|Install Dlib on MacOS | |\n|Install OpenCV 3 on MacOS | |\n|Install OpenCV 3 on Windows | |\n|Get OpenCV Build Information ( getBuildInformation ) | |\n|Color spaces in OpenCV (C++ / Python) | Code|\n|Neural Networks : A 30,000 Feet View for Beginners | |\n|Alpha Blending using OpenCV (C++ / Python) | Code |\n|User stories : How readers of this blog are applying their knowledge to build applications | |\n|How to select a bounding box ( ROI ) in OpenCV (C++/Python) ? | |\n|Automatic Red Eye Remover using OpenCV (C++ / Python) | Code |\n|Bias-Variance Tradeoff in Machine Learning | |\n|Embedded Computer Vision: Which device should you choose? | |\n|Object Tracking using OpenCV (C++/Python) | Code |\n|Handwritten Digits Classification : An OpenCV ( C++ / Python ) Tutorial | Code |\n|Training a better Haar and LBP cascade based Eye Detector using OpenCV | |\n|Deep Learning Book Gift Recipients | |\n|Minified OpenCV Haar and LBP Cascades | Code|\n|Deep Learning Book Gift | |\n|Histogram of Oriented Gradients | |\n|Image Recognition and Object Detection : Part 1 | |\n|Head Pose Estimation using OpenCV and Dlib | Code |\n|Live CV : A Computer Vision Coding Application | |\n|Approximate Focal Length for Webcams and Cell Phone Cameras | |\n|Configuring Qt for OpenCV on OSX | Code |\n|Rotation Matrix To Euler Angles | Code |\n|Speeding up Dlib\u2019s Facial Landmark Detector | |\n|Warp one triangle to another using OpenCV ( C++ / Python ) | Code |\n|Average Face : OpenCV ( C++ / Python ) Tutorial | Code |\n|Face Swap using OpenCV ( C++ / Python ) | Code |\n|Face Morph Using OpenCV \u2014 C++ / Python | Code |\n|Deep Learning Example using NVIDIA DIGITS 3 on EC2 | |\n|NVIDIA DIGITS 3 on EC2 | |\n|Homography Examples using OpenCV ( Python / C ++ ) | Code |\n|Filling holes in an image using OpenCV ( Python / C++ ) | Code |\n|How to find frame rate or frames per second (fps) in OpenCV ( Python / C++ ) ? | Code |\n|Delaunay Triangulation and Voronoi Diagram using OpenCV ( C++ / Python)  | Code |\n|OpenCV (C++ vs Python) vs MATLAB for Computer Vision | |\n|Facial Landmark Detection | |\n|Why does OpenCV use BGR color format ? | |\n|Computer Vision for Predicting Facial Attractiveness | Code |\n|applyColorMap for pseudocoloring in OpenCV ( C++ / Python ) | Code |\n|Image Alignment (ECC) in OpenCV ( C++ / Python ) | Code |\n|How to find OpenCV version in Python and C++ ? | |\n|Baidu banned from ILSVRC 2015 | |\n|OpenCV Transparent API | |\n|How Computer Vision Solved the Greatest Soccer Mystery of All Time | |\n|Embedded Vision Summit 2015 | |\n|Read an Image in OpenCV ( Python, C++ ) | Code |\n|Non-Photorealistic Rendering using OpenCV ( Python, C++ ) | Code |\n|Seamless Cloning using OpenCV ( Python , C++ ) | Code |\n|OpenCV Threshold ( Python , C++ ) | Code |\n|Blob Detection Using OpenCV ( Python, C++ ) | Code |\n|Turn your OpenCV Code into a Web API in under 10 minutes \u2014 Part 1 | |\n|How to compile OpenCV sample Code ? | |\n|Install OpenCV 3 on Yosemite ( OSX 10.10.x ) | |",
	"c-plus-plus c-sharp cntk cognitive-toolkit deep-learning deep-neural-networks distributed java machine-learning neural-network python": "CNTK\n| Chat | Windows build status | Linux build status |\n|-------------|-------------|---------------|\n|  |  |  |\nThe Microsoft Cognitive Toolkit (https://cntk.ai) is a unified deep learning toolkit that describes neural networks as a series of computational steps via a directed graph. In this directed graph, leaf nodes represent input values or network parameters, while other nodes represent matrix operations upon their inputs. CNTK allows users to easily realize and combine popular model types such as feed-forward DNNs, convolutional nets (CNNs), and recurrent networks (RNNs/LSTMs). It implements stochastic gradient descent (SGD, error backpropagation) learning with automatic differentiation and parallelization across multiple GPUs and servers. CNTK has been available under an open-source license since April 2015. It is our hope that the community will take advantage of CNTK to share ideas more quickly through the exchange of open source working code.\nInstallation\nSetup CNTK\nWindows (Python-only / Script-driven / Manual)\nLinux (Python-only / Script-driven / Manual / Docker)\nCNTK backend for Keras\nSetup CNTK development environment\nWindows (Script-driven / Manual)\nLinux (Manual)\nInstalling nightly packages\nIf you prefer to use latest CNTK bits from master, use one of the CNTK nightly packages:\nNightly packages for Windows\nNightly packages for Linux\nLearning CNTK\nYou can learn more about using and contributing to CNTK with the following resources:\nGeneral documentation\nPython API documentation\nEvaluation documentation (C++, C#/.NET, Python, Java)\nManual\nTutorials\nExamples\nPretrained models\nBlog\nPresentations\nLicense\nMore information\nContribute to CNTK\nFAQ\nFeedback\nDisclaimer\nDear community, \nWith our ongoing contributions to ONNX and the ONNX Runtime, we have made it easier to interoperate within the AI framework ecosystem and to access high performance, cross-platform inferencing capabilities for both traditional ML models and deep neural networks. Over the last few years we have been privileged to develop such key open-source machine learning projects, including the Microsoft Cognitive Toolkit, which has enabled its users to leverage industry-wide advancements in deep learning at scale. \nToday\u2019s 2.7 release will be the last main release of CNTK. We may have some subsequent minor releases for bug fixes, but these will be evaluated on a case-by-case basis. There are no plans for new feature development post this release. \nThe CNTK 2.7 release has full support for ONNX 1.4.1, and we encourage those seeking to operationalize their CNTK models to take advantage of ONNX and the ONNX Runtime. Moving forward, users can continue to leverage evolving ONNX innovations via the number of frameworks that support it. For example, users can natively export ONNX models from PyTorch or convert TensorFlow models to ONNX with the TensorFlow-ONNX converter. \nWe are incredibly grateful for all the support we have received from contributors and users over the years since the initial open-source release of CNTK. CNTK has enabled both Microsoft teams and external users to execute complex and large-scale workloads in all manner of deep learning applications, such as historical breakthroughs in speech recognition achieved by Microsoft Speech researchers, the originators of the framework. \nAs ONNX is increasingly employed in serving models used across Microsoft products such as Bing and Office, we are dedicated to synthesizing innovations from research with the rigorous demands of production to progress the ecosystem forward. \nAbove all, our goal is to make innovations in deep learning across the software and hardware stacks as open and accessible as possible. We will be working hard to bring both the existing strengths of CNTK and new state-of-the-art research into other open-source projects to truly broaden the reach of such technologies. \nWith gratitude, \n-- The CNTK Team \nMicrosoft Open Source Code of Conduct\nThis project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.\nNews\nYou can find more news on the official project feed\n2019-03-29. CNTK 2.7.0\nHighlights of this release\nMoved to CUDA 10 for both Windows and Linux.\nSupport advance RNN loop in ONNX export.\nExport larger than 2GB models in ONNX format.\nSupport FP16 in Brain Script train action.\nCNTK support for CUDA 10\nCNTK now supports CUDA 10. This requires an update to build environment to Visual Studio 2017 v15.9 for Windows.\nTo setup build and runtime environment on Windows:\n* Install Visual Studio 2017. Note: going forward for CUDA 10 and beyond, it is no longer required to install and run with the specific VC Tools version 14.11.\n* Install Nvidia CUDA 10\n* From PowerShell, run:\n    DevInstall.ps1\n* Start Visual Studio 2017 and open CNTK.sln.\nTo setup build and runtime environment on Linux using docker, please build Unbuntu 16.04 docker image using Dockerfiles here. For other Linux systems, please refer to the Dockerfiles to setup dependent libraries for CNTK.\nSupport advance RNN loop in ONNX export\nCNTK models with recursive loops can be exported to ONNX models with scan ops.\nExport larger than 2GB models in ONNX format\nTo export models larger than 2GB in ONNX format, use cntk.Function API:\nsave(self, filename, format=ModelFormat.CNTKv2, use_external_files_to_store_parameters=False)\nwith 'format' set to ModelFormat.ONNX and use_external_files_to_store_parameters set to True.\nIn this case, model parameters are saved in external files. Exported models shall be used with external parameter files when doing model evaluation with onnxruntime.\n2018-11-26.\nNetron now supports visualizing CNTK v1 and CNTK v2 .model files.\nProject changelog\n2018-09-17. CNTK 2.6.0\nEfficient group convolution\nThe implementation of group convolution in CNTK has been updated. The updated implementation moves away from creating a sub-graph for group convolution (using slicing and splicing), and instead uses cuDNN7 and MKL2017 APIs directly. This improves the experience both in terms of performance and model size. \nAs an example, for a single group convolution op with the following attributes:\nInput tensor (C, H, W) = (32, 128, 128)\nNumber of output channels = 32 (channel multiplier is 1)\nGroups = 32 (depth wise convolution)\nKernel size = (5, 5)\nThe comparison numbers for this single node are as follows:\n| First Header  | GPU exec. time (in millisec., 1000 run avg.) | CPU exec. time (in millisec., 1000 run avg.) | Model Size (in KB, CNTK format)\n| ------------- | ------------- | ------------- | ------------- |\n| Old implementation  | 9.349  | 41.921  | 38  |\n| New implementation  | 6.581  | 9.963  | 5  |\n| Speedup/savings   Approx.  | 30%  Approx.  | 65-75%   Approx.  | 87% |\nSequential Convolution\nThe implementation of sequential convolution in CNTK has been updated. The updated implementation creates a separate sequential convolution layer. Different from regular convolution layer, this operation convolves also on the dynamic axis(sequence), and filter_shape[0] is applied to that axis. The updated implementation supports broader cases, such as where stride > 1 for the sequence axis.\nFor example, a sequential convolution over a batch of one-channel black-and-white images. The images have the same fixed height of 640, but each with width of variable lengths. The width is then represented by sequential axis. Padding is enabled, and strides for both width and height are 2.\n\n\n\nf = SequentialConvolution((3,3), reduction_rank=0, pad=True, strides=(2,2), activation=C.relu)\nx = C.input_variable(**Sequence[Tensor[640]])\nx.shape\n     (640,)\nh = f(x)\nh.shape\n     (320,)\nf.W.shape\n     (1, 1, 3, 3)\n\n\n\nOperators\ndepth_to_space and space_to_depth\nThere is a breaking change in the depth_to_space and space_to_depth operators. These have been updated to match ONNX specification, specifically\nthe permutation for how the depth dimension is placed as blocks in the spatial dimensions, and vice-versa, has been changed. Please refer to the updated doc\nexamples for these two ops to see the change.\nTan and Atan\nAdded support for trigonometric ops Tan and Atan.\nELU\nAdded support for alpha attribute in ELU op.\nConvolution\nUpdated auto padding algorithms of Convolution to produce symmetric padding at best effort on CPU, without affecting the final convolution output values. This update increases the range of cases that could be covered by MKL API and improves the performance, E.g. ResNet50.\nDefault arguments order\nThere is a breaking change in the arguments property in CNTK python API. The default behavior has been updated to return arguments in python order instead of in C++ order. This way it will return arguments in the same order as they are fed into ops. If you wish to still get arguments in C++ order, you can simply override the global option. This change should only affect the following ops: Times, TransposeTimes, and Gemm(internal). \nBug fixes\nUpdated doc for Convolution layer to include group and dilation arguments.\nAdded improved input validation for group convolution.\nUpdated LogSoftMax to use more numerically stable implementation.\nFixed Gather op's incorrect gradient value.\nAdded validation for 'None' node in python clone substitution.\nAdded validation for padding channel axis in convolution.\nAdded CNTK native default lotusIR logger to fix the \"Attempt to use DefaultLogger\" error when loading some ONNX models.\nAdded proper initialization for ONNX TypeStrToProtoMap.\nUpdated python doctest to handle different print format for newer version numpy(version >= 1.14).\nFixed Pooling(CPU) to produce correct output values when kernel center is on padded input cells.\nONNX\nUpdates\nUpdated CNTK's ONNX import/export to use ONNX 1.2 spec.\nMajor update to how batch and sequence axes are handled in export and import. As a result, the complex scenarios and edge cases are handled accurately.\nUpdated CNTK's ONNX BatchNormalization op export/import to latest spec.\nAdded model domain to ONNX model export.\nImproved error reporting during import and export of ONNX models.\nUpdated DepthToSpace and SpaceToDepth ops to match ONNX spec on the permutation for how the depth dimension is placed as block dimension.\nAdded support for exporting alpha attribute in ELU ONNX op.\nMajor overhaul to Convolution and Pooling export. Unlike before, these ops do not export an explicit Pad op in any situation.\nMajor overhaul to ConvolutionTranspose export and import. Attributes such as output_shape, output_padding, and pads are fully supported.\nAdded support for CNTK's StopGradient as a no-op.\nAdded ONNX support for TopK op.\nAdded ONNX support for sequence ops: sequence.slice, sequence.first, sequence.last, sequence.reduce_sum, sequence.reduce_max, sequence.softmax. For these ops, there is no need to expand ONNX spec. CNTK ONNX exporter just builds computation equivalent graphs for these sequence ops.\nAdded full support for Softmax op.\nMade CNTK broadcast ops compatible with ONNX specification.\nHandle to_batch, to_sequence, unpack_batch, sequence.unpack ops in CNTK ONNX exporter.\nONNX tests to export ONNX test cases for other toolkits to run and to validate.\nFixed Hardmax/Softmax/LogSoftmax import/export.\nAdded support for Select op export.\nAdded import/export support for several trigonometric ops.\nUpdated CNTK support for ONNX MatMul op.\nUpdated CNTK support for ONNX Gemm op.\nUpdated CNTK's ONNX MeanVarianceNormalization op export/import to latest spec.\nUpdated CNTK's ONNX LayerNormalization op export/import to latest spec.\nUpdated CNTK's ONNX PRelu op export/import to latest spec.\nUpdated CNTK's ONNX Gather op export/import to latest spec.\nUpdated CNTK's ONNX ImageScaler op export/import to latest spec.\nUpdated CNTK's ONNX Reduce ops export/import to latest spec.\nUpdated CNTK's ONNX Flatten op export/import to latest spec.\nAdded CNTK support for ONNX Unsqueeze op.\nBug or minor fixes:\nUpdated LRN op to match ONNX 1.2 spec where the size attribute has the semantics of diameter, not radius. Added validation if LRN kernel size is larger than channel size.\nUpdated Min/Max import implementation to handle variadic inputs.\nFixed possible file corruption when resaving on top of existing ONNX model file.\n.Net Support\nThe Cntk.Core.Managed library has officially been converted to .Net Standard and supports .Net Core and .Net Framework applications on both Windows and Linux. Starting from this release, .Net developers should be able to restore CNTK Nuget packages using new .Net SDK style project file with package management format set to PackageReference.\nThe following C# code now works on both Windows and Linux:\n\n\n\nvar weightParameterName = \"weight\";\nvar biasParameterName = \"bias\";\nvar inputName = \"input\";\nvar outputDim = 2;\nvar inputDim = 3;\nVariable inputVariable = Variable.InputVariable(new int[] { inputDim }, DataType.Float, inputName);\nvar weightParameter = new Parameter(new int[] { outputDim, inputDim }, DataType.Float, 1, device, weightParameterName);\nvar biasParameter = new Parameter(new int[] { outputDim }, DataType.Float, 0, device, biasParameterName);\nFunction modelFunc = CNTKLib.Times(weightParameter, inputVariable) + biasParameter;\n\n\n\nFor example, simply adding an ItemGroup clause in the .csproj file of a .Net Core application is sufficient:\n     >>> \n     >>>\n     >>> \n     >>>     netcoreapp2.1\n     >>>     x64\n     >>> \n     >>>\n     >>> \n     >>>   \n     >>> \n     >>>\n     >>> \nBug or minor fixes:\nFixed C# string and char to native wstring and wchar UTF conversion issues on Linux.\nFixed multibyte and wide character conversions across the codebase.\nFixed Nuget package mechanism to pack for .Net Standard.\nFixed a memory leak issue in Value class in C# API where Dispose was not called upon object destruction.\nMisc\n2018-04-16. CNTK 2.5.1\nRepack CNTK 2.5 with third party libraries included in the bundles (Python wheel packages)\n2018-03-15. CNTK 2.5\nChange profiler details output format to be chrome://tracing\nEnable per-node timing. Working example here\n* per-node timing creates items in profiler details when profiler is enabled.\n* usage in Python:\npython\nimport cntk as C\nC.debugging.debug.set_node_timing(True)\nC.debugging.start_profiler() # optional\nC.debugging.enable_profiler() # optional\n executions\n.print_node_timing()\nC.debugging.stop_profiler()\nExample profiler details view in chrome://tracing\nCPU inference performance improvements using MKL\n* Accelerates some common tensor ops in Intel CPU inference for float32, especially for fully connected networks\n* Can be turned on/off by cntk.cntk_py.enable_cpueval_optimization()/cntk.cntk_py.disable_cpueval_optimization()\n1BitSGD incorporated into CNTK\n* 1BitSGD source code is now available with CNTK license (MIT license) under Source/1BitSGD/\n* 1bitsgd build target was merged into existing gpu target\nNew loss function: hierarchical softmax\n* Thanks @yaochengji for the contribution!\nDistributed Training with Multiple Learners\n* Trainer now accepts multiple parameter learners for distributed training. With this change, different parameters of a network can be learned by different learners in a single training session. This also facilitates distributed training for GANs. For more information, please refer to the Basic_GAN_Distributed.py and the cntk.learners.distributed_multi_learner_test.py\nOperators\n* Added MeanVarianceNormalization operator. \nBug fixes\n* Fixed convergence issue in Tutorial 201B\n* Fixed pooling/unpooling to support free dimension for sequences\n* Fixed crash in CNTKBinaryFormat deserializer when crossing sweep boundary\n* Fixed shape inference bug in RNN step function for scalar broadcasting\n* Fixed a build bug when mpi=no\n* Improved distributed training aggregation speed by increasing packing threshold, and expose the knob in V2\n* Fixed a memory leak in MKL layout\n* Fixed a bug in cntk.convert API in misc.converter.py, which prevents converting complex networks.\nONNX\n* Updates\n    * CNTK exported ONNX models are now ONNX.checker compliant. \n    * Added ONNX support for CNTK\u2019s OptimizedRNNStack operator (LSTM only).\n    * Added support for LSTM and GRU operators\n    * Added support for experimental ONNX op MeanVarianceNormalization.\n    * Added support for experimental ONNX op Identity.\n    * Added support for exporting CNTK\u2019s LayerNormalization layer using ONNX MeanVarianceNormalization op.\n* Bug or minor fixes:\n    * Axis attribute is optional in CNTK\u2019s ONNX Concat operator.\n    * Bug fix in ONNX broadcasting for scalars.\n    * Bug fix in ONNX ConvTranspose operator. \n    * Backward compatibility bug fix in LeakyReLu (argument \u2018alpha\u2019 reverted to type double).\nMisc\n* Added a new API find_by_uid() under cntk.logging.graph. \n2018-02-28. CNTK supports nightly build\nIf you prefer to use latest CNTK bits from master, use one of the CNTK nightly package.\n* Nightly packages for Windows\n* Nightly packages for Linux\nAlternatively, you can also click corresponding build badge to land to nightly build page.\n2018-01-31. CNTK 2.4\nHighlights:\n* Moved to CUDA9, cuDNN 7 and Visual Studio 2017.\n* Removed Python 3.4 support.\n* Added Volta GPU and FP16 support.\n* Better ONNX support.\n* CPU perf improvement.\n* More OPs.\nOPs\n* top_k operation: in the forward pass it computes the top (largest) k values and corresponding indices along the specified axis. In the backward pass the gradient is scattered to the top k elements (an element not in the top k gets a zero gradient).\n* gather operation now supports an axis argument\n* squeeze and expand_dims operations for easily removing and adding singleton axes\n* zeros_like and ones_like operations. In many situations you can just rely on CNTK correctly broadcasting a simple 0 or 1 but sometimes you need the actual tensor.\n* depth_to_space: Rearranges elements in the input tensor from the depth dimension into spatial blocks. Typical use of this operation is for implementing sub-pixel convolution for some image super-resolution models.\n* space_to_depth: Rearranges elements in the input tensor from the spatial dimensions to the depth dimension. It is largely the inverse of DepthToSpace.\n* sum operation: Create a new Function instance that computes element-wise sum of input tensors.\n* softsign operation: Create a new Function instance that computes the element-wise softsign of a input tensor.\n* asinh operation: Create a new Function instance that computes the element-wise asinh of a input tensor.\n* log_softmax operation: Create a new Function instance that computes the logsoftmax normalized values of a input tensor.\n* hard_sigmoid operation: Create a new Function instance that computes the hard_sigmoid normalized values of a input tensor.\n* element_and, element_not, element_or, element_xor element-wise logic operations\n* reduce_l1 operation: Computes the L1 norm of the input tensor's element along the provided axes.\n* reduce_l2 operation: Computes the L2 norm of the input tensor's element along the provided axes.\n* reduce_sum_square operation: Computes the sum square of the input tensor's element along the provided axes.\n* image_scaler operation: Alteration of image by scaling its individual values.\nONNX\n* There have been several improvements to ONNX support in CNTK.\n* Updates\n  * Updated ONNX Reshape op to handle InferredDimension.\n  * Adding producer_name and producer_version fields to ONNX models.\n  * Handling the case when neither auto_pad nor pads atrribute is specified in ONNX Conv op.\n* Bug fixes\n  * Fixed bug in ONNX Pooling op serialization\n  * Bug fix to create ONNX InputVariable with only one batch axis.\n  * Bug fixes and updates to implementation of ONNX Transpose op to match updated spec.\n  * Bug fixes and updates to implementation of ONNX Conv, ConvTranspose, and Pooling ops to match updated spec.\nOperators\n* Group convolution\n  * Fixed bug in group convolution. Output of CNTK Convolution op will change for groups > 1. More optimized implementation of group convolution is expected in the next release.\n  * Better error reporting for group convolution in Convolution layer.\nHalide Binary Convolution\n- The CNTK build can now use optional Halide libraries to build Cntk.BinaryConvolution.so/dll library that can be used with the netopt module. The library contains optimized binary convolution operators that perform better than the python based binarized convolution operators. To enable Halide in the build, please download Halide release and set HALIDE_PATH environment varibale before starting a build. In Linux, you can use ./configure --with-halide[=directory] to enable it. For more information on how to use this feature, please refer to How_to_use_network_optimization.\nSee more in the Release Notes.\nGet the Release from the CNTK Releases page.",
	"deep-learning deep-neural-networks dnn keras machine-learning ml mxnet neural-network onnx pytorch scikit-learn tensorflow": "Open Neural Network Exchange (ONNX) is an open ecosystem that empowers AI developers\nto choose the right tools as their project evolves. ONNX provides an open source format for AI models, both deep learning and traditional ML. It defines an extensible computation graph model, as well as definitions of built-in operators and standard\ndata types. Currently we focus on the capabilities needed for inferencing (scoring).\nONNX is widely supported and can be found in many frameworks, tools, and hardware. Enabling interoperability between different frameworks and streamlining the path from research to production helps increase the speed of innovation in the AI community. We invite the community to join us and further evolve ONNX.\nUse ONNX\nDocumentation of ONNX Python Package\nTutorials for creating ONNX models.\nPre-trained ONNX models\nLearn about the ONNX spec\nOverview\nONNX intermediate representation spec\nVersioning principles of the spec\nOperators documentation (development version)\nOperators documentation (latest release)\nPython API Overview\nProgramming utilities for working with ONNX Graphs\nShape and Type Inference\nGraph Optimization\nOpset Version Conversion\nContribute\nONNX is a community project. We encourage you to join the effort and contribute feedback, ideas, and code. You can participate in the Special Interest Groups and Working Groups to shape the future of ONNX.\nCheck out our contribution guide to get started.\nIf you think some operator should be added to ONNX specification, please read\nthis document.\nDiscuss\nWe encourage you to open Issues, or use Slack (If you have not joined yet, please use this link to join the group) for more real-time discussion.\nFollow Us\nStay up to date with the latest ONNX news. [Facebook] [Twitter]\nInstallation\nOfficial Python packages\nONNX released packages are published in PyPi.\npip install onnx\nWeekly packages are published in test pypi to enable experimentation and early testing.\nvcpkg packages\nonnx is in the maintenance list of vcpkg, you can easily use vcpkg to build and install it.\ngit clone https://github.com/microsoft/vcpkg.git\ncd vcpkg\n./bootstrap-vcpkg.bat # For powershell\n./bootstrap-vcpkg.sh # For bash\n./vcpkg install onnx\nConda packages\nA binary build of ONNX is available from Conda, in conda-forge:\nconda install -c conda-forge onnx\nBuild ONNX from Source\nBefore building from source uninstall any existing versions of onnx pip uninstall onnx.\nc++17 or higher C++ compiler version is required to build ONNX from source on Windows. For other platforms, please use C++11 or higher versions.\nGenerally speaking, you need to install protobuf C/C++ libraries and tools before proceeding forward. Then depending on how you installed protobuf, you need to set environment variable CMAKE_ARGS to \"-DONNX_USE_PROTOBUF_SHARED_LIBS=ON\" or \"-DONNX_USE_PROTOBUF_SHARED_LIBS=OFF\".  For example, you may need to run the following command:\nLinux:\nbash\nexport CMAKE_ARGS=\"-DONNX_USE_PROTOBUF_SHARED_LIBS=ON\"\nWindows:\nbat\nset CMAKE_ARGS=\"-DONNX_USE_PROTOBUF_SHARED_LIBS=ON\"\nThe ON/OFF depends on what kind of protobuf library you have. Shared libraries are files ending with .dll/.so/.dylib. Static libraries are files ending with .a/*.lib. This option depends on how you get your protobuf library and how it was built. And it is default OFF. You don't need to run the commands above if you'd prefer to use a static protobuf library.\nWindows\nIf you are building ONNX from source, it is recommended that you also build Protobuf locally as a static library. The version distributed with conda-forge is a DLL, but ONNX expects it to be a static library. Building protobuf locally also lets you control the version of protobuf. The tested and recommended version is 3.20.2.\nThe instructions in this README assume you are using Visual Studio.  It is recommended that you run all the commands from a shell started from \"x64 Native Tools Command Prompt for VS 2019\" and keep the build system generator for cmake (e.g., cmake -G \"Visual Studio 16 2019\") consistent while building protobuf as well as ONNX.\nYou can get protobuf by running the following commands:\nbat\ngit clone https://github.com/protocolbuffers/protobuf.git\ncd protobuf\ngit checkout v3.20.2\ncd cmake\ncmake -G \"Visual Studio 16 2019\" -A x64 -DCMAKE_INSTALL_PREFIX= -Dprotobuf_MSVC_STATIC_RUNTIME=OFF -Dprotobuf_BUILD_SHARED_LIBS=OFF -Dprotobuf_BUILD_TESTS=OFF -Dprotobuf_BUILD_EXAMPLES=OFF .\nmsbuild protobuf.sln /m /p:Configuration=Release\nmsbuild INSTALL.vcxproj /p:Configuration=Release\nThen it will be built as a static library and installed to . Please add the bin directory(which contains protoc.exe) to your PATH.\nbat\nset PATH=/bin;%PATH%\nPlease note: if your protobuf_install_dir contains spaces, do not add quotation marks around it.\nAlternative: if you don't want to change your PATH, you can set ONNX_PROTOC_EXECUTABLE instead.\nbat\nset CMAKE_ARGS=-DONNX_PROTOC_EXECUTABLE=\nThen you can build ONNX as:\ngit clone https://github.com/onnx/onnx.git\ncd onnx\ngit submodule update --init --recursive\nprefer lite proto\nset CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON\npip install -e .\nLinux\nFirst, you need to install protobuf. The minimum Protobuf compiler (protoc) version required by ONNX is 3.0.0. Please note that old protoc versions might not work with CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON.\nUbuntu 18.04 (and newer) users may choose to install protobuf via\nbash\napt-get install python3-pip python3-dev libprotobuf-dev protobuf-compiler\nIn this case, it is required to add -DONNX_USE_PROTOBUF_SHARED_LIBS=ON to CMAKE_ARGS in the ONNX build step.\nA more general way is to build and install it from source. See the instructions below for more details.\nInstalling Protobuf from source \nDebian/Ubuntu:\n  bash\n    git clone https://github.com/protocolbuffers/protobuf.git\n    cd protobuf\n    git checkout v3.20.2\n    git submodule update --init --recursive\n    mkdir build_source && cd build_source\n    cmake ../cmake -Dprotobuf_BUILD_SHARED_LIBS=OFF -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_INSTALL_SYSCONFDIR=/etc -DCMAKE_POSITION_INDEPENDENT_CODE=ON -Dprotobuf_BUILD_TESTS=OFF -DCMAKE_BUILD_TYPE=Release\n    make -j$(nproc)\n    make install\nCentOS/RHEL/Fedora:\n  bash\n    git clone https://github.com/protocolbuffers/protobuf.git\n    cd protobuf\n    git checkout v3.20.2\n    git submodule update --init --recursive\n    mkdir build_source && cd build_source\n    cmake ../cmake  -DCMAKE_INSTALL_LIBDIR=lib64 -Dprotobuf_BUILD_SHARED_LIBS=OFF -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_INSTALL_SYSCONFDIR=/etc -DCMAKE_POSITION_INDEPENDENT_CODE=ON -Dprotobuf_BUILD_TESTS=OFF -DCMAKE_BUILD_TYPE=Release\n    make -j$(nproc)\n    make install\nHere \"-DCMAKE_POSITION_INDEPENDENT_CODE=ON\" is crucial. By default static libraries are built without \"-fPIC\" flag, they are not position independent code. But shared libraries must be position independent code. Python C/C++ extensions(like ONNX) are shared libraries. So if a static library was not built with \"-fPIC\", it can't be linked to such a shared library.\nOnce build is successful, update PATH to include protobuf paths.\nThen you can build ONNX as:\ngit clone https://github.com/onnx/onnx.git\ncd onnx\ngit submodule update --init --recursive\nOptional: prefer lite proto\nexport CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON\npip install -e .\nMac\nexport NUM_CORES=sysctl -n hw.ncpu\nbrew update\nbrew install autoconf && brew install automake\nwget https://github.com/protocolbuffers/protobuf/releases/download/v3.20.2/protobuf-cpp-3.20.2.tar.gz\ntar -xvf protobuf-cpp-3.20.2.tar.gz\ncd protobuf-3.20.2\nmkdir build_source && cd build_source\ncmake ../cmake -Dprotobuf_BUILD_SHARED_LIBS=OFF -DCMAKE_POSITION_INDEPENDENT_CODE=ON -Dprotobuf_BUILD_TESTS=OFF -DCMAKE_BUILD_TYPE=Release\nmake -j${NUM_CORES}\nmake install\nOnce build is successful, update PATH to include protobuf paths.\nThen you can build ONNX as:\ngit clone --recursive https://github.com/onnx/onnx.git\ncd onnx\nOptional: prefer lite proto\nset CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON\npip install -e .\nVerify Installation\nAfter installation, run\npython -c \"import onnx\"\nto verify it works.\nCommon Build Options\nFor full list refer to CMakeLists.txt\nEnvironment variables\n* USE_MSVC_STATIC_RUNTIME should be 1 or 0, not ON or OFF. When set to 1 onnx links statically to runtime library.\nDefault: USE_MSVC_STATIC_RUNTIME=0\nDEBUG should be 0 or 1. When set to 1 onnx is built in debug mode. or debug versions of the dependencies, you need to open the CMakeLists file and append a letter d at the end of the package name lines. For example, NAMES protobuf-lite would become NAMES protobuf-lited.\nDefault: Debug=0\nCMake variables\n* ONNX_USE_PROTOBUF_SHARED_LIBS should be ON or OFF.\nDefault: ONNX_USE_PROTOBUF_SHARED_LIBS=OFF USE_MSVC_STATIC_RUNTIME=0\nONNX_USE_PROTOBUF_SHARED_LIBS determines how onnx links to protobuf libraries.\n    - When set to ON - onnx will dynamically link to protobuf shared libs, PROTOBUF_USE_DLLS will be defined as described here, Protobuf_USE_STATIC_LIBS will be set to OFF and USE_MSVC_STATIC_RUNTIME must be 0.\n    - When set to OFF - onnx will link statically to protobuf, and Protobuf_USE_STATIC_LIBS will be set to ON (to force the use of the static libraries) and USE_MSVC_STATIC_RUNTIME can be 0 or 1.\nONNX_USE_LITE_PROTO should be ON or OFF. When set to ON onnx uses lite protobuf instead of full protobuf.\nDefault: ONNX_USE_LITE_PROTO=OFF\nONNX_WERROR should be ON or OFF. When set to ON warnings are treated as errors.\nDefault: ONNX_WERROR=OFF in local builds, ON in CI and release pipelines.\nCommon Errors\nNote: the import onnx command does not work from the source checkout directory; in this case you'll see ModuleNotFoundError: No module named 'onnx.onnx_cpp2py_export'. Change into another directory to fix this error.\nIf you run into any issues while building Protobuf as a static library, please ensure that shared Protobuf libraries, like libprotobuf, are not installed on your device or in the conda environment. If these shared libraries exist, either remove them to build Protobuf from source as a static library, or skip the Protobuf build from source to use the shared version directly.\nIf you run into any issues while building ONNX from source, and your error message reads, \"Could not find pythonXX.lib\", ensure that you have consistent Python versions for common commands, such as python and pip. Clean all existing build files and rebuild ONNX again.\nTesting\nONNX uses pytest as test driver. In order to run tests, you will first need to install pytest:\npip install pytest nbval\nAfter installing pytest, use the following command to run tests.\npytest\nDevelopment\nCheck out the contributor guide for instructions.\nLicense\nApache License v2.0\nCode of Conduct\nONNX Open Source Code of Conduct",
	"awesome awesome-list deep-learning deep-learning-tutorial deep-neural-networks deeplearning list machine-learning machinelearning neural-network neural-networks": "Machine Learning & Deep Learning Tutorials \nThis repository contains a topic-wise curated list of Machine Learning and Deep Learning tutorials, articles and other resources. Other awesome lists can be found in this list.\nIf you want to contribute to this list, please read Contributing Guidelines.\nCurated list of R tutorials for Data Science, NLP and Machine Learning.\nCurated list of Python tutorials for Data Science, NLP and Machine Learning.\nContents\nIntroduction\nInterview Resources\nArtificial Intelligence\nGenetic Algorithms\nStatistics\nUseful Blogs\nResources on Quora\nResources on Kaggle\nCheat Sheets\nClassification\nLinear Regression\nLogistic Regression\nModel Validation using Resampling\nCross Validation\nBootstraping\nDeep Learning\nFrameworks\nFeed Forward Networks\nRecurrent Neural Nets, LSTM, GRU\nRestricted Boltzmann Machine, DBNs\nAutoencoders\nConvolutional Neural Nets\nGraph Representation Learning\nNatural Language Processing\nTopic Modeling, LDA\nWord2Vec\nComputer Vision\nSupport Vector Machine\nReinforcement Learning\nDecision Trees\nRandom Forest / Bagging\nBoosting\nEnsembles\nStacking Models\nVC Dimension\nBayesian Machine Learning\nSemi Supervised Learning\nOptimizations\nOther Useful Tutorials\nIntroduction\nMachine Learning Course by Andrew Ng (Stanford University)\nAI/ML YouTube Courses\nCurated List of Machine Learning Resources\nIn-depth introduction to machine learning in 15 hours of expert videos\nAn Introduction to Statistical Learning\nList of Machine Learning University Courses\nMachine Learning for Software Engineers\nDive into Machine Learning\nA curated list of awesome Machine Learning frameworks, libraries and software\nA curated list of awesome data visualization libraries and resources.\nAn awesome Data Science repository to learn and apply for real world problems\nThe Open Source Data Science Masters\nMachine Learning FAQs on Cross Validated\nMachine Learning algorithms that you should always have a strong understanding of\nDifference between Linearly Independent, Orthogonal, and Uncorrelated Variables\nList of Machine Learning Concepts\nSlides on Several Machine Learning Topics\nMIT Machine Learning Lecture Slides\nComparison Supervised Learning Algorithms\nLearning Data Science Fundamentals\nMachine Learning mistakes to avoid\nStatistical Machine Learning Course\nTheAnalyticsEdge edX Notes and Codes\nHave Fun With Machine Learning\nTwitter's Most Shared #machineLearning Content From The Past 7 Days\nGrokking Machine Learning\nInterview Resources\n41 Essential Machine Learning Interview Questions (with answers)\nHow can a computer science graduate student prepare himself for data scientist interviews?\nHow do I learn Machine Learning?\nFAQs about Data Science Interviews\nWhat are the key skills of a data scientist?\nThe Big List of DS/ML Interview Resources\nArtificial Intelligence\nAwesome Artificial Intelligence (GitHub Repo)\nUC Berkeley CS188 Intro to AI, Lecture Videos, 2\nProgramming Community Curated Resources for learning Artificial Intelligence \nMIT 6.034 Artificial Intelligence Lecture Videos, Complete Course\nedX course | Klein & Abbeel\nUdacity Course | Norvig & Thrun\nTED talks on AI\nGenetic Algorithms\nGenetic Algorithms Wikipedia Page\nSimple Implementation of Genetic Algorithms in Python (Part 1), Part 2\nGenetic Algorithms vs Artificial Neural Networks\nGenetic Algorithms Explained in Plain English\nGenetic Programming\nGenetic Programming in Python (GitHub)\nGenetic Alogorithms vs Genetic Programming (Quora), StackOverflow\nStatistics\nStat Trek Website - A dedicated website to teach yourselves Statistics\nLearn Statistics Using Python - Learn Statistics using an application-centric programming approach\nStatistics for Hackers | Slides | @jakevdp - Slides by Jake VanderPlas\nOnline Statistics Book - An Interactive Multimedia Course for Studying Statistics\nWhat is a Sampling Distribution?\nTutorials\nAP Statistics Tutorial\nStatistics and Probability Tutorial\nMatrix Algebra Tutorial\nWhat is an Unbiased Estimator?\nGoodness of Fit Explained\nWhat are QQ Plots?\nOpenIntro Statistics - Free PDF textbook\nUseful Blogs\nEdwin Chen's Blog - A blog about Math, stats, ML, crowdsourcing, data science\nThe Data School Blog - Data science for beginners!\nML Wave - A blog for Learning Machine Learning\nAndrej Karpathy - A blog about Deep Learning and Data Science in general\nColah's Blog - Awesome Neural Networks Blog\nAlex Minnaar's Blog - A blog about Machine Learning and Software Engineering\nStatistically Significant - Andrew Landgraf's Data Science Blog\nSimply Statistics - A blog by three biostatistics professors\nYanir Seroussi's Blog - A blog about Data Science and beyond\nfastML - Machine learning made easy\nTrevor Stephens Blog - Trevor Stephens Personal Page\nno free hunch | kaggle - The Kaggle Blog about all things Data Science\nA Quantitative Journey | outlace -  learning quantitative applications\nr4stats - analyze the world of data science, and to help people learn to use R\nVariance Explained - David Robinson's Blog\nAI Junkie - a blog about Artificial Intellingence\nDeep Learning Blog by Tim Dettmers - Making deep learning accessible\nJ Alammar's Blog- Blog posts about Machine Learning and Neural Nets\nAdam Geitgey - Easiest Introduction to machine learning\nEthen's Notebook Collection - Continuously updated machine learning documentations (mainly in Python3). Contents include educational implementation of machine learning algorithms from scratch and open-source library usage\nResources on Quora\nMost Viewed Machine Learning writers\nData Science Topic on Quora\nWilliam Chen's Answers\nMichael Hochster's Answers\nRicardo Vladimiro's Answers\nStorytelling with Statistics\nData Science FAQs on Quora\nMachine Learning FAQs on Quora\nKaggle Competitions WriteUp\nHow to almost win Kaggle Competitions\nConvolution Neural Networks for EEG detection\nFacebook Recruiting III Explained\nPredicting CTR with Online ML\nHow to Rank 10% in Your First Kaggle Competition\nCheat Sheets\nProbability Cheat Sheet,\nSource\nMachine Learning Cheat Sheet\nML Compiled\nClassification\nDoes Balancing Classes Improve Classifier Performance?\nWhat is Deviance?\nWhen to choose which machine learning classifier?\nWhat are the advantages of different classification algorithms?\nROC and AUC Explained (related video)\nAn introduction to ROC analysis\nSimple guide to confusion matrix terminology\nLinear Regression\nGeneral\nAssumptions of Linear Regression, Stack Exchange\nLinear Regression Comprehensive Resource\nApplying and Interpreting Linear Regression\nWhat does having constant variance in a linear regression model mean?\nDifference between linear regression on y with x and x with y\nIs linear regression valid when the dependant variable is not normally distributed?\nMulticollinearity and VIF\nDummy Variable Trap | Multicollinearity\nDealing with multicollinearity using VIFs\nResidual Analysis\nInterpreting plot.lm() in R\nHow to interpret a QQ plot?\nInterpreting Residuals vs Fitted Plot\nOutliers\nHow should outliers be dealt with?\nElastic Net\nRegularization and Variable Selection via the\nElastic Net\nLogistic Regression\nLogistic Regression Wiki\nGeometric Intuition of Logistic Regression\nObtaining predicted categories (choosing threshold)\nResiduals in logistic regression\nDifference between logit and probit models, Logistic Regression Wiki, Probit Model Wiki\nPseudo R2 for Logistic Regression, How to calculate, Other Details\nGuide to an in-depth understanding of logistic regression\nModel Validation using Resampling\nResampling Explained\nPartioning data set in R\nImplementing hold-out Validaion in R, 2\nCross Validation\nHow to use cross-validation in predictive modeling\nTraining with Full dataset after CV?\nWhich CV method is best?\nVariance Estimates in k-fold CV\nIs CV a subsitute for Validation Set?\nChoice of k in k-fold CV\nCV for ensemble learning\nk-fold CV in R\nGood Resources\nOverfitting and Cross Validation\nPreventing Overfitting the Cross Validation Data | Andrew Ng\nOver-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation\nCV for detecting and preventing Overfitting\nHow does CV overcome the Overfitting Problem\nBootstrapping\nWhy Bootstrapping Works?\nGood Animation\nExample of Bootstapping\nUnderstanding Bootstapping for Validation and Model Selection\nCross Validation vs Bootstrap to estimate prediction error, Cross-validation vs .632 bootstrapping to evaluate classification performance\nDeep Learning\nfast.ai - Practical Deep Learning For Coders\nfast.ai - Cutting Edge Deep Learning For Coders\nA curated list of awesome Deep Learning tutorials, projects and communities\nDeep Learning Papers Reading Roadmap\nLots of Deep Learning Resources\nInteresting Deep Learning and NLP Projects (Stanford), Website\nCore Concepts of Deep Learning\nUnderstanding Natural Language with Deep Neural Networks Using Torch\nStanford Deep Learning Tutorial\nDeep Learning FAQs on Quora\nGoogle+ Deep Learning Page\nRecent Reddit AMAs related to Deep Learning, Another AMA\nWhere to Learn Deep Learning?\nDeep Learning nvidia concepts\nIntroduction to Deep Learning Using Python (GitHub), Good Introduction Slides\nVideo Lectures Oxford 2015, Video Lectures Summer School Montreal\nDeep Learning Software List\nHacker's guide to Neural Nets\nTop arxiv Deep Learning Papers explained\nGeoff Hinton Youtube Vidoes on Deep Learning\nAwesome Deep Learning Reading List\nDeep Learning Comprehensive Website, Software\ndeeplearning Tutorials\nAWESOME! Deep Learning Tutorial\nDeep Learning Basics\nIntuition Behind Backpropagation\nStanford Tutorials\nTrain, Validation & Test in Artificial Neural Networks\nArtificial Neural Networks Tutorials\nNeural Networks FAQs on Stack Overflow\nDeep Learning Tutorials on deeplearning.net\nNeural Networks and Deep Learning Online Book\nNeural Machine Translation\nMachine Translation Reading List\nIntroduction to Neural Machine Translation with GPUs (part 1), Part 2, Part 3\nDeep Speech: Accurate Speech Recognition with GPU-Accelerated Deep Learning\nDeep Learning Frameworks\nTorch vs. Theano\ndl4j vs. torch7 vs. theano\nDeep Learning Libraries by Language\nTheano\nWebsite\nTheano Introduction\nTheano Tutorial\nGood Theano Tutorial\nLogistic Regression using Theano for classifying digits\nMLP using Theano\nCNN using Theano\nRNNs using Theano\nLSTM for Sentiment Analysis in Theano\nRBM using Theano\nDBNs using Theano\nAll Codes\nDeep Learning Implementation Tutorials - Keras and Lasagne\nTorch\nTorch ML Tutorial, Code\nIntro to Torch\nLearning Torch GitHub Repo\nAwesome-Torch (Repository on GitHub)\nMachine Learning using Torch Oxford Univ, Code\nTorch Internals Overview\nTorch Cheatsheet\nUnderstanding Natural Language with Deep Neural Networks Using Torch\nCaffe\nDeep Learning for Computer Vision with Caffe and cuDNN\nTensorFlow\nWebsite\nTensorFlow Examples for Beginners\nStanford Tensorflow for Deep Learning Research Course\nGitHub Repo\nSimplified Scikit-learn Style Interface to TensorFlow\nLearning TensorFlow GitHub Repo\nBenchmark TensorFlow GitHub\nAwesome TensorFlow List\nTensorFlow Book\nAndroid TensorFlow Machine Learning Example\nGitHub Repo\n        - Creating Custom Model For Android Using TensorFlow\nGitHub Repo \nFeed Forward Networks\nA Quick Introduction to Neural Networks\nImplementing a Neural Network from scratch, Code\nSpeeding up your Neural Network with Theano and the gpu, Code\nBasic ANN Theory\nRole of Bias in Neural Networks\nChoosing number of hidden layers and nodes,2,3\nBackpropagation in Matrix Form\nANN implemented in C++ | AI Junkie\nSimple Implementation\nNN for Beginners\nRegression and Classification with NNs (Slides)\nAnother Intro\nRecurrent and LSTM Networks\nawesome-rnn: list of resources (GitHub Repo)\nRecurrent Neural Net Tutorial Part 1, Part 2, Part 3, Code\nNLP RNN Representations\nThe Unreasonable effectiveness of RNNs, Torch Code, Python Code\nIntro to RNN, LSTM\nAn application of RNN\nOptimizing RNN Performance\nSimple RNN\nAuto-Generating Clickbait with RNN\nSequence Learning using RNN (Slides)\nMachine Translation using RNN (Paper)\nMusic generation using RNNs (Keras)\nUsing RNN to create on-the-fly dialogue (Keras)\nLong Short Term Memory (LSTM)\nUnderstanding LSTM Networks\nLSTM explained\nBeginner\u2019s Guide to LSTM\nImplementing LSTM from scratch, Python/Theano code\nTorch Code for character-level language models using LSTM\nLSTM for Kaggle EEG Detection competition (Torch Code)\nLSTM for Sentiment Analysis in Theano\nDeep Learning for Visual Q&A | LSTM | CNN, Code\nComputer Responds to email using LSTM | Google\nLSTM dramatically improves Google Voice Search, Another Article\nUnderstanding Natural Language with LSTM Using Torch\nTorch code for Visual Question Answering using a CNN+LSTM model\nLSTM for Human Activity Recognition\nGated Recurrent Units (GRU)\nLSTM vs GRU\nTime series forecasting with Sequence-to-Sequence (seq2seq) rnn models\nRecursive Neural Network (not Recurrent)\nRecursive Neural Tensor Network (RNTN)\nword2vec, DBN, RNTN for Sentiment Analysis \nRestricted Boltzmann Machine\nBeginner's Guide about RBMs\nAnother Good Tutorial\nIntroduction to RBMs\nHinton's Guide to Training RBMs\nRBMs in R\nDeep Belief Networks Tutorial\nword2vec, DBN, RNTN for Sentiment Analysis \nAutoencoders: Unsupervised (applies BackProp after setting target = input)\nAndrew Ng Sparse Autoencoders pdf\nDeep Autoencoders Tutorial\nDenoising Autoencoders, Theano Code\nStacked Denoising Autoencoders\nConvolutional Neural Networks\nAn Intuitive Explanation of Convolutional Neural Networks\nAwesome Deep Vision: List of Resources (GitHub)\nIntro to CNNs\nUnderstanding CNN for NLP\nStanford Notes, Codes, GitHub\nJavaScript Library (Browser Based) for CNNs\nUsing CNNs to detect facial keypoints\nDeep learning to classify business photos at Yelp\nInterview with Yann LeCun | Kaggle\nVisualising and Understanding CNNs\nNetwork Representation Learning\nAwesome Graph Embedding\nAwesome Network Embedding\nNetwork Representation Learning Papers\nKnowledge Representation Learning Papers\nGraph Based Deep Learning Literature\nNatural Language Processing\nA curated list of speech and natural language processing resources\nUnderstanding Natural Language with Deep Neural Networks Using Torch\ntf-idf explained\nInteresting Deep Learning NLP Projects Stanford, Website\nThe Stanford NLP Group\nNLP from Scratch | Google Paper\nGraph Based Semi Supervised Learning for NLP\nBag of Words\nClassification text with Bag of Words\nTopic Modeling\nTopic Modeling Wikipedia \nProbabilistic Topic Models Princeton PDF\nLDA Wikipedia, LSA Wikipedia, Probabilistic LSA Wikipedia\nWhat is a good explanation of Latent Dirichlet Allocation (LDA)?\nIntroduction to LDA, Another good explanation\nThe LDA Buffet - Intuitive Explanation\nYour Guide to Latent Dirichlet Allocation (LDA)\nDifference between LSI and LDA\nOriginal LDA Paper\nalpha and beta in LDA\nIntuitive explanation of the Dirichlet distribution\ntopicmodels: An R Package for Fitting Topic Models\nTopic modeling made just simple enough\nOnline LDA, Online LDA with Spark\nLDA in Scala, Part 2\nSegmentation of Twitter Timelines via Topic Modeling\nTopic Modeling of Twitter Followers\nMultilingual Latent Dirichlet Allocation (LDA). (Tutorial here)\nDeep Belief Nets for Topic Modeling\nGaussian LDA for Topic Models with Word Embeddings\nPython\nSeries of lecture notes for probabilistic topic models written in ipython notebook\nImplementation of various topic models in Python\nword2vec\nGoogle word2vec\nBag of Words Model Wiki\nword2vec Tutorial\nA closer look at Skip Gram Modeling\nSkip Gram Model Tutorial, CBoW Model\nWord Vectors Kaggle Tutorial Python, Part 2\nMaking sense of word2vec\nword2vec explained on deeplearning4j\nQuora word2vec\nOther Quora Resources, 2, 3\nword2vec, DBN, RNTN for Sentiment Analysis \nText Clustering\nHow string clustering works\nLevenshtein distance for measuring the difference between two sequences\nText clustering with Levenshtein distances\nText Classification\nClassification Text with Bag of Words\nNamed Entity Recognitation \nStanford Named Entity Recognizer (NER)\nNamed Entity Recognition: Applications and Use Cases- Towards Data Science\nLanguage learning with NLP and reinforcement learning\nKaggle Tutorial Bag of Words and Word vectors, Part 2, Part 3\nWhat would Shakespeare say (NLP Tutorial)\nA closer look at Skip Gram Modeling\nComputer Vision\nAwesome computer vision (github)\nAwesome deep vision (github)\nSupport Vector Machine\nHighest Voted Questions about SVMs on Cross Validated\nHelp me Understand SVMs!\nSVM in Layman's terms\nHow does SVM Work | Comparisons\nA tutorial on SVMs\nPractical Guide to SVC, Slides\nIntroductory Overview of SVMs\nComparisons\nSVMs > ANNs, ANNs > SVMs, Another Comparison\nTrees > SVMs\nKernel Logistic Regression vs SVM\nLogistic Regression vs SVM, 2, 3\nOptimization Algorithms in Support Vector Machines\nVariable Importance from SVM\nSoftware\nLIBSVM\nIntro to SVM in R\nKernels\nWhat are Kernels in ML and SVM?\nIntuition Behind Gaussian Kernel in SVMs?\nProbabilities post SVM\nPlatt's Probabilistic Outputs for SVM\nPlatt Calibration Wiki\nWhy use Platts Scaling\nClassifier Classification with Platt's Scaling\nReinforcement Learning\nAwesome Reinforcement Learning (GitHub)\nRL Tutorial Part 1, Part 2\nDecision Trees\nWikipedia Page - Lots of Good Info\nFAQs about Decision Trees\nBrief Tour of Trees and Forests\nTree Based Models in R\nHow Decision Trees work?\nWeak side of Decision Trees\nThorough Explanation and different algorithms\nWhat is entropy and information gain in the context of building decision trees?\nSlides Related to Decision Trees\nHow do decision tree learning algorithms deal with missing values?\nUsing Surrogates to Improve Datasets with Missing Values\nGood Article\nAre decision trees almost always binary trees?\nPruning Decision Trees, Grafting of Decision Trees\nWhat is Deviance in context of Decision Trees?\nDiscover structure behind data with decision trees - Grow and plot a decision tree to automatically figure out hidden rules in your data\nComparison of Different Algorithms\nCART vs CTREE\nComparison of complexity or performance\nCHAID vs CART , CART vs CHAID\nGood Article on comparison\nCART\nRecursive Partitioning Wikipedia\nCART Explained\nHow to measure/rank \u201cvariable importance\u201d when using CART?\nPruning a Tree in R\nDoes rpart use multivariate splits by default?\nFAQs about Recursive Partitioning\nCTREE\nparty package in R\nShow volumne in each node using ctree in R\nHow to extract tree structure from ctree function?\nCHAID\nWikipedia Artice on CHAID\nBasic Introduction to CHAID\nGood Tutorial on CHAID\nMARS\nWikipedia Article on MARS\nProbabilistic Decision Trees\nBayesian Learning in Probabilistic Decision Trees\nProbabilistic Trees Research Paper\nRandom Forest / Bagging\nAwesome Random Forest (GitHub)**\nHow to tune RF parameters in practice?\nMeasures of variable importance in random forests\nCompare R-squared from two different Random Forest models\nOOB Estimate Explained | RF vs LDA\nEvaluating Random Forests for Survival Analysis Using Prediction Error Curve\nWhy doesn't Random Forest handle missing values in predictors?\nHow to build random forests in R with missing (NA) values?\nFAQs about Random Forest, More FAQs\nObtaining knowledge from a random forest\nSome Questions for R implementation, 2, 3\nBoosting\nBoosting for Better Predictions\nBoosting Wikipedia Page\nIntroduction to Boosted Trees | Tianqi Chen\nGradient Boosting Machine\nGradiet Boosting Wiki\nGuidelines for GBM parameters in R, Strategy to set parameters\nMeaning of Interaction Depth, 2\nRole of n.minobsinnode parameter of GBM in R\nGBM in R\nFAQs about GBM\nGBM vs xgboost\nxgboost\nxgboost tuning kaggle\nxgboost vs gbm\nxgboost survey\nPractical XGBoost in Python online course (free)\nAdaBoost\nAdaBoost Wiki, Python Code\nAdaBoost Sparse Input Support\nadaBag R package\nTutorial\nCatBoost\nCatBoost Documentation\nBenchmarks\nTutorial\nGitHub Project\nCatBoost vs. Light GBM vs. XGBoost\nEnsembles\nWikipedia Article on Ensemble Learning\nKaggle Ensembling Guide\nThe Power of Simple Ensembles\nEnsemble Learning Intro\nEnsemble Learning Paper\nEnsembling models with R, Ensembling Regression Models in R, Intro to Ensembles in R\nEnsembling Models with caret\nBagging vs Boosting vs Stacking\nGood Resources | Kaggle Africa Soil Property Prediction\nBoosting vs Bagging\nResources for learning how to implement ensemble methods\nHow are classifications merged in an ensemble classifier?\nStacking Models\nStacking, Blending and Stacked Generalization\nStacked Generalization (Stacking)\nStacked Generalization: when does it work?\nStacked Generalization Paper\nVapnik\u2013Chervonenkis Dimension\nWikipedia article on VC Dimension\nIntuitive Explanantion of VC Dimension\nVideo explaining VC Dimension\nIntroduction to VC Dimension\nFAQs about VC Dimension\nDo ensemble techniques increase VC-dimension?\nBayesian Machine Learning\nBayesian Methods for Hackers (using pyMC)\nShould all Machine Learning be Bayesian?\nTutorial on Bayesian Optimisation for Machine Learning\nBayesian Reasoning and Deep Learning, Slides\nBayesian Statistics Made Simple\nKalman & Bayesian Filters in Python\nMarkov Chain Wikipedia Page\nSemi Supervised Learning\nWikipedia article on Semi Supervised Learning\nTutorial on Semi Supervised Learning\nGraph Based Semi Supervised Learning for NLP\nTaxonomy\nVideo Tutorial Weka\nUnsupervised, Supervised and Semi Supervised learning\nResearch Papers 1, 2, 3\nOptimization\nMean Variance Portfolio Optimization with R and Quadratic Programming\nAlgorithms for Sparse Optimization and Machine Learning\nOptimization Algorithms in Machine Learning, Video Lecture\nOptimization Algorithms for Data Analysis\nVideo Lectures on Optimization\nOptimization Algorithms in Support Vector Machines\nThe Interplay of Optimization and Machine Learning Research\nHyperopt tutorial for Optimizing Neural Networks\u2019 Hyperparameters\nOther Tutorials\nFor a collection of Data Science Tutorials using R, please refer to this list.\nFor a collection of Data Science Tutorials using Python, please refer to this list.",
	"datasets deep-learning deep-neural-networks front-end-development graphical-user-interface": "pix2code\nGenerating Code from a Graphical User Interface Screenshot\nA video demo of the system can be seen here\nThe paper is available at https://arxiv.org/abs/1705.07962\nOfficial research page: https://uizard.io/research#pix2code\nAbstract\nTransforming a graphical user interface screenshot created by a designer into computer code is a typical task conducted by a developer in order to build customized software, websites, and mobile applications. In this paper, we show that deep learning methods can be leveraged to train a model end-to-end to automatically generate code from a single input image with over 77% of accuracy for three different platforms (i.e. iOS, Android and web-based technologies).\nCitation\n@article{beltramelli2017pix2code,\n  title={pix2code: Generating Code from a Graphical User Interface Screenshot},\n  author={Beltramelli, Tony},\n  journal={arXiv preprint arXiv:1705.07962},\n  year={2017}\n}\nDisclaimer\nThe following software is shared for educational purposes only. The author and its affiliated institution are not responsible in any manner whatsoever for any damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of the use or inability to use this software.\nThe project pix2code is a research project demonstrating an application of deep neural networks to generate code from visual inputs.\nThe current implementation is not, in any way, intended, nor able to generate code in a real-world context.\nWe could not emphasize enough that this project is experimental and shared for educational purposes only.\nBoth the source code and the datasets are provided to foster future research in machine intelligence and are not designed for end users.\nSetup\nPrerequisites\nPython 2 or 3\npip\nInstall dependencies\nsh\npip install -r  requirements.txt\nUsage\nPrepare the data:\nsh\nreassemble and unzip the data\ncd datasets\nzip -F pix2code_datasets.zip --out datasets.zip\nunzip datasets.zip\ncd ../model\nsplit training set and evaluation set while ensuring no training example in the evaluation set\nusage: build_datasets.py  \n./build_datasets.py ../datasets/ios/all_data\n./build_datasets.py ../datasets/android/all_data\n./build_datasets.py ../datasets/web/all_data\ntransform images (normalized pixel values and resized pictures) in training dataset to numpy arrays (smaller files if you need to upload the set to train your model in the cloud)\nusage: convert_imgs_to_arrays.py  \n./convert_imgs_to_arrays.py ../datasets/ios/training_set ../datasets/ios/training_features\n./convert_imgs_to_arrays.py ../datasets/android/training_set ../datasets/android/training_features\n./convert_imgs_to_arrays.py ../datasets/web/training_set ../datasets/web/training_features\nTrain the model:\nsh\nmkdir bin\ncd model\nprovide input path to training data and output path to save trained model and metadata\nusage: train.py    \n./train.py ../datasets/web/training_set ../bin\ntrain on images pre-processed as arrays\n./train.py ../datasets/web/training_features ../bin\ntrain with generator to avoid having to fit all the data in memory (RECOMMENDED)\n./train.py ../datasets/web/training_features ../bin 1\ntrain on top of pretrained weights\n./train.py ../datasets/web/training_features ../bin 1 ../bin/pix2code.h5\nGenerate code for batch of GUIs:\nsh\nmkdir code\ncd model\ngenerate DSL code (.gui file), the default search method is greedy\nusage: generate.py     \n./generate.py ../bin pix2code ../gui_screenshots ../code\nequivalent to command above\n./generate.py ../bin pix2code ../gui_screenshots ../code greedy\ngenerate DSL code with beam search and a beam width of size 3\n./generate.py ../bin pix2code ../gui_screenshots ../code 3\nGenerate code for a single GUI image:\nsh\nmkdir code\ncd model\ngenerate DSL code (.gui file), the default search method is greedy\nusage: sample.py     \n./sample.py ../bin pix2code ../test_gui.png ../code\nequivalent to command above\n./sample.py ../bin pix2code ../test_gui.png ../code greedy\ngenerate DSL code with beam search and a beam width of size 3\n./sample.py ../bin pix2code ../test_gui.png ../code 3\nCompile generated code to target language:\nsh\ncd compiler\ncompile .gui file to Android XML UI\n./android-compiler.py .gui\ncompile .gui file to iOS Storyboard\n./ios-compiler.py .gui\ncompile .gui file to HTML/CSS (Bootstrap style)\n./web-compiler.py .gui\nFAQ\nWill pix2code supports other target platforms/languages?\nNo, pix2code is only a research project and will stay in the state described in the paper for consistency reasons.\nThis project is really just a toy example but you are of course more than welcome to fork the repo and experiment yourself with other target platforms/languages.\nWill I be able to use pix2code for my own frontend projects?\nNo, pix2code is experimental and won't work for your specific use cases.\nHow is the model performance measured?\nThe accuracy/error reported in the paper is measured at the DSL level by comparing each generated token with each expected token.\nAny difference in length between the generated token sequence and the expected token sequence is also counted as error.\nHow long does it take to train the model?\nOn a Nvidia Tesla K80 GPU, it takes a little less than 5 hours to optimize the 109 * 10^6 parameters for one dataset; so expect around 15 hours if you want to train the model for the three target platforms.\nI am a front-end developer, will I soon lose my job?\n(I have genuinely been asked this question multiple times)\nTL;DR Not anytime soon will AI replace front-end developers.\nEven assuming a mature version of pix2code able to generate GUI code with 100% accuracy for every platforms/languages in the universe, front-enders will still be needed to implement the logic, the interactive parts, the advanced graphics and animations, and all the features users love. The product we are building at Uizard Technologies is intended to bridge the gap between UI/UX designers and front-end developers, not replace any of them. We want to rethink the traditional workflow that too often results in more frustration than innovation. We want designers to be as creative as possible to better serve end users, and developers to dedicate their time programming the core functionality and forget about repetitive tasks such as UI implementation. We believe in a future where AI collaborate with humans, not replace humans.\nMedia coverage\nWired UK\nThe Next Web\nFast Company\nNVIDIA Developer News\nLifehacker Australia\nTwo Minute Papers (web series)\nNLP Highlights (podcast)\nData Skeptic (podcast)\nRead comments on Hacker News",
	"deep-learning deep-neural-networks deeplearning object-detection objectdetection": "deep learning object detection\nA paper list of object detection using deep learning. I wrote this page with reference to this survey paper and searching and searching.. \nLast updated: 2020/09/22\nUpdate log\n2018/9/18 - update all of recent papers and make some diagram about history of object detection using deep learning. \n2018/9/26 - update codes of papers. (official and unofficial)\n2018/october - update 5 papers and performance table.\n2018/november - update 9 papers.\n2018/december - update 8 papers and and performance table and add new diagram(2019 version!!).\n2019/january - update 4 papers and and add commonly used datasets.\n2019/february - update 3 papers.\n2019/march - update figure and code links.\n2019/april - remove author's names and update ICLR 2019 & CVPR 2019 papers.\n2019/may - update CVPR 2019 papers.\n2019/june - update CVPR 2019 papers and dataset paper.\n2019/july - update BMVC 2019 papers and some of ICCV 2019 papers.\n2019/september - update NeurIPS 2019 papers and ICCV 2019 papers.\n2019/november - update some of AAAI 2020 papers and other papers.\n2020/january - update ICLR 2020 papers and other papers.\n2020/may - update CVPR 2020 papers and other papers.\n2020/june - update arxiv papers.\n2020/august - update paper links.  \nTable of Contents\nPaper list from 2014 to now(2019)\nPerformance table\nPapers\n2014\n2015\n2016\n2017\n2018\n2019\n2020\nDataset Papers\nPaper list from 2014 to now(2019)\nThe part highlighted with red characters means papers that i think \"must-read\".\nHowever, it is my personal opinion and other papers are important too, so I recommend to read them if you have time.\nPerformance table\nFPS(Speed) index is related to the hardware spec(e.g. CPU, GPU, RAM, etc), so it is hard to make an equal comparison. The solution is to measure the performance of all models on hardware with equivalent specifications, but it is very difficult and time consuming. \n|   Detector   | VOC07 (mAP@IoU=0.5) | VOC12 (mAP@IoU=0.5) | COCO (mAP@IoU=0.5:0.95) | Published In |\n|:------------:|:-------------------:|:-------------------:|:----------:|:------------:| \n|     R-CNN    |         58.5        |          -          |      -     |    CVPR'14   |\n|    SPP-Net   |         59.2        |          -          |      -     |    ECCV'14   |\n|    MR-CNN    |     78.2 (07+12)    |     73.9 (07+12)    |      -     |    ICCV'15   |\n|  Fast R-CNN  |     70.0 (07+12)    |     68.4 (07++12)   |    19.7    |    ICCV'15   |\n| Faster R-CNN |     73.2 (07+12)    |     70.4 (07++12)   |    21.9    |    NIPS'15   |\n|    YOLO v1   |     66.4 (07+12)    |     57.9 (07++12)   |      -     |    CVPR'16   |\n|     G-CNN    |         66.8        |     66.4 (07+12)    |      -     |    CVPR'16   |\n|     AZNet    |         70.4        |          -          |    22.3    |    CVPR'16   |\n|      ION     |         80.1        |         77.9        |    33.1    |    CVPR'16   |\n|   HyperNet   |     76.3 (07+12)    |    71.4 (07++12)    |      -     |    CVPR'16   |\n|     OHEM     |     78.9 (07+12)    |    76.3 (07++12)    |    22.4    |    CVPR'16   |\n|      MPN     |           -         |          -          |    33.2    |    BMVC'16   |\n|      SSD     |     76.8 (07+12)    |    74.9 (07++12)    |    31.2    |    ECCV'16   |\n|    GBDNet    |     77.2 (07+12)    |          -          |    27.0    |    ECCV'16   |\n|      CPF     |     76.4 (07+12)    |    72.6 (07++12)    |      -     |    ECCV'16   |\n|     R-FCN    |     79.5 (07+12)    |    77.6 (07++12)    |    29.9    |    NIPS'16   |\n|  DeepID-Net  |         69.0        |          -          |      -     |    PAMI'16   |\n|      NoC     |     71.6 (07+12)    |    68.8 (07+12)     |    27.2    |   TPAMI'16   |\n|     DSSD     |     81.5 (07+12)    |    80.0 (07++12)    |    33.2    |   arXiv'17   |\n|      TDM     |          -          |          -          |    37.3    |    CVPR'17   |\n|      FPN     |          -          |          -          |    36.2    |    CVPR'17   |\n|    YOLO v2   |     78.6 (07+12)    |    73.4 (07++12)    |      -     |    CVPR'17   |\n|      RON     |     77.6 (07+12)    |    75.4 (07++12)    |    27.4    |    CVPR'17   |\n|     DeNet    |     77.1 (07+12)    |    73.9 (07++12)    |    33.8    |    ICCV'17   |\n|   CoupleNet  |     82.7 (07+12)    |    80.4 (07++12)    |    34.4    |    ICCV'17   |\n|   RetinaNet  |          -          |          -          |    39.1    |    ICCV'17   |\n|     DSOD     |     77.7 (07+12)    |    76.3 (07++12)    |      -     |    ICCV'17   |\n|      SMN     |         70.0        |          -          |      -     |    ICCV'17   |\n|Light-Head R-CNN|        -          |          -          |    41.5    |   arXiv'17   |\n|    YOLO v3   |          -          |          -          |    33.0    |   arXiv'18   |\n|      SIN     |     76.0 (07+12)    |    73.1 (07++12)    |    23.2    |    CVPR'18   |\n|     STDN     |     80.9 (07+12)    |          -          |      -     |    CVPR'18   |\n|   RefineDet  |     83.8 (07+12)    |    83.5 (07++12)    |    41.8    |    CVPR'18   |\n|     SNIP     |          -          |          -          |    45.7    |    CVPR'18   |\n|Relation-Network|        -          |          -          |     32.5   |    CVPR'18   |\n| Cascade R-CNN|          -          |          -          |     42.8   |    CVPR'18   |\n|     MLKP     |     80.6 (07+12)    |    77.2 (07++12)    |     28.6   |    CVPR'18   |\n|  Fitness-NMS |          -          |          -          |     41.8   |    CVPR'18   |\n|    RFBNet    |     82.2 (07+12)    |          -          |      -     |    ECCV'18   |\n|   CornerNet  |          -          |          -          |     42.1   |    ECCV'18   |\n|    PFPNet    |     84.1 (07+12)    |    83.7 (07++12)    |     39.4   |    ECCV'18   |\n|    Pelee     |     70.9 (07+12)    |          -          |      -     |    NIPS'18   |\n|     HKRM     |     78.8 (07+12)    |          -          |     37.8   |    NIPS'18   |\n|     M2Det    |          -          |          -          |     44.2   |    AAAI'19   |\n|     R-DAD    |     81.2 (07++12)   |    82.0 (07++12)    |     43.1   |    AAAI'19   |\n| ScratchDet   |   84.1 (07++12)     |    83.6 (07++12)    |     39.1   |    CVPR'19   |\n| Libra R-CNN  |          -          |          -          |     43.0   |    CVPR'19   |\n| Reasoning-RCNN  | 82.5 (07++12)    |          -          |     43.2   |    CVPR'19   |\n|      FSAF    |          -          |          -          |     44.6   |    CVPR'19   |\n| AmoebaNet + NAS-FPN |     -        |          -          |     47.0   |    CVPR'19   |\n| Cascade-RetinaNet |       -        |           -         |     41.1   |    CVPR'19   |\n|      HTC     |          -          |          -          |     47.2   |    CVPR'19   |\n|   TridentNet |          -          |          -          |     48.4   |    ICCV'19   |\n|      DAFS    |   85.3 (07+12)  |    83.1 (07++12)    |     40.5   |    ICCV'19   |\n|   Auto-FPN   |     81.8 (07++12)   |          -          |     40.5   |    ICCV'19   |\n|     FCOS     |          -          |          -          |     44.7   |    ICCV'19   |\n|   FreeAnchor |          -          |          -          |     44.8   |  NeurIPS'19  |\n|    DetNAS    |     81.5 (07++12)   |          -          |     42.0   |  NeurIPS'19  |\n|     NATS     |          -          |          -          |     42.0   |  NeurIPS'19  |\n| AmoebaNet + NAS-FPN + AA |   -     |          -          |     50.7   |    arXiv'19  |\n|   SpineNet   |          -          |          -          |     52.1   |    arXiv'19  |\n|     CBNet    |          -          |          -          |     53.3   |    AAAI'20   |\n| EfficientDet |          -          |          -          |     52.6   |    CVPR'20   |\n|  DetectoRS   |          -          |          -          |     54.7   |    arXiv'20   |\n2014\n[R-CNN] Rich feature hierarchies for accurate object detection and semantic segmentation | [CVPR' 14] |[pdf] [official code - caffe] \n[OverFeat] OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks | [ICLR' 14] |[pdf] [official code - torch] \n[MultiBox] Scalable Object Detection using Deep Neural Networks | [CVPR' 14] |[pdf]\n[SPP-Net] Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition | [ECCV' 14] |[pdf] [official code - caffe] [unofficial code - keras] [unofficial code - tensorflow]\n2015\nImproving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction | [CVPR' 15] |[pdf] [official code - matlab]\n[MR-CNN] Object detection via a multi-region & semantic segmentation-aware CNN model | [ICCV' 15] |[pdf] [official code - caffe]\n[DeepBox] DeepBox: Learning Objectness with Convolutional Networks | [ICCV' 15] |[pdf] [official code - caffe]\n[AttentionNet] AttentionNet: Aggregating Weak Directions for Accurate Object Detection | [ICCV' 15] |[pdf] \n[Fast R-CNN] Fast R-CNN | [ICCV' 15] |[pdf] [official code - caffe] \n[DeepProposal] DeepProposal: Hunting Objects by Cascading Deep Convolutional Layers | [ICCV' 15] |[pdf] [official code - matconvnet]\n[Faster R-CNN, RPN] Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks | [NIPS' 15] |[pdf] [official code - caffe] [unofficial code - tensorflow] [unofficial code - pytorch] \n2016\n[YOLO v1] You Only Look Once: Unified, Real-Time Object Detection | [CVPR' 16] |[pdf] [official code - c] \n[G-CNN] G-CNN: an Iterative Grid Based Object Detector | [CVPR' 16] |[pdf]\n[AZNet] Adaptive Object Detection Using Adjacency and Zoom Prediction | [CVPR' 16] |[pdf]\n[ION] Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks | [CVPR' 16] |[pdf]\n[HyperNet] HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection | [CVPR' 16] |[pdf]\n[OHEM] Training Region-based Object Detectors with Online Hard Example Mining | [CVPR' 16] |[pdf] [official code - caffe] \n[CRAPF] CRAFT Objects from Images | [CVPR' 16] |[pdf] [official code - caffe] \n[MPN] A MultiPath Network for Object Detection | [BMVC' 16] |[pdf] [official code - torch] \n[SSD] SSD: Single Shot MultiBox Detector | [ECCV' 16] |[pdf] [official code - caffe] [unofficial code - tensorflow] [unofficial code - pytorch] \n[GBDNet] Crafting GBD-Net for Object Detection | [ECCV' 16] |[pdf] [official code - caffe]\n[CPF] Contextual Priming and Feedback for Faster R-CNN | [ECCV' 16] |[pdf]\n[MS-CNN] A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection | [ECCV' 16] |[pdf] [official code - caffe]\n[R-FCN] R-FCN: Object Detection via Region-based Fully Convolutional Networks | [NIPS' 16] |[pdf] [official code - caffe] [unofficial code - caffe]\n[PVANET] PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection | [NIPSW' 16] |[pdf] [official code - caffe]\n[DeepID-Net] DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection | [PAMI' 16] |[pdf]\n[NoC] Object Detection Networks on Convolutional Feature Maps | [TPAMI' 16] |[pdf]\n2017\n[DSSD] DSSD : Deconvolutional Single Shot Detector | [arXiv' 17] |[pdf] [official code - caffe]\n[TDM] Beyond Skip Connections: Top-Down Modulation for Object Detection | [CVPR' 17] |[pdf]\n[FPN] Feature Pyramid Networks for Object Detection  | [CVPR' 17] |[pdf] [unofficial code - caffe]\n[YOLO v2] YOLO9000: Better, Faster, Stronger | [CVPR' 17] |[pdf] [official code - c] [unofficial code - caffe] [unofficial code - tensorflow] [unofficial code - tensorflow] [unofficial code - pytorch] \n[RON] RON: Reverse Connection with Objectness Prior Networks for Object Detection | [CVPR' 17] |[pdf] [official code - caffe] [unofficial code - tensorflow]\n[RSA] Recurrent Scale Approximation for Object Detection in CNN |  | [ICCV' 17] |[pdf] [official code - caffe]\n[DCN] Deformable Convolutional Networks  | [ICCV' 17] |[pdf] [official code - mxnet] [unofficial code - tensorflow] [unofficial code - pytorch]\n[DeNet] DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling | [ICCV' 17] |[pdf] [official code - theano]\n[CoupleNet] CoupleNet: Coupling Global Structure with Local Parts for Object Detection | [ICCV' 17] |[pdf] [official code - caffe]\n[RetinaNet] Focal Loss for Dense Object Detection | [ICCV' 17] |[pdf] [official code - keras] [unofficial code - pytorch] [unofficial code - mxnet] [unofficial code - tensorflow]\n[Mask R-CNN] Mask R-CNN | [ICCV' 17] |[pdf] [official code - caffe2] [unofficial code - tensorflow] [unofficial code - tensorflow] [unofficial code - pytorch]\n[DSOD] DSOD: Learning Deeply Supervised Object Detectors from Scratch | [ICCV' 17] |[pdf] [official code - caffe] [unofficial code - pytorch] \n[SMN] Spatial Memory for Context Reasoning in Object Detection | [ICCV' 17] |[pdf]\n[Light-Head R-CNN] Light-Head R-CNN: In Defense of Two-Stage Object Detector | [arXiv' 17] |[pdf] [official code - tensorflow]\n[Soft-NMS] Improving Object Detection With One Line of Code | [ICCV' 17] |[pdf] [official code - caffe]\n2018\n[YOLO v3] YOLOv3: An Incremental Improvement | [arXiv' 18] |[pdf] [official code - c] [unofficial code - pytorch] [unofficial code - pytorch] [unofficial code - keras] [unofficial code - tensorflow]\n[ZIP] Zoom Out-and-In Network with Recursive Training for Object Proposal | [IJCV' 18] |[pdf] [official code - caffe]\n[SIN] Structure Inference Net: Object Detection Using Scene-Level Context and Instance-Level Relationships | [CVPR' 18] |[pdf] [official code - tensorflow]\n[STDN] Scale-Transferrable Object Detection | [CVPR' 18] |[pdf]\n[RefineDet] Single-Shot Refinement Neural Network for Object Detection | [CVPR' 18] |[pdf] [official code - caffe] [unofficial code - chainer] [unofficial code - pytorch]\n[MegDet] MegDet: A Large Mini-Batch Object Detector | [CVPR' 18] |[pdf]\n[DA Faster R-CNN] Domain Adaptive Faster R-CNN for Object Detection in the Wild | [CVPR' 18] |[pdf] [official code - caffe]\n[SNIP] An Analysis of Scale Invariance in Object Detection \u2013 SNIP | [CVPR' 18] |[pdf]\n[Relation-Network] Relation Networks for Object Detection | [CVPR' 18] |[pdf] [official code - mxnet]\n[Cascade R-CNN] Cascade R-CNN: Delving into High Quality Object Detection | [CVPR' 18] |[pdf] [official code - caffe]\nFinding Tiny Faces in the Wild with Generative Adversarial Network | [CVPR' 18] |[pdf]\n[MLKP] Multi-scale Location-aware Kernel Representation for Object Detection | [CVPR' 18] |[pdf] [official code - caffe]\nCross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation | [CVPR' 18] |[pdf] [official code - chainer]\n[Fitness NMS] Improving Object Localization with Fitness NMS and Bounded IoU Loss | [CVPR' 18] |[pdf] \n[STDnet] STDnet: A ConvNet for Small Target Detection | [BMVC' 18] |[pdf]\n[RFBNet] Receptive Field Block Net for Accurate and Fast Object Detection | [ECCV' 18] |[pdf] [official code - pytorch]\nZero-Annotation Object Detection with Web Knowledge Transfer | [ECCV' 18] |[pdf]\n[CornerNet] CornerNet: Detecting Objects as Paired Keypoints | [ECCV' 18] |[pdf] [official code - pytorch]\n[PFPNet] Parallel Feature Pyramid Network for Object Detection | [ECCV' 18] |[pdf]\n[Softer-NMS] Softer-NMS: Rethinking Bounding Box Regression for Accurate Object Detection | [arXiv' 18] |[pdf]\n[ShapeShifter] ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object Detector | [ECML-PKDD' 18] |[pdf] [official code - tensorflow]\n[Pelee] Pelee: A Real-Time Object Detection System on Mobile Devices | [NIPS' 18] |[pdf] [official code - caffe]\n[HKRM] Hybrid Knowledge Routed Modules for Large-scale Object Detection | [NIPS' 18] |[pdf] \n[MetaAnchor] MetaAnchor: Learning to Detect Objects with Customized Anchors | [NIPS' 18] |[pdf] \n[SNIPER] SNIPER: Efficient Multi-Scale Training | [NIPS' 18] |[pdf] \n2019\n[M2Det] M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network | [AAAI' 19] |[pdf] [official code - pytorch]\n[R-DAD] Object Detection based on Region Decomposition and Assembly | [AAAI' 19] |[pdf] \n[CAMOU] CAMOU: Learning Physical Vehicle Camouflages to Adversarially Attack Detectors in the Wild | [ICLR' 19] |[pdf] \nFeature Intertwiner for Object Detection | [ICLR' 19] |[pdf] \n[GIoU] Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression | [CVPR' 19] |[pdf] \nAutomatic adaptation of object detectors to new domains using self-training | [CVPR' 19] |[pdf] \n[Libra R-CNN] Libra R-CNN: Balanced Learning for Object Detection | [CVPR' 19] |[pdf] \n[FSAF] Feature Selective Anchor-Free Module for Single-Shot Object Detection | [CVPR' 19] |[pdf] \n[ExtremeNet] Bottom-up Object Detection by Grouping Extreme and Center Points | [CVPR' 19] |[pdf] | [official code - pytorch]\n[C-MIL] C-MIL: Continuation Multiple Instance Learning for Weakly Supervised Object Detection\n | [CVPR' 19] |[pdf] | [official code - torch]\n[ScratchDet] ScratchDet: Training Single-Shot Object Detectors from Scratch | [CVPR' 19] |[pdf] \nBounding Box Regression with Uncertainty for Accurate Object Detection | [CVPR' 19] |[pdf] | [official code - caffe2]\nActivity Driven Weakly Supervised Object Detection | [CVPR' 19] |[pdf] \nTowards Accurate One-Stage Object Detection with AP-Loss | [CVPR' 19] |[pdf] \nStrong-Weak Distribution Alignment for Adaptive Object Detection | [CVPR' 19] |[pdf] | [official code - pytorch] \n[NAS-FPN] NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection | [CVPR' 19] |[pdf] \n[Adaptive NMS] Adaptive NMS: Refining Pedestrian Detection in a Crowd | [CVPR' 19] |[pdf] \nPoint in, Box out: Beyond Counting Persons in Crowds | [CVPR' 19] |[pdf] \nLocating Objects Without Bounding Boxes | [CVPR' 19] |[pdf] \nSampling Techniques for Large-Scale Object Detection from Sparsely Annotated Objects | [CVPR' 19] |[pdf] \nTowards Universal Object Detection by Domain Attention | [CVPR' 19] |[pdf] \nExploring the Bounds of the Utility of Context for Object Detection | [CVPR' 19] |[pdf] \nWhat Object Should I Use? - Task Driven Object Detection | [CVPR' 19] |[pdf] \nDissimilarity Coefficient based Weakly Supervised Object Detection | [CVPR' 19] |[pdf] \nAdapting Object Detectors via Selective Cross-Domain Alignment | [CVPR' 19] |[pdf] \nFully Quantized Network for Object Detection | [CVPR' 19] |[pdf]\nDistilling Object Detectors with Fine-grained Feature Imitation | [CVPR' 19] |[pdf]\nMulti-task Self-Supervised Object Detection via Recycling of Bounding Box Annotations | [CVPR' 19] |[pdf]\n[Reasoning-RCNN] Reasoning-RCNN: Unifying Adaptive Global Reasoning into Large-scale Object Detection | [CVPR' 19] |[pdf]\nArbitrary Shape Scene Text Detection with Adaptive Text Region Representation | [CVPR' 19] |[pdf]\nAssisted Excitation of Activations: A Learning Technique to Improve Object Detectors | [CVPR' 19] |[pdf]\nSpatial-aware Graph Relation Network for Large-scale Object Detection | [CVPR' 19] |[pdf]\n[MaxpoolNMS] MaxpoolNMS: Getting Rid of NMS Bottlenecks in Two-Stage Object Detectors | [CVPR' 19] |[pdf]\nYou reap what you sow: Generating High Precision Object Proposals for Weakly-supervised Object Detection | [CVPR' 19] |[pdf]\nObject detection with location-aware deformable convolution and backward attention filtering | [CVPR' 19] |[pdf]\nDiversify and Match: A Domain Adaptive Representation Learning Paradigm for Object Detection | [CVPR' 19] |[pdf]\nHybrid Task Cascade for Instance Segmentation | [CVPR' 19] |[pdf]\n[GFR] Improving Object Detection from Scratch via Gated Feature Reuse | [BMVC' 19] |[pdf] | [official code - pytorch]\n[Cascade RetinaNet] Cascade RetinaNet: Maintaining Consistency for Single-Stage Object Detection | [BMVC' 19] |[pdf]\nSoft Sampling for Robust Object Detection | [BMVC' 19] |[pdf]\nMulti-adversarial Faster-RCNN for Unrestricted Object Detection | [ICCV' 19] |[pdf]\nTowards Adversarially Robust Object Detection | [ICCV' 19] |[pdf]\nA Robust Learning Approach to Domain Adaptive Object Detection | [ICCV' 19] |[pdf]\nA Delay Metric for Video Object Detection: What Average Precision Fails to Tell   | [ICCV' 19] |[pdf]\nDelving Into Robust Object Detection From Unmanned Aerial Vehicles: A Deep Nuisance Disentanglement Approach | [ICCV' 19] |[pdf]\nEmploying Deep Part-Object Relationships for Salient Object Detection | [ICCV' 19] |[pdf]\nLearning Rich Features at High-Speed for Single-Shot Object Detection | [ICCV' 19] |[pdf]\nStructured Modeling of Joint Deep Feature and Prediction Refinement for Salient Object Detection  | [ICCV' 19] |[pdf]\nSelectivity or Invariance: Boundary-Aware Salient Object Detection    | [ICCV' 19] |[pdf]\nProgressive Sparse Local Attention for Video Object Detection | [ICCV' 19] |[pdf]\nMinimum Delay Object Detection From Video | [ICCV' 19] |[pdf]\nTowards Interpretable Object Detection by Unfolding Latent Structures  | [ICCV' 19]  |[pdf]\nScaling Object Detection by Transferring Classification Weights   | [ICCV' 19] |[pdf]\n[TridentNet] Scale-Aware Trident Networks for Object Detection    | [ICCV' 19] |[pdf]\nGenerative Modeling for Small-Data Object Detection   | [ICCV' 19] |[pdf]\nTransductive Learning for Zero-Shot Object Detection  | [ICCV' 19] |[pdf]\nSelf-Training and Adversarial Background Regularization for Unsupervised Domain Adaptive One-Stage Object Detection   | [ICCV' 19] |[pdf]\n[CenterNet] CenterNet: Keypoint Triplets for Object Detection    | [ICCV' 19] |[pdf]\n[DAFS] Dynamic Anchor Feature Selection for Single-Shot Object Detection  | [ICCV' 19] |[pdf]\n[Auto-FPN] Auto-FPN: Automatic Network Architecture Adaptation for Object Detection Beyond Classification | [ICCV' 19] |[pdf]\nMulti-Adversarial Faster-RCNN for Unrestricted Object Detection   | [ICCV' 19] |[pdf]\nObject Guided External Memory Network for Video Object Detection | [ICCV' 19] |[pdf]\n[ThunderNet] ThunderNet: Towards Real-Time Generic Object Detection on Mobile Devices | [ICCV' 19] |[pdf]\n[RDN] Relation Distillation Networks for Video Object Detection   | [ICCV' 19] |[pdf]\n[MMNet] Fast Object Detection in Compressed Video | [ICCV' 19] |[pdf]\nTowards High-Resolution Salient Object Detection  | [ICCV' 19] |[pdf]\n[SCAN] Stacked Cross Refinement Network for Edge-Aware Salient Object Detection   | [ICCV' 19] |[official code] |[pdf]\nMotion Guided Attention for Video Salient Object Detection    | [ICCV' 19] |[pdf]\nSemi-Supervised Video Salient Object Detection Using Pseudo-Labels    | [ICCV' 19] |[pdf]\nLearning to Rank Proposals for Object Detection   | [ICCV' 19] |[pdf]\n[WSOD2] WSOD2: Learning Bottom-Up and Top-Down Objectness Distillation for Weakly-Supervised Object Detection | [ICCV' 19] |[pdf]\n[ClusDet] Clustered Object Detection in Aerial Images | [ICCV' 19] |[pdf]\nTowards Precise End-to-End Weakly Supervised Object Detection Network | [ICCV' 19] |[pdf]\nFew-Shot Object Detection via Feature Reweighting  | [ICCV' 19] |[pdf]\n[Objects365] Objects365: A Large-Scale, High-Quality Dataset for Object Detection | [ICCV' 19] |[pdf]\n[EGNet] EGNet: Edge Guidance Network for Salient Object Detection | [ICCV' 19] |[pdf]\nOptimizing the F-Measure for Threshold-Free Salient Object Detection  | [ICCV' 19] |[pdf]\nSequence Level Semantics Aggregation for Video Object Detection   | [ICCV' 19] |[pdf]\n[NOTE-RCNN] NOTE-RCNN: NOise Tolerant Ensemble RCNN for Semi-Supervised Object Detection | [ICCV' 19] |[pdf] \nEnriched Feature Guided Refinement Network for Object Detection   | [ICCV' 19] |[pdf]\n[POD] POD: Practical Object Detection With Scale-Sensitive Network    | [ICCV' 19] |[pdf] \n[FCOS] FCOS: Fully Convolutional One-Stage Object Detection   | [ICCV' 19] |[pdf] \n[RepPoints] RepPoints: Point Set Representation for Object Detection  | [ICCV' 19] |[pdf] \nBetter to Follow, Follow to Be Better: Towards Precise Supervision of Feature Super-Resolution for Small Object Detection | [ICCV' 19] |[pdf]\nWeakly Supervised Object Detection With Segmentation Collaboration    | [ICCV' 19] |[pdf] \nLeveraging Long-Range Temporal Relationships Between Proposals for Video Object Detection | [ICCV' 19] |[pdf]\nDetecting 11K Classes: Large Scale Object Detection Without Fine-Grained Bounding Boxes   | [ICCV' 19] |[pdf] \n[C-MIDN] C-MIDN: Coupled Multiple Instance Detection Network With Segmentation Guidance for Weakly Supervised Object Detection    | [ICCV' 19] |[pdf]\nMeta-Learning to Detect Rare Objects  | [ICCV' 19] |[pdf]\n[Cap2Det] Cap2Det: Learning to Amplify Weak Caption Supervision for Object Detection | [ICCV' 19] |[pdf]\n[Gaussian YOLOv3] Gaussian YOLOv3: An Accurate and Fast Object Detector using Localization Uncertainty for Autonomous Driving | [ICCV' 19] |[pdf] [official code - c]\n[FreeAnchor] FreeAnchor: Learning to Match Anchors for Visual Object Detection | [NeurIPS' 19] |[pdf]\nMemory-oriented Decoder for Light Field Salient Object Detection | [NeurIPS' 19] |[pdf]\nOne-Shot Object Detection with Co-Attention and Co-Excitation | [NeurIPS' 19] |[pdf]\n[DetNAS] DetNAS: Backbone Search for Object Detection | [NeurIPS' 19] |[pdf]\nConsistency-based Semi-supervised Learning for Object detection | [NeurIPS' 19] |[pdf]\n[NATS] Efficient Neural Architecture Transformation Searchin Channel-Level for Object Detection | [NeurIPS' 19] |[pdf]\n[AA] Learning Data Augmentation Strategies for Object Detection | [arXiv' 19] |[pdf]\n[Spinenet] Spinenet: Learning scale-permuted backbone for recognition and localization | [arXiv' 19] |[pdf]\nObject Detection in 20 Years: A Survey | [arXiv' 19] |[pdf]\n2020\n[Spiking-YOLO] Spiking-YOLO: Spiking Neural Network for Real-time Object Detection | [AAAI' 20] |[pdf]\nTell Me What They're Holding: Weakly-supervised Object Detection with Transferable Knowledge from Human-object Interaction | [AAAI' 20] |[pdf]\n[CBnet] Cbnet: A novel composite backbone network architecture for object detection | [AAAI' 20] |[pdf]\n[Distance-IoU Loss] Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression | [AAAI' 20] |[pdf]\nComputation Reallocation for Object Detection | [ICLR' 20] |[pdf]\n[YOLOv4] YOLOv4: Optimal Speed and Accuracy of Object Detection | [arXiv' 20] |[pdf]\nFew-Shot Object Detection With Attention-RPN and Multi-Relation Detector | [CVPR' 20] |[pdf]\nLarge-Scale Object Detection in the Wild From Imbalanced Multi-Labels | [CVPR' 20] |[pdf]\nBridging the Gap Between Anchor-Based and Anchor-Free Detection via Adaptive Training Sample Selection | [CVPR' 20] |[pdf]\nRethinking Classification and Localization for Object Detection    | [CVPR' 20] |[pdf]\nMultiple Anchor Learning for Visual Object Detection | [CVPR' 20] |[pdf]\n[CentripetalNet] CentripetalNet: Pursuing High-Quality Keypoint Pairs for Object Detection     | [CVPR' 20] |[pdf]\nLearning From Noisy Anchors for One-Stage Object Detection | [CVPR' 20] |[pdf]\n[EfficientDet] EfficientDet: Scalable and Efficient Object Detection | [CVPR' 20] |[pdf]\nOvercoming Classifier Imbalance for Long-Tail Object Detection With Balanced Group Softmax | [CVPR' 20] |[pdf]\nDynamic Refinement Network for Oriented and Densely Packed Object Detection | [CVPR' 20] |[pdf]\nNoise-Aware Fully Webly Supervised Object Detection    | [CVPR' 20] |[pdf]\n[Hit-Detector] Hit-Detector: Hierarchical Trinity Architecture Search for Object Detection     | [CVPR' 20] |[pdf]\n[D2Det] D2Det: Towards High Quality Object Detection and Instance Segmentation | [CVPR' 20] |[pdf]\nPrime Sample Attention in Object Detection | [CVPR' 20] |[pdf]\nDon\u2019t Even Look Once: Synthesizing Features for Zero-Shot Detection    | [CVPR' 20] |[pdf]\nExploring Categorical Regularization for Domain Adaptive Object Detection  | [CVPR' 20] |[pdf]\n[SP-NAS] SP-NAS: Serial-to-Parallel Backbone Search for Object Detection   | [CVPR' 20] |[pdf]\n[NAS-FCOS] NAS-FCOS: Fast Neural Architecture Search for Object Detection | [CVPR' 20] |[pdf]\n[DR Loss] DR Loss: Improving Object Detection by Distributional Ranking    | [CVPR' 20] |[pdf]\nDetection in Crowded Scenes: One Proposal, Multiple Predictions    | [CVPR' 20] |[pdf]\n[AugFPN] AugFPN: Improving Multi-Scale Feature Learning for Object Detection   | [CVPR' 20] |[pdf]\nRobust Object Detection Under Occlusion With Context-Aware CompositionalNets   | [CVPR' 20] |[pdf]\nCross-Domain Document Object Detection: Benchmark Suite and Method | [CVPR' 20] |[pdf]\nExploring Bottom-Up and Top-Down Cues With Attentive Learning for Webly Supervised Object Detection    | [CVPR' 20] |[pdf]\n[SLV] SLV: Spatial Likelihood Voting for Weakly Supervised Object Detection    | [CVPR' 20] |[pdf]\n[HAMBox] HAMBox: Delving Into Mining High-Quality Anchors on Face Detection    | [CVPR' 20] |[pdf]\n[Context R-CNN] Context R-CNN: Long Term Temporal Context for Per-Camera Object Detection  | [CVPR' 20] |[pdf]\nMixture Dense Regression for Object Detection and Human Pose Estimation    | [CVPR' 20] |[pdf]\nOffset Bin Classification Network for Accurate Object Detection    | [CVPR' 20] |[pdf]\n[NETNet] NETNet: Neighbor Erasing and Transferring Network for Better Single Shot Object Detection     | [CVPR' 20] |[pdf]\nScale-Equalizing Pyramid Convolution for Object Detection  | [CVPR' 20] |[pdf]\nTemporal-Context Enhanced Detection of Heavily Occluded Pedestrians    | [CVPR' 20] |[pdf]\n[MnasFPN] MnasFPN: Learning Latency-Aware Pyramid Architecture for Object Detection on Mobile Devices  | [CVPR' 20] |[pdf]\nPhysically Realizable Adversarial Examples for LiDAR Object Detection  | [CVPR' 20] |[pdf]\nCross-domain Object Detection through Coarse-to-Fine Feature Adaptation    | [CVPR' 20] |[pdf]\nIncremental Few-Shot Object Detection  | [CVPR' 20] |[pdf]\nWhere, What, Whether: Multi-Modal Learning Meets Pedestrian Detection  | [CVPR' 20] |[pdf]\nCylindrical Convolutional Networks for Joint Object Detection and Viewpoint Estimation     | [CVPR' 20] |[pdf]\nLearning a Unified Sample Weighting Network for Object Detection   | [CVPR' 20] |[pdf]\nSeeing without Looking: Contextual Rescoring of Object Detections for AP Maximization  | [CVPR' 20] |[pdf]\nDetectoRS: Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution  | [arXiv' 20] |[pdf]\n[DETR] End-to-End Object Detection with Transformers  | [ECCV' 20] |[pdf]\nSuppress and Balance: A Simple Gated Network for Salient Object Detection | [ECCV' 20] |[code]\n[BorderDet] BorderDet: Border Feature for Dense Object Detection | [ECCV' 20] |[pdf]\nCorner Proposal Network for Anchor-free, Two-stage Object Detection   | [ECCV' 20] |[pdf]\nA General Toolbox for Understanding Errors in Object Detection    | [ECCV' 20] |[pdf]\n[Chained-Tracker] Chained-Tracker: Chaining Paired Attentive Regression Results for End-to-End Joint Multiple-Object Detection and Tracking   | [ECCV' 20] |[pdf]\nSide-Aware Boundary Localization for More Precise Object Detection    | [ECCV' 20] |[pdf]\n[PIoU] PIoU Loss: Towards Accurate Oriented Object Detection in Complex Environments  | [ECCV' 20] |[pdf]\n[AABO] AABO: Adaptive Anchor Box Optimization for Object Detection via Bayesian Sub-sampling  | [ECCV' 20] |[pdf]\nHighly Efficient Salient Object Detection with 100K Parameters | [ECCV' 20] |[pdf]\n[GeoGraph] GeoGraph: Learning graph-based multi-view object detection with geometric cues end-to-end      | [ECCV' 20] |[pdf]\nMany-shot from Low-shot: Learning to Annotate using Mixed Supervision for Object Detection| [ECCV' 20] |[pdf]\nCheaper Pre-training Lunch: An Efficient Paradigm for Object Detection    | [ECCV' 20] |[pdf]\nArbitrary-Oriented Object Detection with Circular Smooth Label    | [ECCV' 20] |[pdf]\nSoft Anchor-Point Object Detection        | [ECCV' 20] |[pdf]\nObject Detection with a Unified Label Space from Multiple Datasets    | [ECCV' 20] |[pdf]\n[MimicDet] MimicDet: Bridging the Gap Between One-Stage and Two-Stage Object Detection | [ECCV' 20] |[pdf]\nPrior-based Domain Adaptive Object Detection for Hazy and Rainy Conditions        | [ECCV' 20] |[pdf]\n[Dynamic R-CNN] Dynamic R-CNN: Towards High Quality Object Detection via Dynamic Training     | [ECCV' 20] |[pdf]\n[OS2D] OS2D: One-Stage One-Shot Object Detection by Matching Anchor Features      | [ECCV' 20] |[pdf]\nMulti-Scale Positive Sample Refinement for Few-Shot Object Detection      | [ECCV' 20] |[pdf]\nFew-Shot Object Detection and Viewpoint Estimation for Objects in the Wild        | [ECCV' 20] |[pdf]\nCollaborative Training between Region Proposal Localization and Classification for Domain Adaptive Object Detection       | [ECCV' 20] |[pdf]\nTwo-Stream Active Query Suggestion for Large-Scale Object Detection in Connectomics       | [ECCV' 20] |[pdf]\n[FDTS] FDTS: Fast Diverse-Transformation Search for Object Detection and Beyond       | [ECCV' 20] \nDual refinement underwater object detection network       | [ECCV' 20] |[pdf]\n[APRICOT] APRICOT: A Dataset of Physical Adversarial Attacks on Object Detection      | [ECCV' 20] |[pdf]\nLarge Batch Optimization for Object Detection: Training COCO in 12 Minutes        | [ECCV' 20] |[pdf]\nHierarchical Context Embedding for Region-based Object Detection      | [ECCV' 20] |[pdf]\nPillar-based Object Detection for Autonomous Driving      | [ECCV' 20] |[pdf]\nDive Deeper Into Box for Object Detection     | [ECCV' 20] |[pdf]\nDomain Adaptive Object Detection via Asymmetric Tri-way Faster-RCNN       | [ECCV' 20] |[pdf]\nProbabilistic Anchor Assignment with IoU Prediction for Object Detection      | [ECCV' 20] |[pdf]\n[HoughNet] HoughNet: Integrating near and long-range evidence for bottom-up object detection      | [ECCV' 20] |[pdf]\n[LabelEnc] LabelEnc: A New Intermediate Supervision Method for Object Detection       | [ECCV' 20] |[pdf]\nBoosting Weakly Supervised Object Detection with Progressive Knowledge Transfer       | [ECCV' 20] |[pdf]\nOn the Importance of Data Augmentation for Object Detection       | [ECCV' 20] |[pdf]\nAdaptive Object Detection with Dual Multi-Label Prediction        | [ECCV' 20] |[pdf]\nQuantum-soft QUBO Suppression for Accurate Object Detection       | [ECCV' 20] |[pdf]\nImproving Object Detection with Selective Self-supervised Self-training       | [ECCV' 20] |[pdf]\nDataset Papers\nStatistics of commonly used object detection datasets. The Table came from this survey paper.\nChallenge\nObject Classes\nNumber of Images\nNumber of Annotated Images\nTrain\nVal\nTest\nTrain\nVal\nPASCAL VOC Object Detection Challenge\n VOC07  20  2,501  2,510   4,952    6,301 (7,844)    6,307 (7,818) \n VOC08  20  2,111  2,221   4,133    5,082 (6,337)    5,281 (6,347) \n VOC09  20  3,473  3,581   6,650    8,505 (9,760)    8,713 (9,779) \n VOC10  20  4,998  5,105   9,637  11,577 (13,339)  11,797 (13,352) \n VOC11  20  5,717  5,823  10,994  13,609 (15,774)  13,841 (15,787) \n VOC12  20  5,717  5,823  10,991  13,609 (15,774)  13,841 (15,787) \nILSVRC Object Detection Challenge\n ILSVRC13  200  395,909  20,121  40,152  345,854  55,502 \n ILSVRC14  200  456,567  20,121  40,152  478,807  55,502 \n ILSVRC15  200  456,567  20,121  51,294  478,807  55,502 \n ILSVRC16  200  456,567  20,121  60,000  478,807  55,502 \n ILSVRC17  200  456,567  20,121  65,500  478,807  55,502 \nMS COCO Object Detection Challenge\n MS COCO15  80   82,783  40,504  81,434  604,907  291,875 \n MS COCO16  80   82,783  40,504  81,434  604,907  291,875 \n MS COCO17  80  118,287   5,000  40,670  860,001   36,781 \n MS COCO18  80  118,287   5,000  40,670  860,001   36,781 \nOpen Images Object Detection Challenge\n OID18  500  1,743,042  41,620  125,436  12,195,144  \u2015 \nThe papers related to datasets used mainly in Object Detection are as follows.\n[PASCAL VOC] The PASCAL Visual Object Classes (VOC) Challenge | [IJCV' 10] | [pdf]\n[PASCAL VOC] The PASCAL Visual Object Classes Challenge: A Retrospective | [IJCV' 15] | [pdf] | [link]\n[ImageNet] ImageNet: A Large-Scale Hierarchical Image Database| [CVPR' 09] | [pdf]\n[ImageNet] ImageNet Large Scale Visual Recognition Challenge | [IJCV' 15] | [pdf] | [link]\n[COCO] Microsoft COCO: Common Objects in Context | [ECCV' 14] | [pdf] | [link]\n[Open Images] The Open Images Dataset V4: Unified image classification, object detection, and visual relationship detection at scale | [arXiv' 18] | [pdf] | [link]\n[DOTA] DOTA: A Large-scale Dataset for Object Detection in Aerial Images | [CVPR' 18] | [pdf] | [link]\n[Objects365] Objects365: A Large-Scale, High-Quality Dataset for Object Detection | [ICCV' 19] | [link]\nContact & Feedback\nIf you have any suggestions about papers, feel free to mail me :)\ne-mail\nblog\npull request",
	"artificial-intelligence-algorithms artificial-neural-networks bayesian-statistics computer-vision deep-learning deep-neural-networks deep-reinforcement-learning explainable-ai geometric-deep-learning graph-neural-networks machine-learning medical-imaging natural-language-processing optimization pattern-recognition probabilistic-graphical-models probability reinforcement-learning speech-recognition visual-recognition": ":balloon: :tada: Deep Learning Drizzle :confetti_ball: :balloon:\n:books: \"Read enough so you start developing intuitions and then trust your intuitions and go for it!\"  :books:  \u200b  Prof. Geoffrey Hinton, University of Toronto\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\nContents\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n|                                                              |                                                              |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| Deep Learning (Deep Neural Networks) :arrow_heading_down: | Probabilistic Graphical Models :arrow_heading_down: |\n|                                                              |                                                              |\n| Machine Learning Fundamentals :arrow_heading_down: | Natural Language Processing :arrow_heading_down: |\n|                                                              |                                                              |\n| Optimization for Machine Learning :arrow_heading_down: | Automatic Speech Recognition :arrow_heading_down: |\n|                                                              |                                                              |\n| General Machine Learning :arrow_heading_down: | Modern Computer Vision :arrow_heading_down: |\n|                                                              |                                                              |\n| Reinforcement Learning :arrow_heading_down: | Boot Camps or Summer Schools :arrow_heading_down: |\n|                                                              |                                                              |\n| Bayesian Deep Learning :arrow_heading_down: | Medical Imaging :arrow_heading_down: |\n|                                                              |                                                              |\n| Graph Neural Networks :arrow_heading_down:  | Bird's-eye view of Artificial Intelligence :arrow_heading_down: |\n|                                                              |                                                              |\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:tada: Deep Learning (Deep Neural Networks) :confetti_ball: :balloon:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                           | University/Instructor(s)                       | Course WebPage                                               | Lecture Videos                                               | Year            |\n| ---- | ----------------------------------------------------- | ---------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------------- |\n| 1.   | Neural Networks for Machine Learning              | Geoffrey Hinton, University of Toronto         | Lecture-Slides  CSC321-tijmen | YouTube-Lectures  UofT-mirror | 2012  2014 |\n| 2.   | Neural Networks Demystified                       | Stephen Welch, Welch Labs                      | Suppl. Code | YouTube-Lectures | 2014            |\n| 3.   | Deep Learning at Oxford                           | Nando de Freitas, Oxford University            | Oxford-ML | YouTube-Lectures | 2015            |\n| 4.   | Deep Learning for Perception                      | Dhruv Batra, Virginia Tech                     | ECE-6504        | YouTube-Lectures | 2015            |\n| 5.   | Deep Learning                                     | Ali Ghodsi, University of Waterloo             | STAT-946 | YouTube-Lectures | F2015           |\n| 6.   | CS231n: CNNs for Visual Recognition               | Andrej Karpathy, Stanford University           | CS231n                   | None                                                       | 2015            |\n| 7.   | CS224d: Deep Learning for NLP                     | Richard Socher, Stanford University            | CS224d                         | YouTube-Lectures | 2015            |\n| 8.   | Bay Area Deep Learning                            | Many legends, Stanford                         | None                                                       | YouTube-Lectures | 2016            |\n| 9.   | CS231n: CNNs for Visual Recognition               | Andrej Karpathy, Stanford University           | CS231n                   | YouTube-Lectures (Academic Torrent) | 2016            |\n| 10.  | Neural Networks                                   | Hugo Larochelle, Universit\u00e9 de Sherbrooke      | Neural-Networks | YouTube-Lectures  (Academic Torrent) | 2016            |\n|      |                                                       |                                                |                                                              |                                                              |                 |\n| 11.  | CS224d: Deep Learning for NLP                     | Richard Socher, Stanford University            | CS224d                         | YouTube-Lectures (Academic Torrent) | 2016            |\n| 12.  | CS224n: NLP with Deep Learning                    | Richard Socher, Stanford University            | CS224n              | YouTube-Lectures | 2017            |\n| 13.  | CS231n: CNNs for Visual Recognition               | Justin Johnson, Stanford University            | CS231n                   | YouTube-Lectures  (Academic Torrent) | 2017            |\n| 14.  | Topics in Deep Learning                           | Ruslan Salakhutdinov, CMU                      | 10707           | YouTube-Lectures | F2017           |\n| 15.  | Deep Learning Crash Course                        | Leo Isikdogan, UT Austin                       | None                                                       | YouTube-Lectures | 2017            |\n| 16.  | Deep Learning and its Applications                | Fran\u00e7ois Piti\u00e9, Trinity College Dublin         | EE4C16                  | YouTube-Lectures | 2017            |\n| 17.  | Deep Learning                                     | Andrew Ng, Stanford University                 | CS230                          | YouTube-Lectures | 2018            |\n| 18.  | UvA Deep Learning                                 | Efstratios Gavves, University of Amsterdam     | UvA-DLC                         | Lecture-Videos | 2018            |\n| 19.  | Advanced Deep Learning and Reinforcement Learning | Many legends, DeepMind                         | None                                                       | YouTube-Lectures | 2018            |\n| 20.  | Machine Learning                                  | Peter Bloem, Vrije Universiteit Amsterdam      | MLVU                              | YouTube-Lectures | 2018            |\n|      |                                                       |                                                |                                                              |                                                              |                 |\n| 21.  | Deep Learning                                     | Francois Fleuret, EPFL                         | EE-59                  | Video-Lectures | 2018            |\n| 22.  | Introduction to Deep Learning                     | Alexander Amini, Harini Suresh and others, MIT | 6.S191                    | YouTube-Lectures  2017-version | 2017- 2021     |\n| 23.  | Deep Learning for Self-Driving Cars               | Lex Fridman, MIT                               | 6.S094                   | YouTube-Lectures | 2017-2018       |\n| 24.  | Introduction to Deep Learning                     | Bhiksha Raj and many others, CMU               | 11-485/785                | YouTube-Lectures | S2018           |\n| 25.  | Introduction to Deep Learning                     | Bhiksha Raj and many others, CMU               | 11-485/785                | YouTube-Lectures Recitation-Inclusive | F2018           |\n| 26.  | Deep Learning Specialization                      | Andrew Ng, Stanford                            | DL.AI | YouTube-Lectures | 2017-2018       |\n| 27.  | Deep Learning                                     | Ali Ghodsi, University of Waterloo             | STAT-946 | YouTube-Lectures | F2017           |\n| 28.  | Deep Learning                                     | Mitesh Khapra, IIT-Madras                      | CS7015    | YouTube-Lectures | 2018            |\n| 29.  | Deep Learning for AI                              | UPC Barcelona                                  | DLAI-2017  DLAI-2018 | YouTube-Lectures | 2017-2018       |\n| 30.  | Deep Learning                                     | Alex Bronstein and Avi Mendelson, Technion     | CS236605 | YouTube-Lectures | 2018            |\n|      |                                                       |                                                |                                                              |                                                              |                 |\n| 31.  | MIT Deep Learning                                 | Many Researchers,  Lex Fridman, MIT            | 6.S094, 6.S091, 6.S093      | YouTube-Lectures | 2019            |\n| 32.  | Deep Learning Book companion videos               | Ian Goodfellow and others                      | DL-book slides | YouTube-Lectures | 2017            |\n| 33.  | Theories of Deep Learning                         | Many Legends, Stanford                         | Stats-385                     | YouTube-Lectures  (first 10 lectures) | F2017           |\n| 34.  | Neural Networks                                   | Grant Sanderson                                | None                                                       | YouTube-Lectures | 2017-2018       |\n| 35.  | CS230: Deep Learning                              | Andrew Ng, Kian Katanforoosh, Stanford         | CS230                          | YouTube-Lectures | A2018           |\n| 36.  | Theory of Deep Learning                           | Lots of Legends, Canary Islands                | DALI'18 | YouTube-Lectures | 2018            |\n| 37.  | Introduction to Deep Learning                     | Alex Smola, UC Berkeley                        | Stat-157 | YouTube-Lectures | S2019           |\n| 38.  | Deep Unsupervised Learning                        | Pieter Abbeel, UC Berkeley                     | CS294-158 | YouTube-Lectures | S2019           |\n| 39.  | Machine Learning                                  | Peter Bloem, Vrije Universiteit Amsterdam      | MLVU                              | YouTube-Lectures | 2019            |\n| 40.  | Deep Learning on Computational Accelerators       | Alex Bronstein and Avi Mendelson, Technion     | CS236605 | YouTube-Lectures | S2019           |\n|      |                                                       |                                                |                                                              |                                                              |                 |\n| 41.  | Introduction to Deep Learning                     | Bhiksha Raj and many others, CMU               | 11-785 | YouTube-Lectures | S2019           |\n| 42.  | Introduction to Deep Learning                     | Bhiksha Raj and many others, CMU               | 11-785 | YouTube-Lectures  Recitations | F2019           |\n| 43.  | UvA Deep Learning                                 | Efstratios Gavves, University of Amsterdam     | UvA-DLC                         | Lecture-Videos | S2019           |\n| 44. | Deep Learning | Prabir Kumar Biswas, IIT Kgp | None | YouTube-Lectures | 2019 |\n| 45. | Deep Learning and its Applications | Aditya Nigam, IIT Mandi | CS-671 | YouTube-Lectures | 2019 |\n| 46. | Neural Networks                                   | Neil Rhodes, Harvey Mudd College               | CS-152 | YouTube-Lectures | F2019           |\n| 47. | Deep Learning                                     | Thomas Hofmann, ETH Z\u00fcrich                     | DAL-DL | Lecture-Videos | F2019           |\n| 48. | Deep Learning                                     | Milan Straka, Charles University               | NPFL114 | Lecture-Videos | S2019 |\n| 49. | UvA Deep Learning | Efstratios Gavves, University of Amsterdam | UvA-DLC-19 | Lecture-Videos | F2019 |\n| 50. | Artificial Intelligence: Principles and Techniques | Percy Liang and Dorsa Sadigh, Stanford University | CS221 | YouTube-Lectures | F2019 |\n|  |  |  |  |  |  |\n| 51. | Analyses of Deep Learning | Lots of Legends, Stanford University | STATS-385 | YouTube-Lectures | 2017-2019 |\n| 52. | Deep Learning Foundations and Applications | Debdoot Sheet and Sudeshna Sarkar, IIT-Kgp | AI61002 | YouTube-Lectures | S2020 |\n| 53. | Designing, Visualizing, and Understanding Deep Neural Networks | John Canny, UC Berkeley | CS 182/282A | YouTube-Lectures | S2020 |\n| 54. | Deep Learning | Yann LeCun and Alfredo Canziani, NYU | DS-GA 1008 | YouTube-Lectures | S2020 |\n| 55. | Introduction to Deep Learning | Bhiksha Raj, CMU | 11-785 | YouTube-Lectures | S2020 |\n| 56. | Deep Unsupervised Learning | Pieter Abbeel, UC Berkeley | CS294-158 | YouTube-Lectures | S2020 |\n| 57. | Machine Learning | Peter Bloem, Vrije Universiteit Amsterdam | VUML | YouTube-Lectures | S2020 |\n| 58. | Deep Learning (with PyTorch) | Alfredo Canziani and Yann LeCun, NYU | DS-GA 1008 | YouTube-Lectures | S2020 |\n| 59. | Introduction to Deep Learning and Generative Models | Sebastian Raschka, UW-Madison | Stat453 | YouTube-Lectures | S2020 |\n| 60. | Deep Learning | Andreas Maier, FAU Erlangen-N\u00fcrnberg | DL-2020 | YouTube-Lectures Lecture-Videos | SS2020 |\n|  |  |  |  |  |  |\n| 61. | Introduction to Deep Learning | Laura Leal-Taix\u00e9 and Matthias Niessner, TU-M\u00fcnchen | I2DL-IN2346 | YouTube-Lectures | SS2020 |\n| 62. | Deep Learning | Sargur Srihari, SUNY-Buffalo | CSE676 | YouTube-Lectures-P1 YouTube-Lectures-P2 | 2020 |\n| 63. | Deep Learning Lecture Series | Lots of Legends, DeepMind x UCL, London | DLLS-20 | YouTube-Lectures | 2020 |\n| 64. | MultiModal Machine Learning | Louis-Philippe Morency & others, Carnegie Mellon University | 11-777 MMML-20 | YouTube-Lectures | F2020 |\n| 65. | Reliable and Interpretable Artificial Intelligence | Martin Vechev, ETH Z\u00fcrich | RIAI-20 | YouTube-Lectures | F2020 |\n| 66. | Fundamentals of Deep Learning | David McAllester, Toyota Technological Institute, Chicago | TTIC-31230 | YouTube-Lectures | F2020 |\n| 67. | Foundations of Deep Learning | Soheil Feize, University of Maryland, College Park | CMSC 828W | YouTube-Lectures | F2020 |\n| 68. | Deep Learning | Andreas Geiger, Universit\u00e4t T\u00fcbingen | DL-UT | YouTube-Lectures | W20/21 |\n| 69. | Deep Learning | Andreas Maier, FAU Erlangen-N\u00fcrnberg | DL-FAU | YouTube-Lectures | W20/21 |\n| 70. | Fundamentals of Deep Learning | Terence Parr and Yannet Interian, University of San Francisco | DL-Fundamentals | YouTube-Lectures | S2021 |\n|  |  |  |  |  |  |\n| 71. | Full Stack Deep Learning | Pieter Abbeel, Sergey Karayev, UC Berkeley | FS-DL | YouTube-Lectures | S2021 |\n| 72. | Deep Learning: Designing, Visualizing, and Understanding DNNs | Sergey Levine, UC Berkeley | CS 182 | YouTube-Lectures | S2021 |\n| 73. | Deep Learning in the Life Sciences | Manolis Kellis, MIT | 6.874 | YouTube-Lectures | S2021 |\n| 74. | Introduction to Deep Learning and Generative Models | Sebastian Raschka, University of Wisconsin-Madison | Stat 453 | YouTube-Lectures | S2021 |\n| 75. | Deep Learning | Alfredo Canziani and Yann LeCun, NYU | NYU-DLSP21 | YouTube-Lectures | S2021 |\n| 76. | Applied Deep Learning | Alexander Pacha, TU Wien | None | YouTube-Lectures | 2020-2021 |\n| 77. | Machine Learning | Hung-yi Lee, National Taiwan University | ML'21 | YouTube-Lectures | S2021 |\n| 78. | Mathematics of Deep Learning | Lots of legends, FAU | MoDL | Lecture-Videos | 2019-21 |\n| 79. | Deep Learning | Peter Bloem, Michael Cochez, and Jakub Tomczak, VU-Amsterdam | DL | YouTube-Lectures | 2020-21 |\n| 80. | Applied Deep Learning | Maziar Raissi, UC Boulder | ADL'21 | YouTube-Lectures | 2021 |\n| | | | | | |\n| 81. | An Introduction to Group Equivariant Deep Learning | Erik J. Bekkers, Universiteit van Amsterdam | UvAGEDL | YouTube-Lectures | 2022 |\n| | | | | | |\nGo to Contents :arrow_heading_up: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:cupid: Machine Learning Fundamentals :cyclone: :boom:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                                  | University/Instructor(s)                                | Course Webpage                                               | Video Lectures                                               | Year       |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------- |\n| 1.   | Linear Algebra                                           | Gilbert Strang, MIT                                     | 18.06 SC                    | YouTube-Lectures | 2011       |\n| 2.   | Probability Primer                                       | Jeffrey Miller, Brown University                        | mathematical monk                                          | YouTube-Lectures | 2011       |\n| 3.   | Information Theory, Pattern Recognition, and Neural Networks | David Mackay, University of Cambridge                   | ITPRNN          | YouTube-Lectures | 2012       |\n| 4.   | Linear Algebra Review                                    | Zico Kolter, CMU                                        | LinAlg | YouTube-Lectures | 2013       |\n| 5.   | Probability and Statistics                               | Michel van Biezen                                       | None                                                       | YouTube-Lectures | 2015       |\n| 6.   | Linear Algebra: An in-depth Introduction                 | Pavel Grinfeld                                          | None                                                       | Part-1  Part-2  Part-3  Part-4 | 2015- 2017 |\n| 7.   | Multivariable Calculus                                   | Grant Sanderson, Khan Academy                           | None                                                       | YouTube-Lectures | 2016       |\n| 8.   | Essence of Linear Algebra                                | Grant Sanderson                                         | None                                                       | YouTube-Lectures | 2016       |\n| 9.   | Essence of Calculus                                      | Grant Sanderson                                         | None                                                       | YouTube-Lectures | 2017-2018  |\n| 10.  | Math Background for Machine Learning                     | Geoff Gordon, CMU                                       | 10-606, 10-607 | YouTube-Lectures | F2017      |\n|      |                                                              |                                                         |                                                              |                                                              |            |\n| 11.  | Mathematics for Machine Learning (Linear Algebra, Calculus) | David Dye, Samuel Cooper, and Freddie Page, IC-London   | MML | YouTube-Lectures | 2018       |\n| 12.  | Multivariable Calculus                                   | S.K. Gupta and Sanjeev Kumar, IIT-Roorkee               | MVC               | YouTube-Lectures | 2018       |\n| 13.  | Engineering Probability                                  | Rich Radke, Rensselaer Polytechnic Institute            | None                                                       | YouTube-Lectures | 2018       |\n| 14.  | Matrix Methods in Data Analysis, Signal Processing, and Machine Learning | Gilbert Strang, MIT                                     | 18.065 | YouTube-Lectures | S2018      |\n| 15.  | Information Theory                                       | Himanshu Tyagi, IISC, Bengaluru                         | E2 201 | YouTube-Lectures | 2018-20    |\n| 16.  | Math Camp                                                | Mark Walker, University of Arizona                      | UAMathCamp / Econ-519 | YouTube-Lectures | 2019       |\n| 17.  | A 2020 Vision of Linear Algebra                          | Gilbert Strang, MIT                                     | VoLA | YouTube-Lectures | S2020      |\n| 18.  | Mathematics for Numerical Computing and Machine Learning | Szymon Rusinkiewicz, Princeton University               | COS-302 | YouTube-Lectures | F2020      |\n| 19.  | Essential Statistics for Neuroscientists                 | Philipp Berens, Universit\u00e4t Klinikum T\u00fcbingen           | None                                                       | YouTube-Lectures | 2020       |\n| 20.  | Mathematics for Machine Learning                         | Ulrike von Luxburg, Eberhard Karls Universit\u00e4t T\u00fcbingen | Math4ML | YouTube-Lectures | W2020      |\n| 21.  | Introduction to Causal Inference                         | Brady Neal, Mila, Montr\u00e9al                              | CausalInf | YouTube-Lectures | F2020      |\n| 22.  | Applied Linear Algebra                                   | Andrew Thangaraj, IIT Madras                            | EE5120            | YouTube-Lectures | 2021       |\n| 23.  | Mathematical Tools for Data Science                      | Carlos Fernandez-Granda, New York University            | DS-GA 1013/Math-GA 2824    | YouTube-Lectures | 2021       |\n| 24.  | Mathematics for Numerical Computing and Machine Learning | Ryan Adams, Princeton University                        | COS 302 / SML 305 | YouTube-Lectures | 2021       |\n|      |                                                              |                                                         |                                                              |                                                              |            |\n|      |                                                              |                                                         |                                                              |                                                              |            |\nGo to Contents :arrow_heading_up: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:cupid: Optimization for Machine Learning :cyclone: :boom:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                                  | University/Instructor(s)                                     | Course Webpage                                               | Video Lectures                                               | Year       |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------- |\n| 1.   | Convex Optimization                                      | Stephen Boyd, Stanford University                            | ee364a | YouTube-Lectures | 2008       |\n| 2.   | Introduction to Optimization                             | Michael Zibulevsky, Technion                                 | CS-236330 | YouTube-Lectures | 2009       |\n| 3.   | Optimization for Machine Learning                        | S V N Vishwanathan, Purdue University                        | None                                                       | YouTube-Lectures | 2011       |\n| 4.   | Optimization                                             | Geoff Gordon & Ryan Tibshirani, CMU                          | 10-725         | YouTube-Lectures | 2012       |\n| 5.   | Convex Optimization                                      | Joydeep Dutta, IIT-Kanpur                                    | cvx-nptel   | YouTube-Lectures | 2013       |\n| 6.   | Foundations of Optimization                              | Joydeep Dutta, IIT-Kanpur                                    | fop-nptel   | YouTube-Lectures | 2014       |\n| 7.   | Algorithmic Aspects of Machine Learning                  | Ankur Moitra, MIT                                            | 18.409-AAML   | YouTube-Lectures | S2015      |\n| 8.   | Numerical Optimization                                   | Shirish K. Shevade, IISC                                     | None                                                       | YouTube-Lectures | 2015       |\n| 9.   | Convex Optimization                                      | Ryan Tibshirani, CMU                                         | 10-725  | YouTube-Lectures | S2015      |\n| 10.  | Convex Optimization                                      | Ryan Tibshirani, CMU                                         | 10-725       | YouTube-Lectures | F2015      |\n| 11.  | Advanced Algorithms                                      | Ankur Moitra, MIT                                            | 6.854-AA      | YouTube-Lectures | S2016      |\n| 12.  | Introduction to Optimization                             | Michael Zibulevsky, Technion                                 | None                                                       | YouTube-Lectures | 2016       |\n| 13.  | Convex Optimization                                      | Javier Pe\u00f1a & Ryan Tibshirani                                | 10-725/36-725 | YouTube-Lectures | F2016      |\n| 14.  | Convex Optimization                                      | Ryan Tibshirani, CMU                                         | 10-725  | YouTube-Lectures  Lecture-Videos | F2018      |\n| 15.  | Modern Algorithmic Optimization                          | Yurii Nesterov, UCLouvain                                    | None                                                       | YouTube-Lectures | 2018       |\n| 16.  | Optimization, Foundations of Optimization                | Mark Walker, University of Arizona                           | MathCamp-20 | YouTube-Lectures-Found.  YouTube-Lectures-Opt | 2019 - now |\n| 17.  | Optimization: Principles and Algorithms                  | Michel Bierlaire, \u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL) | opt-algo | YouTube-Lectures | 2019       |\n| 18.  | Optimization and Simulation                              | Michel Bierlaire, \u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL) | opt-sim | YouTube-Lectures | S2019      |\n| 19.  | Brazilian Workshop on Continuous Optimization            | Lots of Legends, Instituto Nacional de Matem\u00e1tica Pura e Aplicada, Rio de Janeiro | cont. opt. | YouTube-Lectures | 2019       |\n| 20.  | One World Optimization Seminar                           | Lots of Legends, Universit\u00e4t Wien                            | 1W-OPT                          | YouTube-Lectures | 2020-      |\n|      |                                                              |                                                              |                                                              |                                                              |            |\n| 21.  | Convex Optimization II                                   | Constantine Caramanis, UT Austin                             | CVX-Optim-II | YouTube-Lectures | S2020      |\n| 22.  | Combinatorial Optimization                               | Constantine Caramanis, UT Austin                             | comb-op             | YouTube-Lectures | F2020      |\n| 23.  | Optimization Methods for Machine Learning and Engineering | Julius Pfrommer, J\u00fcrgen Beyerer, Karlsruher Institut f\u00fcr Technologie (KIT) | Optim-MLE, slides | YouTube-Lectures | W2020-21   |\n|      |                                                              |                                                              |                                                              |                                                              |            |\nGo to Contents :arrow_heading_up: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:cupid: General Machine Learning :cyclone: :boom:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                                  | University/Instructor(s)                                     | Course Webpage                                               | Video Lectures                                               | Year      |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- |\n| 1.   | CS229: Machine Learning                                  | Andrew Ng, Stanford University                               | CS229-old  CS229-new | YouTube-Lectures | 2007      |\n| 2.   | Machine Learning                                         | Jeffrey Miller, Brown University                             | mathematical monk                                          | YouTube-Lectures | 2011      |\n| 3.   | Machine Learning                                         | Tom Mitchell, CMU                                            | 10-701             | Lecture-Videos | 2011      |\n| 4.   | Machine Learning and Data Mining                         | Nando de Freitas, University of British Columbia             | CPSC-340  | YouTube-Lectures | 2012      |\n| 5.   | Learning from Data                                       | Yaser Abu-Mostafa, CalTech                                   | CS156             | YouTube-Lectures | 2012      |\n| 6.   | Machine Learning                                         | Rudolph Triebel, Technische Universit\u00e4t M\u00fcnchen              | Machine Learning | YouTube-Lectures | 2013      |\n| 7.   | Introduction to Machine Learning                         | Alex Smola, CMU                                              | 10-701     | YouTube-Lectures | 2013      |\n| 8.   | Introduction to Machine Learning                         | Alex Smola and Geoffrey Gordon, CMU                          | 10-701x   | YouTube-Lectures | 2013      |\n| 9.   | Pattern Recognition                                      | Sukhendu Das, IIT-M and C.A. Murthy, ISI-Calcutta            | PR-NPTEL          | YouTube-Lectures | 2014      |\n| 10.  | An Introduction to Statistical Learning with Applications in R | Trevor Hastie and Robert Tibshirani, Stanford                | stat-learn  R-bloggers | YouTube-Lectures | 2014      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 11.  | Introduction to Machine Learning                         | Katie Malone, Sebastian Thrun, Udacity                       | ML-Udacity           | YouTube-Lectures | 2015      |\n| 12.  | Introduction to Machine Learning                         | Dhruv Batra, Virginia Tech                                   | ECE-5984          | YouTube-Lectures | 2015      |\n| 13.  | Statistical Learning - Classification                    | Ali Ghodsi, University of Waterloo                           | STAT-441 | YouTube-Lectures | 2015      |\n| 14.  | Machine Learning Theory                                  | Shai Ben-David, University of Waterloo                       | None                                                       | YouTube-Lectures | 2015      |\n| 15.  | Introduction to Machine Learning                         | Alex Smola, CMU                                              | 10-701          | YouTube-Lectures | S2015     |\n| 16.  | Statistical Machine Learning                             | Larry Wasserman, CMU                                         | None                                                       | YouTube-Lectures | S2015     |\n| 17.  | ML: Supervised Learning                                  | Michael Littman, Charles Isbell, Pushkar Kolhe, GaTech       | ML-Udacity | YouTube-Lectures | 2015      |\n| 18.  | ML: Unsupervised Learning                                | Michael Littman, Charles Isbell, Pushkar Kolhe, GaTech       | ML-Udacity | YouTube-Lectures | 2015      |\n| 19.  | Advanced Introduction to Machine Learning                | Barnabas Poczos and Alex Smola                               | 10-715 | YouTube-Lectures | F2015     |\n| 20.  | Machine Learning                                         | Pedro Domingos, UWashington                                  | CSEP-546 | YouTube-Lectures | S2016     |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 21.  | Statistical Machine Learning                             | Larry Wasserman, CMU                                         | None                                                       | YouTube-Lectures | S2016     |\n| 22.  | Machine Learning with Large Datasets                     | William Cohen, CMU                                           | 10-605 | YouTube-Lectures | F2016     |\n| 23.  | Math Background for Machine Learning                     | Geoffrey Gordon, CMU                                         | 10-600                                                     | YouTube-Lectures | F2016     |\n| 24.  | Statistical Learning - Classification                    | Ali Ghodsi, University of Waterloo                           | None                                                       | YouTube-Lectures | 2017      |\n| 25.  | Machine Learning                                         | Andrew Ng, Stanford University                               | Coursera-ML | YouTube-Lectures | 2017      |\n| 26.  | Machine Learning                                         | Roni Rosenfield, CMU                                         | 10-601             | YouTube-Lectures | 2017      |\n| 27.  | Statistical Machine Learning                             | Ryan Tibshirani, Larry Wasserman, CMU                        | 10-702          | YouTube-Lectures | S2017     |\n| 28.  | Machine Learning for Computer Vision                     | Fred Hamprecht, Heidelberg University                        | None                                                       | YouTube-Lectures | F2017     |\n| 29.  | Math Background for Machine Learning                     | Geoffrey Gordon, CMU                                         | 10-606 / 10-607 | YouTube-Lectures | F2017     |\n| 30.  | Data Visualization                                       | Ali Ghodsi, University of Waterloo                           | None                                                       | YouTube-Lectures | 2017      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 31.  | Machine Learning for Physicists                          | Florian Marquardt, Uni Erlangen-N\u00fcrnberg                     | ML4Phy-17 | Lecture-Videos | 2017      |\n| 32.  | Machine Learning for Intelligent Systems                 | Kilian Weinberger, Cornell University                        | CS4780   | YouTube-Lectures | F2018     |\n| 33.  | Statistical Learning Theory and Applications             | Tomaso Poggio, Lorenzo Rosasco, Sasha Rakhlin                | 9.520/6.860                 | YouTube-Lectures | F2018     |\n| 34.  | Machine Learning and Data Mining                         | Mike Gelbart, University of British Columbia                 | CPSC-340                | YouTube-Lectures | 2018      |\n| 35.  | Foundations of Machine Learning                          | David Rosenberg, Bloomberg                                   | FOML               | YouTube-Lectures | 2018      |\n| 36.  | Introduction to Machine Learning                         | Andreas Krause, ETH Z\u00fcrich                                   | IntroML      | YouTube-Lectures | 2018      |\n| 37.  | Machine Learning Fundamentals                            | Sanjoy Dasgupta, UC-San Diego                                | MLF-slides | YouTube-Lectures | 2018      |\n| 38.  | Machine Learning                                         | Jordan Boyd-Graber, University of Maryland                   | CMSC-726 | YouTube-Lectures | 2015-2018 |\n| 39.  | Machine Learning                                         | Andrew Ng, Stanford University                               | CS229  | YouTube-Lectures | 2018      |\n| 40.  | Machine Intelligence                                     | H.R.Tizhoosh, UWaterloo                                      | SYDE-522 | YouTube-Lectures | 2019      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 41.  | Introduction to Machine Learning                         | Pascal Poupart, University of Waterloo                       | CS480/680 | YouTube-Lectures | S2019     |\n| 42.  | Advanced Machine Learning                                | Thorsten Joachims, Cornell University                        | CS-6780  | Lecture-Videos | S2019     |\n| 43.  | Machine Learning for Structured Data                     | Matt Gormley, Carnegie Mellon University                     | 10-418/10-618 | YouTube-Lectures | F2019     |\n| 44.  | Advanced Machine Learning                                | Joachim Buhmann, ETH Z\u00fcrich                                  | ML2-AML              | Lecture-Videos | F2019     |\n| 45.  | Machine Learning for Signal Processing                   | Vipul Arora, IIT-Kanpur                                      | MLSP | Lecture-Videos | F2019     |\n| 46.  | Foundations of Machine Learning                          | Animashree Anandkumar, CalTech                               | CMS-165 | YouTube-Lectures | 2019      |\n| 47.  | Machine Learning for Physicists                          | Florian Marquardt, Uni Erlangen-N\u00fcrnberg                     | None                                                       | Lecture-Videos | 2019      |\n| 48.  | Applied Machine Learning                                 | Andreas M\u00fcller, Columbia University                          | COMS-W4995 | YouTube-Lectures | 2019      |\n| 49.  | Fundamentals of Machine Learning over Networks           | Hossein Shokri-Ghadikolaei, KTH, Sweden                      | MLoNs | YouTube-Lectures | 2019      |\n| 50.  | Foundations of Machine Learning and Statistical Inference | Animashree Anandkumar, CalTech                               | CMS-165 | YouTube-Lectures | 2020      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 51.  | Machine Learning                                         | Rebecca Willett and Yuxin Chen, University of Chicago        | STAT 37710 / CMSC 35400 | Lecture-Videos | S2020     |\n| 52.  | Introduction to Machine Learning                         | Sanjay Lall and Stephen Boyd, Stanford University            | EE104/CME107                    | YouTube-Lectures | S2020     |\n| 53.  | Applied Machine Learning                                 | Andreas M\u00fcller, Columbia University                          | COMS-W4995 | YouTube-Lectures | S2020     |\n| 54.  | Statistical Machine Learning                             | Ulrike von Luxburg, Eberhard Karls Universit\u00e4t T\u00fcbingen      | Stat-ML | YouTube-Lectures | SS2020    |\n| 55.  | Probabilistic Machine Learning                           | Philipp Hennig, Eberhard Karls Universit\u00e4t T\u00fcbingen          | Prob-ML                | YouTube-Lectures | SS2020    |\n| 56.  | Machine Learning                                         | Sarath Chandar, PolyMTL, UdeM, Mila                          | INF8953CE    | YouTube-Lectures | F2020     |\n| 57.  | Machine Learning                                         | Erik Bekkers, Universiteit van Amsterdam                     | UvA-ML                          | YouTube-Lectures | F2020     |\n| 58.  | Neural Networks for Signal Processing                    | Shayan Srinivasa Garani, Indian Institute of Science         | NN4SP | YouTube-Lectures | F2020     |\n| 59.  | Introduction to Machine Learning                         | Dmitry Kobak, Universit\u00e4t Klinikum T\u00fcbingen                  | None                                                       | YouTube-Lectures | 2020      |\n| 60.  | Machine Learning (PRML)                                  | Erik J. Bekkers, Universiteit van Amsterdam                  | UvAML-1                          | YouTube-Lectures | 2020      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 61.  | Machine Learning with Kernel Methods                     | Julien Mairal and Jean-Philippe Vert, Inria/ENS Paris-Saclay, Google | ML-Kernels | YouTube-Lectures | S2021     |\n| 62.  | Continual Learning                                       | Vincenzo Lomonaco, Universit\u00e0 di Pisa                        | ContLearn'21 | YouTube-Lectures | 2021      |\n| 63.  | Causality                                                | Christina Heinze-Deml, ETH Zurich                            | Causal'21 | YouTube-Lectures | 2021      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\nGo to Contents :arrow_heading_up: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:balloon: Reinforcement Learning :hotsprings: :video_game:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                              | University/Instructor(s)                                     | Course Webpage                                               | Video Lectures                                               | Year   |\n| ---- | -------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------ |\n| 1.   | A Short Course on Reinforcement Learning             | Satinder Singh, UMichigan                                    | None                                                       | YouTube-Lectures | 2011   |\n| 2.   | Approximate Dynamic Programming                      | Dimitri P. Bertsekas, MIT                                    | Lecture-Slides | YouTube-Lectures | 2014   |\n| 3.   | Introduction to Reinforcement Learning               | David Silver, DeepMind                                       | UCL-RL | YouTube-Lectures | 2015   |\n| 4.   | Reinforcement Learning                               | Charles Isbell, Chris Pryby, GaTech; Michael Littman, Brown  | RL-Udacity | YouTube-Lectures | 2015   |\n| 5.   | Reinforcement Learning                               | Balaraman Ravindran, IIT Madras                              | RL-IITM | YouTube-Lectures | 2016   |\n| 6.   | Deep Reinforcement Learning                          | Sergey Levine, UC Berkeley                                   | CS-294    | YouTube-Lectures | S2017  |\n| 7.   | Deep Reinforcement Learning                          | Sergey Levine, UC Berkeley                                   | CS-294   | YouTube-Lectures | F2017  |\n| 8.   | Deep RL Bootcamp                                     | Many legends, UC Berkeley                                    | Deep-RL | YouTube-Lectures | 2017   |\n| 9    | Data Efficient Reinforcement Learning                | Lots of Legends, Canary Islands                              | DERL-17 | YouTube-Lectures | 2017   |\n| 10.  | Deep Reinforcement Learning                          | Sergey Levine, UC Berkeley                                   | CS-294-112 | YouTube-Lectures | 2018   |\n|      |                                                          |                                                              |                                                              |                                                              |        |\n| 11.  | Reinforcement Learning                               | Pascal Poupart, University of Waterloo                       | CS-885 | YouTube-Lectures | 2018   |\n| 12.  | Deep Reinforcement Learning and Control              | Katerina Fragkiadaki and Tom Mitchell, CMU                   | 10-703           | YouTube-Lectures | 2018   |\n| 13.  | Reinforcement Learning and Optimal Control           | Dimitri Bertsekas, Arizona State University                  | RLOC          | Lecture-Videos | 2019   |\n| 14.  | Reinforcement Learning                               | Emma Brunskill, Stanford University                          | CS 234     | YouTube-Lectures | 2019   |\n| 15.  | Reinforcement Learning Day                           | Lots of Legends, Microsoft Research, New York                | RLD-19 | YouTube-Lectures | 2019   |\n| 16.  | New Directions in Reinforcement Learning and Control | Lots of Legends, IAS, Princeton University                   | NDRLC-19                   | YouTube-Lectures | 2019   |\n| 17.  | Deep Reinforcement Learning                          | Sergey Levine, UC Berkeley                                   | CS 285    | YouTube-Lectures | F2019  |\n| 18.  | Deep Multi-Task and Meta Learning                    | Chelsea Finn, Stanford University                            | CS 330                        | YouTube-Lectures | F2019  |\n| 19.  | RL-Theory Seminars                                   | Lots of Legends, Earth                                       | RL-theory-sem | YouTube-Lectures | 2020 - |\n| 20.  | Deep Reinforcement Learning                          | Sergey Levine, UC Berkeley                                   | CS 285    | YouTube-Lectures | F2020  |\n|      |                                                          |                                                              |                                                              |                                                              |        |\n| 21.  | Introduction to Reinforcement Learning               | Amir-massoud Farahmand, Vector Institute, University of Toronto | RL-intro            | YouTube-Lectures | S2021  |\n| 22.  | Reinforcement Learning                               | Antonio Celani and Emanuele Panizon, International Centre for Theoretical Physics | None                                                       | YouTube-Lectures | 2021   |\n| 23.  | Computational Sensorimotor Learning                  | Pulkit Agrawal, MIT-CSAIL                                    | 6.884-CSL       | YouTube-Lectures | S2021  |\n| 24.  | Reinforcement Learning                               | Dimitri P. Bertsekas, ASU/MIT                                | RL-21         | YouTube-Lectures | S2021  |\n| 25.  | Reinforcement Learning                               | Sarath Chandar,  \u00c9cole Polytechnique de Montr\u00e9al             | INF8953DE         | YouTube-Lectures | F2021  |\n| 26.  | Deep Reinforcement Learning                          | Sergey Levine, UC Berkeley                                   | CS 285         | YouTube-Lectures | F2021  |\n| 27.  | Reinforcement Learning Lecture Series                | Lots of Legends, DeepMind & UC London                        | RL-series | YouTube-Lectures | 2021   |\n| 28.  | Reinforcement Learning                               | Dimitri P. Bertsekas, ASU/MIT                                | RL-22         | YouTube-Lectures | S2022  |\n|      |                                                          |                                                              |                                                              |                                                              |        |\nGo to Contents :arrow_heading_up: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:loudspeaker: Probabilistic Graphical Models :sparkles:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                                  | University/Instructor(s)                            | Course WebPage                                               | Lecture Videos                                               | Year    |\n| ---- | ------------------------------------------------------------ | --------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------- |\n| 1.   | Probabilistic Graphical Models                           | Many Legends, MPI-IS                                | MLSS-Tuebingen | YouTube-Lectures | 2013    |\n| 2.   | Probabilistic Modeling and Machine Learning              | Zoubin Ghahramani, University of Cambridge          | WUST-Wroclaw | YouTube-Lectures | 2013    |\n| 3.   | Probabilistic Graphical Models                           | Eric Xing, CMU                                      | 10-708 | YouTube-Lectures | 2014    |\n| 4.   | Learning with Structured Data: An Introduction to Probabilistic Graphical Models | Christoph Lampert, IST Austria                      | None                                                       | YouTube-Lectures | 2016    |\n| 5.   | Probabilistic Graphical Models                           | Nicholas Zabaras, University of Notre Dame          | PGM | YouTube-Lectures | 2018    |\n| 6.   | Probabilistic Graphical Models                           | Eric Xing, CMU                                      | 10-708      | Lecture-Videos  YouTube-Lectures | S2019   |\n| 7.   | Probabilistic Graphical Models                           | Eric Xing, CMU                                      | 10-708 | YouTube-Lectures | S2020   |\n| 8.   | Uncertainty Modeling in AI                               | Gim Hee Lee, National University of Singapura (NUS) | CS 5340 - CH, CS 5340-NB | YouTube-Lectures | 2020-21 |\n|      |                                                              |                                                     |                                                              |                                                              |         |\nGo to Contents :arrow_heading_up:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:game_die: Bayesian Deep Learning :spades: :gem:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                         | University/Instructor(s)          | Course WebPage                                           | Lecture Videos                                               | Year     |\n| ---- | --------------------------------------------------- | --------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ | -------- |\n| 1.   | Bayesian Neural Networks, Variational Inference | Lots of Legends                   | None                                                   | YouTube-Lectures | 2014-now |\n| 2.   | Variational Inference                           | Chieh Wu, Northeastern University | None                                                   | YouTube-Lectures | 2015     |\n| 3.   | Deep Learning and Bayesian Methods              | Lots of Legends, HSE Moscow       | DLBM-SS                      | YouTube-Lectures | 2018     |\n| 4.   | Deep Learning and Bayesian Methods              | Lots of Legends, HSE Moscow       | DLBM-SS                          | YouTube-Lectures | 2019     |\n| 5.   | Nordic Probabilistic AI                         | Lots of Legends, NTNU, Trondheim  | ProbAI | YouTube-Lectures | 2019     |\n|      |                                                     |                                   |                                                          |                                                              |          |\nGo to Contents :arrow_heading_up:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:movie_camera: Medical Imaging :camera: :video_camera:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                                  | University/Instructor(s)                    | Course WebPage                                               | Lecture Videos                                               | Year  |\n| ---- | ------------------------------------------------------------ | ------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----- |\n| 1.   | Medical Imaging Summer School                            | Lots of Legends, Sicily                     | MISS-14   | YouTube-Lectures | 2014  |\n| 2.   | Biomedical Image Analysis Summer School                  | Lots of Legends, Paris                      | None                                                       | YouTube-Lectures | 2015  |\n| 3.   | Medical Imaging Summer School                            | Lots of Legends, Sicily                     | MISS-16   | YouTube-Lectures | 2016  |\n| 4.   | OPtical and UltraSound imaging - OPUS                    | Lots of Legends, Universit\u00e9 de Lyon, France | OPUS'16 | YouTube-Lectures | 2016  |\n| 5.   | Medical Imaging Summer School                            | Lots of Legends, Sicily                     | MISS-18      | YouTube-Lectures | 2018  |\n| 6.   | Seminar on AI in Healthcare                              | Lots of Legends, Stanford                   | CS 522          | YouTube-Lectures | 2018  |\n| 7.   | Machine Learning for Healthcare                          | David Sontag, Peter Szolovits, CSAIL MIT    | MLHC-19 MIT 6.S897 | YouTube-Lectures | S2019 |\n| 8.   | Deep Learning and Medical Applications                   | Lots of Legends, IPAM, UCLA                 | DLM-20 | Lecture-Videos | 2020  |\n| 9.   | Stanford Symposium on Artificial Intelligence in Medicine and Imaging | Lots of Legends, Stanford AIMI              | AIMI-20 | YouTube-Lectures | 2020  |\n|      |                                                              |                                             |                                                              |                                                              |       |\nGo to Contents :arrow_heading_up:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:tada: Graph Neural Networks (Geometric DL) :confetti_ball: :balloon:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                                  | University/Instructor(s)                                | Course WebPage                                               | Lecture Videos                                               | Year  |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----- |\n| 1.   | Deep learning on graphs and manifolds                    | Michael Bronstein, Technion                             | None                                                       | YouTube-Lectures | 2017  |\n| 2.   | Geometric Deep Learning on Graphs and Manifolds          | Michael Bronstein, Technische Universit\u00e4t M\u00fcnchen       | None                                                       | Lec-part1,  Lec-part2 | 2017  |\n| 3.   | Eurographics Symposium on Geometry Processing - Graduate School | Lots of Legends, SIGGRAPH, London                       | SGP-2017 | YouTube-Lectures | 2017  |\n| 4.   | Eurographics Symposium on Geometry Processing - Graduate School | Lots of Legends, SIGGRAPH, Paris                        | SGP-2018 | YouTube-Lectures | 2018  |\n| 5.   | Analysis of Networks: Mining and Learning with Graphs    | Jure Leskovec, Stanford University                      | CS224W        | Lecture-Videos | 2018  |\n| 6.   | Machine Learning with Graphs                             | Jure Leskovec, Stanford University                      | CS224W        | YouTube-Lectures | 2019  |\n| 7.   | Geometry and Learning from Data in 3D and Beyond -Geometry and Learning from Data Tutorials | Lots of Legends, IPAM UCLA                              | GLDT | Lecture-Videos | 2019  |\n| 8.   | Geometry and Learning from Data in 3D and Beyond - Geometric Processing | Lots of Legends, IPAM UCLA                              | GeoPro | Lecture-Videos | 2019  |\n| 9.   | Geometry and Learning from Data in 3D and Beyond - Shape Analysis | Lots of Legends, IPAM UCLA                              | Shape-Analysis | Lecture-Videos | 2019  |\n| 10.  | Geometry and Learning from Data in 3D and Beyond - Geometry of Big Data | Lots of Legends, IPAM UCLA                              | Geo-BData | Lecture-Videos | 2019  |\n|      |                                                              |                                                         |                                                              |                                                              |       |\n| 11.  | Geometry and Learning from Data in 3D and Beyond - Deep Geometric Learning of Big Data and Applications | Lots of Legends, IPAM UCLA                              | DGL-BData | Lecture-Videos | 2019  |\n| 12.  | Israeli Geometric Deep Learning                          | Lots of Legends, Israel                                 | iGDL-20        | Lecture-Videos | 2020  |\n| 13.  | Machine Learning for Graphs and Sequential Data          | Stephan G\u00fcnnemann, Technische Universit\u00e4t M\u00fcnchen (TUM) | MLGS-20 | Lecture-Videos  | S2020 |\n| 14.  | Machine Learning with Graphs                             | Jure Leskovec, Stanford                                 | CS224W               | YouTube-Lectures | W2021 |\n| 15.  | Geometric Deep Learning - AMMI                           | Lots of Legends, Virtual                                | GDL-AMMI       | YouTube-Lectures | 2021  |\n| 16.  | Summer School on Geometric Deep Learning -               | Lots of Legends, DTU, DIKU & AAU                        | GDL- DTU, DIKU & AAU | Lecture-Videos | 2021  |\n| 17.  | Graph Neural Networks                                    | Alejandro Ribeiro, University of Pennsylvania           | ESE 514                        | YouTube-Lectures | F2021 |\n|      |                                                              |                                                         |                                                              |                                                              |       |\nGo to Contents :arrow_heading_up:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:hibiscus: Natural Language Processing :cherry_blossom: :sparkling_heart:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                         | University/Instructor(s)                                     | Course WebPage                                               | Lecture Videos                                               | Year      |\n| ---- | --------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- |\n| 1.   | Computational Linguistics I                     | Jordan Boyd-Graber, University of Maryland                   | CMS-723 | YouTube-Lectures | 2013-2018 |\n| 2.   | Deep Learning for Natural Language Processing   | Nils Reimers, TU Darmstadt                                   | DL4NLP | YouTube-Lectures | 2015-2017 |\n| 3.   | Deep Learning for Natural Language Processing   | Many Legends, DeepMind-Oxford                                | DL-NLP | YouTube-Lectures | 2017      |\n| 4.   | Deep Learning for Speech & Language             | UPC Barcelona                                                | DL-SL          | Lecture-Videos | 2017      |\n| 5.   | Neural Networks for Natural Language Processing | Graham Neubig, CMU                                           | NN4NLP Code | YouTube-Lectures | 2017      |\n| 6.   | Neural Networks for Natural Language Processing | Graham Neubig, CMU                                           | NN4-NLP         | YouTube-Lectures | 2018      |\n| 7.   | Deep Learning for NLP                           | Min-Yen Kan, NUS                                             | CS-6101 | YouTube-Lectures | 2018      |\n| 8.   | Neural Networks for Natural Language Processing | Graham Neubig, CMU                                           | NN4NLP          | YouTube-Lectures | 2019      |\n| 9.   | Natural Language Processing with Deep Learning  | Abigail See, Chris Manning, Richard Socher, Stanford University | CS224n              | YouTube-Lectures | 2019      |\n| 10.  | Natural Language Understanding                  | Bill MacCartney and Christopher Potts                        | CS224U              | YouTube-Lectures | S2019     |\n|      |                                                     |                                                              |                                                              |                                                              |           |\n| 11.  | Neural Networks for Natural Language Processing | Graham Neubig, Carnegie Mellon University                    | CS 11-747 | YouTube-Lectures | S2020     |\n| 12.  | Advanced Natural Language Processing            | Mohit Iyyer, UMass Amherst                                   | CS 685          | YouTube-Lectures | F2020     |\n| 13.  | Machine Translation                             | Philipp Koehn, Johns Hopkins University                      | EN 601.468/668      | YouTube-Lectures | F2020     |\n| 14.  | Neural Networks for NLP                         | Graham Neubig, Carnegie Mellon University                    | CS 11-747        | YouTube-Lectures | 2021      |\n| 15.  | Deep Learning for Natural Language Processing   | Kyunghyun Cho, New York University                           | DS-GA 1011 | YouTube-Lectures | F2021     |\n| 16.  | Natural Language Processing with Deep Learning  | Chris Manning, Stanford University                           | CS224n | YouTube-Lectures | 2021      |\n|      |                                                     |                                                              |                                                              |                                                              |           |\nGo to Contents :arrow_heading_up: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:speaking_head: Automatic Speech Recognition :speech_balloon: :thought_balloon:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                              | University/Instructor(s)       | Course WebPage                                      | Lecture Videos                                               | Year      |\n| ---- | ---------------------------------------- | ------------------------------ | --------------------------------------------------- | ------------------------------------------------------------ | --------- |\n| 1.   | Deep Learning for Speech & Language  | UPC Barcelona                  | DL-SL | Lecture-Videos  YouTube-Videos | 2017      |\n| 2.   | Speech and Audio in the Northeast    | Many Legends, Google NYC       | SANE-15    | YouTube-Videos | 2015      |\n| 3.   | Automatic Speech Recognition         | Samudra Vijaya K, TIFR         | None                                              | YouTube-Videos | 2016      |\n| 4.   | Speech and Audio in the Northeast    | Many Legends, Google NYC       | SANE-17    | YouTube-Videos | 2017      |\n| 5.   | Speech and Audio in the Northeast    | Many Legends, Google Cambridge | SANE-18    | YouTube-Videos | 2018      |\n|      |                                          |                                |                                                     |                                                              |           |\n| -1.  | Deep Learning for Speech Recognition | Many Legends, AoE              | None                                              | YouTube-Videos | 2015-2018 |\nGo to Contents :arrow_heading_up: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:fire: Modern Computer Vision :camera_flash: :movie_camera:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                                  | University/Instructor(s)                               | Course WebPage                                               | Lecture Videos                                               | Year       |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------- |\n| 1.   | Microsoft Computer Vision Summer School - (classical)    | Lots of Legends, Lomonosov Moscow State University     | None                                                       | YouTube-Videos  Russian-mirror | 2011       |\n| 2.   | Computer Vision - (classical)                            | Mubarak Shah, UCF                                      | CAP-5415 | YouTube-Lectures | 2012       |\n| 3.   | Image and Multidimensional Signal Processing - (classical) | William Hoff, Colorado School of Mines                 | CSCI 510/EENG 510 | YouTube-Lectures | 2012       |\n| 4.   | Computer Vision - (classical)                            | William Hoff, Colorado School of Mines                 | CSCI 512/EENG 512 | YouTube-Lectures | 2012       |\n| 5.   | Image and Video Processing: From Mars to Hollywood with a Stop at the Hospital | Guillermo Sapiro, Duke University                      | None                                                       | YouTube-Videos | 2013       |\n| 6.   | Multiple View Geometry (classical)                       | Daniel Cremers, Technische Universit\u00e4t M\u00fcnchen         | mvg      | YouTube-Lectures | 2013       |\n| 7.   | Mathematical Methods for Robotics, Vision, and Graphics  | Justin Solomon, Stanford University                    | CS-205A      | YouTube-Lectures | 2013       |\n| 8.   | Computer Vision - (classical)                            | Mubarak Shah, UCF                                      | CAP-5415 | YouTube-Lectures | 2014       |\n| 9.   | Computer Vision for Visual Effects (classical)           | Rich Radke, Rensselaer Polytechnic Institute           | ECSE-6969 | YouTube-Lectures | S2014      |\n| 10.  | Autonomous Navigation for Flying Robots                  | Juergen Sturm, Technische Universit\u00e4t M\u00fcnchen          | Autonavx   | YouTube-Lectures | 2014       |\n|      |                                                              |                                                        |                                                              |                                                              |            |\n| 11.  | SLAM - Mobile Robotics                                   | Cyrill Stachniss, Universitaet Freiburg                | RobotMapping | YouTube-Lectures | 2014       |\n| 12.  | Computational Photography                                | Irfan Essa, David Joyner, Arpan Chakraborty            | CP-Udacity | YouTube-Lectures | 2015       |\n| 13.  | Introduction to Digital Image Processing                 | Rich Radke, Rensselaer Polytechnic Institute           | ECSE-4540 | YouTube-Lectures | S2015      |\n| 14.  | Lectures on Digital Photography                          | Marc Levoy, Stanford/Google Research                   | LoDP     | YouTube-Lectures | 2016       |\n| 15.  | Introduction to Computer Vision (foundation)             | Aaron Bobick, Irfan Essa, Arpan Chakraborty            | CV-Udacity | YouTube-Lectures | 2016       |\n| 16.  | Computer Vision                                          | Syed Afaq Ali Shah, University of Western Australia    | None                                                       | YouTube-Lectures | 2016       |\n| 17.  | Photogrammetry I & II                                    | Cyrill Stachniss, University of Bonn                   | PG-I&II  | YouTube-Lectures | 2016       |\n| 18.  | Deep Learning for Computer Vision                        | UPC Barcelona                                          | DLCV-16  DLCV-17  DLCV-18 | YouTube-Lectures | 2016-2018  |\n| 19.  | Convolutional Neural Networks                            | Andrew Ng, Stanford University                         | DeepLearning.AI | YouTube-Lectures | 2017       |\n| 20.  | Variational Methods for Computer Vision                  | Daniel Cremers, Technische Universit\u00e4t M\u00fcnchen         | VMCV    | YouTube-Lectures | 2017       |\n|      |                                                              |                                                        |                                                              |                                                              |            |\n| 21.  | Winter School on Computer Vision                         | Lots of Legends, Israel Institute for Advanced Studies | WS-CV                        | YouTube-Lectures | 2017       |\n| 22.  | Deep Learning for Visual Computing                       | Debdoot Sheet, IIT-Kgp                                 | Nptel Notebooks | YouTube-Lectures | 2018       |\n| 23.  | The Ancient Secrets of Computer Vision                   | Joseph Redmon, Ali Farhadi                             | TASCV ; TASCV-UW | YouTube-Lectures | 2018       |\n| 24.  | Modern Robotics                                          | Kevin Lynch, Northwestern Robotics                     | modern-robot | YouTube-Lectures | 2018       |\n| 25.  | Digial Image Processing                                  | Alex Bronstein, Technion                               | CS236860 | YouTube-Lectures | 2018       |\n| 26.  | Mathematics of Imaging - Variational Methods and Optimization in Imaging | Lots of Legends, Institut Henri Poincar\u00e9               | Workshop-1 | YouTube-Lectures | 2019       |\n| 27.  | Deep Learning for Video                                  | Xavier Gir\u00f3, UPC Barcelona                             | deepvideo  | YouTube-Lectures | 2019       |\n| 28.  | Statistical modeling for shapes and imaging              | Lots of Legends, Institut Henri Poincar\u00e9, Paris        | workshop-2 | YouTube-Lectures | 2019       |\n| 29.  | Imaging and machine learning                             | Lots of Legends, Institut Henri Poincar\u00e9, Paris        | workshop-3 | YouTube-Lectures | 2019       |\n| 30.  | Computer Vision                                          | Jayanta Mukhopadhyay, IIT Kgp                          | CV-nptel   | YouTube-Lectures | 2019       |\n|      |                                                              |                                                        |                                                              |                                                              |            |\n| 31.  | Deep Learning for Computer Vision                        | Justin Johnson, UMichigan                              | EECS 498-007 | Lecture-Videos  YouTube-Lectures | 2019       |\n| 32.  | Sensors and State Estimation 2                           | Cyrill Stachniss, University of Bonn                   | None                                                       | YouTube-Lectures | S2020      |\n| 33.  | Computer Vision III: Detection, Segmentation and Tracking | Laura Leal-Taix\u00e9, TU M\u00fcnchen                           | CV3DST        | YouTube-Lectures | S2020      |\n| 34.  | Advanced Deep Learning for Computer Vision               | Laura Leal-Taix\u00e9 and Matthias Nie\u00dfner, TU M\u00fcnchen      | ADL4CV         | YouTube-Lectures | S2020      |\n| 35.  | Computer Vision: Foundations                             | Fred Hamprecht, Universit\u00e4t Heidelberg                 | CVF             | YouTube-Lectures | SS2020     |\n| 36.  | MIT Vision Seminar                                       | Lots of Legends, MIT                                   | MIT-Vision | YouTube-Lectures | 2015-now   |\n| 37.  | TUM AI Guest Lectures                                    | Lots of Legends, Technische Universit\u00e4t M\u00fcnchen        | TUM-AI   | YouTube-Lectures | 2020 - now |\n| 38.  | Seminar on 3D Geometry & Vision                          | Lots of Legends, Virtual                               | 3DGV seminar                       | YouTube-Lectures | 2020 - now |\n| 39.  | Event-based Robot Vision                                 | Guillermo Gallego, Technische Universit\u00e4t Berlin       | EVIS-SS20 | YouTube-Lectures | 2020 - now |\n| 40.  | Deep Learning for Computer Vision                        | Vineeth Balasubramanian, IIT Hyderabad                 | DL-CV'20 | YouTube-Lectures | 2020       |\n|      |                                                              |                                                        |                                                              |                                                              |            |\n| 41.  | Deep Learning for Visual Computing                       | Peter Wonka, KAUST, SA                                 | NOne                                                       | YouTube-Lectures | 2020       |\n| 42.  | Computer Vision                                          | Yogesh Rawat, University of Central Florida            | CAP5415-CV | YouTube-Lectures | F2020      |\n| 43.  | Multimedia Signal Processing                             | Mark Hasegawa-Johnson, UIUC                            | ECE-417 MSP | Lecture Videos | F2020      |\n| 44.  | Computer Vision                                          | Andreas Geiger, Universit\u00e4t T\u00fcbingen                   | Comp.Vis | YouTube-Lectures | S2021      |\n| 45.  | 3D Computer Vision                                       | Lee Gim Hee, National Univeristy of Singapura          | None                                                       | YouTube-Lectures | 2021       |\n| 46.  | Deep Learning for Computer Vision: Fundamentals and Applications | T. Dekel et al., Weizmann Institute of Science         | DL4CV               | YouTube-Lectures | S2021      |\n| 47.  | Current Topics in ML Methods in 3D and Geometric Deep Learning | Animesh Garg  & others, University of Toronto          | CSC 2547          | YouTube-Lectures | 2021       |\n| 48.  | First Principles of Computer Vision                      | Shree K. Nayar, Columbia University                    | FPCV                         | YouTube-Lectures | 2021       |\n| 49.  | Self-Driving Cars                                        | Andreas Geiger, Universit\u00e4t T\u00fcbingen                   | SDC'21                 | YouTube-Lectures | W2021      |\n|      |                                                              |                                                        |                                                              |                                                              |            |\nGo to Contents :arrow_heading_up: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:star2: Boot Camps or Summer Schools :maple_leaf:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                                             | University/Instructor(s)                                 | Course WebPage                                               | Lecture Videos                                               | Year      |\n| ---- | ------------------------------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- |\n| 1.   | Deep Learning, Feature Learning                     | Lots of Legends, IPAM UCLA                               | GSS-2012 | YouTube-Lectures | 2012      |\n| 2.   | Big Data Boot Camp                                  | Lots of Legends, Simons Institute                    | Big Data | YouTube-Lectures | 2013      |\n| 3. | Machine Learning Summer School | Lots of Legends, MPI-IS T\u00fcbingen | MLSS-13 | YouTube-Lectures | 2013 |\n| 4 | Graduate Summer School: Computer Vision | Lots of Legends, IPAM-UCLA | GSS-CV | Video-Lectures | 2013 |\n| 5. | Machine Learning Summer School | Lots of Legends, Reykjavik University | MLSS-14 | YouTube-Lectures | 2014 |\n| 6. | Machine Learning Summer School | Lots of Legends, Pittsburgh | MLSS-14 | YouTube-Lectures | 2014 |\n| 7. | Deep Learning Summer School | Lots of Legends, Universit\u00e9 de Montr\u00e9al | DLSS-15 | YouTube-Lectures | 2015 |\n| 8. | Biomedical Image Analysis Summer School | Lots of Legends, CentraleSupelec, Paris | None | YouTube-Lectures | 2015 |\n| 9. | Mathematics of Signal Processing                    | Lots of Legends, Hausdorff Institute for Mathematics | SigProc | YouTube-Lectures | 2016      |\n| 10. | Microsoft Research - Machine Learning Course        | S V N Vishwanathan and Prateek Jain MS-Research          | None                                                       | YouTube-Lectures | 2016      |\n|  |  |  |  |  |  |\n| 11. | Deep Learning Summer School                         | Lots of Legends, Universit\u00e9 de Montr\u00e9al                  | DL-SS-16 | YouTube-Lectures | 2016      |\n| 12. | Lisbon Machine Learning School | Lots of Legends, Instituto Superior T\u00e9cnico, Portugal | LxMLS-16 | YouTube-Lectures | 2016 |\n| 13. | Machine Learning Advances and Applications Seminar  | Lots of Legends, Fields Institute, University of Toronto | MLAAS-16 | YouTube-Lectures  Video-Lectures | 2016-2017 |\n| 14. | Machine Learning Advances and Applications Seminar  | Lots of Legends, Fields Institute, University of Toronto | MLAAS-17 | Video Lectures | 2017-2018 |\n| 15. | Machine Learning Summer School | Lots of Legends, MPI-IS T\u00fcbingen | MLSS-17 | YouTube-Lectures | 2017 |\n| 16. | Representation Learning                             | Lots of Legends, Simons Institute                    | RepLearn | YouTube-Lectures | 2017      |\n| 17. | Foundations of Machine Learning                     | Lots of Legends, Simons Institute                  | ML-BootCamp | YouTube-Lectures | 2017      |\n| 18. | Optimization, Statistics, and Uncertainty           | Lots of Legends, Simons Institute                    | Optim-Stats | YouTube-Lectures | 2017      |\n| 19. | Deep Learning: Theory, Algorithms, and Applications | Lots of Legends, TU-Berlin                         | DL: TAA        | YouTube-Lectures | 2017      |\n| 20. | Deep Learning and Reinforcement Learning Summer School | Lots of Legends, Universit\u00e9 de Montr\u00e9al                                   | DLRL-2017   | Lecture-videos          | 2017 |\n|  |  |  |  |  |  |\n| 21. | Statistical Physics Methods in Machine Learning | Lots of Legends, International Centre for Theoretical Sciences, TIFR | SPMML | YouTube-Lectures | 2017 |\n| 22. | Lisbon Machine Learning School | Lots of Legends, Instituto Superior T\u00e9cnico, Portugal | LxMLS-17 | YouTube-Lectures | 2017 |\n| 23. | Interactive Learning | Lots of Legends, Simons Institute, Berkeley | IL-2017 | YouTube-Lectures | 2017 |\n| 24. | Computational Challenges in Machine Learning | Lots of Legends, Simons Institute, Berkeley | CCML-17 | YouTube-Lectures | 2017 |\n| 25. | Foundations of Data Science                         | Lots of Legends, Simons Institute                   | DS-BootCamp | YouTube-Lectures | 2018      |\n| 26. | Deep Learning and Bayesian Methods           | Lots of Legends, HSE Moscow                          | DLBM-SS | YouTube-Lectures | 2018      |\n| 27. | New Deep Learning Techniques                        | Lots of Legends, IPAM UCLA                           | IPAM-Workshop | YouTube-Lectures | 2018      |\n| 28. | Deep Learning and Reinforcement Learning Summer School | Lots of Legends, University of Toronto | DLRL-2018 | Lecture-videos | 2018 |\n| 29. | Machine Learning Summer School | Lots of Legends, Universidad Aut\u00f3noma de Madrid, Spain | MLSS-18 | YouTube-Lectures  Course-videos | 2018 |\n| 30. | Theoretical Basis of Machine Learning | Lots of Legends, International Centre for Theoretical Sciences, TIFR | TBML-18 | Lecture-Videos  YouTube-Videos | 2018 |\n|  |  |  |  |  |  |\n| 31. | Polish View on Machine Learning | Lots of Legends, Warsaw | PLinML-18 | YouTube-Videos | 2018 |\n| 32. | Big Data Analysis in Astronomy | Lots of Legends, Tenerife | BDAA-18 | YouTube-Lectures | 2018 |\n| 33. | Machine Learning Advances and Applications Seminar  | Lots of Legends, Fields Institute, University of Toronto | MLASS | Video Lectures | 2018-2019 |\n| 34. | MIFODS- ML, Stats, ToC seminar                      | Lots of Legends, MIT                                     | MIFODS-seminar          | Lecture-videos          | 2018-2019 |\n| 35. | Learning Machines Seminar Series | Lots of Legends, Cornell Tech | LMSS | YouTube-Lectures | 2018-now |\n| 36. | Machine Learning Summer School | Lots of Legends, South Africa | MLSS'19 | YouTube-Lectures | 2019 |\n| 37. | Deep Learning Boot Camp | Lots of Legends, Simons Institute, Berkeley | DLBC-19 | YouTube-Lectures | 2019 |\n| 38. | Frontiers of Deep Learning | Lots of Legends, Simons Institute, Berkeley | FoDL-19 | YouTube-Lectures | 2019 |\n| 39. | Mathematics of data: Structured representations for sensing, approximation and learning | Lots of Legends, The Alan Turing Institute, London | MoD-19 | YouTube-Lectures | 2019 |\n| 40. | Deep Learning and Bayesian Methods | Lots of Legends, HSE Moscow | DLBM-SS | YouTube-Lectures | 2019 |\n|  |  |  |  |  |  |\n| 41. | The Mathematics of Deep Learning and Data Science | Lots of Legends, Isaac Newton Institute, Cambridge | MoDL-DS | Lecture-Videos | 2019 |\n| 42. | Geometry of Deep Learning | Lots of Legends, MSR Redmond | GoDL | YouTube-Lectures | 2019 |\n| 43. | Deep Learning for Science School | Many folks, LBNL, Berkeley | DLfSS | YouTube-Lectures | 2019 |\n| 44. | Emerging Challenges in Deep Learning | Lots of Legends, Simons Institute, Berkeley | ECDL | YouTube-Lectures | 2019 |\n| 45. | Full Stack Deep Learning | Pieter Abbeel and many others, UC Berkeley | FSDL-M19 | YouTube-Lectures-Day-1  Day-2 | 2019 |\n| 46. | Algorithmic and Theoretical aspects of Machine Learning | Lots of legends, IIIT-Bengaluru | ACM-ML  nptel | YouTube-Lectures | 2019 |\n| 47. | Deep Learning and Reinforcement Learning Summer School | Lots of Legends, AMII, Edmonton, Canada | DLRL-2019 | YouTube-Lectures | 2019 |\n| 48. | Mathematics of Machine Learning - Summer Graduate School | Lots of Legends, University of Washington | MoML-SGS, MoML-SS | YouTube-Lectures | 2019 |\n| 49. | Workshop on Theory of Deep Learning: Where next? | Lots of Legends, IAS, Princeton University | WTDL | YouTube-Lectures | 2019 |\n| 50. | Computational Vision Summer School | Lots of Legends, Black Forest, Germany | CVSS-2019 | YouTube-Lectures | 2019 |\n| | | | | | |\n| 51. | Learning under complex structure | Lots of Legends, MIT | LUCS | YouTube-Lectures | 2020 |\n| 52. | Machine Learning Summer School | Lots of Legends, MPI-IS T\u00fcbingen (virtual) | MLSS | YouTube-Lectures | SS2020 |\n| 53. | Eastern European Machine Learning Summer School | Lots of Legends, Krak\u00f3w, Poland (virtual) | EEML | YouTube-Lectures | S2020 |\n| 54. | Lisbon Machine Learning Summer School | Lots of Legends, Lisbon, Portugal (virtual) | LxMLS | YouTube-Lectures | S2020 |\n| 55. | Workshop on New Directions in Optimization, Statistics and Machine Learning | Lots of Legends,  Institute of Advanced Study, Princeton | ML-Opt new dir. | YouTube-Lectures | 2020 |\n| 56. | Mediterranean Machine Learning School | Lots of Legends, Italy (virtual) | M2L-school | YouTube-Lectures | 2021 |\n| 57. | Mathematics of Machine Learning - One World Seminar | Lots of Legends, Virtual | 1W-ML | YouTube-Lectures | 2020 - now |\n| 58. | Deep Learning Theory Summer School | Lots of Legends, Princeton University (virtual) | DLT'21 | YouTube-Lectures | 2021 |\n| | | | | | |\nGo to Contents :arrow_heading_up:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:bird: Bird's Eye view of A(G)I :eagle:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n| S.No | Course Name                            | University/Instructor(s)                                 | Course WebPage                                               | Lecture Videos                                               | Year      |\n| ---- | -------------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- |\n| 1.   | Artificial General Intelligence    | Lots of Legends, MIT                                     | 6.S099-AGI                           | Lecture-Videos                       | 2018-2019 |\n| 2.   | AI Podcast                         | Lots of Legends, MIT                                     | AI-Pod                         | YouTube-Lectures | 2018-2019 |\n| 3.   | NYU - AI Seminars                  | Lots of Legends, NYU                                     | modern-AI | YouTube-Lectures | 2017-now  |\n| 4.   | Deep Learning: Alchemy or Science? | Lots of Legends, Institute for Advanced Study, Princeton | DLAS  Agenda | YouTube-Lectures | 2019      |\n|      |                                        |                                                          |                                                              |                                                              |           |\nGo to Contents :arrow_heading_up:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\nTo-Do :running:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:white_large_square: Optimization courses which form the foundation for ML, DL, RL\n:white_large_square: Computer Vision courses which are DL & ML heavy\n:white_large_square: Speech recognition courses which are DL heavy\n:white_large_square: Structured Courses on Geometric, Graph Neural Networks\n:white_large_square: Section on Autonomous Vehicles\n:white_large_square: Section on Computer Graphics with ML/DL focus\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\nGo to Contents :arrow_heading_up: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\nAround the Web :earth_asia:\nMontreal.AI\nUPC-DLAI-2018\nUPC-DLAI-2019\nwww.hashtagtechgeek.com\nUPC-Barcelona, IDL-2020 \nUPC-DLAI-2020 \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\nContributions :pray:\nIf you find a course that fits in any of the above categories (i.e. DL, ML, RL, CV, NLP), and the course has lecture videos (with slides being optional), then please raise an issue or send a PR by updating the course according to the above format.\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\nSupport :moneybag:\nOptional: If you're a kind Samaritan and want to support me, please do so if possible, for which I would eternally be thankful and, most importantly, your contribution imbues me with greater motivation to work, particularly in hard times :pray:\nVielen lieben Dank! :blue_heart: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n:gift_heart: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board::mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board::mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :gift_heart:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:",
	"deep-learning deep-learning-library deep-learning-tutorial deep-neural-networks python pytorch": "This is a curated list of tutorials, projects, libraries, videos, papers, books and anything related to the incredible PyTorch. Feel free to make a pull request to contribute to this list.\nTable Of Contents\nTabular Data\nTutorials\nVisualization\nExplainability\nObject Detection\nLong-Tailed / Out-of-Distribution Recognition\nActivation Functions\nEnergy-Based Learning\nMissing Data\nArchitecture Search\nOptimization\nQuantization\nQuantum Machine Learning\nNeural Network Compression\nFacial, Action and Pose Recognition\nSuper resolution\nSynthetesizing Views\nVoice\nMedical\n3D Segmentation, Classification and Regression\nVideo Recognition\nRecurrent Neural Networks (RNNs)\nConvolutional Neural Networks (CNNs)\nSegmentation\nGeometric Deep Learning: Graph & Irregular Structures\nSorting\nOrdinary Differential Equations Networks\nMulti-task Learning\nGANs, VAEs, and AEs\nUnsupervised Learning\nAdversarial Attacks\nStyle Transfer\nImage Captioning\nTransformers\nSimilarity Networks and Functions\nReasoning\nGeneral NLP\nQuestion and Answering\nSpeech Generation and Recognition\nDocument and Text Classification\nText Generation\nTranslation\nSentiment Analysis\nDeep Reinforcement Learning\nDeep Bayesian Learning and Probabilistic Programmming\nSpiking Neural Networks\nAnomaly Detection\nRegression Types\nTime Series\nSynthetic Datasets\nNeural Network General Improvements\nDNN Applications in Chemistry and Physics\nNew Thinking on General Neural Network Architecture\nLinear Algebra\nAPI Abstraction\nLow Level Utilities\nPyTorch Utilities\nPyTorch Video Tutorials\nDatasets\nCommunity\nLinks to This Repository\nTo be Classified\nContributions\nTabular Data\nPyTorch-TabNet: Attentive Interpretable Tabular Learning\ncarefree-learn: A minimal Automatic Machine Learning (AutoML) solution for tabular datasets based on PyTorch\nTutorials\nOfficial PyTorch Tutorials\nOfficial PyTorch Examples\nDive Into Deep Learning with PyTorch\nMinicourse in Deep Learning with PyTorch (Multi-language)\nPractical Deep Learning with PyTorch\nDeep Learning Models\nC++ Implementation of PyTorch Tutorial\nSimple Examples to Introduce PyTorch\nMini Tutorials in PyTorch\nDeep Learning for NLP\nDeep Learning Tutorial for Researchers\nFully Convolutional Networks implemented with PyTorch\nSimple PyTorch Tutorials Zero to ALL\nDeepNLP-models-Pytorch\nMILA PyTorch Welcome Tutorials\nEffective PyTorch, Optimizing Runtime with TorchScript and Numerical Stability Optimization\nPractical PyTorch\nPyTorch Project Template\nSemantic Search with PyTorch\nVisualization\nLoss Visualization\nGrad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\nDeep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps\nSmoothGrad: removing noise by adding noise\nDeepDream: dream-like hallucinogenic visuals\nFlashTorch: Visualization toolkit for neural networks in PyTorch\nLucent: Lucid adapted for PyTorch\nDreamCreator: Training GoogleNet models for DeepDream with custom datasets made simple\nCNN Feature Map Visualisation\nExplainability\nNeural-Backed Decision Trees\nEfficient Covariance Estimation from Temporal Data\nHierarchical interpretations for neural network predictions\nShap, a unified approach to explain the output of any machine learning model\nVIsualizing PyTorch saved .pth deep learning models with netron\nDistilling a Neural Network Into a Soft Decision Tree\nCaptum, A unified model interpretability library for PyTorch\nObject Detection\nMMDetection Object Detection Toolbox\nMask R-CNN Benchmark: Faster R-CNN and Mask R-CNN in PyTorch 1.0\nYOLOS\nYOLOF\nYOLOX\nYolov7\nYOLOv6\nYolov5\nYolov4\nYOLOv3\nYOLOv2: Real-Time Object Detection\nSSD: Single Shot MultiBox Detector\nDetectron models for Object Detection\nMulti-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks\nWhale Detector\nCatalyst.Detection\nLong-Tailed / Out-of-Distribution Recognition\nDistributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization\nInvariant Risk Minimization\nTraining Confidence-Calibrated Classifier for Detecting Out-of-Distribution Samples\nDeep Anomaly Detection with Outlier Exposure\nLarge-Scale Long-Tailed Recognition in an Open World\nPrincipled Detection of Out-of-Distribution Examples in Neural Networks\nLearning Confidence for Out-of-Distribution Detection in Neural Networks\nPyTorch Imbalanced Class Sampler\nActivation Functions\nRational Activations - Learnable Rational Activation Functions\nEnergy-Based Learning\nEBGAN, Energy-Based GANs\nMaximum Entropy Generators for Energy-based Models\nMissing Data\nBRITS: Bidirectional Recurrent Imputation for Time Series\nArchitecture Search\nEfficientNetV2\nDenseNAS\nDARTS: Differentiable Architecture Search\nEfficient Neural Architecture Search (ENAS)\nEfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\nOptimization\nAccSGD, AdaBound, AdaMod, DiffGrad, Lamb, NovoGrad, RAdam, SGDW, Yogi and more\nLookahead Optimizer: k steps forward, 1 step back\nRAdam, On the Variance of the Adaptive Learning Rate and Beyond\nOver9000, Comparison of RAdam, Lookahead, Novograd, and combinations\nAdaBound, Train As Fast as Adam As Good as SGD\nRiemannian Adaptive Optimization Methods\nL-BFGS\nOptNet: Differentiable Optimization as a Layer in Neural Networks\nLearning to learn by gradient descent by gradient descent\nSurrogate Gradient Learning in Spiking Neural Networks\nQuantization\nAdditive Power-of-Two Quantization: An Efficient Non-uniform Discretization For Neural Networks\nQuantum Machine Learning\nTor10, generic tensor-network library for quantum simulation in PyTorch\nPennyLane, cross-platform Python library for quantum machine learning with PyTorch interface\nNeural Network Compression\nBayesian Compression for Deep Learning\nNeural Network Distiller by Intel AI Lab: a Python package for neural network compression research\nLearning Sparse Neural Networks through L0 regularization\nEnergy-constrained Compression for Deep Neural Networks via Weighted Sparse Projection and Layer Input Masking\nEigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis\nPruning Convolutional Neural Networks for Resource Efficient Inference\nPruning neural networks: is it time to nip it in the bud? (showing reduced networks work better)\nFacial, Action and Pose Recognition\nFacenet: Pretrained Pytorch face detection and recognition models\nDGC-Net: Dense Geometric Correspondence Network\nHigh performance facial recognition library on PyTorch\nFaceBoxes, a CPU real-time face detector with high accuracy\nHow far are we from solving the 2D & 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)\nLearning Spatio-Temporal Features with 3D Residual Networks for Action Recognition\nPyTorch Realtime Multi-Person Pose Estimation\nSphereFace: Deep Hypersphere Embedding for Face Recognition\nGANimation: Anatomically-aware Facial Animation from a Single Image\nShufflenet V2 by Face++ with better results than paper\nTowards 3D Human Pose Estimation in the Wild: a Weakly-supervised Approach\nUnsupervised Learning of Depth and Ego-Motion from Video\nFlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\nFlowNet: Learning Optical Flow with Convolutional Networks\nOptical Flow Estimation using a Spatial Pyramid Network\nOpenFace in PyTorch\nDeep Face Recognition in PyTorch\nSuper resolution\nEnhanced Deep Residual Networks for Single Image Super-Resolution\nSuperresolution using an efficient sub-pixel convolutional neural network\nPerceptual Losses for Real-Time Style Transfer and Super-Resolution\nSynthetesizing Views\nNeRF, Neural Radian Fields, Synthesizing Novels Views of Complex Scenes\nVoice\nGoogle AI VoiceFilter: Targeted Voice Separatation by Speaker-Conditioned Spectrogram Masking\nMedical\nMedical Zoo, 3D multi-modal medical image segmentation library in PyTorch\nU-Net for FLAIR Abnormality Segmentation in Brain MRI\nGenomic Classification via ULMFiT\nDeep Neural Networks Improve Radiologists' Performance in Breast Cancer Screening\nDelira, lightweight framework for medical imaging prototyping\nV-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation\nMedical Torch, medical imaging framework for PyTorch\nTorchXRayVision - A library for chest X-ray datasets and models. Including pre-trainined models.\n3D Segmentation, Classification and Regression\nKaolin, Library for Accelerating 3D Deep Learning Research\nPointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\n3D segmentation with MONAI and Catalyst\nVideo Recognition\nDancing to Music\nDevil Is in the Edges: Learning Semantic Boundaries from Noisy Annotations\nDeep Video Analytics\nPredRNN: Recurrent Neural Networks for Predictive Learning using Spatiotemporal LSTMs\nRecurrent Neural Networks (RNNs)\nSRU: training RNNs as fast as CNNs\nOrdered Neurons: Integrating Tree Structures into Recurrent Neural Networks\nAveraged Stochastic Gradient Descent with Weight Dropped LSTM\nTraining RNNs as Fast as CNNs\nQuasi-Recurrent Neural Network (QRNN)\nReSeg: A Recurrent Neural Network-based Model for Semantic Segmentation\nA Recurrent Latent Variable Model for Sequential Data (VRNN)\nImproved Semantic Representations From Tree-Structured Long Short-Term Memory Networks\nAttention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling\nAttentive Recurrent Comparators\nCollection of Sequence to Sequence Models with PyTorch\nVanilla Sequence to Sequence models\nAttention based Sequence to Sequence models\nFaster attention mechanisms using dot products between the final encoder and decoder hidden states\nConvolutional Neural Networks (CNNs)\nLegoNet: Efficient Convolutional Neural Networks with Lego Filters\nMeshCNN, a convolutional neural network designed specifically for triangular meshes\nOctave Convolution\nPyTorch Image Models, ResNet/ResNeXT, DPN, MobileNet-V3/V2/V1, MNASNet, Single-Path NAS, FBNet\nDeep Neural Networks with Box Convolutions\nInvertible Residual Networks\nStochastic Downsampling for Cost-Adjustable Inference and Improved Regularization in Convolutional Networks \nFaster Faster R-CNN Implementation\nFaster R-CNN Another Implementation\nPaying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer\nWide ResNet model in PyTorch\n    -DiracNets: Training Very Deep Neural Networks Without Skip-Connections\nAn End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition\nEfficient Densenet\nVideo Frame Interpolation via Adaptive Separable Convolution\nLearning local feature descriptors with triplets and shallow convolutional neural networks\nDensely Connected Convolutional Networks\nVery Deep Convolutional Networks for Large-Scale Image Recognition\nSqueezeNet: AlexNet-level accuracy with 50x fewer parameters and \\<0.5MB model size\nDeep Residual Learning for Image Recognition\nTraining Wide ResNets for CIFAR-10 and CIFAR-100 in PyTorch\nDeformable Convolutional Network\nConvolutional Neural Fabrics\nDeformable Convolutional Networks in PyTorch\nDilated ResNet combination with Dilated Convolutions\nStriving for Simplicity: The All Convolutional Net\nConvolutional LSTM Network\nBig collection of pretrained classification models\nPyTorch Image Classification with Kaggle Dogs vs Cats Dataset\nCIFAR-10 on Pytorch with VGG, ResNet and DenseNet\nBase pretrained models and datasets in pytorch (MNIST, SVHN, CIFAR10, CIFAR100, STL10, AlexNet, VGG16, VGG19, ResNet, Inception, SqueezeNet)\nNVIDIA/unsupervised-video-interpolation\nSegmentation\nDetectron2 by FAIR\nPixel-wise Segmentation on VOC2012 Dataset using PyTorch\nPywick - High-level batteries-included neural network training library for Pytorch\nImproving Semantic Segmentation via Video Propagation and Label Relaxation\nSuper-BPD: Super Boundary-to-Pixel Direction for Fast Image Segmentation\nCatalyst.Segmentation\nSegmentation models with pretrained backbones\nGeometric Deep Learning: Graph & Irregular Structures\nPyTorch Geometric, Deep Learning Extension\nPyTorch Geometric Temporal: A Temporal Extension Library for PyTorch Geometric\nPyTorch Geometric Signed Directed: A Signed & Directed Extension Library for PyTorch Geometric\nChemicalX: A PyTorch Based Deep Learning Library for Drug Pair Scoring\nSelf-Attention Graph Pooling\nPosition-aware Graph Neural Networks\nSigned Graph Convolutional Neural Network\nGraph U-Nets\nCluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks\nMixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing\nSemi-Supervised Graph Classification: A Hierarchical Graph Perspective\nPyTorch BigGraph by FAIR for Generating Embeddings From Large-scale Graph Data\nCapsule Graph Neural Network\nSplitter: Learning Node Representations that Capture Multiple Social Contexts\nA Higher-Order Graph Convolutional Layer\nPredict then Propagate: Graph Neural Networks meet Personalized PageRank\nLorentz Embeddings: Learn Continuous Hierarchies in Hyperbolic Space\nGraph Wavelet Neural Network\nWatch Your Step: Learning Node Embeddings via Graph Attention\nSigned Graph Convolutional Network\nGraph Classification Using Structural Attention\nSimGNN: A Neural Network Approach to Fast Graph Similarity Computation\nSINE: Scalable Incomplete Network Embedding\nHypER: Hypernetwork Knowledge Graph Embeddings\nTuckER: Tensor Factorization for Knowledge Graph Completion\nPyKEEN: A Python library for learning and evaluating knowledge graph embeddings\nPathfinder Discovery Networks for Neural Message Passing\nSSSNET: Semi-Supervised Signed Network Clustering\nMagNet: A Neural Network for Directed Graphs\nSorting\nStochastic Optimization of Sorting Networks via Continuous Relaxations\nOrdinary Differential Equations Networks\nLatent ODEs for Irregularly-Sampled Time Series\nGRU-ODE-Bayes: continuous modelling of sporadically-observed time series\nMulti-task Learning\nHierarchical Multi-Task Learning Model\nTask-based End-to-end Model Learning\nGANs, VAEs, and AEs\nStable Diffusion\nBigGAN: Large Scale GAN Training for High Fidelity Natural Image Synthesis\nHigh Fidelity Performance Metrics for Generative Models in PyTorch\nMimicry, PyTorch Library for Reproducibility of GAN Research\nClean Readable CycleGAN\nStarGAN\nBlock Neural Autoregressive Flow\nHigh-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs\nA Style-Based Generator Architecture for Generative Adversarial Networks\nGANDissect, PyTorch Tool for Visualizing Neurons in GANs\nLearning deep representations by mutual information estimation and maximization\nVariational Laplace Autoencoders\nVeGANS, library for easily training GANs\nProgressive Growing of GANs for Improved Quality, Stability, and Variation\nConditional GAN\nWasserstein GAN\nAdversarial Generator-Encoder Network\nImage-to-Image Translation with Conditional Adversarial Networks\nUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\nOn the Effects of Batch and Weight Normalization in Generative Adversarial Networks\nImproved Training of Wasserstein GANs\nCollection of Generative Models with PyTorch\nGenerative Adversarial Nets (GAN)\nVanilla GAN\nConditional GAN\nInfoGAN\nWasserstein GAN\nMode Regularized GAN\nVariational Autoencoder (VAE)\nVanilla VAE\nConditional VAE\nDenoising VAE\nAdversarial Autoencoder\nAdversarial Variational Bayes\nImproved Training of Wasserstein GANs\nCycleGAN and Semi-Supervised GAN\nImproving Variational Auto-Encoders using Householder Flow and using convex combination linear Inverse Autoregressive Flow\nPyTorch GAN Collection\nGenerative Adversarial Networks, focusing on anime face drawing\nSimple Generative Adversarial Networks\nAdversarial Auto-encoders\ntorchgan: Framework for modelling Generative Adversarial Networks in Pytorch\nEvaluating Lossy Compression Rates of Deep Generative Models\nCatalyst.GAN\nVanilla GAN\nConditional GAN\nWasserstein GAN\nImproved Training of Wasserstein GANs\nUnsupervised Learning\nUnsupervised Embedding Learning via Invariant and Spreading Instance Feature\nAND: Anchor Neighbourhood Discovery\nAdversarial Attacks\nDeep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images\nExplaining and Harnessing Adversarial Examples\nAdverTorch - A Toolbox for Adversarial Robustness Research\nStyle Transfer\nPystiche: Framework for Neural Style Transfer\nDetecting Adversarial Examples via Neural Fingerprinting\nA Neural Algorithm of Artistic Style\nMulti-style Generative Network for Real-time Transfer\nDeOldify, Coloring Old Images\nNeural Style Transfer\nFast Neural Style Transfer\nDraw like Bob Ross\nImage Captioning\nCLIP (Contrastive Language-Image Pre-Training)\nNeuraltalk 2, Image Captioning Model, in PyTorch\nGenerate captions from an image with PyTorch\nDenseCap: Fully Convolutional Localization Networks for Dense Captioning\nTransformers\nAttention is all you need\nSpatial Transformer Networks\nSimilarity Networks and Functions\nConditional Similarity Networks\nReasoning\nInferring and Executing Programs for Visual Reasoning\nGeneral NLP\nEspresso, Module Neural Automatic Speech Recognition Toolkit\nLabel-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification\nXLNet\nConversing by Reading: Contentful Neural Conversation with On-demand Machine Reading\nCross-lingual Language Model Pretraining\nLibre Office Translate via PyTorch NMT\nBERT\nVSE++: Improved Visual-Semantic Embeddings\nA Structured Self-Attentive Sentence Embedding\nNeural Sequence labeling model\nSkip-Thought Vectors\nComplete Suite for Training Seq2Seq Models in PyTorch\nMUSE: Multilingual Unsupervised and Supervised Embeddings\nTorchMoji: PyTorch Implementation of DeepMoji to under Language used to Express Emotions\nQuestion and Answering\nVisual Question Answering in Pytorch\nReading Wikipedia to Answer Open-Domain Questions\nDeal or No Deal? End-to-End Learning for Negotiation Dialogues\nInterpretable Counting for Visual Question Answering\nOpen Source Chatbot with PyTorch\nSpeech Generation and Recognition\nPyTorch-Kaldi Speech Recognition Toolkit\nWaveGlow: A Flow-based Generative Network for Speech Synthesis\nOpenNMT\nDeep Speech 2: End-to-End Speech Recognition in English and Mandarin\nWeNet: Production First and Production Ready End-to-End Speech Recognition Toolkit\nDocument and Text Classification\nHierarchical Attention Network for Document Classification\nHierarchical Attention Networks for Document Classification\nCNN Based Text Classification\nText Generation\nPytorch Poetry Generation\nTranslation\nOpen-source (MIT) Neural Machine Translation (NMT) System\nSentiment Analysis\nRecurrent Neural Networks for Sentiment Analysis (Aspect-Based) on SemEval 2014\nSeq2Seq Intent Parsing\nFinetuning BERT for Sentiment Analysis\nDeep Reinforcement Learning\nImage Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels\nExploration by Random Network Distillation\nEGG: Emergence of lanGuage in Games, quickly implement multi-agent games with discrete channel communication\nTemporal Difference VAE\nHigh-performance Atari A3C Agent in 180 Lines PyTorch\nLearning when to communicate at scale in multiagent cooperative and competitive tasks\nActor-Attention-Critic for Multi-Agent Reinforcement Learning\nPPO in PyTorch C++\nReinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback\nAsynchronous Methods for Deep Reinforcement Learning\nContinuous Deep Q-Learning with Model-based Acceleration\nAsynchronous Methods for Deep Reinforcement Learning for Atari 2600\nTrust Region Policy Optimization\nNeural Combinatorial Optimization with Reinforcement Learning\nNoisy Networks for Exploration\nDistributed Proximal Policy Optimization\nReinforcement learning models in ViZDoom environment with PyTorch\nReinforcement learning models using Gym and Pytorch\nSLM-Lab: Modular Deep Reinforcement Learning framework in PyTorch\nCatalyst.RL\nDeep Bayesian Learning and Probabilistic Programmming\nBatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning\nSubspace Inference for Bayesian Deep Learning\nBayesian Deep Learning with Variational Inference Package\nProbabilistic Programming and Statistical Inference in PyTorch\nBayesian CNN with Variational Inferece in PyTorch\nSpiking Neural Networks\nNorse, Library for Deep Learning with Spiking Neural Networks\nAnomaly Detection\nDetection of Accounting Anomalies using Deep Autoencoder Neural Networks\nRegression Types\nQuantile Regression DQN\nTime Series\nDual Self-Attention Network for Multivariate Time Series Forecasting\nDILATE: DIstortion Loss with shApe and tImE\nVariational Recurrent Autoencoder for Timeseries Clustering\nSpatio-Temporal Neural Networks for Space-Time Series Modeling and Relations Discovery\nFlow Forecast: A deep learning for time series forecasting framework built in PyTorch\nSynthetic Datasets\nMeta-Sim: Learning to Generate Synthetic Datasets\nNeural Network General Improvements\nIn-Place Activated BatchNorm for Memory-Optimized Training of DNNs\nTrain longer, generalize better: closing the generalization gap in large batch training of neural networks\nFreezeOut: Accelerate Training by Progressively Freezing Layers\nBinary Stochastic Neurons\nCompact Bilinear Pooling\nMixed Precision Training in PyTorch\nDNN Applications in Chemistry and Physics\nWave Physics as an Analog Recurrent Neural Network\nNeural Message Passing for Quantum Chemistry\nAutomatic chemical design using a data-driven continuous representation of molecules\nDeep Learning for Physical Processes: Integrating Prior Scientific Knowledge\nDifferentiable Molecular Simulation for Learning and Control\nNew Thinking on General Neural Network Architecture\nComplement Objective Training\nDecoupled Neural Interfaces using Synthetic Gradients\nLinear Algebra\nEigenvectors from Eigenvalues\nAPI Abstraction\nTorch Layers, Shape inference for PyTorch, SOTA Layers\nHummingbird, run trained scikit-learn models on GPU with PyTorch\nLow Level Utilities\nTorchSharp, .NET API with access to underlying library powering PyTorch\nPyTorch Utilities\nFunctorch: prototype of JAX-like composable Function transformers for PyTorch\nPoutyne: Simplified Framework for Training Neural Networks\nPyTorch Metric Learning\nKornia: an Open Source Differentiable Computer Vision Library for PyTorch\nBackPACK to easily Extract Variance, Diagonal of Gauss-Newton, and KFAC\nPyHessian for Computing Hessian Eigenvalues, trace of matrix, and ESD\nHessian in PyTorch\nDifferentiable Convex Layers\nAlbumentations: Fast Image Augmentation Library\nHigher, obtain higher order gradients over losses spanning training loops\nNeural Pipeline, Training Pipeline for PyTorch\nLayer-by-layer PyTorch Model Profiler for Checking Model Time Consumption\nSparse Distributions\nDiffdist, Adds Support for Differentiable Communication allowing distributed model parallelism\nHessianFlow, Library for Hessian Based Algorithms\nTexar, PyTorch Toolkit for Text Generation\nPyTorch FLOPs counter\nPyTorch Inference on C++ in Windows\nEuclidesDB, Multi-Model Machine Learning Feature Database\nData Augmentation and Sampling for Pytorch\nPyText, deep learning based NLP modelling framework officially maintained by FAIR\nTorchstat for Statistics on PyTorch Models\nLoad Audio files directly into PyTorch Tensors\nWeight Initializations\nSpatial transformer implemented in PyTorch\nPyTorch AWS AMI, run PyTorch with GPU support in less than 5 minutes\nUse tensorboard with PyTorch\nSimple Fit Module in PyTorch, similar to Keras\ntorchbearer: A model fitting library for PyTorch\nPyTorch to Keras model converter\nGluon to PyTorch model converter with code generation\nCatalyst: High-level utils for PyTorch DL & RL research\nPyTorch Lightning: Scalable and lightweight deep learning research framework\nDetermined: Scalable deep learning platform with PyTorch support\nPyTorch-Ignite: High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently\ntorchvision: A package consisting of popular datasets, model architectures, and common image transformations for computer vision.\nPoutyne: A Keras-like framework for PyTorch and handles much of the boilerplating code needed to train neural networks.\ntorchensemble: Scikit-Learn like ensemble methods in PyTorch\nPyTorch Video Tutorials\nPyTorch Zero to All Lectures\nPyTorch For Deep Learning Full Course\nPyTorch Lightning 101 with Alfredo Canziani and William Falcon\nPractical Deep Learning with PyTorch\nDatasets\nWorldbank Data\nCommunity\nPyTorch Discussion Forum\nStackOverflow PyTorch Tags\nCatalyst.Slack\nLinks to This Repository\nGithub Repository\nWebsite\nTo be Classified\nPerturbative Neural Networks\nAccurate Neural Network Potential\nScaling the Scattering Transform: Deep Hybrid Networks\nCortexNet: a Generic Network Family for Robust Visual Temporal Representations\nOriented Response Networks\nAssociative Compression Networks\nClarinet\nContinuous Wavelet Transforms\nmixup: Beyond Empirical Risk Minimization\nNetwork In Network\nHighway Networks\nHybrid computing using a neural network with dynamic external memory\nValue Iteration Networks\nDifferentiable Neural Computer\nA Neural Representation of Sketch Drawings\nUnderstanding Deep Image Representations by Inverting Them\nNIMA: Neural Image Assessment\nNASNet-A-Mobile. Ported weights\nGraphics code generating model using Processing\nContributions\nDo feel free to contribute!\nYou can raise an issue or submit a pull request, whichever is more convenient for you. The guideline is simple: just follow the format of the previous bullet point or create a new section if it's a new category.",
	"deep-learning deep-neural-networks gpu-acceleration javascript machine-learning neural-network typescript webgl": "This repository has been archived in favor of tensorflow/tfjs.\nThis repo will remain around for some time to keep history but all future PRs should be sent to tensorflow/tfjs inside the tfjs-core folder.\nAll history and contributions have been preserved in the monorepo.",
	"ai artificial-intelligence caffe2 deep-learning deep-neural-networks machine-learning ml": "Source code now lives in the PyTorch repository.\nCaffe2\nCaffe2 is a lightweight, modular, and scalable deep learning framework. Building on the original Caffe, Caffe2 is designed with expression, speed, and modularity in mind.\nLearn more about Caffe2 on the caffe2.ai website",
	"arm convolution deep-learning deep-neural-networks embedded-devices machine-learning ml mnn vulkan winograd-algorithm": "\u4e2d\u6587\u7248\u672c\nMNN Homepage\nIntro\nMNN is a highly efficient and lightweight deep learning framework. It supports inference and training of deep learning models, and has industry leading performance for inference and training on-device. At present, MNN has been integrated in more than 30 apps of Alibaba Inc, such as Taobao, Tmall, Youku, Dingtalk, Xianyu and etc., covering more than 70 usage scenarios such as live broadcast, short video capture, search recommendation, product searching by image, interactive marketing, equity distribution, security risk control. In addition, MNN is also used on embedded devices, such as IoT.\nInside Alibaba, MNN works as the basic module of the compute container in the Walle System, the first end-to-end, general-purpose, and large-scale production system for device-cloud collaborative machine learning, which has been published in the top system conference OSDI\u201922. The key design principles of MNN and the extensive benchmark testing results (vs. TensorFlow, TensorFlow Lite, PyTorch, PyTorch Mobile, TVM) can be found in the OSDI paper. The scripts and instructions for benchmark testing are put in the path \u201c/benchmark\u201d. If MNN or the design of Walle helps your research or production use, please cite our OSDI paper as follows:\n@inproceedings {proc:osdi22:walle,\n    author = {Chengfei Lv and Chaoyue Niu and Renjie Gu and Xiaotang Jiang and Zhaode Wang and Bin Liu and Ziqi Wu and Qiulin Yao and Congyu Huang and Panos Huang and Tao Huang and Hui Shu and Jinde Song and Bin Zou and Peng Lan and Guohuan Xu and Fei Wu and Shaojie Tang and Fan Wu and Guihai Chen},\n    title = {Walle: An {End-to-End}, {General-Purpose}, and {Large-Scale} Production System for {Device-Cloud} Collaborative Machine Learning},\n    booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},\n    year = {2022},\n    isbn = {978-1-939133-28-1},\n    address = {Carlsbad, CA},\n    pages = {249--265},\n    url = {https://www.usenix.org/conference/osdi22/presentation/lv},\n    publisher = {USENIX Association},\n    month = jul,\n}\nDocumentation and Workbench\nMNN's docs are in placed in Yuque docs here and Read the docs.\nMNN Workbench could be downloaded from MNN's homepage, which provides pretrained models, visualized training tools, and one-click deployment of models to devices.\nKey Features\nLightweight\nOptimized for devices, no dependencies, can be easily deployed to mobile devices and a variety of embedded devices.\niOS platform: static library size will full option for armv7+arm64 platforms is about 12MB, size increase of linked executables is about 2M.\nAndroid platform: core so size is about 800KB (armv7a - c++_shared).\nUse MNN_BUILD_MINI can reduce package size about 25% , with limit of fix model input size\nSupport FP16 / Int8 qunatize, can reduce model size 50%-70%\nVersatility\nSupports Tensorflow, Caffe, ONNX,Torchscripts and supports common neural networks such as CNN, RNN, GAN, Transformork.\nSupports AI model with multi-inputs or multi-outputs, every kind of dimenstion format, dynamic inputs, controlflow.\nMNN supports approximate full OPs used for AI Model. The converter supports 178 Tensorflow OPs, 52 Caffe OPs, 163 Torchscripts OPs, 158 ONNX OPs.\nSupports iOS 8.0+, Android 4.3+ and embedded devices with POSIX interface.\nSupports hybrid computing on multiple devices. Currently supports CPU and GPU.\nHigh performance\nImplements core computing with lots of optimized assembly code to make full use of the ARM / x64 CPU.\nUse Metal / OpenCL / Vulkan to support GPU inference on mobile.\nUse CUDA and tensorcore to support NVIDIA GPU for better performance\nConvolution and transposition convolution algorithms are efficient and stable. The Winograd convolution algorithm is widely used to better symmetric convolutions such as 3x3,4x4,5x5,6x6,7x7.\nTwice speed increase for the new architecture ARM v8.2 with FP16 half-precision calculation support. 2.5 faster to use sdot for ARM v8.2 and VNNI.\nEase of use\nSupport use MNN's OP to do numerical calculating like numpy.\nSupport lightweight image process module like OpenCV, which is only 100k.\nSupport build model and train it on PC / mobile.\nMNN Python API helps ML engineers to easily use MNN to inference, train, process image, without dipping their toes in C++ code.\nThe Architecture / Precision MNN supported is shown below:\nS \uff1aSupport and work well, deeply optimized, recommend to use\nA \uff1aSupport and work well, can use\nB \uff1aSupport but has bug or not optimized, no recommend to use\nC \uff1aNot Support\n| Architecture / Precision |  | Normal | FP16 | BF16 | Int8 |\n| --- | --- | --- | --- | --- | --- |\n| CPU | Native | B | C | B | B |\n|  | x86/x64-SSE4.1 | A | B | B | A |\n|  | x86/x64-AVX2 | S | B | B | A |\n|  | x86/x64-AVX512 | S | B | B | S |\n|  | ARMv7a | S | S (ARMv8.2) | S | S |\n|  | ARMv8 | S | S (ARMv8.2) | S(ARMv8.6) | S |\n| GPU | OpenCL | A | S | C | C |\n|  | Vulkan | A | A | C | C |\n|  | Metal | A | S | C | C |\n|  | CUDA | A | S | C | C |\n| NPU | CoreML | B | B | C | C |\n|  | HIAI | B | C | C | B |\n|  | NNAPI | B | B | C | C |\nTools\nBase on MNN (Tensor compute engine), we provided a series of tools for inference, train and general computation.\nMNN-Converter: Convert other model to MNN model for inference, such as Tensorflow(lite), Caffe, ONNX, Torchscripts. And do graph optimization to reduce computation.\nMNN-Compress: Compress model to reduce size and increase performance / speed\nMNN-Express: Support model with controlflow, use MNN's OP to do general-purpose compute.\nMNN-CV: An OpenCV liked library, but based on MNN and then much more lightweight.\nMNN-Train: Support train MNN model.\nHow to Discuss and Get Help From MNN Community\nThe group discussions are predominantly Chinese. But we welcome and will help English speakers.\nDingtalk discussion groups:\nGroup #1 (Full): 23329087\nGroup #2 (Full): 23350225\nGroup #3: https://h5.dingtalk.com/circle/healthCheckin.html?dtaction=os&corpId=ding8989a1d6ae6ef130b177420cc0e366ea&f0c81=1b93a&cbdbhh=qwertyuiop\nHistorical Paper\nThe preliminary version of MNN, as mobile inference engine and with the focus on manual optimization, has also been published in MLSys 2020. Please cite the paper, if MNN previously helped your research:\n@inproceedings{alibaba2020mnn,\n  author = {Jiang, Xiaotang and Wang, Huan and Chen, Yiliu and Wu, Ziqi and Wang, Lichuan and Zou, Bin and Yang, Yafeng and Cui, Zongyang and Cai, Yu and Yu, Tianhang and Lv, Chengfei and Wu, Zhihua},\n  title = {MNN: A Universal and Efficient Inference Engine},\n  booktitle = {MLSys},\n  year = {2020}\n}\nLicense\nApache 2.0\nAcknowledgement\nMNN participants: Taobao Technology Department, Search Engineering Team, DAMO Team, Youku and other Alibaba Group employees.\nMNN refers to the following projects:\n- Caffe\n- flatbuffer\n- gemmlowp\n- Google Vulkan demo\n- Halide\n- Mace\n- ONNX\n- protobuffer\n- skia\n- Tensorflow\n- ncnn\n- paddle-mobile\n- stb\n- rapidjson\n- pybind11\n- pytorch\n- bolt\n- libyuv\n- libjpeg\n- opencv",
	"convolutional-networks convolutional-neural-networks darknet deep-learning deep-neural-networks graph image-processing machine-learning mobile-development object-detection real-time tensorflow": "Intro\nReal-time object detection and classification. Paper: version 1, version 2.\nRead more about YOLO (in darknet) and download weight files here. In case the weight file cannot be found, I uploaded some of mine here, which include yolo-full and yolo-tiny of v1.0, tiny-yolo-v1.1 of v1.1 and yolo, tiny-yolo-voc of v2.\nSee demo below or see on this imgur\nDependencies\nPython3, tensorflow 1.0, numpy, opencv 3.\nCitation\n@article{trieu2018darkflow,\n  title={Darkflow},\n  author={Trieu, Trinh Hoang},\n  journal={GitHub Repository. Available online: https://github. com/thtrieu/darkflow (accessed on 14 February 2019)},\n  year={2018}\n}\nGetting started\nYou can choose one of the following three ways to get started with darkflow.\nJust build the Cython extensions in place. NOTE: If installing this way you will have to use ./flow in the cloned darkflow directory instead of flow as darkflow is not installed globally.\n    python3 setup.py build_ext --inplace\nLet pip install darkflow globally in dev mode (still globally accessible, but changes to the code immediately take effect)\n    pip install -e .\nInstall with pip globally\n    pip install .\nUpdate\nAndroid demo on Tensorflow's here\nI am looking for help:\n - help wanted labels in issue track\nParsing the annotations\nSkip this if you are not training or fine-tuning anything (you simply want to forward flow a trained net)\nFor example, if you want to work with only 3 classes tvmonitor, person, pottedplant; edit labels.txt as follows\ntvmonitor\nperson\npottedplant\nAnd that's it. darkflow will take care of the rest. You can also set darkflow to load from a custom labels file with the --labels flag (i.e. --labels myOtherLabelsFile.txt). This can be helpful when working with multiple models with different sets of output labels. When this flag is not set, darkflow will load from labels.txt by default (unless you are using one of the recognized .cfg files designed for the COCO or VOC dataset - then the labels file will be ignored and the COCO or VOC labels will be loaded).\nDesign the net\nSkip this if you are working with one of the original configurations since they are already there. Otherwise, see the following example:\npython\n...\n[convolutional]\nbatch_normalize = 1\nsize = 3\nstride = 1\npad = 1\nactivation = leaky\n[maxpool]\n[connected]\noutput = 4096\nactivation = linear\n...\nFlowing the graph using flow\nbash\nHave a look at its options\nflow --h\nFirst, let's take a closer look at one of a very useful option --load\nbash\n1. Load tiny-yolo.weights\nflow --model cfg/tiny-yolo.cfg --load bin/tiny-yolo.weights\n2. To completely initialize a model, leave the --load option\nflow --model cfg/yolo-new.cfg\n3. It is useful to reuse the first identical layers of tiny for yolo-new\nflow --model cfg/yolo-new.cfg --load bin/tiny-yolo.weights\nthis will print out which layers are reused, which are initialized\nAll input images from default folder sample_img/ are flowed through the net and predictions are put in sample_img/out/. We can always specify more parameters for such forward passes, such as detection threshold, batch size, images folder, etc.\nbash\nForward all images in sample_img/ using tiny yolo and 100% GPU usage\nflow --imgdir sample_img/ --model cfg/tiny-yolo.cfg --load bin/tiny-yolo.weights --gpu 1.0\njson output can be generated with descriptions of the pixel location of each bounding box and the pixel location. Each prediction is stored in the `sample_img/out` folder by default. An example json array is shown below.bash\nForward all images in sample_img/ using tiny yolo and JSON output.\nflow --imgdir sample_img/ --model cfg/tiny-yolo.cfg --load bin/tiny-yolo.weights --json\nJSON output:json\n[{\"label\":\"person\", \"confidence\": 0.56, \"topleft\": {\"x\": 184, \"y\": 101}, \"bottomright\": {\"x\": 274, \"y\": 382}},\n{\"label\": \"dog\", \"confidence\": 0.32, \"topleft\": {\"x\": 71, \"y\": 263}, \"bottomright\": {\"x\": 193, \"y\": 353}},\n{\"label\": \"horse\", \"confidence\": 0.76, \"topleft\": {\"x\": 412, \"y\": 109}, \"bottomright\": {\"x\": 592,\"y\": 337}}]\n - label: self explanatory\n - confidence: somewhere between 0 and 1 (how confident yolo is about that detection)\n - topleft: pixel coordinate of top left corner of box.\n - bottomright: pixel coordinate of bottom right corner of box.\nTraining new model\nTraining is simple as you only have to add option --train. Training set and annotation will be parsed if this is the first time a new configuration is trained. To point to training set and annotations, use option --dataset and --annotation. A few examples:\nbash\nInitialize yolo-new from yolo-tiny, then train the net on 100% GPU:\nflow --model cfg/yolo-new.cfg --load bin/tiny-yolo.weights --train --gpu 1.0\nCompletely initialize yolo-new and train it with ADAM optimizer\nflow --model cfg/yolo-new.cfg --train --trainer adam\nDuring training, the script will occasionally save intermediate results into Tensorflow checkpoints, stored in ckpt/. To resume to any checkpoint before performing training/testing, use --load [checkpoint_num] option, if checkpoint_num < 0, darkflow will load the most recent save by parsing ckpt/checkpoint.\nbash\nResume the most recent checkpoint for training\nflow --train --model cfg/yolo-new.cfg --load -1\nTest with checkpoint at step 1500\nflow --model cfg/yolo-new.cfg --load 1500\nFine tuning yolo-tiny from the original one\nflow --train --model cfg/tiny-yolo.cfg --load bin/tiny-yolo.weights\nExample of training on Pascal VOC 2007:\nbash\nDownload the Pascal VOC dataset:\ncurl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\ntar xf VOCtest_06-Nov-2007.tar\nAn example of the Pascal VOC annotation format:\nvim VOCdevkit/VOC2007/Annotations/000001.xml\nTrain the net on the Pascal dataset:\nflow --model cfg/yolo-new.cfg --train --dataset \"~/VOCdevkit/VOC2007/JPEGImages\" --annotation \"~/VOCdevkit/VOC2007/Annotations\"\nTraining on your own dataset\nThe steps below assume we want to use tiny YOLO and our dataset has 3 classes\nCreate a copy of the configuration file tiny-yolo-voc.cfg and rename it according to your preference tiny-yolo-voc-3c.cfg (It is crucial that you leave the original tiny-yolo-voc.cfg file unchanged, see below for explanation).\nIn tiny-yolo-voc-3c.cfg, change classes in the [region] layer (the last layer) to the number of classes you are going to train for. In our case, classes are set to 3.\npython\n...\n[region]\nanchors = 1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52\nbias_match=1\nclasses=3\ncoords=4\nnum=5\nsoftmax=1\n...\nIn tiny-yolo-voc-3c.cfg, change filters in the [convolutional] layer (the second to last layer) to num * (classes + 5). In our case, num is 5 and classes are 3 so 5 * (3 + 5) = 40 therefore filters are set to 40.\npython\n...\n[convolutional]\nsize=1\nstride=1\npad=1\nfilters=40\nactivation=linear\n[region]\nanchors = 1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52\n...\nChange labels.txt to include the label(s) you want to train on (number of labels should be the same as the number of classes you set in tiny-yolo-voc-3c.cfg file). In our case, labels.txt will contain 3 labels.\nlabel1\nlabel2\nlabel3\n5. Reference the tiny-yolo-voc-3c.cfg model when you train.\nflow --model cfg/tiny-yolo-voc-3c.cfg --load bin/tiny-yolo-voc.weights --train --annotation train/Annotations --dataset train/Images\nWhy should I leave the original tiny-yolo-voc.cfg file unchanged?\nWhen darkflow sees you are loading tiny-yolo-voc.weights it will look for tiny-yolo-voc.cfg in your cfg/ folder and compare that configuration file to the new one you have set with --model cfg/tiny-yolo-voc-3c.cfg. In this case, every layer will have the same exact number of weights except for the last two, so it will load the weights into all layers up to the last two because they now contain different number of weights.\nCamera/video file demo\nFor a demo that entirely runs on the CPU:\nbash\nflow --model cfg/yolo-new.cfg --load bin/yolo-new.weights --demo videofile.avi\nFor a demo that runs 100% on the GPU:\nbash\nflow --model cfg/yolo-new.cfg --load bin/yolo-new.weights --demo videofile.avi --gpu 1.0\nTo use your webcam/camera, simply replace videofile.avi with keyword camera.\nTo save a video with predicted bounding box, add --saveVideo option.\nUsing darkflow from another python application\nPlease note that return_predict(img) must take an numpy.ndarray. Your image must be loaded beforehand and passed to return_predict(img). Passing the file path won't work.\nResult from return_predict(img) will be a list of dictionaries representing each detected object's values in the same format as the JSON output listed above.\npython\nfrom darkflow.net.build import TFNet\nimport cv2\noptions = {\"model\": \"cfg/yolo.cfg\", \"load\": \"bin/yolo.weights\", \"threshold\": 0.1}\ntfnet = TFNet(options)\nimgcv = cv2.imread(\"./sample_img/sample_dog.jpg\")\nresult = tfnet.return_predict(imgcv)\nprint(result)\nSave the built graph to a protobuf file (.pb)\nbash\nSaving the lastest checkpoint to protobuf file\nflow --model cfg/yolo-new.cfg --load -1 --savepb\nSaving graph and weights to protobuf file\nflow --model cfg/yolo.cfg --load bin/yolo.weights --savepb\n``\nWhen saving the.pbfile, a.metafile will also be generated alongside it. This.metafile is a JSON dump of everything in themetadictionary that contains information nessecary for post-processing such asanchorsandlabels. This way, everything you need to make predictions from the graph and do post processing is contained in those two files - no need to have the.cfg` or any labels file tagging along.\nThe created .pb file can be used to migrate the graph to mobile devices (JAVA / C++ / Objective-C++). The name of input tensor and output tensor are respectively 'input' and 'output'. For further usage of this protobuf file, please refer to the official documentation of Tensorflow on C++ API here. To run it on, say, iOS application, simply add the file to Bundle Resources and update the path to this file inside source code.\nAlso, darkflow supports loading from a .pb and .meta file for generating predictions (instead of loading from a .cfg and checkpoint or .weights).bash\nForward images in sample_img for predictions based on protobuf file\nflow --pbLoad built_graph/yolo.pb --metaLoad built_graph/yolo.meta --imgdir sample_img/\n`\nIf you'd like to load a.pband.metafile when usingreturn_predict()you can set the\"pbLoad\"and\"metaLoad\"options in place of the\"model\"and\"load\" options you would normally set.\nThat's all.",
	"computer-graphics computer-vision deep-learning deep-neural-networks gan generative-adversarial-network image-to-image-translation pix2pix pytorch": "pix2pixHD\nProject | Youtube | Paper \nPytorch implementation of our method for high-resolution (e.g. 2048x1024) photorealistic image-to-image translation. It can be used for turning semantic label maps into photo-realistic images or synthesizing portraits from face label maps. \nHigh-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs\nTing-Chun Wang1, Ming-Yu Liu1, Jun-Yan Zhu2, Andrew Tao1, Jan Kautz1, Bryan Catanzaro1\n1NVIDIA Corporation, 2UC Berkeley\n In CVPR 2018.\nImage-to-image translation at 2k/1k resolution\nOur label-to-streetview results\nInteractive editing results\nAdditional streetview results\nLabel-to-face and interactive editing results\nOur editing interface\nPrerequisites\nLinux or macOS\nPython 2 or 3\nNVIDIA GPU (11G memory or larger) + CUDA cuDNN\nGetting Started\nInstallation\nInstall PyTorch and dependencies from http://pytorch.org\nInstall python libraries dominate.\nbash\npip install dominate\nClone this repo:\nbash\ngit clone https://github.com/NVIDIA/pix2pixHD\ncd pix2pixHD\nTesting\nA few example Cityscapes test images are included in the datasets folder.\nPlease download the pre-trained Cityscapes model from here (google drive link), and put it under ./checkpoints/label2city_1024p/\nTest the model (bash ./scripts/test_1024p.sh):\n```bash\n!./scripts/test_1024p.sh\npython test.py --name label2city_1024p --netG local --ngf 32 --resize_or_crop none\n`\nThe test results will be saved to a html file here:./results/label2city_1024p/test_latest/index.html.\nMore example scripts can be found in the scripts directory.\nDataset\nWe use the Cityscapes dataset. To train a model on the full dataset, please download it from the official website (registration required).\nAfter downloading, please put it under the datasets folder in the same way the example images are provided.\nTraining\nTrain a model at 1024 x 512 resolution (bash ./scripts/train_512p.sh):\n```bash\n!./scripts/train_512p.sh\npython train.py --name label2city_512p\n`\n- To view training results, please checkout intermediate results in./checkpoints/label2city_512p/web/index.html.\nIf you have tensorflow installed, you can see tensorboard logs in./checkpoints/label2city_512p/logsby adding--tf_log to the training scripts.\nMulti-GPU training\nTrain a model using multiple GPUs (bash ./scripts/train_512p_multigpu.sh):\n```bash\n!./scripts/train_512p_multigpu.sh\npython train.py --name label2city_512p --batchSize 8 --gpu_ids 0,1,2,3,4,5,6,7\n```\nNote: this is not tested and we trained our model using single GPU only. Please use at your own discretion.\nTraining with Automatic Mixed Precision (AMP) for faster speed\nTo train with mixed precision support, please first install apex from: https://github.com/NVIDIA/apex\nYou can then train the model by adding --fp16. For example,\n```bash\n!./scripts/train_512p_fp16.sh\npython -m torch.distributed.launch train.py --name label2city_512p --fp16\n```\nIn our test case, it trains about 80% faster with AMP on a Volta machine.\nTraining at full resolution\nTo train the images at full resolution (2048 x 1024) requires a GPU with 24G memory (bash ./scripts/train_1024p_24G.sh), or 16G memory if using mixed precision (AMP).\nIf only GPUs with 12G memory are available, please use the 12G script (bash ./scripts/train_1024p_12G.sh), which will crop the images during training. Performance is not guaranteed using this script.\nTraining with your own dataset\nIf you want to train with your own dataset, please generate label maps which are one-channel whose pixel values correspond to the object labels (i.e. 0,1,...,N-1, where N is the number of labels). This is because we need to generate one-hot vectors from the label maps. Please also specity --label_nc N during both training and testing.\nIf your input is not a label map, please just specify --label_nc 0 which will directly use the RGB colors as input. The folders should then be named train_A, train_B instead of train_label, train_img, where the goal is to translate images from A to B.\nIf you don't have instance maps or don't want to use them, please specify --no_instance.\nThe default setting for preprocessing is scale_width, which will scale the width of all training images to opt.loadSize (1024) while keeping the aspect ratio. If you want a different setting, please change it by using the --resize_or_crop option. For example, scale_width_and_crop first resizes the image to have width opt.loadSize and then does random cropping of size (opt.fineSize, opt.fineSize). crop skips the resizing step and only performs random cropping. If you don't want any preprocessing, please specify none, which will do nothing other than making sure the image is divisible by 32.\nMore Training/Test Details\nFlags: see options/train_options.py and options/base_options.py for all the training flags; see options/test_options.py and options/base_options.py for all the test flags.\nInstance map: we take in both label maps and instance maps as input. If you don't want to use instance maps, please specify the flag --no_instance.\nCitation\nIf you find this useful for your research, please use the following.\n@inproceedings{wang2018pix2pixHD,\n  title={High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs},\n  author={Ting-Chun Wang and Ming-Yu Liu and Jun-Yan Zhu and Andrew Tao and Jan Kautz and Bryan Catanzaro},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  year={2018}\n}\nAcknowledgments\nThis code borrows heavily from pytorch-CycleGAN-and-pix2pix.",
	"c-plus-plus computer-vision deep-learning image-processing opencv": "OpenCV: Open Source Computer Vision Library\nResources\nHomepage: https://opencv.org\nCourses: https://opencv.org/courses\nDocs: https://docs.opencv.org/4.x/\nQ&A forum: https://forum.opencv.org\nprevious forum (read only): http://answers.opencv.org\nIssue tracking: https://github.com/opencv/opencv/issues\nAdditional OpenCV functionality: https://github.com/opencv/opencv_contrib \nContributing\nPlease read the contribution guidelines before starting work on a pull request.\nSummary of the guidelines:\nOne pull request per issue;\nChoose the right base branch;\nInclude tests and documentation;\nClean up \"oops\" commits before submitting;\nFollow the coding style guide.",
	"deep-learning python pytorch tensorflow tts voice-cloning": "Real-Time Voice Cloning\nThis repository is an implementation of Transfer Learning from Speaker Verification to\nMultispeaker Text-To-Speech Synthesis (SV2TTS) with a vocoder that works in real-time. This was my master's thesis.\nSV2TTS is a deep learning framework in three stages. In the first stage, one creates a digital representation of a voice from a few seconds of audio. In the second and third stages, this representation is used as reference to generate speech given arbitrary text.\nVideo demonstration (click the picture):\nPapers implemented\n| URL | Designation | Title | Implementation source |\n| --- | ----------- | ----- | --------------------- |\n|1806.04558 | SV2TTS | Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis | This repo |\n|1802.08435 | WaveRNN (vocoder) | Efficient Neural Audio Synthesis | fatchord/WaveRNN |\n|1703.10135 | Tacotron (synthesizer) | Tacotron: Towards End-to-End Speech Synthesis | fatchord/WaveRNN\n|1710.10467 | GE2E (encoder)| Generalized End-To-End Loss for Speaker Verification | This repo |\nNews\n08/09/22: Our team at Resemble.AI is releasing a voice conversion model (closed source), check out my demo here. \n10/01/22: I recommend checking out CoquiTTS. It's a good and up-to-date TTS repository targeted for the ML community. It can also do voice cloning and more, such as cross-language cloning or voice conversion.\n28/12/21: I've done a major maintenance update. Mostly, I've worked on making setup easier. Find new instructions in the section below.\n14/02/21: This repo now runs on PyTorch instead of Tensorflow, thanks to the help of @bluefish.\n13/11/19: I'm now working full time and I will rarely maintain this repo anymore. To anyone who reads this:\n- If you just want to clone your voice (and not someone else's): I recommend our free plan on Resemble.AI. You will get a better voice quality and less prosody errors.\n- If this is not your case: proceed with this repository, but you might end up being disappointed by the results. If you're planning to work on a serious project, my strong advice: find another TTS repo. Go here for more info.\n20/08/19: I'm working on resemblyzer, an independent package for the voice encoder (inference only). You can use your trained encoder models from this repo with it.\nSetup\n1. Install Requirements\nBoth Windows and Linux are supported. A GPU is recommended for training and for inference speed, but is not mandatory.\nPython 3.7 is recommended. Python 3.5 or greater should work, but you'll probably have to tweak the dependencies' versions. I recommend setting up a virtual environment using venv, but this is optional.\nInstall ffmpeg. This is necessary for reading audio files.\nInstall PyTorch. Pick the latest stable version, your operating system, your package manager (pip by default) and finally pick any of the proposed CUDA versions if you have a GPU, otherwise pick CPU. Run the given command.\nInstall the remaining requirements with pip install -r requirements.txt\n\n(Optional) Download Pretrained Models\nPretrained models are now downloaded automatically. If this doesn't work for you, you can manually download them here.\n(Optional) Test Configuration\nBefore you download any dataset, you can begin by testing your configuration with:\npython demo_cli.py\nIf all tests pass, you're good to go.\n(Optional) Download Datasets\nFor playing with the toolbox alone, I only recommend downloading LibriSpeech/train-clean-100. Extract the contents as /LibriSpeech/train-clean-100 where  is a directory of your choosing. Other datasets are supported in the toolbox, see here. You're free not to download any dataset, but then you will need your own data as audio files or you will have to record it with the toolbox.\nLaunch the Toolbox\nYou can then try the toolbox:\npython demo_toolbox.py -d \nor\npython demo_toolbox.py \ndepending on whether you downloaded any datasets. If you are running an X-server or if you have the error Aborted (core dumped), see this issue.\n",
	"deep-learning": "Deep Learning Papers Reading Roadmap\nIf you are a newcomer to the Deep Learning area, the first question you may have is \"Which paper should I start reading from?\"\nHere is a reading roadmap of Deep Learning papers!\nThe roadmap is constructed in accordance with the following four guidelines:\nFrom outline to detail\nFrom old to state-of-the-art\nfrom generic to specific areas\nfocus on state-of-the-art\nYou will find many papers that are quite new but really worth reading.\nI would continue adding papers to this roadmap.\n1 Deep Learning History and Basics\n1.0 Book\n[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. \"Deep learning.\" An MIT Press book. (2015). [html] (Deep Learning Bible, you can read this book while reading following papers.) :star::star::star::star::star:\n1.1 Survey\n[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. \"Deep learning.\" Nature 521.7553 (2015): 436-444. [pdf] (Three Giants' Survey) :star::star::star::star::star:\n1.2 Deep Belief Network(DBN)(Milestone of Deep Learning Eve)\n[2] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. \"A fast learning algorithm for deep belief nets.\" Neural computation 18.7 (2006): 1527-1554. pdf :star::star::star:\n[3] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. \"Reducing the dimensionality of data with neural networks.\" Science 313.5786 (2006): 504-507. [pdf] (Milestone, Show the promise of deep learning) :star::star::star:\n1.3 ImageNet Evolution\uff08Deep Learning broke out from here\uff09\n[4] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \"Imagenet classification with deep convolutional neural networks.\" Advances in neural information processing systems. 2012. [pdf] (AlexNet, Deep Learning Breakthrough) :star::star::star::star::star:\n[5] Simonyan, Karen, and Andrew Zisserman. \"Very deep convolutional networks for large-scale image recognition.\" arXiv preprint arXiv:1409.1556 (2014). [pdf] (VGGNet,Neural Networks become very deep!) :star::star::star:\n[6] Szegedy, Christian, et al. \"Going deeper with convolutions.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [pdf] (GoogLeNet) :star::star::star:\n[7] He, Kaiming, et al. \"Deep residual learning for image recognition.\" arXiv preprint arXiv:1512.03385 (2015). [pdf] (ResNet,Very very deep networks, CVPR best paper) :star::star::star::star::star:\n1.4 Speech Recognition Evolution\n[8] Hinton, Geoffrey, et al. \"Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups.\" IEEE Signal Processing Magazine 29.6 (2012): 82-97. [pdf] (Breakthrough in speech recognition):star::star::star::star:\n[9] Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. \"Speech recognition with deep recurrent neural networks.\" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (RNN):star::star::star:\n[10] Graves, Alex, and Navdeep Jaitly. \"Towards End-To-End Speech Recognition with Recurrent Neural Networks.\" ICML. Vol. 14. 2014. [pdf]:star::star::star:\n[11] Sak, Ha\u015fim, et al. \"Fast and accurate recurrent neural network acoustic models for speech recognition.\" arXiv preprint arXiv:1507.06947 (2015). [pdf] (Google Speech Recognition System) :star::star::star:\n[12] Amodei, Dario, et al. \"Deep speech 2: End-to-end speech recognition in english and mandarin.\" arXiv preprint arXiv:1512.02595 (2015). [pdf] (Baidu Speech Recognition System) :star::star::star::star:\n[13] W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig \"Achieving Human Parity in Conversational Speech Recognition.\" arXiv preprint arXiv:1610.05256 (2016). [pdf] (State-of-the-art in speech recognition, Microsoft) :star::star::star::star:\nAfter reading above papers, you will have a basic understanding of the Deep Learning history, the basic architectures of Deep Learning model(including CNN, RNN, LSTM) and how deep learning can be applied to image and speech recognition issues. The following papers will take you in-depth understanding of the Deep Learning method, Deep Learning in different areas of application and the frontiers. I suggest that you can choose the following papers based on your interests and research direction.\n2 Deep Learning Method\n2.1 Model\n[14] Hinton, Geoffrey E., et al. \"Improving neural networks by preventing co-adaptation of feature detectors.\" arXiv preprint arXiv:1207.0580 (2012). [pdf] (Dropout) :star::star::star:\n[15] Srivastava, Nitish, et al. \"Dropout: a simple way to prevent neural networks from overfitting.\" Journal of Machine Learning Research 15.1 (2014): 1929-1958. [pdf] :star::star::star:\n[16] Ioffe, Sergey, and Christian Szegedy. \"Batch normalization: Accelerating deep network training by reducing internal covariate shift.\" arXiv preprint arXiv:1502.03167 (2015). [pdf] (An outstanding Work in 2015) :star::star::star::star:\n[17] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \"Layer normalization.\" arXiv preprint arXiv:1607.06450 (2016). [pdf] (Update of Batch Normalization) :star::star::star::star:\n[18] Courbariaux, Matthieu, et al. \"Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or\u22121.\" [pdf] (New Model,Fast)  :star::star::star:\n[19] Jaderberg, Max, et al. \"Decoupled neural interfaces using synthetic gradients.\" arXiv preprint arXiv:1608.05343 (2016). [pdf] (Innovation of Training Method,Amazing Work) :star::star::star::star::star:\n[20] Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. \"Net2net: Accelerating learning via knowledge transfer.\" arXiv preprint arXiv:1511.05641 (2015). [pdf] (Modify previously trained network to reduce training epochs) :star::star::star:\n[21] Wei, Tao, et al. \"Network Morphism.\" arXiv preprint arXiv:1603.01670 (2016). [pdf] (Modify previously trained network to reduce training epochs) :star::star::star:\n2.2 Optimization\n[22] Sutskever, Ilya, et al. \"On the importance of initialization and momentum in deep learning.\" ICML (3) 28 (2013): 1139-1147. [pdf] (Momentum optimizer) :star::star:\n[23] Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic optimization.\" arXiv preprint arXiv:1412.6980 (2014). [pdf] (Maybe used most often currently) :star::star::star:\n[24] Andrychowicz, Marcin, et al. \"Learning to learn by gradient descent by gradient descent.\" arXiv preprint arXiv:1606.04474 (2016). [pdf] (Neural Optimizer,Amazing Work) :star::star::star::star::star:\n[25] Han, Song, Huizi Mao, and William J. Dally. \"Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding.\" CoRR, abs/1510.00149 2 (2015). [pdf] (ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup) :star::star::star::star::star:\n[26] Iandola, Forrest N., et al. \"SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size.\" arXiv preprint arXiv:1602.07360 (2016). [pdf] (Also a new direction to optimize NN,DeePhi Tech Startup) :star::star::star::star:\n[27] Glorat Xavier, Bengio Yoshua, et al. \"Understanding the difficulty of training deep forward neural networks.\" Proceedings of the thirteenth International Conference on Artificial Intelligence and Statistics, PMLR 9:249-256,2010. [pdf] :star::star::star::star:\n2.3 Unsupervised Learning / Deep Generative Model\n[28] Le, Quoc V. \"Building high-level features using large scale unsupervised learning.\" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (Milestone, Andrew Ng, Google Brain Project, Cat) :star::star::star::star:\n[29] Kingma, Diederik P., and Max Welling. \"Auto-encoding variational bayes.\" arXiv preprint arXiv:1312.6114 (2013). [pdf] (VAE) :star::star::star::star:\n[30] Goodfellow, Ian, et al. \"Generative adversarial nets.\" Advances in Neural Information Processing Systems. 2014. [pdf] (GAN,super cool idea) :star::star::star::star::star:\n[31] Radford, Alec, Luke Metz, and Soumith Chintala. \"Unsupervised representation learning with deep convolutional generative adversarial networks.\" arXiv preprint arXiv:1511.06434 (2015). [pdf] (DCGAN) :star::star::star::star:\n[32] Gregor, Karol, et al. \"DRAW: A recurrent neural network for image generation.\" arXiv preprint arXiv:1502.04623 (2015). [pdf] (VAE with attention, outstanding work) :star::star::star::star::star:\n[33] Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. \"Pixel recurrent neural networks.\" arXiv preprint arXiv:1601.06759 (2016). [pdf] (PixelRNN) :star::star::star::star:\n[34] Oord, Aaron van den, et al. \"Conditional image generation with PixelCNN decoders.\" arXiv preprint arXiv:1606.05328 (2016). [pdf] (PixelCNN) :star::star::star::star:\n[34] S. Mehri et al., \"SampleRNN: An Unconditional End-to-End Neural Audio Generation Model.\" arXiv preprint    arXiv:1612.07837 (2016). [pdf] :star::star::star::star::star:\n2.4 RNN / Sequence-to-Sequence Model\n[35] Graves, Alex. \"Generating sequences with recurrent neural networks.\" arXiv preprint arXiv:1308.0850 (2013). [pdf] (LSTM, very nice generating result, show the power of RNN) :star::star::star::star:\n[36] Cho, Kyunghyun, et al. \"Learning phrase representations using RNN encoder-decoder for statistical machine translation.\" arXiv preprint arXiv:1406.1078 (2014). [pdf] (First Seq-to-Seq Paper) :star::star::star::star:\n[37] Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \"Sequence to sequence learning with neural networks.\" Advances in neural information processing systems. 2014. [pdf] (Outstanding Work) :star::star::star::star::star:\n[38] Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. \"Neural Machine Translation by Jointly Learning to Align and Translate.\" arXiv preprint arXiv:1409.0473 (2014). [pdf] :star::star::star::star:\n[39] Vinyals, Oriol, and Quoc Le. \"A neural conversational model.\" arXiv preprint arXiv:1506.05869 (2015). [pdf] (Seq-to-Seq on Chatbot) :star::star::star:\n2.5 Neural Turing Machine\n[40] Graves, Alex, Greg Wayne, and Ivo Danihelka. \"Neural turing machines.\" arXiv preprint arXiv:1410.5401 (2014). [pdf] (Basic Prototype of Future Computer) :star::star::star::star::star:\n[41] Zaremba, Wojciech, and Ilya Sutskever. \"Reinforcement learning neural Turing machines.\" arXiv preprint arXiv:1505.00521 362 (2015). [pdf] :star::star::star:\n[42] Weston, Jason, Sumit Chopra, and Antoine Bordes. \"Memory networks.\" arXiv preprint arXiv:1410.3916 (2014). [pdf] :star::star::star:\n[43] Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. \"End-to-end memory networks.\" Advances in neural information processing systems. 2015. [pdf] :star::star::star::star:\n[44] Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. \"Pointer networks.\" Advances in Neural Information Processing Systems. 2015. [pdf] :star::star::star::star:\n[45] Graves, Alex, et al. \"Hybrid computing using a neural network with dynamic external memory.\" Nature (2016). [pdf] (Milestone,combine above papers' ideas) :star::star::star::star::star:\n2.6 Deep Reinforcement Learning\n[46] Mnih, Volodymyr, et al. \"Playing atari with deep reinforcement learning.\" arXiv preprint arXiv:1312.5602 (2013). [pdf]) (First Paper named deep reinforcement learning) :star::star::star::star:\n[47] Mnih, Volodymyr, et al. \"Human-level control through deep reinforcement learning.\" Nature 518.7540 (2015): 529-533. [pdf] (Milestone) :star::star::star::star::star:\n[48] Wang, Ziyu, Nando de Freitas, and Marc Lanctot. \"Dueling network architectures for deep reinforcement learning.\" arXiv preprint arXiv:1511.06581 (2015). [pdf] (ICLR best paper,great idea)  :star::star::star::star:\n[49] Mnih, Volodymyr, et al. \"Asynchronous methods for deep reinforcement learning.\" arXiv preprint arXiv:1602.01783 (2016). [pdf] (State-of-the-art method) :star::star::star::star::star:\n[50] Lillicrap, Timothy P., et al. \"Continuous control with deep reinforcement learning.\" arXiv preprint arXiv:1509.02971 (2015). [pdf] (DDPG) :star::star::star::star:\n[51] Gu, Shixiang, et al. \"Continuous Deep Q-Learning with Model-based Acceleration.\" arXiv preprint arXiv:1603.00748 (2016). [pdf] (NAF) :star::star::star::star:\n[52] Schulman, John, et al. \"Trust region policy optimization.\" CoRR, abs/1502.05477 (2015). [pdf] (TRPO) :star::star::star::star:\n[53] Silver, David, et al. \"Mastering the game of Go with deep neural networks and tree search.\" Nature 529.7587 (2016): 484-489. [pdf] (AlphaGo) :star::star::star::star::star:\n2.7 Deep Transfer Learning / Lifelong Learning / especially for RL\n[54] Bengio, Yoshua. \"Deep Learning of Representations for Unsupervised and Transfer Learning.\" ICML Unsupervised and Transfer Learning 27 (2012): 17-36. [pdf] (A Tutorial) :star::star::star:\n[55] Silver, Daniel L., Qiang Yang, and Lianghao Li. \"Lifelong Machine Learning Systems: Beyond Learning Algorithms.\" AAAI Spring Symposium: Lifelong Machine Learning. 2013. [pdf] (A brief discussion about lifelong learning)  :star::star::star:\n[56] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. \"Distilling the knowledge in a neural network.\" arXiv preprint arXiv:1503.02531 (2015). [pdf] (Godfather's Work) :star::star::star::star:\n[57] Rusu, Andrei A., et al. \"Policy distillation.\" arXiv preprint arXiv:1511.06295 (2015). [pdf] (RL domain) :star::star::star:\n[58] Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. \"Actor-mimic: Deep multitask and transfer reinforcement learning.\" arXiv preprint arXiv:1511.06342 (2015). [pdf] (RL domain) :star::star::star:\n[59] Rusu, Andrei A., et al. \"Progressive neural networks.\" arXiv preprint arXiv:1606.04671 (2016). [pdf] (Outstanding Work, A novel idea) :star::star::star::star::star:\n2.8 One Shot Deep Learning\n[60] Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. \"Human-level concept learning through probabilistic program induction.\" Science 350.6266 (2015): 1332-1338. [pdf] (No Deep Learning,but worth reading) :star::star::star::star::star:\n[61] Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. \"Siamese Neural Networks for One-shot Image Recognition.\"(2015) [pdf] :star::star::star:\n[62] Santoro, Adam, et al. \"One-shot Learning with Memory-Augmented Neural Networks.\" arXiv preprint arXiv:1605.06065 (2016). [pdf] (A basic step to one shot learning) :star::star::star::star:\n[63] Vinyals, Oriol, et al. \"Matching Networks for One Shot Learning.\" arXiv preprint arXiv:1606.04080 (2016). [pdf] :star::star::star:\n[64] Hariharan, Bharath, and Ross Girshick. \"Low-shot visual object recognition.\" arXiv preprint arXiv:1606.02819 (2016). [pdf] (A step to large data) :star::star::star::star:\n3 Applications\n3.1 NLP(Natural Language Processing)\n[1] Antoine Bordes, et al. \"Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing.\" AISTATS(2012) [pdf] :star::star::star::star:\n[2] Mikolov, et al. \"Distributed representations of words and phrases and their compositionality.\" ANIPS(2013): 3111-3119 [pdf] (word2vec) :star::star::star:\n[3] Sutskever, et al. \"\u201cSequence to sequence learning with neural networks.\" ANIPS(2014) [pdf] :star::star::star:\n[4] Ankit Kumar, et al. \"\u201cAsk Me Anything: Dynamic Memory Networks for Natural Language Processing.\" arXiv preprint arXiv:1506.07285(2015) [pdf] :star::star::star::star:\n[5] Yoon Kim, et al. \"Character-Aware Neural Language Models.\" NIPS(2015) arXiv preprint arXiv:1508.06615(2015) [pdf] :star::star::star::star:\n[6] Jason Weston, et al. \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.\" arXiv preprint arXiv:1502.05698(2015) [pdf] (bAbI tasks) :star::star::star:\n[7] Karl Moritz Hermann, et al. \"Teaching Machines to Read and Comprehend.\" arXiv preprint arXiv:1506.03340(2015) [pdf] (CNN/DailyMail cloze style questions) :star::star:\n[8] Alexis Conneau, et al. \"Very Deep Convolutional Networks for Natural Language Processing.\" arXiv preprint arXiv:1606.01781(2016) [pdf] (state-of-the-art in text classification) :star::star::star:\n[9] Armand Joulin, et al. \"Bag of Tricks for Efficient Text Classification.\" arXiv preprint arXiv:1607.01759(2016) [pdf] (slightly worse than state-of-the-art, but a lot faster) :star::star::star:\n3.2 Object Detection\n[1] Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. \"Deep neural networks for object detection.\" Advances in Neural Information Processing Systems. 2013. [pdf] :star::star::star:\n[2] Girshick, Ross, et al. \"Rich feature hierarchies for accurate object detection and semantic segmentation.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [pdf] (RCNN) :star::star::star::star::star:\n[3] He, Kaiming, et al. \"Spatial pyramid pooling in deep convolutional networks for visual recognition.\" European Conference on Computer Vision. Springer International Publishing, 2014. [pdf] (SPPNet) :star::star::star::star:\n[4] Girshick, Ross. \"Fast r-cnn.\" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] :star::star::star::star:\n[5] Ren, Shaoqing, et al. \"Faster R-CNN: Towards real-time object detection with region proposal networks.\" Advances in neural information processing systems. 2015. [pdf] :star::star::star::star:\n[6] Redmon, Joseph, et al. \"You only look once: Unified, real-time object detection.\" arXiv preprint arXiv:1506.02640 (2015). [pdf] (YOLO,Oustanding Work, really practical) :star::star::star::star::star:\n[7] Liu, Wei, et al. \"SSD: Single Shot MultiBox Detector.\" arXiv preprint arXiv:1512.02325 (2015). [pdf] :star::star::star:\n[8] Dai, Jifeng, et al. \"R-FCN: Object Detection via\nRegion-based Fully Convolutional Networks.\" arXiv preprint arXiv:1605.06409 (2016). [pdf] :star::star::star::star:\n[9] He, Gkioxari, et al. \"Mask R-CNN\" arXiv preprint arXiv:1703.06870 (2017). [pdf] :star::star::star::star:\n[10] Bochkovskiy, Alexey, et al. \"YOLOv4: Optimal Speed and Accuracy of Object Detection.\"  arXiv preprint arXiv:2004.10934 (2020). [pdf] :star::star::star::star:\n[11] Tan, Mingxing, et al. \u201cEfficientDet: Scalable and Efficient Object Detection.\" arXiv preprint arXiv:1911.09070 (2019). [pdf] :star::star::star::star::star:\n3.3 Visual Tracking\n[1] Wang, Naiyan, and Dit-Yan Yeung. \"Learning a deep compact image representation for visual tracking.\" Advances in neural information processing systems. 2013. [pdf] (First Paper to do visual tracking using Deep Learning,DLT Tracker) :star::star::star:\n[2] Wang, Naiyan, et al. \"Transferring rich feature hierarchies for robust visual tracking.\" arXiv preprint arXiv:1501.04587 (2015). [pdf] (SO-DLT) :star::star::star::star:\n[3] Wang, Lijun, et al. \"Visual tracking with fully convolutional networks.\" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] (FCNT) :star::star::star::star:\n[4] Held, David, Sebastian Thrun, and Silvio Savarese. \"Learning to Track at 100 FPS with Deep Regression Networks.\" arXiv preprint arXiv:1604.01802 (2016). [pdf] (GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods) :star::star::star::star:\n[5] Bertinetto, Luca, et al. \"Fully-Convolutional Siamese Networks for Object Tracking.\" arXiv preprint arXiv:1606.09549 (2016). [pdf] (SiameseFC,New state-of-the-art for real-time object tracking) :star::star::star::star:\n[6] Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. \"Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking.\" ECCV (2016) [pdf] (C-COT) :star::star::star::star:\n[7] Nam, Hyeonseob, Mooyeol Baek, and Bohyung Han. \"Modeling and Propagating CNNs in a Tree Structure for Visual Tracking.\" arXiv preprint arXiv:1608.07242 (2016). [pdf] (VOT2016 Winner,TCNN) :star::star::star::star:\n3.4 Image Caption\n[1] Farhadi,Ali,etal. \"Every picture tells a story: Generating sentences from images\". In Computer VisionECCV 2010. Springer Berlin Heidelberg:15-29, 2010. [pdf] :star::star::star:\n[2] Kulkarni, Girish, et al. \"Baby talk: Understanding and generating image descriptions\". In Proceedings of the 24th CVPR, 2011. [pdf]:star::star::star::star:\n[3] Vinyals, Oriol, et al. \"Show and tell: A neural image caption generator\". In arXiv preprint arXiv:1411.4555, 2014. [pdf]:star::star::star:\n[4] Donahue, Jeff, et al. \"Long-term recurrent convolutional networks for visual recognition and description\". In arXiv preprint arXiv:1411.4389 ,2014. [pdf]\n[5] Karpathy, Andrej, and Li Fei-Fei. \"Deep visual-semantic alignments for generating image descriptions\". In arXiv preprint arXiv:1412.2306, 2014. [pdf]:star::star::star::star::star:\n[6] Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. \"Deep fragment embeddings for bidirectional image sentence mapping\". In Advances in neural information processing systems, 2014. [pdf]:star::star::star::star:\n[7] Fang, Hao, et al. \"From captions to visual concepts and back\". In arXiv preprint arXiv:1411.4952, 2014. [pdf]:star::star::star::star::star:\n[8] Chen, Xinlei, and C. Lawrence Zitnick. \"Learning a recurrent visual representation for image caption generation\". In arXiv preprint arXiv:1411.5654, 2014. [pdf]:star::star::star::star:\n[9] Mao, Junhua, et al. \"Deep captioning with multimodal recurrent neural networks (m-rnn)\". In arXiv preprint arXiv:1412.6632, 2014. [pdf]:star::star::star:\n[10] Xu, Kelvin, et al. \"Show, attend and tell: Neural image caption generation with visual attention\". In arXiv preprint arXiv:1502.03044, 2015. [pdf]:star::star::star::star::star:\n3.5 Machine Translation\nSome milestone papers are listed in RNN / Seq-to-Seq topic.\n[1] Luong, Minh-Thang, et al. \"Addressing the rare word problem in neural machine translation.\" arXiv preprint arXiv:1410.8206 (2014). [pdf] :star::star::star::star:\n[2] Sennrich, et al. \"Neural Machine Translation of Rare Words with Subword Units\". In arXiv preprint arXiv:1508.07909, 2015. [pdf]:star::star::star:\n[3] Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. \"Effective approaches to attention-based neural machine translation.\" arXiv preprint arXiv:1508.04025 (2015). [pdf] :star::star::star::star:\n[4] Chung, et al. \"A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation\". In arXiv preprint arXiv:1603.06147, 2016. [pdf]:star::star:\n[5] Lee, et al. \"Fully Character-Level Neural Machine Translation without Explicit Segmentation\". In arXiv preprint arXiv:1610.03017, 2016. [pdf]:star::star::star::star::star:\n[6] Wu, Schuster, Chen, Le, et al. \"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\". In arXiv preprint arXiv:1609.08144v2, 2016. [pdf] (Milestone) :star::star::star::star:\n3.6 Robotics\n[1] Koutn\u00edk, Jan, et al. \"Evolving large-scale neural networks for vision-based reinforcement learning.\" Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. [pdf] :star::star::star:\n[2] Levine, Sergey, et al. \"End-to-end training of deep visuomotor policies.\" Journal of Machine Learning Research 17.39 (2016): 1-40. [pdf] :star::star::star::star::star:\n[3] Pinto, Lerrel, and Abhinav Gupta. \"Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours.\" arXiv preprint arXiv:1509.06825 (2015). [pdf] :star::star::star:\n[4] Levine, Sergey, et al. \"Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection.\" arXiv preprint arXiv:1603.02199 (2016). [pdf] :star::star::star::star:\n[5] Zhu, Yuke, et al. \"Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning.\" arXiv preprint arXiv:1609.05143 (2016). [pdf] :star::star::star::star:\n[6] Yahya, Ali, et al. \"Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search.\" arXiv preprint arXiv:1610.00673 (2016). [pdf] :star::star::star::star:\n[7] Gu, Shixiang, et al. \"Deep Reinforcement Learning for Robotic Manipulation.\" arXiv preprint arXiv:1610.00633 (2016). [pdf] :star::star::star::star:\n[8] A Rusu, M Vecerik, Thomas Roth\u00f6rl, N Heess, R Pascanu, R Hadsell.\"Sim-to-Real Robot Learning from Pixels with Progressive Nets.\" arXiv preprint arXiv:1610.04286 (2016). [pdf] :star::star::star::star:\n[9] Mirowski, Piotr, et al. \"Learning to navigate in complex environments.\" arXiv preprint arXiv:1611.03673 (2016). [pdf] :star::star::star::star:\n3.7 Art\n[1] Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). \"Inceptionism: Going Deeper into Neural Networks\". Google Research. [html] (Deep Dream)\n:star::star::star::star:\n[2] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. \"A neural algorithm of artistic style.\" arXiv preprint arXiv:1508.06576 (2015). [pdf] (Outstanding Work, most successful method currently) :star::star::star::star::star:\n[3] Zhu, Jun-Yan, et al. \"Generative Visual Manipulation on the Natural Image Manifold.\" European Conference on Computer Vision. Springer International Publishing, 2016. [pdf] (iGAN) :star::star::star::star:\n[4] Champandard, Alex J. \"Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks.\" arXiv preprint arXiv:1603.01768 (2016). [pdf] (Neural Doodle) :star::star::star::star:\n[5] Zhang, Richard, Phillip Isola, and Alexei A. Efros. \"Colorful Image Colorization.\" arXiv preprint arXiv:1603.08511 (2016). [pdf] :star::star::star::star:\n[6] Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. \"Perceptual losses for real-time style transfer and super-resolution.\" arXiv preprint arXiv:1603.08155 (2016). [pdf] :star::star::star::star:\n[7] Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. \"A learned representation for artistic style.\" arXiv preprint arXiv:1610.07629 (2016). [pdf] :star::star::star::star:\n[8] Gatys, Leon and Ecker, et al.\"Controlling Perceptual Factors in Neural Style Transfer.\" arXiv preprint arXiv:1611.07865 (2016). [pdf] (control style transfer over spatial location,colour information and across spatial scale):star::star::star::star:\n[9] Ulyanov, Dmitry and Lebedev, Vadim, et al. \"Texture Networks: Feed-forward Synthesis of Textures and Stylized Images.\" arXiv preprint arXiv:1603.03417(2016). [pdf] (texture generation and style transfer) :star::star::star::star:\n[10] Yijun Li, Ming-Yu Liu ,Xueting Li, Ming-Hsuan Yang,Jan Kautz (NVIDIA). \"A Closed-form Solution to Photorealistic Image Stylization.\" arXiv preprint arXiv:1802.06474(2018). [pdf] (Very fast and ultra realistic style transfer) :star::star::star::star:\n3.8 Object Segmentation\n[1] J. Long, E. Shelhamer, and T. Darrell, \u201cFully convolutional networks for semantic segmentation.\u201d in CVPR, 2015. [pdf] :star::star::star::star::star:\n[2] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. \"Semantic image segmentation with deep convolutional nets and fully connected crfs.\" In ICLR, 2015. [pdf] :star::star::star::star::star:\n[3] Pinheiro, P.O., Collobert, R., Dollar, P. \"Learning to segment object candidates.\" In: NIPS. 2015. [pdf] :star::star::star::star:\n[4] Dai, J., He, K., Sun, J. \"Instance-aware semantic segmentation via multi-task network cascades.\" in CVPR. 2016 [pdf] :star::star::star:\n[5] Dai, J., He, K., Sun, J. \"Instance-sensitive Fully Convolutional Networks.\" arXiv preprint arXiv:1603.08678 (2016). [pdf] :star::star::star:",
	"deep-learning javascript ocr tesseract webassembly": "Tesseract.js is a javascript library that gets words in almost any language out of images. (Demo)\nImage Recognition\nVideo Real-time Recognition\nTesseract.js wraps an emscripten port of the Tesseract OCR Engine.\nIt works in the browser using webpack or plain script tags with a CDN and on the server with Node.js.\nAfter you install it, using it is as simple as:\njavascript\nimport Tesseract from 'tesseract.js';\nTesseract.recognize(\n  'https://tesseract.projectnaptha.com/img/eng_bw.png',\n  'eng',\n  { logger: m => console.log(m) }\n).then(({ data: { text } }) => {\n  console.log(text);\n})\nOr more imperative\njavascript\nimport { createWorker } from 'tesseract.js';\nconst worker = await createWorker({\n  logger: m => console.log(m)\n});\n(async () => {\n  await worker.loadLanguage('eng');\n  await worker.initialize('eng');\n  const { data: { text } } = await worker.recognize('https://tesseract.projectnaptha.com/img/eng_bw.png');\n  console.log(text);\n  await worker.terminate();\n})();\nCheck out the docs for a full explanation of the API.\nMajor changes in v4\nVersion 4 includes many new features and bug fixes--see this issue for a full list.  Several highlights are below. \nAdded rotation preprocessing options (including auto-rotate) for significantly better accuracy\nProcessed images (rotated, grayscale, binary) can now be retrieved\nImproved support for parallel processing (schedulers)\nBreaking changes:\ncreateWorker is now async\ngetPDF function replaced by pdf recognize option\nMajor changes in v3\nSignificantly faster performance\nRuntime reduction of 84% for Browser and 96% for Node.js when recognizing the example images\nUpgrade to Tesseract v5.1.0 (using emscripten 3.1.18)\nAdded SIMD-enabled build for supported devices\nAdded support:\nNode.js version 18\nRemoved support:\nASM.js version, any other old versions of Tesseract.js-core (<3.0.0) \nNode.js versions 10 and 12\nMajor changes in v2\nUpgrade to tesseract v4.1.1 (using emscripten 1.39.10 upstream)\nSupport multiple languages at the same time, eg: eng+chi_tra for English and Traditional Chinese\nSupported image formats: png, jpg, bmp, pbm\nSupport WebAssembly (fallback to ASM.js when browser doesn't support)\nSupport Typescript\nRead a story about v2: Why I refactor tesseract.js v2?\n  Check the support/1.x branch for version 1\nInstallation\nTesseract.js works with a ",
	"artificial-intelligence deep-learning machine-learning machine-learning-algorithms software-engineer": "Top-down learning path: Machine Learning for Software Engineers\nInspired by Coding Interview University.\nTranslations: Brazilian Portuguese | \u4e2d\u6587\u7248\u672c | Fran\u00e7ais | \u81fa\u7063\u83ef\u8a9e\u7248\u672c\nHow I (Nam Vu) plan to become a machine learning engineer\nWhat is it?\nThis is my multi-month study plan for going from mobile developer (self-taught, no CS degree) to machine learning engineer.\nMy main goal was to find an approach to studying Machine Learning that is mainly hands-on and abstracts most of the Math for the beginner.\nThis approach is unconventional because it\u2019s the top-down and results-first approach designed for software engineers.\nPlease, feel free to make any contributions you feel will make it better.\nTable of Contents\nWhat is it?\nWhy use it?\nHow to use it\nFollow me\nDon't feel you aren't smart enough\nAbout Video Resources\nPrerequisite Knowledge\nThe Daily Plan\nMotivation\nMachine learning overview\nMachine learning mastery\nMachine learning is fun\nInky Machine Learning\nMachine Learning: An In-Depth Guide\nStories and experiences\nMachine Learning Algorithms\nBeginner Books\nPractical Books\nKaggle knowledge competitions\nVideo Series\nMOOC\nResources\nBecoming an Open Source Contributor\nGames\nPodcasts\nCommunities\nConferences\nInterview Questions\nMy admired companies\nWhy use it?\nI'm following this plan to prepare for my near-future job: Machine learning engineer. I've been building native mobile applications (Android/iOS/Blackberry) since 2011. I have a Software Engineering degree, not a Computer Science degree. I have an itty-bitty amount of basic knowledge about: Calculus, Linear Algebra, Discrete Mathematics, Probability & Statistics from university.\nThink about my interest in machine learning:\n- Can I learn and get a job in Machine Learning without studying CS Master and PhD?\n    - \"You can, but it is far more difficult than when I got into the field.\" Drac Smith\n- How do I get a job in Machine Learning as a software programmer who self-studies Machine Learning, but  never has a chance to use it at work?\n    - \"I'm hiring machine learning experts for my team and your MOOC will not get you the job (there is better news below). In fact, many people with a master's in machine learning will not get the job because they (and most who have taken MOOCs) do not have a deep understanding that will help me solve my problems.\" Ross C. Taylor\n- What skills are needed for machine learning jobs?\n    - \"First, you need to have a decent CS/Math background. ML is an advanced topic so most textbooks assume that you have that background. Second, machine learning is a very general topic with many sub-specialties requiring unique skills. You may want to browse the curriculum of an MS program in Machine Learning to see the course, curriculum and textbook.\" Uri\n    - \"Probability, distributed computing, and Statistics.\" Hydrangea\nI find myself in times of trouble.\nAFAIK, There are two sides to machine learning:\n- Practical Machine Learning: This is about querying databases, cleaning data, writing scripts to transform data and gluing algorithm and libraries together and writing custom code to squeeze reliable answers from data to satisfy difficult and ill-defined questions. It\u2019s the mess of reality.\n- Theoretical Machine Learning: This is about math and abstraction and idealized scenarios and limits and beauty and informing what is possible. It is a whole lot neater and cleaner and removed from the mess of reality.\nI think the best way for practice-focused methodology is something like 'practice \u2014 learning \u2014 practice', that means where students first come with some existing projects with problems and solutions (practice) to get familiar with traditional methods in the area and perhaps also with their methodology. After practicing with some elementary experiences, they can go into the books and study the underlying theory, which serves to guide their future advanced practice and will enhance their toolbox of solving practical problems. Studying theory also further improves their understanding on the elementary experiences, and will help them acquire advanced experiences more quickly.\nIt's a long plan. It's going to take me years. If you are familiar with a lot of this already it will take you a lot less time.\nHow to use it\nEverything below is an outline, and you should tackle the items in order from top to bottom.\nI'm using Github's special markdown flavor, including tasks lists to check progress.\n[x] Create a new branch so you can check items like this, just put an x in the brackets: [x]\nMore about Github-flavored markdown\nFollow me\nI'm a Vietnamese Software Engineer who is really passionate and wants to work in the USA.\nHow much did I work during this plan? Roughly 4 hours/night after a long, hard day at work.\nI'm on the journey.\nTwitter: @Nam Vu\n| |\n|:---:|\n| USA as heck |\nDon't feel you aren't smart enough\nI get discouraged from books and courses that tell me as soon as I open them that multivariate calculus, inferential statistics and linear algebra are prerequisites. I still don\u2019t know how to get started\u2026\nWhat if I\u2019m Not Good at Mathematics\n5 Techniques To Understand Machine Learning Algorithms Without the Background in Mathematics\nHow do I learn machine learning?\nAbout Video Resources\nSome videos are available only by enrolling in a Coursera or EdX class. It is free to do so, but sometimes the classes\nare no longer in session so you have to wait a couple of months, so you have no access. I'm going to be adding more videos\nfrom public sources and replacing the online course videos over time. I like using university lectures.\nPrerequisite Knowledge\nThis short section consists of prerequisites/interesting info I wanted to learn before getting started on the daily plan.\n[ ] What is the difference between Data Analytics, Data Analysis, Data Mining, Data Science, Machine Learning, and Big Data?\n[ ] Learning How to Learn\n[ ] Don\u2019t Break The Chain\n[ ] How to learn on your own\nThe Daily Plan\nEach subject does not require a whole day to be able to understand it fully, and you can do multiple of these in a day.\nEach day I take one subject from the list below, read it cover to cover, take notes, do the exercises and write an implementation in Python or R.\nMotivation\n[ ] Dream\nMachine learning overview\n[ ] A Visual Introduction to Machine Learning\n[ ] Gentle Guide to Machine Learning\n[ ] Introduction to Machine Learning for Developers\n[ ] Machine Learning basics for a newbie\n[ ] How do you explain Machine Learning and Data Mining to non Computer Science people?\n[ ] Machine Learning: Under the hood. Blog post explains the principles of machine learning in layman terms. Simple and clear\n[ ] What is machine learning, and how does it work?\n~~[] Deep Learning - A Non-Technical Introduction~~[removed]\nMachine learning mastery\n[ ] The Machine Learning Mastery Method\n[ ] Machine Learning for Programmers\n[ ] Applied Machine Learning with Machine Learning Mastery\n[ ] Python Machine Learning Mini-Course\n[ ] Machine Learning Algorithms Mini-Course\nMachine learning is fun\n[ ] Machine Learning is Fun!\n[ ] Part 2: Using Machine Learning to generate Super Mario Maker levels\n[ ] Part 3: Deep Learning and Convolutional Neural Networks\n[ ] Part 4: Modern Face Recognition with Deep Learning\n[ ] Part 5: Language Translation with Deep Learning and the Magic of Sequences\n[ ] Part 6: How to do Speech Recognition with Deep Learning\n[ ] Part 7: Abusing Generative Adversarial Networks to Make 8-bit Pixel Art\n[ ] Part 8: How to Intentionally Trick Neural Networks\nInky Machine Learning\n[ ] Part 1: What is Machine Learning ?\n[ ] Part 2: Supervised Learning and Unsupervised Learning\nMachine Learning: An In-Depth Guide\n[ ] Overview, goals, learning types, and algorithms\n[ ] Data selection, preparation, and modeling\n[ ] Model evaluation, validation, complexity, and improvement\n[ ] Model performance and error analysis\n[ ] Unsupervised learning, related fields, and machine learning in practice\nStories and experiences\n[ ] Machine Learning in a Week\n[ ] Machine Learning in a Year\n[ ] How I wrote my first Machine Learning program in 3 days\n[ ] Learning Path : Your mentor to become a machine learning expert\n[ ] You Too Can Become a Machine Learning Rock Star! No PhD\n[ ] How to become a Data Scientist in 6 months: A hacker\u2019s approach to career planning\nVideo\nSlide\n[ ] 5 Skills You Need to Become a Machine Learning Engineer\n[ ] Are you a self-taught machine learning engineer? If yes, how did you do it & how long did it take you?\n[ ] How can one become a good machine learning engineer?\n[ ] A Learning Sabbatical focused on Machine Learning\nMachine Learning Algorithms\n[ ] 10 Machine Learning Algorithms Explained to an \u2018Army Soldier\u2019\n[ ] Top 10 data mining algorithms in plain English\n[ ] 10 Machine Learning Terms Explained in Simple English\n[ ] A Tour of Machine Learning Algorithms\n[ ] The 10 Algorithms Machine Learning Engineers Need to Know\n[ ] Comparing supervised learning algorithms\n[ ] Machine Learning Algorithms: A collection of minimal and clean implementations of machine learning algorithms\n[ ] KNN Algorithm in Machine Learning\nBeginner Books\n[ ] Data Smart: Using Data Science to Transform Information into Insight 1st Edition\n[ ] Data Science for Business: What you need to know about data mining and data\u00ad analytic-thinking\n[ ] Predictive Analytics: The Power to Predict Who Will Click, Buy, Lie, or Die\nPractical Books\n[ ] Machine Learning for Hackers\nGitHub repository(R)\nGitHub repository(Python)\n[ ] Python Machine Learning\nGitHub repository\n[ ] Programming Collective Intelligence: Building Smart Web 2.0 Applications\n[ ] Machine Learning: An Algorithmic Perspective, Second Edition\nGitHub repository\nResource repository\n[ ] Introduction to Machine Learning with Python: A Guide for Data Scientists\nGitHub repository\n[ ] Data Mining: Practical Machine Learning Tools and Techniques, Third Edition\nTeaching material\nSlides for Chapters 1-5 (zip)\nSlides for Chapters 6-8 (zip)\n[ ] Machine Learning in Action\nGitHub repository\n[ ] Reactive Machine Learning Systems(MEAP)\nGitHub repository\n[ ] An Introduction to Statistical Learning\nGitHub repository(R)\nGitHub repository(Python)\nVideos\n[ ] Building Machine Learning Systems with Python\nGitHub repository\n[ ] Learning scikit-learn: Machine Learning in Python\nGitHub repository\n[ ] Probabilistic Programming & Bayesian Methods for Hackers\n[ ] Probabilistic Graphical Models: Principles and Techniques\n[ ] Machine Learning: Hands-On for Developers and Technical Professionals\nMachine Learning Hands-On for Developers and Technical Professionals review\nGitHub repository\n[ ] Learning from Data\nOnline tutorials\n[ ] Reinforcement Learning: An Introduction (2nd Edition)\nGitHub repository\n[ ] Machine Learning with TensorFlow(MEAP)\nGitHub repository\n[ ] How Machine Learning Works (MEAP)\nGitHub repository\n[ ] Succeeding with AI\nKaggle knowledge competitions\n[ ] Kaggle Competitions: How and where to begin?\n[ ] How a Beginner Used Small Projects To Get Started in Machine Learning and Compete on Kaggle\n[ ] Master Kaggle By Competing Consistently\nVideo Series\n[ ] Machine Learning for Hackers\n[ ] Fresh Machine Learning\n[ ] Machine Learning Recipes with Josh Gordon\n[ ] Everything You Need to know about Machine Learning in 30 Minutes or Less\n[ ] A Friendly Introduction to Machine Learning\n[ ] Nuts and Bolts of Applying Deep Learning - Andrew Ng\n[ ] BigML Webinar\nVideo\nResources\n[ ] mathematicalmonk's Machine Learning tutorials\n[ ] Machine learning in Python with scikit-learn\nGitHub repository\nBlog\n[ ] My playlist \u2013 Top YouTube Videos on Machine Learning, Neural Network & Deep Learning\n[ ] 16 New Must Watch Tutorials, Courses on Machine Learning\n[ ] DeepLearning.TV\n[ ] Learning To See\n[ ] Neural networks class - Universit\u00e9 de Sherbrooke\n[ ] 21 Deep Learning Videos, Tutorials & Courses on Youtube from 2016\n[ ] 30 Top Videos, Tutorials & Courses on Machine Learning & Artificial Intelligence from 2016\n[ ] Practical Deep Learning For Coders\n[ ]  Practical Deep Learning For Coders Version 2 (PyTorch)\nMOOC\n[ ] Coursera\u2019s AI For Everyone\n[ ] edX's Introduction to Artificial Intelligence (AI)\n[ ] Udacity\u2019s Intro to Machine Learning\nUdacity Intro to Machine Learning Review\n[ ] Udacity\u2019s Supervised, Unsupervised & Reinforcement\n[ ] Machine Learning Foundations: A Case Study Approach\n[ ] Machine Learning & AI Foundations: Value Estimations\n[ ] Kaggle's Hands-On Data Science Education\n[ ] Microsoft Professional Program for Artificial Intelligence\n[ ] Coursera\u2019s Machine Learning\nVideo only\nCoursera Machine Learning review\nCoursera: Machine Learning Roadmap\n[ ] Machine Learning Distilled\n[ ] BigML training\n[ ] Coursera\u2019s Neural Networks for Machine Learning\nTaught by Geoffrey Hinton, a pioneer in the field of neural networks\n[ ] Machine Learning\u200a-\u200aCS\u200a-\u200aOxford University\n[ ] Creative Applications of Deep Learning with TensorFlow\n[ ] Intro to Descriptive Statistics\n[ ] Intro to Inferential Statistics\n[ ] 6.S094: Deep Learning for Self-Driving Cars\n[ ] 6.S191: Introduction to Deep Learning\n[ ] Coursera\u2019s Deep Learning\nResources\n[ ] Absolute Beginning into Machine Learning\n[ ] Learn Machine Learning in a Single Month\n[ ] The Non-Technical Guide to Machine Learning & Artificial Intelligence\n[ ] Programming Community Curated Resources for learning Machine Learning\n[ ] Best practices rule book for Machine Learning engineering from Google\n[ ] Machine Learning for Software Engineers on Hacker News\n[ ] Machine Learning for Developers\n[ ] Machine Learning for Humans\ud83e\udd16\ud83d\udc76\n[ ] Machine Learning Advice for Developers\n[ ] Machine Learning For Complete Beginners\n[ ] Getting Started with Machine Learning: For absolute beginners and fifth graders\n[ ] How to Learn Machine Learning: The Self-Starter Way\n[ ] Machine Learning Self-study Resources\n[ ] Level-Up Your Machine Learning\n[ ] An Honest Guide to Machine Learning\n[ ] Enough Machine Learning to Make Hacker News Readable Again\nVideo\nSlide\n[ ] Dive into Machine Learning\n[ ] {Machine, Deep} Learning for software engineers\n[ ] Deep Learning For Beginners\n[ ] Foundations for deep learning\n[ ] Machine Learning Mindmap / Cheatsheet\nMachine Learning courses in Universities\n[ ] Stanford\n[ ] Machine Learning Summer Schools\n[ ] Oxford\n[ ] Cambridge\nFlipboard Topics\nMachine learning\nDeep learning\nArtificial Intelligence\nMedium Topics\nMachine learning\nDeep learning\nArtificial Intelligence\nMonthly top 10 articles\nMachine Learning\nAlgorithms\nComprehensive list of data science resources\nDigitalMind's Artificial Intelligence resources\nAwesome Machine Learning\nAwesome Graph Classification\nAwesome Community Detection\nCreativeAi's Machine Learning\nMachine Learning Online Courses\nGames\nHalite: A.I. Coding Game\nVindinium: A.I. Programming Challenge\nGeneral Video Game AI Competition\nAngry Birds AI Competition\nThe AI Games\nFighting Game AI Competition\nCodeCup\nStudent StarCraft AI Tournament\nAIIDE StarCraft AI Competition\nCIG StarCraft AI Competition\nCodinGame - AI Bot Games\nBecoming an Open Source Contributor\n[ ] tensorflow/magenta: Magenta: Music and Art Generation with Machine Intelligence\n[ ] tensorflow/tensorflow: Computation using data flow graphs for scalable machine learning\n[ ] cmusatyalab/openface: Face recognition with deep neural networks.\n[ ] tensorflow/models/syntaxnet: Neural Models of Syntax.\nPodcasts\nPodcasts for Beginners:\nTalking Machines\nLinear Digressions\nData Skeptic\nThis Week in Machine Learning & AI\nMachine Learning Guide\nInterviews with ML Practitioners, Researchers and Kagglers about their Joureny\nChai Time Data Science, Audio, Writeups\nMachine Learning for Beginners - Interviews, Audio\n\"More\" advanced podcasts\nPartially Derivative\nO\u2019Reilly Data Show\nNot So Standard Deviation\nPodcasts to think outside the box:\nData Stories\nCommunities\nQuora\nMachine Learning\nStatistics\nData Mining\nReddit\nMachine Learning\nComputer Vision\nNatural Language\nData Science\nBig Data\nStatistics\nData Tau\nDeep Learning News\nKDnuggets\nConferences\nNeural Information Processing Systems (NIPS)\nInternational Conference on Learning Representations (ICLR)\nAssociation for the Advancement of Artificial Intelligence (AAAI)\nIEEE Conference on Computational Intelligence and Games (CIG)\nIEEE International Conference on Machine Learning and Applications (ICMLA)\nInternational Conference on Machine Learning (ICML)\nInternational Joint Conferences on Artificial Intelligence (IJCAI)\nAssociation for Computational Linguistics (ACL)\nInterview Questions\n[ ] How To Prepare For A Machine Learning Interview\n[ ] 40 Interview Questions asked at Startups in Machine Learning / Data Science\n[ ] 21 Must-Know Data Science Interview Questions and Answers\n[ ] Top 50 Machine learning Interview questions & Answers\n[ ] Machine Learning Engineer interview questions\n[ ] Popular Machine Learning Interview Questions\n[ ] What are some common Machine Learning interview questions?\n[ ] What are the best interview questions to evaluate a machine learning researcher?\n[ ] Collection of Machine Learning Interview Questions\n[ ] 121 Essential Machine Learning Questions & Answers\n[ ] Minimum Viable Study Plan for Machine Learning Interviews\nMy admired companies\n[ ] ELSA - Your virtual pronunciation coach",
	"caffe computer-vision cpp cvpr-2017 deep-learning face foot-estimation hand-estimation human-behavior-understanding human-pose human-pose-estimation keypoint-detection keypoints machine-learning multi-person opencv openpose pose pose-estimation real-time": "| Build Type   |Linux           |MacOS           |Windows         |\n| :---:            | :---:            | :---:            | :---:            |\n| Build Status |  |  |  |\nOpenPose has represented the first real-time multi-person system to jointly detect human body, hand, facial, and foot keypoints (in total 135 keypoints) on single images.\nIt is authored by Gin\u00e9s Hidalgo, Zhe Cao, Tomas Simon, Shih-En Wei, Yaadhav Raaj, Hanbyul Joo, and Yaser Sheikh. It is maintained by Gin\u00e9s Hidalgo and Yaadhav Raaj. OpenPose would not be possible without the CMU Panoptic Studio dataset. We would also like to thank all the people who has helped OpenPose in any way.\nAuthors Gin\u00e9s Hidalgo (left) and Hanbyul Joo (right) in front of the CMU Panoptic Studio\nContents\nResults\nFeatures\nRelated Work\nInstallation\nQuick Start Overview\nSend Us Feedback!\nCitation\nLicense\nResults\nWhole-body (Body, Foot, Face, and Hands) 2D Pose Estimation\nTesting OpenPose: (Left) Crazy Uptown Funk flashmob in Sydney video sequence. (Center and right) Authors Gin\u00e9s Hidalgo and Tomas Simon testing face and hands\nWhole-body 3D Pose Reconstruction and Estimation\nTianyi Zhao testing the OpenPose 3D Module\nUnity Plugin\nTianyi Zhao and Gin\u00e9s Hidalgo testing the OpenPose Unity Plugin\nRuntime Analysis\nWe show an inference time comparison between the 3 available pose estimation libraries (same hardware and conditions): OpenPose, Alpha-Pose (fast Pytorch version), and Mask R-CNN. The OpenPose runtime is constant, while the runtime of Alpha-Pose and Mask R-CNN grow linearly with the number of people. More details here.\nFeatures\nMain Functionality:\n- 2D real-time multi-person keypoint detection:\n    - 15, 18 or 25-keypoint body/foot keypoint estimation, including 6 foot keypoints. Runtime invariant to number of detected people.\n    - 2x21-keypoint hand keypoint estimation. Runtime depends on number of detected people. See OpenPose Training for a runtime invariant alternative.\n    - 70-keypoint face keypoint estimation. Runtime depends on number of detected people. See OpenPose Training for a runtime invariant alternative.\n- 3D real-time single-person keypoint detection:\n    - 3D triangulation from multiple single views.\n    - Synchronization of Flir cameras handled.\n    - Compatible with Flir/Point Grey cameras.\n- Calibration toolbox: Estimation of distortion, intrinsic, and extrinsic camera parameters.\n- Single-person tracking for further speedup or visual smoothing.\nInput: Image, video, webcam, Flir/Point Grey, IP camera, and support to add your own custom input source (e.g., depth camera).\nOutput: Basic image + keypoint display/saving (PNG, JPG, AVI, ...), keypoint saving (JSON, XML, YML, ...), keypoints as array class, and support to add your own custom output code (e.g., some fancy UI).\nOS: Ubuntu (20, 18, 16, 14), Windows (10, 8), Mac OSX, Nvidia TX2.\nHardware compatibility: CUDA (Nvidia GPU), OpenCL (AMD GPU), and non-GPU (CPU-only) versions.\nUsage Alternatives:\n- Command-line demo for built-in functionality.\n- C++ API and Python API for custom functionality. E.g., adding your custom inputs, pre-processing, post-posprocessing, and output steps.\nFor further details, check the major released features and release notes docs.\nRelated Work\nOpenPose training code\nOpenPose foot dataset\nOpenPose Unity Plugin\nOpenPose papers published in IEEE TPAMI and CVPR. Cite them in your publications if OpenPose helps your research! (Links and more details in the Citation section below).\nInstallation\nIf you want to use OpenPose without installing or writing any code, simply download and use the latest Windows portable version of OpenPose!\nOtherwise, you could build OpenPose from source. See the installation doc for all the alternatives.\nQuick Start Overview\nSimply use the OpenPose Demo from your favorite command-line tool (e.g., Windows PowerShell or Ubuntu Terminal). E.g., this example runs OpenPose on your webcam and displays the body keypoints:\n```\nUbuntu\n./build/examples/openpose/openpose.bin\n:: Windows - Portable Demo\nbin\\OpenPoseDemo.exe --video examples\\media\\video.avi\nYou can also add any of the available flags in any order. E.g., the following example runs on a video (--video {PATH}), enables face (--face) and hands (--hand), and saves the output keypoints on JSON files on disk (--write_json {PATH}).\nUbuntu\n./build/examples/openpose/openpose.bin --video examples/media/video.avi --face --hand --write_json output_json_folder/\n:: Windows - Portable Demo\nbin\\OpenPoseDemo.exe --video examples\\media\\video.avi --face --hand --write_json output_json_folder/\n```\nOptionally, you can also extend OpenPose's functionality from its Python and C++ APIs. After installing OpenPose, check its official doc for a quick overview of all the alternatives and tutorials.\nSend Us Feedback!\nOur library is open source for research purposes, and we want to improve it! So let us know (create a new GitHub issue or pull request, email us, etc.) if you...\n1. Find/fix any bug (in functionality or speed) or know how to speed up or improve any part of OpenPose.\n2. Want to add/show some cool functionality/demo/project made on top of OpenPose. We can add your project link to our Community-based Projects section or even integrate it with OpenPose!\nCitation\nPlease cite these papers in your publications if OpenPose helps your research. All of OpenPose is based on OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields, while the hand and face detectors also use Hand Keypoint Detection in Single Images using Multiview Bootstrapping (the face detector was trained using the same procedure than the hand detector).\n@article{8765346,\n  author = {Z. {Cao} and G. {Hidalgo Martinez} and T. {Simon} and S. {Wei} and Y. A. {Sheikh}},\n  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n  title = {OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},\n  year = {2019}\n}\n@inproceedings{simon2017hand,\n  author = {Tomas Simon and Hanbyul Joo and Iain Matthews and Yaser Sheikh},\n  booktitle = {CVPR},\n  title = {Hand Keypoint Detection in Single Images using Multiview Bootstrapping},\n  year = {2017}\n}\n@inproceedings{cao2017realtime,\n  author = {Zhe Cao and Tomas Simon and Shih-En Wei and Yaser Sheikh},\n  booktitle = {CVPR},\n  title = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},\n  year = {2017}\n}\n@inproceedings{wei2016cpm,\n  author = {Shih-En Wei and Varun Ramakrishna and Takeo Kanade and Yaser Sheikh},\n  booktitle = {CVPR},\n  title = {Convolutional pose machines},\n  year = {2016}\n}\nPaper links:\n- OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields:\n    - IEEE TPAMI\n    - ArXiv\n- Hand Keypoint Detection in Single Images using Multiview Bootstrapping\n- Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields\n- Convolutional Pose Machines\nLicense\nOpenPose is freely available for free non-commercial use, and may be redistributed under these conditions. Please, see the license for further details. Interested in a commercial license? Check this FlintBox link. For commercial queries, use the Contact section from the FlintBox link and also send a copy of that message to Yaser Sheikh.",
	"deep-learning neural-networks pytorch pytorch-tutorial": "This repository provides tutorial code for deep learning researchers to learn PyTorch. In the tutorial, most of the models were implemented with less than 30 lines of code. Before starting this tutorial, it is recommended to finish Official Pytorch Tutorial.\nTable of Contents\n1. Basics\nPyTorch Basics\nLinear Regression\nLogistic Regression\nFeedforward Neural Network\n\nIntermediate\n\nConvolutional Neural Network\nDeep Residual Network\nRecurrent Neural Network\nBidirectional Recurrent Neural Network\nLanguage Model (RNN-LM)\n\nAdvanced\n\nGenerative Adversarial Networks\nVariational Auto-Encoder\nNeural Style Transfer\nImage Captioning (CNN-RNN)\n\nUtilities\n\nTensorBoard in PyTorch\nGetting Started\nbash\n$ git clone https://github.com/yunjey/pytorch-tutorial.git\n$ cd pytorch-tutorial/tutorials/PATH_TO_PROJECT\n$ python main.py\nDependencies\nPython 2.7 or 3.5+\nPyTorch 0.4.0+",
	"ai deep-learning pytorch speech": "English | \u4e2d\u6587\nFeatures\n\ud83c\udf0d Chinese supported mandarin and tested with multiple datasets: aidatatang_200zh, magicdata, aishell3, data_aishell, and etc.\n\ud83e\udd29 PyTorch worked for pytorch, tested in version of 1.9.0(latest in August 2021), with GPU Tesla T4 and GTX 2060\n\ud83c\udf0d Windows + Linux run in both Windows OS and linux OS (even in M1 MACOS)\n\ud83e\udd29 Easy & Awesome effect with only newly-trained synthesizer, by reusing the pretrained encoder/vocoder\n\ud83c\udf0d Webserver Ready to serve your result with remote calling\nDEMO VIDEO\nOngoing Works(Helps Needed)\nMajor upgrade on GUI/Client and unifying web and toolbox\n[X] Init framework ./mkgui and tech design\n[X] Add demo part of Voice Cloning and Conversion\n[X] Add preprocessing and training for Voice Conversion\n[ ] Add preprocessing and training for Encoder/Synthesizer/Vocoder\nMajor upgrade on model backend based on ESPnet2(not yet started)\nQuick Start\n1. Install Requirements\nFollow the original repo to test if you got all environment ready.\nPython 3.7 or higher  is needed to run the toolbox.\nInstall PyTorch.\nIf you get an ERROR: Could not find a version that satisfies the requirement torch==1.9.0+cu102 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2 ) This error is probably due to a low version of python, try using 3.9 and it will install successfully\nInstall ffmpeg.\nRun pip install -r requirements.txt to install the remaining necessary packages.\nInstall webrtcvad pip install webrtcvad-wheels(If you need)\nNote that we are using the pretrained encoder/vocoder but synthesizer since the original model is incompatible with the Chinese symbols. It means the demo_cli is not working at this moment.\n\nPrepare your models\nYou can either train your models or use existing ones:\n2.1 Train encoder with your dataset (Optional)\n\nPreprocess with the audios and the mel spectrograms:\npython encoder_preprocess.py  Allowing parameter --dataset {dataset} to support the datasets you want to preprocess. Only the train set of these datasets will be used. Possible names: librispeech_other, voxceleb1, voxceleb2. Use comma to sperate multiple datasets.\nTrain the encoder: python encoder_train.py my_run /SV2TTS/encoder\nFor training, the encoder uses visdom. You can disable it with --no_visdom, but it's nice to have. Run \"visdom\" in a separate CLI/process to start your visdom server.\n2.2 Train synthesizer with your dataset\nDownload dataset and unzip: make sure you can access all .wav in folder\nPreprocess with the audios and the mel spectrograms:\npython pre.py \nAllowing parameter --dataset {dataset} to support aidatatang_200zh, magicdata, aishell3, data_aishell, etc.If this parameter is not passed, the default dataset will be aidatatang_200zh.\nTrain the synthesizer:\npython synthesizer_train.py mandarin /SV2TTS/synthesizer\nGo to next step when you see attention line show and loss meet your need in training folder synthesizer/saved_models/.\n2.3 Use pretrained model of synthesizer\nThanks to the community, some models will be shared:\n| author | Download link | Preview Video | Info |\n| --- | ----------- | ----- |----- |\n| @author | https://pan.baidu.com/s/1iONvRxmkI-t1nHqxKytY3g  Baidu 4j5d  |  | 75k steps trained by multiple datasets\n| @author | https://pan.baidu.com/s/1fMh9IlgKJlL2PIiRTYDUvw  Baidu code\uff1aom7f  |  | 25k steps trained by multiple datasets, only works under version 0.0.1\n|@FawenYo | https://drive.google.com/file/d/1H-YGOUHpmqKxJ9FRc6vAjPuqQki24UbC/view?usp=sharing https://u.teknik.io/AYxWf.pt  | input output | 200k steps with local accent of Taiwan, only works under version 0.0.1\n|@miven| https://pan.baidu.com/s/1PI-hM3sn5wbeChRryX-RCQ code: 2021 https://www.aliyundrive.com/s/AwPsbo8mcSP code: z2m0 | https://www.bilibili.com/video/BV1uh411B7AD/ | only works under version 0.0.1\n2.4 Train vocoder (Optional)\nnote: vocoder has little difference in effect, so you may not need to train a new one.\n* Preprocess the data:\npython vocoder_preprocess.py  -m \n replace with your dataset root\uff0creplace with directory of your best trained models of sythensizer, e.g. sythensizer\\saved_mode\\xxx\nTrain the wavernn vocoder:\npython vocoder_train.py mandarin \nTrain the hifigan vocoder\npython vocoder_train.py mandarin  hifigan\n\nLaunch\n3.1 Using the web server\nYou can then try to run:python web.py and open it in browser, default as http://localhost:8080\n3.2 Using the Toolbox\nYou can then try the toolbox:\npython demo_toolbox.py -d \n3.3 Using the command line\nYou can then try the command:\npython gen_voice.py  your_wav_file.wav\nyou may need to install cn2an by \"pip install cn2an\" for better digital number result.\nReference\n\nThis repository is forked from Real-Time-Voice-Cloning which only support English.\n| URL | Designation | Title | Implementation source |\n| --- | ----------- | ----- | --------------------- |\n| 1803.09017 | GlobalStyleToken (synthesizer)| Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis | This repo |\n| 2010.05646 | HiFi-GAN (vocoder)| Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis | This repo |\n| 2106.02297 | Fre-GAN (vocoder)| Fre-GAN: Adversarial Frequency-consistent Audio Synthesis | This repo |\n|1806.04558 | SV2TTS | Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis | This repo |\n|1802.08435 | WaveRNN (vocoder) | Efficient Neural Audio Synthesis | fatchord/WaveRNN |\n|1703.10135 | Tacotron (synthesizer) | Tacotron: Towards End-to-End Speech Synthesis | fatchord/WaveRNN\n|1710.10467 | GE2E (encoder)| Generalized End-To-End Loss for Speaker Verification | This repo |\nF Q&A\n1.Where can I download the dataset?\n| Dataset | Original Source | Alternative Sources |\n| --- | ----------- | ---------------|\n| aidatatang_200zh | OpenSLR | Google Drive |\n| magicdata | OpenSLR | Google Drive (Dev set) |\n| aishell3 | OpenSLR | Google Drive |\n| data_aishell | OpenSLR |  |\nAfter unzip aidatatang_200zh, you need to unzip all the files under aidatatang_200zh\\corpus\\train\n2.What is?\nIf the dataset path is D:\\data\\aidatatang_200zh,then  isD:\\data\n3.Not enough VRAM\nTrain the synthesizer\uff1aadjust the batch_size in synthesizer/hparams.py\n//Before\ntts_schedule = [(2,  1e-3,  20_000,  12),   # Progressive training schedule\n                (2,  5e-4,  40_000,  12),   # (r, lr, step, batch_size)\n                (2,  2e-4,  80_000,  12),   #\n                (2,  1e-4, 160_000,  12),   # r = reduction factor (# of mel frames\n                (2,  3e-5, 320_000,  12),   #     synthesized for each decoder iteration)\n                (2,  1e-5, 640_000,  12)],  # lr = learning rate\n//After\ntts_schedule = [(2,  1e-3,  20_000,  8),   # Progressive training schedule\n                (2,  5e-4,  40_000,  8),   # (r, lr, step, batch_size)\n                (2,  2e-4,  80_000,  8),   #\n                (2,  1e-4, 160_000,  8),   # r = reduction factor (# of mel frames\n                (2,  3e-5, 320_000,  8),   #     synthesized for each decoder iteration)\n                (2,  1e-5, 640_000,  8)],  # lr = learning rate\nTrain Vocoder-Preprocess the data\uff1aadjust the batch_size in synthesizer/hparams.py\n```\n//Before\nData Preprocessing\n    max_mel_frames = 900,\n    rescale = True,\n    rescaling_max = 0.9,\n    synthesis_batch_size = 16,                  # For vocoder preprocessing and inference.\n//After\nData Preprocessing\n    max_mel_frames = 900,\n    rescale = True,\n    rescaling_max = 0.9,\n    synthesis_batch_size = 8,                  # For vocoder preprocessing and inference.\nTrain Vocoder-Train the vocoder\uff1aadjust the batch_size in vocoder/wavernn/hparams.py\n//Before\nTraining\nvoc_batch_size = 100\nvoc_lr = 1e-4\nvoc_gen_at_checkpoint = 5\nvoc_pad = 2\n//After\nTraining\nvoc_batch_size = 6\nvoc_lr = 1e-4\nvoc_gen_at_checkpoint = 5\nvoc_pad =2\n```\n4.If it happens RuntimeError: Error(s) in loading state_dict for Tacotron: size mismatch for encoder.embedding.weight: copying a param with shape torch.Size([70, 512]) from checkpoint, the shape in current model is torch.Size([75, 512]).\nPlease refer to issue #37\n5. How to improve CPU and GPU occupancy rate?\nAdjust the batch_size as appropriate to improve\n6. What if it happens the page file is too small to complete the operation\nPlease refer to this video and change the virtual memory to 100G (102400), for example : When the file is placed in the D disk, the virtual memory of the D disk is changed.\n7. When should I stop during training?\nFYI, my attention came after 18k steps and loss became lower than 0.4 after 50k steps.",
	"deep-learning deprecated distributed jupyter-notebook machine-learning ml neural-network python scikit-learn tensorflow": "Machine Learning Notebooks\n\u26a0 THE THIRD EDITION OF MY BOOK IS NOW AVAILABLE.\nThis project is for the first edition, which is now outdated.\nThis project aims at teaching you the fundamentals of Machine Learning in\npython. It contains the example code and solutions to the exercises in my O'Reilly book Hands-on Machine Learning with Scikit-Learn and TensorFlow:\n\nQuick Start\nWant to play with these notebooks online without having to install anything?\nUse any of the following services.\nWARNING: Please be aware that these services provide temporary environments: anything you do will be deleted after a while, so make sure you download any data you care about.\n\n\nRecommended: open this repository in Colaboratory:\n\n\nOr open it in Binder:\n\n\nNote: Most of the time, Binder starts up quickly and works great, but when handson-ml is updated, Binder creates a new environment from scratch, and this can take quite some time.\n\n\nOr open it in Deepnote:\n\n\nJust want to quickly look at some notebooks, without executing any code?\nBrowse this repository using jupyter.org's notebook viewer:\nNote: github.com's notebook viewer also works but it is slower and the math equations are not always displayed correctly.\nWant to run this project using a Docker image?\nRead the Docker instructions.\nWant to install this project on your own machine?\nStart by installing Anaconda (or Miniconda), git, and if you have a TensorFlow-compatible GPU, install the GPU driver, as well as the appropriate version of CUDA and cuDNN (see TensorFlow's documentation for more details).\nNext, clone this project by opening a terminal and typing the following commands (do not type the first $ signs on each line, they just indicate that these are terminal commands):\n$ git clone https://github.com/ageron/handson-ml.git\n$ cd handson-ml\n\nNext, run the following commands:\n$ conda env create -f environment.yml\n$ conda activate tf1\n$ python -m ipykernel install --user --name=python3\n\nFinally, start Jupyter:\n$ jupyter notebook\n\nIf you need further instructions, read the detailed installation instructions.\nFAQ\nWhich Python version should I use?\nI recommend Python 3.7. If you follow the installation instructions above, that's the version you will get. Most code will work with other versions of Python 3, but some libraries do not support Python 3.8 or 3.9 yet, which is why I recommend Python 3.7.\nI'm getting an error when I call load_housing_data()\nMake sure you call fetch_housing_data() before you call load_housing_data(). If you're getting an HTTP error, make sure you're running the exact same code as in the notebook (copy/paste it if needed). If the problem persists, please check your network configuration.\nI'm getting an SSL error on MacOSX\nYou probably need to install the SSL certificates (see this StackOverflow question). If you downloaded Python from the official website, then run /Applications/Python\\ 3.7/Install\\ Certificates.command in a terminal (change 3.7 to whatever version you installed). If you installed Python using MacPorts, run sudo port install curl-ca-bundle in a terminal.\nI've installed this project locally. How do I update it to the latest version?\nSee INSTALL.md\nHow do I update my Python libraries to the latest versions, when using Anaconda?\nSee INSTALL.md\nContributors\nI would like to thank everyone who contributed to this project, either by providing useful feedback, filing issues or submitting Pull Requests. Special thanks go to Haesun Park and Ian Beauregard who reviewed every notebook and submitted many PRs, including help on some of the exercise solutions. Thanks as well to Steven Bunkley and Ziembla who created the docker directory, and to github user SuperYorio who helped on some exercise solutions.",
	"ai caffe caffe2 coreml darknet deep-learning deeplearning keras machine-learning machinelearning ml mxnet neural-network onnx paddle pytorch tensorflow tensorflow-lite torch visualizer": "Netron is a viewer for neural network, deep learning and machine learning models. \nNetron supports ONNX, TensorFlow Lite, Caffe, Keras, Darknet, PaddlePaddle, ncnn, MNN, Core ML, RKNN, MXNet, MindSpore Lite, TNN, Barracuda, Tengine, CNTK, TensorFlow.js, Caffe2 and UFF.\nNetron has experimental support for PyTorch, TensorFlow, TorchScript, OpenVINO, Torch, Vitis AI, kmodel, Arm NN, BigDL, Chainer, Deeplearning4j, MediaPipe, MegEngine, ML.NET and scikit-learn.\nInstall\nmacOS: Download the .dmg file or run brew install --cask netron\nLinux: Download the .AppImage file or run snap install netron\nWindows: Download the .exe installer or run winget install -s winget netron\nBrowser: Start the browser version.\nPython Server: Run pip install netron and netron [FILE] or netron.start('[FILE]').\nModels\nSample model files to download or open using the browser version:\nONNX: squeezenet [open]\nTensorFlow Lite: yamnet [open]\nTensorFlow: chessbot [open]\nKeras: mobilenet [open]\nTorchScript: traced_online_pred_layer [open]\nCore ML: exermote [open]\nDarknet: yolo [open]",
	"google-kubernetes-engine jupyter kubeflow kubernetes machine-learning minikube ml notebook tensorflow": "Kubeflow the cloud-native platform for machine learning operations - pipelines, training and deployment.\nDocumentation\nPlease refer to the official docs at kubeflow.org.\nWorking Groups\nThe Kubeflow community is organized into working groups (WGs) with associated repositories, that focus on specific pieces of the ML platform. \nAutoML\nDeployment\nManifests\nNotebooks\nPipelines\nServing\nTraining\nQuick Links\nProw jobs dashboard\nPR Dashboard\nArgo UI for E2E tests\nGet Involved\nPlease refer to the Community page.",
	"ai google ml rl tensorflow": "Dopamine\nGetting Started |\nDocs |\nBaseline Results |\nChangelist\nDopamine is a research framework for fast prototyping of reinforcement learning\nalgorithms. It aims to fill the need for a small, easily grokked codebase in\nwhich users can freely experiment with wild ideas (speculative research).\nOur design principles are:\nEasy experimentation: Make it easy for new users to run benchmark\n                          experiments.\nFlexible development: Make it easy for new users to try out research ideas.\nCompact and reliable: Provide implementations for a few, battle-tested\n                          algorithms.\nReproducible: Facilitate reproducibility in results. In particular, our\n                  setup follows the recommendations given by\n                  Machado et al. (2018).\nDopamine supports the following agents, implemented with jax:\nDQN (Mnih et al., 2015)\nC51 (Bellemare et al., 2017)\nRainbow (Hessel et al., 2018)\nIQN (Dabney et al., 2018)\nSAC (Haarnoja et al., 2018)\nFor more information on the available agents, see the docs.\nMany of these agents also have a tensorflow (legacy) implementation, though\nnewly added agents are likely to be jax-only.\nThis is not an official Google product.\nGetting Started\nWe provide docker containers for using Dopamine.\nInstructions can be found here.\nAlternatively, Dopamine can be installed from source (preferred) or installed\nwith pip. For either of these methods, continue reading at prerequisites.\nPrerequisites\nDopamine supports Atari environments and Mujoco environments. Install the\nenvironments you intend to use before you install Dopamine:\nAtari\nInstall the atari roms following the instructions from\natari-py.\npip install ale-py (we recommend using a virtual environment):\nunzip $ROM_DIR/ROMS.zip -d $ROM_DIR && ale-import-roms $ROM_DIR/ROMS\n(replace $ROM_DIR with the directory you extracted the ROMs to).\nMujoco\nInstall Mujoco and get a license\nhere.\nRun pip install mujoco-py (we recommend using a\nvirtual environment).\nInstalling from Source\nThe most common way to use Dopamine is to install it from source and modify\nthe source code directly:\ngit clone https://github.com/google/dopamine\nAfter cloning, install dependencies:\npip install -r dopamine/requirements.txt\nDopamine supports tensorflow (legacy) and jax (actively maintained) agents.\nView the Tensorflow documentation for\nmore information on installing tensorflow.\nNote: We recommend using a virtual environment when working with Dopamine.\nInstalling with Pip\nNote: We strongly recommend installing from source for most users.\nInstalling with pip is simple, but Dopamine is designed to be modified\ndirectly. We recommend installing from source for writing your own experiments.\npip install dopamine-rl\nRunning tests\nYou can test whether the installation was successful by running the following\nfrom the dopamine root directory.\nexport PYTHONPATH=$PYTHONPATH:$PWD\npython -m tests.dopamine.atari_init_test\nNext Steps\nView the docs for more information on training agents.\nWe supply baselines for each Dopamine agent.\nWe also provide a set of Colaboratory notebooks\nwhich demonstrate how to use Dopamine.\nReferences\nBellemare et al., The Arcade Learning Environment: An evaluation platform for\ngeneral agents. Journal of Artificial Intelligence Research, 2013.\nMachado et al., Revisiting the Arcade Learning Environment: Evaluation\nProtocols and Open Problems for General Agents, Journal of Artificial\nIntelligence Research, 2018.\nHessel et al., Rainbow: Combining Improvements in Deep Reinforcement Learning.\nProceedings of the AAAI Conference on Artificial Intelligence, 2018.\nMnih et al., Human-level Control through Deep Reinforcement Learning. Nature,\n2015.\nSchaul et al., Prioritized Experience Replay. Proceedings of the International\nConference on Learning Representations, 2016.\nHaarnoja et al., Soft Actor-Critic Algorithms and Applications,\narXiv preprint arXiv:1812.05905, 2018.\nGiving credit\nIf you use Dopamine in your work, we ask that you cite our\nwhite paper. Here is an example BibTeX entry:\n@article{castro18dopamine,\n  author    = {Pablo Samuel Castro and\n               Subhodeep Moitra and\n               Carles Gelada and\n               Saurabh Kumar and\n               Marc G. Bellemare},\n  title     = {Dopamine: {A} {R}esearch {F}ramework for {D}eep {R}einforcement {L}earning},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1812.06110},\n  archivePrefix = {arXiv}\n}",
	"ai data-science devops engineering federated-learning machine-learning ml mlops software-engineering": "Awesome MLOps  \nAn awesome list of references for MLOps - Machine Learning Operations :point_right: ml-ops.org\nTable of Content\n|                          |                          |\n| -------------------------------- | -------------------------------- |\n| MLOps Core | MLOps Communities |\n| MLOps Books | MLOps Articles |\n| MLOps Workflow Management| MLOps: Feature Stores | \n|MLOps: Data Engineering (DataOps) | MLOps: Model Deployment and Serving |\n| MLOps: Testing, Monitoring and Maintenance| MLOps: Infrastructure| \n|MLOps Papers | Talks About MLOps | \n| Existing ML Systems | Machine Learning|\n| Software Engineering | Product Management for ML/AI | \n| The Economics of ML/AI | Model Governance, Ethics, Responsible AI | \n| MLOps: People & Processes|Newsletters About MLOps, Machine Learning, Data Science and Co.| \nMLOps Core\nClick to expand!\n\nMachine Learning Operations: You Design It, You Train It, You Run It!\nMLOps SIG Specification\nML in Production\nAwesome production machine learning: State of MLOps Tools and Frameworks\nUdemy \u201cDeployment of ML Models\u201d\nFull Stack Deep Learning\nEngineering best practices for Machine Learning\n:rocket: Putting ML in Production\nStanford MLSys Seminar Series\nIBM ML Operationalization Starter Kit\nProductize ML. A self-study guide for Developers and Product Managers building Machine Learning products.\nMLOps (Machine Learning Operations) Fundamentals on GCP\nML full Stack preparation\nMLOps Guide: Theory and Implementation\nPractitioners guide to MLOps: A framework for continuous delivery and automation of machine learning.\n\nMLOps Communities\nClick to expand!\n\nMLOps.community\nCDF Special Interest Group - MLOps\nRsqrdAI - Robust and Responsible AI\nDataTalks.Club\nSynthetic Data Community\nMLOps World Community\n\nMLOps Courses\nMLOps Zoomcamp (free)\nCoursera's Machine Learning Engineering for Production (MLOps) Specialization\nMLOps Books\nClick to expand!\n\n\u201cMachine Learning Engineering\u201d by Andriy Burkov, 2020\n\"ML Ops: Operationalizing Data Science\" by David Sweenor, Steven Hillion, Dan Rope, Dev Kannabiran, Thomas Hill, Michael O'Connell\n\"Building Machine Learning Powered Applications\" by Emmanuel Ameisen\n\"Building Machine Learning Pipelines\" by Hannes Hapke, Catherine Nelson, 2020, O\u2019Reilly \n\"Managing Data Science\" by Kirill Dubovikov\n\"Accelerated DevOps with AI, ML & RPA: Non-Programmer's Guide to AIOPS & MLOPS\" by Stephen Fleming\n\"Evaluating Machine Learning Models\" by Alice Zheng\nAgile AI. 2020. By Carlo Appugliese, Paco Nathan, William S. Roberts. O'Reilly Media, Inc.\n\"Machine Learning Logistics\". 2017. By T. Dunning et al. O'Reilly Media Inc.\n\"Machine Learning Design Patterns\" by Valliappa Lakshmanan, Sara Robinson, Michael Munn. O'Reilly 2020\n\"Serving Machine Learning Models: A Guide to Architecture, Stream Processing Engines, and Frameworks\" by Boris Lublinsky, O'Reilly Media, Inc. 2017\n\"Kubeflow for Machine Learning\" by Holden Karau, Trevor Grant, Ilan Filonenko, Richard Liu, Boris Lublinsky\n\"Clean Machine Learning Code\" by Moussa Taifi. Leanpub. 2020\nE-Book \"Practical MLOps. How to Get Ready for Production Models\"\n\"Introducing MLOps\" by Mark Treveil, et al. O'Reilly Media, Inc. 2020\n\"Machine Learning for Data Streams with Practical Examples in MOA\", Bifet, Albert and Gavald`a, Ricard and Holmes, Geoff and Pfahringer, Bernhard, MIT Press, 2018\n\"Machine Learning Product Manual\" by Laszlo Sragner, Chris Kelly\n\"Data Science Bootstrap Notes\" by Eric J. Ma\n\"Data Teams\" by Jesse Anderson, 2020\n\"Data Science on AWS\" by Chris Fregly, Antje Barth, 2021\n\u201cEngineering MLOps\u201d by Emmanuel Raj, 2021\nMachine Learning Engineering in Action\nPractical MLOps\n\"Effective Data Science Infrastructure\" by Ville Tuulos, 2021\nAI and Machine Learning for On-Device Development, 2021, By Laurence Moroney. O'Reilly\nDesigning Machine Learning Systems ,2022 by Chip Huyen , O'Reilly \nReliable Machine Learning. 2022. By Cathy Chen, Niall Richard Murphy, Kranti Parisa, D. Sculley, Todd Underwood. O'Reilly\n\nMLOps Articles\nClick to expand!\n\nContinuous Delivery for Machine Learning (by Thoughtworks)\nWhat is MLOps? NVIDIA Blog\nMLSpec: A project to standardize the intercomponent schemas for a multi-stage ML Pipeline.\nThe 2021 State of Enterprise Machine Learning | State of Enterprise ML 2020: PDF and Interactive\nOrganizing machine learning projects: project management guidelines.\nRules for ML Project (Best practices)\nML Pipeline Template\nData Science Project Structure\nReproducible ML\nML project template facilitating both research and production phases.\nMachine learning requires a fundamentally different deployment approach. As organizations embrace machine learning, the need for new deployment tools and strategies grows.\nIntroducting Flyte: A Cloud Native Machine Learning and Data Processing Platform\nWhy is DevOps for Machine Learning so Different?\nLessons learned turning machine learning models into real products and services \u2013 O\u2019Reilly\nMLOps: Model management, deployment and monitoring with Azure Machine Learning\nGuide to File Formats for Machine Learning: Columnar, Training, Inferencing, and the Feature Store\nArchitecting a Machine Learning Pipeline How to build scalable Machine Learning systems\nWhy Machine Learning Models Degrade In Production\nConcept Drift and Model Decay in Machine Learning\nMachine Learning in Production: Why You Should Care About Data and Concept Drift\nBringing ML to Production\nA Tour of End-to-End Machine Learning Platforms\nMLOps: Continuous delivery and automation pipelines in machine learning\nAI meets operations\nWhat would machine learning look like if you mixed in DevOps? Wonder no more, we lift the lid on MLOps\nForbes: The Emergence Of ML Ops\nCognilytica Report \"ML Model Management and Operations 2020 (MLOps)\" \nIntroducing Cloud AI Platform Pipelines\nA Guide to Production Level Deep Learning \nThe 5 Components Towards Building Production-Ready Machine Learning Systems\nDeep Learning in Production (references about deploying deep learning-based models in production)\nMachine Learning Experiment Tracking\nThe Team Data Science Process (TDSP)\nMLOps Solutions (Azure based)\nMonitoring ML pipelines\nDeployment & Explainability of Machine Learning COVID-19 Solutions at Scale with Seldon Core and Alibi\nDemystifying AI Infrastructure\nOrganizing machine learning projects: project management guidelines.\nThe Checklist for Machine Learning Projects (from Aur\u00e9lien G\u00e9ron,\"Hands-On Machine Learning with Scikit-Learn and TensorFlow\")\nData Project Checklist by Jeremy Howard\nMLOps: not as Boring as it Sounds\n10 Steps to Making Machine Learning Operational. Cloudera White Paper\nMLOps is Not Enough. The Need for an End-to-End Data Science Lifecycle Process.\nData Science Lifecycle Repository Template\nTemplate: code and pipeline definition for a machine learning project demonstrating how to automate an end to end ML/AI workflow. \nNitpicking Machine Learning Technical Debt\nThe Best Tools, Libraries, Frameworks and Methodologies that Machine Learning Teams Actually Use \u2013 Things We Learned from 41 ML Startups\nSoftware Engineering for AI/ML - An Annotated Bibliography\nIntelligent System. Machine Learning in Practice\nCMU 17-445/645: Software Engineering for AI-Enabled Systems (SE4AI)\nMachine Learning is Requirements Engineering\nMachine Learning Reproducibility Checklist\nMachine Learning Ops. A collection of resources on how to facilitate Machine Learning Ops with GitHub.\nTask Cheatsheet for Almost Every Machine Learning Project A checklist of tasks for building End-to-End ML projects\nWeb services vs. streaming for real-time machine learning endpoints\nHow PyTorch Lightning became the first ML framework to run continuous integration on TPUs\nThe ultimate guide to building maintainable Machine Learning pipelines using DVC\nContinuous Machine Learning (CML) is CI/CD for Machine Learning Projects (DVC)\nWhat I learned from looking at 200 machine learning tools | Update: MLOps Tooling Landscape v2 (+84 new tools) - Dec '20\nBig Data & AI Landscape\nDeploying Machine Learning Models as Data, not Code \u2014 A better match?\n\u201cThou shalt always scale\u201d \u2014 10 commandments of MLOps\nThree Risks in Building Machine Learning Systems\nBlog about ML in production (by maiot.io)\nBack to the Machine Learning fundamentals: How to write code for Model deployment. Part 1, Part 2, Part 3\nMLOps: Machine Learning as an Engineering Discipline\nML Engineering on Google Cloud Platform (hands-on labs and code samples)\nDeep Reinforcement Learning in Production. The use of Reinforcement Learning to Personalize User Experience at Zynga\nWhat is Data Observability?\nA Practical Guide to Maintaining Machine Learning in Production\nContinuous Machine Learning. Part 1, Part 2. Part 3 is coming soon.\nThe Agile approach in data science explained by an ML expert\nHere is what you need to look for in a model server to build ML-powered services\nThe problem with AI developer tools for enterprises (and what IKEA has to do with it)\nStreaming Machine Learning with Tiered Storage\nBest practices for performance and cost optimization for machine learning (Google Cloud)\nLean Data and Machine Learning Operations\nA Brief Guide to Running ML Systems in Production Best Practices for Site Reliability Engineers\nAI engineering practices in the wild - SIG | Getting software right for a healthier digital world\nSE-ML | The 2020 State of Engineering Practices for Machine Learning\nAwesome Software Engineering for Machine Learning (GitHub repository)\nSampling isn\u2019t enough, profile your ML data instead\nReproducibility in ML: why it matters and how to achieve it\n12 Factors of reproducible Machine Learning in production\nMLOps: More Than Automation\nLean Data Science\nEngineering Skills for Data Scientists\nDAGsHub Blog. Read about data science and machine learning workflows, MLOps, and open source data science\nData Science Project Flow for Startups\nData Science Engineering at Shopify\nBuilding state-of-the-art machine learning technology with efficient execution for the crypto economy\nCompleting the Machine Learning Loop\nDeploying Machine Learning Models: A Checklist \nGlobal MLOps and ML tools landscape (by MLReef)\nWhy all Data Science teams need to get serious about MLOps \nMLOps Values (by Bart Grasza)\nMachine Learning Systems Design (by Chip Huyen)\nDesigning an ML system (Stanford | CS 329 | Chip Huyen)\nHow COVID-19 Has Infected AI Models (about the data drift or model drift concept)\nMicrokernel Architecture for Machine Learning Library. An Example of Microkernel Architecture with Python Metaclass\nMachine Learning in production: the Booking.com approach\nWhat I Learned From Attending TWIMLcon 2021 (by James Le)\nDesigning ML Orchestration Systems for Startups. A case study in building a lightweight production-grade ML orchestration system\nTowards MLOps: Technical capabilities of a Machine Learning platform | Prosus AI Tech Blog\nGet started with MLOps A comprehensive MLOps tutorial with open source tools\nFrom DevOps to MLOPS: Integrate Machine Learning Models using Jenkins and Docker\nExample code for a basic ML Platform based on Pulumi, FastAPI, DVC, MLFlow and more\nSoftware Engineering for Machine Learning: Characterizing and Detecting Mismatch in Machine-Learning Systems\nTWIML Solutions Guide\nHow Well Do You Leverage Machine Learning at Scale? Six Questions to Ask\nGetting started with MLOps: Selecting the right capabilities for your use case\nThe Latest Work from the SEI: Artificial Intelligence, DevSecOps, and Security Incident Response\nMLOps: The Ultimate Guide. A handbook on MLOps and how to think about it\nEnterprise Readiness of Cloud MLOps\nShould I Train a Model for Each Customer or Use One Model for All of My Customers?\nMLOps-Basics (GitHub repo) by raviraja\nAnother tool won\u2019t fix your MLOps problems\nBest MLOps Tools: What to Look for and How to Evaluate Them\nMLOps vs. DevOps: A Detailed Comparison\nA Guide To Setting Up Your MLOps Team\n\nMLOps: Workflow Management\nOpen-source Workflow Management Tools: A Survey by Ploomber\nHow to Compare ML Experiment Tracking Tools to Fit Your Data Science Workflow (by dagshub)\n15 Best Tools for Tracking Machine Learning Experiments\nMLOps: Feature Stores\nClick to expand!\n\nFeature Stores for Machine Learning Medium Blog\nMLOps with a Feature Store\nFeature Stores for ML\nHopsworks: Data-Intensive AI with a Feature Store\nFeast: An open-source Feature Store for Machine Learning\nWhat is a Feature Store?\nML Feature Stores: A Casual Tour\nComprehensive List of Feature Store Architectures for Data Scientists and Big Data Professionals\nML Engineer Guide: Feature Store vs Data Warehouse (vendor blog)\nBuilding a Gigascale ML Feature Store with Redis, Binary Serialization, String Hashing, and Compression (DoorDash blog)\nFeature Stores: Variety of benefits for Enterprise AI.\nFeature Store as a Foundation for Machine Learning\nML Feature Serving Infrastructure at Lyft\nFeature Stores for Self-Service Machine Learning\nThe Architecture Used at LinkedIn to Improve Feature Management in Machine Learning Models.\nIs There a Feature Store Over the Rainbow? How to select the right feature store for your use case\n\nMLOps: Data Engineering (DataOps)\nClick to expand!\n\nThe state of data quality in 2020 \u2013 O\u2019Reilly\nWhy We Need DevOps for ML Data \nData Preparation for Machine Learning (7-Day Mini-Course)\nBest practices in data cleaning: A Complete Guide to Everything You Need to Do Before and After Collecting Your Data.\n17 Strategies for Dealing with Data, Big Data, and Even Bigger Data\nDataOps Data Architecture\nData Orchestration \u2014 A Primer\n4 Data Trends to Watch in 2020\nCSE 291D / 234: Data Systems for Machine Learning\nA complete picture of the modern data engineering landscape\nContinuous Integration for your data with GitHub Actions and Great Expectations. One step closer to CI/CD for your data pipelines\nEmerging Architectures for Modern Data Infrastructure\nAwesome Data Engineering. Learning path and resources to become a data engineer\nData Quality at Airbnb Part 1 | Part 2\nDataHub: Popular metadata architectures explained\nFinancial Times Data Platform: From zero to hero. An in-depth walkthrough of the evolution of our Data Platform\nAlki, or how we learned to stop worrying and love cold metadata (Dropbox)\nA Beginner's Guide to Clean Data. Practical advice to spot and avoid data quality problems (by Benjamin Greve)\nML Lake: Building Salesforce\u2019s Data Platform for Machine Learning\nData Catalog 3.0: Modern Metadata for the Modern Data Stack\nMetadata Management Systems\nEssential resources for data engineers (a curated recommended read and watch list for scalable data processing)\nComprehensive and Comprehensible Data Catalogs: The What, Who, Where, When, Why, and How of Metadata Management (Paper)\nWhat I Learned From Attending DataOps Unleashed 2021 (byJames Le)\nUber's Journey Toward Better Data Culture From First Principles\nCerberus - lightweight and extensible data validation library for Python\nDesign a data mesh architecture using AWS Lake Formation and AWS Glue. AWS Big Data Blog\nData Management Challenges in Production Machine Learning (slides)\nThe Missing Piece of Data Discovery and Observability Platforms: Open Standard for Metadata\nAutomating Data Protection at Scale\nA curated list of awesome pipeline toolkits\nData Mesh Archtitecture\nThe Essential Guide to Data Exploration in Machine Learning\n\nMLOps: Model Deployment and Serving\nClick to expand!\n\nAI Infrastructure for Everyone: DeterminedAI\nDeploying R Models with MLflow and Docker\nWhat Does it Mean to Deploy a Machine Learning Model?\nSoftware Interfaces for Machine Learning Deployment\nBatch Inference for Machine Learning Deployment\nAWS Cost Optimization for ML Infrastructure - EC2 spend\nCI/CD for Machine Learning & AI\nIta\u00fa Unibanco: How we built a CI/CD Pipeline for machine learning with online training in Kubeflow\n101 For Serving ML Models\nDeploying Machine Learning models to production \u2014 Inference service architecture patterns\nServerless ML: Deploying Lightweight Models at Scale\nML Model Rollout To Production. Part 1 | Part 2\nDeploying Python ML Models with Flask, Docker and Kubernetes\nDeploying Python ML Models with Bodywork\nFramework for a successful Continuous Training Strategy. When should the model be retrained? What data should be used? What should be retrained? A data-driven approach\nEfficient Machine Learning Inference. The benefits of multi-model serving where latency matters\n\nMLOps: Testing, Monitoring and Maintenance\nClick to expand!\n\nBuilding dashboards for operational visibility (AWS)\nMonitoring Machine Learning Models in Production\nEffective testing for machine learning systems\nUnit Testing Data: What is it and how do you do it?\nHow to Test Machine Learning Code and Systems (Accompanying code)\nWu, T., Dong, Y., Dong, Z., Singa, A., Chen, X. and Zhang, Y., 2020. Testing Artificial Intelligence System Towards Safety and Robustness: State of the Art. IAENG International Journal of Computer Science, 47(3).\nMulti-Armed Bandits and the Stitch Fix Experimentation Platform\nA/B Testing Machine Learning Models\nData validation for machine learning. Polyzotis, N., Zinkevich, M., Roy, S., Breck, E. and Whang, S., 2019. Proceedings of Machine Learning and Systems\nTesting machine learning based systems: a systematic mapping\nExplainable Monitoring: Stop flying blind and monitor your AI\nWhyLogs: Embrace Data Logging Across Your ML Systems\nEvidently AI. Insights on doing machine learning in production. (Vendor blog.)\nThe definitive guide to comprehensively monitoring your AI\nIntroduction to Unit Testing for Machine Learning\nProduction Machine Learning Monitoring: Outliers, Drift, Explainers & Statistical Performance\nTest-Driven Development in MLOps Part 1\nDomain-Specific Machine Learning Monitoring\nIntroducing ML Model Performance Management (Blog by fiddler)\nWhat is ML Observability? (Arize AI)\nBeyond Monitoring: The Rise of Observability (Arize AI & Monte Carlo Data)\nModel Failure Modes (Arize AI)\nQuick Start to Data Quality Monitoring for ML (Arize AI)\nPlaybook to Monitoring Model Performance in Production (Arize AI)\nRobust ML by Property Based Domain Coverage Testing (Blog by Efemarai)\nMonitoring and explainability of models in production\nBeyond Monitoring: The Rise of Observability\nML Model Monitoring \u2013 9 Tips From the Trenches. (by NU bank)\nModel health assurance at LinkedIn. By LinkedIn Engineering\nHow to Trust Your Deep Learning Code (Accompanying code)\nEstimating Performance of Regression Models Without Ground-Truth (Using NannyML)\nHow Hyperparameter Tuning in Machine Learning Works\n\nMLOps: Infrastructure & Tooling\nClick to expand!\n\nMLOps Infrastructure Stack Canvas\nRise of the Canonical Stack in Machine Learning. How a Dominant New Software Stack Will Unlock the Next Generation of Cutting Edge AI Apps\nAI Infrastructure Alliance. Building the canonical stack for AI/ML\nLinux Foundation AI Foundation\nML Infrastructure Tools for Production | Part 1 \u2014 Production ML \u2014 The Final Stage of the Model Workflow | Part 2 \u2014 Model Deployment and Serving\nThe MLOps Stack Template (by valohai)\nNavigating the MLOps tooling landscape\nMLOps.toys curated list of MLOps projects (by Aporia)\nComparing Cloud MLOps platforms, From a former AWS SageMaker PM\nMachine Learning Ecosystem 101 (whitepaper by Arize AI)\nSelecting your optimal MLOps stack: advantages and challenges. By Intellerts\nInfrastructure Design for Real-time Machine Learning Inference. The Databricks Blog\nThe 2021 State of AI Infrastructure Survey\nAI infrastructure Maturity matrix\nA Curated Collection of the Best Open-source MLOps Tools. By Censius\nBest MLOps Tools to Manage the ML Lifecycle\n\nMLOps Papers\nA list of scientific and industrial papers and resources about Machine Learning operalization since 2015. See more.\nTalks About MLOps\nClick to expand!\n\n\"MLOps: Automated Machine Learning\" by Emmanuel Raj\nDeliveryConf 2020. \"Continuous Delivery For Machine Learning: Patterns And Pains\" by Emily Gorcenski\nMLOps Conference: Talks from 2019\nKubecon 2019: Flyte: Cloud Native Machine Learning and Data Processing Platform\nKubecon 2019: Running LargeScale Stateful workloads on Kubernetes at Lyft\nA CI/CD Framework for Production Machine Learning at Massive Scale (using Jenkins X and Seldon Core)\nMLOps Virtual Event (Databricks)\nMLOps NY conference 2019\nMLOps.community YouTube Channel\nMLinProduction YouTube Channel\nIntroducing MLflow for End-to-End Machine Learning on Databricks. Spark+AI Summit 2020. Sean Owen\nMLOps Tutorial #1: Intro to Continuous Integration for ML\nMachine Learning At Speed: Operationalizing ML For Real-Time Data Streams (2019)\nDamian Brady - The emerging field of MLops\nMLOps - Entwurf, Entwicklung, Betrieb (INNOQ Podcast in German)\nInstrumentation, Observability & Monitoring of Machine Learning Models\nEfficient ML engineering: Tools and best practices\nBeyond the jupyter notebook: how to build data science products\nAn introduction to MLOps on Google Cloud (First 19 min are vendor-, language-, and framework-agnostic. @visenger)\nHow ML Breaks: A Decade of Outages for One Large ML Pipeline\nClean Machine Learning Code: Practical Software Engineering\nMachine Learning Engineering: 10 Fundamentale Praktiken\nArchitecture of machine learning systems (3-part series)\nMachine Learning Design Patterns\nThe laylist that covers techniques and approaches for model deployment on to production\nML Observability: A Critical Piece in Ensuring Responsible AI (Arize AI at Re-Work)\nML Engineering vs. Data Science (Arize AI Un/Summit)\nSRE for ML: The First 10 Years and the Next 10 \nDemystifying Machine Learning in Production: Reasoning about a Large-Scale ML Platform\nApply Conf 2022\nDatabricks' Data + AI Summit 2022\nRE\u2022WORK MLOps Summit 2022\nAnnual MLOps World Conference\n\nExisting ML Systems\nClick to expand!\n\nIntroducing FBLearner Flow: Facebook\u2019s AI backbone\nTFX: A TensorFlow-Based Production-Scale Machine Learning Platform\nAccelerate your ML and Data workflows to production: Flyte\nGetting started with Kubeflow Pipelines\nMeet Michelangelo: Uber\u2019s Machine Learning Platform\nMeson: Workflow Orchestration for Netflix Recommendations\nWhat are Azure Machine Learning pipelines?\nUber ATG\u2019s Machine Learning Infrastructure for Self-Driving Vehicles\nAn overview of ML development platforms\nSnorkel AI: Putting Data First in ML Development\nA Tour of End-to-End Machine Learning Platforms\nIntroducing WhyLabs, a Leap Forward in AI Reliability\nProject: Ease.ml (ETH Z\u00fcrich)\nBodywork: model-training and deployment automation\nLessons on ML Platforms \u2014 from Netflix, DoorDash, Spotify, and more\nPapers & tech blogs by companies sharing their work on data science & machine learning in production. By Eugen Yan\nHow do different tech companies approach building internal ML platforms? (tweet)\nDeclarative Machine Learning Systems\nStreamING Machine Learning Models: How ING Adds Fraud Detection Models at Runtime with Apache Flink\n\nMachine Learning\nClick to expand!\n\nBook, Aur\u00e9lien G\u00e9ron,\"Hands-On Machine Learning with Scikit-Learn and TensorFlow\"\nFoundations of Machine Learning\nBest Resources to Learn Machine Learning\nAwesome TensorFlow\n\"Papers with Code\" - Browse the State-of-the-Art in Machine Learning\nZhi-Hua Zhou. 2012. Ensemble Methods: Foundations and Algorithms. Chapman & Hall/CRC.\nFeature Engineering for Machine Learning. Principles and Techniques for Data Scientists. By Alice Zheng, Amanda Casari\nGoogle Research: Looking Back at 2019, and Forward to 2020 and Beyond\nO\u2019Reilly: The road to Software 2.0\nMachine Learning and Data Science Applications in Industry\nDeep Learning for Anomaly Detection\nFederated Learning for Mobile Keyboard Prediction\nFederated Learning. Building better products with on-device data and privacy on default\nFederated Learning: Collaborative Machine Learning without Centralized Training Data \nYang, Q., Liu, Y., Cheng, Y., Kang, Y., Chen, T. and Yu, H., 2019. Federated learning. Synthesis Lectures on Artificial Intelligence and Machine Learning, 13(3). Chapters 1 and 2.\nFederated Learning by FastForward\nTHE FEDERATED & DISTRIBUTED MACHINE LEARNING CONFERENCE\nFederated Learning: Challenges, Methods, and Future Directions\nBook: Molnar, Christoph. \"Interpretable machine learning. A Guide for Making Black Box Models Explainable\", 2019\nBook: Hutter, Frank, Lars Kotthoff, and Joaquin Vanschoren. \"Automated Machine Learning\". Springer,2019.\nML resources by topic, curated by the community. \nAn Introduction to Machine Learning Interpretability, by Patrick Hall, Navdeep Gill, 2nd Edition. O'Reilly 2019\nExamples of techniques for training interpretable machine learning (ML) models, explaining ML models, and debugging ML models for accuracy, discrimination, and security.\nPaper: \"Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence\", by Sebastian Raschka, Joshua Patterson, and Corey Nolet. 2020\nDistill: Machine Learning Research\nAtHomeWithAI: Curated Resource List by DeepMind\nAwesome Data Science\nIntro to probabilistic programming. A use case using Tensorflow-Probability (TFP)\nDive into Snorkel: Weak-Superversion on German Texts. inovex Blog\nDive into Deep Learning. An interactive deep learning book with code, math, and discussions. Provides NumPy/MXNet, PyTorch, and TensorFlow implementations\nData Science Collected Resources (GitHub repository)\nSet of illustrated Machine Learning cheatsheets\n\"Machine Learning Bookcamp\" by Alexey Grigorev\n130 Machine Learning Projects Solved and Explained\nMachine learning cheat sheet\nStateoftheart AI. An open-data and free platform built by the research community to facilitate the collaborative development of AI\nOnline Machine Learning Courses: 2020 Edition\nEnd-to-End Machine Learning Library\nMachine Learning Toolbox (by Amit Chaudhary)\nCausality for Machine Learning\nCausal Inference for the Brave and True\nCausal Inference\nA resource list for causality in statistics, data science and physics\nLearning from data. Caltech\nMachine Learning Glossary\nBook: \"Distributed Machine Learning Patterns\". 2022. By Yuan Tang. Manning\nMachine Learning for Beginners - A Curriculum\nMaking Friends with Machine Learning. By Cassie Kozyrkov\nMachine Learning Workflow - A Complete Guide\nPerformance Metrics to Monitor in Machine Learning Projects\n\nSoftware Engineering\nClick to expand!\n\nThe Twelve Factors\nBook \"Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations\", 2018 by Nicole Forsgren et.al\nBook \"The DevOps Handbook\" by Gene Kim, et al. 2016\nState of DevOps 2019\nClean Code concepts adapted for machine learning and data science.\nSchool of SRE\n10 Laws of Software Engineering That People Ignore\nThe Patterns of Scalable, Reliable, and Performant Large-Scale Systems\nThe Book of Secret Knowledge\nSHADES OF CONWAY'S LAW\nEngineering Practices for Data Scientists\n\nProduct Management for ML/AI\nClick to expand!\n\nWhat you need to know about product management for AI. A product manager for AI does everything a traditional PM does, and much more.\nBringing an AI Product to Market. Previous articles have gone through the basics of AI product management. Here we get to the meat: how do you bring a product to market?\nThe People + AI Guidebook\nUser Needs + Defining Success\nBuilding machine learning products: a problem well-defined is a problem half-solved.\nTalk: Designing Great ML Experiences (Apple) \nMachine Learning for Product Managers\nUnderstanding the Data Landscape and Strategic Play Through Wardley Mapping\nTechniques for prototyping machine learning systems across products and features\nMachine Learning and User Experience: A Few Resources\nAI ideation canvas\nIdeation in AI\n5 Steps for Building Machine Learning Models for Business. By shopify engineering\nMetric Design for Data Scientists and Business Leaders\n\nThe Economics of ML/AI\nClick to expand!\n\nBook: \"Prediction Machines: The Simple Economics of Artificial Intelligence\"\nBook: \"The AI Organization\" by David Carmona\nBook: \"Succeeding with AI\". 2020. By Veljko Krunic. Manning Publications\nA list of articles about AI and the economy\nGartner AI Trends 2019\nGlobal AI Survey: AI proves its worth, but few scale impact\nGetting started with AI? Start here! Everything you need to know to dive into your project\n11 questions to ask before starting a successful Machine Learning project\nWhat AI still can\u2019t do\nDemystifying AI Part 4: What is an AI Canvas and how do you use it?\nA Data Science Workflow Canvas to Kickstart Your Projects\nIs your AI project a nonstarter? Here\u2019s a reality check(list) to help you avoid the pain of learning the hard way\nWhat is THE main reason most ML projects fail?\nDesigning great data products. The Drivetrain Approach: A four-step process for building data products.\nThe New Business of AI (and How It\u2019s Different From Traditional Software)\nThe idea maze for AI startups\nThe Enterprise AI Challenge: Common Misconceptions\nMisconception 1 (of 5): Enterprise AI Is Primarily About The Technology\nMisconception 2 (of 5): Automated Machine Learning Will Unlock Enterprise AI\nThree Principles for Designing ML-Powered Products\nA Step-by-Step Guide to Machine Learning Problem Framing\nAI adoption in the enterprise 2020\nHow Adopting MLOps can Help Companies With ML Culture?\nWeaving AI into Your Organization\nWhat to Do When AI Fails\nIntroduction to Machine Learning Problem Framing\nStructured Approach for Identifying AI Use Cases\nBook: \"Machine Learning for Business\" by Doug Hudgeon, Richard Nichol, O'reilly\nWhy Commercial Artificial Intelligence Products Do Not Scale (FemTech)\nGoogle Cloud\u2019s AI Adoption Framework (White Paper)\nData Science Project Management\nBook: \"Competing in the Age of AI\" by Marco Iansiti, Karim R. Lakhani. Harvard Business Review Press. 2020\nThe Three Questions about AI that Startups Need to Ask. The first is: Are you sure you need AI?\nTaming the Tail: Adventures in Improving AI Economics\nManaging the Risks of Adopting AI Engineering\nGet rid of AI Saviorism\nCollection of articles listing reasons why data science projects fail\nHow to Choose Your First AI Project by Andrew Ng\nHow to Set AI Goals\nExpanding AI's Impact With Organizational Learning\nPotemkin Data Science\nWhen Should You Not Invest in AI?\nWhy 90% of machine learning models never hit the market. Most companies lack leadership support, effective communication between teams, and accessible data\n\nModel Governance, Ethics, Responsible AI\nThis topic is extracted into our new Awesome ML Model Governace repository\nMLOps: People & Processes\nClick to expand!\n\nScaling An ML Team (0\u201310 People)\nThe Knowledge Repo project is focused on facilitating the sharing of knowledge between data scientists and other technical roles. \nScaling Knowledge at Airbnb\nModels for integrating data science teams within companies A comparative analysis\nHow to Write Better with The Why, What, How Framework. How to write design documents for data science/machine learning projects? (by Eugene Yan)\nTechnical Writing Courses\nBuilding a data team at a mid-stage startup: a short story. By Erik Bernhardsson\nThe Cultural Benefits of Artificial Intelligence in the Enterprise. by Sam Ransbotham, Fran\u00e7ois Candelon, David Kiron, Burt LaFountain, and Shervin Khodabandeh\n\nNewsletters About MLOps, Machine Learning, Data Science and Co.\nClick to expand!\n\nML in Production newsletter\nMLOps.community\nAndriy Burkov newsletter\nDecision Intelligence by Cassie Kozyrkov\nLaszlo's Newsletter about Data Science\nData Elixir newsletter for a weekly dose of the top data science picks from around the web. Covering machine learning, data visualization, analytics, and strategy.\nThe Data Science Roundup by Tristan Handy\nVicki Boykis Newsletter about Data Science\nKDnuggets News\nAnalytics Vidhya, Any questions on business analytics, data science, big data, data visualizations tools and techniques\nData Science Weekly Newsletter: A free weekly newsletter featuring curated news, articles and jobs related to Data Science\nThe Machine Learning Engineer Newsletter\nGradient Flow helps you stay ahead of the latest technology trends and tools with in-depth coverage, analysis and insights. See the latest on data, technology and business, with a focus on machine learning and AI\nYour guide to AI by Nathan Benaich. Monthly analysis of AI technology, geopolitics, research, and startups.\nO'Reilly Data & AI Newsletter\ndeeplearning.ai\u2019s newsletter by Andrew Ng\nDeep Learning Weekly\nImport AI is a weekly newsletter about artificial intelligence, read by more than ten thousand experts. By Jack Clark.\nAI Ethics Weekly\nAnnouncing Projects To Know, a weekly machine intelligence and data science newsletter\nTWIML: This Week in Machine Learning and AI newsletter\nfeaturestore.org: Monthly Newsletter on Feature Stores for ML\nDataTalks.Club Community: Slack, Newsletter, Podcast, Weeekly Events\nMachine Learning Ops Roundup\nData Science Programming Newsletter by Eric Ma\nMarginally Interesting by Mikio L. Braun \nSynced\nThe Ground Truth: Newsletter for Computer Vision Practitioners\nSwirlAI: Data Engineering, MLOps and overall Data focused Newsletter by Aurimas Grici\u016bnas\n",
	"computer-vision data-centric data-science datascience deep deep-learning deeplearning learning machine machine-learning machinelearning ml natural-language natural-language-processing neural-network python pytorch": "\n\n\n\n\n\n\n\nFull Documentation: ludwig.ai\nWhat is Ludwig?\nLudwig is a declarative machine learning framework\nthat makes it easy to define machine learning pipelines using a simple and\nflexible data-driven configuration system. Ludwig is suitable for a wide variety\nof AI tasks, and is hosted by the\nLinux Foundation AI & Data.\nThe configuration declares the input and output features, with their respective\ndata types. Users can also specify additional parameters to preprocess, encode,\nand decode features, load from pre-trained models, compose the internal model\narchitecture, set training parameters, or run hyperparameter optimization.\nLudwig will build an end-to-end machine learning pipeline automatically, using\nwhatever is explicitly specified in the configuration, while falling back to\nsmart defaults for any parameters that are not.\nDeclarative Machine Learning\nLudwig\u2019s declarative approach to machine learning empowers you to have full\ncontrol of the components of the machine learning pipeline that you care about,\nwhile leaving it up to Ludwig to make reasonable decisions for the rest.\nAnalysts, scientists, engineers, and researchers use Ludwig to explore\nstate-of-the-art model architectures, run hyperparameter search, scale up to\nlarger than available memory datasets and multi-node clusters, and finally\nserve the best model in production.\nFinally, the use of abstract interfaces throughout the codebase makes it easy\nfor users to extend Ludwig by adding new models, metrics, losses, and\npreprocessing functions that can be registered to make them immediately useable\nin the same unified configuration system.\nMain Features\nData-Driven configuration system\nA config YAML file that describes the schema of your data (input features,\n  output features, and their types) is all you need to start training deep\n  learning models. Ludwig uses declared features to compose a deep learning\n  model accordingly.\nyaml\n  input_features:\n      - name: data_column_1\n        type: number\n      - name: data_column_2\n        type: category\n      - name: data_column_3\n        type: text\n      - name: data_column_4\n        type: image\n      ...\noutput_features:\n      - name: data_column_5\n        type: number\n      - name: data_column_6\n        type: category\n      ...\nTraining, prediction, and evaluation from the command line\nSimple commands can be used to train models and predict new data.\nshell\n  ludwig train --config config.yaml --dataset data.csv\n  ludwig predict --model_path results/experiment_run/model --dataset test.csv\n  ludwig eval --model_path results/experiment_run/model --dataset test.csv\nProgrammatic API\nLudwig also provides a simple programmatic API for all of the functionality\n  described above and more.\n```python\n  from ludwig.api import LudwigModel\ntrain a model\nconfig = {\n      \"input_features\": [...],\n      \"output_features\": [...],\n  }\n  model = LudwigModel(config)\n  data = pd.read_csv(\"data.csv\")\n  train_stats, _, model_dir = model.train(data)\nor load a model\nmodel = LudwigModel.load(model_dir)\nobtain predictions\npredictions = model.predict(data)\n  ```\nDistributed training\nTrain models in a distributed setting using Horovod,\n  which allows training on a single machine with multiple GPUs or multiple\n  machines with multiple GPUs.\nServing\nServe models using FastAPI.\nshell\n  ludwig serve --model_path ./results/experiment_run/model\n  curl http://0.0.0.0:8000/predict -X POST -F \"movie_title=Friends With Money\" -F \"content_rating=R\" -F \"genres=Art House & International, Comedy, Drama\" -F \"runtime=88.0\" -F \"top_critic=TRUE\" -F \"review_content=The cast is terrific, the movie isn't.\"\nHyperparameter optimization\nRun hyperparameter optimization locally or using Ray Tune.\nshell\n  ludwig hyperopt --config config.yaml --dataset data.csv\nAutoML\nLudwig AutoML takes a dataset, the target column, and a time budget, and\n  returns a trained Ludwig model.\nThird-Party integrations\nLudwig provides an extendable interface to integrate with third-party\n  systems for tracking experiments. Third-party integrations exist for Comet\n  ML, Weights & Biases, WhyLabs, and MLFlow.\nExtensibility\nLudwig is built from the ground up with extensibility in mind. It is easy to\n  add new data types by implementing clear, well-documented abstract classes\n  that define functions to preprocess, encode, and decode data.\nFurthermore, new torch nn.Module models can be easily added by them to a\n  registry. This encourages reuse and sharing new models with the community.\n  Refer to the Developer Guide\n  for further details.\nQuick Start\nFor a full tutorial, check out the official getting started guide,\nor take a look at end-to-end Examples.\nStep 1: Install\nInstall from PyPi. Be aware that Ludwig requires Python 3.7+.\nshell\npip install ludwig\nStep 2: Define a configuration\nCreate a config that describes the schema of your data.\nAssume we have a text classification task, with data containing a sentence and class column like the following.\n|               sentence               |  class   |\n| :----------------------------------: | :------: |\n|  Former president Barack Obama ...   | politics |\n| Juventus hired Cristiano Ronaldo ... |  sport   |\n|  LeBron James joins the Lakers ...   |  sport   |\n|                 ...                  |   ...    |\nA configuration will look like this.\nyaml\ninput_features:\n- name: sentence\n  type: text\noutput_features:\n- name: class\n  type: category\nStarting from a simple config like the one above, any and all aspects of the model architecture, training loop,\nhyperparameter search, and backend infrastructure can be modified as additional fields in the declarative configuration\nto customize the pipeline to meet your requirements.\nyaml\ninput_features:\n- name: sentence\n  type: text\n  encoder: transformer\n  layers: 6\n  embedding_size: 512\noutput_features:\n- name: class\n  type: category\n  loss: cross_entropy\ntrainer:\n  epochs: 50\n  batch_size: 64\n  optimizer:\n    type: adamw\n    beat1: 0.9\n  learning_rate: 0.001\nbackend:\n  type: ray\n  cache_format: parquet\n  processor:\n    type: dask\n  trainer:\n    use_gpu: true\n    num_workers: 4\n    resources_per_worker:\n      CPU: 4\n      GPU: 1\nhyperopt:\n  metric: f1\n  sampler: random\n  parameters:\n    title.num_layers:\n      lower: 1\n      upper: 5\n    trainer.learning_rate:\n      values: [0.01, 0.003, 0.001]\nFor details on what can be configured, check out Ludwig Configuration\ndocs.\nStep 3: Train a model\nSimple commands can be used to train models and predict new data.\nshell\nludwig train --config config.yaml --dataset data.csv\nStep 4: Predict and evaluate\nThe training process will produce a model that can be used for evaluating on and obtaining predictions for new data.\nshell\nludwig predict --model path/to/trained/model --dataset heldout.csv\nludwig evaluate --model path/to/trained/model --dataset heldout.csv\nStep 5: Visualize\nLudwig provides a suite of visualization tools allows you to analyze models' training and test performance and to\ncompare them.\nshell\nludwig visualize --visualization compare_performance --test_statistics path/to/test_statistics_model_1.json path/to/test_statistics_model_2.json\nFor the full set of visualization see the Visualization Guide.\nStep 6: Happy modeling\nTry applying Ludwig to your data. Reach out\nif you have any questions.\nAdvantages\nMinimal machine learning boilerplate\nLudwig takes care of the engineering complexity of machine learning out of\n  the box, enabling research scientists to focus on building models at the\n  highest level of abstraction. Data preprocessing, hyperparameter\n  optimization, device management, and distributed training for\n  torch.nn.Module models come completely free.\nEasily build your benchmarks\nCreating a state-of-the-art baseline and comparing it with a new model is a\n  simple config change.\nEasily apply new architectures to multiple problems and datasets\nApply new models across the extensive set of tasks and datasets that Ludwig\n  supports. Ludwig includes a\n  full benchmarking toolkit accessible to\n  any user, for running experiments with multiple models across multiple\n  datasets with just a simple configuration.\nHighly configurable data preprocessing, modeling, and metrics\nAny and all aspects of the model architecture, training loop, hyperparameter\n  search, and backend infrastructure can be modified as additional fields in\n  the declarative configuration to customize the pipeline to meet your\n  requirements. For details on what can be configured, check out\n  Ludwig Configuration\n  docs.\nMulti-modal, multi-task learning out-of-the-box\nMix and match tabular data, text, images, and even audio into complex model\n  configurations without writing code.\nRich model exporting and tracking\nAutomatically track all trials and metrics with tools like Tensorboard,\n  Comet ML, Weights & Biases, MLFlow, and Aim Stack.\nAutomatically scale training to multi-GPU, multi-node clusters\nGo from training on your local machine to the cloud without code changes.\nLow-code interface for state-of-the-art models, including pre-trained Huggingface Transformers\nLudwig also natively integrates with pre-trained models, such as the ones\n  available in Huggingface Transformers.\n  Users can choose from a vast collection of state-of-the-art pre-trained\n  PyTorch models to use without needing to write any code at all. For example,\n  training a BERT-based sentiment analysis model with Ludwig is as simple as:\nshell\n  ludwig train --dataset sst5 --config_str \u201c{input_features: [{name: sentence, type: text, encoder: bert}], output_features: [{name: label, type: category}]}\u201d\nLow-code interface for AutoML\nLudwig AutoML\n  allows users to obtain trained models by providing just a dataset, the\n  target column, and a time budget.\npython\n  auto_train_results = ludwig.automl.auto_train(dataset=my_dataset_df, target=target_column_name, time_limit_s=7200)\nEasy productionisation\nLudwig makes it easy to serve deep learning models, including on GPUs.\n  Launch a REST API for your trained Ludwig model.\nshell\n  ludwig serve --model_path=/path/to/model\nLudwig supports exporting models to efficient Torschscript bundles.\nshell\n  ludwig export_torchscript -\u2013model_path=/path/to/model\nTutorials\nText Classification\nTabular Data Classification\nImage Classification\nMultimodal Classification\nExample Use Cases\nNamed Entity Recognition Tagging\nNatural Language Understanding\nMachine Translation\nChit-Chat Dialogue Modeling through seq2seq\nSentiment Analysis\nOne-shot Learning with Siamese Networks\nVisual Question Answering\nSpoken Digit Speech Recognition\nSpeaker Verification\nBinary Classification (Titanic)\nTimeseries forecasting\nTimeseries forecasting (Weather)\nMovie rating prediction\nMulti-label classification\nMulti-Task Learning\nSimple Regression: Fuel Efficiency Prediction\nFraud Detection\nMore Information\nRead our publications on Ludwig, declarative ML, and Ludwig\u2019s SoTA benchmarks.\nLearn more about how Ludwig works, how to get started, and work through more examples.\nIf you are interested in contributing, have questions, comments, or thoughts to share, or if you just want to be in the\nknow, please consider joining the Ludwig Slack and follow us on Twitter!\nGetting Involved\nSlack\nTwitter\nMedium\nGitHub Issues",
	"algorithms dotnet machine-learning ml": "Machine Learning for .NET\nML.NET is a cross-platform open-source machine learning (ML) framework for .NET.\nML.NET allows developers to easily build, train, deploy, and consume custom models in their .NET applications without requiring prior expertise in developing machine learning models or experience with other programming languages like Python or R. The framework provides data loading from files and databases, enables data transformations, and includes many ML algorithms.\nWith ML.NET, you can train models for a variety of scenarios, like classification, forecasting, and anomaly detection.\nYou can also consume both TensorFlow and ONNX models within ML.NET which makes the framework more extensible and expands the number of supported scenarios.\nGetting started with machine learning and ML.NET\nLearn more about the basics of ML.NET.\nBuild your first ML.NET model by following our ML.NET Getting Started tutorial.\nCheck out our documentation and tutorials.\nSee the API Reference documentation.\nClone our ML.NET Samples GitHub repo and run some sample apps.\nTake a look at some ML.NET Community Samples.\nWatch some videos on the ML.NET videos YouTube playlist.\nRoadmap\nTake a look at ML.NET's Roadmap to see what the team plans to work on in the next year.\nOperating systems and processor architectures supported by ML.NET\nML.NET runs on Windows, Linux, and macOS using .NET Core, or Windows using .NET Framework.\nML.NET also runs on ARM64, Apple M1, and Blazor Web Assembly. However, there are some limitations.\n64-bit is supported on all platforms. 32-bit is supported on Windows, except for TensorFlow and LightGBM related functionality.\nML.NET NuGet packages status\nRelease notes\nCheck out the release notes to see what's new. You can also read the blog posts for more details about each release.\nUsing ML.NET packages\nFirst, ensure you have installed .NET Core 2.1 or later. ML.NET also works on the .NET Framework 4.6.1 or later, but 4.7.2 or later is recommended.\nOnce you have an app, you can install the ML.NET NuGet package from the .NET Core CLI using:\ndotnet add package Microsoft.ML\nor from the NuGet Package Manager:\nInstall-Package Microsoft.ML\nAlternatively, you can add the Microsoft.ML package from within Visual Studio's NuGet package manager or via Paket.\nDaily NuGet builds of the project are also available in our Azure DevOps feed:\nhttps://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet-libraries/nuget/v3/index.json\nBuilding ML.NET (For contributors building ML.NET open source code)\nTo build ML.NET from source please visit our developer guide.\n|    | Debug | Release |\n|:---|----------------:|------------------:|\n|CentOS|||\n|Ubuntu|||\n|macOS|||\n|Windows x64|||\n|Windows FullFramework|||\n|Windows x86|||\n|Windows NetCore3.1|||\nRelease process and versioning\nMajor releases of ML.NET are shipped once a year with the major .NET releases, starting with ML.NET 1.7 in November 2021 with .NET 6, then ML.NET 2.0 with .NET 7, etc. We will maintain release branches to optionally service ML.NET with bug fixes and/or minor features on the same cadence as .NET servicing.\nCheck out the Release Notes to see all of the past ML.NET releases.\nContributing\nWe welcome contributions! Please review our contribution guide.\nCommunity\nJoin our community on Discord.\nTune into the .NET Machine Learning Community Standup every other Wednesday at 10AM Pacific Time.\nThis project has adopted the code of conduct defined by the Contributor Covenant to clarify expected behavior in our community.\nFor more information, see the .NET Foundation Code of Conduct.\nCode examples\nHere is a code snippet for training a model to predict sentiment from text samples. You can find complete samples in the samples repo.\nC#\nvar dataPath = \"sentiment.csv\";\nvar mlContext = new MLContext();\nvar loader = mlContext.Data.CreateTextLoader(new[]\n    {\n        new TextLoader.Column(\"SentimentText\", DataKind.String, 1),\n        new TextLoader.Column(\"Label\", DataKind.Boolean, 0),\n    },\n    hasHeader: true,\n    separatorChar: ',');\nvar data = loader.Load(dataPath);\nvar learningPipeline = mlContext.Transforms.Text.FeaturizeText(\"Features\", \"SentimentText\")\n        .Append(mlContext.BinaryClassification.Trainers.FastTree());\nvar model = learningPipeline.Fit(data);\nNow from the model we can make inferences (predictions):\nC#\nvar predictionEngine = mlContext.Model.CreatePredictionEngine(model);\nvar prediction = predictionEngine.Predict(new SentimentData\n{\n    SentimentText = \"Today is a great day!\"\n});\nConsole.WriteLine(\"prediction: \" + prediction.Prediction);\nLicense\nML.NET is licensed under the MIT license, and it is free to use commercially.\n.NET Foundation\nML.NET is a part of the .NET Foundation.",
	"anomaly-detection citizen-data-scientists classification clustering data-science gpu machine-learning ml nlp pycaret python regression time-series": "An open-source, low-code machine learning library in Python \n:rocket: PyCaret 3.0-rc is now out. pip install --pre pycaret\nOfficial \u2022\n  Docs \u2022\n  Install \u2022\n  Tutorials \u2022\n  FAQs \u2022\n  Cheat sheet \u2022\n  Discussions \u2022\n  Contribute \u2022\n  Resources \u2022\n  Blog \u2022\n  LinkedIn \u2022 \n  YouTube \u2022 \n  Slack\n\n\n\n\n \n\n\nWelcome to PyCaret\nPyCaret is an open-source, low-code machine learning library in Python that automates machine learning workflows. It is an end-to-end machine learning and model management tool that speeds up the experiment cycle exponentially and makes you more productive.\nIn comparison with the other open-source machine learning libraries, PyCaret is an alternate low-code library that can be used to replace hundreds of lines of code with few lines only. This makes experiments exponentially fast and efficient. PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as scikit-learn, XGBoost, LightGBM, CatBoost, spaCy, Optuna, Hyperopt, Ray, and few more.\nThe design and simplicity of PyCaret are inspired by the emerging role of citizen data scientists, a term first used by Gartner. Citizen Data Scientists are power users who can perform both simple and moderately sophisticated analytical tasks that would previously have required more technical expertise.\n| Important Links              |                                                                |\n| -------------------------- | -------------------------------------------------------------- |\n| :star: Tutorials        | New to PyCaret? Checkout our official notebooks!            |\n| :clipboard: Example Notebooks | Example notebooks created by community.               |\n| :orange_book: Official Blog | Tutorials and articles by contributors.                      |\n| :books: Documentation      | The detailed API docs of PyCaret                         |\n| :tv: Video Tutorials            | Our video tutorial from various events.             |\n| \u2708\ufe0f Cheat sheet            | Cheat sheet for all functions across modules.             |\n| :loudspeaker: Discussions        | Have questions? Engage with community and contributors.|\n| :hammer_and_wrench: Changelog          | Changes and version history.                 |\n| :deciduous_tree: Roadmap          | PyCaret's software and community development plan.|\nInstallation\nPyCaret's default installation only installs hard dependencies as listed in the requirements.txt file. \npython\npip install pycaret\nTo install the full version:\npython\npip install pycaret[full]\nSupervised Workflow\nClassification           |  Regression\n:-------------------------:|:-------------------------:\n  | \n# Unsupervised Workflow\nClustering               |  Anomaly Detection\n:-------------------------:|:-------------------------:\n  |   \n\u26a1 PyCaret Time Series Module\nPyCaret time series module is now available with the main pycaret installation. Staying true to simplicity of PyCaret, it is consistent with our existing API and fully loaded with functionalities. Statistical testing, model training and selection (30+ algorithms), model analysis, automated hyperparameter tuning, experiment logging, deployment on cloud, and more. All of this with only few lines of code (just like the other modules of pycaret). \n| Important Links              |                                                                |\n| -------------------------- | -------------------------------------------------------------- |\n| :star: Time Series Quickstart        | Get started with Time Series Analysis         |\n| :books: Time Series Notebooks        | New to Time Series? Checkout our official (detailed) notebooks!            |\n| :tv: Time Series Video Tutorials            | Our video tutorial from various events.             |\n| :question: Time Series FAQs        |   Have questions? Queck out the FAQ's     |\n| :hammer_and_wrench: Time Series API Interface        |   The detailed API interface for the Time Series Module          |\n| :deciduous_tree: Time Series Features and Roadmap          | PyCaret's software and community development plan.|\nInstallation\npip install --pre pycaret \n \nWho should use PyCaret?\nPyCaret is an open source library that anybody can use. In our view the ideal target audience of PyCaret is: \n\nExperienced Data Scientists who want to increase productivity.\nCitizen Data Scientists who prefer a low code machine learning solution.\nData Science Professionals who want to build rapid prototypes.\nData Science and Machine Learning students and enthusiasts.\n\nPyCaret GPU support\nWith PyCaret >= 2.2, you can train models on GPU and speed up your workflow by 10x. To train models on GPU simply pass use_gpu = True in the setup function. There is no change in the use of the API, however, in some cases, additional libraries have to be installed as they are not installed with the default version or the full version. As of the latest release, the following models can be trained on GPU:\n\nExtreme Gradient Boosting (requires no further installation)\nCatBoost (requires no further installation)\nLight Gradient Boosting Machine requires GPU installation\nLogistic Regression, Ridge Classifier, Random Forest, K Neighbors Classifier, K Neighbors Regressor, Support Vector Machine, Linear Regression, Ridge Regression, Lasso Regression requires cuML >= 0.15\n\nPyCaret Intel sklearnex support\nYou can apply Intel optimizations for machine learning algorithms and speed up your workflow. To train models with Intel optimizations use sklearnex engine. There is no change in the use of the API, however, installation of Intel sklearnex is required:\npip install scikit-learn-intelex\nLicense\nPyCaret is completely free and open-source and licensed under the MIT license. \nContributors",
	"ai cli data-science datascience high-performance-computing kubernetes machine-learning ml ml-infrastructure ml-platform mlops model-management productivity python r r-package reproducible-research rstats": "Metaflow\nMetaflow is a human-friendly Python/R library that helps scientists and engineers build and manage real-life data science projects. Metaflow was originally developed at Netflix to boost productivity of data scientists who work on a wide variety of projects from classical statistics to state-of-the-art deep learning.\nFor more information, see Metaflow's website and documentation.\nGetting Started\nGetting up and running with Metaflow is easy. \nPython\nInstall metaflow from pypi:\nsh\npip install metaflow\nand access tutorials by typing:\nsh\nmetaflow tutorials pull\nR\nInstall Metaflow from github:\nR\ndevtools::install_github(\"Netflix/metaflow\", subdir=\"R\")\nmetaflow::install()\nand access tutorials by typing:\nR\nmetaflow::pull_tutorials()\nGet in Touch\nThere are several ways to get in touch with us:\nOpen an issue at: https://github.com/Netflix/metaflow \nEmail us at: help@metaflow.org\nChat with us on: http://chat.metaflow.org \nContributing\nWe welcome contributions to Metaflow. Please see our contribution guide for more details.\nCode style\nWe use black as a code formatter. The easiest way to ensure your commits are always formatted with the correct version of black it is to use pre-commit: install it and then run pre-commit install once in your local copy of the repo.",
	"cpp deep-learning deep-neural-networks machine-learning ml neural-network python serving tensorflow": "TensorFlow Serving\nTensorFlow Serving is a flexible, high-performance serving system for\nmachine learning models, designed for production environments. It deals with\nthe inference aspect of machine learning, taking models after training and\nmanaging their lifetimes, providing clients with versioned access via\na high-performance, reference-counted lookup table.\nTensorFlow Serving provides out-of-the-box integration with TensorFlow models,\nbut can be easily extended to serve other types of models and data.\nTo note a few features:\nCan serve multiple models, or multiple versions of the same model\n    simultaneously\nExposes both gRPC as well as HTTP inference endpoints\nAllows deployment of new model versions without changing any client code\nSupports canarying new versions and A/B testing experimental models\nAdds minimal latency to inference time due to efficient, low-overhead\n    implementation\nFeatures a scheduler that groups individual inference requests into batches\n    for joint execution on GPU, with configurable latency controls\nSupports many servables: Tensorflow models, embeddings, vocabularies,\n    feature transformations and even non-Tensorflow-based machine learning\n    models\nServe a Tensorflow model in 60 seconds\nbash\nDownload the TensorFlow Serving Docker image and repo\ndocker pull tensorflow/serving\ngit clone https://github.com/tensorflow/serving\nLocation of demo models\nTESTDATA=\"$(pwd)/serving/tensorflow_serving/servables/tensorflow/testdata\"\nStart TensorFlow Serving container and open the REST API port\ndocker run -t --rm -p 8501:8501 \\\n    -v \"$TESTDATA/saved_model_half_plus_two_cpu:/models/half_plus_two\" \\\n    -e MODEL_NAME=half_plus_two \\\n    tensorflow/serving &\nQuery the model using the predict API\ncurl -d '{\"instances\": [1.0, 2.0, 5.0]}' \\\n    -X POST http://localhost:8501/v1/models/half_plus_two:predict\nReturns => { \"predictions\": [2.5, 3.0, 4.5] }\nEnd-to-End Training & Serving Tutorial\nRefer to the official Tensorflow documentations site for a complete tutorial to train and serve a Tensorflow Model.\nDocumentation\nSet up\nThe easiest and most straight-forward way of using TensorFlow Serving is with\nDocker images. We highly recommend this route unless you have specific needs\nthat are not addressed by running in a container.\nInstall Tensorflow Serving using Docker\n(Recommended)\nInstall Tensorflow Serving without Docker\n(Not Recommended)\nBuild Tensorflow Serving from Source with Docker\nDeploy Tensorflow Serving on Kubernetes\nUse\nExport your Tensorflow model\nIn order to serve a Tensorflow model, simply export a SavedModel from your\nTensorflow program.\nSavedModel\nis a language-neutral, recoverable, hermetic serialization format that enables\nhigher-level systems and tools to produce, consume, and transform TensorFlow\nmodels.\nPlease refer to Tensorflow documentation\nfor detailed instructions on how to export SavedModels.\nConfigure and Use Tensorflow Serving\nFollow a tutorial on Serving Tensorflow models\nConfigure Tensorflow Serving to make it fit your serving use case\nRead the Performance Guide\nand learn how to use TensorBoard to profile and optimize inference requests\nRead the REST API Guide\nor gRPC API definition\nUse SavedModel Warmup if initial inference requests are slow due to lazy initialization of graph\nIf encountering issues regarding model signatures, please read the SignatureDef documentation\nIf using a model with custom ops, learn how to serve models with custom ops\nExtend\nTensorflow Serving's architecture is highly modular. You can use some parts\nindividually (e.g. batch scheduling) and/or extend it to serve new use cases.\nEnsure you are familiar with building Tensorflow Serving\nLearn about Tensorflow Serving's architecture\nExplore the Tensorflow Serving C++ API reference\nCreate a new type of Servable\nCreate a custom Source of Servable versions\nContribute\nIf you'd like to contribute to TensorFlow Serving, be sure to review the\ncontribution guidelines.\nFor more information\nPlease refer to the official TensorFlow website for\nmore information."
}