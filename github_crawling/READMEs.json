{
	"data-science deep-learning machine-learning neural-networks python tensorflow": "# Keras: Deep Learning for humans\n\n![Keras logo](https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png)\n\nThis repository hosts the development of the Keras library.\nRead the documentation at [keras.io](https://keras.io/).\n\n## About Keras\n\nKeras is a deep learning API written in Python,\nrunning on top of the machine learning platform [TensorFlow](https://github.com/tensorflow/tensorflow).\nIt was developed with a focus on enabling fast experimentation.\n*Being able to go from idea to result as fast as possible is key to doing good research.*\n\nKeras is:\n\n-   **Simple** -- but not simplistic. Keras reduces developer *cognitive load*\n    to free you to focus on the parts of the problem that really matter.\n-   **Flexible** -- Keras adopts the principle of *progressive disclosure of\n    complexity*: simple workflows should be quick and easy, while arbitrarily\n    advanced workflows should be *possible* via a clear path that builds upon\n    what you've already learned.\n-   **Powerful** -- Keras provides industry-strength performance and\n    scalability: it is used by organizations and companies including NASA,\n    YouTube, and Waymo.\n\n---\n\n## Keras & TensorFlow 2\n\n[TensorFlow 2](https://www.tensorflow.org/) is an end-to-end, open-source machine learning platform.\nYou can think of it as an infrastructure layer for\n[differentiable programming](https://en.wikipedia.org/wiki/Differentiable_programming).\nIt combines four key abilities:\n\n- Efficiently executing low-level tensor operations on CPU, GPU, or TPU.\n- Computing the gradient of arbitrary differentiable expressions.\n- Scaling computation to many devices, such as clusters of hundreds of GPUs.\n- Exporting programs (\"graphs\") to external runtimes such as servers, browsers, mobile and embedded devices.\n\nKeras is the high-level API of TensorFlow 2: an approachable, highly-productive interface\nfor solving machine learning problems,\nwith a focus on modern deep learning. It provides essential abstractions and building blocks for developing\nand shipping machine learning solutions with high iteration velocity.\n\nKeras empowers engineers and researchers to take full advantage of the scalability\nand cross-platform capabilities of TensorFlow 2: you can run Keras on TPU or on large clusters of GPUs,\nand you can export your Keras models to run in the browser or on a mobile device.\n\n---\n\n## First contact with Keras\n\nThe core data structures of Keras are __layers__ and __models__.\nThe simplest type of model is the [`Sequential` model](/guides/sequential_model/), a linear stack of layers.\nFor more complex architectures, you should use the [Keras functional API](/guides/functional_api/),\nwhich allows you to build arbitrary graphs of layers or [write models entirely from scratch via subclassing](/guides/making_new_layers_and_models_via_subclassing/).\n\nHere is the `Sequential` model:\n\n```python\nfrom tensorflow.keras.models import Sequential\n\nmodel = Sequential()\n```\n\nStacking layers is as easy as `.add()`:\n\n```python\nfrom tensorflow.keras.layers import Dense\n\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dense(units=10, activation='softmax'))\n```\n\nOnce your model looks good, configure its learning process with `.compile()`:\n\n```python\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])\n```\n\nIf you need to, you can further configure your optimizer. The Keras philosophy is to keep simple things simple,\nwhile allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code via subclassing).\n\n```python\nmodel.compile(loss=tf.keras.losses.categorical_crossentropy,\n              optimizer=tf.keras.optimizers.SGD(\n                  learning_rate=0.01, momentum=0.9, nesterov=True))\n```\n\nYou can now iterate on your training data in batches:\n\n```python\n# x_train and y_train are Numpy arrays.\nmodel.fit(x_train, y_train, epochs=5, batch_size=32)\n```\n\nEvaluate your test loss and metrics in one line:\n\n```python\nloss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n```\n\nOr generate predictions on new data:\n\n```python\nclasses = model.predict(x_test, batch_size=128)\n```\n\nWhat you just saw is the most elementary way to use Keras.\n\nHowever, Keras is also a highly-flexible framework suitable to iterate on state-of-the-art research ideas.\nKeras follows the principle of **progressive disclosure of complexity**: it makes it easy to get started,\nyet it makes it possible to handle arbitrarily advanced use cases,\nonly requiring incremental learning at each step.\n\nIn much the same way that you were able to train & evaluate a simple neural network above in a few lines,\nyou can use Keras to quickly develop new training procedures or exotic model architectures.\nHere's a low-level training loop example, combining Keras functionality with the TensorFlow `GradientTape`:\n\n```python\nimport tensorflow as tf\n\n# Prepare an optimizer.\noptimizer = tf.keras.optimizers.Adam()\n# Prepare a loss function.\nloss_fn = tf.keras.losses.kl_divergence\n\n# Iterate over the batches of a dataset.\nfor inputs, targets in dataset:\n    # Open a GradientTape.\n    with tf.GradientTape() as tape:\n        # Forward pass.\n        predictions = model(inputs)\n        # Compute the loss value for this batch.\n        loss_value = loss_fn(targets, predictions)\n\n    # Get gradients of loss wrt the weights.\n    gradients = tape.gradient(loss_value, model.trainable_weights)\n    # Update the weights of the model.\n    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n```\n\nFor more in-depth tutorials about Keras, you can check out:\n\n-   [Introduction to Keras for engineers](https://keras.io/getting_started/intro_to_keras_for_engineers/)\n-   [Introduction to Keras for researchers](https://keras.io/getting_started/intro_to_keras_for_researchers/)\n-   [Developer guides](https://keras.io/guides/)\n-   [Other learning resources](https://keras.io/getting_started/learning_resources/)\n\n---\n\n## Installation\n\nKeras comes packaged with TensorFlow 2 as `tensorflow.keras`.\nTo start using Keras, simply [install TensorFlow 2](https://www.tensorflow.org/install).\n\n---\n\n## Release and compatibility\n\nKeras has **nightly releases** (`keras-nightly` on PyPI)\nand **stable releases** (`keras` on PyPI).\nThe nightly Keras releases are usually compatible with the corresponding version\nof the `tf-nightly` releases\n(e.g. `keras-nightly==2.7.0.dev2021100607` should be\nused with `tf-nightly==2.7.0.dev2021100607`).\nWe don't maintain backward compatibility for nightly releases.\nFor stable releases, each Keras\nversion maps to a specific stable version of TensorFlow.\n\nThe table below shows the compatibility version mapping\nbetween TensorFlow versions and Keras versions.\n\nAll the release branches can be found on [GitHub](https://github.com/keras-team/keras/releases).\n\nAll the release binaries can be found on [Pypi](https://pypi.org/project/keras/#history).\n\n| Keras release | Note      | Compatible Tensorflow version |\n| -----------   | ----------- | -----------        |\n| [2.4](https://github.com/keras-team/keras/releases/tag/2.4.0)  | Last stable release of multi-backend Keras | < 2.5\n| 2.5-pre| Pre-release (not formal) for standalone Keras repo | >= 2.5 < 2.6\n| [2.6](https://github.com/keras-team/keras/releases/tag/v2.6.0)    | First formal release of standalone Keras.  | >= 2.6 < 2.7\n| [2.7](https://github.com/keras-team/keras/releases/tag/v2.7.0-rc0)    | (Upcoming release) | >= 2.7 < 2.8\n| nightly|                                            | tf-nightly\n\n---\n## Support\n\nYou can ask questions and join the development discussion:\n\n- In the [TensorFlow forum](https://discuss.tensorflow.org/).\n- On the [Keras Google group](https://groups.google.com/forum/#!forum/keras-users).\n\n---\n\n## Opening an issue\n\nYou can also post **bug reports and feature requests** (only)\nin [GitHub issues](https://github.com/keras-team/keras/issues).\n\n\n---\n\n## Opening a PR\n\nWe welcome contributions! Before opening a PR, please read\n[our contributor guide](https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md),\nand the [API design guideline](https://github.com/keras-team/governance/blob/master/keras_api_design_guidelines.md).\n",
	"analytics apache apache-superset asf bi business-analytics business-intelligence data-analysis data-analytics data-engineering data-science data-visualization data-viz flask python react sql-editor superset": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n# Superset\n\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/apache/superset?sort=semver)](https://github.com/apache/superset/tree/latest)\n[![Build Status](https://github.com/apache/superset/workflows/Python/badge.svg)](https://github.com/apache/superset/actions)\n[![PyPI version](https://badge.fury.io/py/apache-superset.svg)](https://badge.fury.io/py/apache-superset)\n[![Coverage Status](https://codecov.io/github/apache/superset/coverage.svg?branch=master)](https://codecov.io/github/apache/superset)\n[![PyPI](https://img.shields.io/pypi/pyversions/apache-superset.svg?maxAge=2592000)](https://pypi.python.org/pypi/apache-superset)\n[![Get on Slack](https://img.shields.io/badge/slack-join-orange.svg)](https://join.slack.com/t/apache-superset/shared_invite/zt-1jp6hjzrq-H0PlFtToyLWuPiJDuRWCNw)\n[![Documentation](https://img.shields.io/badge/docs-apache.org-blue.svg)](https://superset.apache.org)\n\n<img\n  src=\"https://github.com/apache/superset/raw/master/superset-frontend/src/assets/branding/superset-logo-horiz-apache.png\"\n  alt=\"Superset\"\n  width=\"500\"\n/>\n\nA modern, enterprise-ready business intelligence web application.\n\n[**Why Superset?**](#why-superset) |\n[**Supported Databases**](#supported-databases) |\n[**Installation and Configuration**](#installation-and-configuration) |\n[**Release Notes**](RELEASING/README.md#release-notes-for-recent-releases) |\n[**Get Involved**](#get-involved) |\n[**Contributor Guide**](#contributor-guide) |\n[**Resources**](#resources) |\n[**Organizations Using Superset**](RESOURCES/INTHEWILD.md)\n\n## Why Superset?\n\nSuperset is a modern data exploration and data visualization platform. Superset can replace or augment proprietary business intelligence tools for many teams. Superset integrates well with a variety of data sources.\n\nSuperset provides:\n\n- A **no-code interface** for building charts quickly\n- A powerful, web-based **SQL Editor** for advanced querying\n- A **lightweight semantic layer** for quickly defining custom dimensions and metrics\n- Out of the box support for **nearly any SQL** database or data engine\n- A wide array of **beautiful visualizations** to showcase your data, ranging from simple bar charts to geospatial visualizations\n- Lightweight, configurable **caching layer** to help ease database load\n- Highly extensible **security roles and authentication** options\n- An **API** for programmatic customization\n- A **cloud-native architecture** designed from the ground up for scale\n\n## Screenshots & Gifs\n\n**Large Gallery of Visualizations**\n\n<kbd><img title=\"Gallery\" src=\"superset-frontend/src/assets/images/screenshots/gallery.jpg\"/></kbd><br/>\n\n**Craft Beautiful, Dynamic Dashboards**\n\n<kbd><img title=\"View Dashboards\" src=\"superset-frontend/src/assets/images/screenshots/slack_dash.jpg\"/></kbd><br/>\n\n**No-Code Chart Builder**\n\n<kbd><img title=\"Slice & dice your data\" src=\"superset-frontend/src/assets/images/screenshots/explore.jpg\"/></kbd><br/>\n\n**Powerful SQL Editor**\n\n<kbd><img title=\"SQL Lab\" src=\"superset-frontend/src/assets/images/screenshots/sql_lab.jpg\"/></kbd><br/>\n\n## Supported Databases\n\nSuperset can query data from any SQL-speaking datastore or data engine (Presto, Trino, Athena, [and more](https://superset.apache.org/docs/databases/installing-database-drivers/)) that has a Python DB-API driver and a SQLAlchemy dialect.\n\nHere are some of the major database solutions that are supported:\n\n<p align=\"center\">\n  <img src=\"superset-frontend/src/assets/images/redshift.png\" alt=\"redshift\" border=\"0\" width=\"200\" height=\"80\"/>\n  <img src=\"superset-frontend/src/assets/images/google-biquery.png\" alt=\"google-biquery\" border=\"0\" width=\"200\" height=\"80\"/>\n  <img src=\"superset-frontend/src/assets/images/snowflake.png\" alt=\"snowflake\" border=\"0\" width=\"200\" height=\"80\"/>\n  <img src=\"superset-frontend/src/assets/images/trino.png\" alt=\"trino\" border=\"0\" width=\"200\" height=\"80\"/>\n  <img src=\"superset-frontend/src/assets/images/presto.png\" alt=\"presto\" border=\"0\" width=\"200\" height=\"80\"/>\n  <img src=\"superset-frontend/src/assets/images/databricks.png\" alt=\"databricks\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/druid.png\" alt=\"druid\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/firebolt.png\" alt=\"firebolt\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/timescale.png\" alt=\"timescale\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/rockset.png\" alt=\"rockset\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/postgresql.png\" alt=\"postgresql\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/mysql.png\" alt=\"mysql\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/mssql-server.png\" alt=\"mssql-server\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/db2.png\" alt=\"db2\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/sqlite.png\" alt=\"sqlite\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/sybase.png\" alt=\"sybase\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/mariadb.png\" alt=\"mariadb\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/vertica.png\" alt=\"vertica\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/oracle.png\" alt=\"oracle\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/firebird.png\" alt=\"firebird\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/greenplum.png\" alt=\"greenplum\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/clickhouse.png\" alt=\"clickhouse\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/exasol.png\" alt=\"exasol\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/monet-db.png\" alt=\"monet-db\" border=\"0\" width=\"200\" height=\"80\" />\n  <img src=\"superset-frontend/src/assets/images/apache-kylin.png\" alt=\"apache-kylin\" border=\"0\" width=\"200\" height=\"80\"/>\n  <img src=\"superset-frontend/src/assets/images/hologres.png\" alt=\"hologres\" border=\"0\" width=\"200\" height=\"80\"/>\n  <img src=\"superset-frontend/src/assets/images/netezza.png\" alt=\"netezza\" border=\"0\" width=\"200\" height=\"80\"/>\n  <img src=\"superset-frontend/src/assets/images/pinot.png\" alt=\"pinot\" border=\"0\" width=\"200\" height=\"80\"/>\n  <img src=\"superset-frontend/src/assets/images/teradata.png\" alt=\"teradata\" border=\"0\" width=\"200\" height=\"80\"/>\n  <img src=\"superset-frontend/src/assets/images/yugabyte.png\" alt=\"yugabyte\" border=\"0\" width=\"200\" height=\"80\"/>\n</p>\n\n**A more comprehensive list of supported databases** along with the configuration instructions can be found [here](https://superset.apache.org/docs/databases/installing-database-drivers).\n\nWant to add support for your datastore or data engine? Read more [here](https://superset.apache.org/docs/frequently-asked-questions#does-superset-work-with-insert-database-engine-here) about the technical requirements.\n\n## Installation and Configuration\n\n[Extended documentation for Superset](https://superset.apache.org/docs/installation/installing-superset-using-docker-compose)\n\n## Get Involved\n\n- Ask and answer questions on [StackOverflow](https://stackoverflow.com/questions/tagged/apache-superset) using the **apache-superset** tag\n- [Join our community's Slack](https://join.slack.com/t/apache-superset/shared_invite/zt-1jp6hjzrq-H0PlFtToyLWuPiJDuRWCNw)\n  and please read our [Slack Community Guidelines](https://github.com/apache/superset/blob/master/CODE_OF_CONDUCT.md#slack-community-guidelines)\n- [Join our dev@superset.apache.org Mailing list](https://lists.apache.org/list.html?dev@superset.apache.org)\n\n## Contributor Guide\n\nInterested in contributing? Check out our\n[CONTRIBUTING.md](https://github.com/apache/superset/blob/master/CONTRIBUTING.md)\nto find resources around contributing along with a detailed guide on\nhow to set up a development environment.\n\n## Resources\n\nSuperset 2.0!\n- [Superset 2.0 Meetup](https://preset.io/events/superset-2-0-meetup/)\n- [Superset 2.0 Release Notes](https://github.com/apache/superset/tree/master/RELEASING/release-notes-2-0)\n\nUnderstanding the Superset Points of View\n- [The Case for Dataset-Centric Visualization](https://preset.io/blog/dataset-centric-visualization/)\n- [Understanding the Superset Semantic Layer](https://preset.io/blog/understanding-superset-semantic-layer/)\n\n\n- Getting Started with Superset\n  - [Superset in 2 Minutes using Docker Compose](https://superset.apache.org/docs/installation/installing-superset-using-docker-compose#installing-superset-locally-using-docker-compose)\n  - [Installing Database Drivers](https://superset.apache.org/docs/databases/docker-add-drivers/)\n  - [Building New Database Connectors](https://preset.io/blog/building-database-connector/)\n  - [Create Your First Dashboard](https://superset.apache.org/docs/creating-charts-dashboards/first-dashboard)\n  - [Comprehensive Tutorial for Contributing Code to Apache Superset\n  ](https://preset.io/blog/tutorial-contributing-code-to-apache-superset/)\n- [Resources to master Superset by Preset](https://preset.io/resources/)\n\n- Deploying Superset\n  - [Official Docker image](https://hub.docker.com/r/apache/superset)\n  - [Helm Chart](https://github.com/apache/superset/tree/master/helm/superset)\n\n- Recordings of Past [Superset Community Events](https://preset.io/events)\n  - [Mixed Time Series Charts](https://preset.io/events/mixed-time-series-visualization-in-superset-workshop/)  \n  - [How the Bing Team Customized Superset for the Internal Self-Serve Data & Analytics Platform](https://preset.io/events/how-the-bing-team-heavily-customized-superset-for-their-internal-data/)\n  - [Live Demo: Visualizing MongoDB and Pinot Data using Trino](https://preset.io/events/2021-04-13-visualizing-mongodb-and-pinot-data-using-trino/)\n\t- [Introduction to the Superset API](https://preset.io/events/introduction-to-the-superset-api/)\n\t- [Building a Database Connector for Superset](https://preset.io/events/2021-02-16-building-a-database-connector-for-superset/)\n\n- Visualizations\n  - [Building Custom Viz Plugins](https://superset.apache.org/docs/installation/building-custom-viz-plugins)\n  - [Managing and Deploying Custom Viz Plugins](https://medium.com/nmc-techblog/apache-superset-manage-custom-viz-plugins-in-production-9fde1a708e55)\n  - [Why Apache Superset is Betting on Apache ECharts](https://preset.io/blog/2021-4-1-why-echarts/)\n\n- [Superset API](https://superset.apache.org/docs/rest-api)\n",
	"data-science education machine-learning machine-learning-algorithms machinelearning machinelearning-python ml python r scikit-learn scikit-learn-python": "[![GitHub license](https://img.shields.io/github/license/microsoft/ML-For-Beginners.svg)](https://github.com/microsoft/ML-For-Beginners/blob/master/LICENSE)\n[![GitHub contributors](https://img.shields.io/github/contributors/microsoft/ML-For-Beginners.svg)](https://GitHub.com/microsoft/ML-For-Beginners/graphs/contributors/)\n[![GitHub issues](https://img.shields.io/github/issues/microsoft/ML-For-Beginners.svg)](https://GitHub.com/microsoft/ML-For-Beginners/issues/)\n[![GitHub pull-requests](https://img.shields.io/github/issues-pr/microsoft/ML-For-Beginners.svg)](https://GitHub.com/microsoft/ML-For-Beginners/pulls/)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)\n\n[![GitHub watchers](https://img.shields.io/github/watchers/microsoft/ML-For-Beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/ML-For-Beginners/watchers/)\n[![GitHub forks](https://img.shields.io/github/forks/microsoft/ML-For-Beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/ML-For-Beginners/network/)\n[![GitHub stars](https://img.shields.io/github/stars/microsoft/ML-For-Beginners.svg?style=social&label=Star)](https://GitHub.com/microsoft/ML-For-Beginners/stargazers/)\n\n# Machine Learning for Beginners - A Curriculum\n\n> \ud83c\udf0d Travel around the world as we explore Machine Learning by means of world cultures \ud83c\udf0d\n\nAzure Cloud Advocates at Microsoft are pleased to offer a 12-week, 26-lesson curriculum all about **Machine Learning**. In this curriculum, you will learn about what is sometimes called **classic machine learning**, using primarily Scikit-learn as a library and avoiding deep learning, which is covered in our forthcoming 'AI for Beginners' curriculum. Pair these lessons with our ['Data Science for Beginners' curriculum](https://aka.ms/datascience-beginners), as well!\n\nTravel with us around the world as we apply these classic techniques to data from many areas of the world. Each lesson includes pre- and post-lesson quizzes, written instructions to complete the lesson, a solution, an assignment, and more. Our project-based pedagogy allows you to learn while building, a proven way for new skills to 'stick'.\n\n**\u270d\ufe0f Hearty thanks to our authors** Jen Looper, Stephen Howell, Francesca Lazzeri, Tomomi Imura, Cassie Breviu, Dmitry Soshnikov, Chris Noring, Anirban Mukherjee, Ornella Altunyan, and Amy Boyd\n\n**\ud83c\udfa8 Thanks as well to our illustrators** Tomomi Imura, Dasani Madipalli, and Jen Looper\n\n**\ud83d\ude4f Special thanks \ud83d\ude4f to our Microsoft Student Ambassador authors, reviewers, and content contributors**, notably Rishit Dagli, Muhammad Sakib Khan Inan, Rohan Raj, Alexandru Petrescu, Abhishek Jaiswal, Nawrin Tabassum, Ioan Samuila, and Snigdha Agarwal\n\n**\ud83e\udd29 Extra gratitude to Microsoft Student Ambassador Eric Wanjau for our R lessons!**\n\n---\n\n# Getting Started\n\n**[Students](https://aka.ms/student-page)**, to use this curriculum, fork the entire repo to your own GitHub account and complete the exercises on your own or with a group:\n\n- Start with a pre-lecture quiz.\n- Read the lecture and complete the activities, pausing and reflecting at each knowledge check.\n- Try to create the projects by comprehending the lessons rather than running the solution code; however that code is available in the `/solution` folders in each project-oriented lesson.\n- Take the post-lecture quiz.\n- Complete the challenge.\n- Complete the assignment.\n- After completing a lesson group, visit the [Discussion Board](https://github.com/microsoft/ML-For-Beginners/discussions) and \"learn out loud\" by filling out the appropriate PAT rubric. A 'PAT' is a Progress Assessment Tool that is a rubric you fill out to further your learning. You can also react to other PATs so we can learn together.\n\n> For further study, we recommend following these [Microsoft Learn](https://docs.microsoft.com/en-us/users/jenlooper-2911/collections/k7o7tg1gp306q4?WT.mc_id=academic-77952-leestott) modules and learning paths.\n\n**Teachers**, we have [included some suggestions](for-teachers.md) on how to use this curriculum.\n\n---\n\n## Meet the Team\n\n[![Promo video](ml.gif)](https://youtu.be/Tj1XWrDSYJU \"Promo video\")\n\n**Gif by** [Mohit Jaisal](https://linkedin.com/in/mohitjaisal)\n\n> \ud83c\udfa5 Click the image above for a video about the project and the folks who created it!\n\n---\n\n## Pedagogy\n\nWe have chosen two pedagogical tenets while building this curriculum: ensuring that it is hands-on **project-based** and that it includes **frequent quizzes**. In addition, this curriculum has a common **theme** to give it cohesion.\n\nBy ensuring that the content aligns with projects, the process is made more engaging for students and retention of concepts will be augmented. In addition, a low-stakes quiz before a class sets the intention of the student towards learning a topic, while a second quiz after class ensures further retention. This curriculum was designed to be flexible and fun and can be taken in whole or in part. The projects start small and become increasingly complex by the end of the 12-week cycle. This curriculum also includes a postscript on real-world applications of ML, which can be used as extra credit or as a basis for discussion.\n\n> Find our [Code of Conduct](CODE_OF_CONDUCT.md), [Contributing](CONTRIBUTING.md), and [Translation](TRANSLATIONS.md) guidelines. We welcome your constructive feedback!\n\n## Each lesson includes:\n\n- optional sketchnote\n- optional supplemental video\n- pre-lecture warmup quiz\n- written lesson\n- for project-based lessons, step-by-step guides on how to build the project\n- knowledge checks\n- a challenge\n- supplemental reading\n- assignment\n- post-lecture quiz\n\n> **A note about languages**: These lessons are primarily written in Python, but many are also available in R. To complete an R lesson, go to the `/solution` folder and look for R lessons. They include an .rmd extension that represents an **R Markdown** file which can be simply defined as an embedding of `code chunks` (of R or other languages) and a `YAML header` (that guides how to format outputs such as PDF) in a `Markdown document`. As such, it serves as an exemplary authoring framework for data science since it allows you to combine your code, its output, and your thoughts by allowing you to write them down in Markdown. Moreover, R Markdown documents can be rendered to output formats such as PDF, HTML, or Word.\n\n> **A note about quizzes**: All quizzes are contained [in this app](https://gray-sand-07a10f403.1.azurestaticapps.net/), for 52 total quizzes of three questions each. They are linked from within the lessons but the quiz app can be run locally; follow the instruction in the `quiz-app` folder.\n\n| Lesson Number |                             Topic                              |                   Lesson Grouping                   | Learning Objectives                                                                                                             |                                                              Linked Lesson                                                               |                        Author                        |\n| :-----------: | :------------------------------------------------------------: | :-------------------------------------------------: | ------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------: |\n|      01       |                Introduction to machine learning                |      [Introduction](1-Introduction/README.md)       | Learn the basic concepts behind machine learning                                                                                |                                             [Lesson](1-Introduction/1-intro-to-ML/README.md)                                             |                       Muhammad                       |\n|      02       |                The History of machine learning                 |      [Introduction](1-Introduction/README.md)       | Learn the history underlying this field                                                                                         |                                            [Lesson](1-Introduction/2-history-of-ML/README.md)                                            |                     Jen and Amy                      |\n|      03       |                 Fairness and machine learning                  |      [Introduction](1-Introduction/README.md)       | What are the important philosophical issues around fairness that students should consider when building and applying ML models? |                                              [Lesson](1-Introduction/3-fairness/README.md)                                               |                        Tomomi                        |\n|      04       |                Techniques for machine learning                 |      [Introduction](1-Introduction/README.md)       | What techniques do ML researchers use to build ML models?                                                                       |                                          [Lesson](1-Introduction/4-techniques-of-ML/README.md)                                           |                    Chris and Jen                     |\n|      05       |                   Introduction to regression                   |        [Regression](2-Regression/README.md)         | Get started with Python and Scikit-learn for regression models                                                                  |         <ul><li>[Python](2-Regression/1-Tools/README.md)</li><li>[R](2-Regression/1-Tools/solution/R/lesson_1-R.ipynb)</li></ul>         |      <ul><li>Jen</li><li>Eric Wanjau</li></ul>       |\n|      06       |                North American pumpkin prices \ud83c\udf83                |        [Regression](2-Regression/README.md)         | Visualize and clean data in preparation for ML                                                                                  |          <ul><li>[Python](2-Regression/2-Data/README.md)</li><li>[R](2-Regression/2-Data/solution/R/lesson_2-R.ipynb)</li></ul>          |      <ul><li>Jen</li><li>Eric Wanjau</li></ul>       |\n|      07       |                North American pumpkin prices \ud83c\udf83                |        [Regression](2-Regression/README.md)         | Build linear and polynomial regression models                                                                                   |        <ul><li>[Python](2-Regression/3-Linear/README.md)</li><li>[R](2-Regression/3-Linear/solution/R/lesson_3-R.ipynb)</li></ul>        |      <ul><li>Jen and Dmitry</li><li>Eric Wanjau</li></ul>       |\n|      08       |                North American pumpkin prices \ud83c\udf83                |        [Regression](2-Regression/README.md)         | Build a logistic regression model                                                                                               |     <ul><li>[Python](2-Regression/4-Logistic/README.md) </li><li>[R](2-Regression/4-Logistic/solution/R/lesson_4-R.ipynb)</li></ul>      |      <ul><li>Jen</li><li>Eric Wanjau</li></ul>       |\n|      09       |                          A Web App \ud83d\udd0c                          |           [Web App](3-Web-App/README.md)            | Build a web app to use your trained model                                                                                       |                                                 [Python](3-Web-App/1-Web-App/README.md)                                                  |                         Jen                          |\n|      10       |                 Introduction to classification                 |    [Classification](4-Classification/README.md)     | Clean, prep, and visualize your data; introduction to classification                                                            | <ul><li> [Python](4-Classification/1-Introduction/README.md) </li><li>[R](4-Classification/1-Introduction/solution/R/lesson_10-R.ipynb)  | <ul><li>Jen and Cassie</li><li>Eric Wanjau</li></ul> |\n|      11       |             Delicious Asian and Indian cuisines \ud83c\udf5c             |    [Classification](4-Classification/README.md)     | Introduction to classifiers                                                                                                     | <ul><li> [Python](4-Classification/2-Classifiers-1/README.md)</li><li>[R](4-Classification/2-Classifiers-1/solution/R/lesson_11-R.ipynb) | <ul><li>Jen and Cassie</li><li>Eric Wanjau</li></ul> |\n|      12       |             Delicious Asian and Indian cuisines \ud83c\udf5c             |    [Classification](4-Classification/README.md)     | More classifiers                                                                                                                | <ul><li> [Python](4-Classification/3-Classifiers-2/README.md)</li><li>[R](4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb) | <ul><li>Jen and Cassie</li><li>Eric Wanjau</li></ul> |\n|      13       |             Delicious Asian and Indian cuisines \ud83c\udf5c             |    [Classification](4-Classification/README.md)     | Build a recommender web app using your model                                                                                    |                                              [Python](4-Classification/4-Applied/README.md)                                              |                         Jen                          |\n|      14       |                   Introduction to clustering                   |        [Clustering](5-Clustering/README.md)         | Clean, prep, and visualize your data; Introduction to clustering                                                                |         <ul><li> [Python](5-Clustering/1-Visualize/README.md)</li><li>[R](5-Clustering/1-Visualize/solution/R/lesson_14-R.ipynb)         |      <ul><li>Jen</li><li>Eric Wanjau</li></ul>       |\n|      15       |              Exploring Nigerian Musical Tastes \ud83c\udfa7              |        [Clustering](5-Clustering/README.md)         | Explore the K-Means clustering method                                                                                           |           <ul><li> [Python](5-Clustering/2-K-Means/README.md)</li><li>[R](5-Clustering/2-K-Means/solution/R/lesson_15-R.ipynb)           |      <ul><li>Jen</li><li>Eric Wanjau</li></ul>       |\n|      16       |        Introduction to natural language processing \u2615\ufe0f         |   [Natural language processing](6-NLP/README.md)    | Learn the basics about NLP by building a simple bot                                                                             |                                             [Python](6-NLP/1-Introduction-to-NLP/README.md)                                              |                       Stephen                        |\n|      17       |                      Common NLP Tasks \u2615\ufe0f                      |   [Natural language processing](6-NLP/README.md)    | Deepen your NLP knowledge by understanding common tasks required when dealing with language structures                          |                                                    [Python](6-NLP/2-Tasks/README.md)                                                     |                       Stephen                        |\n|      18       |             Translation and sentiment analysis \u2665\ufe0f              |   [Natural language processing](6-NLP/README.md)    | Translation and sentiment analysis with Jane Austen                                                                             |                                            [Python](6-NLP/3-Translation-Sentiment/README.md)                                             |                       Stephen                        |\n|      19       |                  Romantic hotels of Europe \u2665\ufe0f                  |   [Natural language processing](6-NLP/README.md)    | Sentiment analysis with hotel reviews 1                                                                                         |                                               [Python](6-NLP/4-Hotel-Reviews-1/README.md)                                                |                       Stephen                        |\n|      20       |                  Romantic hotels of Europe \u2665\ufe0f                  |   [Natural language processing](6-NLP/README.md)    | Sentiment analysis with hotel reviews 2                                                                                         |                                               [Python](6-NLP/5-Hotel-Reviews-2/README.md)                                                |                       Stephen                        |\n|      21       |            Introduction to time series forecasting             |        [Time series](7-TimeSeries/README.md)        | Introduction to time series forecasting                                                                                         |                                             [Python](7-TimeSeries/1-Introduction/README.md)                                              |                      Francesca                       |\n|      22       | \u26a1\ufe0f World Power Usage \u26a1\ufe0f - time series forecasting with ARIMA |        [Time series](7-TimeSeries/README.md)        | Time series forecasting with ARIMA                                                                                              |                                                 [Python](7-TimeSeries/2-ARIMA/README.md)                                                 |                      Francesca                       |\n|      23       |  \u26a1\ufe0f World Power Usage \u26a1\ufe0f - time series forecasting with SVR  |        [Time series](7-TimeSeries/README.md)        | Time series forecasting with Support Vector Regressor                                                                           |                                                  [Python](7-TimeSeries/3-SVR/README.md)                                                  |                       Anirban                        |\n|      24       |             Introduction to reinforcement learning             | [Reinforcement learning](8-Reinforcement/README.md) | Introduction to reinforcement learning with Q-Learning                                                                          |                                             [Python](8-Reinforcement/1-QLearning/README.md)                                              |                        Dmitry                        |\n|      25       |                 Help Peter avoid the wolf! \ud83d\udc3a                  | [Reinforcement learning](8-Reinforcement/README.md) | Reinforcement learning Gym                                                                                                      |                                                [Python](8-Reinforcement/2-Gym/README.md)                                                 |                        Dmitry                        |\n|  Postscript   |            Real-World ML scenarios and applications            |      [ML in the Wild](9-Real-World/README.md)       | Interesting and revealing real-world applications of classical ML                                                               |                                             [Lesson](9-Real-World/1-Applications/README.md)                                              |                         Team                         |\n\n## Offline access\n\nYou can run this documentation offline by using [Docsify](https://docsify.js.org/#/). Fork this repo, [install Docsify](https://docsify.js.org/#/quickstart) on your local machine, and then in the root folder of this repo, type `docsify serve`. The website will be served on port 3000 on your localhost: `localhost:3000`.\n\n## PDFs\n\nFind a pdf of the curriculum with links [here](https://microsoft.github.io/ML-For-Beginners/pdf/readme.pdf).\n\n## Help Wanted!\n\nWould you like to contribute a translation? Please read our [translation guidelines](TRANSLATIONS.md) and add a templated issue to manage the workload [here](https://github.com/microsoft/ML-For-Beginners/issues).\n\n## Other Curricula\n\nOur team produces other curricula! Check out:\n\n- [Web Dev for Beginners](https://aka.ms/webdev-beginners)\n- [IoT for Beginners](https://aka.ms/iot-beginners)\n- [Data Science for Beginners](https://aka.ms/datascience-beginners)\n- [AI for Beginners](https://aka.ms/ai-beginners)\n",
	"alignment data-analysis data-science flexible pandas python": "<div align=\"center\">\n  <img src=\"https://pandas.pydata.org/static/img/pandas.svg\"><br>\n</div>\n\n-----------------\n\n# pandas: powerful Python data analysis toolkit\n[![PyPI Latest Release](https://img.shields.io/pypi/v/pandas.svg)](https://pypi.org/project/pandas/)\n[![Conda Latest Release](https://anaconda.org/conda-forge/pandas/badges/version.svg)](https://anaconda.org/anaconda/pandas/)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3509134.svg)](https://doi.org/10.5281/zenodo.3509134)\n[![Package Status](https://img.shields.io/pypi/status/pandas.svg)](https://pypi.org/project/pandas/)\n[![License](https://img.shields.io/pypi/l/pandas.svg)](https://github.com/pandas-dev/pandas/blob/main/LICENSE)\n[![Coverage](https://codecov.io/github/pandas-dev/pandas/coverage.svg?branch=main)](https://codecov.io/gh/pandas-dev/pandas)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/pandas-dev/pandas/badge)](https://api.securityscorecards.dev/projects/github.com/pandas-dev/pandas)\n[![Downloads](https://static.pepy.tech/personalized-badge/pandas?period=month&units=international_system&left_color=black&right_color=orange&left_text=PyPI%20downloads%20per%20month)](https://pepy.tech/project/pandas)\n[![Slack](https://img.shields.io/badge/join_Slack-information-brightgreen.svg?logo=slack)](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack)\n[![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](https://numfocus.org)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)\n\n## What is it?\n\n**pandas** is a Python package that provides fast, flexible, and expressive data\nstructures designed to make working with \"relational\" or \"labeled\" data both\neasy and intuitive. It aims to be the fundamental high-level building block for\ndoing practical, **real world** data analysis in Python. Additionally, it has\nthe broader goal of becoming **the most powerful and flexible open source data\nanalysis / manipulation tool available in any language**. It is already well on\nits way towards this goal.\n\n## Main Features\nHere are just a few of the things that pandas does well:\n\n  - Easy handling of [**missing data**][missing-data] (represented as\n    `NaN`, `NA`, or `NaT`) in floating point as well as non-floating point data\n  - Size mutability: columns can be [**inserted and\n    deleted**][insertion-deletion] from DataFrame and higher dimensional\n    objects\n  - Automatic and explicit [**data alignment**][alignment]: objects can\n    be explicitly aligned to a set of labels, or the user can simply\n    ignore the labels and let `Series`, `DataFrame`, etc. automatically\n    align the data for you in computations\n  - Powerful, flexible [**group by**][groupby] functionality to perform\n    split-apply-combine operations on data sets, for both aggregating\n    and transforming data\n  - Make it [**easy to convert**][conversion] ragged,\n    differently-indexed data in other Python and NumPy data structures\n    into DataFrame objects\n  - Intelligent label-based [**slicing**][slicing], [**fancy\n    indexing**][fancy-indexing], and [**subsetting**][subsetting] of\n    large data sets\n  - Intuitive [**merging**][merging] and [**joining**][joining] data\n    sets\n  - Flexible [**reshaping**][reshape] and [**pivoting**][pivot-table] of\n    data sets\n  - [**Hierarchical**][mi] labeling of axes (possible to have multiple\n    labels per tick)\n  - Robust IO tools for loading data from [**flat files**][flat-files]\n    (CSV and delimited), [**Excel files**][excel], [**databases**][db],\n    and saving/loading data from the ultrafast [**HDF5 format**][hdfstore]\n  - [**Time series**][timeseries]-specific functionality: date range\n    generation and frequency conversion, moving window statistics,\n    date shifting and lagging\n\n\n   [missing-data]: https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html\n   [insertion-deletion]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#column-selection-addition-deletion\n   [alignment]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html?highlight=alignment#intro-to-data-structures\n   [groupby]: https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#group-by-split-apply-combine\n   [conversion]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe\n   [slicing]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#slicing-ranges\n   [fancy-indexing]: https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#advanced\n   [subsetting]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing\n   [merging]: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging\n   [joining]: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#joining-on-index\n   [reshape]: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n   [pivot-table]: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n   [mi]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#hierarchical-indexing-multiindex\n   [flat-files]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#csv-text-files\n   [excel]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#excel-files\n   [db]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#sql-queries\n   [hdfstore]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#hdf5-pytables\n   [timeseries]: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-series-date-functionality\n\n## Where to get it\nThe source code is currently hosted on GitHub at:\nhttps://github.com/pandas-dev/pandas\n\nBinary installers for the latest released version are available at the [Python\nPackage Index (PyPI)](https://pypi.org/project/pandas) and on [Conda](https://docs.conda.io/en/latest/).\n\n```sh\n# conda\nconda install pandas\n```\n\n```sh\n# or PyPI\npip install pandas\n```\n\n## Dependencies\n- [NumPy - Adds support for large, multi-dimensional arrays, matrices and high-level mathematical functions to operate on these arrays](https://www.numpy.org)\n- [python-dateutil - Provides powerful extensions to the standard datetime module](https://dateutil.readthedocs.io/en/stable/index.html)\n- [pytz - Brings the Olson tz database into Python which allows accurate and cross platform timezone calculations](https://github.com/stub42/pytz)\n\nSee the [full installation instructions](https://pandas.pydata.org/pandas-docs/stable/install.html#dependencies) for minimum supported versions of required, recommended and optional dependencies.\n\n## Installation from sources\nTo install pandas from source you need [Cython](https://cython.org/) in addition to the normal\ndependencies above. Cython can be installed from PyPI:\n\n```sh\npip install cython\n```\n\nIn the `pandas` directory (same one where you found this file after\ncloning the git repo), execute:\n\n```sh\npython setup.py install\n```\n\nor for installing in [development mode](https://pip.pypa.io/en/latest/cli/pip_install/#install-editable):\n\n\n```sh\npython -m pip install -e . --no-build-isolation --no-use-pep517\n```\n\nor alternatively\n\n```sh\npython setup.py develop\n```\n\nSee the full instructions for [installing from source](https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html#installing-from-source).\n\n## License\n[BSD 3](LICENSE)\n\n## Documentation\nThe official documentation is hosted on PyData.org: https://pandas.pydata.org/pandas-docs/stable\n\n## Background\nWork on ``pandas`` started at [AQR](https://www.aqr.com/) (a quantitative hedge fund) in 2008 and\nhas been under active development since then.\n\n## Getting Help\n\nFor usage questions, the best place to go to is [StackOverflow](https://stackoverflow.com/questions/tagged/pandas).\nFurther, general questions and discussions can also take place on the [pydata mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata).\n\n## Discussion and Development\nMost development discussions take place on GitHub in this repo. Further, the [pandas-dev mailing list](https://mail.python.org/mailman/listinfo/pandas-dev) can also be used for specialized discussions or design issues, and a [Slack channel](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack) is available for quick development related questions.\n\n## Contributing to pandas [![Open Source Helpers](https://www.codetriage.com/pandas-dev/pandas/badges/users.svg)](https://www.codetriage.com/pandas-dev/pandas)\n\nAll contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome.\n\nA detailed overview on how to contribute can be found in the **[contributing guide](https://pandas.pydata.org/docs/dev/development/contributing.html)**.\n\nIf you are simply looking to start working with the pandas codebase, navigate to the [GitHub \"issues\" tab](https://github.com/pandas-dev/pandas/issues) and start looking through interesting issues. There are a number of issues listed under [Docs](https://github.com/pandas-dev/pandas/issues?labels=Docs&sort=updated&state=open) and [good first issue](https://github.com/pandas-dev/pandas/issues?labels=good+first+issue&sort=updated&state=open) where you could start out.\n\nYou can also triage issues which may include reproducing bug reports, or asking for vital information such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to [subscribe to pandas on CodeTriage](https://www.codetriage.com/pandas-dev/pandas).\n\nOr maybe through using pandas you have an idea of your own or are looking for something in the documentation and thinking \u2018this can be improved\u2019...you can do something about it!\n\nFeel free to ask questions on the [mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata) or on [Slack](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack).\n\nAs contributors and maintainers to this project, you are expected to abide by pandas' code of conduct. More information can be found at: [Contributor Code of Conduct](https://github.com/pandas-dev/.github/blob/master/CODE_OF_CONDUCT.md)\n",
	"data-engineering data-science deep-learning machine-learning mlops natural-language-processing python pytorch": "\n<div align=\"center\">\n<h1><img width=\"30\" src=\"https://madewithml.com/static/images/rounded_logo.png\">&nbsp;<a href=\"https://madewithml.com/\">Made With ML</a></h1>\nApplied ML \u00b7 MLOps \u00b7 Production\n<br>\nJoin 30K+ developers in learning how to responsibly <a href=\"https://madewithml.com/about/\">deliver value</a> with ML.\n    <br>\n</div>\n\n<br>\n\n<div align=\"center\">\n    <a target=\"_blank\" href=\"https://madewithml.com/\"><img src=\"https://img.shields.io/badge/Subscribe-30K-brightgreen\"></a>&nbsp;\n    <a target=\"_blank\" href=\"https://github.com/GokuMohandas/Made-With-ML\"><img src=\"https://img.shields.io/github/stars/GokuMohandas/Made-With-ML.svg?style=social&label=Star\"></a>&nbsp;\n    <a target=\"_blank\" href=\"https://www.linkedin.com/in/goku\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>&nbsp;\n    <a target=\"_blank\" href=\"https://twitter.com/GokuMohandas\"><img src=\"https://img.shields.io/twitter/follow/GokuMohandas.svg?label=Follow&style=social\"></a>\n    <br>\n    \ud83d\udd25&nbsp; Among the <a href=\"https://github.com/GokuMohandas/Made-With-ML\" target=\"_blank\">top MLOps</a> repositories on GitHub\n</div>\n\n<br>\n<hr>\n\n## Foundations\nLearn the foundations of machine learning through intuitive explanations, clean code and visualizations.\n\n- Lessons: https://madewithml.com/#foundations\n- Code: [GokuMohandas/Made-With-ML/tree/master/notebooks](https://github.com/GokuMohandas/Made-With-ML/tree/master/notebooks)\n\n<table class=\"table table-striped table-bordered table-vcenter\">\n    <tr>\n        <td align=\"center\"><b>\ud83d\udee0&nbsp; Toolkit</b></td>\n        <td align=\"center\"><b>\ud83d\udd25&nbsp; Machine Learning</b></td>\n        <td align=\"center\"><b>\ud83e\udd16&nbsp; Deep Learning</b></td>\n    </tr>\n    <tr>\n        <td><a href=\"https://madewithml.com/courses/foundations/notebooks/\">Notebooks</a></td>\n        <td><a href=\"https://madewithml.com/courses/foundations/linear-regression/\">Linear Regression</a></td>\n        <td><a href=\"https://madewithml.com/courses/foundations/convolutional-neural-networks/\">CNNs</a></td>\n    </tr>\n    <tr>\n        <td><a href=\"https://madewithml.com/courses/foundations/python/\">Python</a></td>\n        <td><a href=\"https://madewithml.com/courses/foundations/logistic-regression/\">Logistic Regression</a></td>\n        <td><a href=\"https://madewithml.com/courses/foundations/embeddings/\">Embeddings</a></td>\n    </tr>\n    <tr>\n        <td><a href=\"https://madewithml.com/courses/foundations/numpy/\">NumPy</a></td>\n        <td><a href=\"https://madewithml.com/courses/foundations/neural-networks/\">Neural Network</a></td>\n        <td><a href=\"https://madewithml.com/courses/foundations/recurrent-neural-networks/\">RNNs</a></td>\n    </tr>\n    <tr>\n        <td><a href=\"https://madewithml.com/courses/foundations/pandas/\">Pandas</a></td>\n        <td><a href=\"https://madewithml.com/courses/foundations/data-quality/\">Data Quality</a></td>\n        <td><a href=\"https://madewithml.com/courses/foundations/attention/\">Attention</a></td>\n    </tr>\n    <tr>\n        <td><a href=\"https://madewithml.com/courses/foundations/pytorch/\">PyTorch</a></td>\n        <td><a href=\"https://madewithml.com/courses/foundations/utilities/\">Utilities</a></td>\n        <td><a href=\"https://madewithml.com/courses/foundations/transformers/\">Transformers</a></td>\n    </tr>\n</table>\n\n<br>\n\n## MLOps course\nLearn how to combine machine learning with software engineering to build production-grade applications.\n\n- Lessons: https://madewithml.com/#mlops\n- Code: [GokuMohandas/mlops-course](https://github.com/GokuMohandas/mlops-course)\n\n<table>\n\t<tbody>\n\t\t<tr>\n\t\t\t<td><strong>\ud83c\udfa8&nbsp; Design</strong></td>\n\t\t\t<td><strong>\ud83d\udcbb&nbsp; Developing</strong>&nbsp;</td>\n\t\t\t<td><strong>\u267b\ufe0f&nbsp; Reproducibility</strong></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/design/\">Product</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/packaging/\">Packaging</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/git/\">Git</a></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/design/#engineering\">Engineering</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/organization/\">Organization</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/pre-commit/\">Pre-commit</a></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/design/#project-management\">Project</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/logging/\">Logging</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/versioning/\">Versioning</a></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><strong>\ud83d\udd22&nbsp; Data</strong></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/documentation/\">Documentation</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/docker/\">Docker</a></td>\n\t\t</tr>\n\t\t<tr style=\"height: 23.5px;\">\n\t\t\t<td style=\"height: 23.5px;\"><a href=\"https://madewithml.com/courses/mlops/exploratory-data-analysis/\">Exploration</a></td>\n\t\t\t<td style=\"height: 23.5px;\"><a href=\"https://madewithml.com/courses/mlops/styling/\">Styling</a></td>\n\t\t\t<td style=\"height: 23.5px;\"><strong>\ud83d\ude80&nbsp; Production</strong></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/labeling/\">Labeling</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/makefile/\">Makefile</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/dashboard/\">Dashboard</a></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/preprocessing/\">Preprocessing</a></td>\n\t\t\t<td><strong>\ud83d\udce6&nbsp; Serving</strong></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/cicd/\">CI/CD</a></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/splitting/\">Splitting</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/cli/\">Command-line</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/monitoring/\">Monitoring</a></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/augmentation/\">Augmentation</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/api/\">RESTful API</a></td>\n            <td><a href=\"https://madewithml.com/courses/mlops/systems-design/\">Systems design</a></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><strong>\ud83d\udcc8&nbsp; Modeling</strong></td>\n\t\t\t<td><strong>\u2705&nbsp; Testing</strong></td>\n            <td><strong>\u2388&nbsp; Data engineering</strong></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>&nbsp;<a href=\"https://madewithml.com/courses/mlops/baselines/\">Baselines</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/testing/\">Code</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/data-stack/\">Data stack</a></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/evaluation/\">Evaluation</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/testing/#data\">Data</a></td>\n            <td><a href=\"https://madewithml.com/courses/mlops/orchestration/\">Orchestration</a></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/experiment-tracking/\">Experiment tracking</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/testing/#models\">Models</a></td>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/feature-store/\">Feature store</a></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td><a href=\"https://madewithml.com/courses/mlops/optimization/\">Optimization</a></td>\n\t\t\t<td>&nbsp;</td>\n\t\t\t<td>&nbsp;</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n<br>\n\n### Mission\n\nML is **not a separate industry**, instead, it's a powerful **way of thinking** about data, so let's make sure we have a solid foundation before we start changing the world with it. Made With ML is our medium to catalyze this goal and though we're off to great start, we still have a long way to go.\n\n### Who is this content for?\n- `Software engineers` looking to learn ML and become even better software engineers.\n- `Data scientists` who want to learn how to responsibly deliver value with ML.\n- `College graduates` looking to learn the practical skills they'll need for the industry.\n- `Product Managers` who want to develop a technical foundation for ML applications.\n\n### What makes this content unique?\n- `hands-on`: If you search production ML or MLOps online, you'll find great blog posts and tweets. But in order to really understand these concepts, you need to implement them. Unfortunately, you don\u2019t see a lot of the inner workings of running production ML because of scale, proprietary content & expensive tools. However, Made With ML is free, open and live which makes it a perfect learning opportunity for the community.\n- `intuition-first`: We will never jump straight to code. In every lesson, we will develop intuition for the concepts and think about it from a product perspective.\n- `software engineering`: This course isn't just about ML. In fact, it's mostly about clean software engineering! We'll cover important concepts like versioning, testing, logging, etc. that really makes something production-grade product.\n- `focused yet holistic`: For every concept, we'll not only cover what's most important for our specific task (this is the case study aspect) but we'll also cover related methods (this is the guide aspect) which may prove to be useful in other situations.\n\n### Who is the author?\n- I've built and deployed large scale ML systems at Apple, as well as smaller systems with constraints at startups. I currently work closely with early-stage and F500 companies in helping them deliver value with ML while diving into the best and bespoke practices of this rapidly evolving space. I want to share this knowledge with the rest of the world so we can accelerate progress in this space.\n- Connect with me on <a href=\"https://twitter.com/GokuMohandas\" target=\"_blank\"><i class=\"fab fa-twitter ai-color-info mr-1\"></i>Twitter</a> and <a href=\"https://www.linkedin.com/in/goku\" target=\"_blank\"><i class=\"fab fa-linkedin ai-color-primary mr-1\"></i>LinkedIn</a>\n\n### Why is this free?\nWhile this content is for everyone, it's especially targeted towards people who don't have as much opportunity to learn. I believe that creativity and intelligence are randomly distributed while opportunities are siloed. I want to enable more people to create and contribute to innovation.\n\n<hr>\n<!-- Citation -->\nTo cite this content, please use:\n\n```bibtex\n@misc{madewithml,\n    author       = {Goku Mohandas},\n    title        = {Made With ML},\n    howpublished = {\\url{https://madewithml.com/}},\n    year         = {2022}\n}\n```\n",
	"ai artificial-intelligence cython data-science deep-learning entity-linking machine-learning named-entity-recognition natural-language-processing neural-network neural-networks nlp nlp-library python spacy text-classification tokenization": "<a href=\"https://explosion.ai\"><img src=\"https://explosion.ai/assets/img/logo.svg\" width=\"125\" height=\"125\" align=\"right\" /></a>\n\n# spaCy: Industrial-strength NLP\n\nspaCy is a library for **advanced Natural Language Processing** in Python and\nCython. It's built on the very latest research, and was designed from day one to\nbe used in real products.\n\nspaCy comes with\n[pretrained pipelines](https://spacy.io/models) and\ncurrently supports tokenization and training for **70+ languages**. It features\nstate-of-the-art speed and **neural network models** for tagging,\nparsing, **named entity recognition**, **text classification** and more,\nmulti-task learning with pretrained **transformers** like BERT, as well as a\nproduction-ready [**training system**](https://spacy.io/usage/training) and easy\nmodel packaging, deployment and workflow management. spaCy is commercial\nopen-source software, released under the MIT license.\n\n\ud83d\udcab **Version 3.4 out now!**\n[Check out the release notes here.](https://github.com/explosion/spaCy/releases)\n\n[![Azure Pipelines](https://img.shields.io/azure-devops/build/explosion-ai/public/8/master.svg?logo=azure-pipelines&style=flat-square&label=build)](https://dev.azure.com/explosion-ai/public/_build?definitionId=8)\n[![Current Release Version](https://img.shields.io/github/release/explosion/spacy.svg?style=flat-square&logo=github)](https://github.com/explosion/spaCy/releases)\n[![pypi Version](https://img.shields.io/pypi/v/spacy.svg?style=flat-square&logo=pypi&logoColor=white)](https://pypi.org/project/spacy/)\n[![conda Version](https://img.shields.io/conda/vn/conda-forge/spacy.svg?style=flat-square&logo=conda-forge&logoColor=white)](https://anaconda.org/conda-forge/spacy)\n[![Python wheels](https://img.shields.io/badge/wheels-%E2%9C%93-4c1.svg?longCache=true&style=flat-square&logo=python&logoColor=white)](https://github.com/explosion/wheelwright/releases)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/ambv/black)\n<br />\n[![PyPi downloads](https://static.pepy.tech/personalized-badge/spacy?period=total&units=international_system&left_color=grey&right_color=orange&left_text=pip%20downloads)](https://pypi.org/project/spacy/)\n[![Conda downloads](https://img.shields.io/conda/dn/conda-forge/spacy?label=conda%20downloads)](https://anaconda.org/conda-forge/spacy)\n[![spaCy on Twitter](https://img.shields.io/twitter/follow/spacy_io.svg?style=social&label=Follow)](https://twitter.com/spacy_io)\n\n## \ud83d\udcd6 Documentation\n\n| Documentation                                                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                              |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| \u2b50\ufe0f **[spaCy 101]**                                                                                                                                                                                                       | New to spaCy? Here's everything you need to know!                                                                                                                                                                                                                                                                            |\n| \ud83d\udcda **[Usage Guides]**                                                                                                                                                                                                     | How to use spaCy and its features.                                                                                                                                                                                                                                                                                           |\n| \ud83d\ude80 **[New in v3.0]**                                                                                                                                                                                                      | New features, backwards incompatibilities and migration guide.                                                                                                                                                                                                                                                               |\n| \ud83e\ude90 **[Project Templates]**                                                                                                                                                                                                | End-to-end workflows you can clone, modify and run.                                                                                                                                                                                                                                                                          |\n| \ud83c\udf9b **[API Reference]**                                                                                                                                                                                                     | The detailed reference for spaCy's API.                                                                                                                                                                                                                                                                                      |\n| \ud83d\udce6 **[Models]**                                                                                                                                                                                                           | Download trained pipelines for spaCy.                                                                                                                                                                                                                                                                                        |\n| \ud83c\udf0c **[Universe]**                                                                                                                                                                                                         | Plugins, extensions, demos and books from the spaCy ecosystem.                                                                                                                                                                                                                                                               |\n| \ud83d\udc69\u200d\ud83c\udfeb **[Online Course]**                                                                                                                                                                                                    | Learn spaCy in this free and interactive online course.                                                                                                                                                                                                                                                                      |\n| \ud83d\udcfa **[Videos]**                                                                                                                                                                                                           | Our YouTube channel with video tutorials, talks and more.                                                                                                                                                                                                                                                                    |\n| \ud83d\udee0 **[Changelog]**                                                                                                                                                                                                         | Changes and version history.                                                                                                                                                                                                                                                                                                 |\n| \ud83d\udc9d **[Contribute]**                                                                                                                                                                                                       | How to contribute to the spaCy project and code base.                                                                                                                                                                                                                                                                        |\n| <a href=\"https://explosion.ai/spacy-tailored-pipelines\"><img src=\"https://user-images.githubusercontent.com/13643239/152853098-1c761611-ccb0-4ec6-9066-b234552831fe.png\" width=\"125\" alt=\"spaCy Tailored Pipelines\"/></a> | Get a custom spaCy pipeline, tailor-made for your NLP problem by spaCy's core developers. Streamlined, production-ready, predictable and maintainable. Start by completing our 5-minute questionnaire to tell us what you need and we'll be in touch! **[Learn more &rarr;](https://explosion.ai/spacy-tailored-pipelines)** |\n\n[spacy 101]: https://spacy.io/usage/spacy-101\n[new in v3.0]: https://spacy.io/usage/v3\n[usage guides]: https://spacy.io/usage/\n[api reference]: https://spacy.io/api/\n[models]: https://spacy.io/models\n[universe]: https://spacy.io/universe\n[videos]: https://www.youtube.com/c/ExplosionAI\n[online course]: https://course.spacy.io\n[project templates]: https://github.com/explosion/projects\n[changelog]: https://spacy.io/usage#changelog\n[contribute]: https://github.com/explosion/spaCy/blob/master/CONTRIBUTING.md\n\n## \ud83d\udcac Where to ask questions\n\nThe spaCy project is maintained by the [spaCy team](https://explosion.ai/about).\nPlease understand that we won't be able to provide individual support via email.\nWe also believe that help is much more valuable if it's shared publicly, so that\nmore people can benefit from it.\n\n| Type                            | Platforms                               |\n| ------------------------------- | --------------------------------------- |\n| \ud83d\udea8 **Bug Reports**              | [GitHub Issue Tracker]                  |\n| \ud83c\udf81 **Feature Requests & Ideas** | [GitHub Discussions]                    |\n| \ud83d\udc69\u200d\ud83d\udcbb **Usage Questions**          | [GitHub Discussions] \u00b7 [Stack Overflow] |\n| \ud83d\uddef **General Discussion**        | [GitHub Discussions]                    |\n\n[github issue tracker]: https://github.com/explosion/spaCy/issues\n[github discussions]: https://github.com/explosion/spaCy/discussions\n[stack overflow]: https://stackoverflow.com/questions/tagged/spacy\n\n## Features\n\n- Support for **70+ languages**\n- **Trained pipelines** for different languages and tasks\n- Multi-task learning with pretrained **transformers** like BERT\n- Support for pretrained **word vectors** and embeddings\n- State-of-the-art speed\n- Production-ready **training system**\n- Linguistically-motivated **tokenization**\n- Components for named **entity recognition**, part-of-speech-tagging, dependency parsing, sentence segmentation, **text classification**, lemmatization, morphological analysis, entity linking and more\n- Easily extensible with **custom components** and attributes\n- Support for custom models in **PyTorch**, **TensorFlow** and other frameworks\n- Built in **visualizers** for syntax and NER\n- Easy **model packaging**, deployment and workflow management\n- Robust, rigorously evaluated accuracy\n\n\ud83d\udcd6 **For more details, see the\n[facts, figures and benchmarks](https://spacy.io/usage/facts-figures).**\n\n## \u23f3 Install spaCy\n\nFor detailed installation instructions, see the\n[documentation](https://spacy.io/usage).\n\n- **Operating system**: macOS / OS X \u00b7 Linux \u00b7 Windows (Cygwin, MinGW, Visual\n  Studio)\n- **Python version**: Python 3.6+ (only 64 bit)\n- **Package managers**: [pip] \u00b7 [conda] (via `conda-forge`)\n\n[pip]: https://pypi.org/project/spacy/\n[conda]: https://anaconda.org/conda-forge/spacy\n\n### pip\n\nUsing pip, spaCy releases are available as source packages and binary wheels.\nBefore you install spaCy and its dependencies, make sure that\nyour `pip`, `setuptools` and `wheel` are up to date.\n\n```bash\npip install -U pip setuptools wheel\npip install spacy\n```\n\nTo install additional data tables for lemmatization and normalization you can\nrun `pip install spacy[lookups]` or install\n[`spacy-lookups-data`](https://github.com/explosion/spacy-lookups-data)\nseparately. The lookups package is needed to create blank models with\nlemmatization data, and to lemmatize in languages that don't yet come with\npretrained models and aren't powered by third-party libraries.\n\nWhen using pip it is generally recommended to install packages in a virtual\nenvironment to avoid modifying system state:\n\n```bash\npython -m venv .env\nsource .env/bin/activate\npip install -U pip setuptools wheel\npip install spacy\n```\n\n### conda\n\nYou can also install spaCy from `conda` via the `conda-forge` channel. For the\nfeedstock including the build recipe and configuration, check out\n[this repository](https://github.com/conda-forge/spacy-feedstock).\n\n```bash\nconda install -c conda-forge spacy\n```\n\n### Updating spaCy\n\nSome updates to spaCy may require downloading new statistical models. If you're\nrunning spaCy v2.0 or higher, you can use the `validate` command to check if\nyour installed models are compatible and if not, print details on how to update\nthem:\n\n```bash\npip install -U spacy\npython -m spacy validate\n```\n\nIf you've trained your own models, keep in mind that your training and runtime\ninputs must match. After updating spaCy, we recommend **retraining your models**\nwith the new version.\n\n\ud83d\udcd6 **For details on upgrading from spaCy 2.x to spaCy 3.x, see the\n[migration guide](https://spacy.io/usage/v3#migrating).**\n\n## \ud83d\udce6 Download model packages\n\nTrained pipelines for spaCy can be installed as **Python packages**. This\nmeans that they're a component of your application, just like any other module.\nModels can be installed using spaCy's [`download`](https://spacy.io/api/cli#download)\ncommand, or manually by pointing pip to a path or URL.\n\n| Documentation              |                                                                  |\n| -------------------------- | ---------------------------------------------------------------- |\n| **[Available Pipelines]**  | Detailed pipeline descriptions, accuracy figures and benchmarks. |\n| **[Models Documentation]** | Detailed usage and installation instructions.                    |\n| **[Training]**             | How to train your own pipelines on your data.                    |\n\n[available pipelines]: https://spacy.io/models\n[models documentation]: https://spacy.io/usage/models\n[training]: https://spacy.io/usage/training\n\n```bash\n# Download best-matching version of specific model for your spaCy installation\npython -m spacy download en_core_web_sm\n\n# pip install .tar.gz archive or .whl from path or URL\npip install /Users/you/en_core_web_sm-3.0.0.tar.gz\npip install /Users/you/en_core_web_sm-3.0.0-py3-none-any.whl\npip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n```\n\n### Loading and using models\n\nTo load a model, use [`spacy.load()`](https://spacy.io/api/top-level#spacy.load)\nwith the model name or a path to the model data directory.\n\n```python\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"This is a sentence.\")\n```\n\nYou can also `import` a model directly via its full name and then call its\n`load()` method with no arguments.\n\n```python\nimport spacy\nimport en_core_web_sm\n\nnlp = en_core_web_sm.load()\ndoc = nlp(\"This is a sentence.\")\n```\n\n\ud83d\udcd6 **For more info and examples, check out the\n[models documentation](https://spacy.io/docs/usage/models).**\n\n## \u2692 Compile from source\n\nThe other way to install spaCy is to clone its\n[GitHub repository](https://github.com/explosion/spaCy) and build it from\nsource. That is the common way if you want to make changes to the code base.\nYou'll need to make sure that you have a development environment consisting of a\nPython distribution including header files, a compiler,\n[pip](https://pip.pypa.io/en/latest/installing/),\n[virtualenv](https://virtualenv.pypa.io/en/latest/) and\n[git](https://git-scm.com) installed. The compiler part is the trickiest. How to\ndo that depends on your system.\n\n| Platform    |                                                                                                                                                                                                                                                                     |\n| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Ubuntu**  | Install system-level dependencies via `apt-get`: `sudo apt-get install build-essential python-dev git` .                                                                                                                                                            |\n| **Mac**     | Install a recent version of [XCode](https://developer.apple.com/xcode/), including the so-called \"Command Line Tools\". macOS and OS X ship with Python and git preinstalled.                                                                                        |\n| **Windows** | Install a version of the [Visual C++ Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/) or [Visual Studio Express](https://visualstudio.microsoft.com/vs/express/) that matches the version that was used to compile your Python interpreter. |\n\nFor more details\nand instructions, see the documentation on\n[compiling spaCy from source](https://spacy.io/usage#source) and the\n[quickstart widget](https://spacy.io/usage#section-quickstart) to get the right\ncommands for your platform and Python version.\n\n```bash\ngit clone https://github.com/explosion/spaCy\ncd spaCy\n\npython -m venv .env\nsource .env/bin/activate\n\n# make sure you are using the latest pip\npython -m pip install -U pip setuptools wheel\n\npip install -r requirements.txt\npip install --no-build-isolation --editable .\n```\n\nTo install with extras:\n\n```bash\npip install --no-build-isolation --editable .[lookups,cuda102]\n```\n\n## \ud83d\udea6 Run tests\n\nspaCy comes with an [extensive test suite](spacy/tests). In order to run the\ntests, you'll usually want to clone the repository and build spaCy from source.\nThis will also install the required development dependencies and test utilities\ndefined in the [`requirements.txt`](requirements.txt).\n\nAlternatively, you can run `pytest` on the tests from within the installed\n`spacy` package. Don't forget to also install the test utilities via spaCy's\n[`requirements.txt`](requirements.txt):\n\n```bash\npip install -r requirements.txt\npython -m pytest --pyargs spacy\n```\n",
	"aws big-data caffe data-science deep-learning hadoop kaggle keras machine-learning mapreduce matplotlib numpy pandas python scikit-learn scipy spark tensorflow theano": "<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/README_1200x800.gif\">\n</p>\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/coversmall_alt.png\">\n  <br/>\n</p>\n\n# data-science-ipython-notebooks\n\n## Index\n\n* [deep-learning](#deep-learning)\n    * [tensorflow](#tensor-flow-tutorials)\n    * [theano](#theano-tutorials)\n    * [keras](#keras-tutorials)\n    * [caffe](#deep-learning-misc)\n* [scikit-learn](#scikit-learn)\n* [statistical-inference-scipy](#statistical-inference-scipy)\n* [pandas](#pandas)\n* [matplotlib](#matplotlib)\n* [numpy](#numpy)\n* [python-data](#python-data)\n* [kaggle-and-business-analyses](#kaggle-and-business-analyses)\n* [spark](#spark)\n* [mapreduce-python](#mapreduce-python)\n* [amazon web services](#aws)\n* [command lines](#commands)\n* [misc](#misc)\n* [notebook-installation](#notebook-installation)\n* [credits](#credits)\n* [contributing](#contributing)\n* [contact-info](#contact-info)\n* [license](#license)\n\n<br/>\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/ZhKXrKZ.png\">\n</p>\n\n## deep-learning\n\nIPython Notebook(s) demonstrating deep learning functionality.\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://avatars0.githubusercontent.com/u/15658638?v=3&s=100\">\n</p>\n\n### tensor-flow-tutorials\n\nAdditional TensorFlow tutorials:\n\n* [pkmital/tensorflow_tutorials](https://github.com/pkmital/tensorflow_tutorials)\n* [nlintz/TensorFlow-Tutorials](https://github.com/nlintz/TensorFlow-Tutorials)\n* [alrojo/tensorflow-tutorial](https://github.com/alrojo/tensorflow-tutorial)\n* [BinRoot/TensorFlow-Book](https://github.com/BinRoot/TensorFlow-Book)\n* [tuanavu/tensorflow-basic-tutorials](https://github.com/tuanavu/tensorflow-basic-tutorials)\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [tsf-basics](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/1_intro/basic_operations.ipynb) | Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google. |\n| [tsf-linear](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/linear_regression.ipynb) | Implement linear regression in TensorFlow. |\n| [tsf-logistic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/logistic_regression.ipynb) | Implement logistic regression in TensorFlow. |\n| [tsf-nn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/nearest_neighbor.ipynb) | Implement nearest neighboars in TensorFlow. |\n| [tsf-alex](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/alexnet.ipynb) | Implement AlexNet in TensorFlow. |\n| [tsf-cnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/convolutional_network.ipynb) | Implement convolutional neural networks in TensorFlow. |\n| [tsf-mlp](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/multilayer_perceptron.ipynb) | Implement multilayer perceptrons in TensorFlow. |\n| [tsf-rnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/recurrent_network.ipynb) | Implement recurrent neural networks in TensorFlow. |\n| [tsf-gpu](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/4_multi_gpu/multigpu_basics.ipynb) | Learn about basic multi-GPU computation in TensorFlow. |\n| [tsf-gviz](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/graph_visualization.ipynb) | Learn about graph visualization in TensorFlow. |\n| [tsf-lviz](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/loss_visualization.ipynb) | Learn about loss visualization in TensorFlow. |\n\n### tensor-flow-exercises\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [tsf-not-mnist](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/1_notmnist.ipynb) | Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow. |\n| [tsf-fully-connected](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/2_fullyconnected.ipynb) | Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow. |\n| [tsf-regularization](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/3_regularization.ipynb) | Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow. |\n| [tsf-convolutions](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/4_convolutions.ipynb) | Create convolutional neural networks in TensorFlow. |\n| [tsf-word2vec](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/5_word2vec.ipynb) | Train a skip-gram model over Text8 data in TensorFlow. |\n| [tsf-lstm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/6_lstm.ipynb) | Train a LSTM character model over Text8 data in TensorFlow. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"http://www.deeplearning.net/software/theano/_static/theano_logo_allblue_200x46.png\">\n</p>\n\n### theano-tutorials\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [theano-intro](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/intro_theano.ipynb) | Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation. |\n| [theano-scan](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/scan_tutorial/scan_tutorial.ipynb) | Learn scans, a mechanism to perform loops in a Theano graph. |\n| [theano-logistic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/logistic_regression.ipynb) | Implement logistic regression in Theano. |\n| [theano-rnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/rnn_tutorial/simple_rnn.ipynb) | Implement recurrent neural networks in Theano. |\n| [theano-mlp](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/theano_mlp/theano_mlp.ipynb) | Implement multilayer perceptrons in Theano. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/L45Q8c2.jpg\">\n</p>\n\n### keras-tutorials\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| keras | Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano. |\n| [setup](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/0.%20Preamble.ipynb) | Learn about the tutorial goals and how to set up your Keras environment. |\n| [intro-deep-learning-ann](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.1%20Introduction%20-%20Deep%20Learning%20and%20ANN.ipynb) | Get an intro to deep learning with Keras and Artificial Neural Networks (ANN). |\n| [theano](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.2%20Introduction%20-%20Theano.ipynb) | Learn about Theano by working with weights matrices and gradients. |\n| [keras-otto](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.3%20Introduction%20-%20Keras.ipynb) | Learn about Keras by looking at the Kaggle Otto challenge. |\n| [ann-mnist](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.4%20%28Extra%29%20A%20Simple%20Implementation%20of%20ANN%20for%20MNIST.ipynb) | Review a simple implementation of ANN for MNIST using Keras. |\n| [conv-nets](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.1%20Supervised%20Learning%20-%20ConvNets.ipynb) | Learn about Convolutional Neural Networks (CNNs) with Keras. |\n| [conv-net-1](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.1%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20I.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 1. |\n| [conv-net-2](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.2%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20II.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 2. |\n| [keras-models](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.3%20Supervised%20Learning%20-%20Famous%20Models%20with%20Keras.ipynb) | Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras. |\n| [auto-encoders](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.1%20Unsupervised%20Learning%20-%20AutoEncoders%20and%20Embeddings.ipynb) | Learn about Autoencoders with Keras. |\n| [rnn-lstm](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.2%20RNN%20and%20LSTM.ipynb) | Learn about Recurrent Neural Networks (RNNs) with Keras. |\n| [lstm-sentence-gen](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.3%20%28Extra%29%20LSTM%20for%20Sentence%20Generation.ipynb) |  Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras. |\n\n### deep-learning-misc\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [deep-dream](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/deep-dream/dream.ipynb) | Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png\">\n</p>\n\n## scikit-learn\n\nIPython Notebook(s) demonstrating scikit-learn functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [intro](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb) | Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| [knn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb#K-Nearest-Neighbors-Classifier) | Implement k-nearest neighbors in scikit-learn. |\n| [linear-reg](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb) | Implement linear regression in scikit-learn. |\n| [svm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-svm.ipynb) | Implement support vector machine classifiers with and without kernels in scikit-learn. |\n| [random-forest](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-random-forest.ipynb) | Implement random forest classifiers and regressors in scikit-learn. |\n| [k-means](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-k-means.ipynb) | Implement k-means clustering in scikit-learn. |\n| [pca](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-pca.ipynb) | Implement principal component analysis in scikit-learn. |\n| [gmm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-gmm.ipynb) | Implement Gaussian mixture models in scikit-learn. |\n| [validation](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-validation.ipynb) | Implement validation and model selection in scikit-learn. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png\">\n</p>\n\n## statistical-inference-scipy\n\nIPython Notebook(s) demonstrating statistical inference with SciPy functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| scipy | SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. |\n| [effect-size](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/effect_size.ipynb) | Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States. |\n| [sampling](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/sampling.ipynb) | Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data. |\n| [hypothesis](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/hypothesis.ipynb) | Explore hypothesis testing by analyzing the difference of first-born babies compared with others. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png\">\n</p>\n\n## pandas\n\nIPython Notebook(s) demonstrating pandas functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [pandas](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/pandas.ipynb) | Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series. |\n| [github-data-wrangling](https://github.com/donnemartin/viz/blob/master/githubstats/data_wrangling.ipynb) | Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the [`Viz`](https://github.com/donnemartin/viz) repo. |\n| [Introduction-to-Pandas](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.00-Introduction-to-Pandas.ipynb) | Introduction to Pandas. |\n| [Introducing-Pandas-Objects](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.01-Introducing-Pandas-Objects.ipynb) | Learn about Pandas objects. |\n| [Data Indexing and Selection](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.02-Data-Indexing-and-Selection.ipynb) | Learn about data indexing and selection in Pandas. |\n| [Operations-in-Pandas](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.03-Operations-in-Pandas.ipynb) | Learn about operating on data in Pandas. |\n| [Missing-Values](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.04-Missing-Values.ipynb) | Learn about handling missing data in Pandas. |\n| [Hierarchical-Indexing](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.05-Hierarchical-Indexing.ipynb) | Learn about hierarchical indexing in Pandas. |\n| [Concat-And-Append](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.06-Concat-And-Append.ipynb) | Learn about combining datasets: concat and append in Pandas. |\n| [Merge-and-Join](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.07-Merge-and-Join.ipynb) | Learn about combining datasets: merge and join in Pandas. |\n| [Aggregation-and-Grouping](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.08-Aggregation-and-Grouping.ipynb) | Learn about aggregation and grouping in Pandas. |\n| [Pivot-Tables](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.09-Pivot-Tables.ipynb) | Learn about pivot tables in Pandas. |\n| [Working-With-Strings](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.10-Working-With-Strings.ipynb) | Learn about vectorized string operations in Pandas. |\n| [Working-with-Time-Series](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.11-Working-with-Time-Series.ipynb) | Learn about working with time series in pandas. |\n| [Performance-Eval-and-Query](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.12-Performance-Eval-and-Query.ipynb) | Learn about high-performance Pandas: eval() and query() in Pandas. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png\">\n</p>\n\n## matplotlib\n\nIPython Notebook(s) demonstrating matplotlib functionality.\n\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [matplotlib](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib.ipynb) | Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. |\n| [matplotlib-applied](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib-applied.ipynb) | Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots. |\n| [Introduction-To-Matplotlib](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.00-Introduction-To-Matplotlib.ipynb) | Introduction to Matplotlib. |\n| [Simple-Line-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.01-Simple-Line-Plots.ipynb) | Learn about simple line plots in Matplotlib. |\n| [Simple-Scatter-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.02-Simple-Scatter-Plots.ipynb) | Learn about simple scatter plots in Matplotlib. |\n| [Errorbars.ipynb](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.03-Errorbars.ipynb) | Learn about visualizing errors in Matplotlib. |\n| [Density-and-Contour-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.04-Density-and-Contour-Plots.ipynb) | Learn about density and contour plots in Matplotlib. |\n| [Histograms-and-Binnings](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.05-Histograms-and-Binnings.ipynb) | Learn about histograms, binnings, and density in Matplotlib. |\n| [Customizing-Legends](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.06-Customizing-Legends.ipynb) | Learn about customizing plot legends in Matplotlib. |\n| [Customizing-Colorbars](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.07-Customizing-Colorbars.ipynb) | Learn about customizing colorbars in Matplotlib. |\n| [Multiple-Subplots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.08-Multiple-Subplots.ipynb) | Learn about multiple subplots in Matplotlib. |\n| [Text-and-Annotation](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.09-Text-and-Annotation.ipynb) | Learn about text and annotation in Matplotlib. |\n| [Customizing-Ticks](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.10-Customizing-Ticks.ipynb) | Learn about customizing ticks in Matplotlib. |\n| [Settings-and-Stylesheets](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.11-Settings-and-Stylesheets.ipynb) | Learn about customizing Matplotlib: configurations and stylesheets. |\n| [Three-Dimensional-Plotting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.12-Three-Dimensional-Plotting.ipynb) | Learn about three-dimensional plotting in Matplotlib. |\n| [Geographic-Data-With-Basemap](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.13-Geographic-Data-With-Basemap.ipynb) | Learn about geographic data with basemap in Matplotlib. |\n| [Visualization-With-Seaborn](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.14-Visualization-With-Seaborn.ipynb) | Learn about visualization with Seaborn. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png\">\n</p>\n\n## numpy\n\nIPython Notebook(s) demonstrating NumPy functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [numpy](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/numpy.ipynb) | Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| [Introduction-to-NumPy](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.00-Introduction-to-NumPy.ipynb) | Introduction to NumPy. |\n| [Understanding-Data-Types](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.01-Understanding-Data-Types.ipynb) | Learn about data types in Python. |\n| [The-Basics-Of-NumPy-Arrays](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.02-The-Basics-Of-NumPy-Arrays.ipynb) | Learn about the basics of NumPy arrays. |\n| [Computation-on-arrays-ufuncs](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.03-Computation-on-arrays-ufuncs.ipynb) | Learn about computations on NumPy arrays: universal functions. |\n| [Computation-on-arrays-aggregates](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.04-Computation-on-arrays-aggregates.ipynb) | Learn about aggregations: min, max, and everything in between in NumPy. |\n| [Computation-on-arrays-broadcasting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.05-Computation-on-arrays-broadcasting.ipynb) | Learn about computation on arrays: broadcasting in NumPy. |\n| [Boolean-Arrays-and-Masks](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.06-Boolean-Arrays-and-Masks.ipynb) | Learn about comparisons, masks, and boolean logic in NumPy. |\n| [Fancy-Indexing](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.07-Fancy-Indexing.ipynb) | Learn about fancy indexing in NumPy. |\n| [Sorting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.08-Sorting.ipynb) | Learn about sorting arrays in NumPy. |\n| [Structured-Data-NumPy](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.09-Structured-Data-NumPy.ipynb) | Learn about structured data: NumPy's structured arrays. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png\">\n</p>\n\n## python-data\n\nIPython Notebook(s) demonstrating Python functionality geared towards data analysis.\n\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n| [data structures](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs.ipynb) | Learn Python basics with tuples, lists, dicts, sets. |\n| [data structure utilities](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs_utils.ipynb) | Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions. |\n| [functions](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/functions.ipynb) | Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools. |\n| [datetime](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/datetime.ipynb) | Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta. |\n| [logging](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/logs.ipynb) | Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler. |\n| [pdb](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/pdb.ipynb) | Learn how to debug in Python with the interactive source code debugger. |\n| [unit tests](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/unit_tests.ipynb) | Learn how to test in Python with Nose unit tests. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png\">\n</p>\n\n## kaggle-and-business-analyses\n\nIPython Notebook(s) used in [kaggle](https://www.kaggle.com/) competitions and business analyses.\n\n| Notebook | Description |\n|-------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|\n| [titanic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb) | Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning. |\n| [churn-analysis](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/analyses/churn.ipynb) | Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.|\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png\">\n</p>\n\n## spark\n\nIPython Notebook(s) demonstrating spark and HDFS functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| [spark](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/spark.ipynb) | In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms. |\n| [hdfs](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/hdfs.ipynb) | Reliably stores very large files across machines in a large cluster. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png\">\n</p>\n\n## mapreduce-python\n\nIPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| [mapreduce-python](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/mapreduce/mapreduce-python.ipynb) | Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and [mrjob](https://github.com/Yelp/mrjob) config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  [Disco](https://github.com/discoproject/disco/) is another python-based alternative.|\n\n<br/>\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png\">\n</p>\n\n## aws\n\nIPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.\n\n\nAlso check out:\n\n* [SAWS](https://github.com/donnemartin/saws): A Supercharged AWS command line interface (CLI).\n* [Awesome AWS](https://github.com/donnemartin/awesome-aws): A curated list of libraries, open source repos, guides, blogs, and other resources.\n\n| Notebook | Description |\n|------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [boto](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#Boto) | Official AWS SDK for Python. |\n| [s3cmd](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3cmd) | Interacts with S3 through the command line. |\n| [s3distcp](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3distcp) | Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster. |\n| [s3-parallel-put](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3-parallel-put) | Uploads multiple files to S3 in parallel. |\n| [redshift](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#redshift) | Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP). |\n| [kinesis](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#kinesis) | Streams data in real time with the ability to process thousands of data streams per second. |\n| [lambda](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#lambda) | Runs code in response to events, automatically managing compute resources. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png\">\n</p>\n\n## commands\n\nIPython Notebook(s) demonstrating various command lines for Linux, Git, etc.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [linux](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/linux.ipynb) | Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.|\n| [anaconda](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#anaconda) | Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment. |\n| [ipython notebook](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#ipython-notebook) | Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document. |\n| [git](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#git) | Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows. |\n| [ruby](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#ruby) | Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages. |\n| [jekyll](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#jekyll) | Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server. |\n| [pelican](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#pelican) | Python-based alternative to Jekyll. |\n| [django](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#django) | High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include [Pyramid](https://github.com/Pylons/pyramid), [Flask](https://github.com/pallets/flask), [Tornado](https://github.com/tornadoweb/tornado), and [Bottle](https://github.com/bottlepy/bottle).\n\n## misc\n\nIPython Notebook(s) demonstrating miscellaneous functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [regex](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/misc/regex.ipynb) | Regular expression cheat sheet useful in data wrangling.|\n[algorithmia](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/misc/Algorithmia.ipynb) | Algorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.|\n\n## notebook-installation\n\n### anaconda\n\nAnaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.\n\nFollow instructions to install [Anaconda](https://docs.continuum.io/anaconda/install) or the more lightweight [miniconda](http://conda.pydata.org/miniconda.html).\n\n### dev-setup\n\nFor detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the [dev-setup](https://github.com/donnemartin/dev-setup) repo.\n\n### running-notebooks\n\nTo view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found [here.](http://ipython.org/notebook.html)\n\n    $ git clone https://github.com/donnemartin/data-science-ipython-notebooks.git\n    $ cd data-science-ipython-notebooks\n    $ jupyter notebook\n\nNotebooks tested with Python 2.7.x.\n\n## credits\n\n* [Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793) by Wes McKinney\n* [PyCon 2015 Scikit-learn Tutorial](https://github.com/jakevdp/sklearn_pycon2015) by Jake VanderPlas\n* [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook) by Jake VanderPlas\n* [Parallel Machine Learning with scikit-learn and IPython](https://github.com/ogrisel/parallel_ml_tutorial) by Olivier Grisel\n* [Statistical Interference Using Computational Methods in Python](https://github.com/AllenDowney/CompStats) by Allen Downey\n* [TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples) by Aymeric Damien\n* [TensorFlow Tutorials](https://github.com/pkmital/tensorflow_tutorials) by Parag K Mital\n* [TensorFlow Tutorials](https://github.com/nlintz/TensorFlow-Tutorials) by Nathan Lintz\n* [TensorFlow Tutorials](https://github.com/alrojo/tensorflow-tutorial) by Alexander R Johansen\n* [TensorFlow Book](https://github.com/BinRoot/TensorFlow-Book) by Nishant Shukla\n* [Summer School 2015](https://github.com/mila-udem/summerschool2015) by mila-udem\n* [Keras tutorials](https://github.com/leriomaggio/deep-learning-keras-tensorflow) by Valerio Maggio\n* [Kaggle](https://www.kaggle.com/)\n* [Yhat Blog](http://blog.yhat.com/)\n\n## contributing\n\nContributions are welcome!  For bug reports or requests please [submit an issue](https://github.com/donnemartin/data-science-ipython-notebooks/issues).\n\n## contact-info\n\nFeel free to contact me to discuss any issues, questions, or comments.\n\n* Email: [donne.martin@gmail.com](mailto:donne.martin@gmail.com)\n* Twitter: [@donne_martin](https://twitter.com/donne_martin)\n* GitHub: [donnemartin](https://github.com/donnemartin)\n* LinkedIn: [donnemartin](https://www.linkedin.com/in/donnemartin)\n* Website: [donnemartin.com](http://donnemartin.com)\n\n## license\n\nThis repository contains a variety of content; some developed by Donne Martin, and some from third-parties.  The third-party content is distributed under the license provided by those parties.\n\nThe content developed by Donne Martin is distributed under the following license:\n\n*I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).*\n\n    Copyright 2015 Donne Martin\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n",
	"applied-data-science applied-machine-learning computer-vision data-discovery data-engineering data-quality data-science deep-learning machine-learning natural-language-processing production recsys reinforcement-learning search": "# applied-ml\nCurated papers, articles, and blogs on **data science & machine learning in production**. \u2699\ufe0f\n\n[![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](./CONTRIBUTING.md) [![Summaries](https://img.shields.io/badge/summaries-in%20tweets-%2300acee.svg?style=flat)](https://twitter.com/eugeneyan/status/1350509546133811200) ![HitCount](http://hits.dwyl.com/eugeneyan/applied-ml.svg)\n\nFiguring out how to implement your ML project? Learn how other organizations did it:\n\n- **How** the problem is framed \ud83d\udd0e(e.g., personalization as recsys vs. search vs. sequences)\n- **What** machine learning techniques worked \u2705 (and sometimes, what didn't \u274c)\n- **Why** it works, the science behind it with research, literature, and references \ud83d\udcc2\n- **What** real-world results were achieved (so you can better assess ROI \u23f0\ud83d\udcb0\ud83d\udcc8)\n\nP.S., Want a summary of ML advancements? \ud83d\udc49[`ml-surveys`](https://github.com/eugeneyan/ml-surveys)\n\nP.P.S, Looking for guides and interviews on applying ML? \ud83d\udc49[`applyingML`](https://applyingml.com)\n\n**Table of Contents**\n\n1. [Data Quality](#data-quality)\n2. [Data Engineering](#data-engineering)\n3. [Data Discovery](#data-discovery)\n4. [Feature Stores](#feature-stores)\n5. [Classification](#classification)\n6. [Regression](#regression)\n7. [Forecasting](#forecasting)\n8. [Recommendation](#recommendation)\n9. [Search & Ranking](#search--ranking)\n10. [Embeddings](#embeddings)\n11. [Natural Language Processing](#natural-language-processing)\n12. [Sequence Modelling](#sequence-modelling)\n13. [Computer Vision](#computer-vision)\n14. [Reinforcement Learning](#reinforcement-learning)\n15. [Anomaly Detection](#anomaly-detection)\n16. [Graph](#graph)\n17. [Optimization](#optimization)\n18. [Information Extraction](#information-extraction)\n19. [Weak Supervision](#weak-supervision)\n20. [Generation](#generation)\n21. [Audio](#audio)\n22. [Validation and A/B Testing](#validation-and-ab-testing)\n23. [Model Management](#model-management)\n24. [Efficiency](#efficiency)\n25. [Ethics](#ethics)\n26. [Infra](#infra)\n27. [MLOps Platforms](#mlops-platforms)\n28. [Practices](#practices)\n29. [Team Structure](#team-structure)\n30. [Fails](#fails)\n\n## Data Quality\n1. [Reliable and Scalable Data Ingestion at Airbnb](https://www.slideshare.net/HadoopSummit/reliable-and-scalable-data-ingestion-at-airbnb-63920989) `Airbnb` `2016`\n2. [Monitoring Data Quality at Scale with Statistical Modeling](https://eng.uber.com/monitoring-data-quality-at-scale/) `Uber` `2017`\n3. [Data Management Challenges in Production Machine Learning](https://research.google/pubs/pub46178/) ([Paper](https://thodrek.github.io/CS839_spring18/papers/p1723-polyzotis.pdf)) `Google` `2017`\n4. [Automating Large-Scale Data Quality Verification](https://www.amazon.science/publications/automating-large-scale-data-quality-verification) ([Paper](https://assets.amazon.science/a6/88/ad858ee240c38c6e9dce128250c0/automating-large-scale-data-quality-verification.pdf))`Amazon` `2018`\n5. [Meet Hodor \u2014 Gojek\u2019s Upstream Data Quality Tool](https://www.gojek.io/blog/meet-hodor-gojeks-upstream-data-quality-tool) `Gojek` `2019`\n6. [An Approach to Data Quality for Netflix Personalization Systems](https://www.youtube.com/watch?v=t7vHpA39TXM) `Netflix` `2020`\n7. [Improving Accuracy By Certainty Estimation of Human Decisions, Labels, and Raters](https://research.fb.com/blog/2020/08/improving-the-accuracy-of-community-standards-enforcement-by-certainty-estimation-of-human-decisions/) ([Paper](https://research.fb.com/wp-content/uploads/2020/08/CLARA-Confidence-of-Labels-and-Raters.pdf)) `Facebook` `2020`\n\n## Data Engineering\n1. [Zipline: Airbnb\u2019s Machine Learning Data Management Platform](https://databricks.com/session/zipline-airbnbs-machine-learning-data-management-platform) `Airbnb` `2018`\n2. [Sputnik: Airbnb\u2019s Apache Spark Framework for Data Engineering](https://databricks.com/session_na20/sputnik-airbnbs-apache-spark-framework-for-data-engineering) `Airbnb` `2020`\n3. [Unbundling Data Science Workflows with Metaflow and AWS Step Functions](https://netflixtechblog.com/unbundling-data-science-workflows-with-metaflow-and-aws-step-functions-d454780c6280) `Netflix` `2020`\n4. [How DoorDash is Scaling its Data Platform to Delight Customers and Meet Growing Demand](https://doordash.engineering/2020/09/25/how-doordash-is-scaling-its-data-platform/) `DoorDash` `2020`\n5. [Revolutionizing Money Movements at Scale with Strong Data Consistency](https://eng.uber.com/money-scale-strong-data/) `Uber` `2020`\n6. [Zipline - A Declarative Feature Engineering Framework](https://www.youtube.com/watch?v=LjcKCm0G_OY) `Airbnb` `2020`\n7. [Automating Data Protection at Scale, Part 1](https://medium.com/airbnb-engineering/automating-data-protection-at-scale-part-1-c74909328e08) ([Part 2](https://medium.com/airbnb-engineering/automating-data-protection-at-scale-part-2-c2b8d2068216)) `Airbnb` `2021`\n8. [Real-time Data Infrastructure at Uber](https://arxiv.org/pdf/2104.00087.pdf) `Uber` `2021`\n9. [Introducing Fabricator: A Declarative Feature Engineering Framework](https://doordash.engineering/2022/01/11/introducing-fabricator-a-declarative-feature-engineering-framework/) `DoorDash` `2022`\n10. [Functions & DAGs: introducing Hamilton, a microframework for dataframe generation](https://multithreaded.stitchfix.com/blog/2021/10/14/functions-dags-hamilton/) `Stitch Fix` `2021`\n11. [Optimizing Pinterest\u2019s Data Ingestion Stack: Findings and Learnings](https://medium.com/@Pinterest_Engineering/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-994fddb063bf) `Pinterest` `2022`\n12. [Lessons Learned From Running Apache Airflow at Scale](https://shopifyengineering.myshopify.com/blogs/engineering/lessons-learned-apache-airflow-scale) `Shopify` `2022`\n13. [Understanding Data Storage and Ingestion for Large-Scale Deep Recommendation Model Training](https://arxiv.org/abs/2108.09373v4) `Meta` `2022`\n\n## Data Discovery\n1. [Apache Atlas: Data Goverance and Metadata Framework for Hadoop](https://atlas.apache.org/#/) ([Code](https://github.com/apache/atlas)) `Apache`\n2. [Collect, Aggregate, and Visualize a Data Ecosystem's Metadata](https://marquezproject.github.io/marquez/) ([Code](https://github.com/MarquezProject/marquez)) `WeWork`\n3. [Discovery and Consumption of Analytics Data at Twitter](https://blog.twitter.com/engineering/en_us/topics/insights/2016/discovery-and-consumption-of-analytics-data-at-twitter.html) `Twitter` `2016`\n4. [Democratizing Data at Airbnb](https://medium.com/airbnb-engineering/democratizing-data-at-airbnb-852d76c51770) `Airbnb` `2017`\n5. [Databook: Turning Big Data into Knowledge with Metadata at Uber](https://eng.uber.com/databook/) `Uber` `2018`\n6. [Metacat: Making Big Data Discoverable and Meaningful at Netflix](https://netflixtechblog.com/metacat-making-big-data-discoverable-and-meaningful-at-netflix-56fb36a53520) ([Code](https://github.com/Netflix/metacat)) `Netflix` `2018`\n7. [Amundsen \u2014 Lyft\u2019s Data Discovery & Metadata Engine](https://eng.lyft.com/amundsen-lyfts-data-discovery-metadata-engine-62d27254fbb9) `Lyft` `2019`\n8. [Open Sourcing Amundsen: A Data Discovery And Metadata Platform](https://eng.lyft.com/open-sourcing-amundsen-a-data-discovery-and-metadata-platform-2282bb436234) ([Code](https://github.com/lyft/amundsen)) `Lyft` `2019`\n9. [DataHub: A Generalized Metadata Search & Discovery Tool](https://engineering.linkedin.com/blog/2019/data-hub) ([Code](https://github.com/linkedin/datahub)) `LinkedIn` `2019`\n10. [Amundsen: One Year Later](https://eng.lyft.com/amundsen-1-year-later-7b60bf28602) `Lyft` `2020`\n11. [Using Amundsen to Support User Privacy via Metadata Collection at Square](https://developer.squareup.com/blog/using-amundsen-to-support-user-privacy-via-metadata-collection-at-square/) `Square` `2020`\n12. [Turning Metadata Into Insights with Databook](https://eng.uber.com/metadata-insights-databook/) `Uber` `2020`\n13. [DataHub: Popular Metadata Architectures Explained](https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained) `LinkedIn` `2020`\n14. [How We Improved Data Discovery for Data Scientists at Spotify](https://engineering.atspotify.com/2020/02/27/how-we-improved-data-discovery-for-data-scientists-at-spotify/) `Spotify` `2020` \n15. [How We\u2019re Solving Data Discovery Challenges at Shopify](https://engineering.shopify.com/blogs/engineering/solving-data-discovery-challenges-shopify) `Shopify` `2020`\n16. [Nemo: Data discovery at Facebook](https://engineering.fb.com/data-infrastructure/nemo/) `Facebook` `2020`\n17. [Exploring Data @ Netflix](https://netflixtechblog.com/exploring-data-netflix-9d87e20072e3) ([Code](https://github.com/Netflix/nf-data-explorer)) `Netflix` `2021`\n\n## Feature Stores\n1. [Distributed Time Travel for Feature Generation](https://netflixtechblog.com/distributed-time-travel-for-feature-generation-389cccdd3907) `Netflix` `2016`\n2. [Building the Activity Graph, Part 2 (Feature Storage Section)](https://engineering.linkedin.com/blog/2017/07/building-the-activity-graph--part-2) `LinkedIn` `2017`\n3. [Fact Store at Scale for Netflix Recommendations](https://databricks.com/session/fact-store-scale-for-netflix-recommendations) `Netflix` `2018`\n4. [Zipline: Airbnb\u2019s Machine Learning Data Management Platform](https://databricks.com/session/zipline-airbnbs-machine-learning-data-management-platform) `Airbnb` `2018`\n5. [Introducing Feast: An Open Source Feature Store for Machine Learning](https://cloud.google.com/blog/products/ai-machine-learning/introducing-feast-an-open-source-feature-store-for-machine-learning) ([Code](https://github.com/feast-dev/feast)) `Gojek` `2019`\n6. [Michelangelo Palette: A Feature Engineering Platform at Uber](https://www.infoq.com/presentations/michelangelo-palette-uber/) `Uber` `2019`\n7. [The Architecture That Powers Twitter's Feature Store](https://www.youtube.com/watch?v=UNailXoiIrY) `Twitter` `2019`\n8. [Accelerating Machine Learning with the Feature Store Service](https://technology.condenast.com/story/accelerating-machine-learning-with-the-feature-store-service) `Cond\u00e9 Nast` `2019` \n9. [Feast: Bridging ML Models and Data](https://www.gojek.io/blog/feast-bridging-ml-models-and-data) `Gojek` `2020`\n10. [Building a Scalable ML Feature Store with Redis, Binary Serialization, and Compression](https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/) `DoorDash` `2020`\n11. [Rapid Experimentation Through Standardization: Typed AI features for LinkedIn\u2019s Feed](https://engineering.linkedin.com/blog/2020/feed-typed-ai-features) `LinkedIn` `2020`\n12. [Building a Feature Store](https://nlathia.github.io/2020/12/Building-a-feature-store.html) `Monzo Bank` `2020`\n13. [Butterfree: A Spark-based Framework for Feature Store Building](https://medium.com/quintoandar-tech-blog/butterfree-a-spark-based-framework-for-feature-store-building-48c3640522c7) ([Code](https://github.com/quintoandar/butterfree)) `QuintoAndar` `2020`\n14. [Building Riviera: A Declarative Real-Time Feature Engineering Framework](https://doordash.engineering/2021/03/04/building-a-declarative-real-time-feature-engineering-framework/) `DoorDash` `2021`\n15. [Optimal Feature Discovery: Better, Leaner Machine Learning Models Through Information Theory](https://eng.uber.com/optimal-feature-discovery-ml/) `Uber` `2021`\n16. [ML Feature Serving Infrastructure at Lyft](https://eng.lyft.com/ml-feature-serving-infrastructure-at-lyft-d30bf2d3c32a) `Lyft` `2021`\n17. [Near real-time features for near real-time personalization](https://engineering.linkedin.com/blog/2022/near-real-time-features-for-near-real-time-personalization) `LinkedIn` `2022`\n18. [Building the Model Behind DoorDash\u2019s Expansive Merchant Selection](https://doordash.engineering/2022/04/19/building-merchant-selection/) `DoorDash` `2022`\n19. [Open sourcing Feathr \u2013 LinkedIn\u2019s feature store for productive machine learning](https://engineering.linkedin.com/blog/2022/open-sourcing-feathr---linkedin-s-feature-store-for-productive-m) `LinkedIn` `2022`\n20. [Developing scalable feature engineering DAGs](https://outerbounds.com/blog/developing-scalable-feature-engineering-dags) `Metaflow + Hamilton` via `Outerbounds` `2022`\n\n\n## Classification\n1. [Prediction of Advertiser Churn for Google AdWords](https://research.google/pubs/pub36678/) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36678.pdf)) `Google` `2010`\n2. [High-Precision Phrase-Based Document Classification on a Modern Scale](https://engineering.linkedin.com/research/2011/high-precision-phrase-based-document-classification-on-a-modern-scale) ([Paper](http://web.stanford.edu/~gavish/documents/phrase_based.pdf)) `LinkedIn` `2011`\n3. [Chimera: Large-scale Classification using Machine Learning, Rules, and Crowdsourcing](https://dl.acm.org/doi/10.14778/2733004.2733024) ([Paper](http://pages.cs.wisc.edu/%7Eanhai/papers/chimera-vldb14.pdf)) `Walmart` `2014`\n4. [Large-scale Item Categorization in e-Commerce Using Multiple Recurrent Neural Networks](https://www.kdd.org/kdd2016/subtopic/view/large-scale-item-categorization-in-e-commerce-using-multiple-recurrent-neur/) ([Paper](https://www.kdd.org/kdd2016/papers/files/adf0392-haAemb.pdf)) `NAVER` `2016`\n5. [Learning to Diagnose with LSTM Recurrent Neural Networks](https://arxiv.org/abs/1511.03677) ([Paper](https://arxiv.org/pdf/1511.03677.pdf)) `Google` `2017`\n6. [Discovering and Classifying In-app Message Intent at Airbnb](https://medium.com/airbnb-engineering/discovering-and-classifying-in-app-message-intent-at-airbnb-6a55f5400a0c) `Airbnb` `2019`\n7. [Teaching Machines to Triage Firefox Bugs](https://hacks.mozilla.org/2019/04/teaching-machines-to-triage-firefox-bugs/) `Mozilla` `2019`\n8. [Categorizing Products at Scale](https://engineering.shopify.com/blogs/engineering/categorizing-products-at-scale) `Shopify` `2020`\n9. [How We Built the Good First Issues Feature](https://github.blog/2020-01-22-how-we-built-good-first-issues/) `GitHub` `2020`\n10. [Testing Firefox More Efficiently with Machine Learning](https://hacks.mozilla.org/2020/07/testing-firefox-more-efficiently-with-machine-learning/) `Mozilla` `2020`\n11. [Using ML to Subtype Patients Receiving Digital Mental Health Interventions](https://www.microsoft.com/en-us/research/blog/a-path-to-personalization-using-ml-to-subtype-patients-receiving-digital-mental-health-interventions/) ([Paper](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2768347)) `Microsoft` `2020`\n12. [Scalable Data Classification for Security and Privacy](https://engineering.fb.com/security/data-classification-system/) ([Paper](https://arxiv.org/pdf/2006.14109.pdf)) `Facebook` `2020`\n13. [Uncovering Online Delivery Menu Best Practices with Machine Learning](https://doordash.engineering/2020/11/10/uncovering-online-delivery-menu-best-practices-with-machine-learning/) `DoorDash` `2020`\n14. [Using a Human-in-the-Loop to Overcome the Cold Start Problem in Menu Item Tagging](https://doordash.engineering/2020/08/28/overcome-the-cold-start-problem-in-menu-item-tagging/) `DoorDash` `2020`\n15. [Deep Learning: Product Categorization and Shelving](https://medium.com/walmartglobaltech/deep-learning-product-categorization-and-shelving-630571e81e96) `Walmart` `2021`\n16. [Large-scale Item Categorization for e-Commerce](https://dl.acm.org/doi/10.1145/2396761.2396838) ([Paper](https://www.researchgate.net/profile/Jean_David_Ruvini/publication/262270957_Large-scale_item_categorization_for_e-commerce/links/5512dc3d0cf270fd7e33a0d5/Large-scale-item-categorization-for-e-commerce.pdf)) `DianPing`, `eBay` `2012`\n17. [Semantic Label Representation with an Application on Multimodal Product Categorization](https://medium.com/walmartglobaltech/semantic-label-representation-with-an-application-on-multimodal-product-categorization-63d668b943b7) `Walmart` `2022`\n\n\n## Regression\n1. [Using Machine Learning to Predict Value of Homes On Airbnb](https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d) `Airbnb` `2017`\n2. [Using Machine Learning to Predict the Value of Ad Requests](https://blog.twitter.com/engineering/en_us/topics/insights/2020/using-machine-learning-to-predict-the-value-of-ad-requests.html) `Twitter` `2020`\n3. [Open-Sourcing Riskquant, a Library for Quantifying Risk](https://netflixtechblog.com/open-sourcing-riskquant-a-library-for-quantifying-risk-6720cc1e4968) ([Code](https://github.com/Netflix-Skunkworks/riskquant)) `Netflix` `2020`\n4. [Solving for Unobserved Data in a Regression Model Using a Simple Data Adjustment](https://doordash.engineering/2020/10/14/solving-for-unobserved-data-in-a-regression-model/) `DoorDash` `2020`\n\n## Forecasting\n1. [Engineering Extreme Event Forecasting at Uber with RNN](https://eng.uber.com/neural-networks/) `Uber` `2017`\n2. [Forecasting at Uber: An Introduction](https://eng.uber.com/forecasting-introduction/) `Uber` `2018`\n3. [Transforming Financial Forecasting with Data Science and Machine Learning at Uber](https://eng.uber.com/transforming-financial-forecasting-machine-learning/) `Uber` `2018`\n4. [Under the Hood of Gojek\u2019s Automated Forecasting Tool](https://www.gojek.io/blog/under-the-hood-of-gojeks-automated-forecasting-tool) `Gojek` `2019`\n5. [BusTr: Predicting Bus Travel Times from Real-Time Traffic](https://dl.acm.org/doi/abs/10.1145/3394486.3403376) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3394486.3403376), [Video](https://crossminds.ai/video/5f3369790576dd25aef288db/)) `Google` `2020`\n6. [Retraining Machine Learning Models in the Wake of COVID-19](https://doordash.engineering/2020/09/15/retraining-ml-models-covid-19/) `DoorDash` `2020`\n7. [Automatic Forecasting using Prophet, Databricks, Delta Lake and MLflow](https://www.youtube.com/watch?v=TkcpjnLh690) ([Paper](https://peerj.com/preprints/3190.pdf), [Code](https://github.com/facebook/prophet)) `Atlassian` `2020`\n8. [Introducing Orbit, An Open Source Package for Time Series Inference and Forecasting](https://eng.uber.com/orbit/) ([Paper](https://arxiv.org/abs/2004.08492), [Video](https://youtu.be/LXDpq_iwcWY), [Code](https://github.com/uber/orbit)) `Uber` `2021`\n9. [Managing Supply and Demand Balance Through Machine Learning](https://doordash.engineering/2021/06/29/managing-supply-and-demand-balance-through-machine-learning/) `DoorDash` `2021`\n10. [Greykite: A flexible, intuitive, and fast forecasting library](https://engineering.linkedin.com/blog/2021/greykite--a-flexible--intuitive--and-fast-forecasting-library) `LinkedIn` `2021`\n11. [DeepETA: How Uber Predicts Arrival Times Using Deep Learning](https://eng.uber.com/deepeta-how-uber-predicts-arrival-times/) `Uber` `2022`\n12. [Forecasting Grubhub Order Volume At Scale](https://bytes.grubhub.com/forecasting-grubhub-order-volume-at-scale-a966c2f901d2) `Grubhub` `2022`\n\n## Recommendation\n1. [Amazon.com Recommendations: Item-to-Item Collaborative Filtering](https://ieeexplore.ieee.org/document/1167344) ([Paper](https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf)) `Amazon` `2003`\n2. [Netflix Recommendations: Beyond the 5 stars (Part 1](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429) ([Part 2](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5)) `Netflix` `2012`\n3. [How Music Recommendation Works \u2014 And Doesn\u2019t Work](https://notes.variogr.am/2012/12/11/how-music-recommendation-works-and-doesnt-work/) `Spotify` `2012`\n4. [Learning to Rank Recommendations with the k -Order Statistic Loss](https://dl.acm.org/doi/10.1145/2507157.2507210) ([Paper](https://dl.acm.org/doi/pdf/10.1145/2507157.2507210)) `Google` `2013`\n5. [Recommending Music on Spotify with Deep Learning](https://benanne.github.io/2014/08/05/spotify-cnns.html) `Spotify` `2014`\n6. [Learning a Personalized Homepage](https://netflixtechblog.com/learning-a-personalized-homepage-aa8ec670359a) `Netflix` `2015`\n7. [Session-based Recommendations with Recurrent Neural Networks](https://arxiv.org/abs/1511.06939) ([Paper](https://arxiv.org/pdf/1511.06939.pdf)) `Telefonica` `2016`\n8. [Deep Neural Networks for YouTube Recommendations](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf) `YouTube` `2016`\n9. [E-commerce in Your Inbox: Product Recommendations at Scale](https://arxiv.org/abs/1606.07154) ([Paper](https://arxiv.org/pdf/1606.07154.pdf)) `Yahoo` `2016`\n10. [To Be Continued: Helping you find shows to continue watching on Netflix](https://netflixtechblog.com/to-be-continued-helping-you-find-shows-to-continue-watching-on-7c0d8ee4dab6) `Netflix` `2016`\n11. [Personalized Recommendations in LinkedIn Learning](https://engineering.linkedin.com/blog/2016/12/personalized-recommendations-in-linkedin-learning) `LinkedIn` `2016`\n12. [Personalized Channel Recommendations in Slack](https://slack.engineering/personalized-channel-recommendations-in-slack/) `Slack` `2016`\n13. [Recommending Complementary Products in E-Commerce Push Notifications](https://arxiv.org/abs/1707.08113) ([Paper](https://arxiv.org/pdf/1707.08113.pdf)) `Alibaba` `2017`\n14. [Artwork Personalization at Netflix](https://netflixtechblog.com/artwork-personalization-c589f074ad76) `Netflix` `2017`\n15. [A Meta-Learning Perspective on Cold-Start Recommendations for Items](https://papers.nips.cc/paper/7266-a-meta-learning-perspective-on-cold-start-recommendations-for-items) ([Paper](https://papers.nips.cc/paper/7266-a-meta-learning-perspective-on-cold-start-recommendations-for-items.pdf)) `Twitter` `2017`\n16. [Pixie: A System for Recommending 3+ Billion Items to 200+ Million Users in Real-Time](https://arxiv.org/abs/1711.07601) ([Paper](https://arxiv.org/pdf/1711.07601.pdf)) `Pinterest` `2017`\n17. [How 20th Century Fox uses ML to predict a movie audience](https://cloud.google.com/blog/products/ai-machine-learning/how-20th-century-fox-uses-ml-to-predict-a-movie-audience) ([Paper](https://arxiv.org/abs/1810.08189)) `20th Century Fox` `2018`\n18. [Calibrated Recommendations](https://dl.acm.org/doi/10.1145/3240323.3240372) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3240323.3240372)) `Netflix` `2018`\n19. [Food Discovery with Uber Eats: Recommending for the Marketplace](https://eng.uber.com/uber-eats-recommending-marketplace/) `Uber` `2018`\n20. [Explore, Exploit, and Explain: Personalizing Explainable Recommendations with Bandits](https://dl.acm.org/doi/10.1145/3240323.3240354) ([Paper](https://static1.squarespace.com/static/5ae0d0b48ab7227d232c2bea/t/5ba849e3c83025fa56814f45/1537755637453/BartRecSys.pdf)) `Spotify` `2018`\n21. [Behavior Sequence Transformer for E-commerce Recommendation in Alibaba](https://arxiv.org/abs/1905.06874) ([Paper](https://arxiv.org/pdf/1905.06874.pdf)) `Alibaba` `2019`\n22. [SDM: Sequential Deep Matching Model for Online Large-scale Recommender System](https://arxiv.org/abs/1909.00385) ([Paper](https://arxiv.org/pdf/1909.00385.pdf)) `Alibaba` `2019`\n23. [Multi-Interest Network with Dynamic Routing for Recommendation at Tmall](https://arxiv.org/abs/1904.08030) ([Paper](https://arxiv.org/pdf/1904.08030.pdf)) `Alibaba` `2019`\n24. [Personalized Recommendations for Experiences Using Deep Learning](https://www.tripadvisor.com/engineering/personalized-recommendations-for-experiences-using-deep-learning/) `TripAdvisor` `2019`\n25. [Powered by AI: Instagram\u2019s Explore recommender system](https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/) `Facebook` `2019`\n26. [Marginal Posterior Sampling for Slate Bandits](https://www.ijcai.org/proceedings/2019/308) ([Paper](https://www.ijcai.org/proceedings/2019/0308.pdf)) `Netflix` `2019`\n27. [Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations](https://eng.uber.com/uber-eats-graph-learning/) `Uber` `2019`\n28. [Music recommendation at Spotify](http://sigir.org/afirm2019/slides/16.%20Friday%20-%20Music%20Recommendation%20at%20Spotify%20-%20Ben%20Carterette.pdf) `Spotify` `2019`\n29. [Using Machine Learning to Predict what File you Need Next (Part 1)](https://dropbox.tech/machine-learning/content-suggestions-machine-learning) `Dropbox` `2019`\n30. [Using Machine Learning to Predict what File you Need Next (Part 2)](https://dropbox.tech/machine-learning/using-machine-learning-to-predict-what-file-you-need-next-part-2) `Dropbox` `2019`\n31. [Learning to be Relevant: Evolution of a Course Recommendation System](https://dl.acm.org/doi/pdf/10.1145/3357384.3357817) (**PAPER NEEDED**)`LinkedIn` `2019`\n32. [Temporal-Contextual Recommendation in Real-Time](https://www.amazon.science/publications/temporal-contextual-recommendation-in-real-time) ([Paper](https://assets.amazon.science/96/71/d1f25754497681133c7aa2b7eb05/temporal-contextual-recommendation-in-real-time.pdf)) `Amazon` `2020`\n33. [P-Companion: A Framework for Diversified Complementary Product Recommendation](https://www.amazon.science/publications/p-companion-a-principled-framework-for-diversified-complementary-product-recommendation) ([Paper](https://assets.amazon.science/d5/16/3f7809974a899a11bacdadefdf24/p-companion-a-principled-framework-for-diversified-complementary-product-recommendation.pdf)) `Amazon` `2020`\n34. [Deep Interest with Hierarchical Attention Network for Click-Through Rate Prediction](https://arxiv.org/abs/2005.12981) ([Paper](https://arxiv.org/pdf/2005.12981.pdf)) `Alibaba` `2020`\n35. [TPG-DNN: A Method for User Intent Prediction with Multi-task Learning](https://arxiv.org/abs/2008.02122) ([Paper](https://arxiv.org/pdf/2008.02122.pdf)) `Alibaba` `2020`\n36. [PURS: Personalized Unexpected Recommender System for Improving User Satisfaction](https://dl.acm.org/doi/10.1145/3383313.3412238) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3383313.3412238)) `Alibaba` `2020`\n37. [Controllable Multi-Interest Framework for Recommendation](https://arxiv.org/abs/2005.09347) ([Paper](https://arxiv.org/pdf/2005.09347)) `Alibaba` `2020`\n38. [MiNet: Mixed Interest Network for Cross-Domain Click-Through Rate Prediction](https://arxiv.org/abs/2008.02974) ([Paper](https://arxiv.org/pdf/2008.02974.pdf)) `Alibaba` `2020`\n39. [ATBRG: Adaptive Target-Behavior Relational Graph Network for Effective Recommendation](https://arxiv.org/abs/2005.12002) ([Paper](https://arxiv.org/pdf/2005.12002.pdf)) `Alibaba` `2020`\n40. [For Your Ears Only: Personalizing Spotify Home with Machine Learning](https://engineering.atspotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/) `Spotify` `2020`\n41. [Reach for the Top: How Spotify Built Shortcuts in Just Six Months](https://engineering.atspotify.com/2020/04/15/reach-for-the-top-how-spotify-built-shortcuts-in-just-six-months/) `Spotify` `2020`\n42. [Contextual and Sequential User Embeddings for Large-Scale Music Recommendation](https://dl.acm.org/doi/10.1145/3383313.3412248) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3383313.3412248)) `Spotify` `2020`\n43. [The Evolution of Kit: Automating Marketing Using Machine Learning](https://engineering.shopify.com/blogs/engineering/evolution-kit-automating-marketing-machine-learning) `Shopify` `2020`\n44. [A Closer Look at the AI Behind Course Recommendations on LinkedIn Learning (Part 1)](https://engineering.linkedin.com/blog/2020/course-recommendations-ai-part-one) `LinkedIn` `2020`\n45. [A Closer Look at the AI Behind Course Recommendations on LinkedIn Learning (Part 2)](https://engineering.linkedin.com/blog/2020/course-recommendations-ai-part-two) `LinkedIn` `2020`\n46. [Building a Heterogeneous Social Network Recommendation System](https://engineering.linkedin.com/blog/2020/building-a-heterogeneous-social-network-recommendation-system) `LinkedIn` `2020`\n47. [How TikTok recommends videos #ForYou](https://newsroom.tiktok.com/en-us/how-tiktok-recommends-videos-for-you) `ByteDance` `2020`\n48. [Zero-Shot Heterogeneous Transfer Learning from RecSys to Cold-Start Search Retrieval](https://arxiv.org/abs/2008.02930) ([Paper](https://arxiv.org/pdf/2008.02930.pdf)) `Google` `2020`\n49. [Improved Deep & Cross Network for Feature Cross Learning in Web-scale LTR Systems](https://arxiv.org/abs/2008.13535) ([Paper](https://arxiv.org/pdf/2008.13535.pdf)) `Google` `2020`\n50. [Mixed Negative Sampling for Learning Two-tower Neural Networks in Recommendations](https://research.google/pubs/pub50257/) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/b9f4e78a8830fe5afcf2f0452862fb3c0d6584ea.pdf)) `Google` `2020`\n51. [Future Data Helps Training: Modeling Future Contexts for Session-based Recommendation](https://arxiv.org/pdf/1906.04473.pdf) ([Paper](https://arxiv.org/pdf/1906.04473.pdf)) `Tencent` `2020`\n52. [A Case Study of Session-based Recommendations in the Home-improvement Domain](https://dl.acm.org/doi/10.1145/3383313.3412235) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3383313.3412235)) `Home Depot` `2020`\n53. [Balancing Relevance and Discovery to Inspire Customers in the IKEA App](https://dl.acm.org/doi/10.1145/3383313.3411550) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3383313.3411550)) `Ikea` `2020`\n54. [How we use AutoML, Multi-task learning and Multi-tower models for Pinterest Ads](https://medium.com/pinterest-engineering/how-we-use-automl-multi-task-learning-and-multi-tower-models-for-pinterest-ads-db966c3dc99e) `Pinterest` `2020`\n55. [Multi-task Learning for Related Products Recommendations at Pinterest](https://medium.com/pinterest-engineering/multi-task-learning-for-related-products-recommendations-at-pinterest-62684f631c12) `Pinterest` `2020`\n56. [Improving the Quality of Recommended Pins with Lightweight Ranking](https://medium.com/pinterest-engineering/improving-the-quality-of-recommended-pins-with-lightweight-ranking-8ff5477b20e3) `Pinterest` `2020`\n57. [Multi-task Learning and Calibration for Utility-based Home Feed Ranking](https://medium.com/pinterest-engineering/multi-task-learning-and-calibration-for-utility-based-home-feed-ranking-64087a7bcbad) `Pinterest` `2020`\n57. [Personalized Cuisine Filter Based on Customer Preference and Local Popularity](https://doordash.engineering/2020/01/27/personalized-cuisine-filter/) `DoorDash` `2020`\n58. [How We Built a Matchmaking Algorithm to Cross-Sell Products](https://www.gojek.io/blog/how-we-built-a-matchmaking-algorithm-to-cross-sell-products) `Gojek` `2020`\n59. [Lessons Learned Addressing Dataset Bias in Model-Based Candidate Generation](https://arxiv.org/abs/2105.09293) ([Paper](https://arxiv.org/pdf/2105.09293.pdf)) `Twitter` `2021`\n60. [Self-supervised Learning for Large-scale Item Recommendations](https://arxiv.org/abs/2007.12865) ([Paper](https://arxiv.org/pdf/2007.12865.pdf)) `Google` `2021`\n61. [Deep Retrieval: End-to-End Learnable Structure Model for Large-Scale Recommendations](https://arxiv.org/abs/2007.07203) ([Paper](https://arxiv.org/pdf/2007.07203.pdf)) `ByteDance` `2021`\n62. [Using AI to Help Health Experts Address the COVID-19 Pandemic](https://ai.facebook.com/blog/using-ai-to-help-health-experts-address-the-covid-19-pandemic/) `Facebook` `2021`\n63. [Advertiser Recommendation Systems at Pinterest](https://medium.com/pinterest-engineering/advertiser-recommendation-systems-at-pinterest-ccb255fbde20) `Pinterest` `2021`\n64. [On YouTube's Recommendation System](https://blog.youtube/inside-youtube/on-youtubes-recommendation-system/) `YouTube` `2021`\n65. [Mozrt, a Deep Learning Recommendation System Empowering Walmart Store Associates](https://medium.com/walmartglobaltech/mozrt-a-deep-learning-recommendation-system-empowering-walmart-store-associates-with-a-5d42c08d88da) `Walmart` `2021`\n65. [The Amazon Music conversational recommender is hitting the right notes](https://www.amazon.science/latest-news/how-amazon-music-uses-recommendation-system-machine-learning) `Amazon` `2022`\n66. [Personalized complementary product recommendation](https://www.amazon.science/publications/personalized-complementary-product-recommendation) ([Paper](https://assets.amazon.science/6c/d9/a0ec3eda4f0fb4312ce0ada41771/personalized-complementary-product-recommendation.pdf)) `Amazon` `2022`\n67. [Building a Deep Learning Based Retrieval System for Personalized Recommendations](https://tech.ebayinc.com/engineering/building-a-deep-learning-based-retrieval-system-for-personalized-recommendations/) `eBay` `2022`\n68. [How We Built: An Early-Stage Machine Learning Model for Recommendations](https://www.onepeloton.com/press/articles/how-we-built-machine-learning) `Peloton` `2022`\n69. [Beyond Matrix Factorization: Using hybrid features for user-business recommendations](https://engineeringblog.yelp.com/2022/04/beyond-matrix-factorization-using-hybrid-features-for-user-business-recommendations.html) `Yelp` `2022`\n70. [Improving job matching with machine-learned activity features](https://engineering.linkedin.com/blog/2022/improving-job-matching-with-machine-learned-activity-features-) `LinkedIn` `2022`\n71. [Understanding Data Storage and Ingestion for Large-Scale Deep Recommendation Model Training](https://arxiv.org/abs/2108.09373v4) `Meta` `2022`\n72. [Homepage Recommendation with Exploitation and Exploration](https://doordash.engineering/2022/10/05/homepage-recommendation-with-exploitation-and-exploration/) `DoorDash` `2022`\n\n## Search & Ranking\n1. [Amazon Search: The Joy of Ranking Products](https://www.amazon.science/publications/amazon-search-the-joy-of-ranking-products) ([Paper](https://assets.amazon.science/89/cd/34289f1f4d25b5857d776bdf04d5/amazon-search-the-joy-of-ranking-products.pdf), [Video](https://www.youtube.com/watch?v=NLrhmn-EZ88), [Code](https://github.com/dariasor/TreeExtra)) `Amazon` `2016`\n2. [How Lazada Ranks Products to Improve Customer Experience and Conversion](https://www.slideshare.net/eugeneyan/how-lazada-ranks-products-to-improve-customer-experience-and-conversion) `Lazada` `2016`\n3. [Ranking Relevance in Yahoo Search](https://www.kdd.org/kdd2016/subtopic/view/ranking-relevance-in-yahoo-search) ([Paper](https://www.kdd.org/kdd2016/papers/files/adf0361-yinA.pdf)) `Yahoo` `2016`\n4. [Learning to Rank Personalized Search Results in Professional Networks](https://arxiv.org/abs/1605.04624) ([Paper](https://arxiv.org/pdf/1605.04624.pdf)) `LinkedIn` `2016`\n5. [Using Deep Learning at Scale in Twitter\u2019s Timelines](https://blog.twitter.com/engineering/en_us/topics/insights/2017/using-deep-learning-at-scale-in-twitters-timelines.html) `Twitter` `2017`\n6. [An Ensemble-based Approach to Click-Through Rate Prediction for Promoted Listings at Etsy](https://arxiv.org/abs/1711.01377) ([Paper](https://arxiv.org/pdf/1711.01377.pdf)) `Etsy` `2017`\n7. [Powering Search & Recommendations at DoorDash](https://doordash.engineering/2017/07/06/powering-search-recommendations-at-doordash/) `DoorDash` `2017`\n8. [Applying Deep Learning To Airbnb Search](https://arxiv.org/abs/1810.09591) ([Paper](https://arxiv.org/pdf/1810.09591.pdf)) `Airbnb` `2018`\n9. [In-session Personalization for Talent Search](https://arxiv.org/abs/1809.06488) ([Paper](https://arxiv.org/pdf/1809.06488.pdf)) `LinkedIn` `2018`\n10. [Talent Search and Recommendation Systems at LinkedIn](https://arxiv.org/abs/1809.06481) ([Paper](https://arxiv.org/pdf/1809.06481.pdf)) `LinkedIn` `2018`\n11. [Food Discovery with Uber Eats: Building a Query Understanding Engine](https://eng.uber.com/uber-eats-query-understanding/) `Uber` `2018`\n12. [Globally Optimized Mutual Influence Aware Ranking in E-Commerce Search](https://arxiv.org/abs/1805.08524) ([Paper](https://arxiv.org/pdf/1805.08524.pdf)) `Alibaba` `2018`\n13. [Reinforcement Learning to Rank in E-Commerce Search Engine](https://arxiv.org/abs/1803.00710) ([Paper](https://arxiv.org/pdf/1803.00710.pdf)) `Alibaba` `2018`\n14. [Semantic Product Search](https://arxiv.org/abs/1907.00937) ([Paper](https://arxiv.org/pdf/1907.00937.pdf)) `Amazon` `2019`\n15. [Machine Learning-Powered Search Ranking of Airbnb Experiences](https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789) `Airbnb` `2019`\n16. [Entity Personalized Talent Search Models with Tree Interaction Features](https://arxiv.org/abs/1902.09041) ([Paper](https://arxiv.org/pdf/1902.09041.pdf)) `LinkedIn` `2019`\n17. [The AI Behind LinkedIn Recruiter Search and recommendation systems](https://engineering.linkedin.com/blog/2019/04/ai-behind-linkedin-recruiter-search-and-recommendation-systems) `LinkedIn` `2019`\n18. [Learning Hiring Preferences: The AI Behind LinkedIn Jobs](https://engineering.linkedin.com/blog/2019/02/learning-hiring-preferences--the-ai-behind-linkedin-jobs) `LinkedIn` `2019`\n19. [The Secret Sauce Behind Search Personalisation](https://www.gojek.io/blog/the-secret-sauce-behind-search-personalisation) `Gojek` `2019`\n20. [Neural Code Search: ML-based Code Search Using Natural Language Queries](https://ai.facebook.com/blog/neural-code-search-ml-based-code-search-using-natural-language-queries/) `Facebook` `2019`\n21. [Aggregating Search Results from Heterogeneous Sources via Reinforcement Learning](https://arxiv.org/abs/1902.08882) ([Paper](https://arxiv.org/pdf/1902.08882.pdf)) `Alibaba` `2019`\n22. [Cross-domain Attention Network with Wasserstein Regularizers for E-commerce Search](https://dl.acm.org/doi/10.1145/3357384.3357809) `Alibaba` `2019`\n23. [Understanding Searches Better Than Ever Before](https://www.blog.google/products/search/search-language-understanding-bert/) ([Paper](https://arxiv.org/pdf/1810.04805.pdf)) `Google` `2019`\n24. [How We Used Semantic Search to Make Our Search 10x Smarter](https://medium.com/tokopedia-engineering/how-we-used-semantic-search-to-make-our-search-10x-smarter-bd9c7f601821) `Tokopedia` `2019`\n25. [Query2vec: Search query expansion with query embeddings](https://bytes.grubhub.com/search-query-embeddings-using-query2vec-f5931df27d79) `GrubHub` `2019`\n26. [MOBIUS: Towards the Next Generation of Query-Ad Matching in Baidu\u2019s Sponsored Search](http://research.baidu.com/Public/uploads/5d12eca098d40.pdf) `Baidu` `2019`\n27. [Why Do People Buy Seemingly Irrelevant Items in Voice Product Search?](https://www.amazon.science/publications/why-do-people-buy-irrelevant-items-in-voice-product-search) ([Paper](https://assets.amazon.science/f7/48/0562b2c14338a0b76ccf4f523fa5/why-do-people-buy-irrelevant-items-in-voice-product-search.pdf)) `Amazon` `2020`\n28. [Managing Diversity in Airbnb Search](https://arxiv.org/abs/2004.02621) ([Paper](https://arxiv.org/pdf/2004.02621.pdf)) `Airbnb` `2020`\n29. [Improving Deep Learning for Airbnb Search](https://arxiv.org/abs/2002.05515) ([Paper](https://arxiv.org/pdf/2002.05515.pdf)) `Airbnb` `2020`\n30. [Quality Matches Via Personalized AI for Hirer and Seeker Preferences](https://engineering.linkedin.com/blog/2020/quality-matches-via-personalized-ai) `LinkedIn` `2020`\n31. [Understanding Dwell Time to Improve LinkedIn Feed Ranking](https://engineering.linkedin.com/blog/2020/understanding-feed-dwell-time) `LinkedIn` `2020`\n32. [Ads Allocation in Feed via Constrained Optimization](https://dl.acm.org/doi/abs/10.1145/3394486.3403391) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3394486.3403391), [Video](https://crossminds.ai/video/5f33697a0576dd25aef288ea/)) `LinkedIn` `2020`\n33. [Understanding Dwell Time to Improve LinkedIn Feed Ranking](https://engineering.linkedin.com/blog/2020/understanding-feed-dwell-time) `LinkedIn` `2020`\n34. [AI at Scale in Bing](https://blogs.bing.com/search/2020_05/AI-at-Scale-in-Bing) `Microsoft` `2020`\n35. [Query Understanding Engine in Traveloka Universal Search](https://medium.com/traveloka-engineering/query-understanding-engine-in-traveloka-universal-search-410ad3895db7) `Traveloka` `2020`\n36. [Bayesian Product Ranking at Wayfair](https://tech.wayfair.com/data-science/2020/01/bayesian-product-ranking-at-wayfair) `Wayfair` `2020`\n37. [COLD: Towards the Next Generation of Pre-Ranking System](https://arxiv.org/abs/2007.16122) ([Paper](https://arxiv.org/pdf/2007.16122.pdf)) `Alibaba` `2020`\n38. [Shop The Look: Building a Large Scale Visual Shopping System at Pinterest](https://dl.acm.org/doi/abs/10.1145/3394486.3403372) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3394486.3403372), [Video](https://crossminds.ai/video/5f3369790576dd25aef288d7/)) `Pinterest` `2020`\n39. [Driving Shopping Upsells from Pinterest Search](https://medium.com/pinterest-engineering/driving-shopping-upsells-from-pinterest-search-d06329255402) `Pinterest` `2020`\n40. [GDMix: A Deep Ranking Personalization Framework](https://engineering.linkedin.com/blog/2020/gdmix--a-deep-ranking-personalization-framework) ([Code](https://github.com/linkedin/gdmix)) `LinkedIn` `2020`\n41. [Bringing Personalized Search to Etsy](https://codeascraft.com/2020/10/29/bringing-personalized-search-to-etsy/) `Etsy` `2020`\n42. [Building a Better Search Engine for Semantic Scholar](https://medium.com/ai2-blog/building-a-better-search-engine-for-semantic-scholar-ea23a0b661e7) `Allen Institute for AI` `2020`\n43. [Query Understanding for Natural Language Enterprise Search](https://arxiv.org/abs/2012.06238) ([Paper](https://arxiv.org/pdf/2012.06238.pdf)) `Salesforce` `2020`\n44. [Things Not Strings: Understanding Search Intent with Better Recall](https://doordash.engineering/2020/12/15/understanding-search-intent-with-better-recall/) `DoorDash` `2020`\n45. [Query Understanding for Surfacing Under-served Music Content](https://research.atspotify.com/publications/query-understanding-for-surfacing-under-served-music-content/) ([Paper](https://labtomarket.files.wordpress.com/2020/08/cikm2020.pdf)) `Spotify` `2020`\n46. [Embedding-based Retrieval in Facebook Search](https://arxiv.org/abs/2006.11632) ([Paper](https://arxiv.org/pdf/2006.11632.pdf)) `Facebook` `2020`\n47. [Towards Personalized and Semantic Retrieval for E-commerce Search via Embedding Learning](https://arxiv.org/abs/2006.02282) ([Paper](https://arxiv.org/pdf/2006.02282.pdf)) `JD` `2020`\n48. [QUEEN: Neural query rewriting in e-commerce](https://www.amazon.science/publications/queen-neural-query-rewriting-in-e-commerce) ([Paper](https://assets.amazon.science/f9/78/dda8f1e143dba8ca96e43ec487c6/queen-neural-query-rewriting-in-ecommerce.pdf)) `Amazon` `2021`\n49. [Using Learning-to-rank to Precisely Locate Where to Deliver Packages](https://www.amazon.science/blog/using-learning-to-rank-to-precisely-locate-where-to-deliver-packages) ([Paper](https://www.amazon.science/publications/getting-your-package-to-the-right-place-supervised-machine-learning-for-geolocation)) `Amazon` `2021`\n50. [Seasonal relevance in e-commerce search](https://www.amazon.science/publications/seasonal-relevance-in-e-commerce-search) ([Paper](https://assets.amazon.science/ac/5e/d47612a846d6bec15738d7c8ab40/seasonal-relevance-in-ecommerce-search.pdf)) `Amazon` `2021`\n51. [Graph Intention Network for Click-through Rate Prediction in Sponsored Search](https://arxiv.org/abs/2103.16164) ([Paper](https://arxiv.org/pdf/2103.16164.pdf)) `Alibaba` `2021`\n52. [How We Built A Context-Specific Bidding System for Etsy Ads](https://codeascraft.com/2021/03/23/how-we-built-a-context-specific-bidding-system-for-etsy-ads/) `Etsy` `2021`\n53. [Pre-trained Language Model based Ranking in Baidu Search](https://arxiv.org/abs/2105.11108) ([Paper](https://arxiv.org/pdf/2105.11108.pdf)) `Baidu` `2021`\n54. [Stitching together spaces for query-based recommendations](https://multithreaded.stitchfix.com/blog/2021/08/13/stitching-together-spaces-for-query-based-recommendations/) `Stitch Fix` `2021`\n55. [Deep Natural Language Processing for LinkedIn Search Systems](https://arxiv.org/abs/2108.08252) ([Paper](https://arxiv.org/pdf/2108.08252.pdf)) `LinkedIn` `2021`\n56. [Siamese BERT-based Model for Web Search Relevance Ranking](https://arxiv.org/abs/2112.01810) ([Paper](https://arxiv.org/pdf/2112.01810.pdf), [Code](https://github.com/seznam/DaReCzech)) `Seznam` `2021`\n57. [SearchSage: Learning Search Query Representations at Pinterest](https://medium.com/pinterest-engineering/searchsage-learning-search-query-representations-at-pinterest-654f2bb887fc) `Pinterest` `2021`\n58. [3 Changes to Expand DoorDash\u2019s Product Search Beyond Delivery](https://doordash.engineering/2022/05/10/3-changes-to-expand-doordashs-product-search/) `DoorDash` `2022`\n\n## Embeddings\n1. [Vector Representation Of Items, Customer And Cart To Build A Recommendation System](https://arxiv.org/abs/1705.06338) ([Paper](https://arxiv.org/pdf/1705.06338.pdf)) `Sears` `2017`\n2. [Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba](https://arxiv.org/abs/1803.02349) ([Paper](https://arxiv.org/pdf/1803.02349.pdf)) `Alibaba` `2018`\n3. [Embeddings@Twitter](https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html) `Twitter` `2018`\n4. [Listing Embeddings in Search Ranking](https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e) ([Paper](https://www.kdd.org/kdd2018/accepted-papers/view/real-time-personalization-using-embeddings-for-search-ranking-at-airbnb)) `Airbnb` `2018`\n5. [Understanding Latent Style](https://multithreaded.stitchfix.com/blog/2018/06/28/latent-style/) `Stitch Fix` `2018`\n6. [Towards Deep and Representation Learning for Talent Search at LinkedIn](https://arxiv.org/abs/1809.06473) ([Paper](https://arxiv.org/pdf/1809.06473.pdf)) `LinkedIn` `2018`\n7. [Personalized Store Feed with Vector Embeddings](https://doordash.engineering/2018/04/02/personalized-store-feed-with-vector-embeddings/) `DoorDash` `2018`\n8. [Should we Embed? A Study on Performance of Embeddings for Real-Time Recommendations](https://arxiv.org/abs/1907.06556)([Paper](https://arxiv.org/pdf/1907.06556.pdf)) `Moshbit` `2019`\n9. [Machine Learning for a Better Developer Experience](https://netflixtechblog.com/machine-learning-for-a-better-developer-experience-1e600c69f36c) `Netflix` `2020`\n10. [Announcing ScaNN: Efficient Vector Similarity Search](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) ([Paper](https://arxiv.org/pdf/1908.10396.pdf), [Code](https://github.com/google-research/google-research/tree/master/scann)) `Google` `2020`\n11. [Embedding-based Retrieval at Scribd](https://tech.scribd.com/blog/2021/embedding-based-retrieval-scribd.html) `Scribd` `2021`\n\n## Natural Language Processing\n1. [Abusive Language Detection in Online User Content](https://dl.acm.org/doi/10.1145/2872427.2883062) ([Paper](http://www.yichang-cs.com/yahoo/WWW16_Abusivedetection.pdf)) `Yahoo` `2016`\n2. [Smart Reply: Automated Response Suggestion for Email](https://research.google/pubs/pub45189/) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/45189.pdf)) `Google` `2016` \n3. [Building Smart Replies for Member Messages](https://engineering.linkedin.com/blog/2017/10/building-smart-replies-for-member-messages) `LinkedIn` `2017`\n4. [Active Annotation: bootstrapping annotation lexicon and guidelines for supervised NLU learning](https://arxiv.org/abs/1908.04092) ([Paper](https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/2537.pdf)) `Trento University` `2019`\n5. [How Natural Language Processing Helps LinkedIn Members Get Support Easily](https://engineering.linkedin.com/blog/2019/04/how-natural-language-processing-help-support) `LinkedIn` `2019`\n6. [Gmail Smart Compose: Real-Time Assisted Writing](https://arxiv.org/abs/1906.00080) ([Paper](https://arxiv.org/pdf/1906.00080.pdf)) `Google` `2019`\n7. [Goal-Oriented End-to-End Conversational Models with Profile Features in a Real-World Setting](https://www.amazon.science/publications/goal-oriented-end-to-end-chatbots-with-profile-features-in-a-real-world-setting) ([Paper](https://assets.amazon.science/47/03/e0d14dc34d3eb6e0d4ec282067bd/goal-oriented-end-to-end-chatbots-with-profile-features-in-a-real-world-setting.pdf)) `Amazon` `2019`\n8. [Give Me Jeans not Shoes: How BERT Helps Us Deliver What Clients Want](https://multithreaded.stitchfix.com/blog/2019/07/15/give-me-jeans/) `Stitch Fix` `2019`\n9. [DeText: A deep NLP Framework for Intelligent Text Understanding](https://engineering.linkedin.com/blog/2020/open-sourcing-detext) ([Code](https://github.com/linkedin/detext)) `LinkedIn` `2020`\n10. [SmartReply for YouTube Creators](https://ai.googleblog.com/2020/07/smartreply-for-youtube-creators.html) `Google` `2020`\n11. [Using Neural Networks to Find Answers in Tables](https://ai.googleblog.com/2020/04/using-neural-networks-to-find-answers.html) ([Paper](https://arxiv.org/pdf/2004.02349.pdf)) `Google` `2020`\n12. [A Scalable Approach to Reducing Gender Bias in Google Translate](https://ai.googleblog.com/2020/04/a-scalable-approach-to-reducing-gender.html) `Google` `2020`\n13. [Assistive AI Makes Replying Easier](https://www.microsoft.com/en-us/research/group/msai/articles/assistive-ai-makes-replying-easier-2/) `Microsoft` `2020`\n14. [AI Advances to Better Detect Hate Speech](https://ai.facebook.com/blog/ai-advances-to-better-detect-hate-speech/) `Facebook` `2020`\n15. [A State-of-the-Art Open Source Chatbot](https://ai.facebook.com/blog/state-of-the-art-open-source-chatbot) ([Paper](https://arxiv.org/pdf/2004.13637.pdf)) `Facebook` `2020`\n16. [A Highly Efficient, Real-Time Text-to-Speech System Deployed on CPUs](https://ai.facebook.com/blog/a-highly-efficient-real-time-text-to-speech-system-deployed-on-cpus/) `Facebook` `2020`\n17. [Deep Learning to Translate Between Programming Languages](https://ai.facebook.com/blog/deep-learning-to-translate-between-programming-languages/) ([Paper](https://arxiv.org/abs/2006.03511), [Code](https://github.com/facebookresearch/TransCoder)) `Facebook` `2020`\n18. [Deploying Lifelong Open-Domain Dialogue Learning](https://arxiv.org/abs/2008.08076) ([Paper](https://arxiv.org/pdf/2008.08076.pdf)) `Facebook` `2020`\n19. [Introducing Dynabench: Rethinking the way we benchmark AI](https://ai.facebook.com/blog/dynabench-rethinking-ai-benchmarking/) `Facebook` `2020`\n20. [How Gojek Uses NLP to Name Pickup Locations at Scale](https://www.gojek.io/blog/nlp-cartobert) `Gojek` `2020`\n21. [The State-of-the-art Open-Domain Chatbot in Chinese and English](http://research.baidu.com/Blog/index-view?id=142) ([Paper](https://arxiv.org/pdf/2006.16779.pdf)) `Baidu` `2020`\n22. [PEGASUS: A State-of-the-Art Model for Abstractive Text Summarization](https://ai.googleblog.com/2020/06/pegasus-state-of-art-model-for.html) ([Paper](https://arxiv.org/pdf/1912.08777.pdf), [Code](https://github.com/google-research/pegasus)) `Google` `2020`\n23. [Photon: A Robust Cross-Domain Text-to-SQL System](https://www.aclweb.org/anthology/2020.acl-demos.24/) ([Paper](https://www.aclweb.org/anthology/2020.acl-demos.24.pdf)) ([Demo](http://naturalsql.com)) `Salesforce`\t`2020`\n24. [GeDi: A Powerful New Method for Controlling Language Models](https://blog.einstein.ai/gedi/) ([Paper](https://arxiv.org/abs/2009.06367), [Code](https://github.com/salesforce/GeDi)) `Salesforce` `2020`\n25. [Applying Topic Modeling to Improve Call Center Operations](https://www.youtube.com/watch?v=kzRR8OjF_eI&t=2s) `RICOH` `2020`\n26. [WIDeText: A Multimodal Deep Learning Framework](https://medium.com/airbnb-engineering/widetext-a-multimodal-deep-learning-framework-31ce2565880c) `Airbnb` `2020`\n27. [Dynaboard: Moving Beyond Accuracy to Holistic Model Evaluation in NLP](https://ai.facebook.com/blog/dynaboard-moving-beyond-accuracy-to-holistic-model-evaluation-in-nlp) ([Code](https://github.com/facebookresearch/dynalab?fbclid=IwAR3qcV7QK2uXm4s4M0XUoQQo4i2DEsDy0LZFKxSQCHhP-3hF6fr2-NDFWX8)) `Facebook`  `2021`\n28. [How we reduced our text similarity runtime by 99.96%](https://medium.com/data-science-at-microsoft/how-we-reduced-our-text-similarity-runtime-by-99-96-e8e4b4426b35) `Microsoft` `2021`\n29. [Textless NLP: Generating expressive speech from raw audio](https://ai.facebook.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio/) [(Part 1)](https://arxiv.org/abs/2102.01192) [(Part 2)](https://arxiv.org/abs/2104.00355) [(Part 3)](https://arxiv.org/abs/2109.03264) [(Code and Pretrained Models)](https://github.com/pytorch/fairseq/tree/master/examples/textless_nlp) `Facebook` `2021`\n30. [Grammar Correction as You Type, on Pixel 6](https://ai.googleblog.com/2021/10/grammar-correction-as-you-type-on-pixel.html) `Google` `2021`\n31. [Auto-generated Summaries in Google Docs](https://ai.googleblog.com/2022/03/auto-generated-summaries-in-google-docs.html) `Google` `2022`\n32. [Words All the Way Down \u2014 Conversational Sentiment Analysis](https://medium.com/paypal-tech/words-all-the-way-down-conversational-sentiment-analysis-afe0165b84db) `PayPal` `2022`\n\n## Sequence Modelling\n1. [Doctor AI: Predicting Clinical Events via Recurrent Neural Networks](https://arxiv.org/abs/1511.05942) ([Paper](https://arxiv.org/pdf/1511.05942.pdf)) `Sutter Health` `2015`\n2. [Deep Learning for Understanding Consumer Histories](https://engineering.zalando.com/posts/2016/10/deep-learning-for-understanding-consumer-histories.html) ([Paper](https://doogkong.github.io/2017/papers/paper2.pdf)) `Zalando` `2016`\n3. [Using Recurrent Neural Network Models for Early Detection of Heart Failure Onset](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5391725/) ([Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5391725/pdf/ocw112.pdf)) `Sutter Health` `2016`\n4. [Continual Prediction of Notification Attendance with Classical and Deep Networks](https://arxiv.org/abs/1712.07120) ([Paper](https://arxiv.org/pdf/1712.07120.pdf)) `Telefonica` `2017` \n5. [Deep Learning for Electronic Health Records](https://ai.googleblog.com/2018/05/deep-learning-for-electronic-health.html) ([Paper](https://www.nature.com/articles/s41746-018-0029-1.pdf)) `Google` `2018`\n6. [Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction](https://arxiv.org/abs/1905.09248) ([Paper](https://arxiv.org/pdf/1905.09248.pdf))`Alibaba` `2019`\n7. [Search-based User Interest Modeling with Sequential Behavior Data for CTR Prediction](https://arxiv.org/abs/2006.05639) ([Paper](https://arxiv.org/pdf/2006.05639.pdf)) `Alibaba` `2020`\n8. [How Duolingo uses AI in every part of its app](https://venturebeat.com/2020/08/18/how-duolingo-uses-ai-in-every-part-of-its-app/) `Duolingo` `2020`\n9. [Leveraging Online Social Interactions For Enhancing Integrity at Facebook](https://research.fb.com/blog/2020/08/leveraging-online-social-interactions-for-enhancing-integrity-at-facebook/) ([Paper](https://research.fb.com/wp-content/uploads/2020/08/TIES-Temporal-Interaction-Embeddings-For-Enhancing-Social-Media-Integrity-At-Facebook.pdf), [Video](https://crossminds.ai/video/5f3369780576dd25aef288cf/)) `Facebook` `2020`\n10. [Using deep learning to detect abusive sequences of member activity](https://engineering.linkedin.com/blog/2021/using-deep-learning-to-detect-abusive-sequences-of-member-activi) ([Video](https://exchange.scale.com/public/videos/using-deep-learning-to-detect-abusive-sequences-of-member-activity-on-linkedin)) `LinkedIn` `2021`\n\n## Computer Vision\n1. [Creating a Modern OCR Pipeline Using Computer Vision and Deep Learning](https://dropbox.tech/machine-learning/creating-a-modern-ocr-pipeline-using-computer-vision-and-deep-learning) `Dropbox` `2017`\n2. [Categorizing Listing Photos at Airbnb](https://medium.com/airbnb-engineering/categorizing-listing-photos-at-airbnb-f9483f3ab7e3) `Airbnb` `2018`\n3. [Amenity Detection and Beyond \u2014 New Frontiers of Computer Vision at Airbnb](https://medium.com/airbnb-engineering/amenity-detection-and-beyond-new-frontiers-of-computer-vision-at-airbnb-144a4441b72e) `Airbnb` `2019`\n4. [How we Improved Computer Vision Metrics by More Than 5% Only by Cleaning Labelling Errors](https://deepomatic.com/en/how-we-improved-computer-vision-metrics-by-more-than-5-percent-only-by-cleaning-labelling-errors/) `Deepomatic`\n5. [Making machines recognize and transcribe conversations in meetings using audio and video](https://www.microsoft.com/en-us/research/blog/making-machines-recognize-and-transcribe-conversations-in-meetings-using-audio-and-video/) `Microsoft` `2019`\n6. [Powered by AI: Advancing product understanding and building new shopping experiences](https://ai.facebook.com/blog/powered-by-ai-advancing-product-understanding-and-building-new-shopping-experiences/) `Facebook` `2020`\n7. [A Neural Weather Model for Eight-Hour Precipitation Forecasting](https://ai.googleblog.com/2020/03/a-neural-weather-model-for-eight-hour.html) ([Paper](https://arxiv.org/pdf/2003.12140.pdf)) `Google` `2020`\n8. [Machine Learning-based Damage Assessment for Disaster Relief](https://ai.googleblog.com/2020/06/machine-learning-based-damage.html) ([Paper](https://arxiv.org/pdf/1910.06444.pdf)) `Google` `2020`\n9. [RepNet: Counting Repetitions in Videos](https://ai.googleblog.com/2020/06/repnet-counting-repetitions-in-videos.html) ([Paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Dwibedi_Counting_Out_Time_Class_Agnostic_Video_Repetition_Counting_in_the_CVPR_2020_paper.pdf)) `Google` `2020`\n10. [Converting Text to Images for Product Discovery](https://www.amazon.science/blog/converting-text-to-images-for-product-discovery) ([Paper](https://assets.amazon.science/4c/76/5830542547b7a11089ce3af943b4/scipub-972.pdf)) `Amazon` `2020`\n11. [How Disney Uses PyTorch for Animated Character Recognition](https://medium.com/pytorch/how-disney-uses-pytorch-for-animated-character-recognition-a1722a182627) `Disney` `2020`\n12. [Image Captioning as an Assistive Technology](https://www.ibm.com/blogs/research/2020/07/image-captioning-assistive-technology/) ([Video](https://ivc.ischool.utexas.edu/~yz9244/VizWiz_workshop/videos/MMTeam-oral.mp4)) `IBM` `2020`\n13. [AI for AG: Production machine learning for agriculture](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1) `Blue River` `2020`\n14. [AI for Full-Self Driving at Tesla](https://youtu.be/hx7BXih7zx8?t=513) `Tesla` `2020`\n15. [On-device Supermarket Product Recognition](https://ai.googleblog.com/2020/07/on-device-supermarket-product.html) `Google` `2020`\n16. [Using Machine Learning to Detect Deficient Coverage in Colonoscopy Screenings](https://ai.googleblog.com/2020/08/using-machine-learning-to-detect.html) ([Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9097918)) `Google` `2020`\n17. [Shop The Look: Building a Large Scale Visual Shopping System at Pinterest](https://dl.acm.org/doi/abs/10.1145/3394486.3403372) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3394486.3403372), [Video](https://crossminds.ai/video/5f3369790576dd25aef288d7/)) `Pinterest` `2020`\n18. [Developing Real-Time, Automatic Sign Language Detection for Video Conferencing](https://ai.googleblog.com/2020/10/developing-real-time-automatic-sign.html) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/2eaf0d18ec6bef00d7dd88f39dd4f9ff13eeeeb2.pdf)) `Google` `2020`\n19. [Vision-based Price Suggestion for Online Second-hand Items](https://arxiv.org/abs/2012.06009) ([Paper](https://arxiv.org/pdf/2012.06009.pdf)) `Alibaba` `2020`\n20. [New AI Research to Help Predict COVID-19 Resource Needs From X-rays](https://ai.facebook.com/blog/new-ai-research-to-help-predict-covid-19-resource-needs-from-a-series-of-x-rays/) ([Paper](https://arxiv.org/pdf/2101.04909.pdf), [Model](https://github.com/facebookresearch/CovidPrognosis)) `Facebook` `2021`\n21. [An Efficient Training Approach for Very Large Scale Face Recognition](https://arxiv.org/abs/2105.10375) ([Paper](https://arxiv.org/pdf/2105.10375)) `Alibaba` `2021`\n22. [Identifying Document Types at Scribd](https://tech.scribd.com/blog/2021/identifying-document-types.html) `Scribd` `2021`\n23. [Semi-Supervised Visual Representation Learning for Fashion Compatibility](https://arxiv.org/pdf/2109.08052.pdf) ([Paper](https://arxiv.org/pdf/2109.08052.pdf)) `Walmart` `2021`\n24. [Recognizing People in Photos Through Private On-Device Machine Learning](https://machinelearning.apple.com/research/recognizing-people-photos) `Apple` `2021`\n25. [DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection](https://arxiv.org/pdf/2203.08195.pdf) `Google` `2022`\n\n## Reinforcement Learning\n1. [Deep Reinforcement Learning for Sponsored Search Real-time Bidding](https://arxiv.org/abs/1803.00259) ([Paper](https://arxiv.org/pdf/1803.00259.pdf)) `Alibaba` `2018`\n2. [Budget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising](https://arxiv.org/abs/1802.08365) ([Paper](https://arxiv.org/pdf/1802.08365.pdf)) `Alibaba` `2018`\n3. [Reinforcement Learning for On-Demand Logistics](https://doordash.engineering/2018/09/10/reinforcement-learning-for-on-demand-logistics/) `DoorDash` `2018`\n4. [Reinforcement Learning to Rank in E-Commerce Search Engine](https://arxiv.org/abs/1803.00710) ([Paper](https://arxiv.org/pdf/1803.00710.pdf)) `Alibaba` `2018`\n5. [Dynamic Pricing on E-commerce Platform with Deep Reinforcement Learning](https://arxiv.org/abs/1912.02572) ([Paper](https://arxiv.org/pdf/1912.02572.pdf)) `Alibaba` `2019`\n6. [Productionizing Deep Reinforcement Learning with Spark and MLflow](https://databricks.com/session_na20/productionizing-deep-reinforcement-learning-with-spark-and-mlflow) `Zynga` `2020`\n7. [Deep Reinforcement Learning in Production Part1](https://towardsdatascience.com/deep-reinforcement-learning-in-production-7e1e63471e2) [Part 2](https://towardsdatascience.com/deep-reinforcement-learning-in-production-part-2-personalizing-user-notifications-812a68ce2355) `Zynga` `2020`\n8. [Building AI Trading Systems](https://dennybritz.com/blog/ai-trading/) `Denny Britz` `2020`\n9. [Shifting Consumption towards Diverse content via Reinforcement Learning](https://research.atspotify.com/shifting-consumption-towards-diverse-content-via-reinforcement-learning/) ([Paper](https://dl.acm.org/doi/10.1145/3437963.3441775)) `Spotify` `2022`\n\n## Anomaly Detection\n1. [Detecting Performance Anomalies in External Firmware Deployments](https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46) `Netflix` `2019`\n2. [Detecting and Preventing Abuse on LinkedIn using Isolation Forests](https://engineering.linkedin.com/blog/2019/isolation-forest) ([Code](https://github.com/linkedin/isolation-forest)) `LinkedIn` `2019`\n3. [Deep Anomaly Detection with Spark and Tensorflow](https://databricks.com/session_eu19/deep-anomaly-detection-from-research-to-production-leveraging-spark-and-tensorflow) [(Hopsworks Video](https://www.youtube.com/watch?v=TgXVU8DSyCQ)) `Swedbank`, `Hopsworks` `2019`\n4. [Preventing Abuse Using Unsupervised Learning](https://databricks.com/session_na20/preventing-abuse-using-unsupervised-learning) `LinkedIn` `2020`\n5. [The Technology Behind Fighting Harassment on LinkedIn](https://engineering.linkedin.com/blog/2020/fighting-harassment) `LinkedIn` `2020`\n6. [Uncovering Insurance Fraud Conspiracy with Network Learning](https://arxiv.org/abs/2002.12789) ([Paper](https://arxiv.org/pdf/2002.12789.pdf)) `Ant Financial` `2020`\n7. [How Does Spam Protection Work on Stack Exchange?](https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/) `Stack Exchange` `2020`\n8. [Auto Content Moderation in C2C e-Commerce](https://www.usenix.org/conference/opml20/presentation/ueta) `Mercari` `2020`\n9. [Blocking Slack Invite Spam With Machine Learning](https://slack.engineering/blocking-slack-invite-spam-with-machine-learning/) `Slack` `2020`\n10. [Cloudflare Bot Management: Machine Learning and More](https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/) `Cloudflare` `2020`\n11. [Anomalies in Oil Temperature Variations in a Tunnel Boring Machine](https://www.youtube.com/watch?v=YV_uLLhPRAk) `SENER` `2020`\n12. [Using Anomaly Detection to Monitor Low-Risk Bank Customers](https://www.youtube.com/watch?v=MExokMM_Bp4&t=3s) `Rabobank` `2020`\n13. [Fighting fraud with Triplet Loss](https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e) `OLX Group` `2020`\n14. [Facebook is Now Using AI to Sort Content for Quicker Moderation](https://www.theverge.com/2020/11/13/21562596/facebook-ai-moderation) ([Alternative](https://venturebeat.com/2020/11/13/facebooks-redoubled-ai-efforts-wont-stop-the-spread-of-harmful-content/)) `Facebook` `2020`\n15. How AI is getting better at detecting hate speech [Part 1](https://ai.facebook.com/blog/how-ai-is-getting-better-at-detecting-hate-speech/), [Part 2](https://ai.facebook.com/blog/heres-how-were-using-ai-to-help-detect-misinformation/), [Part 3](https://ai.facebook.com/blog/training-ai-to-detect-hate-speech-in-the-real-world/), [Part 4](https://ai.facebook.com/blog/how-facebook-uses-super-efficient-ai-models-to-detect-hate-speech/) `Facebook` `2020`\n16. [Project RADAR: Intelligent Early Fraud Detection System with Humans in the Loop](https://eng.uber.com/project-radar-intelligent-early-fraud-detection/) `Uber` `2022`\n\n## Graph\n1. [Building The LinkedIn Knowledge Graph](https://engineering.linkedin.com/blog/2016/10/building-the-linkedin-knowledge-graph) `LinkedIn` `2016`\n2. [Scaling Knowledge Access and Retrieval at Airbnb](https://medium.com/airbnb-engineering/scaling-knowledge-access-and-retrieval-at-airbnb-665b6ba21e95) `Airbnb` `2018`\n3. [Graph Convolutional Neural Networks for Web-Scale Recommender Systems](https://arxiv.org/abs/1806.01973) ([Paper](https://arxiv.org/pdf/1806.01973.pdf))`Pinterest` `2018`\n4. [Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations](https://eng.uber.com/uber-eats-graph-learning/) `Uber` `2019`\n5. [AliGraph: A Comprehensive Graph Neural Network Platform](https://arxiv.org/abs/1902.08730) ([Paper](https://arxiv.org/pdf/1902.08730.pdf)) `Alibaba` `2019`\n6. [Contextualizing Airbnb by Building Knowledge Graph](https://medium.com/airbnb-engineering/contextualizing-airbnb-by-building-knowledge-graph-b7077e268d5a) `Airbnb` `2019`\n7. [Retail Graph \u2014 Walmart\u2019s Product Knowledge Graph](https://medium.com/walmartlabs/retail-graph-walmarts-product-knowledge-graph-6ef7357963bc) `Walmart` `2020`\n8. [Traffic Prediction with Advanced Graph Neural Networks](https://deepmind.com/blog/article/traffic-prediction-with-advanced-graph-neural-networks) `DeepMind` `2020`\n9. [SimClusters: Community-Based Representations for Recommendations](https://dl.acm.org/doi/10.1145/3394486.3403370) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3394486.3403370), [Video](https://crossminds.ai/video/5f3369790576dd25aef288d5/)) `Twitter` `2020`\n10. [Metapaths guided Neighbors aggregated Network for Heterogeneous Graph Reasoning](https://arxiv.org/abs/2103.06474) ([Paper](https://arxiv.org/pdf/2103.06474.pdf)) `Alibaba` `2021`\n11. [Graph Intention Network for Click-through Rate Prediction in Sponsored Search](https://arxiv.org/abs/2103.16164) ([Paper](https://arxiv.org/pdf/2103.16164.pdf)) `Alibaba` `2021`\n12. [JEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase](https://ojs.aaai.org/index.php/AAAI/article/view/17796) ([Paper](https://www.aaai.org/AAAI21Papers/IAAI-21.DingW.pdf)) `JPMorgan Chase` `2021`\n13. [How AWS uses graph neural networks to meet customer needs](https://www.amazon.science/blog/how-aws-uses-graph-neural-networks-to-meet-customer-needs) `Amazon` `2022`\n\n## Optimization\n1. [Matchmaking in Lyft Line (Part 1)](https://eng.lyft.com/matchmaking-in-lyft-line-9c2635fe62c4) [(Part 2)](https://eng.lyft.com/matchmaking-in-lyft-line-691a1a32a008) [(Part 3)](https://eng.lyft.com/matchmaking-in-lyft-line-part-3-d8f9497c0e51) `Lyft` `2016`\n2. [The Data and Science behind GrabShare Carpooling](https://ieeexplore.ieee.org/document/8259801) [(Part 1)](https://engineering.grab.com/the-data-and-science-behind-grabshare-part-i) (**PAPER NEEDED**) `Grab` `2017`\n3. [How Trip Inferences and Machine Learning Optimize Delivery Times on Uber Eats](https://eng.uber.com/uber-eats-trip-optimization/) `Uber` `2018`\n4. [Next-Generation Optimization for Dasher Dispatch at DoorDash](https://doordash.engineering/2020/02/28/next-generation-optimization-for-dasher-dispatch-at-doordash/) `DoorDash` `2020` \n5. [Optimization of Passengers Waiting Time in Elevators Using Machine Learning](https://www.youtube.com/watch?v=vXndCC89BCw&t=4s) `Thyssen Krupp AG` `2020`\n6. [Think Out of The Package: Recommending Package Types for E-commerce Shipments](https://www.amazon.science/publications/think-out-of-the-package-recommending-package-types-for-e-commerce-shipments) ([Paper](https://assets.amazon.science/0c/6c/9d0986b94bef92d148f0ac0da1ea/think-out-of-the-package-recommending-package-types-for-e-commerce-shipments.pdf)) `Amazon` `2020`\n7. [Optimizing DoorDash\u2019s Marketing Spend with Machine Learning](https://doordash.engineering/2020/07/31/optimizing-marketing-spend-with-ml/) `DoorDash` `2020`\n8. [Using learning-to-rank to precisely locate where to deliver packages](https://www.amazon.science/blog/using-learning-to-rank-to-precisely-locate-where-to-deliver-packages) ([Paper](https://assets.amazon.science/69/8d/2249945a4e10ba8fc758f7523b0c/getting-your-package-to-the-right-place-supervised-machine-learning-for-geolocation.pdf))`Amazon` `2021`\n\n## Information Extraction\n1. [Unsupervised Extraction of Attributes and Their Values from Product Description](https://www.aclweb.org/anthology/I13-1190/) ([Paper](https://www.aclweb.org/anthology/I13-1190.pdf)) `Rakuten` `2013`\n2. [Using Machine Learning to Index Text from Billions of Images](https://dropbox.tech/machine-learning/using-machine-learning-to-index-text-from-billions-of-images) `Dropbox` `2018`\n3. [Extracting Structured Data from Templatic Documents](https://ai.googleblog.com/2020/06/extracting-structured-data-from.html) ([Paper](https://www.aclweb.org/anthology/I13-1190.pdf)) `Google` `2020`\n4. [AutoKnow: self-driving knowledge collection for products of thousands of types](https://www.amazon.science/publications/autoknow-self-driving-knowledge-collection-for-products-of-thousands-of-types) ([Paper](https://arxiv.org/pdf/2006.13473.pdf), [Video](https://crossminds.ai/video/5f3369730576dd25aef288a6/)) `Amazon` `2020`\n5. [One-shot Text Labeling using Attention and Belief Propagation for Information Extraction](https://arxiv.org/abs/2009.04153) ([Paper](https://arxiv.org/pdf/2009.04153.pdf)) `Alibaba` `2020`\n6. [Information Extraction from Receipts with Graph Convolutional Networks](https://nanonets.com/blog/information-extraction-graph-convolutional-networks/) `Nanonets` `2021`\n\n## Weak Supervision\n1. [Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale](https://dl.acm.org/doi/abs/10.1145/3299869.3314036) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3299869.3314036)) `Google` `2019`\n2. [Osprey: Weak Supervision of Imbalanced Extraction Problems without Code](https://dl.acm.org/doi/abs/10.1145/3329486.3329492) ([Paper](https://ajratner.github.io/assets/papers/Osprey_DEEM.pdf)) `Intel` `2019` \n3. [Overton: A Data System for Monitoring and Improving Machine-Learned Products](https://arxiv.org/abs/1909.05372) ([Paper](https://arxiv.org/pdf/1909.05372.pdf)) `Apple` `2019`\n4. [Bootstrapping Conversational Agents with Weak Supervision](https://www.aaai.org/ojs/index.php/AAAI/article/view/5011) ([Paper](https://arxiv.org/pdf/1812.06176.pdf)) `IBM` `2019`\n\n## Generation\n1. [Better Language Models and Their Implications](https://openai.com/blog/better-language-models/) ([Paper](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf))`OpenAI` `2019`\n2. [Image GPT](https://openai.com/blog/image-gpt/) ([Paper](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf), [Code](https://github.com/openai/image-gpt)) `OpenAI` `2019`\n3. [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) ([Paper](https://arxiv.org/pdf/2005.14165.pdf)) ([GPT-3 Blog post](https://openai.com/blog/openai-api/)) `OpenAI` `2020`\n4. [Deep Learned Super Resolution for Feature Film Production](https://graphics.pixar.com/library/SuperResolution/) ([Paper](https://graphics.pixar.com/library/SuperResolution/paper.pdf)) `Pixar` `2020`\n5. [Unit Test Case Generation with Transformers](https://arxiv.org/pdf/2009.05617.pdf) `Microsoft` `2021`\n\n## Audio\n1. [Improving On-Device Speech Recognition with VoiceFilter-Lite](https://ai.googleblog.com/2020/11/improving-on-device-speech-recognition.html) ([Paper](https://arxiv.org/pdf/2009.04323.pdf))`Google` `2020`\n2. [The Machine Learning Behind Hum to Search](https://ai.googleblog.com/2020/11/the-machine-learning-behind-hum-to.html) `Google` `2020`\n\n## Validation and A/B Testing\n1. [Overlapping Experiment Infrastructure: More, Better, Faster Experimentation](https://research.google/pubs/pub36500/) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36500.pdf)) `Google` `2010`\n2. [The Reusable Holdout: Preserving Validity in Adaptive Data Analysis](https://ai.googleblog.com/2015/08/the-reusable-holdout-preserving.html) ([Paper](https://science.sciencemag.org/content/sci/349/6248/636.full.pdf)) `Google` `2015`\n3. [Twitter Experimentation: Technical Overview](https://blog.twitter.com/engineering/en_us/a/2015/twitter-experimentation-technical-overview.html) `Twitter` `2015`\n4. [It\u2019s All A/Bout Testing: The Netflix Experimentation Platform](https://netflixtechblog.com/its-all-a-bout-testing-the-netflix-experimentation-platform-4e1ca458c15) `Netflix` `2016`\n5. [Building Pinterest\u2019s A/B Testing Platform](https://medium.com/pinterest-engineering/building-pinterests-a-b-testing-platform-ab4934ace9f4) `Pinterest` `2016` \n6. [Experimenting to Solve Cramming](https://blog.twitter.com/engineering/en_us/topics/insights/2017/Experimenting-To-Solve-Cramming.html) `Twitter` `2017`\n7. [Building an Intelligent Experimentation Platform with Uber Engineering](https://eng.uber.com/experimentation-platform/) `Uber` `2017`\n8. [Scaling Airbnb\u2019s Experimentation Platform](https://medium.com/airbnb-engineering/https-medium-com-jonathan-parks-scaling-erf-23fd17c91166) `Airbnb` `2017`\n9. [Meet Wasabi, an Open Source A/B Testing Platform](https://www.intuit.com/blog/technology/engineering/meet-wasabi-an-open-source-ab-testing-platform/) ([Code](https://github.com/intuit/wasabi)) `Intuit` `2017` \n10. [Analyzing Experiment Outcomes: Beyond Average Treatment Effects](https://eng.uber.com/analyzing-experiment-outcomes/) `Uber` `2018`\n11. [Under the Hood of Uber\u2019s Experimentation Platform](https://eng.uber.com/xp/) `Uber` `2018`\n12. [Constrained Bayesian Optimization with Noisy Experiments](https://research.fb.com/publications/constrained-bayesian-optimization-with-noisy-experiments/) ([Paper](https://arxiv.org/pdf/1706.07094.pdf)) `Facebook` `2018`\n13. [Reliable and Scalable Feature Toggles and A/B Testing SDK at Grab](https://engineering.grab.com/feature-toggles-ab-testing) `Grab` `2018`\n14. [Modeling Conversion Rates and Saving Millions Using Kaplan-Meier and Gamma Distributions](https://better.engineering/modeling-conversion-rates-and-saving-millions-of-dollars-using-kaplan-meier-and-gamma-distributions/) ([Code](https://github.com/better/convoys)) `Better` `2019`\n15. [Detecting Interference: An A/B Test of A/B Tests](https://engineering.linkedin.com/blog/2019/06/detecting-interference--an-a-b-test-of-a-b-tests) `LinkedIn` `2019`\n16. [Announcing a New Framework for Designing Optimal Experiments with Pyro](https://eng.uber.com/oed-pyro-release/) ([Paper](https://papers.nips.cc/paper/9553-variational-bayesian-optimal-experimental-design.pdf)) ([Paper](https://arxiv.org/pdf/1911.00294.pdf)) `Uber` `2020`\n17. [Enabling 10x More Experiments with Traveloka Experiment Platform](https://medium.com/traveloka-engineering/enabling-10x-more-experiments-with-traveloka-experiment-platform-8cea13e952c) `Traveloka` `2020`\n18. [Large Scale Experimentation at Stitch Fix](https://multithreaded.stitchfix.com/blog/2020/07/07/large-scale-experimentation/) ([Paper](http://proceedings.mlr.press/v89/schmit19a/schmit19a.pdf)) `Stitch Fix` `2020`\n19. [Multi-Armed Bandits and the Stitch Fix Experimentation Platform](https://multithreaded.stitchfix.com/blog/2020/08/05/bandits/) `Stitch Fix` `2020`\n20. [Experimentation with Resource Constraints](https://multithreaded.stitchfix.com/blog/2020/11/18/virtual-warehouse/) `Stitch Fix` `2020`\n21. [Computational Causal Inference at Netflix](https://netflixtechblog.com/computational-causal-inference-at-netflix-293591691c62) ([Paper](https://arxiv.org/pdf/2007.10979.pdf)) `Netflix` `2020`\n22. [Key Challenges with Quasi Experiments at Netflix](https://netflixtechblog.com/key-challenges-with-quasi-experiments-at-netflix-89b4f234b852) `Netflix` `2020`\n23. [Making the LinkedIn experimentation engine 20x faster](https://engineering.linkedin.com/blog/2020/making-the-linkedin-experimentation-engine-20x-faster) `LinkedIn` `2020`\n24. [Our Evolution Towards T-REX: The Prehistory of Experimentation Infrastructure at LinkedIn](https://engineering.linkedin.com/blog/2020/our-evolution-towards-t-rex--the-prehistory-of-experimentation-i) `LinkedIn` `2020`\n25. [How to Use Quasi-experiments and Counterfactuals to Build Great Products](https://engineering.shopify.com/blogs/engineering/using-quasi-experiments-counterfactuals) `Shopify` `2020`\n26. [Improving Experimental Power through Control Using Predictions as Covariate](https://doordash.engineering/2020/06/08/improving-experimental-power-through-control-using-predictions-as-covariate-cupac/) `DoorDash` `2020`\n27. [Supporting Rapid Product Iteration with an Experimentation Analysis Platform](https://doordash.engineering/2020/09/09/experimentation-analysis-platform-mvp/) `DoorDash` `2020`\n28. [Improving Online Experiment Capacity by 4X with Parallelization and Increased Sensitivity](https://doordash.engineering/2020/10/07/improving-experiment-capacity-by-4x/) `DoorDash` `2020`\n29. [Leveraging Causal Modeling to Get More Value from Flat Experiment Results](https://doordash.engineering/2020/09/18/causal-modeling-to-get-more-value-from-flat-experiment-results/) `DoorDash` `2020`\n30. [Iterating Real-time Assignment Algorithms Through Experimentation](https://doordash.engineering/2020/12/08/optimizing-real-time-algorithms-experimentation/) `DoorDash` `2020`\n31. [Spotify\u2019s New Experimentation Platform (Part 1)](https://engineering.atspotify.com/2020/10/29/spotifys-new-experimentation-platform-part-1/) [(Part 2)](https://engineering.atspotify.com/2020/11/02/spotifys-new-experimentation-platform-part-2/) `Spotify` `2020`\n32. [Interpreting A/B Test Results: False Positives and Statistical Significance](https://netflixtechblog.com/interpreting-a-b-test-results-false-positives-and-statistical-significance-c1522d0db27a) `Netflix` `2021`\n33. [Interpreting A/B Test Results: False Negatives and Power](https://netflixtechblog.com/interpreting-a-b-test-results-false-negatives-and-power-6943995cf3a8) `Netflix` `2021`\n34. [Running Experiments with Google Adwords for Campaign Optimization](https://doordash.engineering/2021/02/05/google-adwords-campaign-optimization/) `DoorDash` `2021`\n35. [The 4 Principles DoorDash Used to Increase Its Logistics Experiment Capacity by 1000%](https://doordash.engineering/2021/09/21/the-4-principles-doordash-used-to-increase-its-logistics-experiment-capacity-by-1000/) `DoorDash` `2021`\n36. [Experimentation Platform at Zalando: Part 1 - Evolution](https://engineering.zalando.com/posts/2021/01/experimentation-platform-part1.html) `Zalando` `2021`\n37. [Designing Experimentation Guardrails](https://medium.com/airbnb-engineering/designing-experimentation-guardrails-ed6a976ec669) `Airbnb` `2021`\n38. [How Airbnb Measures Future Value to Standardize Tradeoffs](https://medium.com/airbnb-engineering/how-airbnb-measures-future-value-to-standardize-tradeoffs-3aa99a941ba5) `Airbnb` `2021`\n38. [Network Experimentation at Scale](https://research.fb.com/publications/network-experimentation-at-scale/)([Paper](https://arxiv.org/abs/2012.08591)] `Facebook` `2021`\n39. [Universal Holdout Groups at Disney Streaming](https://medium.com/disney-streaming/universal-holdout-groups-at-disney-streaming-2043360def4f) `Disney` `2021`\n40. [Experimentation is a major focus of Data Science across Netflix](https://netflixtechblog.com/experimentation-is-a-major-focus-of-data-science-across-netflix-f67923f8e985) `Netflix` `2022`\n41. [Search Journey Towards Better Experimentation Practices](https://engineering.atspotify.com/2022/02/search-journey-towards-better-experimentation-practices/) `Spotify` `2022`\n42. [Artificial Counterfactual Estimation: Machine Learning-Based Causal Inference at Airbnb](https://medium.com/airbnb-engineering/artificial-counterfactual-estimation-ace-machine-learning-based-causal-inference-at-airbnb-ee32ee4d0512) `Airbnb` `2022`\n43. [Challenges in Experimentation](https://eng.lyft.com/challenges-in-experimentation-be9ab98a7ef4) `Lyft` `2022`\n44. [Overtracking and Trigger Analysis: Reducing sample sizes while INCREASING sensitivity](https://booking.ai/overtracking-and-trigger-analysis-how-to-reduce-sample-sizes-and-increase-the-sensitivity-of-71755bad0e5f) `Booking` `2022`\n45. [Meet Dash-AB \u2014 The Statistics Engine of Experimentation at DoorDash](https://doordash.engineering/2022/05/24/meet-dash-ab-the-statistics-engine-of-experimentation-at-doordash/) `DoorDash` `2022`\n46. [Comparing quantiles at scale in online A/B-testing](https://engineering.atspotify.com/2022/03/comparing-quantiles-at-scale-in-online-a-b-testing) `Spotify` `2022`\n\n## Model Management\n1. [Operationalizing Machine Learning\u2014Managing Provenance from Raw Data to Predictions](https://vimeo.com/274396495) `Comcast` `2018`\n2. [Overton: A Data System for Monitoring and Improving Machine-Learned Products](https://arxiv.org/abs/1909.05372) ([Paper](https://arxiv.org/pdf/1909.05372.pdf)) `Apple` `2019`\n3. [Runway - Model Lifecycle Management at Netflix](https://www.usenix.org/conference/opml20/presentation/cepoi) `Netflix` `2020`\n4. [Managing ML Models @ Scale - Intuit\u2019s ML Platform](https://www.usenix.org/conference/opml20/presentation/wenzel) `Intuit` `2020`\n5. [ML Model Monitoring - 9 Tips From the Trenches](https://building.nubank.com.br/ml-model-monitoring-9-tips-from-the-trenches/) `Nubank` `2021`\n\n## Efficiency\n1. [GrokNet: Unified Computer Vision Model Trunk and Embeddings For Commerce](https://ai.facebook.com/research/publications/groknet-unified-computer-vision-model-trunk-and-embeddings-for-commerce/) ([Paper](https://scontent-sea1-1.xx.fbcdn.net/v/t39.8562-6/99353320_565175057533429_3886205100842024960_n.pdf?_nc_cat=110&_nc_sid=ae5e01&_nc_ohc=WQBaZy1gnmUAX8Ecqtt&_nc_ht=scontent-sea1-1.xx&oh=cab2f11dd9154d817149cb73e8b692a8&oe=5F5A3778)) `Facebook` `2020`\n2. [How We Scaled Bert To Serve 1+ Billion Daily Requests on CPUs](https://blog.roblox.com/2020/05/scaled-bert-serve-1-billion-daily-requests-cpus/) `Roblox` `2020`\n3. [Permute, Quantize, and Fine-tune: Efficient Compression of Neural Networks](https://arxiv.org/abs/2010.15703) ([Paper](https://arxiv.org/pdf/2010.15703.pdf)) `Uber` `2021`\n\n## Ethics\n1. [Building Inclusive Products Through A/B Testing](https://engineering.linkedin.com/blog/2020/building-inclusive-products-through-a-b-testing) ([Paper](https://arxiv.org/pdf/2002.05819.pdf)) `LinkedIn` `2020`\n2. [LiFT: A Scalable Framework for Measuring Fairness in ML Applications](https://engineering.linkedin.com/blog/2020/lift-addressing-bias-in-large-scale-ai-applications) ([Paper](https://arxiv.org/pdf/2008.07433.pdf)) `LinkedIn` `2020`\n3. [Introducing Twitter\u2019s first algorithmic bias bounty challenge](https://blog.twitter.com/engineering/en_us/topics/insights/2021/algorithmic-bias-bounty-challenge) `Twitter` `2021`\n3. [Examining algorithmic amplification of political content on Twitter](https://blog.twitter.com/en_us/topics/company/2021/rml-politicalcontent) `Twitter` `2021`\n3. [A closer look at how LinkedIn integrates fairness into its AI products](https://engineering.linkedin.com/blog/2022/a-closer-look-at-how-linkedin-integrates-fairness-into-its-ai-pr) `LinkedIn` `2022`\n\n## Infra\n1. [Reengineering Facebook AI\u2019s Deep Learning Platforms for Interoperability](https://ai.facebook.com/blog/reengineering-facebook-ais-deep-learning-platforms-for-interoperability) `Facebook` `2020`\n2. [Elastic Distributed Training with XGBoost on Ray](https://eng.uber.com/elastic-xgboost-ray/) `Uber` `2021`\n\n## MLOps Platforms\n1. [Meet Michelangelo: Uber\u2019s Machine Learning Platform](https://eng.uber.com/michelangelo-machine-learning-platform/) `Uber` `2017`\n2. [Operationalizing Machine Learning\u2014Managing Provenance from Raw Data to Predictions](https://vimeo.com/274396495) `Comcast` `2018`\n3. [Big Data Machine Learning Platform at Pinterest](https://www.slideshare.net/Alluxio/pinterest-big-data-machine-learning-platform-at-pinterest) `Pinterest` `2019`\n4. [Core Modeling at Instagram](https://instagram-engineering.com/core-modeling-at-instagram-a51e0158aa48) `Instagram` `2019`\n5. [Open-Sourcing Metaflow - a Human-Centric Framework for Data Science](https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9) `Netflix` `2019`\n6. [Managing ML Models @ Scale - Intuit\u2019s ML Platform](https://www.usenix.org/conference/opml20/presentation/wenzel) `Intuit` `2020`\n7. [Real-time Machine Learning Inference Platform at Zomato](https://www.youtube.com/watch?v=0-3ES1vzW14) `Zomato` `2020`\n8. [Introducing Flyte: Cloud Native Machine Learning and Data Processing Platform](https://eng.lyft.com/introducing-flyte-cloud-native-machine-learning-and-data-processing-platform-fb2bb3046a59) `Lyft` `2020`\n9. [Building Flexible Ensemble ML Models with a Computational Graph](https://doordash.engineering/2021/01/26/computational-graph-machine-learning-ensemble-model-support/) `DoorDash` `2021`\n10. [LyftLearn: ML Model Training Infrastructure built on Kubernetes](https://eng.lyft.com/lyftlearn-ml-model-training-infrastructure-built-on-kubernetes-aef8218842bb) `Lyft` `2021`\n11. [\"You Don't Need a Bigger Boat\": A Full Data Pipeline Built with Open-Source Tools](https://github.com/jacopotagliabue/you-dont-need-a-bigger-boat) ([Paper](https://arxiv.org/abs/2107.07346)) `Coveo` `2021`\n12. [MLOps at GreenSteam: Shipping Machine Learning](https://neptune.ai/blog/mlops-at-greensteam-shipping-machine-learning-case-study) `GreenSteam` `2021`\n13. [Evolving Reddit\u2019s ML Model Deployment and Serving Architecture](https://www.reddit.com/r/RedditEng/comments/q14tsw/evolving_reddits_ml_model_deployment_and_serving/) `Reddit` `2021`\n14. [Redesigning Etsy\u2019s Machine Learning Platform](https://www.etsy.com/codeascraft/redesigning-etsys-machine-learning-platform/) `Etsy` `2021`\n15. [Building a Platform for Serving Recommendations at Etsy](https://www.etsy.com/codeascraft/building-a-platform-for-serving-recommendations-at-etsy) `Etsy` `2022` \n16. [Intelligent Automation Platform: Empowering Conversational AI and Beyond at Airbnb](https://medium.com/airbnb-engineering/intelligent-automation-platform-empowering-conversational-ai-and-beyond-at-airbnb-869c44833ff2) `Airbnb` `2022`\n17. [DARWIN: Data Science and Artificial Intelligence Workbench at LinkedIn](https://engineering.linkedin.com/blog/2022/darwin--data-science-and-artificial-intelligence-workbench-at-li) `LinkedIn` `2022`\n18. [The Magic of Merlin: Shopify's New Machine Learning Platform](https://shopify.engineering/merlin-shopify-machine-learning-platform) `Shopify` `2022`\n19. [Zalando's Machine Learning Platform](https://engineering.zalando.com/posts/2022/04/zalando-machine-learning-platform.html) `Zalando` `2022`\n20. [Inside Meta's AI optimization platform for engineers across the company](https://ai.facebook.com/blog/looper-meta-ai-optimization-platform-for-engineers/) ([Paper](https://arxiv.org/pdf/2110.07554.pdf)) `Meta` `2022`\n21. [Monzo\u2019s machine learning stack](https://monzo.com/blog/2022/04/26/monzos-machine-learning-stack) `Monzo` `2022`\n22. [Evolution of ML Fact Store](https://netflixtechblog.com/evolution-of-ml-fact-store-5941d3231762) `Netflix` `2022`\n23. [Deployment for Free: A Machine Learning Platform for Stitch Fix's Data Scientists](https://multithreaded.stitchfix.com/blog/2022/07/14/deployment-for-free/) `Stitch Fix`\n\n## Practices\n1. [Practical Recommendations for Gradient-Based Training of Deep Architectures](https://arxiv.org/abs/1206.5533) ([Paper](https://arxiv.org/pdf/1206.5533.pdf)) `Yoshua Bengio` `2012`\n2. [Machine Learning: The High Interest Credit Card of Technical Debt](https://research.google/pubs/pub43146/) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43146.pdf)) ([Paper](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)) `Google` `2014`\n3. [Rules of Machine Learning: Best Practices for ML Engineering](https://developers.google.com/machine-learning/guides/rules-of-ml) `Google` `2018`\n4. [On Challenges in Machine Learning Model Management](http://sites.computer.org/debull/A18dec/p5.pdf) `Amazon` `2018`\n5. [Machine Learning in Production: The Booking.com Approach](https://booking.ai/https-booking-ai-machine-learning-production-3ee8fe943c70) `Booking` `2019`\n6. [150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com](https://booking.ai/150-successful-machine-learning-models-6-lessons-learned-at-booking-com-681e09107bec) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3292500.3330744)) `Booking` `2019`\n7. [Successes and Challenges in Adopting Machine Learning at Scale at a Global Bank](https://www.youtube.com/watch?v=QYQKG5OcwEI) `Rabobank` `2019`\n8. [Challenges in Deploying Machine Learning: a Survey of Case Studies](https://arxiv.org/abs/2011.09926) ([Paper](https://arxiv.org/pdf/2011.09926.pdf)) `Cambridge` `2020`\n9. [Reengineering Facebook AI\u2019s Deep Learning Platforms for Interoperability](https://ai.facebook.com/blog/reengineering-facebook-ais-deep-learning-platforms-for-interoperability) `Facebook` `2020`\n10. [The problem with AI developer tools for enterprises](https://towardsdatascience.com/the-problem-with-ai-developer-tools-for-enterprises-and-what-ikea-has-to-do-with-it-b26277841661) `Databricks` `2020`\n11. [Continuous Integration and Deployment for Machine Learning Online Serving and Models](https://eng.uber.com/continuous-integration-deployment-ml/) `Uber` `2021`\n12. [Tuning Model Performance](https://eng.uber.com/tuning-model-performance/) `Uber` `2021`\n13. [Maintaining Machine Learning Model Accuracy Through Monitoring](https://doordash.engineering/2021/05/20/monitor-machine-learning-model-drift/) `DoorDash` `2021`\n14. [Building Scalable and Performant Marketing ML Systems at Wayfair](https://www.aboutwayfair.com/careers/tech-blog/building-scalable-and-performant-marketing-ml-systems-at-wayfair) `Wayfair` `2021`\n15. [Our approach to building transparent and explainable AI systems](https://engineering.linkedin.com/blog/2021/transparent-and-explainable-AI-systems) `LinkedIn` `2021`\n16. [5 Steps for Building Machine Learning Models for Business](https://shopify.engineering/building-business-machine-learning-models) `Shopify` `2021`\n17. [Data Is An Art, Not Just A Science\u2014And Storytelling Is The Key](https://shopifyengineering.myshopify.com/blogs/engineering/data-storytelling-shopify) `Shopify` `2022`\n\n## Team structure\n1. [Engineers Shouldn\u2019t Write ETL: A Guide to Building a High Functioning Data Science Department](https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/) `Stitch Fix` `2016`\n2. [Building The Analytics Team At Wish](https://medium.com/wish-engineering/scaling-analytics-at-wish-619eacb97d16) `Wish` `2018`\n3. [Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist](https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/) `Stitch Fix` `2019`\n4. [Cultivating Algorithms: How We Grow Data Science at Stitch Fix](https://cultivating-algos.stitchfix.com) `Stitch Fix`\n5. [Analytics at Netflix: Who We Are and What We Do](https://netflixtechblog.com/analytics-at-netflix-who-we-are-and-what-we-do-7d9c08fe6965) `Netflix` `2020`\n6. [Building a Data Team at a Mid-stage Startup: A Short Story](https://erikbern.com/2021/07/07/the-data-team-a-short-story.html) `Erikbern` `2021`\n7. [A Behind-the-Scenes Look at How Postman\u2019s Data Team Works](https://entrepreneurshandbook.co/a-behind-the-scenes-look-at-how-postmans-data-team-works-fded0b8bfc64) `Postman` `2021`\n8. [Data Scientist x Machine Learning Engineer Roles: How are they different? How are they alike?](https://building.nubank.com.br/data-scientist-x-machine-learning-engineer-roles-how-are-they-different-how-are-they-alike/) `Nubank` `2022`\n\n## Fails\n1. [When It Comes to Gorillas, Google Photos Remains Blind](https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/) `Google` `2018`\n2. [160k+ High School Students Will Graduate Only If a Model Allows Them to](http://positivelysemidefinite.com/2020/06/160k-students.html) `International Baccalaureate` `2020`\n3. [An Algorithm That \u2018Predicts\u2019 Criminality Based on a Face Sparks a Furor](https://www.wired.com/story/algorithm-predicts-criminality-based-face-sparks-furor/) `Harrisburg University` `2020`\n4. [It's Hard to Generate Neural Text From GPT-3 About Muslims](https://twitter.com/abidlabs/status/1291165311329341440) `OpenAI` `2020`\n5. [A British AI Tool to Predict Violent Crime Is Too Flawed to Use](https://www.wired.co.uk/article/police-violence-prediction-ndas) `United Kingdom` `2020`\n6. More in [awful-ai](https://github.com/daviddao/awful-ai)\n\n<br>\n\n**P.S., Want a summary of ML advancements?** Get up to speed with survey papers \ud83d\udc49[`ml-surveys`](https://github.com/eugeneyan/ml-surveys)\n",
	"data-mining data-science deep-learning deep-reinforcement-learning genetic-algorithm machine-learning machine-learning-from-scratch": "# Machine Learning From Scratch\n\n## About\nPython implementations of some of the fundamental Machine Learning models and algorithms from scratch.\n\nThe purpose of this project is not to produce as optimized and computationally efficient algorithms as possible\nbut rather to present the inner workings of them in a transparent and accessible way.\n\n## Table of Contents\n- [Machine Learning From Scratch](#machine-learning-from-scratch)\n  * [About](#about)\n  * [Table of Contents](#table-of-contents)\n  * [Installation](#installation)\n  * [Examples](#examples)\n    + [Polynomial Regression](#polynomial-regression)\n    + [Classification With CNN](#classification-with-cnn)\n    + [Density-Based Clustering](#density-based-clustering)\n    + [Generating Handwritten Digits](#generating-handwritten-digits)\n    + [Deep Reinforcement Learning](#deep-reinforcement-learning)\n    + [Image Reconstruction With RBM](#image-reconstruction-with-rbm)\n    + [Evolutionary Evolved Neural Network](#evolutionary-evolved-neural-network)\n    + [Genetic Algorithm](#genetic-algorithm)\n    + [Association Analysis](#association-analysis)\n  * [Implementations](#implementations)\n    + [Supervised Learning](#supervised-learning)\n    + [Unsupervised Learning](#unsupervised-learning)\n    + [Reinforcement Learning](#reinforcement-learning)\n    + [Deep Learning](#deep-learning)\n  * [Contact](#contact)\n\n## Installation\n    $ git clone https://github.com/eriklindernoren/ML-From-Scratch\n    $ cd ML-From-Scratch\n    $ python setup.py install\n\n## Examples\n### Polynomial Regression\n    $ python mlfromscratch/examples/polynomial_regression.py\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/p_reg.gif\" width=\"640\"\\>\n</p>\n<p align=\"center\">\n    Figure: Training progress of a regularized polynomial regression model fitting <br>\n    temperature data measured in Link\u00f6ping, Sweden 2016.\n</p>\n\n### Classification With CNN\n    $ python mlfromscratch/examples/convolutional_neural_network.py\n\n    +---------+\n    | ConvNet |\n    +---------+\n    Input Shape: (1, 8, 8)\n    +----------------------+------------+--------------+\n    | Layer Type           | Parameters | Output Shape |\n    +----------------------+------------+--------------+\n    | Conv2D               | 160        | (16, 8, 8)   |\n    | Activation (ReLU)    | 0          | (16, 8, 8)   |\n    | Dropout              | 0          | (16, 8, 8)   |\n    | BatchNormalization   | 2048       | (16, 8, 8)   |\n    | Conv2D               | 4640       | (32, 8, 8)   |\n    | Activation (ReLU)    | 0          | (32, 8, 8)   |\n    | Dropout              | 0          | (32, 8, 8)   |\n    | BatchNormalization   | 4096       | (32, 8, 8)   |\n    | Flatten              | 0          | (2048,)      |\n    | Dense                | 524544     | (256,)       |\n    | Activation (ReLU)    | 0          | (256,)       |\n    | Dropout              | 0          | (256,)       |\n    | BatchNormalization   | 512        | (256,)       |\n    | Dense                | 2570       | (10,)        |\n    | Activation (Softmax) | 0          | (10,)        |\n    +----------------------+------------+--------------+\n    Total Parameters: 538570\n\n    Training: 100% [------------------------------------------------------------------------] Time: 0:01:55\n    Accuracy: 0.987465181058\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/mlfs_cnn1.png\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Classification of the digit dataset using CNN.\n</p>\n\n### Density-Based Clustering\n    $ python mlfromscratch/examples/dbscan.py\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/mlfs_dbscan.png\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Clustering of the moons dataset using DBSCAN.\n</p>\n\n### Generating Handwritten Digits\n    $ python mlfromscratch/unsupervised_learning/generative_adversarial_network.py\n\n    +-----------+\n    | Generator |\n    +-----------+\n    Input Shape: (100,)\n    +------------------------+------------+--------------+\n    | Layer Type             | Parameters | Output Shape |\n    +------------------------+------------+--------------+\n    | Dense                  | 25856      | (256,)       |\n    | Activation (LeakyReLU) | 0          | (256,)       |\n    | BatchNormalization     | 512        | (256,)       |\n    | Dense                  | 131584     | (512,)       |\n    | Activation (LeakyReLU) | 0          | (512,)       |\n    | BatchNormalization     | 1024       | (512,)       |\n    | Dense                  | 525312     | (1024,)      |\n    | Activation (LeakyReLU) | 0          | (1024,)      |\n    | BatchNormalization     | 2048       | (1024,)      |\n    | Dense                  | 803600     | (784,)       |\n    | Activation (TanH)      | 0          | (784,)       |\n    +------------------------+------------+--------------+\n    Total Parameters: 1489936\n\n    +---------------+\n    | Discriminator |\n    +---------------+\n    Input Shape: (784,)\n    +------------------------+------------+--------------+\n    | Layer Type             | Parameters | Output Shape |\n    +------------------------+------------+--------------+\n    | Dense                  | 401920     | (512,)       |\n    | Activation (LeakyReLU) | 0          | (512,)       |\n    | Dropout                | 0          | (512,)       |\n    | Dense                  | 131328     | (256,)       |\n    | Activation (LeakyReLU) | 0          | (256,)       |\n    | Dropout                | 0          | (256,)       |\n    | Dense                  | 514        | (2,)         |\n    | Activation (Softmax)   | 0          | (2,)         |\n    +------------------------+------------+--------------+\n    Total Parameters: 533762\n\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/gan_mnist5.gif\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Training progress of a Generative Adversarial Network generating <br>\n    handwritten digits.\n</p>\n\n### Deep Reinforcement Learning\n    $ python mlfromscratch/examples/deep_q_network.py\n\n    +----------------+\n    | Deep Q-Network |\n    +----------------+\n    Input Shape: (4,)\n    +-------------------+------------+--------------+\n    | Layer Type        | Parameters | Output Shape |\n    +-------------------+------------+--------------+\n    | Dense             | 320        | (64,)        |\n    | Activation (ReLU) | 0          | (64,)        |\n    | Dense             | 130        | (2,)         |\n    +-------------------+------------+--------------+\n    Total Parameters: 450\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/mlfs_dql1.gif\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Deep Q-Network solution to the CartPole-v1 environment in OpenAI gym.\n</p>\n\n### Image Reconstruction With RBM\n    $ python mlfromscratch/examples/restricted_boltzmann_machine.py\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/rbm_digits1.gif\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Shows how the network gets better during training at reconstructing <br>\n    the digit 2 in the MNIST dataset.\n</p>\n\n### Evolutionary Evolved Neural Network\n    $ python mlfromscratch/examples/neuroevolution.py\n\n    +---------------+\n    | Model Summary |\n    +---------------+\n    Input Shape: (64,)\n    +----------------------+------------+--------------+\n    | Layer Type           | Parameters | Output Shape |\n    +----------------------+------------+--------------+\n    | Dense                | 1040       | (16,)        |\n    | Activation (ReLU)    | 0          | (16,)        |\n    | Dense                | 170        | (10,)        |\n    | Activation (Softmax) | 0          | (10,)        |\n    +----------------------+------------+--------------+\n    Total Parameters: 1210\n\n    Population Size: 100\n    Generations: 3000\n    Mutation Rate: 0.01\n\n    [0 Best Individual - Fitness: 3.08301, Accuracy: 10.5%]\n    [1 Best Individual - Fitness: 3.08746, Accuracy: 12.0%]\n    ...\n    [2999 Best Individual - Fitness: 94.08513, Accuracy: 98.5%]\n    Test set accuracy: 96.7%\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/evo_nn4.png\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Classification of the digit dataset by a neural network which has<br>\n    been evolutionary evolved.\n</p>\n\n### Genetic Algorithm\n    $ python mlfromscratch/examples/genetic_algorithm.py\n\n    +--------+\n    |   GA   |\n    +--------+\n    Description: Implementation of a Genetic Algorithm which aims to produce\n    the user specified target string. This implementation calculates each\n    candidate's fitness based on the alphabetical distance between the candidate\n    and the target. A candidate is selected as a parent with probabilities proportional\n    to the candidate's fitness. Reproduction is implemented as a single-point\n    crossover between pairs of parents. Mutation is done by randomly assigning\n    new characters with uniform probability.\n\n    Parameters\n    ----------\n    Target String: 'Genetic Algorithm'\n    Population Size: 100\n    Mutation Rate: 0.05\n\n    [0 Closest Candidate: 'CJqlJguPlqzvpoJmb', Fitness: 0.00]\n    [1 Closest Candidate: 'MCxZxdr nlfiwwGEk', Fitness: 0.01]\n    [2 Closest Candidate: 'MCxZxdm nlfiwwGcx', Fitness: 0.01]\n    [3 Closest Candidate: 'SmdsAklMHn kBIwKn', Fitness: 0.01]\n    [4 Closest Candidate: '  lotneaJOasWfu Z', Fitness: 0.01]\n    ...\n    [292 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]\n    [293 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]\n    [294 Answer: 'Genetic Algorithm']\n\n### Association Analysis\n    $ python mlfromscratch/examples/apriori.py\n    +-------------+\n    |   Apriori   |\n    +-------------+\n    Minimum Support: 0.25\n    Minimum Confidence: 0.8\n    Transactions:\n        [1, 2, 3, 4]\n        [1, 2, 4]\n        [1, 2]\n        [2, 3, 4]\n        [2, 3]\n        [3, 4]\n        [2, 4]\n    Frequent Itemsets:\n        [1, 2, 3, 4, [1, 2], [1, 4], [2, 3], [2, 4], [3, 4], [1, 2, 4], [2, 3, 4]]\n    Rules:\n        1 -> 2 (support: 0.43, confidence: 1.0)\n        4 -> 2 (support: 0.57, confidence: 0.8)\n        [1, 4] -> 2 (support: 0.29, confidence: 1.0)\n\n\n## Implementations\n### Supervised Learning\n- [Adaboost](mlfromscratch/supervised_learning/adaboost.py)\n- [Bayesian Regression](mlfromscratch/supervised_learning/bayesian_regression.py)\n- [Decision Tree](mlfromscratch/supervised_learning/decision_tree.py)\n- [Elastic Net](mlfromscratch/supervised_learning/regression.py)\n- [Gradient Boosting](mlfromscratch/supervised_learning/gradient_boosting.py)\n- [K Nearest Neighbors](mlfromscratch/supervised_learning/k_nearest_neighbors.py)\n- [Lasso Regression](mlfromscratch/supervised_learning/regression.py)\n- [Linear Discriminant Analysis](mlfromscratch/supervised_learning/linear_discriminant_analysis.py)\n- [Linear Regression](mlfromscratch/supervised_learning/regression.py)\n- [Logistic Regression](mlfromscratch/supervised_learning/logistic_regression.py)\n- [Multi-class Linear Discriminant Analysis](mlfromscratch/supervised_learning/multi_class_lda.py)\n- [Multilayer Perceptron](mlfromscratch/supervised_learning/multilayer_perceptron.py)\n- [Naive Bayes](mlfromscratch/supervised_learning/naive_bayes.py)\n- [Neuroevolution](mlfromscratch/supervised_learning/neuroevolution.py)\n- [Particle Swarm Optimization of Neural Network](mlfromscratch/supervised_learning/particle_swarm_optimization.py)\n- [Perceptron](mlfromscratch/supervised_learning/perceptron.py)\n- [Polynomial Regression](mlfromscratch/supervised_learning/regression.py)\n- [Random Forest](mlfromscratch/supervised_learning/random_forest.py)\n- [Ridge Regression](mlfromscratch/supervised_learning/regression.py)\n- [Support Vector Machine](mlfromscratch/supervised_learning/support_vector_machine.py)\n- [XGBoost](mlfromscratch/supervised_learning/xgboost.py)\n\n### Unsupervised Learning\n- [Apriori](mlfromscratch/unsupervised_learning/apriori.py)\n- [Autoencoder](mlfromscratch/unsupervised_learning/autoencoder.py)\n- [DBSCAN](mlfromscratch/unsupervised_learning/dbscan.py)\n- [FP-Growth](mlfromscratch/unsupervised_learning/fp_growth.py)\n- [Gaussian Mixture Model](mlfromscratch/unsupervised_learning/gaussian_mixture_model.py)\n- [Generative Adversarial Network](mlfromscratch/unsupervised_learning/generative_adversarial_network.py)\n- [Genetic Algorithm](mlfromscratch/unsupervised_learning/genetic_algorithm.py)\n- [K-Means](mlfromscratch/unsupervised_learning/k_means.py)\n- [Partitioning Around Medoids](mlfromscratch/unsupervised_learning/partitioning_around_medoids.py)\n- [Principal Component Analysis](mlfromscratch/unsupervised_learning/principal_component_analysis.py)\n- [Restricted Boltzmann Machine](mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py)\n\n### Reinforcement Learning\n- [Deep Q-Network](mlfromscratch/reinforcement_learning/deep_q_network.py)\n\n### Deep Learning\n  + [Neural Network](mlfromscratch/deep_learning/neural_network.py)\n  + [Layers](mlfromscratch/deep_learning/layers.py)\n    * Activation Layer\n    * Average Pooling Layer\n    * Batch Normalization Layer\n    * Constant Padding Layer\n    * Convolutional Layer\n    * Dropout Layer\n    * Flatten Layer\n    * Fully-Connected (Dense) Layer\n    * Fully-Connected RNN Layer\n    * Max Pooling Layer\n    * Reshape Layer\n    * Up Sampling Layer\n    * Zero Padding Layer\n  + Model Types\n    * [Convolutional Neural Network](mlfromscratch/examples/convolutional_neural_network.py)\n    * [Multilayer Perceptron](mlfromscratch/examples/multilayer_perceptron.py)\n    * [Recurrent Neural Network](mlfromscratch/examples/recurrent_neural_network.py)\n\n## Contact\nIf there's some implementation you would like to see here or if you're just feeling social,\nfeel free to [email](mailto:eriklindernoren@gmail.com) me or connect with me on [LinkedIn](https://www.linkedin.com/in/eriklindernoren/).\n",
	"data-analysis data-science data-visualization deep-learning developer-tools machine-learning python streamlit": "# Welcome to Streamlit :wave:\n\n**The fastest way to build and share data apps.**\n\nStreamlit lets you turn data scripts into shareable web apps in minutes, not weeks. It\u2019s all Python, open-source, and free! And once you\u2019ve created an app you can use our\u00a0[Community Cloud platform](https://streamlit.io/cloud)\u00a0to deploy, manage, and share your app!\n\n![Example of live coding an app in Streamlit|635x380](https://raw.githubusercontent.com/streamlit/docs/main/public/images/Streamlit_overview.gif)\n\n## Installation\n\n```bash\npip install streamlit\nstreamlit hello\n```\n\nStreamlit can also be installed in a virtual environment on [Windows](https://github.com/streamlit/streamlit/wiki/Installing-in-a-virtual-environment#on-windows), [Mac](https://github.com/streamlit/streamlit/wiki/Installing-in-a-virtual-environment#on-mac--linux), and [Linux](https://github.com/streamlit/streamlit/wiki/Installing-in-a-virtual-environment#on-mac--linux).\n\n## A little example\n\nStreamlit makes it incredibly easy to build interactive apps:\n\n```python\nimport streamlit as st\n\nx = st.slider('Select a value')\nst.write(x, 'squared is', x * x)\n```\n\n<img src=\"https://raw.githubusercontent.com/streamlit/docs/main/public/images/simple_example.png\"/>\n\n## A bigger example\n\nStreamlit's simple and focused API lets you build incredibly rich and powerful tools.\u00a0 [This demo project](https://github.com/streamlit/demo-self-driving) lets you browse the entire [Udacity self-driving-car dataset](https://github.com/udacity/self-driving-car) and run inference in real-time using the [YOLO object detection net](https://pjreddie.com/darknet/yolo).\n\n![Final App Animation](https://raw.githubusercontent.com/streamlit/docs/main/public/images/complex_app_example.gif)\n\nThe complete demo is implemented in less than 300 lines of Python. In fact, the app contains [only 23 Streamlit calls](https://github.com/streamlit/demo-self-driving/blob/master/streamlit_app.py) which illustrates all the major building blocks of Streamlit. You can try it right now at [share.streamlit.io/streamlit/demo-self-driving](https://share.streamlit.io/streamlit/demo-self-driving).\n\n## The Streamlit GitHub badge\n\nStreamlit's GitHub badge helps others find and play with your Streamlit app.\n\n[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io/streamlit/demo-face-gan)\n\nOnce you deploy your app, you can embed this badge right into your GitHub readme.md as follows:\n\n```markdown\n[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io/yourGitHubName/yourRepo/yourApp/)\n```\n\n## More Information\n\n- Our [launch post](https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace?source=friends_link&sk=f7774c54571148b33cde3ba6c6310086) explaining why we created Streamlit\n- Our [Community Cloud platform announcement](https://blog.streamlit.io/introducing-streamlit-cloud)\n- Our amazing [community](https://discuss.streamlit.io/) where Streamlit users share apps, ask questions, and help each other out\n- Streamlit [documentation](https://docs.streamlit.io/) and [blog](https://blog.streamlit.io) for the latest Streamlit info\n- More [demo projects](https://github.com/streamlit/) to inspire you\n- And if you would like to contribute, see [instructions here](https://github.com/streamlit/streamlit/wiki/Contributing)\n\n## Community Cloud\n\nWith [Community Cloud](https://streamlit.io/cloud) you can deploy, manage, and share your apps with the world, directly from Streamlit \u2014 all for free. Sign-up [here](https://share.streamlit.io/signup).\n\n## License\n\nStreamlit is completely free and open-source and licensed under the [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0) license.\n",
	"ai artificial-intelligence data-science deep-learning machine-learning python pytorch": "### \\*\\* NEWS: PyTorch Lightning has been renamed Lightning! In addition to building models, you can now build lightning apps that glue together everything around the models, without the pain of infrastructure, cost management, scaling and everything else.\\*\\*\n\n<div align=\"center\">\n<img src=\"https://pl-flash-data.s3.amazonaws.com/assets_lightning/docs/images/logos/lightning-ai.png\" width=\"400px\">\n\n**Build and train PyTorch models and connect them to the ML lifecycle using Lightning App templates, without handling DIY infrastructure, cost management, scaling, and other headaches.**\n\n______________________________________________________________________\n\n<p align=\"center\">\n  <a href=\"https://www.lightning.ai/\">Lightning Gallery</a> \u2022\n  <a href=\"#key-features\">Key Features</a> \u2022\n  <a href=\"#how-to-use\">How To Use</a> \u2022\n  <a href=\"https://pytorch-lightning.readthedocs.io/en/stable/\">Docs</a> \u2022\n  <a href=\"#examples\">Examples</a> \u2022\n  <a href=\"#community\">Community</a> \u2022\n  <a href=\"https://pytorch-lightning.readthedocs.io/en/stable/generated/CONTRIBUTING.html\">Contribute</a> \u2022\n  <a href=\"#license\">License</a>\n</p>\n\n<!-- DO NOT ADD CONDA DOWNLOADS... README CHANGES MUST BE APPROVED BY EDEN OR WILL -->\n\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pytorch-lightning)](https://pypi.org/project/pytorch-lightning/)\n[![PyPI Status](https://badge.fury.io/py/pytorch-lightning.svg)](https://badge.fury.io/py/pytorch-lightning)\n[![PyPI Status](https://pepy.tech/badge/pytorch-lightning)](https://pepy.tech/project/pytorch-lightning)\n[![Conda](https://img.shields.io/conda/v/conda-forge/pytorch-lightning?label=conda&color=success)](https://anaconda.org/conda-forge/pytorch-lightning)\n[![DockerHub](https://img.shields.io/docker/pulls/pytorchlightning/pytorch_lightning.svg)](https://hub.docker.com/r/pytorchlightning/pytorch_lightning)\n[![codecov](https://codecov.io/gh/Lightning-AI/lightning/branch/master/graph/badge.svg?token=SmzX8mnKlA)](https://codecov.io/gh/Lightning-AI/lightning)\n\n[![ReadTheDocs](https://readthedocs.org/projects/pytorch-lightning/badge/?version=stable)](https://pytorch-lightning.readthedocs.io/en/stable/)\n[![Slack](https://img.shields.io/badge/slack-chat-green.svg?logo=slack)](https://www.pytorchlightning.ai/community)\n[![license](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/Lightning-AI/lightning/blob/master/LICENSE)\n\n<!--\n[![CodeFactor](https://www.codefactor.io/repository/github/Lightning-AI/lightning/badge)](https://www.codefactor.io/repository/github/Lightning-AI/lightning)\n-->\n\n</div>\n\n###### \\*Codecov is > 90%+ but build delays may show less\n\n______________________________________________________________________\n\n## PyTorch Lightning is just organized PyTorch\n\nLightning disentangles PyTorch code to decouple the science from the engineering.\n![PT to PL](docs/source-pytorch/_static/images/general/pl_quick_start_full_compressed.gif)\n\n## Build AI products with Lightning Apps\n\nOnce you're done building models, publish a paper demo or build a full production end-to-end ML system with Lightning Apps. Lightning Apps remove the cloud infrastructure boilerplate so you can focus on solving the research or business problems. Lightning Apps can run on the Lightning Cloud, your own cluster or a private cloud.\n\n[Browse available Lightning apps here](https://lightning.ai/)\n\n<div align=\"center\">\n    <img src=\"https://pl-flash-data.s3.amazonaws.com/assets_lightning/docs/images/logos/lightning-apps-teaser.png\" width=\"80%\">\n</div>\n\n### [Learn more about Lightning Apps](src/lightning_app/README.md)\n\n______________________________________________________________________\n\n## Lightning Design Philosophy\n\nLightning structures PyTorch code with these principles:\n\n<div align=\"center\">\n  <img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/philosophies.jpg\" max-height=\"250px\">\n</div>\n\nLightning forces the following structure to your code which makes it reusable and shareable:\n\n- Research code (the LightningModule).\n- Engineering code (you delete, and is handled by the Trainer).\n- Non-essential research code (logging, etc... this goes in Callbacks).\n- Data (use PyTorch DataLoaders or organize them into a LightningDataModule).\n\nOnce you do this, you can train on multiple-GPUs, TPUs, CPUs and even in 16-bit precision without changing your code!\n\n[Get started in just 15 minutes](https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html)\n\n______________________________________________________________________\n\n## Continuous Integration\n\nLightning is rigorously tested across multiple CPUs, GPUs, TPUs, IPUs, and HPUs and against major Python and PyTorch versions.\n\n<details>\n  <summary>Current build statuses</summary>\n\n<center>\n\n|   System / PyTorch ver.    |                                                                                                              1.10                                                                                                               |                                                                                                       1.12                                                                                                       |\n| :------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\n|  Linux py3.7 \\[GPUs\\*\\*\\]  |                                                                                                                -                                                                                                                |                                                                                                        -                                                                                                         |\n| Linux py3.7 \\[TPUs\\*\\*\\*\\] |                                                                                                                -                                                                                                                |                                                                                                        -                                                                                                         |\n|    Linux py3.8 \\[IPUs\\]    |                                                                                                                -                                                                                                                |                                                                                                        -                                                                                                         |\n|    Linux py3.8 \\[HPUs\\]    | [![Build Status](<https://dev.azure.com/Lightning-AI/lightning/_apis/build/status/pytorch-lightning%20(HPUs)?branchName=master>)](https://dev.azure.com/Lightning-AI/lightning/_build/latest?definitionId=26&branchName=master) |                                                                                                        -                                                                                                         |\n|      Linux py3.{7,9}       |                                                                                                                -                                                                                                                | [![Test](https://github.com/Lightning-AI/lightning/actions/workflows/ci-pytorch-tests.yml/badge.svg?branch=master&event=push)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-pytorch-tests.yml) |\n|       OSX py3.{7,9}        |                                                                                                                -                                                                                                                | [![Test](https://github.com/Lightning-AI/lightning/actions/workflows/ci-pytorch-tests.yml/badge.svg?branch=master&event=push)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-pytorch-tests.yml) |\n|     Windows py3.{7,9}      |                                                                                                                -                                                                                                                | [![Test](https://github.com/Lightning-AI/lightning/actions/workflows/ci-pytorch-tests.yml/badge.svg?branch=master&event=push)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-pytorch-tests.yml) |\n\n- _\\*\\* tests run on two NVIDIA P100_\n- _\\*\\*\\* tests run on Google GKE TPUv2/3. TPU py3.7 means we support Colab and Kaggle env._\n\n</center>\n</details>\n\n______________________________________________________________________\n\n## How To Use\n\n### Step 0: Install\n\nSimple installation from PyPI\n\n```bash\npip install pytorch-lightning\n```\n\n<!-- following section will be skipped from PyPI description -->\n\n<details>\n  <summary>Other installation options</summary>\n    <!-- following section will be skipped from PyPI description -->\n\n#### Install with optional dependencies\n\n```bash\npip install pytorch-lightning['extra']\n```\n\n#### Conda\n\n```bash\nconda install pytorch-lightning -c conda-forge\n```\n\n#### Install stable version\n\nInstall future release from the source\n\n```bash\npip install https://github.com/Lightning-AI/lightning/archive/refs/heads/release/stable.zip -U\n```\n\n#### Install bleeding-edge\n\nInstall nightly from the source (no guarantees)\n\n```bash\npip install https://github.com/Lightning-AI/lightning/archive/refs/heads/master.zip -U\n```\n\nor from testing PyPI\n\n```bash\npip install -iU https://test.pypi.org/simple/ pytorch-lightning\n```\n\n</details>\n<!-- end skipping PyPI description -->\n\n### Step 1: Add these imports\n\n```python\nimport os\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import transforms\nimport pytorch_lightning as pl\n```\n\n### Step 2: Define a LightningModule (nn.Module subclass)\n\nA LightningModule defines a full *system* (ie: a GAN, autoencoder, BERT or a simple Image Classifier).\n\n```python\nclass LitAutoEncoder(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))\n        self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))\n\n    def forward(self, x):\n        # in lightning, forward defines the prediction/inference actions\n        embedding = self.encoder(x)\n        return embedding\n\n    def training_step(self, batch, batch_idx):\n        # training_step defines the train loop. It is independent of forward\n        x, y = batch\n        x = x.view(x.size(0), -1)\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        loss = F.mse_loss(x_hat, x)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer\n```\n\n**Note: Training_step defines the training loop. Forward defines how the LightningModule behaves during inference/prediction.**\n\n### Step 3: Train!\n\n```python\ndataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\ntrain, val = random_split(dataset, [55000, 5000])\n\nautoencoder = LitAutoEncoder()\ntrainer = pl.Trainer()\ntrainer.fit(autoencoder, DataLoader(train), DataLoader(val))\n```\n\n## Advanced features\n\nLightning has over [40+ advanced features](https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-flags) designed for professional AI research at scale.\n\nHere are some examples:\n\n<div align=\"center\">\n  <img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/features_2.jpg\" max-height=\"600px\">\n</div>\n\n<details>\n  <summary>Highlighted feature code snippets</summary>\n\n```python\n# 8 GPUs\n# no code changes needed\ntrainer = Trainer(max_epochs=1, accelerator=\"gpu\", devices=8)\n\n# 256 GPUs\ntrainer = Trainer(max_epochs=1, accelerator=\"gpu\", devices=8, num_nodes=32)\n```\n\n<summary>Train on TPUs without code changes</summary>\n\n```python\n# no code changes needed\ntrainer = Trainer(accelerator=\"tpu\", devices=8)\n```\n\n<summary>16-bit precision</summary>\n\n```python\n# no code changes needed\ntrainer = Trainer(precision=16)\n```\n\n<summary>Experiment managers</summary>\n\n```python\nfrom pytorch_lightning import loggers\n\n# tensorboard\ntrainer = Trainer(logger=TensorBoardLogger(\"logs/\"))\n\n# weights and biases\ntrainer = Trainer(logger=loggers.WandbLogger())\n\n# comet\ntrainer = Trainer(logger=loggers.CometLogger())\n\n# mlflow\ntrainer = Trainer(logger=loggers.MLFlowLogger())\n\n# neptune\ntrainer = Trainer(logger=loggers.NeptuneLogger())\n\n# ... and dozens more\n```\n\n<summary>EarlyStopping</summary>\n\n```python\nes = EarlyStopping(monitor=\"val_loss\")\ntrainer = Trainer(callbacks=[es])\n```\n\n<summary>Checkpointing</summary>\n\n```python\ncheckpointing = ModelCheckpoint(monitor=\"val_loss\")\ntrainer = Trainer(callbacks=[checkpointing])\n```\n\n<summary>Export to torchscript (JIT) (production use)</summary>\n\n```python\n# torchscript\nautoencoder = LitAutoEncoder()\ntorch.jit.save(autoencoder.to_torchscript(), \"model.pt\")\n```\n\n<summary>Export to ONNX (production use)</summary>\n\n```python\n# onnx\nwith tempfile.NamedTemporaryFile(suffix=\".onnx\", delete=False) as tmpfile:\n    autoencoder = LitAutoEncoder()\n    input_sample = torch.randn((1, 64))\n    autoencoder.to_onnx(tmpfile.name, input_sample, export_params=True)\n    os.path.isfile(tmpfile.name)\n```\n\n</details>\n\n### Pro-level control of training loops (advanced users)\n\nFor complex/professional level work, you have optional full control of the training loop and optimizers.\n\n```python\nclass LitAutoEncoder(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.automatic_optimization = False\n\n    def training_step(self, batch, batch_idx):\n        # access your optimizers with use_pl_optimizer=False. Default is True\n        opt_a, opt_b = self.optimizers(use_pl_optimizer=True)\n\n        loss_a = ...\n        self.manual_backward(loss_a, opt_a)\n        opt_a.step()\n        opt_a.zero_grad()\n\n        loss_b = ...\n        self.manual_backward(loss_b, opt_b, retain_graph=True)\n        self.manual_backward(loss_b, opt_b)\n        opt_b.step()\n        opt_b.zero_grad()\n```\n\n______________________________________________________________________\n\n## Advantages over unstructured PyTorch\n\n- Models become hardware agnostic\n- Code is clear to read because engineering code is abstracted away\n- Easier to reproduce\n- Make fewer mistakes because lightning handles the tricky engineering\n- Keeps all the flexibility (LightningModules are still PyTorch modules), but removes a ton of boilerplate\n- Lightning has dozens of integrations with popular machine learning tools.\n- [Tested rigorously with every new PR](https://github.com/Lightning-AI/lightning/tree/master/tests). We test every combination of PyTorch and Python supported versions, every OS, multi GPUs and even TPUs.\n- Minimal running speed overhead (about 300 ms per epoch compared with pure PyTorch).\n\n______________________________________________________________________\n\n## Lightning Lite\n\n<div align=\"center\">\n  <img src=\"docs/source-pytorch/_static/images/lightning_lite/lite.gif\" height=\"200px\" width=\"600px\">\n</div>\n\nIn the Lightning v1.5 release, LightningLite now enables you to leverage all the capabilities of PyTorch Lightning Accelerators without any refactoring to your training loop. Check out the\n[blogpost](https://devblog.pytorchlightning.ai/scale-your-pytorch-code-with-lightninglite-d5692a303f00) and\n[docs](https://pytorch-lightning.readthedocs.io/en/stable/starter/lightning_lite.html) for more info.\n\n______________________________________________________________________\n\n## Examples\n\n###### Hello world\n\n- [MNIST hello world](https://pytorch-lightning.readthedocs.io/en/latest/notebooks/lightning_examples/mnist-hello-world.html)\n\n###### Contrastive Learning\n\n- [BYOL](https://lightning-bolts.readthedocs.io/en/stable/deprecated/models/self_supervised.html#byol)\n- [CPC v2](https://lightning-bolts.readthedocs.io/en/stable/deprecated/models/self_supervised.html#cpc-v2)\n- [Moco v2](https://lightning-bolts.readthedocs.io/en/stable/deprecated/models/self_supervised.html#moco-v2-api)\n- [SIMCLR](https://lightning-bolts.readthedocs.io/en/stable/deprecated/models/self_supervised.html#simclr)\n\n###### NLP\n\n- [GPT-2](https://lightning-bolts.readthedocs.io/en/stable/deprecated/models/convolutional.html#gpt-2)\n- [BERT](https://pytorch-lightning.readthedocs.io/en/latest/notebooks/lightning_examples/text-transformers.html)\n\n###### Reinforcement Learning\n\n- [DQN](https://lightning-bolts.readthedocs.io/en/stable/deprecated/models/reinforce_learn.html#dqn-models)\n- [Dueling-DQN](https://lightning-bolts.readthedocs.io/en/stable/deprecated/models/reinforce_learn.html#dueling-dqn)\n- [Reinforce](https://lightning-bolts.readthedocs.io/en/stable/deprecated/models/reinforce_learn.html#reinforce)\n\n###### Vision\n\n- [GAN](https://pytorch-lightning.readthedocs.io/en/latest/notebooks/lightning_examples/basic-gan.html)\n\n###### Classic ML\n\n- [Logistic Regression](https://lightning-bolts.readthedocs.io/en/stable/deprecated/models/classic_ml.html#logistic-regression)\n- [Linear Regression](https://lightning-bolts.readthedocs.io/en/stable/deprecated/models/classic_ml.html#linear-regression)\n\n______________________________________________________________________\n\n## Community\n\nThe lightning community is maintained by\n\n- [10+ core contributors](https://pytorch-lightning.readthedocs.io/en/latest/governance.html) who are all a mix of professional engineers, Research Scientists, and Ph.D. students from top AI labs.\n- 590+ active community contributors.\n\nWant to help us build Lightning and reduce boilerplate for thousands of researchers? [Learn how to make your first contribution here](https://pytorch-lightning.readthedocs.io/en/stable/generated/CONTRIBUTING.html)\n\nLightning is also part of the [PyTorch ecosystem](https://pytorch.org/ecosystem/) which requires projects to have solid testing, documentation and support.\n\n### Asking for help\n\nIf you have any questions please:\n\n1. [Read the docs](https://pytorch-lightning.rtfd.io/en/latest).\n1. [Search through existing Discussions](https://github.com/Lightning-AI/lightning/discussions), or [add a new question](https://github.com/Lightning-AI/lightning/discussions/new)\n1. [Join our slack](https://www.pytorchlightning.ai/community).\n",
	"bioinformatics charting dash data-science data-visualization finance flask gui-framework julia jupyter modeling plotly plotly-dash productivity python r react rstats technical-computing web-app": "# Dash\n\n[![CircleCI](https://img.shields.io/circleci/project/github/plotly/dash/master.svg)](https://circleci.com/gh/plotly/dash)\n[![GitHub](https://img.shields.io/github/license/plotly/dash.svg?color=dark-green)](https://github.com/plotly/dash/blob/master/LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/dash.svg?color=dark-green)](https://pypi.org/project/dash/)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/dash.svg?color=dark-green)](https://pypi.org/project/dash/)\n[![GitHub commit activity](https://img.shields.io/github/commit-activity/y/plotly/dash.svg?color=dark-green)](https://github.com/plotly/dash/graphs/contributors)\n[![LGTM Alerts](https://img.shields.io/lgtm/alerts/g/plotly/dash.svg)](https://lgtm.com/projects/g/plotly/dash/alerts)\n[![LGTM Grade](https://img.shields.io/lgtm/grade/python/g/plotly/dash.svg)](https://lgtm.com/projects/g/plotly/dash/context:python)\n\n#### *Dash is the most downloaded, trusted Python framework for building ML & data science web apps*.\n\nBuilt on top of [Plotly.js](https://github.com/plotly/plotly.js), [React](https://reactjs.org/) and [Flask](https://palletsprojects.com/p/flask/), Dash ties modern UI elements like dropdowns, sliders, and graphs directly to your analytical Python code. Read [our tutorial](https://dash.plotly.com/getting-started) (proudly crafted \u2764\ufe0f with Dash itself).\n\n- [Docs](https://dash.plotly.com/getting-started): Create your first Dash app in under 5 minutes\n\n- [dash.gallery](https://dash.gallery): Dash app gallery with Python & R code\n\n### Dash App Examples\n\n| Dash App | Description |\n|--- | :---: |\n|![Sample Dash App](https://user-images.githubusercontent.com/1280389/30086128-9bb4a28e-9267-11e7-8fe4-bbac7d53f2b0.gif) | Here\u2019s a simple example of a Dash App that ties a Dropdown to a Plotly Graph. As the user selects a value in the Dropdown, the application code dynamically exports data from Google Finance into a Pandas DataFrame. This app was written in just **43** lines of code ([view the source](https://gist.github.com/chriddyp/3d2454905d8f01886d651f207e2419f0)). |\n|![Crossfiltering Dash App](https://user-images.githubusercontent.com/1280389/30086123-97c58bde-9267-11e7-98a0-7f626de5199a.gif)|Dash app code is declarative and reactive, which makes it easy to build complex apps that contain many interactive elements. Here\u2019s an example with 5 inputs, 3 outputs, and cross filtering. This app was composed in just 160 lines of code, all of which were Python.|\n|![Dash App with Mapbox map showing walmart store openings](https://user-images.githubusercontent.com/1280389/30086299-768509d0-9268-11e7-8e6b-626ac9ca512c.gif)| Dash uses [Plotly.js](https://github.com/plotly/plotly.js) for charting. About 50 chart types are supported, including maps. |\n|![Financial report](https://user-images.githubusercontent.com/2678795/161153710-57952401-6e07-42d5-ba3e-bab6419998c7.gif)| Dash isn't just for dashboards. You have full control over the look and feel of your applications. Here's a Dash App that's styled to look like a PDF report. |\n\nTo learn more about Dash, read the [extensive announcement letter](https://medium.com/@plotlygraphs/introducing-dash-5ecf7191b503) or [jump in with the user guide](https://plotly.com/dash).\n\n### Dash OSS & Dash Enterprise\n\nWith Dash Open Source, Dash apps run on your local laptop or workstation, but cannot be easily accessed by others in your organization.\n\nScale up with Dash Enterprise when your Dash app is ready for department or company-wide consumption. Or, launch your initiative with Dash Enterprise from the start to unlock developer productivity gains and hands-on acceleration from Plotly's team.\n\nML Ops Features: A one-stop shop for ML Ops: Horizontally scalable hosting, deployment, and authentication for your Dash apps. No IT or DevOps required.\n- [**App manager**](https://plotly.com/dash/app-manager/) Deploy & manage Dash apps without needing IT or a DevOps team. App Manager gives you point & click control over all aspects of your Dash deployments.\n- [**Kubernetes scaling**](https://plotly.com/dash/kubernetes/) Ensure high availability of Dash apps and scale horizontally with Dash Enterprise\u2019s Kubernetes architecture. No IT or Helm required.\n- [**No code auth**](https://plotly.com/dash/authentication/) Control Dash app access in a few clicks. Dash Enterprise supports LDAP, AD, PKI, Okta, SAML, OpenID Connect, OAuth, SSO, and simple email authentication.\n- [**Job Queue**](https://plotly.com/dash/job-queue/) The Job Queue is the key to building scalable Dash apps. Move heavy computation from synchronous Dash callbacks to the Job Queue for asynchronous background processing.\n\nLow-Code Features: Low-code Dash app capabilities that supercharge developer productivity.\n- [**Design Kit**](https://plotly.com/dash/design-kit/) Design like a pro without writing a line of CSS. Easily arrange, style, brand, and customize your Dash apps.\n- [**Snapshot Engine**](https://plotly.com/dash/snapshot-engine/) Save & share Dash app views as links or PDFs. Or, run a Python job through Dash and have Snapshot Engine email a report when the job is done.\n- [**Dashboard Toolkit**](https://plotly.com/dash/toolkit/) Drag & drop layouts, chart editing, and crossfilter for your Dash apps.\n- [**Embedding**](https://plotly.com/dash/embedding/) Natively embed Dash apps in an existing web application or website without the use of IFrames.\n\nEnterprise AI Features: Everything that your data science team needs to rapidly deliver AI/ML research and business initiatives.\n- [**AI App Marketplace**](https://plotly.com/dash/ai-and-ml-templates/) Dash Enterprise ships with dozens of Dash app templates for business problems where AI/ML is having the greatest impact.\n- [**Big Data for Pything**](https://plotly.com/dash/big-data-for-python/) Connect to Python's most popular big data back ends: Dask, Databricks, NVIDIA RAPIDS, Snowflake, Postgres, Vaex, and more.\n- [**GPU & Dask Acceleration**](https://plotly.com/dash/gpu-dask-acceleration/) Dash Enterprise puts Python\u2019s most popular HPC stack for GPU and parallel CPU computing in the hands of business users.\n- [**Data Science Workspaces**](https://plotly.com/dash/workspaces/) Be productive from Day 1. Write and execute Python, R, & Julia code from Dash Enterprise's onboard code editor.\n\nSee [https://plotly.com/contact-us/](https://plotly.com/contact-us/) to get in touch.\n\n![Dash Enterprise](https://user-images.githubusercontent.com/2678795/161155614-21c54a22-f821-4dda-b910-ee27e27fb5f2.png)\n",
	"book data-science deep-learning fastai machine-learning notebooks python": "[English](./README.md) / [Spanish](./README_es.md) / [Korean](./README_ko.md) / [Chinese](./README_zh.md) / [Bengali](./README_bn.md) / [Indonesian](./README_id.md) / [Italian](./README_it.md) / [Portuguese](./README_pt.md) / [Vietnamese](./README_vn.md)\n\n# The fastai book\n\nThese notebooks cover an introduction to deep learning, [fastai](https://docs.fast.ai/), and [PyTorch](https://pytorch.org/). fastai is a layered API for deep learning; for more information, see [the fastai paper](https://www.mdpi.com/2078-2489/11/2/108). Everything in this repo is copyright Jeremy Howard and Sylvain Gugger, 2020 onwards. A selection of chapters is available to [read online here](https://fastai.github.io/fastbook2e/).\n\nThe notebooks in this repo are used for [a MOOC](https://course.fast.ai) and form the basis of [this book](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527), which is currently available for purchase. It does not have the same GPL restrictions that are on this repository.\n\nThe code in the notebooks and python `.py` files is covered by the GPL v3 license; see the LICENSE file for details. The remainder (including all markdown cells in the notebooks and other prose) is not licensed for any redistribution or change of format or medium, other than making copies of the notebooks or forking this repo for your own private use. No commercial or broadcast use is allowed. We are making these materials freely available to help you learn deep learning, so please respect our copyright and these restrictions.\n\nIf you see someone hosting a copy of these materials somewhere else, please let them know that their actions are not allowed and may lead to legal action. Moreover, they would be hurting the community because we're not likely to release additional materials in this way if people ignore our copyright.\n\n## Colab\n\nInstead of cloning this repo and opening it on your machine, you can read and work with the notebooks using [Google Colab](https://research.google.com/colaboratory/). This is the recommended approach for folks who are just getting started -- there's no need to set up a Python development environment on your own machine, since you can just work directly in your web-browser.\n\nYou can open any chapter of the book in Colab by clicking on one of these links: [Introduction to Jupyter](https://colab.research.google.com/github/fastai/fastbook/blob/master/app_jupyter.ipynb) | [Chapter 1, Intro](https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb) | [Chapter 2, Production](https://colab.research.google.com/github/fastai/fastbook/blob/master/02_production.ipynb) | [Chapter 3, Ethics](https://colab.research.google.com/github/fastai/fastbook/blob/master/03_ethics.ipynb) | [Chapter 4, MNIST Basics](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb) | [Chapter 5, Pet Breeds](https://colab.research.google.com/github/fastai/fastbook/blob/master/05_pet_breeds.ipynb) | [Chapter 6, Multi-Category](https://colab.research.google.com/github/fastai/fastbook/blob/master/06_multicat.ipynb) | [Chapter 7, Sizing and TTA](https://colab.research.google.com/github/fastai/fastbook/blob/master/07_sizing_and_tta.ipynb) | [Chapter 8, Collab](https://colab.research.google.com/github/fastai/fastbook/blob/master/08_collab.ipynb) | [Chapter 9, Tabular](https://colab.research.google.com/github/fastai/fastbook/blob/master/09_tabular.ipynb) | [Chapter 10, NLP](https://colab.research.google.com/github/fastai/fastbook/blob/master/10_nlp.ipynb) | [Chapter 11, Mid-Level API](https://colab.research.google.com/github/fastai/fastbook/blob/master/11_midlevel_data.ipynb) | [Chapter 12, NLP Deep-Dive](https://colab.research.google.com/github/fastai/fastbook/blob/master/12_nlp_dive.ipynb) | [Chapter 13, Convolutions](https://colab.research.google.com/github/fastai/fastbook/blob/master/13_convolutions.ipynb) | [Chapter 14, Resnet](https://colab.research.google.com/github/fastai/fastbook/blob/master/14_resnet.ipynb) | [Chapter 15, Arch Details](https://colab.research.google.com/github/fastai/fastbook/blob/master/15_arch_details.ipynb) | [Chapter 16, Optimizers and Callbacks](https://colab.research.google.com/github/fastai/fastbook/blob/master/16_accel_sgd.ipynb) | [Chapter 17, Foundations](https://colab.research.google.com/github/fastai/fastbook/blob/master/17_foundations.ipynb) | [Chapter 18, GradCAM](https://colab.research.google.com/github/fastai/fastbook/blob/master/18_CAM.ipynb) | [Chapter 19, Learner](https://colab.research.google.com/github/fastai/fastbook/blob/master/19_learner.ipynb) | [Chapter 20, conclusion](https://colab.research.google.com/github/fastai/fastbook/blob/master/20_conclusion.ipynb)\n\n\n## Contributions\n\nIf you make any pull requests to this repo, then you are assigning copyright of that work to Jeremy Howard and Sylvain Gugger. (Additionally, if you are making small edits to spelling or text, please specify the name of the file and a very brief description of what you're fixing. It's difficult for reviewers to know which corrections have already been made. Thank you.)\n\n## Citations\n\nIf you wish to cite the book, you may use the following:\n\n```\n@book{howard2020deep,\ntitle={Deep Learning for Coders with Fastai and Pytorch: AI Applications Without a PhD},\nauthor={Howard, J. and Gugger, S.},\nisbn={9781492045526},\nurl={https://books.google.no/books?id=xd6LxgEACAAJ},\nyear={2020},\npublisher={O'Reilly Media, Incorporated}\n}\n```\n\n",
	"data-analysis data-science data-visualization pandas python": "# Data Science for Beginners - A Curriculum\n\n[![GitHub license](https://img.shields.io/github/license/microsoft/Data-Science-For-Beginners.svg)](https://github.com/microsoft/Data-Science-For-Beginners/blob/master/LICENSE)\n[![GitHub contributors](https://img.shields.io/github/contributors/microsoft/Data-Science-For-Beginners.svg)](https://GitHub.com/microsoft/Data-Science-For-Beginners/graphs/contributors/)\n[![GitHub issues](https://img.shields.io/github/issues/microsoft/Data-Science-For-Beginners.svg)](https://GitHub.com/microsoft/Data-Science-For-Beginners/issues/)\n[![GitHub pull-requests](https://img.shields.io/github/issues-pr/microsoft/Data-Science-For-Beginners.svg)](https://GitHub.com/microsoft/Data-Science-For-Beginners/pulls/)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)\n\n[![GitHub watchers](https://img.shields.io/github/watchers/microsoft/Data-Science-For-Beginners.svg?style=social&label=Watch)](https://GitHub.com/microsoft/Data-Science-For-Beginners/watchers/)\n[![GitHub forks](https://img.shields.io/github/forks/microsoft/Data-Science-For-Beginners.svg?style=social&label=Fork)](https://GitHub.com/microsoft/Data-Science-For-Beginners/network/)\n[![GitHub stars](https://img.shields.io/github/stars/microsoft/Data-Science-For-Beginners.svg?style=social&label=Star)](https://GitHub.com/microsoft/Data-Science-For-Beginners/stargazers/)\n\nAzure Cloud Advocates at Microsoft are pleased to offer a 10-week, 20-lesson curriculum all about Data Science. Each lesson includes pre-lesson and post-lesson quizzes, written instructions to complete the lesson, a solution, and an assignment. Our project-based pedagogy allows you to learn while building, a proven way for new skills to 'stick'.\n\n**Hearty thanks to our authors:** [Jasmine Greenaway](https://www.twitter.com/paladique), [Dmitry Soshnikov](http://soshnikov.com), [Nitya Narasimhan](https://twitter.com/nitya), [Jalen McGee](https://twitter.com/JalenMcG), [Jen Looper](https://twitter.com/jenlooper), [Maud Levy](https://twitter.com/maudstweets), [Tiffany Souterre](https://twitter.com/TiffanySouterre), [Christopher Harrison](https://www.twitter.com/geektrainer).\n\n**\ud83d\ude4f Special thanks \ud83d\ude4f to our [Microsoft Student Ambassador](https://studentambassadors.microsoft.com/) authors, reviewers and content contributors,** notably Aaryan Arora, [Aditya Garg](https://github.com/AdityaGarg00), [Alondra Sanchez](https://www.linkedin.com/in/alondra-sanchez-molina/), [Ankita Singh](https://www.linkedin.com/in/ankitasingh007), [Anupam Mishra](https://www.linkedin.com/in/anupam--mishra/), [Arpita Das](https://www.linkedin.com/in/arpitadas01/), ChhailBihari Dubey, [Dibri Nsofor](https://www.linkedin.com/in/dibrinsofor), [Dishita Bhasin](https://www.linkedin.com/in/dishita-bhasin-7065281bb), [Majd Safi](https://www.linkedin.com/in/majd-s/), [Max Blum](https://www.linkedin.com/in/max-blum-6036a1186/), [Miguel Correa](https://www.linkedin.com/in/miguelmque/), [Mohamma Iftekher (Iftu) Ebne Jalal](https://twitter.com/iftu119), [Nawrin Tabassum](https://www.linkedin.com/in/nawrin-tabassum), [Raymond Wangsa Putra](https://www.linkedin.com/in/raymond-wp/), [Rohit Yadav](https://www.linkedin.com/in/rty2423), Samridhi Sharma, [Sanya Sinha](https://www.linkedin.com/mwlite/in/sanya-sinha-13aab1200),\n[Sheena Narula](https://www.linkedin.com/in/sheena-narua-n/), [Tauqeer Ahmad](https://www.linkedin.com/in/tauqeerahmad5201/), Yogendrasingh Pawar , [Vidushi Gupta](https://www.linkedin.com/in/vidushi-gupta07/), [Jasleen Sondhi](https://www.linkedin.com/in/jasleen-sondhi/)\n\n|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](./sketchnotes/00-Title.png)|\n|:---:|\n| Data Science For Beginners - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |\n\n# Are you a student?\n\nGet started with the following resources:\n\n- [Student Hub page](https://docs.microsoft.com/en-gb/learn/student-hub?WT.mc_id=academic-77958-bethanycheum) In this page, you will find beginner resources, Student packs and even ways to get a free cert voucher. This is one page you want to bookmark and check from time to time as we switch out content at least monthly.\n- [Microsoft Learn Student Ambassadors](https://studentambassadors.microsoft.com?WT.mc_id=academic-77958-bethanycheum) Join a global community of student ambassadors, this could be your way into Microsoft\n\n# Getting Started\n\n> **Teachers**: we have [included some suggestions](for-teachers.md) on how to use this curriculum.  We'd love your feedback [in our discussion forum](https://github.com/microsoft/Data-Science-For-Beginners/discussions)!\n\n> **[Students](https://aka.ms/student-page)**: to use this curriculum on your own, fork the entire repo and complete the exercises on your own, starting with a pre-lecture quiz.  Then read the lecture and complete the rest of the activities. Try to create the projects by comprehending the lessons rather than copying the solution code; however, that code is available in the /solutions folders in each project-oriented lesson. Another idea would be to form a study group with friends and go through the content together. For further study, we recommend [Microsoft Learn](https://docs.microsoft.com/en-us/users/jenlooper-2911/collections/qprpajyoy3x0g7?WT.mc_id=academic-77958-bethanycheum).\n\n## Meet the Team\n\n[![Promo video](ds-for-beginners.gif)](https://youtu.be/8mzavjQSMM4 \"Promo video\")\n\n**Gif by** [Mohit Jaisal](https://www.linkedin.com/in/mohitjaisal)\n\n> \ud83c\udfa5 Click the image above for a video about the project  the folks who created it!\n\n## Pedagogy\n\nWe have chosen two pedagogical tenets while building this curriculum: ensuring that it is project-based and that it includes frequent quizzes. By the end of this series, students will have learned basic principles of data science, including ethical concepts, data preparation, different ways of working with data, data visualization, data analysis, real-world use cases of data science, and more.\n\nIn addition, a low-stakes quiz before a class sets the intention of the student towards learning a topic, while a second quiz after class ensures further retention. This curriculum was designed to be flexible and fun and can be taken in whole or in part. The projects start small and become increasingly complex by the end of the 10 week cycle.\n\n> Find our [Code of Conduct](CODE_OF_CONDUCT.md), [Contributing](CONTRIBUTING.md),  [Translation](TRANSLATIONS.md) guidelines. We welcome your constructive feedback!\n\n## Each lesson includes:\n\n- Optional sketchnote\n- Optional supplemental video\n- Pre-lesson warmup quiz\n- Written lesson\n- For project-based lessons, step-by-step guides on how to build the project\n- Knowledge checks\n- A challenge\n- Supplemental reading\n- Assignment\n- Post-lesson quiz\n\n> **A note about quizzes**: All quizzes are contained [in this app](https://purple-hill-04aebfb03.1.azurestaticapps.net/), for 40 total quizzes of three questions each. They are linked from within the lessons, but the quiz app can be run locally; follow the instruction in the `quiz-app` folder. They are gradually being localized.\n\n## Lessons\n\n\n|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](./sketchnotes/00-Roadmap.png)|\n|:---:|\n| Data Science For Beginners: Roadmap - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |\n\n\n| Lesson Number | Topic | Lesson Grouping | Learning Objectives | Linked Lesson | Author |\n| :-----------: | :----------------------------------------: | :--------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :---------------------------------------------------------------------: | :----: |\n| 01 | Defining Data Science | [Introduction](1-Introduction/README.md) | Learn the basic concepts behind data science and how it\u2019s related to artificial intelligence, machine learning, and big data. | [lesson](1-Introduction/01-defining-data-science/README.md) [video](https://youtu.be/beZ7Mb_oz9I) | [Dmitry](http://soshnikov.com) |\n| 02 | Data Science Ethics | [Introduction](1-Introduction/README.md) | Data Ethics Concepts, Challenges & Frameworks. | [lesson](1-Introduction/02-ethics/README.md) | [Nitya](https://twitter.com/nitya) |\n| 03 | Defining Data | [Introduction](1-Introduction/README.md) | How data is classified and its common sources. | [lesson](1-Introduction/03-defining-data/README.md) | [Jasmine](https://www.twitter.com/paladique) |\n| 04 | Introduction to Statistics & Probability | [Introduction](1-Introduction/README.md) | The mathematical techniques of probability and statistics to understand data. | [lesson](1-Introduction/04-stats-and-probability/README.md) [video](https://youtu.be/Z5Zy85g4Yjw) | [Dmitry](http://soshnikov.com) |\n| 05 | Working with Relational Data | [Working With Data](2-Working-With-Data/README.md) | Introduction to relational data and the basics of exploring and analyzing relational data with the Structured Query Language, also known as SQL (pronounced \u201csee-quell\u201d). | [lesson](2-Working-With-Data/05-relational-databases/README.md) | [Christopher](https://www.twitter.com/geektrainer) | | |\n| 06 | Working with NoSQL Data | [Working With Data](2-Working-With-Data/README.md) | Introduction to non-relational data, its various types and the basics of exploring and analyzing document databases. | [lesson](2-Working-With-Data/06-non-relational/README.md) | [Jasmine](https://twitter.com/paladique)|\n| 07 | Working with Python | [Working With Data](2-Working-With-Data/README.md) | Basics of using Python for data exploration with libraries such as Pandas. Foundational understanding of Python programming is recommended. | [lesson](2-Working-With-Data/07-python/README.md) [video](https://youtu.be/dZjWOGbsN4Y) | [Dmitry](http://soshnikov.com) |\n| 08 | Data Preparation | [Working With Data](2-Working-With-Data/README.md) | Topics on data techniques for cleaning and transforming the data to handle challenges of missing, inaccurate, or incomplete data. | [lesson](2-Working-With-Data/08-data-preparation/README.md) | [Jasmine](https://www.twitter.com/paladique) |\n| 09 | Visualizing Quantities | [Data Visualization](3-Data-Visualization/README.md) | Learn how to use Matplotlib to visualize bird data \ud83e\udd86 | [lesson](3-Data-Visualization/09-visualization-quantities/README.md) | [Jen](https://twitter.com/jenlooper) |\n| 10 | Visualizing Distributions of Data | [Data Visualization](3-Data-Visualization/README.md) | Visualizing observations and trends within an interval. | [lesson](3-Data-Visualization/10-visualization-distributions/README.md) | [Jen](https://twitter.com/jenlooper) |\n| 11 | Visualizing Proportions | [Data Visualization](3-Data-Visualization/README.md) | Visualizing discrete and grouped percentages. | [lesson](3-Data-Visualization/11-visualization-proportions/README.md) | [Jen](https://twitter.com/jenlooper) |\n| 12 | Visualizing Relationships | [Data Visualization](3-Data-Visualization/README.md) | Visualizing connections and correlations between sets of data and their variables. | [lesson](3-Data-Visualization/12-visualization-relationships/README.md) | [Jen](https://twitter.com/jenlooper) |\n| 13 | Meaningful Visualizations | [Data Visualization](3-Data-Visualization/README.md) | Techniques and guidance for making your visualizations valuable for effective problem solving and insights. | [lesson](3-Data-Visualization/13-meaningful-visualizations/README.md) | [Jen](https://twitter.com/jenlooper) |\n| 14 | Introduction to the Data Science lifecycle | [Lifecycle](4-Data-Science-Lifecycle/README.md) | Introduction to the data science lifecycle and its first step of acquiring and extracting data. | [lesson](4-Data-Science-Lifecycle/14-Introduction/README.md) | [Jasmine](https://twitter.com/paladique) |\n| 15 | Analyzing | [Lifecycle](4-Data-Science-Lifecycle/README.md) | This phase of the data science lifecycle focuses on techniques to analyze data. | [lesson](4-Data-Science-Lifecycle/15-analyzing/README.md) | [Jasmine](https://twitter.com/paladique) | | |\n| 16 | Communication | [Lifecycle](4-Data-Science-Lifecycle/README.md) | This phase of the data science lifecycle focuses on presenting the insights from the data in a way that makes it easier for decision makers to understand. | [lesson](4-Data-Science-Lifecycle/16-communication/README.md) | [Jalen](https://twitter.com/JalenMcG) | | |\n| 17 | Data Science in the Cloud | [Cloud Data](5-Data-Science-In-Cloud/README.md) | This series of lessons introduces data science in the cloud and its benefits. | [lesson](5-Data-Science-In-Cloud/17-Introduction/README.md) | [Tiffany](https://twitter.com/TiffanySouterre) and [Maud](https://twitter.com/maudstweets) |\n| 18 | Data Science in the Cloud | [Cloud Data](5-Data-Science-In-Cloud/README.md) | Training models using Low Code tools. |[lesson](5-Data-Science-In-Cloud/18-Low-Code/README.md) | [Tiffany](https://twitter.com/TiffanySouterre) and [Maud](https://twitter.com/maudstweets) |\n| 19 | Data Science in the Cloud | [Cloud Data](5-Data-Science-In-Cloud/README.md) | Deploying models with Azure Machine Learning Studio. | [lesson](5-Data-Science-In-Cloud/19-Azure/README.md)| [Tiffany](https://twitter.com/TiffanySouterre) and [Maud](https://twitter.com/maudstweets) |\n| 20 | Data Science in the Wild | [In the Wild](6-Data-Science-In-Wild/README.md) | Data science driven projects in the real world. | [lesson](6-Data-Science-In-Wild/20-Real-World-Examples/README.md) | [Nitya](https://twitter.com/nitya) |\n## Offline access\n\nYou can run this documentation offline by using [Docsify](https://docsify.js.org/#/). Fork this repo, [install Docsify](https://docsify.js.org/#/quickstart) on your local machine,  then in the root folder of this repo, type `docsify serve`. The website will be served on port 3000 on your localhost: `localhost:3000`.\n\n> Note, notebooks will not be rendered via Docsify, so when you need to run a notebook, do that separately in VS Code running a Python kernel.\n## PDF\n\nA PDF of all of the lessons can be found [here](https://microsoft.github.io/Data-Science-For-Beginners/pdf/readme.pdf)\n\n## Help Wanted!\n\nIf you would like to translate all or part of the curriculum, please follow our [Translations](TRANSLATIONS.md) guide\n\n## Other Curricula\n\nOur team produces other curricula! Check out:\n\n- [Machine Learning for Beginners](https://aka.ms/ml-beginners)\n- [IoT for Beginners](https://aka.ms/iot-beginners)\n- [Web Dev for Beginners](https://aka.ms/webdev-beginners)\n- [AI for Beginners](https://aka.ms/ai-beginners)\n",
	"data-science data-visualization gtk hacktoberfest matplotlib plotting python qt tk wx": "[![PyPi](https://badge.fury.io/py/matplotlib.svg)](https://badge.fury.io/py/matplotlib)\n[![Downloads](https://pepy.tech/badge/matplotlib/month)](https://pepy.tech/project/matplotlib)\n[![NUMFocus](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](https://numfocus.org)\n\n[![DiscourseBadge](https://img.shields.io/badge/help_forum-discourse-blue.svg)](https://discourse.matplotlib.org)\n[![Gitter](https://badges.gitter.im/matplotlib/matplotlib.svg)](https://gitter.im/matplotlib/matplotlib)\n[![GitHubIssues](https://img.shields.io/badge/issue_tracking-github-blue.svg)](https://github.com/matplotlib/matplotlib/issues)\n[![GitTutorial](https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?)](https://git-scm.com/book/en/v2/GitHub-Contributing-to-a-Project)\n\n[![GitHubActions](https://github.com/matplotlib/matplotlib/workflows/Tests/badge.svg)](https://github.com/matplotlib/matplotlib/actions?query=workflow%3ATests)\n[![AzurePipelines](https://dev.azure.com/matplotlib/matplotlib/_apis/build/status/matplotlib.matplotlib?branchName=main)](https://dev.azure.com/matplotlib/matplotlib/_build/latest?definitionId=1&branchName=main)\n[![AppVeyor](https://ci.appveyor.com/api/projects/status/github/matplotlib/matplotlib?branch=main&svg=true)](https://ci.appveyor.com/project/matplotlib/matplotlib)\n[![Codecov](https://codecov.io/github/matplotlib/matplotlib/badge.svg?branch=main&service=github)](https://codecov.io/github/matplotlib/matplotlib?branch=main)\n[![LGTM](https://img.shields.io/lgtm/grade/python/github/matplotlib/matplotlib.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/matplotlib/matplotlib)\n\n![image](https://matplotlib.org/_static/logo2.svg)\n\nMatplotlib is a comprehensive library for creating static, animated, and\ninteractive visualizations in Python.\n\nCheck out our [home page](https://matplotlib.org/) for more information.\n\n![image](https://matplotlib.org/_static/readme_preview.png)\n\nMatplotlib produces publication-quality figures in a variety of hardcopy\nformats and interactive environments across platforms. Matplotlib can be\nused in Python scripts, Python/IPython shells, web application servers,\nand various graphical user interface toolkits.\n\n## Install\n\nSee the [install\ndocumentation](https://matplotlib.org/stable/users/installing/index.html),\nwhich is generated from `/doc/users/installing/index.rst`\n\n## Contribute\n\nYou've discovered a bug or something else you want to change -\nexcellent!\n\nYou've worked out a way to fix it -- even better!\n\nYou want to tell us about it -- best of all!\n\nStart at the [contributing\nguide](https://matplotlib.org/devdocs/devel/contributing.html)!\n\n## Contact\n\n[Discourse](https://discourse.matplotlib.org/) is the discussion forum\nfor general questions and discussions and our recommended starting\npoint.\n\nOur active mailing lists (which are mirrored on Discourse) are:\n\n-   [Users](https://mail.python.org/mailman/listinfo/matplotlib-users)\n    mailing list: <matplotlib-users@python.org>\n-   [Announcement](https://mail.python.org/mailman/listinfo/matplotlib-announce)\n    mailing list: <matplotlib-announce@python.org>\n-   [Development](https://mail.python.org/mailman/listinfo/matplotlib-devel)\n    mailing list: <matplotlib-devel@python.org>\n\n[Gitter](https://gitter.im/matplotlib/matplotlib) is for coordinating\ndevelopment and asking questions directly related to contributing to\nmatplotlib.\n\n## Citing Matplotlib\n\nIf Matplotlib contributes to a project that leads to publication, please\nacknowledge this by citing Matplotlib.\n\n[A ready-made citation\nentry](https://matplotlib.org/stable/users/project/citing.html) is\navailable.\n\n### Research notice\n\nPlease note that this repository is participating in a study into\nsustainability of open source projects. Data will be gathered about this\nrepository for approximately the next 12 months, starting from June\n2021.\n\nData collected will include number of contributors, number of PRs, time\ntaken to close/merge these PRs, and issues closed.\n\nFor more information, please visit [the informational\npage](https://sustainable-open-science-and-software.github.io/) or\ndownload the [participant information\nsheet](https://sustainable-open-science-and-software.github.io/assets/PIS_sustainable_software.pdf).\n",
	"architecture awesome awesome-list backend big-data computer-science design-patterns devops distributed-systems interview interview-practice interview-questions lists machine-learning programming resources scalability system system-design web-development": "[![Logo](/logo.png)](http://awesome-scalability.com/)\n\nAn updated and organized reading list for illustrating the patterns of scalable, reliable, and performant large-scale systems. Concepts are explained in the articles of prominent engineers and credible references. Case studies are taken from battle-tested systems that serve millions to billions of users.\n\n#### If your system goes slow\n> Understand your problems: scalability problem (fast for a single user but slow under heavy load) or performance problem (slow for a single user) by reviewing some [design principles](#principle) and checking how [scalability](#scalability) and [performance](#performance) problems are solved at tech companies. The section of [intelligence](#intelligence) are created for those who work with data and machine learning at big (data) and deep (learning) scale.\n\n#### If your system goes down\n> \"Even if you lose all one day, you can build all over again if you retain your calm!\" - Thuan Pham, former CTO of Uber. So, keep calm and mind the [availability](#availability) and [stability](#stability) matters! \n\n#### If you are having a system design interview\n> Look at some [interview notes](#interview) and [real-world architectures with completed diagrams](#architecture) to get a comprehensive view before designing your system on whiteboard. You can check some [talks](#talk) of engineers from tech giants to know how they build, scale, and optimize their systems. There are some selected [books](#book) for you (most of them are free)! Good luck!\n\n#### If you are building your dream team\n> The goal of scaling team is not growing team size but increasing team output and value. You can find out how tech companies reach that goal in various aspects: hiring, management, organization, culture, and communication in the [organization](#organization) section.\n\n#### Community power\n\n> Contributions are greatly welcome! You may want to take a look at the [contribution guidelines](CONTRIBUTING.md). If you see a link here that is no longer maintained or is not a good fit, please submit a pull request!\n\n> Many long hours of hard work have gone into this project. If you find it helpful, please share on Facebook, [on Twitter](https://ctt.ec/V8B2p), [on Weibo](http://t.cn/RnjFLCB), or on your chat groups! Knowledge is power, knowledge shared is power multiplied. Thank you!\n\n## Content\n- [Principle](#principle)\n- [Scalability](#scalability)\n- [Availability](#availability)\n- [Stability](#stability)\n- [Performance](#performance)\n- [Intelligence](#intelligence)\n- [Architecture](#architecture)\n- [Interview](#interview)\n- [Organization](#organization)\n- [Talk](#talk)\n- [Book](#book)\n\n## Principle\n* [Lessons from Giant-Scale Services - Eric Brewer, UC Berkeley & Google](https://people.eecs.berkeley.edu/~brewer/papers/GiantScale-IEEE.pdf)\n* [Designs, Lessons and Advice from Building Large Distributed Systems - Jeff Dean, Google](https://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf)\n* [How to Design a Good API & Why it Matters - Joshua Bloch, CMU & Google](https://www.infoq.com/presentations/effective-api-design)\n* [On Efficiency, Reliability, Scaling - James Hamilton, VP at AWS](http://mvdirona.com/jrh/work/)\n* [Things to Keep in Mind When Building a Platform for the Enterprise - Heidi Williams, VP Platform at Box](https://blog.box.com/blog/4-things-to-keep-in-mind-when-building-a-platform-for-the-enterprise/)\n* [Principles of Chaos Engineering](https://www.usenix.org/conference/srecon17americas/program/presentation/rosenthal)\n* [Finding the Order in Chaos](https://www.usenix.org/conference/srecon16/program/presentation/lueder)\n* [The Twelve-Factor App](https://12factor.net/)\n* [Clean Architecture](https://8thlight.com/blog/uncle-bob/2012/08/13/the-clean-architecture.html)\n* [High Cohesion and Low Coupling](http://www.math-cs.gordon.edu/courses/cs211/lectures-2009/Cohesion,Coupling,MVC.pdf)\n* [Monoliths and Microservices](https://medium.com/@SkyscannerEng/monoliths-and-microservices-8c65708c3dbf)\n* [CAP Theorem and Trade-offs](http://robertgreiner.com/2014/08/cap-theorem-revisited/)\n* [CP Databases and AP Databases](https://blog.andyet.com/2014/10/01/right-database)\n* [Stateless vs Stateful Scalability](http://ithare.com/scaling-stateful-objects/)\t\n* [Scale Up vs Scale Out](https://www.brianjgraf.com/scalability-scale-up-scale-out-care/)\n* [Scale Up vs Scale Out: Hidden Costs](https://blog.codinghorror.com/scaling-up-vs-scaling-out-hidden-costs/)\n* [ACID and BASE](https://neo4j.com/blog/acid-vs-base-consistency-models-explained/)\n* [Blocking/Non-Blocking and Sync/Async](https://blogs.msdn.microsoft.com/csliu/2009/08/27/io-concept-blockingnon-blocking-vs-syncasync/)\n* [Performance and Scalability of Databases](https://use-the-index-luke.com/sql/testing-scalability)\n* [Database Isolation Levels and Effects on Performance and Scalability](http://highscalability.com/blog/2011/2/10/database-isolation-levels-and-their-effects-on-performance-a.html)\n* [The Probability of Data Loss in Large Clusters](https://martin.kleppmann.com/2017/01/26/data-loss-in-large-clusters.html)\n* [Data Access for Highly-Scalable Solutions: Using SQL, NoSQL, and Polyglot Persistence](https://docs.microsoft.com/en-us/previous-versions/msp-n-p/dn271399(v=pandp.10))\n* [SQL vs NoSQL](https://www.upwork.com/hiring/data/sql-vs-nosql-databases-whats-the-difference/)\n* [SQL vs NoSQL - Lesson Learned at Salesforce](https://engineering.salesforce.com/sql-or-nosql-9eaf1d92545b)\n* [NoSQL Databases: Survey and Decision Guidance](https://medium.baqend.com/nosql-databases-a-survey-and-decision-guidance-ea7823a822d)\n* [How Sharding Works](https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6)\n* [Consistent Hashing](http://www.tom-e-white.com/2007/11/consistent-hashing.html)\n* [Consistent Hashing: Algorithmic Tradeoffs](https://medium.com/@dgryski/consistent-hashing-algorithmic-tradeoffs-ef6b8e2fcae8)\n* [Don\u2019t be tricked by the Hashing Trick](https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087)\n* [Uniform Consistent Hashing at Netflix](https://medium.com/netflix-techblog/distributing-content-to-open-connect-3e3e391d4dc9)\n* [Eventually Consistent - Werner Vogels, CTO at Amazon](https://www.allthingsdistributed.com/2008/12/eventually_consistent.html)\n* [Cache is King](https://www.stevesouders.com/blog/2012/10/11/cache-is-king/)\n* [Anti-Caching](https://www.the-paper-trail.org/post/2014-06-06-paper-notes-anti-caching/)\n* [Understand Latency](http://highscalability.com/latency-everywhere-and-it-costs-you-sales-how-crush-it)\n* [Latency Numbers Every Programmer Should Know](http://norvig.com/21-days.html#answers)\n* [The Calculus of Service Availability](https://queue.acm.org/detail.cfm?id=3096459&__s=dnkxuaws9pogqdnxmx8i)\n* [Architecture Issues When Scaling Web Applications: Bottlenecks, Database, CPU, IO](http://highscalability.com/blog/2014/5/12/4-architecture-issues-when-scaling-web-applications-bottlene.html)\t\n* [Common Bottlenecks](http://highscalability.com/blog/2012/5/16/big-list-of-20-common-bottlenecks.html)\n* [Life Beyond Distributed Transactions](https://queue.acm.org/detail.cfm?id=3025012)\n* [Relying on Software to Redirect Traffic Reliably at Various Layers](https://www.usenix.org/conference/srecon15/program/presentation/taveira)\n* [Breaking Things on Purpose](https://www.usenix.org/conference/srecon17americas/program/presentation/andrus)\n* [Avoid Over Engineering](https://medium.com/@rdsubhas/10-modern-software-engineering-mistakes-bc67fbef4fc8)\n* [Scalability Worst Practices](https://www.infoq.com/articles/scalability-worst-practices)\n* [Use Solid Technologies - Don\u2019t Re-invent the Wheel - Keep It Simple!](https://medium.com/@DataStax/instagram-engineerings-3-rules-to-a-scalable-cloud-application-architecture-c44afed31406)\n* [Simplicity by Distributing Complexity](https://jobs.zalando.com/tech/blog/simplicity-by-distributing-complexity/)\n* [Why Over-Reusing is Bad](http://tech.transferwise.com/why-over-reusing-is-bad/)\n* [Performance is a Feature](https://blog.codinghorror.com/performance-is-a-feature/)\n* [Make Performance Part of Your Workflow](https://codeascraft.com/2014/12/11/make-performance-part-of-your-workflow/)\n* [The Benefits of Server Side Rendering over Client Side Rendering](https://medium.com/walmartlabs/the-benefits-of-server-side-rendering-over-client-side-rendering-5d07ff2cefe8)\n* [Automate and Abstract: Lessons at Facebook](https://architecht.io/lessons-from-facebook-on-engineering-for-scale-f5716f0afc7a)\n* [AWS Do's and Don'ts](https://8thlight.com/blog/sarah-sunday/2017/09/15/aws-dos-and-donts.html)\n* [(UI) Design Doesn\u2019t Scale - Stanley Wood, Design Director at Spotify](https://medium.com/@hellostanley/design-doesnt-scale-4d81e12cbc3e)\n* [Linux Performance](http://www.brendangregg.com/linuxperf.html)\n* [Building Fast and Resilient Web Applications - Ilya Grigorik](https://www.igvita.com/2016/05/20/building-fast-and-resilient-web-applications/)\n* [Accept Partial Failures, Minimize Service Loss](https://www.usenix.org/conference/srecon17asia/program/presentation/wang_daxin)\n* [Design for Resiliency](http://highscalability.com/blog/2012/12/31/designing-for-resiliency-will-be-so-2013.html)\n* [Design for Self-healing](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/self-healing)\n* [Design for Scaling Out](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/scale-out)\t\n* [Design for Evolution](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/design-for-evolution)\n* [Learn from Mistakes](http://highscalability.com/blog/2013/8/26/reddit-lessons-learned-from-mistakes-made-scaling-to-1-billi.html)\n\n## Scalability\n* [Microservices and Orchestration](https://martinfowler.com/microservices/)\n\t* [Domain-Oriented Microservice Architecture at Uber](https://eng.uber.com/microservice-architecture/)\n\t* [Container (8 parts) at Riot Games](https://engineering.riotgames.com/news/thinking-inside-container)\n\t* [Containerization at Pinterest](https://medium.com/@Pinterest_Engineering/containerization-at-pinterest-92295347f2f3)\n\t* [Evolution of Container Usage at Netflix](https://medium.com/netflix-techblog/the-evolution-of-container-usage-at-netflix-3abfc096781b)\n\t* [Dockerizing MySQL at Uber](https://eng.uber.com/dockerizing-mysql/)\n\t* [Testing of Microservices at Spotify](https://labs.spotify.com/2018/01/11/testing-of-microservices/)\n\t* [Docker in Production at Treehouse](https://medium.com/treehouse-engineering/lessons-learned-running-docker-in-production-5dce99ece770)\n\t* [Microservice at SoundCloud](https://developers.soundcloud.com/blog/inside-a-soundcloud-microservice)\n\t* [Operate Kubernetes Reliably at Stripe](https://stripe.com/blog/operating-kubernetes)\n\t* [Cross-Cluster Traffic Mirroring with Istio at Trivago](https://tech.trivago.com/2020/06/10/cross-cluster-traffic-mirroring-with-istio/)\n\t* [Agrarian-Scale Kubernetes (3 parts) at New York Times](https://open.nytimes.com/agrarian-scale-kubernetes-part-3-ee459887ed7e)\n\t* [Nanoservices at BBC](https://medium.com/bbc-design-engineering/powering-bbc-online-with-nanoservices-727840ba015b)\n\t* [PowerfulSeal: Testing Tool for Kubernetes Clusters at Bloomberg](https://www.techatbloomberg.com/blog/powerfulseal-testing-tool-kubernetes-clusters/)\n\t* [Conductor: Microservices Orchestrator at Netflix](https://medium.com/netflix-techblog/netflix-conductor-a-microservices-orchestrator-2e8d4771bf40)\n\t* [Docker Containers that Power Over 100.000 Online Shops at Shopify](https://shopifyengineering.myshopify.com/blogs/engineering/docker-at-shopify-how-we-built-containers-that-power-over-100-000-online-shops)\n\t* [Microservice Architecture at Medium](https://medium.engineering/microservice-architecture-at-medium-9c33805eb74f)\n\t* [From bare-metal to Kubernetes at Betabrand](https://boxunix.com/post/bare_metal_to_kube/)\n\t* [Kubernetes at Tinder](https://medium.com/tinder-engineering/tinders-move-to-kubernetes-cda2a6372f44)\n\t* [Kubernetes at Quora](https://www.quora.com/q/quoraengineering/Adopting-Kubernetes-at-Quora)\t\n\t* [Kubernetes Platform at Pinterest](https://medium.com/pinterest-engineering/building-a-kubernetes-platform-at-pinterest-fb3d9571c948)\n\t* [Microservices at Nubank](https://medium.com/building-nubank/microservices-at-nubank-an-overview-2ebcb336c64d)\n\t* [Payment Transaction Management in Microservices at Mercari](https://engineering.mercari.com/en/blog/entry/20210831-2019-06-07-155849/)\n\t* [Service Mesh at Snap](https://eng.snap.com/monolith-to-multicloud-microservices-snap-service-mesh)\n\t* [GRIT: Protocol for Distributed Transactions across Microservices at eBay](https://tech.ebayinc.com/engineering/grit-a-protocol-for-distributed-transactions-across-microservices/)\n\t* [Rubix: Kubernetes at Palantir](https://medium.com/palantir/introducing-rubix-kubernetes-at-palantir-ab0ce16ea42e)\n\t* [CRISP: Critical Path Analysis for Microservice Architectures at Uber](https://eng.uber.com/crisp-critical-path-analysis-for-microservice-architectures/)\n* [Distributed Caching](https://www.wix.engineering/post/scaling-to-100m-to-cache-or-not-to-cache)\n\t* [EVCache: Distributed In-memory Caching at Netflix](https://medium.com/netflix-techblog/caching-for-a-global-netflix-7bcc457012f1)\n\t* [EVCache Cache Warmer Infrastructure at Netflix](https://medium.com/netflix-techblog/cache-warming-agility-for-a-stateful-service-2d3b1da82642)\n\t* [Memsniff: Robust Memcache Traffic Analyzer at Box](https://blog.box.com/blog/introducing-memsniff-robust-memcache-traffic-analyzer/)\n\t* [Caching with Consistent Hashing and Cache Smearing at Etsy](https://codeascraft.com/2017/11/30/how-etsy-caches/)\n\t* [Analysis of Photo Caching at Facebook](https://code.facebook.com/posts/220956754772273/an-analysis-of-facebook-photo-caching/)\n\t* [Cache Efficiency Exercise at Facebook](https://code.facebook.com/posts/964122680272229/web-performance-cache-efficiency-exercise/)\n\t* [tCache: Scalable Data-aware Java Caching at Trivago](http://tech.trivago.com/2015/10/15/tcache/)\n\t* [Pycache: In-process Caching at Quora](https://engineering.quora.com/Pycache-lightning-fast-in-process-caching)\t\n\t* [Reduce Memcached Memory Usage by 50% at Trivago](http://tech.trivago.com/2017/12/19/how-trivago-reduced-memcached-memory-usage-by-50/)\n\t* [Caching Internal Service Calls at Yelp](https://engineeringblog.yelp.com/2018/03/caching-internal-service-calls-at-yelp.html)\n\t* [Estimating the Cache Efficiency using Big Data at Allegro](https://allegro.tech/2017/01/estimating-the-cache-efficiency-using-big-data.html)\n\t* [Distributed Cache at Zalando](https://jobs.zalando.com/tech/blog/distributed-cache-akka-kubernetes/)\n\t* [Application Data Caching from RAM to SSD at NetFlix](https://medium.com/netflix-techblog/evolution-of-application-data-caching-from-ram-to-ssd-a33d6fa7a690)\n\t* [Tradeoffs of Replicated Cache at Skyscanner](https://medium.com/@SkyscannerEng/the-tradeoffs-of-a-replicated-cache-b6680c722f58)\n\t* [Avoiding Cache Stampede at DoorDash](https://blog.doordash.com/avoiding-cache-stampede-at-doordash-55bbf596d94b)\n\t* [Location Caching with Quadtrees at Yext](http://engblog.yext.com/post/geolocation-caching)\n\t* [Video Metadata Caching at Vimeo](https://medium.com/vimeo-engineering-blog/video-metadata-caching-at-vimeo-a54b25f0b304)\n\t* [Scaling Redis at Twitter](http://highscalability.com/blog/2014/9/8/how-twitter-uses-redis-to-scale-105tb-ram-39mm-qps-10000-ins.html)\n\t* [Scaling Job Queue with Redis at Slack](https://slack.engineering/scaling-slacks-job-queue-687222e9d100)\n\t* [Moving persistent data out of Redis at Github](https://githubengineering.com/moving-persistent-data-out-of-redis/)\n\t* [Storing Hundreds of Millions of Simple Key-Value Pairs in Redis at Instagram](https://engineering.instagram.com/storing-hundreds-of-millions-of-simple-key-value-pairs-in-redis-1091ae80f74c)\n\t* [Redis at Trivago](http://tech.trivago.com/2017/01/25/learn-redis-the-hard-way-in-production/)\n\t* [Optimizing Redis Storage at Deliveroo](https://deliveroo.engineering/2017/01/19/optimising-membership-queries.html)\n\t* [Memory Optimization in Redis at Wattpad](http://engineering.wattpad.com/post/23244724794/store-more-stuff-memory-optimization-in-redis)\n\t* [Redis Fleet at Heroku](https://blog.heroku.com/rolling-redis-fleet)\n\t* [Solving Remote Build Cache Misses (2 parts) at SoundCloud](https://developers.soundcloud.com/blog/gradle-remote-build-cache-misses-part-2)\n\t* [Ratings & Reviews (2 parts) at Flipkart](https://blog.flipkart.tech/ratings-reviews-flipkart-part-2-574ab08e75cf)\n\t* [Prefetch Caching of Items at eBay](https://tech.ebayinc.com/engineering/prefetch-caching-of-ebay-items/)\n\t* [Cross-Region Caching Library at Wix](https://www.wix.engineering/post/how-we-built-a-cross-region-caching-library)\n\t* [Improving Distributed Caching Performance and Efficiency at Pinterest](https://medium.com/pinterest-engineering/improving-distributed-caching-performance-and-efficiency-at-pinterest-92484b5fe39b)\n    * [HTTP Caching and CDN](https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching)\n        * [Zynga Geo Proxy: Reducing Mobile Game Latency at Zynga](https://www.zynga.com/blogs/engineering/zynga-geo-proxy-reducing-mobile-game-latency)\n        * [Google AMP at Cond\u00e9 Nast](https://technology.condenast.com/story/the-why-and-how-of-google-amp-at-conde-nast)\n        * [A/B Tests on Hosting Infrastructure (CDNs) at Deliveroo](https://deliveroo.engineering/2016/09/19/ab-testing-cdns.html)\n        * [HAProxy with Kubernetes for User-facing Traffic at SoundCloud](https://developers.soundcloud.com/blog/how-soundcloud-uses-haproxy-with-kubernetes-for-user-facing-traffic)\n        * [Bandaid: Service Proxy at Dropbox](https://blogs.dropbox.com/tech/2018/03/meet-bandaid-the-dropbox-service-proxy/)\n        * [CDN in LIVE's Encoder Layer at LINE](https://engineering.linecorp.com/en/blog/detail/230)\n\t\t* [Service Workers at Slack](https://slack.engineering/service-workers-at-slack-our-quest-for-faster-boot-times-and-offline-support-3492cf79c88)\n\t\t* [CDN Services at Spotify](https://labs.spotify.com/2020/02/24/how-spotify-aligned-cdn-services-for-a-lightning-fast-streaming-experience/)\n* [Distributed Locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)\n\t* [Chubby: Lock Service for Loosely Coupled Distributed Systems at Google](https://blog.acolyer.org/2015/02/13/the-chubby-lock-service-for-loosely-coupled-distributed-systems/)\n\t* [Distributed Locking at Uber](https://www.youtube.com/watch?v=MDuagr729aU)\n\t* [Distributed Locks using Redis at GoSquared](https://engineering.gosquared.com/distributed-locks-using-redis)\n\t* [ZooKeeper at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2018/zookeeper-at-twitter.html)\n\t* [Eliminating Duplicate Queries using Distributed Locking at Chartio](https://blog.chartio.com/posts/eliminating-duplicate-queries-using-distributed-locking)\n* [Distributed Tracking, Tracing, and Measuring](https://www.oreilly.com/ideas/understanding-the-value-of-distributed-tracing)\n\t* [Zipkin: Distributed Systems Tracing at Twitter](https://blog.twitter.com/engineering/en_us/a/2012/distributed-systems-tracing-with-zipkin.html)\n\t* [Improve Zipkin Traces using Kubernetes Pod Metadata at SoundCloud](https://developers.soundcloud.com/blog/using-kubernetes-pod-metadata-to-improve-zipkin-traces)\n\t* [Canopy: Scalable Distributed Tracing & Analysis at Facebook](https://www.infoq.com/presentations/canopy-scalable-tracing-analytics-facebook)\n\t* [Pintrace: Distributed Tracing at Pinterest](https://medium.com/@Pinterest_Engineering/distributed-tracing-at-pinterest-with-new-open-source-tools-a4f8a5562f6b)\n\t* [XCMetrics: All-in-One Tool for Tracking Xcode Build Metrics at Spotify](https://engineering.atspotify.com/2021/01/20/introducing-xcmetrics-our-all-in-one-tool-for-tracking-xcode-build-metrics/)\n\t* [Real-time Distributed Tracing at LinkedIn](https://engineering.linkedin.com/distributed-service-call-graph/real-time-distributed-tracing-website-performance-and-efficiency)\t\n\t* [Tracking Service Infrastructure at Scale at Shopify](https://www.usenix.org/conference/srecon17americas/program/presentation/arthorne)\t\n\t* [Distributed Tracing at HelloFresh](https://engineering.hellofresh.com/scaling-hellofresh-distributed-tracing-7b182928247d)\n\t* [Analyzing Distributed Trace Data at Pinterest](https://medium.com/@Pinterest_Engineering/analyzing-distributed-trace-data-6aae58919949)\n\t* [Distributed Tracing at Uber](https://eng.uber.com/distributed-tracing/)\n\t* [JVM Profiler: Tracing Distributed JVM Applications at Uber](https://eng.uber.com/jvm-profiler/)\n\t* [Data Checking at Dropbox](https://www.usenix.org/conference/srecon17asia/program/presentation/mah)\n\t* [Tracing Distributed Systems at Showmax](https://tech.showmax.com/2016/10/tracing-distributed-systems-at-showmax/)\n\t* [osquery Across the Enterprise at Palantir](https://medium.com/@palantir/osquery-across-the-enterprise-3c3c9d13ec55)\n\t* [StatsD at Etsy](https://codeascraft.com/2011/02/15/measure-anything-measure-everything/)\n\t* [StatsD at DoorDash](https://blog.doordash.com/scaling-statsd-84d456a7cc2a)\n* [Distributed Scheduling](https://www.csee.umbc.edu/courses/graduate/CMSC621/fall02/lectures/ch11.pdf)\n\t* [Distributed Task Scheduling (3 parts) at PagerDuty](https://www.pagerduty.com/eng/distributed-task-scheduling-3/)\n    * [Building Cron at Google](https://landing.google.com/sre/sre-book/chapters/distributed-periodic-scheduling/)\n    * [Distributed Cron Architecture at Quora](https://engineering.quora.com/Quoras-Distributed-Cron-Architecture)\n    * [Chronos: A Replacement for Cron at Airbnb](https://medium.com/airbnb-engineering/chronos-a-replacement-for-cron-f05d7d986a9d)\n    * [Scheduler at Nextdoor](https://engblog.nextdoor.com/we-don-t-run-cron-jobs-at-nextdoor-6f7f9cc62040)\n    * [Peloton: Unified Resource Scheduler for Diverse Cluster Workloads at Uber](https://eng.uber.com/peloton/)\n    * [Fenzo: OSS Scheduler for Apache Mesos Frameworks at Netflix](https://medium.com/netflix-techblog/fenzo-oss-scheduler-for-apache-mesos-frameworks-5c340e77e543)\n    * [Airflow - Workflow Orchestration](https://airflow.apache.org/)\n\t\t* [Airflow at Airbnb](https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8)\n\t\t* [Airflow at Pandora](https://engineering.pandora.com/apache-airflow-at-pandora-1d7a844d68ee)\n        * [Airflow at Robinhood](https://robinhood.engineering/why-robinhood-uses-airflow-aed13a9a90c8)\n        * [Airflow at Lyft](https://eng.lyft.com/running-apache-airflow-at-lyft-6e53bb8fccff)\n        * [Airflow at Drivy](https://drivy.engineering/airflow-architecture/)\n\t\t* [Airflow at Grab](https://engineering.grab.com/experimentation-platform-data-pipeline)\n\t\t* [Airflow at Adobe](https://medium.com/adobetech/adobe-experience-platform-orchestration-service-with-apache-airflow-952203723c0b)\n        * [Auditing Airflow Job Runs at Walmart](https://medium.com/walmartlabs/auditing-airflow-batch-jobs-73b45100045)\n        * [MaaT: DAG-based Distributed Task Scheduler at Alibaba](https://hackernoon.com/meet-maat-alibabas-dag-based-distributed-task-scheduler-7c9cf0c83438)\n        * [boundary-layer: Declarative Airflow Workflows at Etsy](https://codeascraft.com/2018/11/14/boundary-layer%e2%80%89-declarative-airflow-workflows/)\n* [Distributed Monitoring and Alerting](https://www.oreilly.com/ideas/monitoring-distributed-systems)\n\t* [Unicorn: Remediation System at eBay](https://www.ebayinc.com/stories/blogs/tech/unicorn-rheos-remediation-center/)\n\t* [M3: Metrics and Monitoring Platform at Uber](https://eng.uber.com/optimizing-m3/)\n\t* [Athena: Automated Build Health Management System at Dropbox](https://blogs.dropbox.com/tech/2019/05/athena-our-automated-build-health-management-system/)\n\t* [Vortex: Monitoring Server Applications at Dropbox](https://blogs.dropbox.com/tech/2019/11/monitoring-server-applications-with-vortex/)\t\n\t* [Nuage: Cloud Management Service at LinkedIn](https://engineering.linkedin.com/blog/2019/solving-manageability-challenges-with-nuage)\n\t* [Telltale: Application Monitoring at Netflix](https://netflixtechblog.com/telltale-netflix-application-monitoring-simplified-5c08bfa780ba)\n\t* [ThirdEye: Monitoring Platform at LinkedIn](https://engineering.linkedin.com/blog/2019/06/smart-alerts-in-thirdeye--linkedins-real-time-monitoring-platfor)\n\t* [Periskop: Exception Monitoring Service at SoundCloud](https://developers.soundcloud.com/blog/periskop-exception-monitoring-service)\n    * [Securitybot: Distributed Alerting Bot at Dropbox](https://blogs.dropbox.com/tech/2017/02/meet-securitybot-open-sourcing-automated-security-at-scale/)\t\n    * [Monitoring System at Alibaba](https://www.usenix.org/conference/srecon18asia/presentation/xinchi)\n    * [Real User Monitoring at Dailymotion](https://medium.com/dailymotion/real-user-monitoring-1948375f8be5)\n    * [Alerting Ecosystem at Uber](https://eng.uber.com/observability-at-scale/)\n\t* [Alerting Framework at Airbnb](https://medium.com/airbnb-engineering/alerting-framework-at-airbnb-35ba48df894f)\n\t* [Alerting on Service-Level Objectives (SLOs) at SoundCloud](https://developers.soundcloud.com/blog/alerting-on-slos)\n    * [Job-based Forecasting Workflow for Observability Anomaly Detection at Uber](https://eng.uber.com/observability-anomaly-detection/)\n\t* [Monitoring and Alert System using Graphite and Cabot at HackerEarth](http://engineering.hackerearth.com/2017/03/21/monitoring-and-alert-system-using-graphite-and-cabot/)\n    * [Observability (2 parts) at Twitter](https://blog.twitter.com/engineering/en_us/a/2016/observability-at-twitter-technical-overview-part-ii.html)\n    * [Distributed Security Alerting at Slack](https://slack.engineering/distributed-security-alerting-c89414c992d6)\n    * [Real-Time News Alerting at Bloomberg](https://www.infoq.com/presentations/news-alerting-bloomberg)\n\t* [Data Pipeline Monitoring System at LinkedIn](https://engineering.linkedin.com/blog/2019/an-inside-look-at-linkedins-data-pipeline-monitoring-system-)\n\t* [Monitoring and Observability at Picnic](https://blog.picnic.nl/monitoring-and-observability-at-picnic-684cefd845c4)\n* [Distributed Security](https://msdn.microsoft.com/en-us/library/cc767123.aspx)\n\t* [Approach to Security at Scale at Dropbox](https://blogs.dropbox.com/tech/2018/02/security-at-scale-the-dropbox-approach/)\n\t* [Aardvark and Repokid: AWS Least Privilege for Distributed, High-Velocity Development at Netflix](https://medium.com/netflix-techblog/introducing-aardvark-and-repokid-53b081bf3a7e)\t\n\t* [LISA: Distributed Firewall at LinkedIn](https://www.slideshare.net/MikeSvoboda/2017-lisa-linkedins-distributed-firewall-dfw)\n\t* [Secure Infrastructure To Store Bitcoin In The Cloud at Coinbase](https://engineering.coinbase.com/how-coinbase-builds-secure-infrastructure-to-store-bitcoin-in-the-cloud-30a6504e40ba)\n\t* [BinaryAlert: Real-time Serverless Malware Detection at Airbnb](https://medium.com/airbnb-engineering/binaryalert-real-time-serverless-malware-detection-ca44370c1b90)\n\t* [Scalable IAM Architecture to Secure Access to 100 AWS Accounts at Segment](https://segment.com/blog/secure-access-to-100-aws-accounts/)\n\t* [OAuth Audit Toolbox at Indeed](http://engineering.indeedblog.com/blog/2018/04/oaudit-toolbox/)\n\t* [Active Directory Password Blacklisting at Yelp](https://engineeringblog.yelp.com/2018/04/ad-password-blacklisting.html)\t\n\t* [Syscall Auditing at Scale at Slack](https://slack.engineering/syscall-auditing-at-scale-e6a3ca8ac1b8)\n\t* [Athenz: Fine-Grained, Role-Based Access Control at Yahoo](https://yahooeng.tumblr.com/post/160481899076/open-sourcing-athenz-fine-grained-role-based)\n\t* [WebAuthn Support for Secure Sign In at Dropbox](https://blogs.dropbox.com/tech/2018/05/introducing-webauthn-support-for-secure-dropbox-sign-in/)\n\t* [Security Development Lifecycle at Slack](https://slack.engineering/moving-fast-and-securing-things-540e6c5ae58a)\n\t* [Unprivileged Container Builds at Kinvolk](https://kinvolk.io/blog/2018/04/towards-unprivileged-container-builds/)\n\t* [Diffy: Differencing Engine for Digital Forensics in the Cloud at Netflix](https://medium.com/netflix-techblog/netflix-sirt-releases-diffy-a-differencing-engine-for-digital-forensics-in-the-cloud-37b71abd2698)\n\t* [Detecting Credential Compromise in AWS at Netflix](https://medium.com/netflix-techblog/netflix-cloud-security-detecting-credential-compromise-in-aws-9493d6fd373a)\n\t* [Scalable User Privacy at Spotify](https://labs.spotify.com/2018/09/18/scalable-user-privacy/)\n\t* [AVA: Audit Web Applications at Indeed](https://engineering.indeedblog.com/blog/2018/09/application-scanning/)\n\t* [TTL as a Service: Automatic Revocation of Stale Privileges at Yelp](https://engineeringblog.yelp.com/2018/11/ttl-as-a-service.html)\n\t* [Enterprise Key Management at Slack](https://slack.engineering/engineering-dive-into-slack-enterprise-key-management-1fce471b178c)\t\n\t* [Scalability and Authentication at Twitch](https://blog.twitch.tv/en/2019/03/15/how-twitch-addresses-scalability-and-authentication/)\n\t* [Edge Authentication and Token-Agnostic Identity Propagation at Netflix](https://netflixtechblog.com/edge-authentication-and-token-agnostic-identity-propagation-514e47e0b602)\n\t* [Hardening Kubernetes Infrastructure with Cilium at Palantir](https://blog.palantir.com/hardening-palantirs-kubernetes-infrastructure-with-cilium-1c40d4c7ef0)\n\t* [Improving Web Vulnerability Management through Automation at Lyft](https://eng.lyft.com/improving-web-vulnerability-management-through-automation-2631570d8415)\n\t* [Clock Skew when Syncing Password Payloads at Drobbox](https://dropbox.tech/application/dropbox-passwords-clock-skew-payload-sync-merge)\n* [Distributed Messaging, Queuing, and Event Streaming](https://arxiv.org/pdf/1704.00411.pdf)\n\t* [Cape: Event Stream Processing Framework at Dropbox](https://blogs.dropbox.com/tech/2017/05/introducing-cape/)\n\t* [Brooklin: Distributed Service for Near Real-Time Data Streaming at LinkedIn](https://engineering.linkedin.com/blog/2019/brooklin-open-source)\n\t* [Samza: Stream Processing System for Latency Insighs at LinkedIn](https://engineering.linkedin.com/blog/2018/04/samza-aeon--latency-insights-for-asynchronous-one-way-flows)\t\n\t* [Bullet: Forward-Looking Query Engine for Streaming Data at Yahoo](https://yahooeng.tumblr.com/post/161855616651/open-sourcing-bullet-yahoos-forward-looking)\n\t* [EventHorizon: Tool for Watching Events Streaming at Etsy](https://codeascraft.com/2018/05/29/the-eventhorizon-saga/)\n\t* [Qmessage: Distributed, Asynchronous Task Queue at Quora](https://engineering.quora.com/Qmessage-Handling-Billions-of-Tasks-Per-Day)\n\t* [Cherami: Message Queue System for Transporting Async Tasks at Uber](https://eng.uber.com/cherami/)\n\t* [Dynein: Distributed Delayed Job Queueing System at Airbnb](https://medium.com/airbnb-engineering/dynein-building-a-distributed-delayed-job-queueing-system-93ab10f05f99)\n\t* [Messaging Service at Riot Games](https://engineering.riotgames.com/news/riot-messaging-service)\n\t* [Debugging Production with Event Logging at Zillow](https://www.zillow.com/engineering/debugging-production-event-logging/)\n\t* [Cross-platform In-app Messaging Orchestration Service at Netflix](https://medium.com/netflix-techblog/building-a-cross-platform-in-app-messaging-orchestration-service-86ba614f92d8)\n\t* [Video Gatekeeper at Netflix](https://medium.com/netflix-techblog/re-architecting-the-video-gatekeeper-f7b0ac2f6b00)\n\t* [Scaling Push Messaging for Millions of Devices at Netflix](https://www.infoq.com/presentations/neflix-push-messaging-scale)\n\t* [Delaying Asynchronous Message Processing with RabbitMQ at Indeed](http://engineering.indeedblog.com/blog/2017/06/delaying-messages/)\t\n\t* [Benchmarking Streaming Computation Engines at Yahoo](https://yahooeng.tumblr.com/post/135321837876/benchmarking-streaming-computation-engines-at)\n\t* [Improving Stream Data Quality With Protobuf Schema Validation at Deliveroo](https://deliveroo.engineering/2019/02/05/improving-stream-data-quality-with-protobuf-schema-validation.html)\n\t* [Scaling Email Infrastructure at Medium](https://medium.engineering/scaling-email-infrastructure-for-medium-digest-254223c883b8)\n\t* [Event Stream Database at Nike](https://medium.com/nikeengineering/moving-faster-with-aws-by-creating-an-event-stream-database-dedec8ca3eeb)\n    * [Event-Driven Messaging](https://martinfowler.com/articles/201701-event-driven.html)\n        * [Domain-Driven Design at Alibaba](https://medium.com/swlh/creating-coding-excellence-with-domain-driven-design-88f73d2232c3)\n        * [Domain-Driven Design at Weebly](https://medium.com/weebly-engineering/how-to-organize-your-monolith-before-breaking-it-into-services-69cbdb9248b0)\n        * [Domain-Driven Design at Moonpig](https://engineering.moonpig.com/development/modelling-for-domain-driven-design)\n        * [Scaling Event Sourcing for Netflix Downloads](https://www.infoq.com/presentations/netflix-scale-event-sourcing)\n        * [Scaling Event-Sourcing at Jet.com](https://medium.com/@eulerfx/scaling-event-sourcing-at-jet-9c873cac33b8)\n        * [Event Sourcing (2 parts) at eBay](https://www.ebayinc.com/stories/blogs/tech/event-sourcing-in-action-with-ebays-continuous-delivery-team/)\n\t\t* [Event Sourcing at FREE NOW](https://medium.com/inside-freenow/event-sourcing-an-evolutionary-perspective-31e7387aa6f1)\n\t\t* [Scalable content feed using Event Sourcing and CQRS patterns at Brainly](https://medium.com/engineering-brainly/scalable-content-feed-using-event-sourcing-and-cqrs-patterns-e09df98bf977)\n    * [Pub-Sub Messaging](https://aws.amazon.com/pub-sub-messaging/)\n\t\t* [Pulsar: Pub-Sub Messaging at Scale at Yahoo](https://yahooeng.tumblr.com/post/150078336821/open-sourcing-pulsar-pub-sub-messaging-at-scale)\n\t\t* [Wormhole: Pub-Sub System at Facebook](https://code.facebook.com/posts/188966771280871/wormhole-pub-sub-system-moving-data-through-space-and-time/)\n\t\t* [MemQ: Cloud Native Pub-Sub System at Pinterest](https://medium.com/pinterest-engineering/memq-an-efficient-scalable-cloud-native-pubsub-system-4402695dd4e7)\n\t\t* [Pub-Sub in Chatting Architecture at LINE](https://engineering.linecorp.com/en/blog/detail/85)\n\t\t* [Pub-Sub in Microservices at Netflix](https://medium.com/netflix-techblog/how-netflix-microservices-tackle-dataset-pub-sub-4a068adcc9a)\n\t* [Kafka - Message Broker](https://martin.kleppmann.com/papers/kafka-debull15.pdf)\t\n\t\t* [Kafka at LinkedIn](https://engineering.linkedin.com/kafka/running-kafka-scale)\n\t\t* [Kafka at Pinterest](https://medium.com/pinterest-engineering/how-pinterest-runs-kafka-at-scale-ff9c6f735be)\n\t\t* [Kafka at Trello](https://tech.trello.com/why-we-chose-kafka/)\t\n\t\t* [Kafka at Salesforce](https://engineering.salesforce.com/how-apache-kafka-inspired-our-platform-events-architecture-2f351fe4cf63)\n\t\t* [Kafka at The New York Times](https://open.nytimes.com/publishing-with-apache-kafka-at-the-new-york-times-7f0e3b7d2077)\n\t\t* [Kafka at Yelp](https://engineeringblog.yelp.com/2016/07/billions-of-messages-a-day-yelps-real-time-data-pipeline.html)\n\t\t* [Kafka at Criteo](https://medium.com/criteo-labs/upgrading-kafka-on-a-large-infra-3ee99f56e970)\n\t\t* [Kafka on Kubernetes at Shopify](https://shopifyengineering.myshopify.com/blogs/engineering/running-apache-kafka-on-kubernetes-at-shopify)\n\t\t* [Kafka on PaaSTA: Running Kafka on Kubernetes at Yelp (2 parts)](https://engineeringblog.yelp.com/2022/03/kafka-on-paasta-part-two.html)\n\t\t* [Migrating Kafka's Zookeeper with No Downtime at Yelp](https://engineeringblog.yelp.com/2019/01/migrating-kafkas-zookeeper-with-no-downtime.html)\n\t\t* [Reprocessing and Dead Letter Queues with Kafka at Uber](https://eng.uber.com/reliable-reprocessing/)\n\t\t* [Chaperone: Audit Kafka End-to-End at Uber](https://eng.uber.com/chaperone/)\n\t\t* [Finding Kafka throughput limit in infrastructure at Dropbox](https://blogs.dropbox.com/tech/2019/01/finding-kafkas-throughput-limit-in-dropbox-infrastructure/)\n\t\t* [Cost Orchestration at Walmart](https://medium.com/walmartlabs/cost-orchestration-at-walmart-f34918af67c4)\n\t\t* [InfluxDB and Kafka to Scale to Over 1 Million Metrics a Second at Hulu](https://medium.com/hulu-tech-blog/how-hulu-uses-influxdb-and-kafka-to-scale-to-over-1-million-metrics-a-second-1721476aaff5)\n\t* [Stream Data Deduplication](https://en.wikipedia.org/wiki/Data_deduplication)\n\t\t* [Exactly-once Semantics with Kafka](https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/)\n\t\t* [Real-time Deduping at Tapjoy](http://eng.tapjoy.com/blog-list/real-time-deduping-at-scale)\n\t\t* [Deduplication at Segment](https://segment.com/blog/exactly-once-delivery/)\n\t\t* [Deduplication at Mail.Ru](https://medium.com/@andrewsumin/efficient-storage-how-we-went-down-from-50-pb-to-32-pb-99f9c61bf6b4)\n\t\t* [Petabyte Scale Data Deduplication at Mixpanel](https://medium.com/mixpaneleng/petabyte-scale-data-deduplication-mixpanel-engineering-e808c70c99f8)\n* [Distributed Logging](https://blog.codinghorror.com/the-problem-with-logging/)\n\t* [Logging at LinkedIn](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying)\n\t* [Scalable and Reliable Log Ingestion at Pinterest](https://medium.com/@Pinterest_Engineering/scalable-and-reliable-data-ingestion-at-pinterest-b921c2ee8754)\n\t* [High-performance Replicated Log Service at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2015/building-distributedlog-twitter-s-high-performance-replicated-log-servic.html)\n\t* [Logging Service with Spark at CERN Accelerator](https://databricks.com/blog/2017/12/14/the-architecture-of-the-next-cern-accelerator-logging-service.html)\n\t* [Logging and Aggregation at Quora](https://engineering.quora.com/Logging-and-Aggregation-at-Quora)\n\t* [Collection and Analysis of Daemon Logs at Badoo](https://badoo.com/techblog/blog/2016/06/06/collection-and-analysis-of-daemon-logs-at-badoo/)\n\t* [Log Parsing with Static Code Analysis at Palantir](https://medium.com/palantir/using-static-code-analysis-to-improve-log-parsing-18f0d1843965)\t\t\n\t* [Centralized Application Logging at eBay](https://tech.ebayinc.com/engineering/low-latency-and-high-throughput-cal-ingress/)\n\t* [Enrich VPC Flow Logs at Hyper Scale to provide Network Insight at Netflix](https://netflixtechblog.com/hyper-scale-vpc-flow-logs-enrichment-to-provide-network-insight-e5f1db02910d)\t\n\t* [BookKeeper: Distributed Log Storage at Yahoo](https://yahooeng.tumblr.com/post/109908973316/bookkeeper-yahoos-distributed-log-storage-is)\n\t* [LogDevice: Distributed Data Store for Logs at Facebook](https://code.facebook.com/posts/357056558062811/logdevice-a-distributed-data-store-for-logs/)\n\t* [LogFeeder: Log Collection System at Yelp](https://engineeringblog.yelp.com/2018/03/introducing-logfeeder.html)\n\t* [DBLog: Generic Change-Data-Capture Framework at Netflix](https://medium.com/netflix-techblog/dblog-a-generic-change-data-capture-framework-69351fb9099b)\t\n* [Distributed Searching](http://nwds.cs.washington.edu/files/nwds/pdf/Distributed-WR.pdf)\n\t* [Search Architecture at Instagram](https://instagram-engineering.com/search-architecture-eeb34a936d3a)\n\t* [Search Architecture at eBay](http://www.cs.otago.ac.nz/homepages/andrew/papers/2017-8.pdf)\n\t* [Search Architecture at Box](https://medium.com/box-tech-blog/scaling-box-search-using-lumos-22d9e0cb4175)\n\t* [Search Discovery Indexing Platform at Coupang](https://medium.com/coupang-tech/the-evolution-of-search-discovery-indexing-platform-fa43e41305f9)\n\t* [Universal Search System at Pinterest](https://medium.com/pinterest-engineering/building-a-universal-search-system-for-pinterest-e4cb03a898d4)\n\t* [Improving Search Engine Efficiency by over 25% at eBay](https://www.ebayinc.com/stories/blogs/tech/making-e-commerce-search-faster/)\t\n\t* [Indexing and Querying Telemetry Logs with Lucene at Palantir](https://medium.com/palantir/indexing-and-querying-telemetry-logs-with-lucene-234c5ce3e5f3)\n\t* [Query Understanding at TripAdvisor](https://www.tripadvisor.com/engineering/query-understanding-at-tripadvisor/)\n\t* [Search Federation Architecture at LinkedIn (2018)](https://engineering.linkedin.com/blog/2018/03/search-federation-architecture-at-linkedin)\n\t* [Search at Slack](https://slack.engineering/search-at-slack-431f8c80619e)\n\t* [Search and Recommendations at DoorDash](https://blog.doordash.com/powering-search-recommendations-at-doordash-8310c5cfd88c)\n\t* [Search Service at Twitter (2014)](https://blog.twitter.com/engineering/en_us/a/2014/building-a-complete-tweet-index.html)\n\t* [Autocomplete Search (2 parts) at Traveloka](https://medium.com/traveloka-engineering/high-quality-autocomplete-search-part-2-d5b15bb0dadf)\n\t* [Data-Driven Autocorrection System at Canva](https://product.canva.com/building-a-data-driven-autocorrection-system/)\n\t* [Adapting Search to Indian Phonetics at Flipkart](https://blog.flipkart.tech/adapting-search-to-indian-phonetics-cdbe65259686)\n\t* [Nautilus: Search Engine at Dropbox](https://blogs.dropbox.com/tech/2018/09/architecture-of-nautilus-the-new-dropbox-search-engine/)\n\t* [Galene: Search Architecture of LinkedIn](https://engineering.linkedin.com/search/did-you-mean-galene)\n\t* [Manas: High Performing Customized Search System at Pinterest](https://medium.com/@Pinterest_Engineering/manas-a-high-performing-customized-search-system-cf189f6ca40f)\n\t* [Sherlock: Near Real Time Search Indexing at Flipkart](https://blog.flipkart.tech/sherlock-near-real-time-search-indexing-95519783859d)\n\t* [Nebula: Storage Platform to Build Search Backends at Airbnb](https://medium.com/airbnb-engineering/nebula-as-a-storage-platform-to-build-airbnbs-search-backends-ecc577b05f06)\n\t* [ELK (Elasticsearch, Logstash, Kibana) Stack](https://logz.io/blog/15-tech-companies-chose-elk-stack/)\n\t\t* [Predictions in Real Time with ELK at Uber](https://eng.uber.com/elk/)\n\t\t* [Building a scalable ELK stack at Envato](https://webuild.envato.com/blog/building-a-scalable-elk-stack/)\n\t\t* [ELK at Robinhood](https://robinhood.engineering/taming-elk-4e1349f077c3)\n\t\t* [Scaling Elasticsearch Clusters at Uber](https://www.infoq.com/presentations/uber-elasticsearch-clusters?utm_source=presentations_about_Case_Study&utm_medium=link&utm_campaign=Case_Study)\n\t\t* [Elasticsearch Performance Tuning Practice at eBay](https://www.ebayinc.com/stories/blogs/tech/elasticsearch-performance-tuning-practice-at-ebay/)\n\t\t* [Improve Performance using Elasticsearch Plugins (2 parts) at Tinder](https://medium.com/tinder-engineering/how-we-improved-our-performance-using-elasticsearch-plugins-part-2-b051da2ee85b)\n\t\t* [Elasticsearch at Kickstarter](https://kickstarter.engineering/elasticsearch-at-kickstarter-db3c487887fc)\n\t\t* [Log Parsing with Logstash and Google Protocol Buffers at Trivago](https://tech.trivago.com/2016/01/19/logstash_protobuf_codec/)\n\t\t* [Fast Order Search using Data Pipeline and Elasticsearch at Yelp](https://engineeringblog.yelp.com/2018/06/fast-order-search.html)\n\t\t* [Moving Core Business Search to Elasticsearch at Yelp](https://engineeringblog.yelp.com/2017/06/moving-yelps-core-business-search-to-elasticsearch.html)\n\t\t* [Sharding out Elasticsearch at Vinted](http://engineering.vinted.com/2017/06/05/sharding-out-elasticsearch/)\n\t\t* [Self-Ranking Search with Elasticsearch at Wattpad](http://engineering.wattpad.com/post/146216619727/self-ranking-search-with-elasticsearch-at-wattpad)\n\t\t* [Vulcanizer: a library for operating Elasticsearch at Github](https://github.blog/2019-03-05-vulcanizer-a-library-for-operating-elasticsearch/)\t\n* [Distributed Storage](http://highscalability.com/blog/2011/11/1/finding-the-right-data-solution-for-your-application-in-the.html)\n\t* [In-memory Storage](https://medium.com/@denisanikin/what-an-in-memory-database-is-and-how-it-persists-data-efficiently-f43868cff4c1)\n\t\t* [MemSQL Architecture - The Fast (MVCC, InMem, LockFree, CodeGen) And Familiar (SQL)](http://highscalability.com/blog/2012/8/14/memsql-architecture-the-fast-mvcc-inmem-lockfree-codegen-and.html)\n\t\t* [Optimizing Memcached Efficiency at Quora](https://engineering.quora.com/Optimizing-Memcached-Efficiency)\n\t\t* [Real-Time Data Warehouse with MemSQL on Cisco UCS](https://blogs.cisco.com/datacenter/memsql)\n\t\t* [Moving to MemSQL at Tapjoy](http://eng.tapjoy.com/blog-list/moving-to-memsql)\n\t\t* [MemSQL and Kinesis for Real-time Insights at Disney](https://conferences.oreilly.com/strata/strata-ca/public/schedule/detail/68131)\n\t\t* [MemSQL to Query Hundreds of Billions of Rows in a Dashboard at Pandora](https://engineering.pandora.com/using-memsql-at-pandora-79a86cb09b57)\n\t* [Object Storage](http://www.datacenterknowledge.com/archives/2013/10/04/object-storage-the-future-of-scale-out)\n\t\t* [Scaling HDFS at Uber](https://eng.uber.com/scaling-hdfs/)\n\t\t* [Reasons for Choosing S3 over HDFS at Databricks](https://databricks.com/blog/2017/05/31/top-5-reasons-for-choosing-s3-over-hdfs.html)\n\t\t* [File System on Amazon S3 at Quantcast](https://www.quantcast.com/blog/quantcast-file-system-on-amazon-s3/)\n\t\t* [Image Recovery at Scale Using S3 Versioning at Trivago](https://tech.trivago.com/2018/09/03/efficient-image-recovery-at-scale-using-amazon-s3-versioning/)\n\t\t* [Cloud Object Store at Yahoo](https://yahooeng.tumblr.com/post/116391291701/yahoo-cloud-object-store-object-storage-at)\n\t\t* [Ambry: Distributed Immutable Object Store at LinkedIn](https://www.usenix.org/conference/srecon17americas/program/presentation/shenoy)\n\t\t* [Dynamometer: Scale Testing HDFS on Minimal Hardware with Maximum Fidelity at LinkedIn](https://engineering.linkedin.com/blog/2018/02/dynamometer--scale-testing-hdfs-on-minimal-hardware-with-maximum)\n\t\t* [Hammerspace: Persistent, Concurrent, Off-heap Storage at Airbnb](https://medium.com/airbnb-engineering/hammerspace-persistent-concurrent-off-heap-storage-3db39bb04472)\n\t\t* [MezzFS: Mounting Object Storage in Media Processing Platform at Netflix](https://medium.com/netflix-techblog/mezzfs-mounting-object-storage-in-netflixs-media-processing-platform-cda01c446ba)\t\n\t\t* [Magic Pocket: In-house Multi-exabyte Storage System at Dropbox](https://blogs.dropbox.com/tech/2016/05/inside-the-magic-pocket/)\n* [Relational Databases](https://www.mysql.com/products/cluster/scalability.html)\n\t* [MySQL for Schema-less Data at FriendFeed](https://backchannel.org/blog/friendfeed-schemaless-mysql)\n\t* [MySQL at Pinterest](https://medium.com/@Pinterest_Engineering/learn-to-stop-using-shiny-new-things-and-love-mysql-3e1613c2ce14)\n\t* [PostgreSQL at Twitch](https://blog.twitch.tv/how-twitch-uses-postgresql-c34aa9e56f58)\n\t* [Scaling MySQL-based Financial Reporting System at Airbnb](https://medium.com/airbnb-engineering/tracking-the-money-scaling-financial-reporting-at-airbnb-6d742b80f040)\n\t* [Scaling MySQL at Wix](https://www.wix.engineering/post/scaling-to-100m-mysql-is-a-better-nosql)\n\t* [MaxScale (MySQL) Database Proxy at Airbnb](https://medium.com/airbnb-engineering/unlocking-horizontal-scalability-in-our-web-serving-tier-d907449cdbcf)\n\t* [Switching from Postgres to MySQL at Uber](https://eng.uber.com/mysql-migration/)\n\t* [Handling Growth with Postgres at Instagram](https://engineering.instagram.com/handling-growth-with-postgres-5-tips-from-instagram-d5d7e7ffdfcb)\n\t* [Scaling the Analytics Database (Postgres) at TransferWise](http://tech.transferwise.com/scaling-our-analytics-database/)\n\t* [Updating a 50 Terabyte PostgreSQL Database at Adyen](https://medium.com/adyen/updating-a-50-terabyte-postgresql-database-f64384b799e7)\n\t* [Scaling Database Access for 100s of Billions of Queries per Day at PayPal](https://medium.com/paypal-engineering/scaling-database-access-for-100s-of-billions-of-queries-per-day-paypal-introducing-hera-e192adacda54)\n\t* [Minimizing Read-Write MySQL Downtime at Yelp](https://engineeringblog.yelp.com/2020/11/minimizing-read-write-mysql-downtime.html)\n\t* [Migrating MySQL from 5.6 to 8.0 at Facebook](https://engineering.fb.com/2021/07/22/data-infrastructure/mysql/)\n\t* [Migration from HBase to MyRocks at Quora](https://quoraengineering.quora.com/Migration-from-HBase-to-MyRocks-at-Quora)\n\t* [Replication](https://docs.microsoft.com/en-us/sql/relational-databases/replication/types-of-replication)\n\t\t* [MySQL Parallel Replication (4 parts) at Booking.com](https://medium.com/booking-com-infrastructure/evaluating-mysql-parallel-replication-part-4-annex-under-the-hood-eb456cf8b2fb)\n\t\t* [Mitigating MySQL Replication Lag and Reducing Read Load at Github](https://githubengineering.com/mitigating-replication-lag-and-reducing-read-load-with-freno/)\n\t\t* [Read Consistency with Database Replicas at Shopify](https://shopify.engineering/read-consistency-database-replicas)\n\t\t* [Black-Box Auditing: Verifying End-to-End Replication Integrity between MySQL and Redshift at Yelp](https://engineeringblog.yelp.com/2018/04/black-box-auditing.html)\n\t\t* [Partitioning Main MySQL Database at Airbnb](https://medium.com/airbnb-engineering/how-we-partitioned-airbnb-s-main-database-in-two-weeks-55f7e006ff21)\n\t\t* [Herb: Multi-DC Replication Engine for Schemaless Datastore at Uber](https://eng.uber.com/herb-datacenter-replication/)\n\t* [Sharding](https://quabase.sei.cmu.edu/mediawiki/index.php/Shard_data_set_across_multiple_servers_(Range-based))\n\t\t* [Sharding MySQL at Pinterest](https://medium.com/@Pinterest_Engineering/sharding-pinterest-how-we-scaled-our-mysql-fleet-3f341e96ca6f)\n\t\t* [Sharding MySQL at Twilio](https://www.twilio.com/engineering/2014/06/26/how-we-replaced-our-data-pipeline-with-zero-downtime)\n\t\t* [Sharding MySQL at Square](https://medium.com/square-corner-blog/sharding-cash-10280fa3ef3b)\n\t\t* [Sharding MySQL at Quora](https://www.quora.com/q/quoraengineering/MySQL-sharding-at-Quora)\n\t\t* [Sharding Layer of Schemaless Datastore at Uber](https://eng.uber.com/schemaless-rewrite/)\n\t\t* [Sharding & IDs at Instagram](https://instagram-engineering.com/sharding-ids-at-instagram-1cf5a71e5a5c)\n\t\t* [Sharding Postgres at Notion](https://www.notion.so/blog/sharding-postgres-at-notion)\n\t\t* [Solr: Improving Performance for Batch Indexing at Box](https://blog.box.com/blog/solr-improving-performance-batch-indexing/)\t\n\t\t* [Geosharded Recommendations (3 parts) at Tinder](https://medium.com/tinder-engineering/geosharded-recommendations-part-3-consistency-2d2cb2f0594b)\n\t\t* [Scaling Services with Shard Manager at Facebook](https://engineering.fb.com/production-engineering/scaling-services-with-shard-manager/)\n\t* [Presto the Distributed SQL Query Engine](https://research.fb.com/wp-content/uploads/2019/03/Presto-SQL-on-Everything.pdf?)\n\t\t* [Presto at Pinterest](https://medium.com/@Pinterest_Engineering/presto-at-pinterest-a8bda7515e52)\n\t\t* [Presto Infrastructure at Lyft](https://eng.lyft.com/presto-infrastructure-at-lyft-b10adb9db01)\n\t\t* [Presto at Grab](https://engineering.grab.com/scaling-like-a-boss-with-presto)\n\t\t* [Engineering Data Analytics with Presto and Apache Parquet at Uber](https://eng.uber.com/presto/)\n\t\t* [Data Wrangling at Slack](https://slack.engineering/data-wrangling-at-slack-f2e0ff633b69)\n\t\t* [Presto in Big Data Platform on AWS at Netflix](https://medium.com/netflix-techblog/using-presto-in-our-big-data-platform-on-aws-938035909fd4)\n\t\t* [Presto Auto Scaling at Eventbrite](https://www.eventbrite.com/engineering/big-data-workloads-presto-auto-scaling/)\n* [NoSQL Databases](https://www.thoughtworks.com/insights/blog/nosql-databases-overview)\n\t* [Key-Value Databases](http://www.cs.ucsb.edu/~agrawal/fall2009/dynamo.pdf)\n\t\t* [DynamoDB at Nike](https://medium.com/nikeengineering/becoming-a-nimble-giant-how-dynamo-db-serves-nike-at-scale-4cc375dbb18e)\n\t\t* [DynamoDB at Segment](https://segment.com/blog/the-million-dollar-eng-problem/)\n\t\t* [DynamoDB at Mapbox](https://blog.mapbox.com/scaling-mapbox-infrastructure-with-dynamodb-streams-d53eabc5e972)\n\t\t* [Manhattan: Distributed Key-Value Database at Twitter](https://blog.twitter.com/engineering/en_us/a/2014/manhattan-our-real-time-multi-tenant-distributed-database-for-twitter-scale.html)\n\t\t* [Sherpa: Distributed NoSQL Key-Value Store at Yahoo](https://yahooeng.tumblr.com/post/120730204806/sherpa-scales-new-heights)\n\t\t* [HaloDB: Embedded Key-Value Storage Engine at Yahoo](https://yahooeng.tumblr.com/post/178262468576/introducing-halodb-a-fast-embedded-key-value)\n\t\t* [MPH: Fast and Compact Immutable Key-Value Stores at Indeed](http://engineering.indeedblog.com/blog/2018/02/indeed-mph/)\n\t\t* [Venice: Distributed Key-Value Database at Linkedin](https://engineering.linkedin.com/blog/2017/02/building-venice-with-apache-helix)\n\t* [Columnar Databases](https://aws.amazon.com/nosql/columnar/)\n\t\t* [Cassandra](http://www.cs.cornell.edu/projects/ladis2009/papers/lakshman-ladis2009.pdf)\n\t\t\t* [Cassandra at Instagram](https://www.slideshare.net/DataStax/cassandra-at-instagram-2016)\n\t\t\t* [Storing Images in Cassandra at Walmart](https://medium.com/walmartlabs/building-object-store-storing-images-in-cassandra-walmart-scale-a6b9c02af593)\n\t\t\t* [Storing Messages with Cassandra at Discord](https://blog.discordapp.com/how-discord-stores-billions-of-messages-7fa6ec7ee4c7)\n\t\t\t* [Scaling Cassandra Cluster at Walmart](https://medium.com/walmartlabs/avoid-pitfalls-in-scaling-your-cassandra-cluster-lessons-and-remedies-a71ca01f8c04)\n\t\t\t* [Scaling Ad Analytics with Cassandra at Yelp](https://engineeringblog.yelp.com/2016/08/how-we-scaled-our-ad-analytics-with-cassandra.html)\n\t\t\t* [Scaling to 100+ Million Reads/Writes using Spark and Cassandra at Dream11](https://medium.com/dream11-tech-blog/leaderboard-dream11-4efc6f93c23e)\t\t\n\t\t\t* [Moving Food Feed from Redis to Cassandra at Zomato](https://www.zomato.com/blog/how-we-moved-our-food-feed-from-redis-to-cassandra)\n\t\t\t* [Benchmarking Cassandra Scalability on AWS at Netflix](https://medium.com/netflix-techblog/benchmarking-cassandra-scalability-on-aws-over-a-million-writes-per-second-39f45f066c9e)\n\t\t\t* [Service Decomposition at Scale with Cassandra at Intuit QuickBooks](https://quickbooks-engineering.intuit.com/service-decomposition-at-scale-70405ac2f637)\n\t\t\t* [Cassandra for Keeping Counts In Sync at SoundCloud](https://developers.soundcloud.com/blog/keeping-counts-in-sync)\n\t\t\t* [Cassandra Driver Configuration for Improved Performance and Load Balancing at Glassdoor](https://medium.com/glassdoor-engineering/cassandra-driver-configuration-for-improved-performance-and-load-balancing-1b0106ce12bb)\n\t\t\t* [cstar: Cassandra Orchestration Tool at Spotify](https://labs.spotify.com/2018/09/04/introducing-cstar-the-spotify-cassandra-orchestration-tool-now-open-source/)\n\t\t* [HBase](https://hbase.apache.org/)\n\t\t\t* [HBase at Salesforce](https://engineering.salesforce.com/investing-in-big-data-apache-hbase-b9d98661a66b)\n\t\t\t* [HBase in Facebook Messages](https://www.facebook.com/notes/facebook-engineering/the-underlying-technology-of-messages/454991608919/)\n\t\t\t* [HBase in Imgur Notification](https://blog.imgur.com/2015/09/15/tech-tuesday-imgur-notifications-from-mysql-to-hbase/)\n\t\t\t* [Improving HBase Backup Efficiency at Pinterest](https://medium.com/@Pinterest_Engineering/improving-hbase-backup-efficiency-at-pinterest-86159da4b954)\n\t\t\t* [HBase at Xiaomi](https://www.slideshare.net/HBaseCon/hbase-practice-at-xiaomi)\n\t\t* [Redshift](https://www.allthingsdistributed.com/2018/11/amazon-redshift-performance-optimization.html)\n\t\t\t* [Redshift at GIPHY](https://engineering.giphy.com/scaling-redshift-without-scaling-costs/)\n\t\t\t* [Redshift at Hudl](https://www.hudl.com/bits/the-low-hanging-fruit-of-redshift-performance)\n\t\t\t* [Redshift at Drivy](https://drivy.engineering/redshift_tips_ticks_part_1/)\n\t* [Document Databases](https://msdn.microsoft.com/en-us/magazine/hh547103.aspx)\n\t\t* [eBay: Building Mission-Critical Multi-Data Center Applications with MongoDB](https://www.mongodb.com/blog/post/ebay-building-mission-critical-multi-data-center-applications-with-mongodb)\n\t\t* [MongoDB at Baidu: Multi-Tenant Cluster Storing 200+ Billion Documents across 160 Shards](https://www.mongodb.com/blog/post/mongodb-at-baidu-powering-100-apps-across-600-nodes-at-pb-scale)\n\t\t* [Migrating Mongo Data at Addepar](https://medium.com/build-addepar/migrating-mountains-of-mongo-data-63e530539952)\n\t\t* [The AWS and MongoDB Infrastructure of Parse (acquired by Facebook)](https://medium.baqend.com/parse-is-gone-a-few-secrets-about-their-infrastructure-91b3ab2fcf71)\n\t\t* [Migrating Mountains of Mongo Data at Addepar](https://medium.com/build-addepar/migrating-mountains-of-mongo-data-63e530539952)\n\t\t* [Couchbase Ecosystem at LinkedIn](https://engineering.linkedin.com/blog/2017/12/couchbase-ecosystem-at-linkedin)\n\t\t* [SimpleDB at Zendesk](https://medium.com/zendesk-engineering/resurrecting-amazon-simpledb-9404034ec506)\n\t\t* [Espresso: Distributed Document Store at LinkedIn](https://engineering.linkedin.com/espresso/introducing-espresso-linkedins-hot-new-distributed-document-store)\n\t* [Graph Databases](https://www.eecs.harvard.edu/margo/papers/systor13-bench/)\n\t\t* [FlockDB: Distributed Graph Database at Twitter](https://blog.twitter.com/engineering/en_us/a/2010/introducing-flockdb.html)\n\t\t* [TAO: Distributed Data Store for the Social Graph at Facebook](https://www.cs.cmu.edu/~pavlo/courses/fall2013/static/papers/11730-atc13-bronson.pdf)\n\t\t* [Akutan: Distributed Knowledge Graph Store at eBay](https://tech.ebayinc.com/engineering/akutan-a-distributed-knowledge-graph-store/)\n* [Time Series Databases](https://www.influxdata.com/time-series-database/)\n\t* [Beringei: High-performance Time Series Storage Engine at Facebook](https://code.facebook.com/posts/952820474848503/beringei-a-high-performance-time-series-storage-engine/)\n\t* [MetricsDB: TimeSeries Database for storing metrics at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2019/metricsdb.html)\t\n\t* [Atlas: In-memory Dimensional Time Series Database at Netflix](https://medium.com/netflix-techblog/introducing-atlas-netflixs-primary-telemetry-platform-bd31f4d8ed9a)\n\t* [Heroic: Time Series Database at Spotify](https://labs.spotify.com/2015/11/17/monitoring-at-spotify-introducing-heroic/)\n\t* [Roshi: Distributed Storage System for Time-Series Event at SoundCloud](https://developers.soundcloud.com/blog/roshi-a-crdt-system-for-timestamped-events)\n\t* [Goku: Time Series Database at Pinterest](https://medium.com/@Pinterest_Engineering/goku-building-a-scalable-and-high-performant-time-series-database-system-a8ff5758a181)\n\t* [Scaling Time Series Data Storage (2 parts) at Netflix](https://medium.com/netflix-techblog/scaling-time-series-data-storage-part-ii-d67939655586)\t\n\t* [Druid - Real-time Analytics Database](https://druid.apache.org/)\n\t\t* [Druid at Airbnb](https://medium.com/airbnb-engineering/druid-airbnb-data-platform-601c312f2a4c)\n\t\t* [Druid at Walmart](https://medium.com/walmartlabs/event-stream-analytics-at-walmart-with-druid-dcf1a37ceda7)\n\t\t* [Druid at eBay](https://tech.ebayinc.com/engineering/monitoring-at-ebay-with-druid/)\n\t\t* [Druid at Netflix](https://netflixtechblog.com/how-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06)\n* [Distributed Repositories, Dependencies, and Configurations Management](https://betterexplained.com/articles/intro-to-distributed-version-control-illustrated/)\n\t* [DGit: Distributed Git at Github](https://githubengineering.com/introducing-dgit/)\n\t* [Stemma: Distributed Git Server at Palantir](https://medium.com/@palantir/stemma-distributed-git-server-70afbca0fc29)\n\t* [Configuration Management for Distributed Systems at Flickr](https://code.flickr.net/2016/03/24/configuration-management-for-distributed-systems-using-github-and-cfg4j/)\n\t* [Git Repository at Microsoft](https://blogs.msdn.microsoft.com/bharry/2017/05/24/the-largest-git-repo-on-the-planet/)\n\t* [Solve Git Problem with Large Repositories at Microsoft](https://www.infoq.com/news/2017/02/GVFS)\t\n\t* [Single Repository at Google](https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext)\t\n\t* [Scaling Infrastructure and (Git) Workflow at Adyen](https://medium.com/adyen/from-0-100-billion-scaling-infrastructure-and-workflow-at-adyen-7b63b690dfb6)\t\n\t* [Dotfiles Distribution at Booking.com](https://medium.com/booking-com-infrastructure/dotfiles-distribution-dedb69c66a75)\n\t* [Secret Detector: Preventing Secrets in Source Code at Yelp](https://engineeringblog.yelp.com/2018/06/yelps-secret-detector.html)\n\t* [Managing Software Dependency at Scale at LinkedIn](https://engineering.linkedin.com/blog/2018/09/managing-software-dependency-at-scale)\n\t* [Merging Code in High-velocity Repositories at LinkedIn](https://engineering.linkedin.com/blog/2020/continuous-integration)\n\t* [Dynamic Configuration at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2018/dynamic-configuration-at-twitter.html)\n\t* [Dynamic Configuration at Mixpanel](https://medium.com/mixpaneleng/dynamic-configuration-at-mixpanel-94bfcf97d6b8)\n\t* [Dynamic Configuration at GoDaddy](https://sg.godaddy.com/engineering/2019/03/06/dynamic-configuration-for-nodejs/)\n* [Scaling Continuous Integration and Continuous Delivery](https://www.synopsys.com/blogs/software-security/agile-cicd-devops-glossary/)\n\t* [Continuous Integration Stack at Facebook](https://code.fb.com/web/rapid-release-at-massive-scale/)\n\t* [Continuous Integration with Distributed Repositories and Dependencies at Netflix](https://medium.com/netflix-techblog/towards-true-continuous-integration-distributed-repositories-and-dependencies-2a2e3108c051)\n\t* [Continuous Integration and Deployment with Bazel at Dropbox](https://blogs.dropbox.com/tech/2019/12/continuous-integration-and-deployment-with-bazel/)\n\t* [Continuous Deployments at BuzzFeed](https://tech.buzzfeed.com/continuous-deployments-at-buzzfeed-d171f76c1ac4)\n\t* [Screwdriver: Continuous Delivery Build System for Dynamic Infrastructure at Yahoo](https://yahooeng.tumblr.com/post/155765242061/open-sourcing-screwdriver-yahoos-continuous)\n\t* [CI/CD at Betterment](https://www.betterment.com/resources/ci-cd-shortening-the-feedback-loop/)\n\t* [CI/CD at Brainly](https://medium.com/engineering-brainly/ci-cd-at-scale-fdfb0f49e031)\n\t* [Scaling iOS CI with Anka at Shopify](https://engineering.shopify.com/blogs/engineering/scaling-ios-ci-with-anka)\n\t* [Scaling Jira Server at Yelp](https://engineeringblog.yelp.com/2019/04/Scaling-Jira-Server-Administration-For-The-Enterprise.html)\n\t* [Auto-scaling CI/CD cluster at Flexport](https://flexport.engineering/how-flexport-halved-testing-costs-with-an-auto-scaling-ci-cd-cluster-8304297222f)\n\n## Availability\n* [Resilience Engineering: Learning to Embrace Failure](https://queue.acm.org/detail.cfm?id=2371297)\t\n\t* [Resilience Engineering with Project Waterbear at LinkedIn](https://engineering.linkedin.com/blog/2017/11/resilience-engineering-at-linkedin-with-project-waterbear)\n\t* [Resiliency against Traffic Oversaturation at iHeartRadio](https://tech.iheart.com/resiliency-against-traffic-oversaturation-77c5ed92a5fb)\n\t* [Resiliency in Distributed Systems at GO-JEK](https://blog.gojekengineering.com/resiliency-in-distributed-systems-efd30f74baf4)\n\t* [Practical NoSQL Resilience Design Pattern for the Enterprise at eBay](https://www.ebayinc.com/stories/blogs/tech/practical-nosql-resilience-design-pattern-for-the-enterprise/)\n\t* [Ensuring Resilience to Disaster at Quora](https://engineering.quora.com/Ensuring-Quoras-Resilience-to-Disaster)\n\t* [Site Resiliency at Expedia](https://www.infoq.com/presentations/expedia-website-resiliency?utm_source=presentations_about_Case_Study&utm_medium=link&utm_campaign=Case_Study)\n\t* [Resiliency and Disaster Recovery with Kafka at eBay](https://tech.ebayinc.com/engineering/resiliency-and-disaster-recovery-with-kafka/)\n\t* [Disaster Recovery for Multi-Region Kafka at Uber](https://eng.uber.com/kafka/)\n* [Failover](http://cloudpatterns.org/mechanisms/failover_system)\n\t* [The Evolution of Global Traffic Routing and Failover](https://www.usenix.org/conference/srecon16/program/presentation/heady)\n\t* [Testing for Disaster Recovery Failover Testing](https://www.usenix.org/conference/srecon17asia/program/presentation/liu_zehua)\n\t* [Designing a Microservices Architecture for Failure](https://blog.risingstack.com/designing-microservices-architecture-for-failure/)\n\t* [ELB for Automatic Failover at GoSquared](https://engineering.gosquared.com/use-elb-automatic-failover)\n\t* [Eliminate the Database for Higher Availability at American Express](http://americanexpress.io/eliminate-the-database-for-higher-availability/)\n\t* [Failover with Redis Sentinel at Vinted](http://engineering.vinted.com/2015/09/03/failover-with-redis-sentinel/)\n\t* [High-availability SaaS Infrastructure at FreeAgent](http://engineering.freeagent.com/2017/02/06/ha-infrastructure-without-breaking-the-bank/)\n\t* [MySQL High Availability at GitHub](https://github.blog/2018-06-20-mysql-high-availability-at-github/)\n\t* [MySQL High Availability at Eventbrite](https://www.eventbrite.com/engineering/mysql-high-availability-at-eventbrite/)\n\t* [Business Continuity & Disaster Recovery at Walmart](https://medium.com/walmartlabs/business-continuity-disaster-recovery-in-the-microservices-world-ef2adca363df)\n* [Load Balancing](https://blog.vivekpanyam.com/scaling-a-web-service-load-balancing/)\n\t* [Introduction to Modern Network Load Balancing and Proxying](https://blog.envoyproxy.io/introduction-to-modern-network-load-balancing-and-proxying-a57f6ff80236)\n\t* [Top Five (Load Balancing) Scalability Patterns](https://www.f5.com/company/blog/top-five-scalability-patterns)\n\t* [Load Balancing infrastructure to support more than 1.3 billion users at Facebook](https://www.usenix.org/conference/srecon15europe/program/presentation/shuff)\n\t* [DHCPLB: DHCP Load Balancer at Facebook](https://code.facebook.com/posts/1734309626831603/dhcplb-an-open-source-load-balancer/)\n\t* [Katran: Scalable Network Load Balancer at Facebook](https://code.facebook.com/posts/1906146702752923/open-sourcing-katran-a-scalable-network-load-balancer/)\n\t* [Deterministic Aperture: A Distributed, Load Balancing Algorithm at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2019/daperture-load-balancer.html)\t\n\t* [Load Balancing with Eureka at Netflix](https://medium.com/netflix-techblog/netflix-shares-cloud-load-balancing-and-failover-tool-eureka-c10647ef95e5)\n\t* [Edge Load Balancing at Netflix](https://medium.com/netflix-techblog/netflix-edge-load-balancing-695308b5548c)\n\t* [Zuul 2: Cloud Gateway at Netflix](https://medium.com/netflix-techblog/open-sourcing-zuul-2-82ea476cb2b3)\n\t* [Load Balancing at Yelp](https://engineeringblog.yelp.com/2017/05/taking-zero-downtime-load-balancing-even-further.html)\n\t* [Load Balancing at Github](https://githubengineering.com/introducing-glb/)\n\t* [Consistent Hashing to Improve Load Balancing at Vimeo](https://medium.com/vimeo-engineering-blog/improving-load-balancing-with-a-new-consistent-hashing-algorithm-9f1bd75709ed)\n\t* [UDP Load Balancing at 500 pixel](https://developers.500px.com/udp-load-balancing-with-keepalived-167382d7ad08)\n\t* [QALM: QoS Load Management Framework at Uber](https://eng.uber.com/qalm/)\t\n\t* [Traffic Steering using Rum DNS at LinkedIn](https://www.usenix.org/conference/srecon17europe/program/presentation/rastogi)\n\t* [Traffic Infrastructure (Edge Network) at Dropbox](https://blogs.dropbox.com/tech/2018/10/dropbox-traffic-infrastructure-edge-network/)\n\t* [Intelligent DNS based load balancing at Dropbox](https://blogs.dropbox.com/tech/2020/01/intelligent-dns-based-load-balancing-at-dropbox/)\n\t* [Monitor DNS systems at Stripe](https://stripe.com/en-sg/blog/secret-life-of-dns)\n\t* [Multi-DNS Architecture (3 parts) at Monday](https://medium.com/monday-engineering/how-and-why-we-migrated-our-dns-from-cloudflare-to-a-multi-dns-architecture-part-3-584a470f4062)\n\t* [Dynamic Anycast DNS Infrastructure at Hulu](https://medium.com/hulu-tech-blog/building-hulus-dynamic-anycast-dns-infrastructure-985a7a11fd30)\n* [Rate Limiting](https://www.keycdn.com/support/rate-limiting/)\n\t* [Rate Limiting for Scaling to Millions of Domains at Cloudflare](https://blog.cloudflare.com/counting-things-a-lot-of-different-things/)\n\t* [Cloud Bouncer: Distributed Rate Limiting at Yahoo](https://yahooeng.tumblr.com/post/111288877956/cloud-bouncer-distributed-rate-limiting-at-yahoo)\n\t* [Scaling API with Rate Limiters at Stripe](https://stripe.com/blog/rate-limiters)\n\t* [Distributed Rate Limiting at Allegro](https://allegro.tech/2017/04/hermes-max-rate.html)\n\t* [Ratequeue: Core Queueing-And-Rate-Limiting System at Twilio](https://www.twilio.com/blog/2017/11/chaos-engineering-ratequeue-ha.html)\n\t* [Quotas Service at Grab](https://engineering.grab.com/quotas-service)\n* [Autoscaling](https://medium.com/@BotmetricHQ/top-11-hard-won-lessons-learned-about-aws-auto-scaling-5bfe56da755f)\n\t* [Autoscaling Pinterest](https://medium.com/@Pinterest_Engineering/auto-scaling-pinterest-df1d2beb4d64)\n\t* [Autoscaling Based on Request Queuing at Square](https://medium.com/square-corner-blog/autoscaling-based-on-request-queuing-c4c0f57f860f)\n\t* [Autoscaling Jenkins at Trivago](http://tech.trivago.com/2017/02/17/your-definite-guide-for-autoscaling-jenkins/)\n\t* [Autoscaling Pub-Sub Consumers at Spotify](https://labs.spotify.com/2017/11/20/autoscaling-pub-sub-consumers/)\n\t* [Autoscaling Bigtable Clusters based on CPU Load at Spotify](https://labs.spotify.com/2018/12/18/bigtable-autoscaler-saving-money-and-time-using-managed-storage/)\n\t* [Autoscaling AWS Step Functions Activities at Yelp](https://engineeringblog.yelp.com/2019/06/autoscaling-aws-step-functions-activities.html)\n\t* [Scryer: Predictive Auto Scaling Engine at Netflix](https://medium.com/netflix-techblog/scryer-netflixs-predictive-auto-scaling-engine-a3f8fc922270)\t\n\t* [Bouncer: Simple AWS Auto Scaling Rollovers at Palantir](https://medium.com/palantir/bouncer-simple-aws-auto-scaling-rollovers-c5af601d65d4)\n\t* [Clusterman: Autoscaling Mesos Clusters at Yelp](https://engineeringblog.yelp.com/2019/02/autoscaling-mesos-clusters-with-clusterman.html)\n* [Availability in Globally Distributed Storage Systems at Google](http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/36737.pdf)\t\n* [NodeJS High Availability at Yahoo](https://yahooeng.tumblr.com/post/68823943185/nodejs-high-availability)\n* [Operations (11 parts) at LinkedIn](https://www.linkedin.com/pulse/introduction-every-day-monday-operations-benjamin-purgason)\n* [Monitoring Powers High Availability for LinkedIn Feed](https://www.usenix.org/conference/srecon17americas/program/presentation/barot)\n* [Supporting Global Events at Facebook](https://code.facebook.com/posts/166966743929963/how-production-engineers-support-global-events-on-facebook/)\n* [High Availability at BlaBlaCar](https://medium.com/blablacar-tech/the-expendables-backends-high-availability-at-blablacar-8cea3b95b26b)\n* [High Availability at Netflix](https://medium.com/@NetflixTechBlog/tips-for-high-availability-be0472f2599c)\n* [High Availability Cloud Infrastructure at Twilio](https://www.twilio.com/engineering/2011/12/12/scaling-high-availablity-infrastructure-in-cloud)\n* [Automating Datacenter Operations at Dropbox](https://blogs.dropbox.com/tech/2019/01/automating-datacenter-operations-at-dropbox/)\n* [Globalizing Player Accounts at Riot Games](https://technology.riotgames.com/news/globalizing-player-accounts)\n\n## Stability\n* [Circuit Breaker](https://martinfowler.com/bliki/CircuitBreaker.html)\n\t* [Circuit Breaking in Distributed Systems](https://www.infoq.com/presentations/circuit-breaking-distributed-systems)\n\t* [Circuit Breaker for Scaling Containers](https://f5.com/about-us/blog/articles/the-art-of-scaling-containers-circuit-breakers-28919)\n\t* [Circuit Breakers for Distributed Services at LINE](https://engineering.linecorp.com/en/blog/detail/76)\n\t* [Applying Circuit Breaker to Channel Gateway at LINE](https://engineering.linecorp.com/en/blog/detail/78)\n\t* [Lessons in Resilience at SoundCloud](https://developers.soundcloud.com/blog/lessons-in-resilience-at-SoundCloud)\n\t* [Protector: Circuit Breaker for Time Series Databases at Trivago](http://tech.trivago.com/2016/02/23/protector/)\n\t* [Improved Production Stability with Circuit Breakers at Heroku](https://blog.heroku.com/improved-production-stability-with-circuit-breakers)\n\t* [Circuit Breaker at Zendesk](https://medium.com/zendesk-engineering/the-joys-of-circuit-breaking-ee6584acd687)\n\t* [Circuit Breaker at Traveloka](https://medium.com/traveloka-engineering/circuit-breakers-dont-let-your-dependencies-bring-you-down-5ba1c5cf1eec)\n\t* [Circuit Breaker at Shopify](https://shopify.engineering/circuit-breaker-misconfigured)\n* [Timeouts](https://www.javaworld.com/article/2824163/application-performance/stability-patterns-applied-in-a-restful-architecture.html)\n\t* [Fault Tolerance (Timeouts and Retries, Thread Separation, Semaphores, Circuit Breakers) at Neflix](https://medium.com/netflix-techblog/fault-tolerance-in-a-high-volume-distributed-system-91ab4faae74a)\n\t* [Enforce Timeout: A Reliability Methodology at DoorDash](https://doordash.engineering/2018/12/21/enforce-timeout-a-doordash-reliability-methodology/)\n\t* [Troubleshooting a Connection Timeout Issue with tcp_tw_recycle Enabled at eBay](https://www.ebayinc.com/stories/blogs/tech/a-vip-connection-timeout-issue-caused-by-snat-and-tcp-tw-recycle/)\n* [Crash-safe Replication for MySQL at Booking.com](https://medium.com/booking-com-infrastructure/better-crash-safe-replication-for-mysql-a336a69b317f)\n* [Bulkheads: Partition and Tolerate Failure in One Part](https://skife.org/architecture/fault-tolerance/2009/12/31/bulkheads.html)\n* [Steady State: Always Put Logs on Separate Disk](https://docs.microsoft.com/en-us/sql/relational-databases/policy-based-management/place-data-and-log-files-on-separate-drives)\n* [Throttling: Maintain a Steady Pace](http://www.sosp.org/2001/papers/welsh.pdf)\n* [Multi-Clustering: Improving Resiliency and Stability of a Large-scale Monolithic API Service at LinkedIn](https://engineering.linkedin.com/blog/2017/11/improving-resiliency-and-stability-of-a-large-scale-api)\n* [Determinism (4 parts) in League of Legends Server](https://engineering.riotgames.com/news/determinism-league-legends-fixing-divergences)\n\n## Performance\n* [Performance Optimization on OS, Storage, Database, Network](https://stackify.com/application-performance-metrics/)\n\t* [Improving Performance with Background Data Prefetching at Instagram](https://engineering.instagram.com/improving-performance-with-background-data-prefetching-b191acb39898)\n\t* [Fixing Linux filesystem performance regressions at LinkedIn](https://engineering.linkedin.com/blog/2020/fixing-linux-filesystem-performance-regressions)\n\t* [Compression Techniques to Solve Network I/O Bottlenecks at eBay](https://www.ebayinc.com/stories/blogs/tech/how-ebays-shopping-cart-used-compression-techniques-to-solve-network-io-bottlenecks/)\n\t* [Optimizing Web Servers for High Throughput and Low Latency at Dropbox](https://blogs.dropbox.com/tech/2017/09/optimizing-web-servers-for-high-throughput-and-low-latency/)\n\t* [Linux Performance Analysis in 60.000 Milliseconds at Netflix](https://medium.com/netflix-techblog/linux-performance-analysis-in-60-000-milliseconds-accc10403c55)\n\t* [Live Downsizing Google Cloud Persistent Disks (PD-SSD) at Mixpanel](https://engineering.mixpanel.com/2018/07/31/live-downsizing-google-cloud-pds-for-fun-and-profit/)\n\t* [Decreasing RAM Usage by 40% Using jemalloc with Python & Celery at Zapier](https://zapier.com/engineering/celery-python-jemalloc/)\n\t* [Reducing Memory Footprint at Slack](https://slack.engineering/reducing-slacks-memory-footprint-4480fec7e8eb)\n\t* [Continuous Load Testing at Slack](https://slack.engineering/continuous-load-testing/)\n\t* [Performance Improvements at Pinterest](https://medium.com/@Pinterest_Engineering/driving-user-growth-with-performance-improvements-cfc50dafadd7)\n\t* [Server Side Rendering at Wix](https://www.youtube.com/watch?v=f9xI2jR71Ms)\n\t* [30x Performance Improvements on MySQLStreamer at Yelp](https://engineeringblog.yelp.com/2018/02/making-30x-performance-improvements-on-yelps-mysqlstreamer.html)\n\t* [Optimizing APIs at Netflix](https://medium.com/netflix-techblog/optimizing-the-netflix-api-5c9ac715cf19)\n\t* [Performance Monitoring with Riemann and Clojure at Walmart](https://medium.com/walmartlabs/performance-monitoring-with-riemann-and-clojure-eafc07fcd375)\n\t* [Performance Tracking Dashboard for Live Games at Zynga](https://www.zynga.com/blogs/engineering/live-games-have-evolving-performance)\n\t* [Optimizing CAL Report Hadoop MapReduce Jobs at eBay](https://www.ebayinc.com/stories/blogs/tech/optimization-of-cal-report-hadoop-mapreduce-job/)\n\t* [Performance Tuning on Quartz Scheduler at eBay](https://www.ebayinc.com/stories/blogs/tech/performance-tuning-on-quartz-scheduler/)\n\t* [Profiling C++ (Part 1: Optimization, Part 2: Measurement and Analysis) at Riot Games](https://engineering.riotgames.com/news/profiling-optimisation)\n\t* [Profiling React Server-Side Rendering at HomeAway](https://medium.com/homeaway-tech-blog/profiling-react-server-side-rendering-to-free-the-node-js-event-loop-7f0fe455a901)\n\t* [Hardware-Assisted Video Transcoding at Dailymotion](https://medium.com/dailymotion-engineering/hardware-assisted-video-transcoding-at-dailymotion-66cd2db448ae)\n\t* [Cross Shard Transactions at 10 Million RPS at Dropbox](https://blogs.dropbox.com/tech/2018/11/cross-shard-transactions-at-10-million-requests-per-second/)\n\t* [API Profiling at Pinterest](https://medium.com/@Pinterest_Engineering/api-profiling-at-pinterest-6fa9333b4961)\n\t* [Pagelets Parallelize Server-side Processing at Yelp](https://engineeringblog.yelp.com/2017/07/generating-web-pages-in-parallel-with-pagelets.html)\n\t* [Improving key expiration in Redis at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2019/improving-key-expiration-in-redis.html)\n\t* [Ad Delivery Network Performance Optimization with Flame Graphs at MindGeek](https://medium.com/mindgeek-engineering-blog/ad-delivery-network-performance-optimization-with-flame-graphs-bc550cf59cf7)\n\t* [Predictive CPU isolation of containers at Netflix](https://medium.com/netflix-techblog/predictive-cpu-isolation-of-containers-at-netflix-91f014d856c7)\n\t* [Improving HDFS I/O Utilization for Efficiency at Uber](https://eng.uber.com/improving-hdfs-i-o-utilization-for-efficiency/)\n\t* [Cloud Jewels: Estimating kWh in the Cloud at Etsy](https://codeascraft.com/2020/04/23/cloud-jewels-estimating-kwh-in-the-cloud/)\n\t* [Unthrottled: Fixing CPU Limits in the Cloud (2 parts) at Indeed](https://engineering.indeedblog.com/blog/2019/12/unthrottled-fixing-cpu-limits-in-the-cloud/)\n* [Performance Optimization by Tuning Garbage Collection](https://confluence.atlassian.com/enterprise/garbage-collection-gc-tuning-guide-461504616.html)\n\t* [Garbage Collection in Java Applications at LinkedIn](https://engineering.linkedin.com/garbage-collection/garbage-collection-optimization-high-throughput-and-low-latency-java-applications)\n\t* [Garbage Collection in High-Throughput, Low-Latency Machine Learning Services at Adobe](https://medium.com/adobetech/engineering-high-throughput-low-latency-machine-learning-services-7d45edac0271)\n\t* [Garbage Collection in Redux Applications at SoundCloud](https://developers.soundcloud.com/blog/garbage-collection-in-redux-applications)\n\t* [Garbage Collection in Go Application at Twitch](https://blog.twitch.tv/go-memory-ballast-how-i-learnt-to-stop-worrying-and-love-the-heap-26c2462549a2)\n\t* [Analyzing V8 Garbage Collection Logs at Alibaba](https://www.linux.com/blog/can-nodejs-scale-ask-team-alibaba)\n\t* [Python Garbage Collection for Dropping 50% Memory Growth Per Request at Instagram](https://instagram-engineering.com/copy-on-write-friendly-python-garbage-collection-ad6ed5233ddf)\n\t* [Performance Impact of Removing Out of Band Garbage Collector (OOBGC) at Github](https://githubengineering.com/removing-oobgc/)\n\t* [Debugging Java Memory Leaks at Allegro](https://allegro.tech/2018/05/a-comedy-of-errors-debugging-java-memory-leaks.html)\n\t* [Optimizing JVM at Alibaba](https://www.youtube.com/watch?v=X4tmr3nhZRg)\n\t* [Tuning JVM Memory for Large-scale Services at Uber](https://eng.uber.com/jvm-tuning-garbage-collection/)\n\t* [Solr Performance Tuning at Walmart](https://medium.com/walmartglobaltech/solr-performance-tuning-beb7d0d0f8d9)\n\t* [Memory Tuning a High Throughput Microservice at Flipkart](https://blog.flipkart.tech/memory-tuning-a-high-throughput-microservice-ed57b3e60997)\n* [Performance Optimization on Image, Video, Page Load](https://developers.google.com/web/fundamentals/performance/why-performance-matters/)\n\t* [Optimizing 360 Photos at Scale at Facebook](https://code.facebook.com/posts/129055711052260/optimizing-360-photos-at-scale/)\n\t* [Reducing Image File Size in the Photos Infrastructure at Etsy](https://codeascraft.com/2017/05/30/reducing-image-file-size-at-etsy/)\n\t* [Improving GIF Performance at Pinterest](https://medium.com/@Pinterest_Engineering/improving-gif-performance-on-pinterest-8dad74bf92f1)\n\t* [Optimizing Video Playback Performance at Pinterest](https://medium.com/@Pinterest_Engineering/optimizing-video-playback-performance-caf55ce310d1)\n\t* [Optimizing Video Stream for Low Bandwidth with Dynamic Optimizer at Netflix](https://medium.com/netflix-techblog/optimized-shot-based-encodes-now-streaming-4b9464204830)\n\t* [Adaptive Video Streaming at YouTube](https://youtube-eng.googleblog.com/2018/04/making-high-quality-video-efficient.html)\n    * [Reducing Video Loading Time at Dailymotion](https://medium.com/dailymotion/reducing-video-loading-time-fa9c997a2294)\n\t* [Improving Homepage Performance at Zillow](https://www.zillow.com/engineering/improving-homepage-performance/)\n\t* [The Process of Optimizing for Client Performance at Expedia](https://medium.com/expedia-engineering/go-fast-or-go-home-the-process-of-optimizing-for-client-performance-57bb497402e)\n\t* [Web Performance at BBC](https://medium.com/bbc-design-engineering/bbc-world-service-web-performance-26b08f7abfcc)\n* [Performance Optimization by Brotli Compression](https://blogs.akamai.com/2016/02/understanding-brotlis-potential.html)\n\t* [Boosting Site Speed Using Brotli Compression at LinkedIn](https://engineering.linkedin.com/blog/2017/05/boosting-site-speed-using-brotli-compression)\t\n\t* [Brotli at Booking.com](https://medium.com/booking-com-development/bookings-journey-with-brotli-978b249d34f3)\n\t* [Brotli at Treebo](https://tech.treebo.com/a-tale-of-brotli-compression-bcb071d9780a)\n\t* [Deploying Brotli for Static Content at Dropbox](https://dropbox.tech/infrastructure/deploying-brotli-for-static-content)\n\t* [Progressive Enhancement with Brotli at Yelp](https://engineeringblog.yelp.com/2017/07/progressive-enhancement-with-brotli.html)\n\t* [Speeding Up Redis with Compression at Doordash](https://doordash.engineering/2019/01/02/speeding-up-redis-with-compression/)\n* [Performance Optimization on Languages and Frameworks](https://www.techempower.com/benchmarks/)\n\t* [Python at Netflix](https://netflixtechblog.com/python-at-netflix-bba45dae649e)\n\t* [Python at scale (3 parts) at Instagram](https://instagram-engineering.com/python-at-scale-strict-modules-c0bb9245c834)\n\t* [OCaml best practices (2 parts) at Issuu](https://engineering.issuu.com/2018/12/10/our-current-ocaml-best-practices-part-2)\n\t* [PHP at Slack](https://slack.engineering/taking-php-seriously-cf7a60065329)\n\t* [Go at Trivago](https://tech.trivago.com/2020/03/02/why-we-chose-go/)\n\t* [TypeScript at Etsy](https://codeascraft.com/2021/11/08/etsys-journey-to-typescript/)\n\t* [Kotlin for taming state at Etsy](https://www.etsy.com/sg-en/codeascraft/sealed-classes-opened-my-mind)\n\t* [BPF and Go at Bumble](https://medium.com/bumble-tech/bpf-and-go-modern-forms-of-introspection-in-linux-6b9802682223)\n\t* [Ruby on Rails at GitLab](https://medium.com/gitlab-magazine/why-we-use-ruby-on-rails-to-build-gitlab-601dce4a7a38)\n\t* [Rust in production at Figma](https://medium.com/figma-design/rust-in-production-at-figma-e10a0ec31929)\n\t* [Choosing a Language Stack at WeWork](https://engineering.wework.com/choosing-a-language-stack-cac3726928f6)\n\t* [Switching from Go to Rust at Discord](https://blog.discord.com/why-discord-is-switching-from-go-to-rust-a190bbca2b1f)\n\t* [ASP.NET Core Performance Optimization at Agoda](https://medium.com/agoda-engineering/happy-asp-net-core-performance-optimization-4e21a383d299)\n\t* [Data Race Patterns in Go at Uber](https://eng.uber.com/data-race-patterns-in-go/)\t\n    \n## Intelligence\n* [Big Data](https://insights.sei.cmu.edu/sei_blog/2017/05/reference-architectures-for-big-data-systems.html)\t\n\t* [Data Platform at Uber](https://eng.uber.com/uber-big-data-platform/)\n\t* [Data Platform at BMW](https://www.unibw.de/code/events-u/jt-2018-workshops/ws3_bigdata_vortrag_widmann.pdf)\n\t* [Data Platform at Netflix](https://www.youtube.com/watch?v=CSDIThSwA7s)\n\t* [Data Platform at Flipkart](https://blog.flipkart.tech/overview-of-flipkart-data-platform-20c6d3e9a196)\n\t* [Data Platform at Coupang](https://medium.com/coupang-tech/evolving-the-coupang-data-platform-308e305a9c45)\n\t* [Data Platform at DoorDash](https://doordash.engineering/2020/09/25/how-doordash-is-scaling-its-data-platform/)\n\t* [Data Platform at Khan Academy](http://engineering.khanacademy.org/posts/khanalytics.htm)\n\t* [Data Infrastructure at Airbnb](https://medium.com/airbnb-engineering/data-infrastructure-at-airbnb-8adfb34f169c)\n\t* [Data Infrastructure at LinkedIn](https://www.infoq.com/presentations/big-data-infrastructure-linkedin)\n\t* [Data Infrastructure at GO-JEK](https://blog.gojekengineering.com/data-infrastructure-at-go-jek-cd4dc8cbd929)\n\t* [Data Ingestion Infrastructure at Pinterest](https://medium.com/@Pinterest_Engineering/scalable-and-reliable-data-ingestion-at-pinterest-b921c2ee8754)\n\t* [Data Analytics Architecture at Pinterest](https://medium.com/@Pinterest_Engineering/behind-the-pins-building-analytics-f7b508cdacab)\n\t* [Data Orchestration Service at Spotify](https://engineering.atspotify.com/2022/03/why-we-switched-our-data-orchestration-service/)\n\t* [Big Data Processing (2 parts) at Spotify](https://labs.spotify.com/2017/10/23/big-data-processing-at-spotify-the-road-to-scio-part-2/)\n\t* [Big Data Processing at Uber](https://cdn.oreillystatic.com/en/assets/1/event/160/Big%20data%20processing%20with%20Hadoop%20and%20Spark%2C%20the%20Uber%20way%20Presentation.pdf)\n\t* [Analytics Pipeline at Lyft](https://cdn.oreillystatic.com/en/assets/1/event/269/Lyft_s%20analytics%20pipeline_%20From%20Redshift%20to%20Apache%20Hive%20and%20Presto%20Presentation.pdf)\n\t* [Analytics Pipeline at Grammarly](https://tech.grammarly.com/blog/building-a-versatile-analytics-pipeline-on-top-of-apache-spark)\n\t* [Analytics Pipeline at Teads](https://medium.com/teads-engineering/give-meaning-to-100-billion-analytics-events-a-day-d6ba09aa8f44)\n\t* [ML Data Pipelines for Real-Time Fraud Prevention at PayPal](https://www.infoq.com/presentations/paypal-ml-fraud-prevention-2018)\n\t* [Big Data Analytics and ML Techniques at LinkedIn](https://cdn.oreillystatic.com/en/assets/1/event/269/Big%20data%20analytics%20and%20machine%20learning%20techniques%20to%20drive%20and%20grow%20business%20Presentation%201.pdf)\n\t* [Self-Serve Reporting Platform on Hadoop at LinkedIn](https://cdn.oreillystatic.com/en/assets/1/event/137/Building%20a%20self-serve%20real-time%20reporting%20platform%20at%20LinkedIn%20Presentation%201.pdf)\n\t* [Privacy-Preserving Analytics and Reporting at LinkedIn](https://engineering.linkedin.com/blog/2019/04/privacy-preserving-analytics-and-reporting-at-linkedin)\n\t* [Analytics Platform for Tracking Item Availability at Walmart](https://medium.com/walmartlabs/how-we-build-a-robust-analytics-platform-using-spark-kafka-and-cassandra-lambda-architecture-70c2d1bc8981)\n\t* [HALO: Hardware Analytics and Lifecycle Optimization at Facebook](https://code.fb.com/data-center-engineering/hardware-analytics-and-lifecycle-optimization-halo-at-facebook/)\n\t* [RBEA: Real-time Analytics Platform at King](https://techblog.king.com/rbea-scalable-real-time-analytics-king/)\n\t* [AresDB: GPU-Powered Real-time Analytics Engine at Uber](https://eng.uber.com/aresdb/)\n\t* [AthenaX: Streaming Analytics Platform at Uber](https://eng.uber.com/athenax/)\n\t* [Delta: Data Synchronization and Enrichment Platform at Netflix](https://medium.com/netflix-techblog/delta-a-data-synchronization-and-enrichment-platform-e82c36a79aee)\n\t* [Keystone: Real-time Stream Processing Platform at Netflix](https://medium.com/netflix-techblog/keystone-real-time-stream-processing-platform-a3ee651812a)\n\t* [Databook: Turning Big Data into Knowledge with Metadata at Uber](https://eng.uber.com/databook/)\n\t* [Amundsen: Data Discovery & Metadata Engine at Lyft](https://eng.lyft.com/amundsen-lyfts-data-discovery-metadata-engine-62d27254fbb9)\n\t* [Maze: Funnel Visualization Platform at Uber](https://eng.uber.com/maze/)\n\t* [Metacat: Making Big Data Discoverable and Meaningful at Netflix](https://medium.com/netflix-techblog/metacat-making-big-data-discoverable-and-meaningful-at-netflix-56fb36a53520)\n\t* [SpinalTap: Change Data Capture System at Airbnb](https://medium.com/airbnb-engineering/capturing-data-evolution-in-a-service-oriented-architecture-72f7c643ee6f)\n\t* [Accelerator: Fast Data Processing Framework at eBay](https://www.ebayinc.com/stories/blogs/tech/announcing-the-accelerator-processing-1-000-000-000-lines-per-second-on-a-single-computer/)\n\t* [Omid: Transaction Processing Platform at Yahoo](https://yahooeng.tumblr.com/post/180867271141/a-new-chapter-for-omid)\n\t* [TensorFlowOnSpark: Distributed Deep Learning on Big Data Clusters at Yahoo](https://yahooeng.tumblr.com/post/157196488076/open-sourcing-tensorflowonspark-distributed-deep)\n\t* [CaffeOnSpark: Distributed Deep Learning on Big Data Clusters at Yahoo](https://yahooeng.tumblr.com/post/139916828451/caffeonspark-open-sourced-for-distributed-deep)\n\t* [Spark on Scala: Analytics Reference Architecture at Adobe](https://medium.com/adobetech/spark-on-scala-adobe-analytics-reference-architecture-7457f5614b4c)\n\t* [Experimentation Platform (2 parts) at Spotify](https://engineering.atspotify.com/2020/11/02/spotifys-new-experimentation-platform-part-2/)\n\t* [Experimentation Platform at Airbnb](https://medium.com/airbnb-engineering/https-medium-com-jonathan-parks-scaling-erf-23fd17c91166)\n\t* [Smart Product Platform at Zalando](https://jobs.zalando.com/tech/blog/zalando-smart-product-platform/?gh_src=4n3gxh1)\n\t* [Log Analysis Platform at LINE](https://www.slideshare.net/wyukawa/strata2017-sg)\n\t* [Data Visualisation Platform at Myntra](https://medium.com/myntra-engineering/universal-dashboarding-platform-udp-data-visualisation-platform-at-myntra-5f2522fcf72d)\n\t* [Building and Scaling Data Lineage at Netflix](https://medium.com/netflix-techblog/building-and-scaling-data-lineage-at-netflix-to-improve-data-infrastructure-reliability-and-1a52526a7977)\n\t* [Building a scalable data management system for computer vision tasks at Pinterest](https://medium.com/@Pinterest_Engineering/building-a-scalable-data-management-system-for-computer-vision-tasks-a6dee8f1c580)\n\t* [Structured Data at Etsy](https://codeascraft.com/2019/07/31/an-introduction-to-structured-data-at-etsy/)\n\t* [Scaling a Mature Data Pipeline - Managing Overhead at Airbnb](https://medium.com/airbnb-engineering/scaling-a-mature-data-pipeline-managing-overhead-f34835cbc866)\n\t* [Spark Partitioning Strategies at Airbnb](https://medium.com/airbnb-engineering/on-spark-hive-and-small-files-an-in-depth-look-at-spark-partitioning-strategies-a9a364f908)\n\t* [Scaling the Hadoop Distributed File System at LinkedIn](https://engineering.linkedin.com/blog/2021/the-exabyte-club--linkedin-s-journey-of-scaling-the-hadoop-distr)\n\t* [Scaling Hadoop YARN cluster beyond 10,000 nodes at LinkedIn](https://engineering.linkedin.com/blog/2021/scaling-linkedin-s-hadoop-yarn-cluster-beyond-10-000-nodes)\n* [Distributed Machine Learning](https://www.csie.ntu.edu.tw/~cjlin/talks/bigdata-bilbao.pdf)\n\t* [Machine Learning Platform at Uber](https://eng.uber.com/michelangelo/)\n\t* [Machine Learning Platform at Yelp](https://engineeringblog.yelp.com/2020/07/ML-platform-overview.html)\n\t* [Machine Learning Platform at Etsy](https://codeascraft.com/2021/12/21/redesigning-etsys-machine-learning-platform/)\n\t* [Platform for Serving Recommendations at Etsy](https://www.etsy.com/sg-en/codeascraft/building-a-platform-for-serving-recommendations-at-etsy)\n\t* [Infrastructure to Run User Forecasts at Spotify](https://engineering.atspotify.com/2022/06/how-we-built-infrastructure-to-run-user-forecasts-at-spotify/)\n\t* [Aroma: Using ML for Code Recommendation at Facebook](https://code.fb.com/developer-tools/aroma/)\n\t* [Flyte: Cloud Native Machine Learning and Data Processing Platform at Lyft](https://eng.lyft.com/introducing-flyte-cloud-native-machine-learning-and-data-processing-platform-fb2bb3046a59)\n\t* [LyftLearn: ML Model Training Infrastructure built on Kubernetes at Lyft](https://eng.lyft.com/lyftlearn-ml-model-training-infrastructure-built-on-kubernetes-aef8218842bb)\n\t* [Horovod: Open Source Distributed Deep Learning Framework for TensorFlow at Uber](https://eng.uber.com/horovod/)\n\t* [COTA: Improving Customer Care with NLP & Machine Learning at Uber](https://eng.uber.com/cota/)\n\t* [Manifold: Model-Agnostic Visual Debugging Tool for Machine Learning at Uber](https://eng.uber.com/manifold/)\t\n\t* [Repo-Topix: Topic Extraction Framework at Github](https://githubengineering.com/topics/)\n\t* [Concourse: Generating Personalized Content Notifications in Near-Real-Time at LinkedIn](https://engineering.linkedin.com/blog/2018/05/concourse--generating-personalized-content-notifications-in-near)\n\t* [Altus Care: Applying a Chatbot to Platform Engineering at eBay](https://www.ebayinc.com/stories/blogs/tech/altus-care-apply-chatbot-to-ebay-platform-engineering/)\n\t* [PyKrylov: Accelerating Machine Learning Research at eBay](https://tech.ebayinc.com/engineering/pykrylov-accelerating-machine-learning-research-at-ebay/)\n\t* [Box Graph: Spontaneous Social Network at Box](https://blog.box.com/blog/box-graph-how-we-built-spontaneous-social-network/)\n\t* [PricingNet: Pricing Modelling with Neural Networks at Skyscanner](https://hackernoon.com/pricingnet-modelling-the-global-airline-industry-with-neural-networks-833844d20ea6)\n\t* [PinText: Multitask Text Embedding System at Pinterest](https://medium.com/pinterest-engineering/pintext-a-multitask-text-embedding-system-in-pinterest-b80ece364555)\n\t* [SearchSage: Learning Search Query Representations at Pinterest](https://medium.com/pinterest-engineering/searchsage-learning-search-query-representations-at-pinterest-654f2bb887fc)\n\t* [Cannes: ML saves $1.7M a year on document previews at Dropbox](https://dropbox.tech/machine-learning/cannes--how-ml-saves-us--1-7m-a-year-on-document-previews)\n\t* [Scaling Gradient Boosted Trees for Click-Through-Rate Prediction at Yelp](https://engineeringblog.yelp.com/2018/01/building-a-distributed-ml-pipeline-part1.html)\t\n\t* [Learning with Privacy at Scale at Apple](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html)\n\t* [Deep Learning for Image Classification Experiment at Mercari](https://medium.com/mercari-engineering/mercaris-image-classification-experiment-using-deep-learning-9b4e994a18ec)\n\t* [Deep Learning for Frame Detection in Product Images at Allegro](https://allegro.tech/2016/12/deep-learning-for-frame-detection.html)\n\t* [Content-based Video Relevance Prediction at Hulu](https://medium.com/hulu-tech-blog/content-based-video-relevance-prediction-b2c448e14752)\n\t* [Improving Photo Selection With Deep Learning at TripAdvisor](http://engineering.tripadvisor.com/improving-tripadvisor-photo-selection-deep-learning/)\n\t* [Personalized Recommendations for Experiences Using Deep Learning at TripAdvisor](https://www.tripadvisor.com/engineering/personalized-recommendations-for-experiences-using-deep-learning/)\n\t* [Personalised Recommender Systems at BBC](https://medium.com/bbc-design-engineering/developing-personalised-recommender-systems-at-the-bbc-e26c5e0c4216)\n\t* [Machine Learning (2 parts) at Cond\u00e9 Nast](https://technology.condenast.com/story/handbag-brand-and-color-detection)\n\t* [Natural Language Processing and Content Analysis (2 parts) at Cond\u00e9 Nast](https://technology.condenast.com/story/natural-language-processing-and-content-analysis-at-conde-nast-part-2-system-architecture)\n\t* [Mapping the World of Music Using Machine Learning (2 parts) at iHeartRadio](https://tech.iheart.com/mapping-the-world-of-music-using-machine-learning-part-2-aa50b6a0304c)\n\t* [Machine Learning to Improve Streaming Quality at Netflix](https://medium.com/netflix-techblog/using-machine-learning-to-improve-streaming-quality-at-netflix-9651263ef09f)\n\t* [Machine Learning to Match Drivers & Riders at GO-JEK](https://blog.gojekengineering.com/how-we-use-machine-learning-to-match-drivers-riders-b06d617b9e5)\n\t* [Improving Video Thumbnails with Deep Neural Nets at YouTube](https://youtube-eng.googleblog.com/2015/10/improving-youtube-video-thumbnails-with_8.html)\n\t* [Quantile Regression for Delivering On Time at Instacart](https://tech.instacart.com/how-instacart-delivers-on-time-using-quantile-regression-2383e2e03edb)\n\t* [Cross-Lingual End-to-End Product Search with Deep Learning at Zalando](https://jobs.zalando.com/tech/blog/search-deep-neural-network/)\n\t* [Machine Learning at Jane Street](https://blog.janestreet.com/real-world-machine-learning-part-1/)\n\t* [Machine Learning for Ranking Answers End-to-End at Quora](https://engineering.quora.com/A-Machine-Learning-Approach-to-Ranking-Answers-on-Quora)\n\t* [Clustering Similar Stories Using LDA at Flipboard](http://engineering.flipboard.com/2017/02/storyclustering)\n\t* [Similarity Search at Flickr](https://code.flickr.net/2017/03/07/introducing-similarity-search-at-flickr/)\n\t* [Large-Scale Machine Learning Pipeline for Job Recommendations at Indeed](http://engineering.indeedblog.com/blog/2016/04/building-a-large-scale-machine-learning-pipeline-for-job-recommendations/)\n\t* [Deep Learning from Prototype to Production at Taboola](http://engineering.taboola.com/deep-learning-from-prototype-to-production/)\n\t* [Atom Smashing using Machine Learning at CERN](https://cdn.oreillystatic.com/en/assets/1/event/144/Atom%20smashing%20using%20machine%20learning%20at%20CERN%20Presentation.pdf)\n\t* [Mapping Tags at Medium](https://medium.engineering/mapping-mediums-tags-1b9a78d77cf0)\n\t* [Clustering with the Dirichlet Process Mixture Model in Scala at Monsanto](http://engineering.monsanto.com/2015/11/23/chinese-restaurant-process/)\n\t* [Map Pins with DBSCAN & Random Forests at Foursquare](https://engineering.foursquare.com/you-are-probably-here-better-map-pins-with-dbscan-random-forests-9d51e8c1964d)\n\t* [Forecasting at Uber](https://eng.uber.com/forecasting-introduction/)\n\t* [Financial Forecasting at Uber](https://eng.uber.com/transforming-financial-forecasting-machine-learning/)\n\t* [Productionizing ML with Workflows at Twitter](https://blog.twitter.com/engineering/en_us/topics/insights/2018/ml-workflows.html)\n\t* [GUI Testing Powered by Deep Learning at eBay](https://www.ebayinc.com/stories/blogs/tech/gui-testing-powered-by-deep-learning/)\n\t* [Scaling Machine Learning to Recommend Driving Routes at Pivotal](http://engineering.pivotal.io/post/scaling-machine-learning-to-recommend-driving-routes/)\n\t* [Real-Time Predictions at DoorDash](https://www.infoq.com/presentations/doordash-real-time-predictions)\n\t* [Machine Intelligence at Dropbox](https://blogs.dropbox.com/tech/2018/09/machine-intelligence-at-dropbox-an-update-from-our-dbxi-team/)\n\t* [Machine Learning for Indexing Text from Billions of Images at Dropbox](https://blogs.dropbox.com/tech/2018/10/using-machine-learning-to-index-text-from-billions-of-images/)\n\t* [Modeling User Journeys via Semantic Embeddings at Etsy](https://codeascraft.com/2018/07/12/modeling-user-journey-via-semantic-embeddings/)\n\t* [Automated Fake Account Detection at LinkedIn](https://engineering.linkedin.com/blog/2018/09/automated-fake-account-detection-at-linkedin)\n\t* [Building Knowledge Graph at Airbnb](https://medium.com/airbnb-engineering/contextualizing-airbnb-by-building-knowledge-graph-b7077e268d5a)\n\t* [Core Modeling at Instagram](https://instagram-engineering.com/core-modeling-at-instagram-a51e0158aa48)\n\t* [Neural Architecture Search (NAS) for Prohibited Item Detection at Mercari](https://tech.mercari.com/entry/2019/04/26/163000)\n\t* [Computer Vision at Airbnb](https://medium.com/airbnb-engineering/amenity-detection-and-beyond-new-frontiers-of-computer-vision-at-airbnb-144a4441b72e)\n\t* [3D Home Backend Algorithms at Zillow](https://www.zillow.com/engineering/behind-zillow-3d-home-backend-algorithms/)\n\t* [Long-term Forecasts at Lyft](https://eng.lyft.com/making-long-term-forecasts-at-lyft-fac475b3ba52)\n\t* [Discovering Popular Dishes with Deep Learning at Yelp](https://engineeringblog.yelp.com/2019/10/discovering-popular-dishes-with-deep-learning.html)\n\t* [SplitNet Architecture for Ad Candidate Ranking at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2019/splitnet-architecture-for-ad-candidate-ranking.html)\n\t* [Jobs Filter at Indeed](https://engineering.indeedblog.com/blog/2019/09/jobs-filter/)\n\t* [Architecting Restaurant Wait Time Predictions at Yelp](https://engineeringblog.yelp.com/2019/12/architecting-wait-time-estimations.html)\n\t* [Music Personalization at Spotify](https://labs.spotify.com/2016/08/07/commodity-music-ml-services/)\n\t* [Deep Learning for Domain Name Valuation at GoDaddy](https://sg.godaddy.com/engineering/2019/07/26/domain-name-valuation/)\n\t* [Similarity Clustering to Catch Fraud Rings at Stripe](https://stripe.com/blog/similarity-clustering)\n\t* [Personalized Search at Etsy](https://codeascraft.com/2020/10/29/bringing-personalized-search-to-etsy/)\n\t* [ML Feature Serving Infrastructure at Lyft](https://eng.lyft.com/ml-feature-serving-infrastructure-at-lyft-d30bf2d3c32a)\n\t* [Context-Specific Bidding System at Etsy](https://codeascraft.com/2021/03/23/how-we-built-a-context-specific-bidding-system-for-etsy-ads/)\n\t* [Moderating Promotional Spam and Inappropriate Content in Photos at Scale at Yelp](https://engineeringblog.yelp.com/2021/05/moderating-promotional-spam-and-inappropriate-content-in-photos-at-scale-at-yelp.html)\n\t* [Optimizing Payments with Machine Learning at Dropbox](https://dropbox.tech/machine-learning/optimizing-payments-with-machine-learning)\n\n## Architecture\n* [Tech Stack (2 parts) at Uber](https://eng.uber.com/tech-stack-part-two/)\n* [Tech Stack at Medium](https://medium.engineering/the-stack-that-helped-medium-drive-2-6-millennia-of-reading-time-e56801f7c492)\n* [Tech Stack at Shopify](https://engineering.shopify.com/blogs/engineering/e-commerce-at-scale-inside-shopifys-tech-stack)\n* [Building Services (4 parts) at Airbnb](https://medium.com/airbnb-engineering/building-services-at-airbnb-part-4-23c95e428064)\n* [Architecture of Evernote](https://evernote.com/blog/a-digest-of-evernotes-architecture/)\n* [Architecture of Chat Service (3 parts) at Riot Games](https://engineering.riotgames.com/news/chat-service-architecture-persistence)\n* [Architecture of League of Legends Client Update](https://technology.riotgames.com/news/architecture-league-client-update)\n* [Architecture of Ad Platform at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2020/building-twitters-ad-platform-architecture-for-the-future.html)\n* [Architecture of API Gateway at Uber](https://eng.uber.com/architecture-api-gateway/)\n* [Basic Architecture of Slack](https://slack.engineering/how-slack-built-shared-channels-8d42c895b19f)\n* [Back-end at LinkedIn](https://engineering.linkedin.com/architecture/brief-history-scaling-linkedin)\n* [Back-end at Flickr](https://yahooeng.tumblr.com/post/157200523046/introducing-tripod-flickrs-backend-refactored)\n* [Infrastructure (3 parts) at Zendesk](https://medium.com/zendesk-engineering/the-history-of-infrastructure-at-zendesk-part-3-foundation-team-forming-and-evolving-9859e40f5390)\n* [Cloud Infrastructure at Grubhub](https://bytes.grubhub.com/cloud-infrastructure-at-grubhub-94db998a898a)\n* [Real-time Presence Platform at LinkedIn](https://engineering.linkedin.com/blog/2018/01/now-you-see-me--now-you-dont--linkedins-real-time-presence-platf)\n* [Settings Platform at LinkedIn](https://engineering.linkedin.com/blog/2019/05/building-member-trust-through-a-centralized-and-scalable-setting)\n* [Nearline System for Scale and Performance (2 parts) at Glassdoor](https://medium.com/glassdoor-engineering/building-a-nearline-system-for-scale-and-performance-part-ii-9e01bf51b23d)\n* [Real-time User Action Counting System for Ads at Pinterest](https://medium.com/@Pinterest_Engineering/building-a-real-time-user-action-counting-system-for-ads-88a60d9c9a)\n* [API Platform at Riot Games](https://engineering.riotgames.com/news/riot-games-api-deep-dive)\n* [Games Platform at The New York Times](https://open.nytimes.com/play-by-play-moving-the-nyt-games-platform-to-gcp-with-zero-downtime-cf425898d569)\n* [Kabootar: Communication Platform at Swiggy](https://bytes.swiggy.com/kabootar-swiggys-communication-platform-e5a43cc25629)\n* [Simone: Distributed Simulation Service at Netflix](https://medium.com/netflix-techblog/https-medium-com-netflix-techblog-simone-a-distributed-simulation-service-b2c85131ca1b)\n* [Seagull: Distributed System that Helps Running > 20 Million Tests Per Day at Yelp](https://engineeringblog.yelp.com/2017/04/how-yelp-runs-millions-of-tests-every-day.html)\n* [PriceAggregator: Intelligent System for Hotel Price Fetching (3 parts) at Agoda](https://medium.com/agoda-engineering/priceaggregator-an-intelligent-system-for-hotel-price-fetching-part-3-52acfc705081)\n* [Phoenix: Testing Platform (3 parts) at Tinder](https://medium.com/tinder-engineering/phoenix-tinders-testing-platform-part-iii-520728b9537)\n* [Hexagonal Architecture at Netflix](https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749)\n* [Architecture of Play API Service at Netflix](https://qconsf.com/system/files/presentation-slides/qcon_netflix_play_api.pdf)\n* [Architecture of Sticker Services at LINE](https://www.slideshare.net/linecorp/architecture-sustaining-line-sticker-services)\n* [Stack Overflow Enterprise at Palantir](https://medium.com/@palantir/terraforming-stack-overflow-enterprise-in-aws-47ee431e6be7)\n* [Architecture of Following Feed, Interest Feed, and Picked For You at Pinterest](https://medium.com/@Pinterest_Engineering/building-a-dynamic-and-responsive-pinterest-7d410e99f0a9)\n* [API Specification Workflow at WeWork](https://engineering.wework.com/our-api-specification-workflow-9337448d6ee6)\n* [Media Database at Netflix](https://medium.com/netflix-techblog/implementing-the-netflix-media-database-53b5a840b42a)\n* [Member Transaction History Architecture at Walmart](https://medium.com/walmartlabs/member-transaction-history-architecture-8b6e34b87c21)\n* [Sync Engine (2 parts) at Dropbox](https://dropbox.tech/infrastructure/-testing-our-new-sync-engine)\n* [Ads Pacing Service at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2021/how-we-built-twitter-s-highly-reliable-ads-pacing-service)\n* [Rapid Event Notification System at Netflix](https://netflixtechblog.com/rapid-event-notification-system-at-netflix-6deb1d2b57d1)\n* [Architectures of Finance and Banking Systems](https://www.sesameindia.com/images/core-banking-system-architecture)\n\t* [Bank Backend at Monzo](https://monzo.com/blog/2016/09/19/building-a-modern-bank-backend/)\n\t* [Trading Platform for Scale at Wealthsimple](https://medium.com/@Wealthsimple/engineering-at-wealthsimple-reinventing-our-trading-platform-for-scale-17e332241b6c)\n\t* [Core Banking System at Margo Bank](https://medium.com/margobank/choosing-an-architecture-85750e1e5a03)\n\t* [Architecture of Nubank](https://www.infoq.com/presentations/nubank-architecture)\n\t* [Tech Stack at TransferWise](http://tech.transferwise.com/the-transferwise-stack-heartbeat-of-our-little-revolution/)\n\t* [Tech Stack at Addepar](https://medium.com/build-addepar/our-tech-stack-a4f55dab4b0d)\n\t* [Avoiding Double Payments in a Distributed Payments System at Airbnb](https://medium.com/airbnb-engineering/avoiding-double-payments-in-a-distributed-payments-system-2981f6b070bb)\n\n## Interview\n* [Designing Large-Scale Systems](https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/)\n\t* [My Scaling Hero - Jeff Atwood (a dose of Endorphins before your interview, JK)](https://blog.codinghorror.com/my-scaling-hero/)\n\t* [Software Engineering Advice from Building Large-Scale Distributed Systems - Jeff Dean](https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf)\n\t* [Introduction to Architecting Systems for Scale](https://lethain.com/introduction-to-architecting-systems-for-scale/)\n\t* [Anatomy of a System Design Interview](https://hackernoon.com/anatomy-of-a-system-design-interview-4cb57d75a53f)\n\t* [8 Things You Need to Know Before a System Design Interview](http://blog.gainlo.co/index.php/2015/10/22/8-things-you-need-to-know-before-system-design-interviews/)\n\t* [Top 10 System Design Interview Questions ](https://hackernoon.com/top-10-system-design-interview-questions-for-software-engineers-8561290f0444)\n\t* [Top 10 Common Large-Scale Software Architectural Patterns in a Nutshell](https://towardsdatascience.com/10-common-software-architectural-patterns-in-a-nutshell-a0b47a1e9013)\n\t* [Cloud Big Data Design Patterns - Lynn Langit](https://lynnlangit.com/2017/03/14/beyond-relational/)\t\n\t* [How NOT to design Netflix in your 45-minute System Design Interview?](https://hackernoon.com/how-not-to-design-netflix-in-your-45-minute-system-design-interview-64953391a054)\n\t* [API Best Practices: Webhooks, Deprecation, and Design](https://zapier.com/engineering/api-best-practices/)\n* [Explaining Low-Level Systems (OS, Network/Protocol, Database, Storage)](https://www.cse.wustl.edu/~jain/cse567-06/ftp/os_monitors/index.html)\n\t* [The Precise Meaning of I/O Wait Time in Linux](http://veithen.github.io/2013/11/18/iowait-linux.html)\n\t* [Paxos Made Live \u2013 An Engineering Perspective](https://research.google.com/archive/paxos_made_live.html)\n\t* [How to do Distributed Locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)\n\t* [SQL Transaction Isolation Levels Explained](http://elliot.land/post/sql-transaction-isolation-levels-explained)\n* [\"What Happens When... and How\" Questions](https://www.glassdoor.com/Interview/What-happens-when-you-type-www-google-com-in-your-browser-QTN_56396.htm)\n\t* [Netflix: What Happens When You Press Play?](http://highscalability.com/blog/2017/12/11/netflix-what-happens-when-you-press-play.html)\n\t* [Monzo: How Peer-To-Peer Payments Work](https://monzo.com/blog/2018/04/05/how-monzo-to-monzo-payments-work/)\n\t* [Transit and Peering: How Your Requests Reach GitHub](https://githubengineering.com/transit-and-peering-how-your-requests-reach-github/)\n\t* [How Spotify Streams Music](https://labs.spotify.com/2018/08/31/smoother-streaming-with-bbr/)\n\n## Organization\n* [Engineering Levels at SoundCloud](https://developers.soundcloud.com/blog/engineering-levels)\n* [Engineering Roles at Palantir](https://medium.com/palantir/dev-versus-delta-demystifying-engineering-roles-at-palantir-ad44c2a6e87)\n* [Scaling Engineering Teams at Twitter](https://www.youtube.com/watch?v=-PXi_7Ld5kU)\n* [Scaling Decision-Making Across Teams at LinkedIn](https://engineering.linkedin.com/blog/2018/03/scaling-decision-making-across-teams-within-linkedin-engineering)\n* [Scaling Data Science Team at GOJEK](https://blog.gojekengineering.com/the-dynamics-of-scaling-an-organisation-cb96dbe8aecd)\n* [Scaling Agile at Zalando](https://jobs.zalando.com/tech/blog/scaling-agile-zalando/?gh_src=4n3gxh1)\n* [Scaling Agile at bol.com](https://hackernoon.com/how-we-run-bol-com-with-60-autonomous-teams-fe7a98c0759)\n* [Lessons Learned from Scaling a Product Team at Intercom](https://blog.intercom.com/how-we-build-software/)\n* [Hiring, Managing, and Scaling Engineering Teams at Typeform](https://medium.com/@eleonorazucconi/toby-oliver-cto-typeform-on-hiring-managing-and-scaling-engineering-teams-86bef9e5a708)\t\n* [Scaling the Datagram Team at Instagram](https://instagram-engineering.com/scaling-the-datagram-team-fc67bcf9b721)\n* [Scaling the Design Team at Flexport](https://medium.com/flexport-design/designing-a-design-team-a9a066bc48a5)\n* [Team Model for Scaling a Design System at Salesforce](https://medium.com/salesforce-ux/the-salesforce-team-model-for-scaling-a-design-system-d89c2a2d404b)\n* [Building Analytics Team (4 parts) at Wish](https://medium.com/wish-engineering/scaling-the-analytics-team-at-wish-part-4-recruiting-2a9823b9f5a)\n* [From 2 Founders to 1000 Employees at Transferwise](https://medium.com/transferwise-ideas/from-2-founders-to-1000-employees-how-a-small-scale-startup-grew-into-a-global-community-9f26371a551b)\n* [Lessons Learned Growing a UX Team from 10 to 170 at Adobe](https://medium.com/thinking-design/lessons-learned-growing-a-ux-team-from-10-to-170-f7b47be02262)\n* [Five Lessons from Scaling at Pinterest](https://medium.com/@sarahtavel/five-lessons-from-scaling-pinterest-6a699a889b08)\n* [Approach Engineering at Vinted](http://engineering.vinted.com/2018/09/04/how-we-approach-engineering-at-vinted/)\n* [Using Metrics to Improve the Development Process (and Coach People) at Indeed](https://engineering.indeedblog.com/blog/2018/10/using-metrics-to-improve-the-development-process-and-coach-people/)\n* [Mistakes to Avoid while Creating an Internal Product at Skyscanner](https://medium.com/@SkyscannerEng/9-mistakes-to-avoid-while-creating-an-internal-product-63d579b00b1a)\n* [RACI (Responsible, Accountable, Consulted, Informed) at Etsy](https://codeascraft.com/2018/01/04/selecting-a-cloud-provider/)\n* [Four Pillars of Leading People (Empathy, Inspiration, Trust, Honesty) at Zalando](https://jobs.zalando.com/tech/blog/four-pillars-leadership/)\n* [Pair Programming at Shopify](https://engineering.shopify.com/blogs/engineering/pair-programming-explained)\n* [Distributed Responsibility at Asana](https://blog.asana.com/2017/12/distributed-responsibility-engineering-manager/)\n* [Rotating Engineers at Zalando](https://jobs.zalando.com/tech/blog/rotating-engineers-at-zalando/)\n* [Experiment Idea Review at Pinterest](https://medium.com/pinterest-engineering/how-pinterest-supercharged-its-growth-team-with-experiment-idea-review-fd6571a02fb8)\n* [Tech Migrations at Spotify](https://engineering.atspotify.com/2020/06/25/tech-migrations-the-spotify-way/)\n* [Improving Code Ownership at Yelp](https://engineeringblog.yelp.com/2021/01/whose-code-is-it-anyway.html)\n* [Agile Code Base at eBay](https://tech.ebayinc.com/engineering/how-creating-an-agile-code-base-helped-ebay-pivot-for-apple-silicon/)\n* [Agile Data Engineering at Miro](https://medium.com/miro-engineering/agile-data-engineering-at-miro-ec2dcc8a3fcb)\n* [Automated Incident Management through Slack at Airbnb](https://medium.com/airbnb-engineering/incident-management-ae863dc5d47f)\n* [Code Review](https://ai.google/research/pubs/pub47025)\n\t* [Code Review at Palantir](https://medium.com/@palantir/code-review-best-practices-19e02780015f)\n\t* [Code Review at LINE](https://engineering.linecorp.com/en/blog/effective-code-review/)\n\t* [Code Reviews at Medium](https://medium.engineering/code-reviews-at-medium-bed2c0dce13a)\n\t* [Code Review at LinkedIn](https://engineering.linkedin.com/blog/2018/06/scaling-collective-code-ownership-with-code-reviews)\n\t* [Code Review at Disney](https://medium.com/disney-streaming/the-secret-to-better-code-reviews-c14c7884b9ac)\n\t* [Code Review at Netlify](https://www.netlify.com/blog/2020/03/05/feedback-ladders-how-we-encode-code-reviews-at-netlify/)\n\n## Talk\n* [Distributed Systems in One Lesson - Tim Berglund, Senior Director of Developer Experience at Confluent](https://www.youtube.com/watch?v=Y6Ev8GIlbxc)\n* [Building Real Time Infrastructure at Facebook - Jeff Barber and Shie Erlich, Software Engineer at Facebook](https://www.usenix.org/conference/srecon17americas/program/presentation/erlich)\n* [Building Reliable Social Infrastructure for Google - Marc Alvidrez, Senior Manager at Google](https://www.usenix.org/conference/srecon16/program/presentation/alvidrez)\n* [Building a Distributed Build System at Google Scale - Aysylu Greenberg, SDE at Google](https://www.youtube.com/watch?v=K8YuavUy6Qc)\n* [Site Reliability Engineering at Dropbox - Tammy Butow, Site Reliability Engineering Manager at Dropbox](https://www.youtube.com/watch?v=ggizCjUCCqE)\n* [How Google Does Planet-Scale for Planet-Scale Infra - Melissa Binde, SRE Director for Google Cloud Platform](https://www.youtube.com/watch?v=H4vMcD7zKM0)\n* [Netflix Guide to Microservices - Josh Evans, Director of Operations Engineering at Netflix](https://www.youtube.com/watch?v=CZ3wIuvmHeM&t=2837s)\n* [Achieving Rapid Response Times in Large Online Services - Jeff Dean, Google Senior Fellow](https://www.youtube.com/watch?v=1-3Ahy7Fxsc)\n* [Architecture to Handle 80K RPS Celebrity Sales at Shopify - Simon Eskildsen, Engineering Lead at Shopify](https://www.youtube.com/watch?v=N8NWDHgWA28)\n* [Lessons of Scale at Facebook - Bobby Johnson, Director of Engineering at Facebook](https://www.youtube.com/watch?v=QCHiNEw73AU)\n* [Performance Optimization for the Greater China Region at Salesforce - Jeff Cheng, Enterprise Architect at Salesforce](https://www.salesforce.com/video/1757880/)\n* [How GIPHY Delivers a GIF to 300 Millions Users - Alex Hoang and Nima Khoshini, Services Engineers at GIPHY](https://vimeo.com/252367076)\n* [High Performance Packet Processing Platform at Alibaba - Haiyong Wang, Senior Director at Alibaba](https://www.youtube.com/watch?v=wzsxJqeVIhY&list=PLMu8-hpCxIVENuAue7bd0eCAglLGY_8AW&index=7)\n* [Solving Large-scale Data Center and Cloud Interconnection Problems -  Ihab Tarazi, CTO at Equinix](https://atscaleconference.com/videos/solving-large-scale-data-center-and-cloud-interconnection-problems/)\n* [Scaling Dropbox - Kevin Modzelewski, Back-end Engineer at Dropbox](https://www.youtube.com/watch?v=PE4gwstWhmc)\n* [Scaling Reliability at Dropbox - Sat Kriya Khalsa, SRE at Dropbox](https://www.youtube.com/watch?v=IhGWOaD5BYQ)\n* [Scaling with Performance at Facebook - Bill Jia, VP of Infrastructure at Facebook](https://atscaleconference.com/videos/performance-scale-2018-opening-remarks/)\n* [Scaling Live Videos to a Billion Users at Facebook - Sachin Kulkarni, Director of Engineering at Facebook](https://www.youtube.com/watch?v=IO4teCbHvZw)\n* [Scaling Infrastructure at Instagram - Lisa Guo, Instagram Engineering](https://www.youtube.com/watch?v=hnpzNAPiC0E)\n* [Scaling Infrastructure at Twitter - Yao Yue, Staff Software Engineer at Twitter](https://www.youtube.com/watch?v=6OvrFkLSoZ0)\n* [Scaling Infrastructure at Etsy - Bethany Macri, Engineering Manager at Etsy](https://www.youtube.com/watch?v=LfqyhM1LeIU)\n* [Scaling Real-time Infrastructure at Alibaba for Global Shopping Holiday - Xiaowei Jiang, Senior Director at Alibaba](https://atscaleconference.com/videos/scaling-alibabas-real-time-infrastructure-for-global-shopping-holiday/)\n* [Scaling Data Infrastructure at Spotify - Matti (Lepist\u00f6) Pehrs, Spotify](https://www.youtube.com/watch?v=cdsfRXr9pJU)\n* [Scaling Pinterest - Marty Weiner, Pinterest\u2019s founding engineer](https://www.youtube.com/watch?v=jQNCuD_hxdQ&list=RDhnpzNAPiC0E&index=11)\n* [Scaling Slack - Bing Wei, Software Engineer (Infrastructure) at Slack](https://www.infoq.com/presentations/slack-scalability)\n* [Scaling Backend at Youtube - Sugu Sougoumarane, SDE at Youtube](https://www.youtube.com/watch?v=5yDO-tmIoXY&feature=youtu.be)\n* [Scaling Backend at Uber - Matt Ranney, Chief Systems Architect at Uber](https://www.youtube.com/watch?v=nuiLcWE8sPA)\n* [Scaling Global CDN at Netflix - Dave Temkin, Director of Global Networks at Netflix](https://www.youtube.com/watch?v=tbqcsHg-Q_o)\n* [Scaling Load Balancing Infra to Support 1.3 Billion Users at Facebook - Patrick Shuff, Production Engineer at Facebook](https://www.youtube.com/watch?v=bxhYNfFeVF4)\n* [Scaling (a NSFW site) to 200 Million Views A Day And Beyond - Eric Pickup, Lead Platform Developer at MindGeek](https://www.youtube.com/watch?v=RlkCdM_f3p4)\n* [Scaling Counting Infrastructure at Quora - Chun-Ho Hung and Nikhil Gar, SEs at Quora](https://www.infoq.com/presentations/quora-analytics)\n* [Scaling Git at Microsoft - Saeed Noursalehi, Principal Program Manager at Microsoft](https://www.youtube.com/watch?v=g_MPGU_m01s)\n* [Scaling Multitenant Architecture Across Multiple Data Centres at Shopify - Weingarten, Engineering Lead at Shopify](https://www.youtube.com/watch?v=F-f0-k46WVk)\n\n## Book\n* [Big Data, Web Ops & DevOps Ebooks - O'Reilly (Online - Free)](http://www.oreilly.com/webops/free/)\n* [Google Site Reliability Engineering (Online - Free)](https://landing.google.com/sre/book.html)\n* [Distributed Systems for Fun and Profit (Online - Free)](http://book.mixu.net/distsys/)\n* [What Every Developer Should Know About SQL Performance (Online - Free)](https://use-the-index-luke.com/sql/table-of-contents)\n* [Beyond the Twelve-Factor App - Exploring the DNA of Highly Scalable, Resilient Cloud Applications (Free)](http://www.oreilly.com/webops-perf/free/beyond-the-twelve-factor-app.csp)\n* [Chaos Engineering - Building Confidence in System Behavior through Experiments (Free)](http://www.oreilly.com/webops-perf/free/chaos-engineering.csp?intcmp=il-webops-free-product-na_new_site_chaos_engineering_text_cta)\n* [The Art of Scalability](http://theartofscalability.com/)\n* [Web Scalability for Startup Engineers](https://www.goodreads.com/book/show/23615147-web-scalability-for-startup-engineers)\n* [Scalability Rules: 50 Principles for Scaling Web Sites](http://scalabilityrules.com/)\n\n## Donation\nRoses are red. Violets are blue. [Binh](https://nguyenquocbinh.org/) likes sweet. [Treat Binh a tiramisu?](https://paypal.me/binhnguyennus) :cake:\n",
	"big-data java jdbc python r scala spark sql": "# Apache Spark\n\nSpark is a unified analytics engine for large-scale data processing. It provides\nhigh-level APIs in Scala, Java, Python, and R, and an optimized engine that\nsupports general computation graphs for data analysis. It also supports a\nrich set of higher-level tools including Spark SQL for SQL and DataFrames,\npandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing,\nand Structured Streaming for stream processing.\n\n<https://spark.apache.org/>\n\n[![GitHub Actions Build](https://github.com/apache/spark/actions/workflows/build_main.yml/badge.svg)](https://github.com/apache/spark/actions/workflows/build_main.yml)\n[![AppVeyor Build](https://img.shields.io/appveyor/ci/ApacheSoftwareFoundation/spark/master.svg?style=plastic&logo=appveyor)](https://ci.appveyor.com/project/ApacheSoftwareFoundation/spark)\n[![PySpark Coverage](https://codecov.io/gh/apache/spark/branch/master/graph/badge.svg)](https://codecov.io/gh/apache/spark)\n[![PyPI Downloads](https://static.pepy.tech/personalized-badge/pyspark?period=month&units=international_system&left_color=black&right_color=orange&left_text=PyPI%20downloads)](https://pypi.org/project/pyspark/)\n\n\n## Online Documentation\n\nYou can find the latest Spark documentation, including a programming\nguide, on the [project web page](https://spark.apache.org/documentation.html).\nThis README file only contains basic setup instructions.\n\n## Building Spark\n\nSpark is built using [Apache Maven](https://maven.apache.org/).\nTo build Spark and its example programs, run:\n\n```bash\n./build/mvn -DskipTests clean package\n```\n\n(You do not need to do this if you downloaded a pre-built package.)\n\nMore detailed documentation is available from the project site, at\n[\"Building Spark\"](https://spark.apache.org/docs/latest/building-spark.html).\n\nFor general development tips, including info on developing Spark using an IDE, see [\"Useful Developer Tools\"](https://spark.apache.org/developer-tools.html).\n\n## Interactive Scala Shell\n\nThe easiest way to start using Spark is through the Scala shell:\n\n```bash\n./bin/spark-shell\n```\n\nTry the following command, which should return 1,000,000,000:\n\n```scala\nscala> spark.range(1000 * 1000 * 1000).count()\n```\n\n## Interactive Python Shell\n\nAlternatively, if you prefer Python, you can use the Python shell:\n\n```bash\n./bin/pyspark\n```\n\nAnd run the following command, which should also return 1,000,000,000:\n\n```python\n>>> spark.range(1000 * 1000 * 1000).count()\n```\n\n## Example Programs\n\nSpark also comes with several sample programs in the `examples` directory.\nTo run one of them, use `./bin/run-example <class> [params]`. For example:\n\n```bash\n./bin/run-example SparkPi\n```\n\nwill run the Pi example locally.\n\nYou can set the MASTER environment variable when running examples to submit\nexamples to a cluster. This can be a mesos:// or spark:// URL,\n\"yarn\" to run on YARN, and \"local\" to run\nlocally with one thread, or \"local[N]\" to run locally with N threads. You\ncan also use an abbreviated class name if the class is in the `examples`\npackage. For instance:\n\n```bash\nMASTER=spark://host:7077 ./bin/run-example SparkPi\n```\n\nMany of the example programs print usage help if no params are given.\n\n## Running Tests\n\nTesting first requires [building Spark](#building-spark). Once Spark is built, tests\ncan be run using:\n\n```bash\n./dev/run-tests\n```\n\nPlease see the guidance on how to\n[run tests for a module, or individual tests](https://spark.apache.org/developer-tools.html#individual-tests).\n\nThere is also a Kubernetes integration test, see resource-managers/kubernetes/integration-tests/README.md\n\n## A Note About Hadoop Versions\n\nSpark uses the Hadoop core library to talk to HDFS and other Hadoop-supported\nstorage systems. Because the protocols have changed in different versions of\nHadoop, you must build Spark against the same version that your cluster runs.\n\nPlease refer to the build documentation at\n[\"Specifying the Hadoop Version and Enabling YARN\"](https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn)\nfor detailed guidance on building for a particular distribution of Hadoop, including\nbuilding for particular Hive and Hive Thriftserver distributions.\n\n## Configuration\n\nPlease refer to the [Configuration Guide](https://spark.apache.org/docs/latest/configuration.html)\nin the online documentation for an overview on how to configure Spark.\n\n## Contributing\n\nPlease review the [Contribution to Spark guide](https://spark.apache.org/contributing.html)\nfor information on how to get started contributing to the project.\n",
	"analytics big-data clickhouse dbms distributed-database hacktoberfest mpp olap sql": "[![ClickHouse \u2014 open source distributed column-oriented DBMS](https://github.com/ClickHouse/clickhouse-presentations/raw/master/images/logo-400x240.png)](https://clickhouse.com)\n\nClickHouse\u00ae is an open-source column-oriented database management system that allows generating analytical data reports in real-time.\n\n## Useful Links\n\n* [Official website](https://clickhouse.com/) has a quick high-level overview of ClickHouse on the main page.\n* [ClickHouse Cloud](https://clickhouse.cloud) ClickHouse as a service, built by the creators and maintainers.\n* [Tutorial](https://clickhouse.com/docs/en/getting_started/tutorial/) shows how to set up and query a small ClickHouse cluster.\n* [Documentation](https://clickhouse.com/docs/en/) provides more in-depth information.\n* [YouTube channel](https://www.youtube.com/c/ClickHouseDB) has a lot of content about ClickHouse in video format.\n* [Slack](https://join.slack.com/t/clickhousedb/shared_invite/zt-rxm3rdrk-lIUmhLC3V8WTaL0TGxsOmg) and [Telegram](https://telegram.me/clickhouse_en) allow chatting with ClickHouse users in real-time.\n* [Blog](https://clickhouse.com/blog/) contains various ClickHouse-related articles, as well as announcements and reports about events.\n* [Code Browser (Woboq)](https://clickhouse.com/codebrowser/ClickHouse/index.html) with syntax highlight and navigation.\n* [Code Browser (github.dev)](https://github.dev/ClickHouse/ClickHouse) with syntax highlight, powered by github.dev.\n* [Contacts](https://clickhouse.com/company/contact) can help to get your questions answered if there are any.\n\n## Upcoming events\n* [**v22.11 Release Webinar**](https://clickhouse.com/company/events/v22-11-release-webinar) Original creator, co-founder, and CTO of ClickHouse Alexey Milovidov will walk us through the highlights of the release, provide live demos, and share vision into what is coming in the roadmap.\n* [**ClickHouse Meetup at the Deutsche Bank office in Berlin**](https://www.meetup.com/clickhouse-berlin-user-group/events/289311596/) Hear from Deutsche Bank on why they chose ClickHouse for big sensitive data in a regulated environment. The ClickHouse team will then present how ClickHouse is used for real time financial data analytics, including tick data, trade analytics and risk management.\n* [**AWS re:Invent**](https://clickhouse.com/company/events/aws-reinvent) Core members of the ClickHouse team -- including 2 of our founders -- will be at re:Invent from November 29 to December 3. We are available on the show floor, but are also determining interest in holding an event during the time there. \n",
	"big-data flink java python scala sql": "# Apache Flink\n\nApache Flink is an open source stream processing framework with powerful stream- and batch-processing capabilities.\n\nLearn more about Flink at [https://flink.apache.org/](https://flink.apache.org/)\n\n\n### Features\n\n* A streaming-first runtime that supports both batch processing and data streaming programs\n\n* Elegant and fluent APIs in Java and Scala\n\n* A runtime that supports very high throughput and low event latency at the same time\n\n* Support for *event time* and *out-of-order* processing in the DataStream API, based on the *Dataflow Model*\n\n* Flexible windowing (time, count, sessions, custom triggers) across different time semantics (event time, processing time)\n\n* Fault-tolerance with *exactly-once* processing guarantees\n\n* Natural back-pressure in streaming programs\n\n* Libraries for Graph processing (batch), Machine Learning (batch), and Complex Event Processing (streaming)\n\n* Built-in support for iterative programs (BSP) in the DataSet (batch) API\n\n* Custom memory management for efficient and robust switching between in-memory and out-of-core data processing algorithms\n\n* Compatibility layers for Apache Hadoop MapReduce\n\n* Integration with YARN, HDFS, HBase, and other components of the Apache Hadoop ecosystem\n\n\n### Streaming Example\n```scala\ncase class WordWithCount(word: String, count: Long)\n\nval text = env.socketTextStream(host, port, '\\n')\n\nval windowCounts = text.flatMap { w => w.split(\"\\\\s\") }\n  .map { w => WordWithCount(w, 1) }\n  .keyBy(\"word\")\n  .window(TumblingProcessingTimeWindow.of(Time.seconds(5)))\n  .sum(\"count\")\n\nwindowCounts.print()\n```\n\n### Batch Example\n```scala\ncase class WordWithCount(word: String, count: Long)\n\nval text = env.readTextFile(path)\n\nval counts = text.flatMap { w => w.split(\"\\\\s\") }\n  .map { w => WordWithCount(w, 1) }\n  .groupBy(\"word\")\n  .sum(\"count\")\n\ncounts.writeAsCsv(outputPath)\n```\n\n\n\n## Building Apache Flink from Source\n\nPrerequisites for building Flink:\n\n* Unix-like environment (we use Linux, Mac OS X, Cygwin, WSL)\n* Git\n* Maven (we recommend version 3.2.5 and require at least 3.1.1)\n* Java 8 or 11 (Java 9 or 10 may work)\n\n```\ngit clone https://github.com/apache/flink.git\ncd flink\n./mvnw clean package -DskipTests # this will take up to 10 minutes\n```\n\nFlink is now installed in `build-target`.\n\n*NOTE: Maven 3.3.x can build Flink, but will not properly shade away certain dependencies. Maven 3.1.1 creates the libraries properly.\nTo build unit tests with Java 8, use Java 8u51 or above to prevent failures in unit tests that use the PowerMock runner.*\n\n## Developing Flink\n\nThe Flink committers use IntelliJ IDEA to develop the Flink codebase.\nWe recommend IntelliJ IDEA for developing projects that involve Scala code.\n\nMinimal requirements for an IDE are:\n* Support for Java and Scala (also mixed projects)\n* Support for Maven with Java and Scala\n\n\n### IntelliJ IDEA\n\nThe IntelliJ IDE supports Maven out of the box and offers a plugin for Scala development.\n\n* IntelliJ download: [https://www.jetbrains.com/idea/](https://www.jetbrains.com/idea/)\n* IntelliJ Scala Plugin: [https://plugins.jetbrains.com/plugin/?id=1347](https://plugins.jetbrains.com/plugin/?id=1347)\n\nCheck out our [Setting up IntelliJ](https://nightlies.apache.org/flink/flink-docs-master/flinkDev/ide_setup.html#intellij-idea) guide for details.\n\n### Eclipse Scala IDE\n\n**NOTE:** From our experience, this setup does not work with Flink\ndue to deficiencies of the old Eclipse version bundled with Scala IDE 3.0.3 or\ndue to version incompatibilities with the bundled Scala version in Scala IDE 4.4.1.\n\n**We recommend to use IntelliJ instead (see above)**\n\n## Support\n\nDon\u2019t hesitate to ask!\n\nContact the developers and community on the [mailing lists](https://flink.apache.org/community.html#mailing-lists) if you need any help.\n\n[Open an issue](https://issues.apache.org/jira/browse/FLINK) if you find a bug in Flink.\n\n\n## Documentation\n\nThe documentation of Apache Flink is located on the website: [https://flink.apache.org](https://flink.apache.org)\nor in the `docs/` directory of the source code.\n\n\n## Fork and Contribute\n\nThis is an active open-source project. We are always open to people who want to use the system or contribute to it.\nContact us if you are looking for implementation tasks that fit your skills.\nThis article describes [how to contribute to Apache Flink](https://flink.apache.org/contributing/how-to-contribute.html).\n\n\n## About\n\nApache Flink is an open source project of The Apache Software Foundation (ASF).\nThe Apache Flink project originated from the [Stratosphere](http://stratosphere.eu) research project.\n",
	"artificial-intelligence big-data blockchain crdt crypto cryptography dapp database decentralized dweb encryption end-to-end graph machine-learning metaverse offline-first p2p protocol realtime web3": "<p id=\"readme\"><a href=\"https://gun.eco/\"><img width=\"40%\" src=\"https://cldup.com/TEy9yGh45l.svg\"/></a><img width=\"50%\" align=\"right\" vspace=\"25\" src=\"https://gun.eco/see/demo.gif\"/></p>\r\n\r\n[![](https://data.jsdelivr.com/v1/package/gh/amark/gun/badge?style=rounded)](https://data.jsdelivr.com/v1/package/gh/amark/gun/stats)\r\n![Build](https://github.com/amark/gun/actions/workflows/ci.yml/badge.svg)\r\n[![Gitter](https://img.shields.io/gitter/room/amark/gun.js.svg)](http://chat.gun.eco)\r\n\r\n**GUN** is an [ecosystem](https://gun.eco/docs/Ecosystem) of **tools** that let you build [community run](https://www.nbcnews.com/tech/tech-news/these-technologists-think-internet-broken-so-they-re-building-another-n1030136) and [encrypted applications](https://gun.eco/docs/Cartoon-Cryptography) - like an Open Source Firebase or a Decentralized Dropbox.\r\n\r\nThe [Internet Archive](https://news.ycombinator.com/item?id=17685682) and [100s of other apps](https://github.com/amark/gun/wiki/awesome-gun) run GUN in-production. GUN is also part of [Twitter's Bluesky](https://blueskycommunity.net/) initiative!\r\n\r\n + Multiplayer by default with realtime p2p state synchronization!\r\n + Graph data lets you use key/value, tables, documents, videos, & more!\r\n + Local-first, offline, and decentralized with end-to-end encryption.\r\n\r\nDecentralized alternatives to [Zoom](https://www.zdnet.com/article/era-hatches-meething-an-open-source-browser-based-video-conferencing-system/), [Reddit](https://notabug.io/t/whatever/comments/36588a16b9008da4e3f15663c2225e949eca4a15/gpu-bot-test), [Instagram](https://iris.to/), [Slack](https://iris.to/), [YouTube](https://d.tube/), [Stripe](https://twitter.com/marknadal/status/1422717427427647489), [Wikipedia](https://news.ycombinator.com/item?id=17685682), Facebook [Horizon](https://twitter.com/marknadal/status/1424476179189305347) and more have already pushed terabytes of daily P2P traffic on GUN. We are a [friendly community](http://chat.gun.eco/) creating a [free fun future for freedom](https://youtu.be/1HJdrBk3BlE):\r\n\r\n<table>\r\n<tr>\r\n<a href=\"https://youtu.be/s_m16-w6bBI\"><img width=\"31%\" src=\"https://gun.eco/see/3dvr.gif\" title=\"3D VR\"/></a>\r\n<a href=\"https://github.com/cstefanache/cstefanache.github.io/blob/06697003449e4fc531fd32ee068bab532976f47b/_posts/2016-08-02-gun-db-artificial-knowledge-sharing.md\"><img width=\"31%\" src=\"https://gun.eco/see/aiml.gif\" title=\"AI/ML\"/></a>\r\n<a href=\"http://gps.gunDB.io/\"><img width=\"31%\" src=\"https://gun.eco/see/gps.gif\" title=\"GPS\"/></a>\r\n</tr>\r\n<tr>\r\n<a href=\"https://github.com/lmangani/gun-scape#gun-scape\"><img width=\"31%\" src=\"https://gun.eco/see/dataviz.gif\" title=\"Data Viz\"/></a>\r\n<a href=\"https://github.com/amark/gun/wiki/Auth\"><img width=\"31%\" src=\"https://gun.eco/see/p2p.gif\" title=\"P2P\"/></a>\r\n<a href=\"https://github.com/Stefdv/gun-ui-lcd#okay-what-about-gundb-\"><img width=\"31%\" src=\"https://gun.eco/see/iot.gif\" title=\"IoT\"/></a>\r\n</tr>\r\n<tr>\r\n<a href=\"http://chat.gun.eco\"><img width=\"31%\" src=\"https://gun.eco/see/vr-world.gif\" title=\"VR World\"/></a>\r\n<a href=\"https://youtu.be/1ASrmQ-CwX4\"><img width=\"31%\" src=\"https://gun.eco/see/ar.gif\" title=\"AR\"/></a>\r\n<a href=\"https://meething.space/\"><img width=\"31%\" src=\"https://gun.eco/see/video-conf.gif\" title=\"Video Confernece\"/></a>\r\n</tr>\r\n</table>\r\n\r\n## Quickstart\r\n\r\nGUN is *super easy* to get started with:\r\n\r\n - Try the [interactive tutorial](https://gun.eco/docs/Todo-Dapp) in the browser (**5min** ~ average developer).\r\n - Or `npm install gun` and run the examples with `cd node_modules/gun && npm start` (**5min** ~ average developer).\r\n\r\n> **Note:** If you don't have [node](http://nodejs.org/) or [npm](https://www.npmjs.com/), read [this](https://github.com/amark/gun/blob/master/examples/install.sh) first.\r\n> If the `npm` command line didn't work, you may need to `mkdir node_modules` first or use `sudo`.\r\n\r\n- An online demo of the examples are available here: http://gunjs.herokuapp.com/\r\n- Or write a quick app: ([try now in a playground](https://jsbin.com/kadobamevo/edit?js,console))\r\n```html\r\n<script src=\"https://cdn.jsdelivr.net/npm/gun/gun.js\"></script>\r\n<script>\r\n// import GUN from 'gun'; // in ESM\r\n// GUN = require('gun'); // in NodeJS\r\n// GUN = require('gun/gun'); // in React\r\ngun = GUN();\r\n\r\ngun.get('mark').put({\r\n  name: \"Mark\",\r\n  email: \"mark@gun.eco\",\r\n});\r\n\r\ngun.get('mark').on((data, key) => {\r\n  console.log(\"realtime updates:\", data);\r\n});\r\n\r\nsetInterval(() => { gun.get('mark').get('live').put(Math.random()) }, 9);\r\n</script>\r\n```\r\n- Or try something **mind blowing**, like saving circular references to a table of documents! ([play](http://jsbin.com/wefozepume/edit?js,console))\r\n```javascript\r\ncat = {name: \"Fluffy\", species: \"kitty\"};\r\nmark = {boss: cat};\r\ncat.slave = mark;\r\n\r\n// partial updates merge with existing data!\r\ngun.get('mark').put(mark);\r\n\r\n// access the data as if it is a document.\r\ngun.get('mark').get('boss').get('name').once(function(data, key){\r\n  // `once` grabs the data once, no subscriptions.\r\n  console.log(\"Mark's boss is\", data);\r\n});\r\n\r\n// traverse a graph of circular references!\r\ngun.get('mark').get('boss').get('slave').once(function(data, key){\r\n  console.log(\"Mark is the cat's slave!\", data);\r\n});\r\n\r\n// add both of them to a table!\r\ngun.get('list').set(gun.get('mark').get('boss'));\r\ngun.get('list').set(gun.get('mark'));\r\n\r\n// grab each item once from the table, continuously:\r\ngun.get('list').map().once(function(data, key){\r\n  console.log(\"Item:\", data);\r\n});\r\n\r\n// live update the table!\r\ngun.get('list').set({type: \"cucumber\", goal: \"jumping cat\"});\r\n```\r\n\r\nWant to keep building more? **Jump to [THE DOCUMENTATION](#documentation)!**\r\n\r\n# About\r\nFirst & foremost, GUN is **a community of the nicest and most helpful people** out there. So [I want to invite you](http://chat.gun.eco) to come tell us about what **you** are working on & wanting to build (new or old school alike! Just be nice as well.) and ask us your questions directly. :)\r\n\r\n<p align=\"center\"><a href=\"https://www.youtube.com/watch?v=oTQXzhm8w_8\"><img width=\"250\" src=\"https://img.youtube.com/vi/oTQXzhm8w_8/0.jpg\"><br/>Watch the 100 second intro!</a></p>\r\n\r\nThe GUN ecosystem stack is a collection of independent and modular tools covering everything from [CRDT](https://crdt.tech/) [conflict resolution](https://gun.eco/distributed/matters.html), [cryptographic security](https://gun.eco/docs/Cartoon-Cryptography) & [encryption](https://gun.eco/docs/SEA), [radix storage serialization](https://gun.eco/docs/RAD), [mesh networking](https://gun.eco/docs/DAM) & [routing algorithms](https://gun.eco/docs/Routing), to distributed systems [correctness & load testing](https://github.com/gundb/panic-server), CPU scheduled [JSON parser](https://github.com/amark/gun/blob/master/lib/yson.js) to prevent UI lag, and more!\r\n\r\n<div><img width=\"48%\" src=\"https://gun.eco/see/stack.png\"/>\r\n<img width=\"48%\" align=\"right\" src=\"https://gun.eco/see/layers.png\"/></div>\r\n\r\nOn that note, let's get some official shout outs covered first:\r\n\r\n### Support\r\n\r\n<p align=\"center\">\r\nThanks to:\r\n\r\n<table>\r\n<tr>\r\n<td vlign=\"center\"><a href=\"https://mozilla.org/builders\"><img height=\"100\" src=\"https://user-images.githubusercontent.com/1423657/81992335-85346480-9643-11ea-8754-8275e98e06bc.png\"></a></td>\r\n<td vlign=\"center\"><a href=\"http://unstoppabledomains.com/\"><img src=\"https://gun.eco/img/unstoppable.png\"></a></td>\r\n<td vlign=\"center\"><a href=\"https://mask.io/\"><img src=\"https://dimensiondev.github.io/Mask-VI/assets/Logo/MB--Logo--CombH-Circle--Blue.svg\" width=\"250\"></a></td>\r\n</tr>\r\n<tr>\r\n<td vlign=\"center\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"https://www.ajar.org/\"><img src=\"https://www.ajar.org/logo.png\" height=\"120\"></a></td>\r\n<td vlign=\"center\"><a href=\"https://wallie.io/\"><img src=\"https://raw.githubusercontent.com/gundb/gun-site/master/img/wallie.png\" width=\"250\"></a></td>\r\n<td vlign=\"center\">&nbsp;&nbsp;<a href=\"https://ghostdrive.com/\"><img src=\"https://gun.eco/img/ghostdrive.png\" height=\"120\"></a></td>\r\n</tr>\r\n</table>\r\n\r\n<a href=\"https://github.com/robertheessels\">Robert Heessels</a>,\r\n<a href=\"http://qxip.net/\">Lorenzo Mangani</a>,\r\n<a href=\"https://nlnet.nl/\">NLnet Foundation</a>,\r\n<a href=\"http://github.com/samliu\">Sam Liu</a>,\r\n<a href=\"http://github.com/ddombrow\">Daniel Dombrowsky</a>,\r\n<a href=\"http://github.com/vincentwoo\">Vincent Woo</a>,\r\n<a href=\"http://github.com/coolaj86\">AJ ONeal</a>,\r\n<a href=\"http://github.com/ottman\">Bill Ottman</a>,\r\n<a href=\"http://github.com/mikewlange\">Mike Lange</a>,\r\n<a href=\"http://github.com/ctrlplusb\">Sean Matheson</a>,\r\n<a href=\"http://github.com/alanmimms\">Alan Mimms</a>,\r\n<a href=\"https://github.com/dfreire\">D\u00e1rio Freire</a>,\r\n<a href=\"http://github.com/velua\">John Williamson</a>,\r\n<a href=\"http://github.com/finwo\">Robin Bron</a>,\r\n<a href=\"http://github.com/ElieMakhoul\">Elie Makhoul</a>,\r\n<a href=\"http://github.com/mikestaub\">Mike Staub</a>,\r\n<a href=\"http://github.com/bmatusiak\">Bradley Matusiak</a>,\r\n<a href=\"https://github.com/sjuxax\">Jeff Cook</a>,\r\n<a href=\"https://github.com/nmauersberg\">Nico</a>,\r\n<a href=\"https://github.com/ajartille\">Aaron Artille</a>,\r\n<a href=\"https://github.com/timjrobinson\">Tim Robinson</a>,\r\n<a href=\"https://github.com/hibas123\">Fabian Stamm</a>,\r\n<a href=\"https://twitter.com/mikestaub\">Mike Staub</a>,\r\n<a href=\"https://hunterowens.com/\">Hunter Owens</a>,\r\n<a href=\"https://github.com/JacobMillner\">Jacob Millner</a>,\r\n<a href=\"https://github.com/b-lack\">Gerrit Balindt</a>,\r\n<a href=\"https://github.com/gabriellemon\">Gabriel Lemon</a>\r\n</p>\r\n\r\n - Join others in sponsoring code: https://www.patreon.com/gunDB !\r\n - Ask questions: http://stackoverflow.com/questions/tagged/gun ?\r\n - Found a bug? Report at: https://github.com/amark/gun/issues ;\r\n - **Need help**? Chat with us: http://chat.gun.eco .\r\n\r\n### History\r\n\r\n[GUN](https://gun.eco) was created by [Mark Nadal](https://twitter.com/marknadal) in 2014 after he had spent 4 years trying to get his collaborative web app to scale up with traditional databases.\r\n\r\n<img width=\"250px\" src=\"https://gun.eco/see/problem.png\" align=\"left\" title=\"pain point\" style=\"margin: 0 1em 1em 0\"> After he realized [Master-Slave database architecture causes one big bottleneck](https://gun.eco/distributed/matters.html), he (as a complete newbie outsider) naively decided **to question the status quo** and shake things up with controversial, heretical, and contrarian experiments:\r\n\r\n**The NoDB** - no master, no servers, no \"single source of truth\", not built with a real programming language or real hardware, no DevOps, no locking, not *just* SQL or NoSQL but both (**all** - graphs, documents, tables, key/value).\r\n\r\nThe goal was to build a P2P database that could survive living inside **any** browser, and could correctly sync data between **any** device after assuming **any** offline-first activity.\r\n\r\n<img src=\"https://gun.eco/see/compare.png\" title=\"comparison table\">\r\n\r\nTechnically, **GUN is a graph synchronization protocol** with a *lightweight embedded engine*, capable of doing *[20M+ API ops/sec](https://gun.eco/docs/Performance)* in **just ~9KB gzipped size**.\r\n\r\n## Documentation\r\n\r\n<table>\r\n  <tr>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://gun.eco/docs/API\">API reference</a></h3></td>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://gun.eco/docs/Todo-Dapp\">Tutorials</a></h3></td>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://github.com/amark/gun/tree/master/examples\">Examples</a></h3></td>\r\n  </tr>\r\n  <tr>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://github.com/brysgo/graphql-gun\">GraphQL</a></h3></td>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://github.com/PenguinMan98/electrontest\">Electron</a></h3></td>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://gun.eco/docs/React-Native\">React & Native</a></h3></td>\r\n  </tr>\r\n  <tr>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://github.com/sjones6/vue-gun\">Vue</a></h3></td>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://gun.eco/docs/Svelte\">Svelte</a></h3></td>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://github.com/Stefdv/gun-ui-lcd#syncing\">Webcomponents</a></h3></td>\r\n  </tr>\r\n  <tr>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://gun.eco/docs/CAP-Theorem\">CAP Theorem Tradeoffs</a></h3></td>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://gun.eco/distributed/matters.html\">How Data Sync Works</a></h3></td>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://gun.eco/docs/Porting-GUN\">How GUN is Built</a></h3></td>\r\n  </tr>\r\n  <tr>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://gun.eco/docs/Auth\">Crypto Auth</a></h3></td>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://github.com/amark/gun/wiki/Awesome-GUN\">Modules</a></h3></td>\r\n    <td style=\"border: 0;\"><h3><a href=\"https://gun.eco/docs/Roadmap\">Roadmap</a></h3></td>\r\n  </tr>\r\n</table>\r\n\r\nThis would not be possible without **community contributors**, big shout out to:\r\n\r\n**[ajmeyghani](https://github.com/ajmeyghani) ([Learn GUN Basics with Diagrams](https://medium.com/@ajmeyghani/gundb-a-graph-database-in-javascript-3860a08d873c))**; **[anywhichway](https://github.com/anywhichway) ([Block Storage](https://github.com/anywhichway/gun-block))**; **[beebase](https://github.com/beebase) ([Quasar](https://github.com/beebase/gun-vuex-quasar))**; **[BrockAtkinson](https://github.com/BrockAtkinson) ([brunch config](https://github.com/BrockAtkinson/brunch-gun))**; **[Brysgo](https://github.com/brysgo) ([GraphQL](https://github.com/brysgo/graphql-gun))**; **[d3x0r](https://github.com/d3x0r) ([SQLite](https://github.com/d3x0r/gun-db))**; **[forrestjt](https://github.com/forrestjt) ([file.js](https://github.com/amark/gun/blob/master/lib/file.js))**; **[hillct](https://github.com/hillct) (Docker)**; **[JosePedroDias](https://github.com/josepedrodias) ([graph visualizer](http://acor.sl.pt:9966))**; **[JuniperChicago](https://github.com/JuniperChicago) ([cycle.js bindings](https://github.com/JuniperChicago/cycle-gun))**; **[jveres](https://github.com/jveres) ([todoMVC](https://github.com/jveres/todomvc))**; **[kristianmandrup](https://github.com/kristianmandrup) ([edge](https://github.com/kristianmandrup/gun-edge))**; **[Lightnet](https://github.com/Lightnet)** ([Awesome Vue User Examples](https://glitch.com/edit/#!/jsvuegunui?path=README.md:1:0) & [User Kitchen Sink Playground](https://gdb-auth-vue-node.glitch.me/)); **[lmangani](https://github.com/lmangani) ([Cytoscape Visualizer](https://github.com/lmangani/gun-scape), [Cassandra](https://github.com/lmangani/gun-cassandra), [Fastify](https://github.com/lmangani/fastify-gundb), [LetsEncrypt](https://github.com/lmangani/polyGun-letsencrypt))**; **[mhelander](https://github.com/mhelander) ([SEA](https://github.com/amark/gun/blob/master/sea.js))**; [omarzion](https://github.com/omarzion) ([Sticky Note App](https://github.com/omarzion/stickies)); [PsychoLlama](https://github.com/PsychoLlama) ([LevelDB](https://github.com/PsychoLlama/gun-level)); **[RangerMauve](https://github.com/RangerMauve) ([schema](https://github.com/gundb/gun-schema))**; **[robertheessels](https://github.com/swifty) ([gun-p2p-auth](https://github.com/swifty/gun-p2p-auth))**; **[rogowski](https://github.com/rogowski) (AXE)**; [sbeleidy](https://github.com/sbeleidy); **[sbiaudet](https://github.com/sbiaudet) ([C# Port](https://github.com/sbiaudet/cs-gun))**; **[Sean Matheson](https://github.com/ctrlplusb) ([Observable/RxJS/Most.js bindings](https://github.com/ctrlplusb/gun-most))**; **[Shadyzpop](https://github.com/Shadyzpop) ([React Native example](https://github.com/amark/gun/tree/master/examples/react-native))**; **[sjones6](https://github.com/sjones6) ([Flint](https://github.com/sjones6/gun-flint))**; RIP **[Stefdv](https://github.com/stefdv) (Polymer/web components)**; **[zrrrzzt](https://github.com/zrrrzzt) ([JWT Auth](https://gist.github.com/zrrrzzt/6f88dc3cedee4ee18588236756d2cfce))**; **[xmonader](https://github.com/xmonader) ([Python Port](https://github.com/xmonader/pygundb))**; \r\n\r\nI am missing many others, apologies, will be adding them soon! This list is infintiely old & way out of date, if you want to be listed in it please make a PR! :)\r\n\r\n## Testing\r\n\r\nYou will need to `npm install -g mocha` first. Then in the gun root folder run `npm test`. Tests will trigger persistent writes to the DB, so subsequent runs of the test will fail. You must clear the DB before running the tests again. This can be done by running `rm -rf *data*` command in the project directory.\r\n\r\n## Shims\r\n\r\n > These are only needed for NodeJS & React Native, they shim the native Browser WebCrypto API.\r\n\r\nIf you want to use [SEA](https://gun.eco/docs/SEA) for `User` auth and security, you will need to install:\r\n\r\n`npm install @peculiar/webcrypto --save`\r\n\r\nPlease see [our React Native docs](https://gun.eco/docs/React-Native) for installation instructions!\r\n\r\nThen you can require [SEA](https://gun.eco/docs/SEA) without an error:\r\n\r\n```javascript\r\nGUN = require('gun/gun');\r\nSEA = require('gun/sea');\r\n```\r\n\r\n## Deploy\r\n\r\n > Note: The default examples that get auto-deployed on `npm start` CDN-ify all GUN files, modules, & storage.\r\n \r\n > Note: Moving forward, AXE will start to automatically cluster your peer into a shared DHT. You may want to disable this to run an isolated network.\r\n \r\n > Note: When deploying a web application using GUN on a cloud provider, you may have to set `CI=false` in your `.env`. This prevents GUN-specific warnings from being treated as errors when deploying your app. You may also resolve this by modifying your webpack config to not try to build the GUN dependencies.\r\n\r\nTo quickly spin up a GUN relay peer for your development team, utilize [Heroku](http://heroku.com), [Docker](http://docker.com), or any others listed below. Or some variant thereof [Dokku](http://dokku.viewdocs.io/dokku/), K8s, etc. ! Or use all of them so your relays are decentralized too!\r\n\r\n### Linux\r\n\r\n`SSH` into the home directory of a clean OS install with `sudo` ability. Set any environment variables you need (see below), then do:\r\n\r\n```bash\r\ncurl -o- https://raw.githubusercontent.com/amark/gun/master/examples/install.sh | bash\r\n```\r\n\r\n > Read [install.sh](https://github.com/amark/gun/blob/master/examples/install.sh) first!\r\n > If `curl` is not found, *copy&paste* the contents of install.sh into your ssh.\r\n\r\nYou can now safely `CTRL+A+D` to escape without stopping the peer. To stop everything `killall screen` or `killall node`.\r\n\r\nEnvironment variables may need to be set like `export HTTPS_CERT=~/cert.pem HTTPS_KEY=~/key.pem PORT=443`. You can also look at a sample [nginx](https://gun.eco/docs/nginx) config. For production deployments, you probably will want to use something like `pm2` or better to keep the peer alive after machine reboots.\r\n\r\n### [Heroku](https://www.heroku.com/)\r\n\r\n[![Deploy](https://www.herokucdn.com/deploy/button.svg)](https://heroku.com/deploy?template=https://github.com/amark/gun)\r\n\r\n > Heroku deletes your data every 15 minutes, one way to fix this is by adding [cheap storage](https://gun.eco/docs/Using-Amazon-S3-for-Storage).\r\n\r\nOr:\r\n\r\n```bash\r\ngit clone https://github.com/amark/gun.git\r\ncd gun\r\nheroku create\r\ngit push -f heroku HEAD:master\r\n```\r\n\r\nThen visit the URL in the output of the 'heroku create' step, in a browser. Make sure to set any environment config vars in the settings tab.\r\n\r\n### [Zeet.co](https://www.zeet.co/)\r\n\r\n[![Deploy](https://deploy.zeet.co/gun.svg)](https://deploy.zeet.co/?url=https://github.com/amark/gun)\r\n\r\nThen visit the URL in the output of the 'now --npm' step, in your browser.\r\n\r\n### [Docker](https://www.docker.com/)\r\n\r\n > Warning: Docker image is community contributed and may be old with missing security updates, please check version numbers to compare.\r\n\r\n[![Docker Automated build](https://img.shields.io/docker/automated/gundb/gun.svg)](https://hub.docker.com/r/gundb/gun/) [![](https://images.microbadger.com/badges/image/gundb/gun.svg)](https://microbadger.com/images/gundb/gun \"Get your own image badge on microbadger.com\") [![Docker Pulls](https://img.shields.io/docker/pulls/gundb/gun.svg)](https://hub.docker.com/r/gundb/gun/) [![Docker Stars](https://img.shields.io/docker/stars/gundb/gun.svg)](https://hub.docker.com/r/gundb/gun/)\r\n\r\nPull from the [Docker Hub](https://hub.docker.com/r/gundb/gun/) [![](https://images.microbadger.com/badges/commit/gundb/gun.svg)](https://microbadger.com/images/gundb/gun). Or:\r\n\r\n```bash\r\ndocker run -p 8765:8765 gundb/gun\r\n```\r\n\r\nOr build the [Docker](https://docs.docker.com/engine/installation/) image locally:\r\n\r\n```bash\r\ngit clone https://github.com/amark/gun.git\r\ncd gun\r\ndocker build -t myrepo/gundb:v1 .\r\ndocker run -p 8765:8765 myrepo/gundb:v1\r\n```\r\n\r\nOr, if you prefer your Docker image with metadata labels (Linux/Mac only):\r\n\r\n```bash\r\nnpm run docker\r\ndocker run -p 8765:8765 username/gun:git\r\n```\r\n\r\nThen visit [http://localhost:8765](http://localhost:8765) in your browser.\r\n\r\n## License\r\n\r\nDesigned with \u2665 by Mark Nadal, the GUN team, and many amazing contributors.\r\n\r\nOpenly licensed under [Zlib / MIT / Apache 2.0](https://github.com/amark/gun/blob/master/LICENSE.md).\r\n\r\n[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Famark%2Fgun.svg?size=large)](https://app.fossa.io/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Famark%2Fgun?ref=badge_large)\r\n\r\n[YouTube](https://www.youtube.com/channel/UCQAtpf-zi9Pp4__2nToOM8g) . [Twitter](https://twitter.com/marknadal)\r\n",
	"big-data hadoop hive java presto sql": "# Presto [![Build Status](https://travis-ci.com/prestodb/presto.svg?branch=master)](https://travis-ci.com/prestodb/presto)\n\nPresto is a distributed SQL query engine for big data.\n\nSee the [User Manual](https://prestodb.github.io/docs/current/) for deployment instructions and end user documentation.\n\n## Requirements\n\n* Mac OS X or Linux\n* Java 8 Update 151 or higher (8u151+), 64-bit. Both Oracle JDK and OpenJDK are supported.\n* Maven 3.3.9+ (for building)\n* Python 2.4+ (for running with the launcher script)\n\n## Building Presto\n\nPresto is a standard Maven project. Simply run the following command from the project root directory:\n\n    ./mvnw clean install\n\nOn the first build, Maven will download all the dependencies from the internet and cache them in the local repository (`~/.m2/repository`), which can take a considerable amount of time. Subsequent builds will be faster.\n\nPresto has a comprehensive set of unit tests that can take several minutes to run. You can disable the tests when building:\n\n    ./mvnw clean install -DskipTests\n\n\n## Presto native and Velox\n\n[Presto native](https://github.com/prestodb/presto/tree/master/presto-native-execution) is a C++ rewrite of Presto worker. [Presto native](https://github.com/prestodb/presto/tree/master/presto-native-execution) uses [Velox](https://github.com/facebookincubator/velox) as its primary engine to run presto workloads.\n\n[Velox](https://github.com/facebookincubator/velox) is a C++ database library which provides reusable, extensible, and high-performance data processing components.\n\nCheck out [building instructions](https://github.com/prestodb/presto/tree/master/presto-native-execution#building) to get started. \n\n\n## Running Presto in your IDE\n\n### Overview\n\nAfter building Presto for the first time, you can load the project into your IDE and run the server. We recommend using [IntelliJ IDEA](http://www.jetbrains.com/idea/). Because Presto is a standard Maven project, you can import it into your IDE using the root `pom.xml` file. In IntelliJ, choose Open Project from the Quick Start box or choose Open from the File menu and select the root `pom.xml` file.\n\nAfter opening the project in IntelliJ, double check that the Java SDK is properly configured for the project:\n\n* Open the File menu and select Project Structure\n* In the SDKs section, ensure that a 1.8 JDK is selected (create one if none exist)\n* In the Project section, ensure the Project language level is set to 8.0 as Presto makes use of several Java 8 language features\n\nPresto comes with sample configuration that should work out-of-the-box for development. Use the following options to create a run configuration:\n\n* Main Class: `com.facebook.presto.server.PrestoServer`\n* VM Options: `-ea -XX:+UseG1GC -XX:G1HeapRegionSize=32M -XX:+UseGCOverheadLimit -XX:+ExplicitGCInvokesConcurrent -Xmx2G -Dconfig=etc/config.properties -Dlog.levels-file=etc/log.properties`\n* Working directory: `$MODULE_WORKING_DIR$` or `$MODULE_DIR$`(Depends your version of IntelliJ)\n* Use classpath of module: `presto-main`\n\nThe working directory should be the `presto-main` subdirectory. In IntelliJ, using `$MODULE_DIR$` accomplishes this automatically.\n\nAdditionally, the Hive plugin must be configured with location of your Hive metastore Thrift service. Add the following to the list of VM options, replacing `localhost:9083` with the correct host and port (or use the below value if you do not have a Hive metastore):\n\n    -Dhive.metastore.uri=thrift://localhost:9083\n\n### Using SOCKS for Hive or HDFS\n\nIf your Hive metastore or HDFS cluster is not directly accessible to your local machine, you can use SSH port forwarding to access it. Setup a dynamic SOCKS proxy with SSH listening on local port 1080:\n\n    ssh -v -N -D 1080 server\n\nThen add the following to the list of VM options:\n\n    -Dhive.metastore.thrift.client.socks-proxy=localhost:1080\n\n### Running the CLI\n\nStart the CLI to connect to the server and run SQL queries:\n\n    presto-cli/target/presto-cli-*-executable.jar\n\nRun a query to see the nodes in the cluster:\n\n    SELECT * FROM system.runtime.nodes;\n\nIn the sample configuration, the Hive connector is mounted in the `hive` catalog, so you can run the following queries to show the tables in the Hive database `default`:\n\n    SHOW TABLES FROM hive.default;\n\n## Code Style\n\nWe recommend you use IntelliJ as your IDE. The code style template for the project can be found in the [codestyle](https://github.com/airlift/codestyle) repository along with our general programming and Java guidelines. In addition to those you should also adhere to the following:\n\n* Alphabetize sections in the documentation source files (both in table of contents files and other regular documentation files). In general, alphabetize methods/variables/sections if such ordering already exists in the surrounding code.\n* When appropriate, use the Java 8 stream API. However, note that the stream implementation does not perform well so avoid using it in inner loops or otherwise performance sensitive sections.\n* Categorize errors when throwing exceptions. For example, PrestoException takes an error code as an argument, `PrestoException(HIVE_TOO_MANY_OPEN_PARTITIONS)`. This categorization lets you generate reports so you can monitor the frequency of various failures.\n* Ensure that all files have the appropriate license header; you can generate the license by running `mvn license:format`.\n* Consider using String formatting (printf style formatting using the Java `Formatter` class): `format(\"Session property %s is invalid: %s\", name, value)` (note that `format()` should always be statically imported). Sometimes, if you only need to append something, consider using the `+` operator.\n* Avoid using the ternary operator except for trivial expressions.\n* Use an assertion from Airlift's `Assertions` class if there is one that covers your case rather than writing the assertion by hand. Over time we may move over to more fluent assertions like AssertJ.\n* When writing a Git commit message, follow these [guidelines](https://chris.beams.io/posts/git-commit/).\n\n## Building the Documentation\n\nTo learn how to build the docs, see the [docs README](presto-docs/README.md).\n\n## Building the Web UI\n\nThe Presto Web UI is composed of several React components and is written in JSX and ES6. This source code is compiled and packaged into browser-compatible JavaScript, which is then checked in to the Presto source code (in the `dist` folder). You must have [Node.js](https://nodejs.org/en/download/) and [Yarn](https://yarnpkg.com/en/) installed to execute these commands. To update this folder after making changes, simply run:\n\n    yarn --cwd presto-main/src/main/resources/webapp/src install\n\nIf no JavaScript dependencies have changed (i.e., no changes to `package.json`), it is faster to run:\n\n    yarn --cwd presto-main/src/main/resources/webapp/src run package\n\nTo simplify iteration, you can also run in `watch` mode, which automatically re-compiles when changes to source files are detected:\n\n    yarn --cwd presto-main/src/main/resources/webapp/src run watch\n\nTo iterate quickly, simply re-build the project in IntelliJ after packaging is complete. Project resources will be hot-reloaded and changes are reflected on browser refresh.\n\n## Release Notes\n\nWhen authoring a pull request, the PR description should include its relevant release notes.\nFollow [Release Notes Guidelines](https://github.com/prestodb/presto/wiki/Release-Notes-Guidelines) when authoring release notes. \n",
	"azkaban big-data bigdata flume hadoop hbase hdfs hive kafka mapreduce phoenix scala spark sqoop storm yarn zookeeper": "# BigData-Notes\n\n\n\n<div align=\"center\"> <img width=\"444px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/bigdata-notes-icon.png\"/> </div>\n<br/>\n\n**\u5927\u6570\u636e\u5165\u95e8\u6307\u5357**\n\n\n\n<table>\n    <tr>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/hadoop.jpg\"></th>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/hive.jpg\"></th>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/spark.jpg\"></th>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/storm.png\"></th>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/flink.png\"></th>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/hbase.png\"></th>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/kafka.png\"></th>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/zookeeper.jpg\"></th>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/flume.png\"></th>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/sqoop.png\"></th>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/azkaban.png\"></th>\n      <th><img width=\"50px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/scala.jpg\"></th>\n    </tr>\n    <tr>\n      <td align=\"center\"><a href=\"#\u4e00hadoop\">Hadoop</a></td>\n      <td align=\"center\"><a href=\"#\u4e8chive\">Hive</a></td>\n      <td align=\"center\"><a href=\"#\u4e09spark\">Spark</a></td>\n      <td align=\"center\"><a href=\"#\u56dbstorm\">Storm</a></td>\n      <td align=\"center\"><a href=\"#\u4e94flink\">Flink</a></td>\n      <td align=\"center\"><a href=\"#\u516dhbase\">HBase</a></td>\n      <td align=\"center\"><a href=\"#\u4e03kafka\">Kafka</a></td>\n      <td align=\"center\"><a href=\"#\u516bzookeeper\">Zookeeper</a></td>\n      <td align=\"center\"><a href=\"#\u4e5dflume\">Flume</a></td>\n      <td align=\"center\"><a href=\"#\u5341sqoop\">Sqoop</a></td>\n      <td align=\"center\"><a href=\"#\u5341\u4e00azkaban\">Azkaban</a></td>\n      <td align=\"center\"><a href=\"#\u5341\u4e8cscala\">Scala</a></td>\n    </tr>\n  </table>\n<br/>\n\n<div align=\"center\">\n\t<a href = \"https://github.com/heibaiying/Full-Stack-Notes\"> \n\t<img width=\"150px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/weixin.jpg\"/> \n\t</a> \n</div>\n<div align=\"center\"> <strong> \u5982\u679c\u9700\u8981\u79bb\u7ebf\u9605\u8bfb\uff0c\u53ef\u4ee5\u5728\u516c\u4f17\u53f7\u4e0a\u53d1\u9001 \u201cbigdata\u201d \u83b7\u53d6\u300a\u5927\u6570\u636e\u5165\u95e8\u6307\u5357\u300b\u79bb\u7ebf\u9605\u8bfb\u7248\uff01 </strong> </div>\n\n<br/>\n\n## :black_nib: \u524d  \u8a00\n\n1. [\u5927\u6570\u636e\u5b66\u4e60\u8def\u7ebf](notes/\u5927\u6570\u636e\u5b66\u4e60\u8def\u7ebf.md)\n2. [\u5927\u6570\u636e\u6280\u672f\u6808\u601d\u7ef4\u5bfc\u56fe](notes/\u5927\u6570\u636e\u6280\u672f\u6808\u601d\u7ef4\u5bfc\u56fe.md)        \n3. [\u5927\u6570\u636e\u5e38\u7528\u8f6f\u4ef6\u5b89\u88c5\u6307\u5357](notes/\u5927\u6570\u636e\u5e38\u7528\u8f6f\u4ef6\u5b89\u88c5\u6307\u5357.md)\n\n## \u4e00\u3001Hadoop\n\n1. [\u5206\u5e03\u5f0f\u6587\u4ef6\u5b58\u50a8\u7cfb\u7edf \u2014\u2014 HDFS](notes/Hadoop-HDFS.md)\n2. [\u5206\u5e03\u5f0f\u8ba1\u7b97\u6846\u67b6 \u2014\u2014 MapReduce](notes/Hadoop-MapReduce.md)\n3. [\u96c6\u7fa4\u8d44\u6e90\u7ba1\u7406\u5668 \u2014\u2014 YARN](notes/Hadoop-YARN.md)\n4. [Hadoop \u5355\u673a\u4f2a\u96c6\u7fa4\u73af\u5883\u642d\u5efa](notes/installation/Hadoop\u5355\u673a\u73af\u5883\u642d\u5efa.md)\n5. [Hadoop \u96c6\u7fa4\u73af\u5883\u642d\u5efa](notes/installation/Hadoop\u96c6\u7fa4\u73af\u5883\u642d\u5efa.md)\n6. [HDFS \u5e38\u7528 Shell \u547d\u4ee4](notes/HDFS\u5e38\u7528Shell\u547d\u4ee4.md)\n7. [HDFS Java API \u7684\u4f7f\u7528](notes/HDFS-Java-API.md)\n8. [\u57fa\u4e8e Zookeeper \u642d\u5efa Hadoop \u9ad8\u53ef\u7528\u96c6\u7fa4](notes/installation/\u57fa\u4e8eZookeeper\u642d\u5efaHadoop\u9ad8\u53ef\u7528\u96c6\u7fa4.md)\n\n## \u4e8c\u3001Hive\n\n1. [Hive \u7b80\u4ecb\u53ca\u6838\u5fc3\u6982\u5ff5](notes/Hive\u7b80\u4ecb\u53ca\u6838\u5fc3\u6982\u5ff5.md)\n2. [Linux \u73af\u5883\u4e0b Hive \u7684\u5b89\u88c5\u90e8\u7f72](notes/installation/Linux\u73af\u5883\u4e0bHive\u7684\u5b89\u88c5\u90e8\u7f72.md)\n4. [Hive CLI \u548c Beeline \u547d\u4ee4\u884c\u7684\u57fa\u672c\u4f7f\u7528](notes/HiveCLI\u548cBeeline\u547d\u4ee4\u884c\u7684\u57fa\u672c\u4f7f\u7528.md)\n6. [Hive \u5e38\u7528 DDL \u64cd\u4f5c](notes/Hive\u5e38\u7528DDL\u64cd\u4f5c.md)\n7. [Hive \u5206\u533a\u8868\u548c\u5206\u6876\u8868](notes/Hive\u5206\u533a\u8868\u548c\u5206\u6876\u8868.md)\n8. [Hive \u89c6\u56fe\u548c\u7d22\u5f15](notes/Hive\u89c6\u56fe\u548c\u7d22\u5f15.md)\n9. [Hive \u5e38\u7528 DML \u64cd\u4f5c](notes/Hive\u5e38\u7528DML\u64cd\u4f5c.md)\n10. [Hive \u6570\u636e\u67e5\u8be2\u8be6\u89e3](notes/Hive\u6570\u636e\u67e5\u8be2\u8be6\u89e3.md)\n\n## \u4e09\u3001Spark\n\n**Spark Core :**\n\n1. [Spark \u7b80\u4ecb](notes/Spark\u7b80\u4ecb.md)\n2. [Spark \u5f00\u53d1\u73af\u5883\u642d\u5efa](notes/installation/Spark\u5f00\u53d1\u73af\u5883\u642d\u5efa.md)\n4. [\u5f39\u6027\u5f0f\u6570\u636e\u96c6 RDD](notes/Spark_RDD.md)\n5. [RDD \u5e38\u7528\u7b97\u5b50\u8be6\u89e3](notes/Spark_Transformation\u548cAction\u7b97\u5b50.md)\n5. [Spark \u8fd0\u884c\u6a21\u5f0f\u4e0e\u4f5c\u4e1a\u63d0\u4ea4](notes/Spark\u90e8\u7f72\u6a21\u5f0f\u4e0e\u4f5c\u4e1a\u63d0\u4ea4.md)\n6. [Spark \u7d2f\u52a0\u5668\u4e0e\u5e7f\u64ad\u53d8\u91cf](notes/Spark\u7d2f\u52a0\u5668\u4e0e\u5e7f\u64ad\u53d8\u91cf.md)\n7. [\u57fa\u4e8e Zookeeper \u642d\u5efa Spark \u9ad8\u53ef\u7528\u96c6\u7fa4](notes/installation/Spark\u96c6\u7fa4\u73af\u5883\u642d\u5efa.md)\n\n**Spark SQL :**\n\n1. [DateFrame \u548c DataSet ](notes/SparkSQL_Dataset\u548cDataFrame\u7b80\u4ecb.md)\n2. [Structured API \u7684\u57fa\u672c\u4f7f\u7528](notes/Spark_Structured_API\u7684\u57fa\u672c\u4f7f\u7528.md)\n3. [Spark SQL \u5916\u90e8\u6570\u636e\u6e90](notes/SparkSQL\u5916\u90e8\u6570\u636e\u6e90.md)\n4. [Spark SQL \u5e38\u7528\u805a\u5408\u51fd\u6570](notes/SparkSQL\u5e38\u7528\u805a\u5408\u51fd\u6570.md)\n5. [Spark SQL JOIN \u64cd\u4f5c](notes/SparkSQL\u8054\u7ed3\u64cd\u4f5c.md)\n\n**Spark Streaming \uff1a**\n\n1. [Spark Streaming \u7b80\u4ecb](notes/Spark_Streaming\u4e0e\u6d41\u5904\u7406.md)\n2. [Spark Streaming \u57fa\u672c\u64cd\u4f5c](notes/Spark_Streaming\u57fa\u672c\u64cd\u4f5c.md)\n3. [Spark Streaming \u6574\u5408 Flume](notes/Spark_Streaming\u6574\u5408Flume.md)\n4. [Spark Streaming \u6574\u5408 Kafka](notes/Spark_Streaming\u6574\u5408Kafka.md)\n\n## \u56db\u3001Storm\n\n1. [Storm \u548c\u6d41\u5904\u7406\u7b80\u4ecb](notes/Storm\u548c\u6d41\u5904\u7406\u7b80\u4ecb.md)\n2. [Storm \u6838\u5fc3\u6982\u5ff5\u8be6\u89e3](notes/Storm\u6838\u5fc3\u6982\u5ff5\u8be6\u89e3.md)\n3. [Storm \u5355\u673a\u73af\u5883\u642d\u5efa](notes/installation/Storm\u5355\u673a\u73af\u5883\u642d\u5efa.md)\n4. [Storm \u96c6\u7fa4\u73af\u5883\u642d\u5efa](notes/installation/Storm\u96c6\u7fa4\u73af\u5883\u642d\u5efa.md)\n5. [Storm \u7f16\u7a0b\u6a21\u578b\u8be6\u89e3](notes/Storm\u7f16\u7a0b\u6a21\u578b\u8be6\u89e3.md)\n6. [Storm \u9879\u76ee\u4e09\u79cd\u6253\u5305\u65b9\u5f0f\u5bf9\u6bd4\u5206\u6790](notes/Storm\u4e09\u79cd\u6253\u5305\u65b9\u5f0f\u5bf9\u6bd4\u5206\u6790.md)\n7. [Storm \u96c6\u6210 Redis \u8be6\u89e3](notes/Storm\u96c6\u6210Redis\u8be6\u89e3.md)\n8. [Storm \u96c6\u6210 HDFS/HBase](notes/Storm\u96c6\u6210HBase\u548cHDFS.md)\n9. [Storm \u96c6\u6210 Kafka](notes/Storm\u96c6\u6210Kakfa.md)\n\n## \u4e94\u3001Flink\n\n1. [Flink \u6838\u5fc3\u6982\u5ff5\u7efc\u8ff0](notes/Flink\u6838\u5fc3\u6982\u5ff5\u7efc\u8ff0.md)\n2. [Flink \u5f00\u53d1\u73af\u5883\u642d\u5efa](notes/Flink\u5f00\u53d1\u73af\u5883\u642d\u5efa.md)\n3. [Flink Data Source](notes/Flink_Data_Source.md)\n4. [Flink Data Transformation](notes/Flink_Data_Transformation.md)\n4. [Flink Data Sink](notes/Flink_Data_Sink.md)\n6. [Flink \u7a97\u53e3\u6a21\u578b](notes/Flink_Windows.md)\n7. [Flink \u72b6\u6001\u7ba1\u7406\u4e0e\u68c0\u67e5\u70b9\u673a\u5236](notes/Flink\u72b6\u6001\u7ba1\u7406\u4e0e\u68c0\u67e5\u70b9\u673a\u5236.md)\n8. [Flink Standalone \u96c6\u7fa4\u90e8\u7f72](notes/installation/Flink_Standalone_Cluster.md)\n\n\n## \u516d\u3001HBase\n\n1. [Hbase \u7b80\u4ecb](notes/Hbase\u7b80\u4ecb.md)\n2. [HBase \u7cfb\u7edf\u67b6\u6784\u53ca\u6570\u636e\u7ed3\u6784](notes/Hbase\u7cfb\u7edf\u67b6\u6784\u53ca\u6570\u636e\u7ed3\u6784.md)\n3. [HBase \u57fa\u672c\u73af\u5883\u642d\u5efa (Standalone /pseudo-distributed mode)](notes/installation/HBase\u5355\u673a\u73af\u5883\u642d\u5efa.md)\n4. [HBase \u96c6\u7fa4\u73af\u5883\u642d\u5efa](notes/installation/HBase\u96c6\u7fa4\u73af\u5883\u642d\u5efa.md)\n5. [HBase \u5e38\u7528 Shell \u547d\u4ee4](notes/Hbase_Shell.md)\n6. [HBase Java API](notes/Hbase_Java_API.md)\n7. [HBase \u8fc7\u6ee4\u5668\u8be6\u89e3](notes/Hbase\u8fc7\u6ee4\u5668\u8be6\u89e3.md)\n8. [HBase \u534f\u5904\u7406\u5668\u8be6\u89e3](notes/Hbase\u534f\u5904\u7406\u5668\u8be6\u89e3.md)\n9. [HBase \u5bb9\u707e\u4e0e\u5907\u4efd](notes/Hbase\u5bb9\u707e\u4e0e\u5907\u4efd.md)\n10. [HBase\u7684 SQL \u4e2d\u95f4\u5c42 \u2014\u2014 Phoenix](notes/Hbase\u7684SQL\u4e2d\u95f4\u5c42_Phoenix.md)\n11. [Spring/Spring Boot \u6574\u5408 Mybatis + Phoenix](notes/Spring+Mybtais+Phoenix\u6574\u5408.md)\n\n## \u4e03\u3001Kafka\n\n1. [Kafka \u7b80\u4ecb](notes/Kafka\u7b80\u4ecb.md)\n2. [\u57fa\u4e8e Zookeeper \u642d\u5efa Kafka \u9ad8\u53ef\u7528\u96c6\u7fa4](notes/installation/\u57fa\u4e8eZookeeper\u642d\u5efaKafka\u9ad8\u53ef\u7528\u96c6\u7fa4.md)\n3. [Kafka \u751f\u4ea7\u8005\u8be6\u89e3](notes/Kafka\u751f\u4ea7\u8005\u8be6\u89e3.md)\n4. [Kafka \u6d88\u8d39\u8005\u8be6\u89e3](notes/Kafka\u6d88\u8d39\u8005\u8be6\u89e3.md)\n5. [\u6df1\u5165\u7406\u89e3 Kafka \u526f\u672c\u673a\u5236](notes/Kafka\u6df1\u5165\u7406\u89e3\u5206\u533a\u526f\u672c\u673a\u5236.md)\n\n## \u516b\u3001Zookeeper\n\n1. [Zookeeper \u7b80\u4ecb\u53ca\u6838\u5fc3\u6982\u5ff5](notes/Zookeeper\u7b80\u4ecb\u53ca\u6838\u5fc3\u6982\u5ff5.md)\n2. [Zookeeper \u5355\u673a\u73af\u5883\u548c\u96c6\u7fa4\u73af\u5883\u642d\u5efa](notes/installation/Zookeeper\u5355\u673a\u73af\u5883\u548c\u96c6\u7fa4\u73af\u5883\u642d\u5efa.md) \n3. [Zookeeper \u5e38\u7528 Shell \u547d\u4ee4](notes/Zookeeper\u5e38\u7528Shell\u547d\u4ee4.md)\n4. [Zookeeper Java \u5ba2\u6237\u7aef \u2014\u2014 Apache Curator](notes/Zookeeper_Java\u5ba2\u6237\u7aefCurator.md)\n5. [Zookeeper  ACL \u6743\u9650\u63a7\u5236](notes/Zookeeper_ACL\u6743\u9650\u63a7\u5236.md)\n\n## \u4e5d\u3001Flume\n\n1. [Flume \u7b80\u4ecb\u53ca\u57fa\u672c\u4f7f\u7528](notes/Flume\u7b80\u4ecb\u53ca\u57fa\u672c\u4f7f\u7528.md)\n2. [Linux \u73af\u5883\u4e0b Flume \u7684\u5b89\u88c5\u90e8\u7f72](notes/installation/Linux\u4e0bFlume\u7684\u5b89\u88c5.md)\n3. [Flume \u6574\u5408 Kafka](notes/Flume\u6574\u5408Kafka.md)\n\n## \u5341\u3001Sqoop\n\n1. [Sqoop \u7b80\u4ecb\u4e0e\u5b89\u88c5](notes/Sqoop\u7b80\u4ecb\u4e0e\u5b89\u88c5.md)\n2. [Sqoop \u7684\u57fa\u672c\u4f7f\u7528](notes/Sqoop\u57fa\u672c\u4f7f\u7528.md)\n\n## \u5341\u4e00\u3001Azkaban\n\n1. [Azkaban \u7b80\u4ecb](notes/Azkaban\u7b80\u4ecb.md)\n2. [Azkaban3.x \u7f16\u8bd1\u53ca\u90e8\u7f72](notes/installation/Azkaban_3.x_\u7f16\u8bd1\u53ca\u90e8\u7f72.md)\n3. [Azkaban Flow 1.0 \u7684\u4f7f\u7528](notes/Azkaban_Flow_1.0_\u7684\u4f7f\u7528.md)\n4. [Azkaban Flow 2.0 \u7684\u4f7f\u7528](notes/Azkaban_Flow_2.0_\u7684\u4f7f\u7528.md)\n\n## \u5341\u4e8c\u3001Scala\n\n1. [Scala \u7b80\u4ecb\u53ca\u5f00\u53d1\u73af\u5883\u914d\u7f6e](notes/Scala\u7b80\u4ecb\u53ca\u5f00\u53d1\u73af\u5883\u914d\u7f6e.md)\n2. [\u57fa\u672c\u6570\u636e\u7c7b\u578b\u548c\u8fd0\u7b97\u7b26](notes/Scala\u57fa\u672c\u6570\u636e\u7c7b\u578b\u548c\u8fd0\u7b97\u7b26.md)\n3. [\u6d41\u7a0b\u63a7\u5236\u8bed\u53e5](notes/Scala\u6d41\u7a0b\u63a7\u5236\u8bed\u53e5.md)\n4. [\u6570\u7ec4 \u2014\u2014 Array](notes/Scala\u6570\u7ec4.md)\n5. [\u96c6\u5408\u7c7b\u578b\u7efc\u8ff0](notes/Scala\u96c6\u5408\u7c7b\u578b.md)\n6. [\u5e38\u7528\u96c6\u5408\u7c7b\u578b\u4e4b \u2014\u2014 List & Set](notes/Scala\u5217\u8868\u548c\u96c6.md)\n7. [\u5e38\u7528\u96c6\u5408\u7c7b\u578b\u4e4b \u2014\u2014 Map & Tuple](notes/Scala\u6620\u5c04\u548c\u5143\u7ec4.md)\n8. [\u7c7b\u548c\u5bf9\u8c61](notes/Scala\u7c7b\u548c\u5bf9\u8c61.md)\n9. [\u7ee7\u627f\u548c\u7279\u8d28](notes/Scala\u7ee7\u627f\u548c\u7279\u8d28.md)\n10. [\u51fd\u6570 & \u95ed\u5305 & \u67ef\u91cc\u5316](notes/Scala\u51fd\u6570\u548c\u95ed\u5305.md)\n11. [\u6a21\u5f0f\u5339\u914d](notes/Scala\u6a21\u5f0f\u5339\u914d.md)\n12. [\u7c7b\u578b\u53c2\u6570](notes/Scala\u7c7b\u578b\u53c2\u6570.md)\n13. [\u9690\u5f0f\u8f6c\u6362\u548c\u9690\u5f0f\u53c2\u6570](notes/Scala\u9690\u5f0f\u8f6c\u6362\u548c\u9690\u5f0f\u53c2\u6570.md)\n\n## \u5341\u4e09\u3001\u516c\u5171\u5185\u5bb9\n\n1. [\u5927\u6570\u636e\u5e94\u7528\u5e38\u7528\u6253\u5305\u65b9\u5f0f](notes/\u5927\u6570\u636e\u5e94\u7528\u5e38\u7528\u6253\u5305\u65b9\u5f0f.md)\n\n<br>\n\n## :bookmark_tabs: \u540e  \u8bb0\n\n[\u8d44\u6599\u5206\u4eab\u4e0e\u5f00\u53d1\u5de5\u5177\u63a8\u8350](notes/\u8d44\u6599\u5206\u4eab\u4e0e\u5de5\u5177\u63a8\u8350.md)\n\n<br>\n\n<div align=\"center\">\n\t<a href = \"https://blog.csdn.net/m0_37809146\"> \n\t<img width=\"200px\" src=\"https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/blog-logo.png\"/> \n\t</a> \n</div>\n<div align=\"center\"> <a  href = \"https://blog.csdn.net/m0_37809146\"> \u6b22\u8fce\u5173\u6ce8\u6211\u7684\u535a\u5ba2\uff1ahttps://blog.csdn.net/m0_37809146</a> </div>\n",
	"big-data predictionio scala": "<!--\nLicensed to the Apache Software Foundation (ASF) under one or more\ncontributor license agreements.  See the NOTICE file distributed with\nthis work for additional information regarding copyright ownership.\nThe ASF licenses this file to You under the Apache License, Version 2.0\n(the \"License\"); you may not use this file except in compliance with\nthe License.  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n# [Apache PredictionIO](http://predictionio.apache.org)\n\n[![Build\nStatus](https://api.travis-ci.org/apache/predictionio.svg?branch=develop)](https://travis-ci.org/apache/predictionio)\n\nApache PredictionIO is an open source machine learning framework\nfor developers, data scientists, and end users. It supports event collection,\ndeployment of algorithms, evaluation, querying predictive results via REST APIs.\nIt is based on scalable open source services like Hadoop, HBase (and other DBs),\nElasticsearch, Spark and implements what is called a Lambda Architecture.\n\nTo get started, check out http://predictionio.apache.org!\n\n\n## Table of contents\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Bugs and Feature Requests](#bugs-and-feature-requests)\n- [Documentation](#documentation)\n- [Contributing](#contributing)\n- [Community](#community)\n\n\n## Installation\n\nA few installation options available.\n\n*   [Installing Apache PredictionIO from\n    Binary/Source](http://predictionio.apache.org/install/install-sourcecode/)\n*   [Installing Apache PredictionIO with\n    Docker](http://predictionio.apache.org/install/install-docker/)\n\n## Quick Start\n\n*   [Recommendation Engine Template Quick\n    Start](http://predictionio.apache.org/templates/recommendation/quickstart/)\n    Guide\n*   [Similiar Product Engine Template Quick\n    Start](http://predictionio.apache.org/templates/similarproduct/quickstart/)\n    Guide\n*   [Classification Engine Template Quick\n    Start](http://predictionio.apache.org/templates/classification/quickstart/)\n    Guide\n\n\n## Bugs and Feature Requests\n\nUse [Apache JIRA](https://issues.apache.org/jira/browse/PIO) to report bugs or request new features.\n\n## Documentation\n\nDocumentation, included in this repo in the `docs/manual` directory, is built\nwith [Middleman](http://middlemanapp.com/) and publicly hosted at\n[predictionio.apache.org](http://predictionio.apache.org/).\n\nInterested in helping with our documentation? Read [Contributing\nDocumentation](http://predictionio.apache.org/community/contribute-documentation/).\n\n\n## Community\n\nKeep track of development and community news.\n\n*   Subscribe to the user mailing list <mailto:user-subscribe@predictionio.apache.org>\n    and the dev mailing list <mailto:dev-subscribe@predictionio.apache.org>\n*   Follow [@predictionio](https://twitter.com/predictionio) on Twitter.\n\n\n## Contributing\n\nRead the [Contribute Code](http://predictionio.apache.org/community/contribute-code/) page.\n\nYou can also list your projects on the [Community Project\npage](http://predictionio.apache.org//community/projects/).\n\n\n## License\n\nApache PredictionIO is under [Apache 2\nlicense](http://www.apache.org/licenses/LICENSE-2.0.html).\n",
	"best-practices big-data cookbook data-engineer data-engineering": "<!--- # The Data Engineering Cookbook -->\n\n<div align=\"center\">\n\t<img width=\"341\" height=\"426\" src=\"images/CookbookCover.jpg\" alt=\"Data Engineering Cookbook\">\n\t<br>\n\t<br>\n\t<br>\n</div>\n\n<p align=\"center\">\n\t<a href=\"sections/01-Introduction.md\">What is this Book?</a>&nbsp;&nbsp;&nbsp;\n  <a href=\"#how-to-contribute\">How to Contribute</a>&nbsp;&nbsp;&nbsp;\n  <a href=\"https://www.youtube.com/channel/UCY8mzqqGwl5_bTpBY9qLMAA\">YouTube</a>&nbsp;&nbsp;&nbsp;\n\t<a\n  <a href=\"https://twitter.com/andreaskayy\">Twitter</a>&nbsp;&nbsp;&nbsp;\n  <a href=\"https://www.amazon.com/shop/plumbersofdatascience\">Amazon Shop</a>\n</p>\n\n<br>\n\n## If You Like This Book & Need More Help\nCheck out my Data Engineering Academy and personal Coaching at LearnDataEngineering.com\n\n**Visit learndataengineering.com:** [Click Here](https://learndataengineering.com)\n\n- Learn Data Engineering with our online Academy\n- Perfect for becoming a Data Engineer or add Data Engineering to your skillset\n- Proven process based on years of experience and hundreds of hours of personal coaching\n- Prepared courses on the most important fundamentals, tools and platforms plus our\n- Associate Data Engineer Certification\n- Private Slack workgroup with over 500 members\n\n\n\n## Support This Book For Free!\n- **Amazon:** [Click Here](https://www.amazon.com/shop/plumbersofdatascience) buy whatever you like from Amazon using this link* (Also check out my complete podcast gear and books)\n\n<!---\nI get asked super often how to become a Data Engineer.\nThat's why I decided to start this cookbook with all the topics you need to look into.\n\nIt's not only useful for beginners, professionals will definitely like the case study section.\n\nIf you look for the old PDF version it's [here](https://github.com/andkret/Cookbook/raw/LaTex-Version-Deprecated/Data%20Engineering%20Cookbook.pdf)\n\n-->\n\n# Contents:\n- [Introduction](sections/01-Introduction.md)\n- [Basic Engineering Skills](sections/02-BasicSkills.md)\n- [Advanced Engineering Skills](sections/03-AdvancedSkills.md)\n- [Hands On Course](sections/04-HandsOnCourse.md)\u201a\n- [Case Studies](sections/05-CaseStudies.md)\n- [Best Practices Cloud Platforms](sections/06-BestPracticesCloud.md)\n- [130+ Data Sources Data Science](sections/07-DataSources.md)\n- [1001 Interview Questions](sections/08-InterviewQuestions.md)\n- [Recommended Books and Courses](sections/09-BooksAndCourses.md)\n<!--  -->\n\n- [How To Contribute](#how-to-contribute)\n- [Support What You Like](#support)\n- [Important Links](#important-links)\n\n# Full Table Of Contents:\n##  Introduction\n- [What is this Cookbook](sections/01-Introduction.md#what-is-this-cookbook)\n- [Data Engineer vs Data Scientist](sections/01-Introduction.md#data-engineer-vs-data-scientist)\n  - [Data Engineer](sections/01-Introduction.md#data-engineer)\n  - [Data Scientist](sections/01-Introduction.md#data-scientist)\n  - [Machine Learning Workflow](sections/01-Introduction.md#machine-learning-workflow)\n  - [Machine Learning Model and Data](sections/01-Introduction.md#machine-learning-model-and-data)\n- [My Data Science Platform Blueprint](sections/01-Introduction.md#my-data-science-platform-blueprint)\n  - [Connect](sections/01-Introduction.md#connect)\n  - [Buffer](sections/01-Introduction.md#buffer)\n  - [Processing Framework](sections/01-Introduction.md#processing-framework)\n  - [Store](sections/01-Introduction.md#store)\n  - [Visualize](sections/01-Introduction.md#visualize)\n- [Who Companies Need](sections/01-Introduction.md#who-companies-need)\n\n## Basic Engineering Skills\n- [Learn To Code](sections/02-BasicSkills.md#learn-to-code)\n- [Get Familiar With Git](sections/02-BasicSkills.md#get-familiar-with-git)\n- [Agile Development](sections/02-BasicSkills.md#agile-development)\n  - [Why is agile so important?](sections/02-BasicSkills.md#Why-is-agile-so-important)\n  - [Agile rules I learned over the years](sections/02-BasicSkills.md#agile-rules-i-learned-over-the-years)\n  - [Agile Frameworks](sections/02-BasicSkills.md#agile-frameworks)\n    - [Scrum](sections/02-BasicSkills.md#scrum)\n    - [OKR](sections/02-BasicSkills.md#okr)\n- [Software Engineering Culture](sections/02-BasicSkills.md#software-engineering-culture)\n- [Learn how a Computer Works](sections/02-BasicSkills.md#learn-how-a-computer-works)\n- [Data Network Transmission](sections/02-BasicSkills.md#data-network-transmission)\n- [Security and Privacy](sections/02-BasicSkills.md#security-and-privacy)\n  - [SSL Public and Private Key Certificates](sections/02-BasicSkills.md#ssl-public-and-private-key-Certificates)\n  - [JSON Web Tokens](sections/02-BasicSkills.md#json-web-tokens)\n  - [GDPR regulations](sections/02-BasicSkills.md#gdpr-regulations)\n- [Linux](sections/02-BasicSkills.md#linux)\n  - [OS Basics](sections/02-BasicSkills.md#os-basics)\n  - [Shell scripting](sections/02-BasicSkills.md#shell-scripting)\n  - [Cron Jobs](sections/02-BasicSkills.md#cron-jobs)\n  - [Packet Management](sections/02-BasicSkills.md#packet-management)\n- [Docker](sections/02-BasicSkills.md#docker)\n  - [What is Docker and How it Works](sections/02-BasicSkills.md#what-is-docker-and-what-do-you-use-it-for)\n    -  [Don't Mess Up Your System](sections/02-BasicSkills.md#dont-mess-up-your-system)\n    - [Preconfigured Images](sections/02-BasicSkills.md#preconfigured-images)\n    - [Take it With You](sections/02-BasicSkills.md#take-it-with-you)\n    - [Kubernetes Container Deployment](sections/02-BasicSkills.md#kubernetes-container-deployment)\n    - [How to Create Start and Stop a Container](sections/02-BasicSkills.md#how-to-create-start-stop-a-container)\n    - [Docker Micro Services](sections/02-BasicSkills.md#docker-micro-services)\n    - [Kubernetes](sections/02-BasicSkills.md#kubernetes)\n    - [Why and How To Do Docker Container Orchestration](sections/02-BasicSkills.md#why-and-how-to-do-docker-container-orchestration)\n    - [Userful Docker Commands](sections/02-BasicSkills.md#useful-docker-commands)\n- [The Cloud](sections/02-BasicSkills.md#the-cloud)\n  - [IaaS vs PaaS vs SaaS](sections/02-BasicSkills.md#iaas-vs-paas-vs-saas)\n  - [AWS Azure IBM Google IBM](sections/02-BasicSkills.md#aws-azure-ibm-google)\n  - [Cloud vs On-Premises](sections/02-BasicSkills.md#cloud-vs-on-premises)\n  - [Security](sections/02-BasicSkills.md#security)\n  - [Hybrid Clouds](sections/02-BasicSkills.md#hybrid-clouds)\n- [Security Zone Design](sections/02-BasicSkills.md#security-zone-design)\n  - [How to secure a multi layered application](sections/02-BasicSkills.md#how-to-secure-a-multi-layered-application)\n  - [Cluster security with Kerberos](sections/02-BasicSkills.md#cluster-security-with-kerberos)\n\n## Advanced Engineering Skills\n- [Data Science Platform](sections/03-AdvancedSkills.md#data-science-platform)\n  - [Why a Good Data Platform Is Important](sections/03-AdvancedSkills.md#why-a-good-data-platform-is-important)\n  - [Big Data vs Data Science and Analytics](sections/03-AdvancedSkills.md#Big-Data-vs-Data-Science-and-Analytics)\n  - [The 4 Vs of Big Data](sections/03-AdvancedSkills.md#the-4-vs-of-big-data)\n  - [Why Big Data](sections/03-AdvancedSkills.md#why-big-data)\n    - [Planning is Everything](sections/03-AdvancedSkills.md#planning-is-everything)\n    - [The Problem with ETL](sections/03-AdvancedSkills.md#the-problem-with-etl)\n    - [Scaling Up](sections/03-AdvancedSkills.md#scaling-up)\n    - [Scaling Out](sections/03-AdvancedSkills.md#scaling-out)\n    - [When not to Do Big Data](sections/03-AdvancedSkills.md#please-dont-go-big-data)\n- [Hadoop Platforms](sections/03-AdvancedSkills.md#hadoop-platforms)\n  - [What is Hadoop](sections/03-AdvancedSkills.md#what-is-hadoop)\n  - [What makes Hadoop so popular](sections/03-AdvancedSkills.md#what-makes-hadoop-so-popular)\n  - [Hadoop Ecosystem Components](sections/03-AdvancedSkills.md#hadoop-ecosystem-components)\n  - [Hadoop is Everywhere?](sections/03-AdvancedSkills.md#hadoop-is-everywhere)\n  - [Should You Learn Hadoop?](sections/03-AdvancedSkills.md#should-you-learn-hadoop)\n  - [How to Select Hadoop Cluster Hardware](sections/03-AdvancedSkills.md#how-to-select-hadoop-cluster-hardware)\n- [Connect](sections/03-AdvancedSkills.md#connect)\n  - [REST APIs](sections/03-AdvancedSkills.md#rest-apis)\n    - [API Design](sections/03-AdvancedSkills.md#api-design)\n    - [Implemenation Frameworks](sections/03-AdvancedSkills.md#implementation-frameworks)\n    - [Security](sections/03-AdvancedSkills.md#security)\n  - [Apache Nifi](sections/03-AdvancedSkills.md#apache-nifi)\n  - [Logstash](sections/03-AdvancedSkills.md#logstash)\n- [Buffer](sections/03-AdvancedSkills.md#buffer)\n  - [Apache Kafka](sections/03-AdvancedSkills.md#apache-kafka)\n    - [Why a Message Queue Tool?](sections/03-AdvancedSkills.md#why-a-message-queue-tool)\n    - [Kafka Architecture](sections/03-AdvancedSkills.md#kafka-architecture)\n    - [Kafka Topics](sections/03-AdvancedSkills.md#what-are-topics)\n    - [Kafka and Zookeeper](sections/03-AdvancedSkills.md#what-does-zookeeper-have-to-do-with-kafka)\n    - [How to Produce and Consume Messages](sections/03-AdvancedSkills.md#how-to-produce-and-consume-messages)\n    - [Kafka Commands](sections/03-AdvancedSkills.md#kafka-commands)\n  - [Apache Redis Pub-Sub](sections/03-AdvancedSkills.md#redis-pub-sub)\n  - [AWS Kinesis](sections/03-AdvancedSkills.md#apache-kafka)\n  - [Google Cloud PubSub](sections/03-AdvancedSkills.md#google-cloud-pubsub)\n- [Processing Frameworks](sections/03-AdvancedSkills.md#processing-frameworks)\n\t- [Lambda and Kappa Architecture](sections/03-AdvancedSkills.md#lambda-and-kappa-architecture)\n\t- [Batch Processing](sections/03-AdvancedSkills.md#batch-processing)\n\t- [Stream Processing](sections/03-AdvancedSkills.md#stream-processing)\n\t\t- [Three Methods of Streaming](sections/03-AdvancedSkills.md#three-methods-of-streaming)\n\t\t- [At Least Once](sections/03-AdvancedSkills.md#at-least-once)\n\t\t- [At Most Once](sections/03-AdvancedSkills.md#at-most-once)\n\t\t- [Exactly Once](sections/03-AdvancedSkills.md#exactly-once)\n\t\t- [Check The Tools](sections/03-AdvancedSkills.md#check-the-tools)\n\t- [Should You do Stream or Batch Processing](sections/03-AdvancedSkills.md#should-you-do-stream-or-batch-processing)\n\t- [Is ETL still relevant for Analytics?](sections/03-AdvancedSkills.md#is-etl-still-relevant-for-analytics)\n  - [MapReduce](sections/03-AdvancedSkills.md#mapreduce)\n    - [How Does MapReduce Work](sections/03-AdvancedSkills.md#How-does-mapreduce-work)\n    - [MapReduce](sections/03-AdvancedSkills.md#mapreduce)\n    - [MapReduce Example](sections/03-AdvancedSkills.md#example)\n    - [MapReduce Limitations](sections/03-AdvancedSkills.md#What-is-the-limitation-of-mapreduce)\n  - [Apache Spark](sections/03-AdvancedSkills.md#apache-spark)\n    - [What is the Difference to MapReduce?](sections/03-AdvancedSkills.md#what-is-the-difference-to-MapReduce)\n    - [How Spark Fits to Hadoop](sections/03-AdvancedSkills.md#how-does-spark-fit-to-hadoop)\n    - [Spark vs Hadoop](sections/03-AdvancedSkills.md#wheres-the-difference)\n    - [Spark and Hadoop a Perfect Fit](sections/03-AdvancedSkills.md#spark-and-hadoop-is-a-perfect-fit)\n    - [Spark on YARn](sections/03-AdvancedSkills.md#spark-on-yarn)\n    - [My Simple Rule of Thumb](sections/03-AdvancedSkills.md#my-simple-rule-of-thumb)\n    - [Available Languages](sections/03-AdvancedSkills.md#available-languages)\n    - [Spark Driver Executor and SparkContext](sections/03-AdvancedSkills.md#how-spark-works-driver-executor-sparkcontext)\n    - [Spark Batch vs Stream processing](sections/03-AdvancedSkills.md#spark-batch-vs-stream-processing)\n    - [How Spark uses Data From Hadoop](sections/03-AdvancedSkills.md#How-does-spark-use-data-from-hadoop)\n    - [What are RDDs and How to Use Them](sections/03-AdvancedSkills.md#what-are-rdds-and-how-to-use-them)\n    - [SparkSQL How and Why to Use It](sections/03-AdvancedSkills.md#available-languages)\n    - [What are Dataframes and How to Use Them](sections/03-AdvancedSkills.md#what-are-dataframes-how-to-use-them)\n    - [Machine Learning on Spark (TensorFlow)](sections/03-AdvancedSkills.md#machine-learning-on-spark-tensor-flow)\n    - [MLlib](sections/03-AdvancedSkills.md#mllib)\n    - [Spark Setup](sections/03-AdvancedSkills.md#spark-setup)\n    - [Spark Resource Management](sections/03-AdvancedSkills.md#spark-resource-management)\n  - [AWS Lambda](sections/03-AdvancedSkills.md#apache-flink)  \n  - [Apache Flink](sections/03-AdvancedSkills.md#apache-flink)\n  - [Elasticsearch](sections/03-AdvancedSkills.md#elasticsearch)\n  - [Apache Drill](sections/03-AdvancedSkills.md#apache-drill)\n  - [StreamSets](sections/03-AdvancedSkills.md#streamsets)\n- [Store](sections/03-AdvancedSkills.md#store)\n  - [Data Warehouse vs Data Lake](sections/03-AdvancedSkills.md#data-warehouse-vs-data-lake)\n  - [SQL Databases](sections/03-AdvancedSkills.md#sql-databases)\n    - [PostgreSQL DB](sections/03-AdvancedSkills.md#postgresql-db)\n    - [Database Design](sections/03-AdvancedSkills.md#database-design)\n    - [SQL Queries](sections/03-AdvancedSkills.md#sql-queries)\n    - [Stored Procedures](sections/03-AdvancedSkills.md#stored-procedures)\n    - [ODBC/JDBC Server Connections](sections/03-AdvancedSkills.md#odbc-jdbc-server-connections)\n  - [NoSQL Stores](sections/03-AdvancedSkills.md#nosql-stores)\n    - [HBase KeyValue Store](sections/03-AdvancedSkills.md#keyvalue-stores-hbase)\n    - [HDFS Document Store](sections/03-AdvancedSkills.md#document-stores-hdfs)\n    - [MongoDB Document Store](sections/03-AdvancedSkills.md#document-stores-mongodb)\n    - [Elasticsearch Document Store](sections/03-AdvancedSkills.md#Elasticsearch-search-engine-and-document-store)\n    - [Hive Warehouse](sections/03-AdvancedSkills.md#hive-warehouse)\n    - [Impala](sections/03-AdvancedSkills.md#impala)\n    - [Kudu](sections/03-AdvancedSkills.md#kudu)\n    - [Apache Druid](sections/03-AdvancedSkills.md#apache-druid)\n    - [InfluxDB Time Series Database](sections/03-AdvancedSkills.md#influxdb-time-series-database)\n    - [Greenplum MPP Database](sections/03-AdvancedSkills.md#mpp-databases-greenplum)\n- [Visualize](sections/03-AdvancedSkills.md#visualize)\n  - [Android and IOS](sections/03-AdvancedSkills.md#android-and-ios)\n  - [API Design for Mobile Apps](sections/03-AdvancedSkills.md#how-to-design-apis-for-mobile-apps)\n  - [Dashboards](sections/03-AdvancedSkills.md#dashboards)\n    - [Grafana](sections/03-AdvancedSkills.md#grafana)\n    - [Kibana](sections/03-AdvancedSkills.md#kibana)\n  - [Webservers](sections/03-AdvancedSkills.md#how-to-use-webservers-to-display-content)\n    - [Tomcat](sections/03-AdvancedSkills.md#tomcat)\n    - [Jetty](sections/03-AdvancedSkills.md#jetty)\n    - [NodeRED](sections/03-AdvancedSkills.md#nodered)\n    - [React](sections/03-AdvancedSkills.md#react)\n  - [Business Intelligence Tools](sections/03-AdvancedSkills.md#business-intelligence-tools)\n    - [Tableau](sections/03-AdvancedSkills.md#tableau)\n    - [Power BI](sections/03-AdvancedSkills.md#power-bi)\n    - [Quliksense](sections/03-AdvancedSkills.md#quliksense)\n  - [Identity & Device Management](sections/03-AdvancedSkills.md#Identity-and-device-management)\n    - [What Is A Digital Twin](sections/03-AdvancedSkills.md#what-is-a-digital-twin)\n    - [Active Directory](sections/03-AdvancedSkills.md#active-directory)\n- [Machine Learning](sections/03-AdvancedSkills.md#machine-learning)\n  - [How to do Machine Learning in production](sections/03-AdvancedSkills.md#how-to-domachine-learning-in-production)\n  - [Why machine learning in production is harder then you think](sections/03-AdvancedSkills.md#why-machine-learning-in-production-is-harder-then-you-think)\n  - [Models Do Not Work Forever](sections/03-AdvancedSkills.md#models-do-not-work-forever)\n  - [Where are The Platforms That Support Machine Learning](sections/03-AdvancedSkills.md#where-are-the-platforms-that-support-this)\n  - [Training Parameter Management](sections/03-AdvancedSkills.md#training-parameter-management)\n  - [How to Convince People That Machine Learning Works](sections/03-AdvancedSkills.md#how-to-convince-people-machine-learning-works)\n  - [No Rules No Physical Models](sections/03-AdvancedSkills.md#no-rules-no-physical-models)\n  - [You Have The Data. Use It!](sections/03-AdvancedSkills.md#you-have-the-data-use-it)\n  - [Data is Stronger Than Opinions](sections/03-AdvancedSkills.md#data-is-stronger-than-opinions)\n  - [AWS Sagemaker](sections/03-AdvancedSkills.md#aws-sagemaker)\n\n\n## Hands On Course\n\n- [What We Want To Do](sections/04-HandsOnCourse.md#what-we-want-to-do)\n- [Thoughts On Choosing A Development Environment](sections/04-HandsOnCourse.md#thoughts-on-choosing-a-development-environment)\n- [A Look Into the Twitter API](sections/04-HandsOnCourse.md#a-look-into-the-twiiter-api)\n- [Ingesting Tweets with Apache Nifi](sections/04-HandsOnCourse.md#ingesting-tweets-with-apache-nifi)\n- [Writing from Nifi to Apache Kafka](sections/04-HandsOnCourse.md#writing-from-nifi-to-kafka)\n- [Apache Zeppelin Data Processing](sections/04-HandsOnCourse.md#apache-zeppelin)\n  - [Install and Ingest Kafka Topic](sections/04-HandsOnCourse.md#install-and-ingest-kafka-topic)\n  - [Processing Messages with Spark & SparkSQL](sections/04-HandsOnCourse.md#processing-messages-with-spark-and-sparksql)\n  - [Visualizing Data](sections/04-HandsOnCourse.md#visualizing-data)\n- [Switch Processing from Zeppelin to Spark](sections/04-HandsOnCourse.md#switch-processing-from-zeppelin-to-spark)\n\n## Case Studies\n\n- [Data Science @Airbnb](sections/05-CaseStudies.md#data-science-at-Airbnb)\n- [Data Science @Amazon](sections/05-CaseStudies.md#data-science-at-Amazon)\n- [Data Science @Baidu](sections/05-CaseStudies.md#data-science-at-Baidu)\n- [Data Science @Blackrock](sections/05-CaseStudies.md#data-science-at-Blackrock)\n- [Data Science @BMW](sections/05-CaseStudies.md#data-science-at-BMW)\n- [Data Science @Booking.com](sections/05-CaseStudies.md#data-science-at-Booking.com)\n- [Data Science @CERN](sections/05-CaseStudies.md#data-science-at-CERN)\n- [Data Science @Disney](sections/05-CaseStudies.md#data-science-at-Disney)\n- [Data Science @DLR](sections/05-CaseStudies.md#data-science-at-DLR)\n- [Data Science @Drivetribe](sections/05-CaseStudies.md#data-science-at-Drivetribe)\n- [Data Science @Dropbox](sections/05-CaseStudies.md#data-science-at-Dropbox)\n- [Data Science @Ebay](sections/05-CaseStudies.md#data-science-at-Ebay)\n- [Data Science @Expedia](sections/05-CaseStudies.md#data-science-at-Expedia)\n- [Data Science @Facebook](sections/05-CaseStudies.md#data-science-at-Facebook)\n- [Data Science @Google](sections/05-CaseStudies.md#data-science-at-Google)\n- [Data Science @Grammarly](sections/05-CaseStudies.md#data-science-at-Grammarly)\n- [Data Science @ING Fraud](sections/05-CaseStudies.md#data-science-at-ING-Fraud)\n- [Data Science @Instagram](sections/05-CaseStudies.md#data-science-at-Instagram)\n- [Data Science @LinkedIn](sections/05-CaseStudies.md#data-science-at-LinkedIn)\n- [Data Science @Lyft](sections/05-CaseStudies.md#data-science-at-Lyft)\n- [Data Science @NASA](sections/05-CaseStudies.md#data-science-at-NASA)\n- [Data Science @Netflix](sections/05-CaseStudies.md#data-science-at-Netflix)\n- [Data Science @OLX](sections/05-CaseStudies.md#data-science-at-OLX)\n- [Data Science @OTTO](sections/05-CaseStudies.md#data-science-at-OTTO)\n- [Data Science @Paypal](sections/05-CaseStudies.md#data-science-at-Paypal)\n- [Data Science @Pinterest](sections/05-CaseStudies.md#data-science-at-Pinterest)\n- [Data Science @Salesforce](sections/05-CaseStudies.md#data-science-at-Salesforce)\n- [Data Science @Siemens Mindsphere](sections/05-CaseStudies.md#data-science-at-Siemens-Mindsphere)\n- [Data Science @Slack](sections/05-CaseStudies.md#data-science-at-Slack)\n- [Data Science @Spotify](sections/05-CaseStudies.md#data-science-at-Spotify)\n- [Data Science @Symantec](sections/05-CaseStudies.md#data-science-at-Symantec)\n- [Data Science @Tinder](sections/05-CaseStudies.md#data-science-at-Tinder)\n- [Data Science @Twitter](sections/05-CaseStudies.md#data-science-at-Twitter)\n- [Data Science @Uber](sections/05-CaseStudies.md#data-science-at-Uber)\n- [Data Science @Upwork](sections/05-CaseStudies.md#data-science-at-Upwork)\n- [Data Science @Woot](sections/05-CaseStudies.md#data-science-at-Woot)\n- [Data Science @Zalando](sections/05-CaseStudies.md#data-science-at-Zalando)\n\n## Best Practices Cloud Platforms\n\n- [Amazon Web Services (AWS)](sections/06-BestPracticesCloud.md#aws)\n  - [Connect](sections/06-BestPracticesCloud.md#Connect)\n  - [Buffer](sections/06-BestPracticesCloud.md#Buffer)\n  - [Processing](sections/06-BestPracticesCloud.md#Processing)\n  - [Store](sections/06-BestPracticesCloud.md#Store)\n  - [Visualize](sections/06-BestPracticesCloud.md#Visualize)\n  - [Containerization](sections/06-BestPracticesCloud.md#Containerization)\n  - [Best Practices](sections/06-BestPracticesCloud.md#Best-Practices)\n  - [More Details](sections/06-BestPracticesCloud.md#More-Details)\n- [Microsoft Azure](sections/06-BestPracticesCloud.md#azure)\n  - [Connect](sections/06-BestPracticesCloud.md#Connect-1)\n  - [Buffer](sections/06-BestPracticesCloud.md#Buffer-1)\n  - [Processing](sections/06-BestPracticesCloud.md#Processing-1)\n  - [Store](sections/06-BestPracticesCloud.md#Store-1)\n  - [Visualize](sections/06-BestPracticesCloud.md#Visualize-1)\n  - [Containerization](sections/06-BestPracticesCloud.md#Containerization-1)\n  - [Best Practices](sections/06-BestPracticesCloud.md#Best-Practices-1)\n- [Google Cloud Platform (GCP)](sections/06-BestPracticesCloud.md#gcp)\n  - [Connect](sections/06-BestPracticesCloud.md#Connect-2)\n  - [Buffer](sections/06-BestPracticesCloud.md#Buffer-2)\n  - [Processing](sections/06-BestPracticesCloud.md#Processing-2)\n  - [Store](sections/06-BestPracticesCloud.md#Store-2)\n  - [Visualize](sections/06-BestPracticesCloud.md#Visualize-2)\n  - [Containerization](sections/06-BestPracticesCloud.md#Containerization-2)\n  - [Best Practices](sections/06-BestPracticesCloud.md#Best-Practices-2)\n\n## 130+ Free Data Sources For Data Science\n\n- [General And Academic](sections/07-DataSources.md#General-And-Academic)\n- [Content Marketing](sections/07-DataSources.md#Content-Marketing)\n- [Crime](sections/07-DataSources.md#Crime)\n- [Drugs](sections/07-DataSources.md#Drugs)\n- [Education](sections/07-DataSources.md#Education)\n- [Entertainment](sections/07-DataSources.md#Entertainment)\n- [Environmental And Weather Data](sections/07-DataSources.md#Environmental-And-Weather-Data)\n- [Financial And Economic Data](sections/07-DataSources.md#Financial-And-Economic-Data])\n- [Government And World](sections/07-DataSources.md#Government-And-World)\n- [Health](sections/07-DataSources.md#Health)\n- [Human Rights](sections/07-DataSources.md#Human-Rights)\n- [Labor And Employment Data](sections/07-DataSources.md#Labor-And-Employment-Data)\n- [Politics](sections/07-DataSources.md#Politics)\n- [Retail](sections/07-DataSources.md#Retail)\n- [Social](sections/07-DataSources.md#Social)\n- [Travel And Transportation](sections/07-DataSources.md#Travel-And-Transportation)\n- [Various Portals](sections/07-DataSources.md#Various-Portals)\n- [Source Articles and Blog Posts](sections/07-DataSources.md#Source-Articles-and-Blog-Posts)\n- [Free Data Sources Data Science](sections/07-DataSources.md)\n\n## 1001 Interview Questions\n\n- [Interview Questions](sections/08-InterviewQuestions.md)\n\n## Recommended Books and Courses\n\n- [About Books and Courses](sections/09-BooksAndCourses.md#about-books-and-courses)\n- [Books](sections/09-BooksAndCourses.md#books)\n  - [Languages](sections/09-BooksAndCourses.md#books-languages)\n    - [Java](sections/09-BooksAndCourses.md#java)\n    - [Python](sections/09-BooksAndCourses.md#Python)\n    - [Scala](sections/09-BooksAndCourses.md#Scala)\n    - [Swift](sections/09-BooksAndCourses.md#Swift)\n  - [Data Science Tools](sections/09-BooksAndCourses.md#books-data-science-tools)\n    - [Apache Spark](sections/09-BooksAndCourses.md#apache-spark)\n    - [Apache Kafka](sections/09-BooksAndCourses.md#apache-Kafka)\n    - [Apache Hadoop](sections/09-BooksAndCourses.md#apache-Hadoop)\n    - [Apache HBase](sections/09-BooksAndCourses.md#apache-HBase)\n  - [Business](sections/09-BooksAndCourses.md#Books-Business)\n    - [The Lean Startup](sections/09-BooksAndCourses.md#the-lean-startup)\n    - [Zero to One](sections/09-BooksAndCourses.md#zero-to-one)\n    - [The Innovators Dilemma](sections/09-BooksAndCourses.md#the-innovators-dilemma)\n    - [Crossing the Chasm](sections/09-BooksAndCourses.md#crossing-the-chasm)\n    - [Crush It!](sections/09-BooksAndCourses.md#crush-it!)\n  - [Community Recommendations](sections/09-BooksAndCourses.md#Community-Recommendations)\n    - [Designing Data-Intensive Applications](sections/09-BooksAndCourses.md#designing-data-intensive-applications)\n- [Online Courses](BooksAndCourses#online-courses)\n  - [Machine Learning Stanford](sections/09-BooksAndCourses.md#machine-learning-stanford)\n  - [Computer Networking](sections/09-BooksAndCourses.md#computer-networking)\n  - [Spring Framework](sections/09-BooksAndCourses.md#spring-framework)\n  - [IOS App Development Specialization](sections/09-BooksAndCourses.md#ios-app-development-specialization)\n\n\n## How To Contribute\nIf you have some cool links or topics for the cookbook, please become a contributor.\n\nSimply pull the repo, add your ideas and create a pull request.\nYou can also open an issue and put your thoughts there.\n\nPlease use the \"Issues\" function for comments.\n\n## Support\n\nEverything is free, but please support what you like!\nJoin my Patreon and become a plumber yourself:\n[Link to my Patreon](https://patreon.com/plumbersofds)\n\nOr support me and send a message I read on the next livestream through Paypal.me:\n[Link to my Paypal.me/feedthestream](https://paypal.me/feedthestream)\n\n## Important Links\n\nSubscribe to my Plumbers of Data Science YouTube channel for regular updates:\n[Link to YouTube](https://www.youtube.com/channel/UCY8mzqqGwl5_bTpBY9qLMAA)\n\nCheck out my blog and get updated via mail by joining my mailing list:\n[andreaskretz.com](https://andreaskretz.com)\n\nI have a Medium publication where you can publish your data engineer articles to reach more people:\n[Medium publication](https://link.medium.com/9oi1VDrhPW)\n\n<br>\n*(As an Amazon Associate I earn from qualifying purchases from Amazon\nThis is free of charge for you, but super helpful for supporting this channel)\n",
	"big-data cluster-management kafka scala": "CMAK (Cluster Manager for Apache Kafka, previously known as Kafka Manager)\n=============\n\nCMAK (previously known as Kafka Manager) is a tool for managing [Apache Kafka](http://kafka.apache.org) clusters.\n_See below for details about the name change._\n\nCMAK supports the following:\n\n - Manage multiple clusters\n - Easy inspection of cluster state (topics, consumers, offsets, brokers, replica distribution, partition distribution)\n - Run preferred replica election\n - Generate partition assignments with option to select brokers to use\n - Run reassignment of partition (based on generated assignments)\n - Create a topic with optional topic configs (0.8.1.1 has different configs than 0.8.2+)\n - Delete topic (only supported on 0.8.2+ and remember set delete.topic.enable=true in broker config)\n - Topic list now indicates topics marked for deletion (only supported on 0.8.2+)\n - Batch generate partition assignments for multiple topics with option to select brokers to use\n - Batch run reassignment of partition for multiple topics\n - Add partitions to existing topic\n - Update config for existing topic\n - Optionally enable JMX polling for broker level and topic level metrics.\n - Optionally filter out consumers that do not have ids/ owners/ & offsets/ directories in zookeeper.\n\nCluster Management\n\n![cluster](/img/cluster.png)\n\n***\n\nTopic List\n\n![topic](/img/topic-list.png)\n\n***\n\nTopic View\n\n![topic](/img/topic.png)\n\n***\n\nConsumer List View\n\n![consumer](/img/consumer-list.png)\n\n***\n\nConsumed Topic View\n\n![consumer](/img/consumed-topic.png)\n\n***\n\nBroker List\n\n![broker](/img/broker-list.png)\n\n***\n\nBroker View\n\n![broker](/img/broker.png)\n\n***\n\nRequirements\n------------\n\n1. [Kafka 0.8.*.* or 0.9.*.* or 0.10.*.* or 0.11.*.*](http://kafka.apache.org/downloads.html)\n2. Java 11+\n\nConfiguration\n-------------\n\nThe minimum configuration is the zookeeper hosts which are to be used for CMAK (pka kafka manager) state.\nThis can be found in the application.conf file in conf directory.  The same file will be packaged\nin the distribution zip file; you may modify settings after unzipping the file on the desired server.\n\n    cmak.zkhosts=\"my.zookeeper.host.com:2181\"\n\nYou can specify multiple zookeeper hosts by comma delimiting them, like so:\n\n    cmak.zkhosts=\"my.zookeeper.host.com:2181,other.zookeeper.host.com:2181\"\n\nAlternatively, use the environment variable `ZK_HOSTS` if you don't want to hardcode any values.\n\n    ZK_HOSTS=\"my.zookeeper.host.com:2181\"\n\nYou can optionally enable/disable the following functionality by modifying the default list in application.conf :\n\n    application.features=[\"KMClusterManagerFeature\",\"KMTopicManagerFeature\",\"KMPreferredReplicaElectionFeature\",\"KMReassignPartitionsFeature\"]\n\n - KMClusterManagerFeature - allows adding, updating, deleting cluster from CMAK (pka Kafka Manager)\n - KMTopicManagerFeature - allows adding, updating, deleting topic from a Kafka cluster\n - KMPreferredReplicaElectionFeature - allows running of preferred replica election for a Kafka cluster\n - KMReassignPartitionsFeature - allows generating partition assignments and reassigning partitions\n\nConsider setting these parameters for larger clusters with jmx enabled :\n\n - cmak.broker-view-thread-pool-size=< 3 * number_of_brokers>\n - cmak.broker-view-max-queue-size=< 3 * total # of partitions across all topics>\n - cmak.broker-view-update-seconds=< cmak.broker-view-max-queue-size / (10 * number_of_brokers) >\n\nHere is an example for a kafka cluster with 10 brokers, 100 topics, with each topic having 10 partitions giving 1000 total partitions with JMX enabled :\n\n - cmak.broker-view-thread-pool-size=30\n - cmak.broker-view-max-queue-size=3000\n - cmak.broker-view-update-seconds=30\n\nThe follow control consumer offset cache's thread pool and queue :\n\n - cmak.offset-cache-thread-pool-size=< default is # of processors>\n - cmak.offset-cache-max-queue-size=< default is 1000>\n - cmak.kafka-admin-client-thread-pool-size=< default is # of processors>\n - cmak.kafka-admin-client-max-queue-size=< default is 1000>\n\nYou should increase the above for large # of consumers with consumer polling enabled.  Though it mainly affects ZK based consumer polling.\n\nKafka managed consumer offset is now consumed by KafkaManagedOffsetCache from the \"__consumer_offsets\" topic.  Note, this has not been tested with large number of offsets being tracked.  There is a single thread per cluster consuming this topic so it may not be able to keep up on large # of offsets being pushed to the topic.\n\n### Authenticating a User with LDAP\nWarning, you need to have SSL configured with CMAK (pka Kafka Manager) to ensure your credentials aren't passed unencrypted.\nAuthenticating a User with LDAP is possible by passing the user credentials with the Authorization header.\nLDAP authentication is done on first visit, if successful, a cookie is set.\nOn next request, the cookie value is compared with credentials from Authorization header.\nLDAP support is through the basic authentication filter.\n\n1. Configure basic authentication\n- basicAuthentication.enabled=true\n- basicAuthentication.realm=< basic authentication realm>\n\n2. Encryption parameters (optional, otherwise randomly generated on startup) :\n- basicAuthentication.salt=\"some-hex-string-representing-byte-array\"\n- basicAuthentication.iv=\"some-hex-string-representing-byte-array\"\n- basicAuthentication.secret=\"my-secret-string\"\n\n3. Configure LDAP/LDAPS authentication\n- basicAuthentication.ldap.enabled=< Boolean flag to enable/disable ldap authentication >\n- basicAuthentication.ldap.server=< fqdn of LDAP server>\n- basicAuthentication.ldap.port=< port of LDAP server>\n- basicAuthentication.ldap.username=< LDAP search username>\n- basicAuthentication.ldap.password=< LDAP search password>\n- basicAuthentication.ldap.search-base-dn=< LDAP search base>\n- basicAuthentication.ldap.search-filter=< LDAP search filter>\n- basicAuthentication.ldap.connection-pool-size=< number of connection to LDAP server>\n- basicAuthentication.ldap.ssl=< Boolean flag to enable/disable LDAPS>\n\n4. (Optional) Limit access to a specific LDAP Group\n- basicAuthentication.ldap.group-filter=< LDAP group filter>\n- basicAuthentication.ldap.ssl-trust-all=< Boolean flag to allow non-expired invalid certificates>\n\n#### Example (Online LDAP Test Server):\n\n- basicAuthentication.ldap.enabled=true\n- basicAuthentication.ldap.server=\"ldap.forumsys.com\"\n- basicAuthentication.ldap.port=389\n- basicAuthentication.ldap.username=\"cn=read-only-admin,dc=example,dc=com\"\n- basicAuthentication.ldap.password=\"password\"\n- basicAuthentication.ldap.search-base-dn=\"dc=example,dc=com\"\n- basicAuthentication.ldap.search-filter=\"(uid=$capturedLogin$)\"\n- basicAuthentication.ldap.group-filter=\"cn=allowed-group,ou=groups,dc=example,dc=com\"\n- basicAuthentication.ldap.connection-pool-size=10\n- basicAuthentication.ldap.ssl=false\n- basicAuthentication.ldap.ssl-trust-all=false\n\n\nDeployment\n----------\n\nThe command below will create a zip file which can be used to deploy the application.\n\n    ./sbt clean dist\n\nPlease refer to play framework documentation on [production deployment/configuration](https://www.playframework.com/documentation/2.4.x/ProductionConfiguration).\n\nIf java is not in your path, or you need to build against a specific java version,\nplease use the following (the example assumes zulu java11):\n\n    $ PATH=/usr/lib/jvm/zulu-11-amd64/bin:$PATH \\\n      JAVA_HOME=/usr/lib/jvm/zulu-11-amd64 \\\n      /path/to/sbt -java-home /usr/lib/jvm/zulu-11-amd64 clean dist\n\nThis ensures that the 'java' and 'javac' binaries in your path are first looked up in the\ncorrect location. Next, for all downstream tools that only listen to JAVA_HOME, it points\nthem to the java11 location. Lastly, it tells sbt to use the java11 location as\nwell.\n\nStarting the service\n--------------------\n\nAfter extracting the produced zipfile, and changing the working directory to it, you can\nrun the service like this:\n\n    $ bin/cmak\n\nBy default, it will choose port 9000. This is overridable, as is the location of the\nconfiguration file. For example:\n\n    $ bin/cmak -Dconfig.file=/path/to/application.conf -Dhttp.port=8080\n\nAgain, if java is not in your path, or you need to run against a different version of java,\nadd the -java-home option as follows:\n\n    $ bin/cmak -java-home /usr/lib/jvm/zulu-11-amd64\n\nStarting the service with Security\n----------------------------------\n\nTo add JAAS configuration for SASL, add the config file location at start:\n\n    $ bin/cmak -Djava.security.auth.login.config=/path/to/my-jaas.conf\n\nNOTE: Make sure the user running CMAK (pka kafka manager) has read permissions on the jaas config file\n\n\nPackaging\n---------\n\nIf you'd like to create a Debian or RPM package instead, you can run one of:\n\n    sbt debian:packageBin\n\n    sbt rpm:packageBin\n\nCredits\n-------\n\nMost of the utils code has been adapted to work with [Apache Curator](http://curator.apache.org) from [Apache Kafka](http://kafka.apache.org).\n\nName and Management\n-------\n\nCMAK was renamed from its previous name due to [this issue](https://github.com/yahoo/kafka-manager/issues/713). CMAK is designed to be used with Apache Kafka and is offered to support the needs of the Kafka community. This project is currently managed by employees at Verizon Media and the community who supports this project. \n\nLicense\n-------\n\nLicensed under the terms of the Apache License 2.0. See accompanying LICENSE file for terms.\n\nConsumer/Producer Lag\n-------\n\nProducer offset is polled.  Consumer offset is read from the offset topic for Kafka based consumers.  This means the reported lag may be negative since we are consuming offset from the offset topic faster then polling the producer offset.  This is normal and not a problem.\n\nMigration from Kafka Manager to CMAK\n-------\n\n1. Copy config files from old version to new version (application.conf, consumer.properties)\n2. Change start script to use bin/cmak instead of bin/kafka-manager\n\n",
	"analytics big-data cpp database financial-analysis grafana hacktoberfest iot java low-latency postgres postgresql questdb simd sql time-series time-series-database tsdb": "<div align=\"center\">\n  <a href=\"https://questdb.io/\" target=\"blank\"><img alt=\"QuestDB Logo\" src=\"https://questdb.io/img/questdb-logo-themed.svg\" width=\"305px\"/></a>\n</div>\n<p>&nbsp;</p>\n\n<p align=\"center\">\n  <a href=\"https://slack.questdb.io\">\n    <img src=\"https://slack.questdb.io/badge.svg\" alt=\"QuestDB community Slack channel\"/>\n  </a>\n  <a href=\"#contribute\">\n    <img src=\"https://img.shields.io/github/all-contributors/questdb/questdb/master\" alt=\"QuestDB open source contributors\"/>\n  </a>\n  <a href=\"https://search.maven.org/search?q=g:org.questdb\">\n    <img src=\"https://img.shields.io/maven-central/v/org.questdb/questdb\" alt=\"QuestDB on Apache Maven\"/>\n  </a>\n</p>\n\nEnglish | [\u7b80\u4f53\u4e2d\u6587](./i18n/README.zh-cn.md) | [\u7e41\u9ad4\u4e2d\u6587](./i18n/README.zh-hk.md) | [\u0627\u0644\u0639\u0631\u0628\u064a\u0629](./i18n/README.ar-dz.md) | [Italiano](./i18n/README.it-it.md) | [\u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430](./i18n/README.ua-ua.md) | [Espa\u00f1ol](./i18n/README.es-es.md) | [Portugu\u00eas](./i18n/README.pt.md) | [\u65e5\u672c](./i18n/README.ja-ja.md)\n\n# QuestDB\n\nQuestDB is an open-source time-series database for high throughput ingestion and\nfast SQL queries with operational simplicity. It supports schema-agnostic\ningestion using the InfluxDB line protocol, PostgreSQL wire protocol, and a REST\nAPI for bulk imports and exports.\n\nQuestDB is well suited for financial market data, application metrics, sensor\ndata, real-time analytics, dashboards, and infrastructure monitoring.\n\nQuestDB implements ANSI SQL with native time-series SQL semantics. These SQL\nsemantics make it simple to correlate data from multiple sources using\nrelational and time-series joins. We achieve high performance by adopting a\ncolumn-oriented storage model, parallelized vector execution, SIMD instructions,\nand low-latency techniques. The entire codebase is built from the ground up in\nJava and C++, with no dependencies and zero garbage collection.\n\n<div align=\"center\">\n  <a href=\"https://demo.questdb.io\">\n    <img alt=\"QuestDB Web Console showing multiple SQL statements and visualizing a query as a chart\" src=\"https://raw.githubusercontent.com/questdb/questdb/master/.github/console.png\" width=\"600\" />\n  </a>\n</div>\n\n## Try QuestDB\n\nWe provide a [live demo](https://demo.questdb.io/) provisioned with the latest\nQuestDB release and sample datasets:\n\n- Trips: 10 years of NYC taxi trips with 1.6 billion rows\n- Trades: live crytocurrency market data with 30M+ rows per month\n- Pos: geolocations of 250k unique ships over time\n\n| Query                                                                         | Execution time                                                                                                                                                                                      |\n| ----------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `SELECT sum(double) FROM trips`                                               | [0.15 secs](<https://demo.questdb.io/?query=SELECT%20sum(trip_distance)%20FROM%20trips;&executeQuery=true>)                                                                                         |\n| `SELECT sum(double), avg(double) FROM trips`                                  | [0.5 secs](<https://demo.questdb.io/?query=SELECT%20sum(fare_amount),%20avg(fare_amount)%20FROM%20trips;&executeQuery=true>)                                                                        |\n| `SELECT avg(double) FROM trips WHERE time in '2019'`                          | [0.02 secs](<https://demo.questdb.io/?query=SELECT%20avg(trip_distance)%20FROM%20trips%20WHERE%20pickup_datetime%20IN%20%272019%27;&executeQuery=true>)                                             |\n| `SELECT time, avg(double) FROM trips WHERE time in '2019-01-01' SAMPLE BY 1h` | [0.01 secs](<https://demo.questdb.io/?query=SELECT%20pickup_datetime,%20avg(trip_distance)%20FROM%20trips%20WHERE%20pickup_datetime%20IN%20%272019-01-01%27%20SAMPLE%20BY%201h;&executeQuery=true>) |\n| `SELECT * FROM trades LATEST ON time PARTITION BY symbol`                     | [0.00025 secs](https://demo.questdb.io/?query=SELECT%20*%20FROM%20trades%20LATEST%20ON%20timestamp%20PARTITION%20BY%20symbol;&executeQuery=true)                                                    |\n\nOur demo is running on `c5.metal` instance and using 24 cores out of 96.\n\n## Get started\n\n### Install QuestDB\n\nTo run QuestDB, Docker can be used to get started quickly:\n\n```bash\ndocker run -p 9000:9000 -p 9009:9009 -p 8812:8812 questdb/questdb\n```\n\nmacOS users can use Homebrew:\n\n```bash\nbrew install questdb\nbrew services start questdb\n\nquestdb start // To start questdb\nquestdb stop  // To stop questdb\n```\n\nThe [QuestDB downloads page](https://questdb.io/get-questdb/) provides direct\ndownloads for binaries and has details for other installation and deployment\nmethods.\n\n### Connect to QuestDB\n\nYou can interact with QuestDB using the following interfaces:\n\n- [Web Console](https://questdb.io/docs/develop/web-console/) for interactive\n  SQL editor on port `9000`\n- [InfluxDB line protocol](https://questdb.io/docs/reference/api/influxdb/) for\n  high-throughput ingestion on port `9009`\n- [REST API](https://questdb.io/docs/reference/api/rest/) on port `9000`\n- [PostgreSQL wire protocol](https://questdb.io/docs/reference/api/postgres/) on\n  port `8812`\n\n### Insert data\n\nBelow are our official InfluxDB line protocol clients for popular programming\nlanguages:\n\n- [.NET](https://github.com/questdb/net-questdb-client)\n- [C/C++](https://github.com/questdb/c-questdb-client)\n- [Go](https://pkg.go.dev/github.com/questdb/go-questdb-client)\n- [Java](https://questdb.io/docs/reference/clients/java_ilp/)\n- [NodeJS](https://questdb.github.io/nodejs-questdb-client)\n- [Python](https://py-questdb-client.readthedocs.io/en/latest/)\n- [Rust](https://docs.rs/crate/questdb-rs/latest)\n\n## How QuestDB compares to other open source TSDBs\n\n[This article](https://questdb.io/blog/2021/07/05/comparing-questdb-timescaledb-influxdb/)\ncompares QuestDB to other open source time series databases spanning\nfunctionality, maturity and performance.\n\nHere are high-cardinality\n[Time Series Benchmark Suite](https://questdb.io/blog/2021/06/16/high-cardinality-time-series-data-performance/)\nresults using the `cpu-only` use case with 6 workers on an AMD Ryzen 3970X:\n\n<div align=\"center\">\n  <a href=\"https://questdb.io/blog/2021/06/16/high-cardinality-time-series-data-performance/\">\n    <img alt=\"A chart comparing the maximum throughput of QuestDB, ClickHouse, TimescaleDB and InfluxDB.\" src=\".github/tsbs-results.png\"/>\n  </a>\n</div>\n\n## Resources\n\n### \ud83d\udcda Read the docs\n\n- [QuestDB documentation:](https://questdb.io/docs/introduction/) understand how\n  to run and configure QuestDB.\n- [Tutorials:](https://questdb.io/tutorial/) learn what's possible with QuestDB\n  step by step.\n- [Product roadmap:](https://github.com/questdb/questdb/projects) check out our\n  plan for upcoming releases.\n\n### \u2753 Get support\n\n- [Community Slack:](https://slack.questdb.io) join technical discussions, ask\n  questions, and meet other users!\n- [GitHub issues:](https://github.com/questdb/questdb/issues) report bugs or\n  issues with QuestDB.\n- [Stack Overflow:](https://stackoverflow.com/questions/tagged/questdb) look for\n  common troubleshooting solutions.\n\n### \ud83d\udea2 Deploy QuestDB\n\n- [AWS AMI](https://questdb.io/docs/guides/aws-official-ami)\n- [Google Cloud Platform](https://questdb.io/docs/guides/google-cloud-platform)\n- [Official Docker image](https://questdb.io/docs/get-started/docker)\n- [DigitalOcean droplets](https://questdb.io/docs/guides/digitalocean)\n- [Kubernetes Helm charts](https://questdb.io/docs/guides/kubernetes)\n\n## Contribute\n\nWe are always happy to have contributions to the project whether it is source\ncode, documentation, bug reports, feature requests or feedback. To get started\nwith contributing:\n\n- Have a look through GitHub issues labeled\n  \"[Good first issue](https://github.com/questdb/questdb/issues?q=is%3Aissue+is%3Aopen+label%3A%22Good+first+issue%22)\".\n- Read the\n  [contribution guide](https://github.com/questdb/questdb/blob/master/CONTRIBUTING.md).\n- For details on building QuestDB, see the\n  [build instructions](https://github.com/questdb/questdb/blob/master/core/README.md).\n- [Create a fork](https://docs.github.com/en/github/getting-started-with-github/fork-a-repo)\n  of QuestDB and submit a pull request with your proposed changes.\n\n\u2728 As a sign of our gratitude, we also send **QuestDB swag** to our\ncontributors. [Claim your swag here.](https://questdb.io/community)\n\nA big thanks goes to the following wonderful people who have contributed to\nQuestDB: ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/clickingbuttons\"><img src=\"https://avatars1.githubusercontent.com/u/43246297?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>clickingbuttons</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=clickingbuttons\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-clickingbuttons\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#userTesting-clickingbuttons\" title=\"User Testing\">\ud83d\udcd3</a></td>\n    <td align=\"center\"><a href=\"https://github.com/ideoma\"><img src=\"https://avatars0.githubusercontent.com/u/2159629?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ideoma</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=ideoma\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#userTesting-ideoma\" title=\"User Testing\">\ud83d\udcd3</a> <a href=\"https://github.com/questdb/questdb/commits?author=ideoma\" title=\"Tests\">\u26a0\ufe0f</a></td>\n    <td align=\"center\"><a href=\"https://github.com/tonytamwk\"><img src=\"https://avatars2.githubusercontent.com/u/20872271?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tonytamwk</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=tonytamwk\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#userTesting-tonytamwk\" title=\"User Testing\">\ud83d\udcd3</a></td>\n    <td align=\"center\"><a href=\"http://sirinath.com/\"><img src=\"https://avatars2.githubusercontent.com/u/637415?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>sirinath</b></sub></a><br /><a href=\"#ideas-sirinath\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/suhorukov\"><img src=\"https://avatars1.githubusercontent.com/u/10332206?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>igor-suhorukov</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=igor-suhorukov\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-igor-suhorukov\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/mick2004\"><img src=\"https://avatars1.githubusercontent.com/u/2042132?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mick2004</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mick2004\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#platform-mick2004\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n    <td align=\"center\"><a href=\"https://rawkode.com\"><img src=\"https://avatars3.githubusercontent.com/u/145816?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rawkode</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=rawkode\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#infra-rawkode\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://solidnerd.dev\"><img src=\"https://avatars0.githubusercontent.com/u/886383?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>solidnerd</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=solidnerd\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#infra-solidnerd\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n    <td align=\"center\"><a href=\"http://solanav.github.io\"><img src=\"https://avatars1.githubusercontent.com/u/32469597?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>solanav</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=solanav\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/questdb/questdb/commits?author=solanav\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    <td align=\"center\"><a href=\"https://shantanoo-desai.github.io\"><img src=\"https://avatars1.githubusercontent.com/u/12070966?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>shantanoo-desai</b></sub></a><br /><a href=\"#blog-shantanoo-desai\" title=\"Blogposts\">\ud83d\udcdd</a> <a href=\"#example-shantanoo-desai\" title=\"Examples\">\ud83d\udca1</a></td>\n    <td align=\"center\"><a href=\"http://alexprut.com\"><img src=\"https://avatars2.githubusercontent.com/u/1648497?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>alexprut</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=alexprut\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#maintenance-alexprut\" title=\"Maintenance\">\ud83d\udea7</a></td>\n    <td align=\"center\"><a href=\"https://github.com/lbowman\"><img src=\"https://avatars1.githubusercontent.com/u/1477427?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>lbowman</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=lbowman\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/questdb/questdb/commits?author=lbowman\" title=\"Tests\">\u26a0\ufe0f</a></td>\n    <td align=\"center\"><a href=\"https://tutswiki.com/\"><img src=\"https://avatars1.githubusercontent.com/u/424822?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>chankeypathak</b></sub></a><br /><a href=\"#blog-chankeypathak\" title=\"Blogposts\">\ud83d\udcdd</a></td>\n    <td align=\"center\"><a href=\"https://github.com/upsidedownsmile\"><img src=\"https://avatars0.githubusercontent.com/u/26444088?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>upsidedownsmile</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=upsidedownsmile\" title=\"Code\">\ud83d\udcbb</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/Nagriar\"><img src=\"https://avatars0.githubusercontent.com/u/2361099?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nagriar</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=Nagriar\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/piotrrzysko\"><img src=\"https://avatars.githubusercontent.com/u/6481553?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>piotrrzysko</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=piotrrzysko\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/questdb/questdb/commits?author=piotrrzysko\" title=\"Tests\">\u26a0\ufe0f</a></td>\n    <td align=\"center\"><a href=\"https://github.com/mpsq/dotfiles\"><img src=\"https://avatars.githubusercontent.com/u/5734722?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mpsq</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mpsq\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/siddheshlatkar\"><img src=\"https://avatars.githubusercontent.com/u/39632173?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>siddheshlatkar</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=siddheshlatkar\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"http://yitaekhwang.com\"><img src=\"https://avatars.githubusercontent.com/u/6628444?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yitaek</b></sub></a><br /><a href=\"#tutorial-Yitaek\" title=\"Tutorials\">\u2705</a> <a href=\"#example-Yitaek\" title=\"Examples\">\ud83d\udca1</a></td>\n    <td align=\"center\"><a href=\"https://www.gaboros.hu\"><img src=\"https://avatars.githubusercontent.com/u/19173947?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>gabor-boros</b></sub></a><br /><a href=\"#tutorial-gabor-boros\" title=\"Tutorials\">\u2705</a> <a href=\"#example-gabor-boros\" title=\"Examples\">\ud83d\udca1</a></td>\n    <td align=\"center\"><a href=\"https://github.com/kovid-r\"><img src=\"https://avatars.githubusercontent.com/u/62409489?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kovid-r</b></sub></a><br /><a href=\"#tutorial-kovid-r\" title=\"Tutorials\">\u2705</a> <a href=\"#example-kovid-r\" title=\"Examples\">\ud83d\udca1</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://borowski-software.de/\"><img src=\"https://avatars.githubusercontent.com/u/8701341?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TimBo93</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ATimBo93\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"#userTesting-TimBo93\" title=\"User Testing\">\ud83d\udcd3</a></td>\n    <td align=\"center\"><a href=\"http://zikani.me\"><img src=\"https://avatars.githubusercontent.com/u/1501387?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>zikani03</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=zikani03\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/jaugsburger\"><img src=\"https://avatars.githubusercontent.com/u/10787042?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>jaugsburger</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=jaugsburger\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#maintenance-jaugsburger\" title=\"Maintenance\">\ud83d\udea7</a></td>\n    <td align=\"center\"><a href=\"http://www.questdb.io\"><img src=\"https://avatars.githubusercontent.com/u/52114895?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TheTanc</b></sub></a><br /><a href=\"#projectManagement-TheTanc\" title=\"Project Management\">\ud83d\udcc6</a> <a href=\"#content-TheTanc\" title=\"Content\">\ud83d\udd8b</a> <a href=\"#ideas-TheTanc\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"http://davidgs.com\"><img src=\"https://avatars.githubusercontent.com/u/2071898?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>davidgs</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Adavidgs\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"#content-davidgs\" title=\"Content\">\ud83d\udd8b</a></td>\n    <td align=\"center\"><a href=\"https://redalemeden.com\"><img src=\"https://avatars.githubusercontent.com/u/519433?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kaishin</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=kaishin\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#example-kaishin\" title=\"Examples\">\ud83d\udca1</a></td>\n    <td align=\"center\"><a href=\"https://questdb.io\"><img src=\"https://avatars.githubusercontent.com/u/7276403?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bluestreak01</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bluestreak01\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#maintenance-bluestreak01\" title=\"Maintenance\">\ud83d\udea7</a> <a href=\"https://github.com/questdb/questdb/commits?author=bluestreak01\" title=\"Tests\">\u26a0\ufe0f</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://patrick.spacesurfer.com/\"><img src=\"https://avatars.githubusercontent.com/u/29952889?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>patrickSpaceSurfer</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=patrickSpaceSurfer\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#maintenance-patrickSpaceSurfer\" title=\"Maintenance\">\ud83d\udea7</a> <a href=\"https://github.com/questdb/questdb/commits?author=patrickSpaceSurfer\" title=\"Tests\">\u26a0\ufe0f</a></td>\n    <td align=\"center\"><a href=\"http://chenrui.dev\"><img src=\"https://avatars.githubusercontent.com/u/1580956?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>chenrui333</b></sub></a><br /><a href=\"#infra-chenrui333\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n    <td align=\"center\"><a href=\"http://bsmth.de\"><img src=\"https://avatars.githubusercontent.com/u/43580235?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bsmth</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bsmth\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#content-bsmth\" title=\"Content\">\ud83d\udd8b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/Ugbot\"><img src=\"https://avatars.githubusercontent.com/u/2143631?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Ugbot</b></sub></a><br /><a href=\"#question-Ugbot\" title=\"Answering Questions\">\ud83d\udcac</a> <a href=\"#userTesting-Ugbot\" title=\"User Testing\">\ud83d\udcd3</a> <a href=\"#talk-Ugbot\" title=\"Talks\">\ud83d\udce2</a></td>\n    <td align=\"center\"><a href=\"https://github.com/lepolac\"><img src=\"https://avatars.githubusercontent.com/u/6312424?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>lepolac</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=lepolac\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#tool-lepolac\" title=\"Tools\">\ud83d\udd27</a></td>\n    <td align=\"center\"><a href=\"https://github.com/tiagostutz\"><img src=\"https://avatars.githubusercontent.com/u/3986989?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tiagostutz</b></sub></a><br /><a href=\"#userTesting-tiagostutz\" title=\"User Testing\">\ud83d\udcd3</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Atiagostutz\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"#projectManagement-tiagostutz\" title=\"Project Management\">\ud83d\udcc6</a></td>\n    <td align=\"center\"><a href=\"https://github.com/Lyncee59\"><img src=\"https://avatars.githubusercontent.com/u/13176504?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Lyncee59</b></sub></a><br /><a href=\"#ideas-Lyncee59\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"https://github.com/questdb/questdb/commits?author=Lyncee59\" title=\"Code\">\ud83d\udcbb</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/rrjanbiah\"><img src=\"https://avatars.githubusercontent.com/u/4907427?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rrjanbiah</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Arrjanbiah\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/sarunas-stasaitis\"><img src=\"https://avatars.githubusercontent.com/u/57004257?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>sarunas-stasaitis</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Asarunas-stasaitis\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/RiccardoGiro\"><img src=\"https://avatars.githubusercontent.com/u/60734967?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>RiccardoGiro</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ARiccardoGiro\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/duggar\"><img src=\"https://avatars.githubusercontent.com/u/37486846?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>duggar</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aduggar\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/postol\"><img src=\"https://avatars.githubusercontent.com/u/7983951?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>postol</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Apostol\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/petrjahoda\"><img src=\"https://avatars.githubusercontent.com/u/45359845?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>petrjahoda</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Apetrjahoda\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://www.turecki.net\"><img src=\"https://avatars.githubusercontent.com/u/1933165?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>t00</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3At00\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/snenkov\"><img src=\"https://avatars.githubusercontent.com/u/13110986?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>snenkov</b></sub></a><br /><a href=\"#userTesting-snenkov\" title=\"User Testing\">\ud83d\udcd3</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Asnenkov\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"#ideas-snenkov\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/marregui\"><img src=\"https://avatars.githubusercontent.com/u/255796?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>marregui</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=marregui\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-marregui\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#design-marregui\" title=\"Design\">\ud83c\udfa8</a></td>\n    <td align=\"center\"><a href=\"https://github.com/bratseth\"><img src=\"https://avatars.githubusercontent.com/u/16574012?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bratseth</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bratseth\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-bratseth\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#userTesting-bratseth\" title=\"User Testing\">\ud83d\udcd3</a></td>\n    <td align=\"center\"><a href=\"https://medium.com/@wellytambunan/\"><img src=\"https://avatars.githubusercontent.com/u/242694?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>welly87</b></sub></a><br /><a href=\"#ideas-welly87\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"http://johnleung.com\"><img src=\"https://avatars.githubusercontent.com/u/20699?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>fuzzthink</b></sub></a><br /><a href=\"#ideas-fuzzthink\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#userTesting-fuzzthink\" title=\"User Testing\">\ud83d\udcd3</a></td>\n    <td align=\"center\"><a href=\"https://github.com/nexthack\"><img src=\"https://avatars.githubusercontent.com/u/6803956?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>nexthack</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=nexthack\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/g-metan\"><img src=\"https://avatars.githubusercontent.com/u/88013490?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>g-metan</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ag-metan\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/tim2skew\"><img src=\"https://avatars.githubusercontent.com/u/54268285?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tim2skew</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Atim2skew\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"#userTesting-tim2skew\" title=\"User Testing\">\ud83d\udcd3</a></td>\n    <td align=\"center\"><a href=\"https://github.com/ospqsp\"><img src=\"https://avatars.githubusercontent.com/u/84992434?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ospqsp</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aospqsp\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/SuperFluffy\"><img src=\"https://avatars.githubusercontent.com/u/701177?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>SuperFluffy</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ASuperFluffy\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/nu11ptr\"><img src=\"https://avatars.githubusercontent.com/u/3615587?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>nu11ptr</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Anu11ptr\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/comunidadio\"><img src=\"https://avatars.githubusercontent.com/u/10286013?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>comunidadio</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Acomunidadio\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/mugendi\"><img src=\"https://avatars.githubusercontent.com/u/5348246?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mugendi</b></sub></a><br /><a href=\"#ideas-mugendi\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Amugendi\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"https://github.com/questdb/questdb/commits?author=mugendi\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    <td align=\"center\"><a href=\"https://github.com/paulwoods222\"><img src=\"https://avatars.githubusercontent.com/u/86227717?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>paulwoods222</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Apaulwoods222\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/mingodad\"><img src=\"https://avatars.githubusercontent.com/u/462618?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mingodad</b></sub></a><br /><a href=\"#ideas-mingodad\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Amingodad\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"https://github.com/questdb/questdb/commits?author=mingodad\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    <td align=\"center\"><a href=\"https://github.com/houarizegai\"><img src=\"https://avatars.githubusercontent.com/houarizegai?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>houarizegai</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=houarizegai\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    <td align=\"center\"><a href=\"http://scrapfly.io\"><img src=\"https://avatars.githubusercontent.com/u/1763341?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>jjsaunier</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ajjsaunier\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/zanek\"><img src=\"https://avatars.githubusercontent.com/u/333102?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>zanek</b></sub></a><br /><a href=\"#ideas-zanek\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#projectManagement-zanek\" title=\"Project Management\">\ud83d\udcc6</a></td>\n    <td align=\"center\"><a href=\"https://github.com/Geekaylee\"><img src=\"https://avatars.githubusercontent.com/u/12583377?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Geekaylee</b></sub></a><br /><a href=\"#userTesting-Geekaylee\" title=\"User Testing\">\ud83d\udcd3</a> <a href=\"#ideas-Geekaylee\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/lg31415\"><img src=\"https://avatars.githubusercontent.com/u/3609384?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>lg31415</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Alg31415\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"#projectManagement-lg31415\" title=\"Project Management\">\ud83d\udcc6</a></td>\n    <td align=\"center\"><a href=\"http://nulldev.xyz/\"><img src=\"https://avatars.githubusercontent.com/u/9571936?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>null-dev</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Anull-dev\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"#projectManagement-null-dev\" title=\"Project Management\">\ud83d\udcc6</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://ultd.io\"><img src=\"https://avatars.githubusercontent.com/u/12675427?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ultd</b></sub></a><br /><a href=\"#ideas-ultd\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#projectManagement-ultd\" title=\"Project Management\">\ud83d\udcc6</a></td>\n    <td align=\"center\"><a href=\"https://github.com/ericsun2\"><img src=\"https://avatars.githubusercontent.com/u/8866410?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>ericsun2</b></sub></a><br /><a href=\"#ideas-ericsun2\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Aericsun2\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"#projectManagement-ericsun2\" title=\"Project Management\">\ud83d\udcc6</a></td>\n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/giovanni-k-bonetti-2809345/\"><img src=\"https://avatars.githubusercontent.com/u/3451581?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>giovannibonetti</b></sub></a><br /><a href=\"#userTesting-giovannibonetti\" title=\"User Testing\">\ud83d\udcd3</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Agiovannibonetti\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"#projectManagement-giovannibonetti\" title=\"Project Management\">\ud83d\udcc6</a></td>\n    <td align=\"center\"><a href=\"https://wavded.com\"><img src=\"https://avatars.githubusercontent.com/u/26638?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>wavded</b></sub></a><br /><a href=\"#userTesting-wavded\" title=\"User Testing\">\ud83d\udcd3</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Awavded\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://medium.com/@apechkurov\"><img src=\"https://avatars.githubusercontent.com/u/37772591?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>puzpuzpuz</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=puzpuzpuz\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"https://github.com/questdb/questdb/commits?author=puzpuzpuz\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#userTesting-puzpuzpuz\" title=\"User Testing\">\ud83d\udcd3</a></td>\n    <td align=\"center\"><a href=\"https://github.com/rstreics\"><img src=\"https://avatars.githubusercontent.com/u/50323347?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rstreics</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=rstreics\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#infra-rstreics\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a> <a href=\"https://github.com/questdb/questdb/commits?author=rstreics\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    <td align=\"center\"><a href=\"https://github.com/mariusgheorghies\"><img src=\"https://avatars.githubusercontent.com/u/84250061?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mariusgheorghies</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mariusgheorghies\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#infra-mariusgheorghies\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a> <a href=\"https://github.com/questdb/questdb/commits?author=mariusgheorghies\" title=\"Documentation\">\ud83d\udcd6</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/pswu11\"><img src=\"https://avatars.githubusercontent.com/u/48913707?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>pswu11</b></sub></a><br /><a href=\"#content-pswu11\" title=\"Content\">\ud83d\udd8b</a> <a href=\"#ideas-pswu11\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#design-pswu11\" title=\"Design\">\ud83c\udfa8</a></td>\n    <td align=\"center\"><a href=\"https://github.com/insmac\"><img src=\"https://avatars.githubusercontent.com/u/1871646?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>insmac</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=insmac\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-insmac\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#design-insmac\" title=\"Design\">\ud83c\udfa8</a></td>\n    <td align=\"center\"><a href=\"https://github.com/eugenels\"><img src=\"https://avatars.githubusercontent.com/u/79919431?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>eugenels</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=eugenels\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-eugenels\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#maintenance-eugenels\" title=\"Maintenance\">\ud83d\udea7</a></td>\n    <td align=\"center\"><a href=\"https://github.com/bziobrowski\"><img src=\"https://avatars.githubusercontent.com/u/26925920?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>bziobrowski</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=bziobrowski\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#projectManagement-bziobrowski\" title=\"Project Management\">\ud83d\udcc6</a></td>\n    <td align=\"center\"><a href=\"https://github.com/Zapfmeister\"><img src=\"https://avatars.githubusercontent.com/u/20150586?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Zapfmeister</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=Zapfmeister\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#userTesting-Zapfmeister\" title=\"User Testing\">\ud83d\udcd3</a></td>\n    <td align=\"center\"><a href=\"https://github.com/mkaruza\"><img src=\"https://avatars.githubusercontent.com/u/3676457?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>mkaruza</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=mkaruza\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/DylanDKnight\"><img src=\"https://avatars.githubusercontent.com/u/17187287?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>DylanDKnight</b></sub></a><br /><a href=\"#userTesting-DylanDKnight\" title=\"User Testing\">\ud83d\udcd3</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3ADylanDKnight\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/enolal826\"><img src=\"https://avatars.githubusercontent.com/u/51820585?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>enolal826</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=enolal826\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/glasstiger\"><img src=\"https://avatars.githubusercontent.com/u/94906625?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>glasstiger</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=glasstiger\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://arijus.net\"><img src=\"https://avatars.githubusercontent.com/u/4284659?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>argshook</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=argshook\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-argshook\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#design-argshook\" title=\"Design\">\ud83c\udfa8</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Aargshook\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/amunra\"><img src=\"https://avatars.githubusercontent.com/u/1499096?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>amunra</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=amunra\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/questdb/questdb/commits?author=amunra\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Aamunra\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://lamottsjourney.wordpress.com/\"><img src=\"https://avatars.githubusercontent.com/u/66742430?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>GothamsJoker</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=GothamsJoker\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/kocko\"><img src=\"https://avatars.githubusercontent.com/u/862000?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>kocko</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=kocko\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/jerrinot\"><img src=\"https://avatars.githubusercontent.com/u/158619?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>jerrinot</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=jerrinot\" title=\"Code\">\ud83d\udcbb</a> <a href=\"#ideas-jerrinot\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Ajerrinot\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://ramiroberrelleza.com\"><img src=\"https://avatars.githubusercontent.com/u/475313?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>rberrelleza</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=rberrelleza\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/Cobalt-27\"><img src=\"https://avatars.githubusercontent.com/u/34511059?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Cobalt-27</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=Cobalt-27\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/eschultz\"><img src=\"https://avatars.githubusercontent.com/u/390064?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>eschultz</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=eschultz\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/xinyi-qiao/\"><img src=\"https://avatars.githubusercontent.com/u/47307374?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>XinyiQiao</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=XinyiQiao\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"http://chenquan.me\"><img src=\"https://avatars.githubusercontent.com/u/20042193?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>terasum</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=terasum\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/hristovdeveloper\"><img src=\"https://avatars.githubusercontent.com/u/3893599?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>PlamenHristov</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=PlamenHristov\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/tris0laris\"><img src=\"https://avatars.githubusercontent.com/u/57298792?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>tris0laris</b></sub></a><br /><a href=\"#blog-tris0laris\" title=\"Blogposts\">\ud83d\udcdd</a> <a href=\"#ideas-tris0laris\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/HeZean\"><img src=\"https://avatars.githubusercontent.com/u/49837965?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>HeZean</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=HeZean\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3AHeZean\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/iridess\"><img src=\"https://avatars.githubusercontent.com/u/104518201?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>iridess</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/commits?author=iridess\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/questdb/questdb/commits?author=iridess\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/selmanfaruky%C4%B1lmaz/\"><img src=\"https://avatars.githubusercontent.com/u/96119894?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>selmanfarukyilmaz</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aselmanfarukyilmaz\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"http://www.donet5.com\"><img src=\"https://avatars.githubusercontent.com/u/12455385?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>donet5</b></sub></a><br /><a href=\"#ideas-donet5\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"https://github.com/questdb/questdb/issues?q=author%3Adonet5\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/Zahlii\"><img src=\"https://avatars.githubusercontent.com/u/218582?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Zahlii</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3AZahlii\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/salsasepp\"><img src=\"https://avatars.githubusercontent.com/u/4884807?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>salsasepp</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Asalsasepp\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/EmmettM\"><img src=\"https://avatars.githubusercontent.com/u/4196372?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>EmmettM</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3AEmmettM\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"https://github.com/questdb/questdb/commits?author=EmmettM\" title=\"Tests\">\u26a0\ufe0f</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://allfactors.com\"><img src=\"https://avatars.githubusercontent.com/u/571328?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>robd003</b></sub></a><br /><a href=\"#ideas-robd003\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/AllenEdison\"><img src=\"https://avatars.githubusercontent.com/u/46532217?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>AllenEdison</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3AAllenEdison\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/CSharpDummy\"><img src=\"https://avatars.githubusercontent.com/u/7610502?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>CSharpDummy</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ACSharpDummy\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/shimondoodkin\"><img src=\"https://avatars.githubusercontent.com/u/314464?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>shimondoodkin</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ashimondoodkin\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"#ideas-shimondoodkin\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://www.zsmart.tech/\"><img src=\"https://avatars.githubusercontent.com/u/40519768?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>huuhait</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Ahuuhait\" title=\"Bug reports\">\ud83d\udc1b</a> <a href=\"#ideas-huuhait\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://clickhouse.com/\"><img src=\"https://avatars.githubusercontent.com/u/18581488?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>alexey-milovidov</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Aalexey-milovidov\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"http://blog.suconghou.cn\"><img src=\"https://avatars.githubusercontent.com/u/4580719?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>suconghou</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3Asuconghou\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n  </tr>\n   <tr>\n    <td align=\"center\"><a href=\"https://github.com/TheZal\"><img src=\"https://avatars.githubusercontent.com/TheZal?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>TheZal</b></sub></a><br /><a href=\"https://github.com/questdb/questdb/issues?q=author%3ATheZal\" title=\"Documentation\">\ud83d\udcd6</a></td>\n  </tr>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project adheres to the\n[all-contributors](https://github.com/all-contributors/all-contributors)\nspecification. Contributions of any kind are welcome!\n",
	"big-data cpp database distributed distributed-systems graph graph-database graphdb nebula nebula-graph nebulagraph raft scalability": "<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/1651790/191656620-3e24764f-26d2-4b9b-b408-94b9eca5cc3e.png\"/>\n  <br> English | <a href=\"README-CN.md\">\u4e2d\u6587</a>\n  <br>A distributed, scalable, lightning-fast graph database<br>\n</p>\n<p align=\"center\">\n  <a href=\"https://app.codecov.io/gh/vesoft-inc/nebula\">\n    <img src=\"https://codecov.io/github/vesoft-inc/nebula/coverage.svg?branch=master\" alt=\"code coverage\"/>\n  </a>\n  <a href=\"https://github.com/vesoft-inc/nebula/actions?workflow=nightly\">\n    <img src=\"https://github.com/vesoft-inc/nebula/workflows/nightly/badge.svg\" alt=\"nightly build\"/>\n  </a>\n  <a href=\"https://github.com/vesoft-inc/nebula/stargazers\">\n    <img src=\"http://githubbadges.com/star.svg?user=vesoft-inc&repo=nebula&style=default\" alt=\"nebula star\"/>\n  </a>\n  <a href=\"https://github.com/vesoft-inc/nebula/network/members\">\n    <img src=\"http://githubbadges.com/fork.svg?user=vesoft-inc&repo=nebula&style=default\" alt=\"nebula fork\"/>\n  </a>\n  <br>\n</p>\n\n\n# What is NebulaGraph?\n\n**NebulaGraph** is an open-source graph database capable of hosting super large-scale graphs with dozens of billions of vertices (nodes) and trillions of edges, with milliseconds of latency.\n\n\nTrusted and contributed by users, the [NebulaGraph community](https://github.com/vesoft-inc/nebula-community/) comes with a rich [open-source ecosystem](https://docs.nebula-graph.io/master/20.appendix/6.eco-tool-version/). And it has been widely used for social media, recommendation systems, knowledge graphs, security, capital flows, AI, etc, see [our users](https://nebula-graph.io/cases).\n\n\nCompared with other graph database solutions, **NebulaGraph** has the following advantages:\n\n* Symmetrically distributed\n* Storage and computing separation\n* Horizontal scalability\n* Strong data consistency by RAFT protocol\n* OpenCypher-compatible query language\n* Role-based access control for higher-level security\n\n<!--\n## Notice of Release\n\nNebulaGraph used to be split into three repositories: [Nebula-Graph](https://github.com/vesoft-inc/nebula-graph), [Nebula-Storage,](https://github.com/vesoft-inc/nebula-storage) and [Nebula-Common](https://github.com/vesoft-inc/nebula-common) for versions between v2.0.0 and v2.5.x, which will be archived.\n\nThe one and only codebase of NebulaGraph is now [github.com/vesoft-inc/nebula](https://github.com/vesoft-inc/nebula), as it's back to mono-repo since v2.6.0.\n\nPlease check the latest release via the documentation: https://docs.nebula-graph.io/.\n\n\nNebulaGraph 1.x is not actively maintained. Please move to NebulaGraph 2.x.  <br/>\nThe data format, rpc protocols, clients, etc. are not compatible between NebulaGraph v1.x and v2.x,  but we do offer [upgrade guide](https://docs.nebula-graph.io/2.5.0/4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-250/).\n\nTo use the stable release, see [NebulaGraph 1.0](https://github.com/vesoft-inc/nebula).\n\n\n## Roadmap\n\nSee our [Roadmap](https://github.com/vesoft-inc/nebula/wiki/Nebula-Graph-Roadmap-2020) for what's coming soon in **NebulaGraph**.\n-->\n\n## Quick start\n\nRead the [Getting started](https://docs.nebula-graph.io/3.2.0/2.quick-start/1.quick-start-workflow/) article for a quick start.\n\n<!--\nPlease note that you need to install **NebulaGraph**, either by [installing source code](https://docs.nebula-graph.io/manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/) or by [docker compose](https://docs.nebula-graph.io/manual-EN/3.build-develop-and-administration/1.build/2.build-by-docker/), before you can actually start using it. If you prefer a video tutorial, visit our [YouTube channel](https://www.youtube.com/channel/UC73V8q795eSEMxDX4Pvdwmw/videos).\n-->\n\n## Getting help\nIn case you encounter any problems playing around **NebulaGraph**, please reach out for help:\n* [FAQ](https://docs.nebula-graph.io/2.0/2.quick-start/0.FAQ/)\n* [Discussions](https://github.com/vesoft-inc/nebula/discussions)\n\n## Documentation\n\n* [English](https://docs.nebula-graph.io/)\n\n## Architecture\n![NebulaGraph Architecture](https://docs-cdn.nebula-graph.com.cn/figures/nebula-graph-architecture_3.png)\n\n## Contributing\n\nContributions are warmly welcomed and greatly appreciated. And here are a few ways you can contribute:\n\n* Start by some [issues](https://github.com/vesoft-inc/nebula/issues)\n* Submit Pull Requests to us. See [how-to-contribute](https://docs.nebula-graph.io/master/15.contribution/how-to-contribute/).\n\n## Landscape\n\n<p align=\"left\">\n<img src=\"https://landscape.cncf.io/images/left-logo.svg\" width=\"150\">&nbsp;&nbsp;<img src=\"https://landscape.cncf.io/images/right-logo.svg\" width=\"200\" />\n<br />\n\n[NebulaGraph](https://landscape.cncf.io/?selected=nebula-graph) enriches the <a href=\"https://landscape.cncf.io/card-mode?category=database&grouping=category\">\nCNCF Database Landscape.</a>\n</p>\n\n## Licensing\n\n**NebulaGraph** is under [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0) license, so you can freely download, modify, and deploy the source code to meet your needs.  <br/>\nYou can also freely deploy **NebulaGraph** as a back-end service to support your SaaS deployment.\n\n## Contact\n\n* [Slack Channel](https://join.slack.com/t/nebulagraph/shared_invite/zt-7ybejuqa-NCZBroh~PCh66d9kOQj45g)\n* [Stack Overflow](https://stackoverflow.com/questions/tagged/nebulagraph)\n* Twitter: [@NebulaGraph](https://twitter.com/NebulaGraph)\n* [LinkedIn Page](https://www.linkedin.com/company/vesoft-nebula-graph)\n* Email: info@vesoft.com\n\n## Community\n\n[![Discussions](https://img.shields.io/badge/GitHub_Discussion-000000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/vesoft-inc/nebula/discussions) [![Slack](https://img.shields.io/badge/Slack-9F2B68?style=for-the-badge&logo=slack&logoColor=white)](https://join.slack.com/t/nebulagraph/shared_invite/zt-7ybejuqa-NCZBroh~PCh66d9kOQj45g) [![Zoom](https://img.shields.io/badge/Zoom-2D8CFF?style=for-the-badge&logo=zoom&logoColor=white)](https://us02web.zoom.us/meeting/register/tZ0rcuypqDMvGdLuIm4VprTlx96wrEf062SH) [![Google Calendar](https://img.shields.io/badge/Calander-4285F4?style=for-the-badge&logo=google&logoColor=white)](https://calendar.google.com/calendar/u/0?cid=Z29mbGttamM3ZTVlZ2hpazI2cmNlNXVnZThAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ) [![Meetup](https://img.shields.io/badge/Meetup-FF0000?style=for-the-badge&logo=meetup&logoColor=white)](https://www.meetup.com/nebulagraph/events/287180186?utm_medium=referral&utm_campaign=share-btn_savedevents_share_modal&utm_source=link) [![Meeting Archive](https://img.shields.io/badge/Community_wiki-808080?style=for-the-badge&logo=readthedocs&logoColor=white)](https://github.com/vesoft-inc/nebula-community/wiki) [![Discourse](https://img.shields.io/badge/\u4e2d\u6587\u8bba\u575b-4285F4?style=for-the-badge&logo=discourse&logoColor=white)](https://discuss.nebula-graph.com.cn/) [![Tencent_Meeting](https://img.shields.io/badge/\u817e\u8baf\u4f1a\u8bae-2D8CFF?style=for-the-badge&logo=googlemeet&logoColor=white)](https://meeting.tencent.com/dm/F8NX1aRZ8PQv)\n\n<br />\n\n#### If you find NebulaGraph interesting, please \u2b50\ufe0f Star it on GitHub at the top of the page.\nhttps://github.com/vesoft-inc/nebula\n",
	"big-data catboost categorical-features coreml cuda data-mining data-science decision-trees gbdt gbm gpu gpu-computing gradient-boosting kaggle machine-learning python r tutorial": "<img src=http://storage.mds.yandex.net/get-devtools-opensource/250854/catboost-logo.png width=300/>\n\n[Website](https://catboost.ai) |\n[Documentation](https://catboost.ai/docs/) |\n[Tutorials](https://catboost.ai/docs/concepts/tutorials.html) |\n[Installation](https://catboost.ai/docs/concepts/installation.html) |\n[Release Notes](https://github.com/catboost/catboost/releases)\n\n[![GitHub license](https://img.shields.io/github/license/catboost/catboost.svg)](https://github.com/catboost/catboost/blob/master/LICENSE)\n[![PyPI version](https://badge.fury.io/py/catboost.svg)](https://badge.fury.io/py/catboost)\n[![Conda Version](https://img.shields.io/conda/vn/conda-forge/catboost.svg)](https://anaconda.org/conda-forge/catboost)\n[![GitHub issues](https://img.shields.io/github/issues/catboost/catboost.svg)](https://github.com/catboost/catboost/issues)\n[![Telegram](https://img.shields.io/badge/chat-on%20Telegram-2ba2d9.svg)](https://t.me/catboost_en)\n[![Twitter](https://img.shields.io/badge/@CatBoostML--_.svg?style=social&logo=twitter)](https://twitter.com/CatBoostML)\n\nCatBoost is a machine learning method based on [gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting) over decision trees.\n\nMain advantages of CatBoost:\n--------------\n  - Superior quality when [compared](https://github.com/catboost/benchmarks/blob/master/README.md) with other GBDT libraries on many datasets.\n  - Best in class [prediction](https://catboost.ai/docs/concepts/c-plus-plus-api.html) speed.\n  - Support for both [numerical and categorical](https://catboost.ai/docs/concepts/algorithm-main-stages.html) features.\n  - Fast GPU and multi-GPU support for training out of the box.\n  - Visualization tools [included](https://catboost.ai/docs/features/visualization.html).\n  - Fast and reproducible distributed training with [Apache Spark](https://catboost.ai/en/docs/concepts/spark-overview) and [CLI](https://catboost.ai/en/docs/concepts/cli-distributed-learning).\n\nGet Started and Documentation\n--------------\nAll CatBoost documentation is available [here](https://catboost.ai/docs/).\n\nInstall CatBoost by following the guide for the\n * [Python package](https://catboost.ai/en/docs/concepts/python-installation)\n * [R-package](https://catboost.ai/en/docs/concepts/r-installation)\n * [\u0421ommand line](https://catboost.ai/en/docs/concepts/cli-installation)\n * [Package for Apache Spark](https://catboost.ai/en/docs/concepts/spark-installation)\n\nNext you may want to investigate:\n* [Tutorials](https://github.com/catboost/tutorials/#readme)\n* [Training modes and metrics](https://catboost.ai/docs/concepts/loss-functions.html)\n* [Cross-validation](https://catboost.ai/docs/features/cross-validation.html#cross-validation)\n* [Parameters tuning](https://catboost.ai/docs/concepts/parameter-tuning.html)\n* [Feature importance calculation](https://catboost.ai/docs/features/feature-importances-calculation.html)\n* [Regular](https://catboost.ai/docs/features/prediction.html#prediction) and [staged](https://catboost.ai/docs/features/staged-prediction.html#staged-prediction) predictions\n* CatBoost for Apache Spark videos: [Introduction](https://youtu.be/47-mAVms-b8) and [Architecture](https://youtu.be/nrGt5VKZpzc)\n\nIf you cannot open documentation in your browser try adding yastatic.net and yastat.net to the list of allowed domains in your privacy badger. \n\nCatboost models in production\n--------------\nIf you want to evaluate Catboost model in your application read [model api documentation](https://github.com/catboost/catboost/tree/master/catboost/CatboostModelAPI.md).\n\nQuestions and bug reports\n--------------\n* For reporting bugs please use the [catboost/bugreport](https://github.com/catboost/catboost/issues) page.\n* Ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/catboost) with the catboost tag, we monitor this for new questions.\n* Seek prompt advice at [Telegram group](https://t.me/catboost_en) or Russian-speaking [Telegram chat](https://t.me/catboost_ru)\n\nHelp to Make CatBoost Better\n----------------------------\n* Check out [open problems](https://github.com/catboost/catboost/blob/master/open_problems/open_problems.md) and [help wanted issues](https://github.com/catboost/catboost/labels/help%20wanted) to see what can be improved, or open an issue if you want something.\n* Add your stories and experience to [Awesome CatBoost](AWESOME.md).\n* To contribute to CatBoost you need to first read CLA text and add to your pull request, that you agree to the terms of the CLA. More information can be found\nin [CONTRIBUTING.md](https://github.com/catboost/catboost/blob/master/CONTRIBUTING.md)\n* Instructions for contributors can be found [here](https://catboost.ai/docs/concepts/development-and-contributions.html).\n\nNews\n--------------\nLatest news are published on [twitter](https://twitter.com/catboostml).\n\nReference Paper\n-------\nAnna Veronika Dorogush, Andrey Gulin, Gleb Gusev, Nikita Kazeev, Liudmila Ostroumova Prokhorenkova, Aleksandr Vorobev [\"Fighting biases with dynamic boosting\"](https://arxiv.org/abs/1706.09516). arXiv:1706.09516, 2017.\n\nAnna Veronika Dorogush, Vasily Ershov, Andrey Gulin [\"CatBoost: gradient boosting with categorical features support\"](http://learningsys.org/nips17/assets/papers/paper_11.pdf). Workshop on ML Systems\nat NIPS 2017.\n\nLicense\n-------\n\u00a9 YANDEX LLC, 2017-2022. Licensed under the Apache License, Version 2.0. See LICENSE file for more details.\n",
	"analytics big-data data-science database databases datalake distributed-database distributed-databases distributed-systems hadoop hive java jdbc presto prestodb query-engine sql trino": "<p align=\"center\">\n    <a href=\"https://trino.io/\"><img alt=\"Trino Logo\" src=\".github/homepage.png\" /></a>\n</p>\n<p align=\"center\">\n    <b>Trino is a fast distributed SQL query engine for big data analytics.</b>\n</p>\n<p align=\"center\">\n    See the <a href=\"https://trino.io/docs/current/\">User Manual</a> for deployment instructions and end user documentation.\n</p>\n<p align=\"center\">\n   <a href=\"https://trino.io/download.html\">\n       <img src=\"https://img.shields.io/maven-central/v/io.trino/trino-server.svg?label=Trino\" alt=\"Trino download\" />\n   </a>\n   <a href=\"https://trino.io/slack.html\">\n       <img src=\"https://img.shields.io/static/v1?logo=slack&logoColor=959DA5&label=Slack&labelColor=333a41&message=join%20conversation&color=3AC358\" alt=\"Trino Slack\" />\n   </a>\n   <a href=\"https://trino.io/trino-the-definitive-guide.html\">\n       <img src=\"https://img.shields.io/badge/Trino%3A%20The%20Definitive%20Guide-download-brightgreen\" alt=\"Trino: The Definitive Guide book download\" />\n   </a>\n</p>\n\n## Development\n\nSee [DEVELOPMENT](.github/DEVELOPMENT.md) for information about code style,\ndevelopment process, and guidelines.\n\nSee [CONTRIBUTING](.github/CONTRIBUTING.md) for contribution requirements.\n\n## Security\n\nSee the project [security policy](.github/SECURITY.md) for\ninformation about reporting vulnerabilities.\n\n## Build requirements\n\n* Mac OS X or Linux\n* Java 17.0.4+, 64-bit\n* Docker\n\n## Building Trino\n\nTrino is a standard Maven project. Simply run the following command from the\nproject root directory:\n\n    ./mvnw clean install -DskipTests\n\nOn the first build, Maven downloads all the dependencies from the internet\nand caches them in the local repository (`~/.m2/repository`), which can take a\nwhile, depending on your connection speed. Subsequent builds are faster.\n\nTrino has a comprehensive set of tests that take a considerable amount of time\nto run, and are thus disabled by the above command. These tests are run by the\nCI system when you submit a pull request. We recommend only running tests\nlocally for the areas of code that you change.\n\n## Running Trino in your IDE\n\n### Overview\n\nAfter building Trino for the first time, you can load the project into your IDE\nand run the server.  We recommend using\n[IntelliJ IDEA](http://www.jetbrains.com/idea/). Because Trino is a standard\nMaven project, you easily can import it into your IDE.  In IntelliJ, choose\n*Open Project* from the *Quick Start* box or choose *Open*\nfrom the *File* menu and select the root `pom.xml` file.\n\nAfter opening the project in IntelliJ, double check that the Java SDK is\nproperly configured for the project:\n\n* Open the File menu and select Project Structure\n* In the SDKs section, ensure that JDK 17 is selected (create one if none exist)\n* In the Project section, ensure the Project language level is set to 17\n\n### Running a testing server\n\nThe simplest way to run Trino for development is to run the `TpchQueryRunner`\nclass. It will start a development version of the server that is configured with\nthe TPCH connector. You can then use the CLI to execute queries against this\nserver. Many other connectors have their own `*QueryRunner` class that you can\nuse when working on a specific connector.\n\n### Running the full server\n\nTrino comes with sample configuration that should work out-of-the-box for\ndevelopment. Use the following options to create a run configuration:\n\n* Main Class: `io.trino.server.DevelopmentServer`\n* VM Options: `-ea -Dconfig=etc/config.properties -Dlog.levels-file=etc/log.properties -Djdk.attach.allowAttachSelf=true`\n* Working directory: `$MODULE_DIR$`\n* Use classpath of module: `trino-server-dev`\n\nThe working directory should be the `trino-server-dev` subdirectory. In\nIntelliJ, using `$MODULE_DIR$` accomplishes this automatically.\n\nIf `VM options` doesn't exist in the dialog, you need to select `Modify options`\nand enable `Add VM options`.\n\n### Running the CLI\n\nStart the CLI to connect to the server and run SQL queries:\n\n    client/trino-cli/target/trino-cli-*-executable.jar\n\nRun a query to see the nodes in the cluster:\n\n    SELECT * FROM system.runtime.nodes;\n\nRun a query against the TPCH connector:\n\n    SELECT * FROM tpch.tiny.region;\n",
	"analytics big-data data-warehousing database datalake dbms distributed-database hadoop hive hudi iceberg mpp olap real-time sql ssb tpch vectorized": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n<div align=\"center\">\n    <img src=\"https://doris.apache.org/assets/images/home-banner-7f193353c932af31634eca0a028f03ed.png\" align=\"right\" height=\"240\"/>\n</div>\n\n# Apache Doris\n[![License](https://img.shields.io/badge/license-Apache%202-4EB1BA.svg)](https://www.apache.org/licenses/LICENSE-2.0.html)\n[![GitHub release](https://img.shields.io/github/release/apache/doris.svg)](https://github.com/apache/doris/releases)\n[![Jenkins Vec](https://img.shields.io/jenkins/tests?compact_message&jobUrl=https://ci-builds.apache.org/job/Doris/job/doris_daily_disable_vectorized&label=OriginEngine)](https://ci-builds.apache.org/job/Doris/job/doris_daily_disable_vectorized)\n[![Jenkins Ori](https://img.shields.io/jenkins/tests?compact_message&jobUrl=https://ci-builds.apache.org/job/Doris/job/doris_daily_enable_vectorized&label=VectorizedEngine)](https://ci-builds.apache.org/job/Doris/job/doris_daily_enable_vectorized)\n[![Total Lines](https://tokei.rs/b1/github/apache/doris?category=lines)](https://github.com/apache/doris)\n[![Join the Doris Community at Slack](https://img.shields.io/badge/chat-slack-brightgreen)](https://join.slack.com/t/apachedoriscommunity/shared_invite/zt-1h153f1ar-sTJB_QahY1SHvZdtPFoIOQ)\n[![Join the chat at https://gitter.im/apache-doris/Lobby](https://badges.gitter.im/apache-doris/Lobby.svg)](https://gitter.im/apache-doris/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![EN doc](https://img.shields.io/badge/Docs-English-blue.svg)](https://doris.apache.org/docs/get-starting/)\n[![CN doc](https://img.shields.io/badge/\u6587\u6863-\u4e2d\u6587\u7248-blue.svg)](https://doris.apache.org/zh-CN/docs/get-starting/)\n[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/doris.svg?style=social&label=Follow%20%40doris_apache)](https://twitter.com/doris_apache)\n\nApache Doris is an easy-to-use, high-performance and real-time analytical database based on MPP architecture, known for its extreme speed and ease of use. It only requires a sub-second response time to return query results under massive data and can support not only high-concurrent point query scenarios but also high-throughput complex analysis scenarios.\n\nBased on this, Apache Doris can better meet the scenarios of report analysis, ad-hoc query, unified data warehouse, Data Lake Query Acceleration, etc. Users can build user behavior analysis, AB test platform, log retrieval analysis, user portrait analysis, order analysis, and other applications on top of this.\n\n\n\ud83c\udf89 Version 1.1.4 released now! It is also a LTS (long-term support) release and all users are encouraged to upgrade to this release. Check out the \ud83d\udd17[Release Notes](https://doris.apache.org/docs/releasenotes/release-1.1.4) here. \n\n\ud83d\udc40 Have a look at the \ud83d\udd17[Official Website](https://doris.apache.org/) for a comprehensive list of Apache Doris's core features, blogs and user cases.\n\n## \ud83d\udcc8 Usage Scenarios\n\nAs shown in the figure below, after various data integration and processing, the data sources are usually stored in the real-time data warehouse Apache Doris and the offline data lake or data warehouse (in Apache Hive, Apache Iceberg or Apache Hudi).\n\n<img src=\"https://dev-to-uploads.s3.amazonaws.com/uploads/articles/sekvbs5ih5rb16wz6n9k.png\">\n\nApache Doris is widely used in the following scenarios:\n\n- Reporting Analysis\n\n    - Real-time Dashboards\n    - Reports for in-house analysts and managers\n    - Highly concurrent user-oriented or customer-oriented report analysis.For example, in the scenarios of site analysis for website owners and advertising reports for advertisers, the concurrency usually requires thousands of QPS and the query latency requires sub-seconds response. The famous e-commerce company JD.com uses Doris in advertising reports, writing 10 billion rows of data per day, with tens of thousands of concurrent query QPS and 150ms query latency for the 99th percentile.\n\n- Ad-Hoc Query. Analyst-oriented self-service analytics with irregular query patterns and high throughput requirements. XiaoMi has built a growth analytics platform (Growth Analytics, GA) based on Doris, using user behavior data for business growth analysis, with an average query latency of 10 seconds and a 95th percentile query latency of 30 seconds or less, and tens of thousands of SQL queries per day.\n\n- Unified data warehouse construction. A platform to meet the needs of unified data warehouse construction and simplify the complicated data software stack. HaiDiLao's Doris-based unified data warehouse replaces the old architecture consisting of Apache Spark, Apache Hive, Apache Kudu, Apache HBase, and Apache Phoenix, and greatly simplifies the architecture.\n\n- Data Lake Query. By federating the data located in Apache Hive, Apache Iceberg, and Apache Hudi using external tables, the query performance is greatly improved while avoiding data copying.\n\n## \ud83d\udda5\ufe0f Core Concepts\n\n### \ud83d\udcc2 Architecture of Apache Doris\n\nThe overall architecture of Apache Doris is shown in the following figure. The Doris architecture is very simple, with only two types of processes.\n\n- Frontend\uff08FE\uff09: It is mainly responsible for user request access, query parsing and planning, management of metadata, and node management-related work.\n\n- Backend\uff08BE\uff09: It is mainly responsible for data storage and query plan execution.\n\nBoth types of processes are horizontally scalable, and a single cluster can support up to hundreds of machines and tens of petabytes of storage capacity. And these two types of processes guarantee high availability of services and high reliability of data through consistency protocols. This highly integrated architecture design greatly reduces the operation and maintenance cost of a distributed system.\n\n![The overall architecture of Apache Doris](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mnz20ae3s23vv3e9ltmi.png)\n\nApache Doris adopts MySQL protocol, highly compatible with MySQL dialect, and supports standard SQL. Users can access Doris through various client tools and support seamless connection with BI tools.\n\n### \ud83d\udcbe Storage Engine\n\nIn terms of the storage engine, Apache Doris uses columnar storage to encode and compress and read data by column, enabling a very high compression ratio while reducing a large number of scans of non-relevant data, thus making more efficient use of IO and CPU resources. Doris also supports a relatively rich index structure to reduce data scans:\n\n- Support sorted compound key index: Up to three columns can be specified to form a compound sort key. With this index, data can be effectively pruned to better support high concurrent reporting scenarios.\n- Z-order index \uff1aUsing Z-order indexing, you can efficiently run range queries on any combination of fields in your schema.\n- MIN/MAX index: Effective filtering of equivalence and range queries for numeric types\n- Bloom Filter index: very effective for equivalence filtering and pruning of high cardinality columns\n- Invert index: It enables the fast search of any field.\n\n\n### \ud83d\udcbf Storage Models\n\nIn terms of storage models, Apache Doris supports a variety of storage models, with specific optimizations for different scenarios:\n\n- Aggregate Key model: Merge the value columns with the same keys, by aggregating in advance to significantly improve performance.\n\n- Unique Key model: The key is unique. Data with the same key will be overwritten to achieve row-level data updates.\n\n- Duplicate Key model: The detailed data model can satisfy the detailed storage of fact tables.\n\nApache Doris also supports strong consistent materialized views, where updates and selections of materialized views are made automatically within the system and do not require manual selection by the user, thus significantly reducing the cost of materialized view maintenance.\n\n### \ud83d\udd0d Query Engine\n\nIn terms of query engine, Apache Doris adopts the MPP model, with parallel execution between and within nodes, and also supports distributed shuffle join for multiple large tables, which can better cope with complex queries.\n\n![](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vjlmumwyx728uymsgcw0.png)\n\nThe Doris query engine is vectorized, and all memory structures can be laid out in a columnar format to achieve significant reductions in virtual function calls, improved Cache hit rates, and efficient use of SIMD instructions. Performance in wide table aggregation scenarios is 5\u201310 times higher than in non-vectorized engines.\n\n![](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ck2m3kbnodn28t28vphp.png)\n\nApache Doris uses Adaptive Query Execution technology, which can dynamically adjust the execution plan based on runtime statistics, such as runtime filter technology to generate filters to push to the probe side at runtime and to automatically penetrate the filters to the probe side which drastically reduces the amount of data in the probe and speeds up join performance. Doris' runtime filter supports In/Min/Max/Bloom filter.\n\n### \ud83d\ude85 Query Optimizer\n\nIn terms of the optimizer, Doris uses a combination of CBO and RBO, with RBO supporting constant folding, subquery rewriting, predicate pushdown, etc., and CBO supporting Join Reorder. CBO is still under continuous optimization, mainly focusing on more accurate statistical information collection and derivation, more accurate cost model prediction, etc.\n\n\n**Technical Overview**: \ud83d\udd17[Introduction to Apache Doris](https://doris.apache.org/docs/summary/basic-summary)\n\n## \ud83c\udf86 Why choose Apache Doris?\n\n- \ud83c\udfaf **Easy to Use:** Two processes, no other dependencies; online cluster scaling, automatic replica recovery; compatible with MySQL protocol, and using standard SQL.\n\n- \ud83d\ude80 **High Performance:** Extremely fast performance for low-latency and high-throughput queries with columnar storage engine, modern MPP architecture, vectorized query engine, pre-aggregated materialized view and data index.\n\n- \ud83d\udda5\ufe0f **Single Unified:** A single system can support real-time data serving, interactive data analysis and offline data processing scenarios.\n\n- \u269b\ufe0f **Federated Querying:** Supports federated querying of data lakes such as Hive, Iceberg, Hudi, and databases such as MySQL and Elasticsearch.\n\n- \u23e9 **Various Data Import Methods:** Supports batch import from HDFS/S3 and stream import from MySQL Binlog/Kafka; supports micro-batch writing through HTTP interface and real-time writing using Insert in JDBC.\n\n- \ud83d\ude99 **Rich Ecology:** Spark uses Spark-Doris-Connector to read and write Doris; Flink-Doris-Connector enables Flink CDC to implement exactly-once data writing to Doris; DBT Doris Adapter is provided to transform data in Doris with DBT.\n\n## \ud83d\ude4c Contributors\n\n**Apache Doris has graduated from Apache incubator successfully and become a Top-Level Project in June 2022**. \n\nCurrently, the Apache Doris community has gathered more than 350 contributors from nearly 100 companies in different industries, and the number of active contributors is close to 100 per month.\n\n\n[![Monthly Active Contributors](https://contributor-overtime-api.apiseven.com/contributors-svg?chart=contributorMonthlyActivity&repo=apache/doris)](https://www.apiseven.com/en/contributor-graph?chart=contributorMonthlyActivity&repo=apache/doris)\n\n[![Contributor over time](https://contributor-overtime-api.apiseven.com/contributors-svg?chart=contributorOverTime&repo=apache/doris)](https://www.apiseven.com/en/contributor-graph?chart=contributorOverTime&repo=apache/doris)\n\nWe deeply appreciate \ud83d\udd17[community contributors](https://github.com/apache/doris/graphs/contributors) for their contribution to Apache Doris.\n\n## \ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66 Users\n\nApache Doris now has a wide user base in China and around the world, and as of today, Apache Doris is used in production environments in over 700 companies worldwide. More than 80% of the top 50 Internet companies in China in terms of market capitalization or valuation have been using Apache Doris for a long time, including Baidu, Meituan, Xiaomi, Jingdong, Bytedance, Tencent, NetEase, Kwai, Weibo, and Ke Holdings. It is also widely used in some traditional industries such as finance, energy, manufacturing, and telecommunications.\n\nThe users of Apache Doris: \ud83d\udd17[https://doris.apache.org/users](https://doris.apache.org/users)\n\nAdd your company logo at Apache Doris Website: \ud83d\udd17[Add Your Company](https://github.com/apache/doris/issues/10229)\n \n## \ud83d\udc63 Get Started\n\n### \ud83d\udcda Docs\n\nAll Documentation   \ud83d\udd17[Docs](https://doris.apache.org/docs/get-starting/)  \n\n### \u2b07\ufe0f Download \n\nAll release and binary version \ud83d\udd17[Download](https://doris.apache.org/download) \n\n### \ud83d\uddc4\ufe0f Compile\n\nSee how to compile  \ud83d\udd17[Compilation](https://doris.apache.org/docs/install/source-install/compilation)\n\n### \ud83d\udcee Install\n\nSee how to install and deploy \ud83d\udd17[Installation and deployment](https://doris.apache.org/docs/install/install-deploy) \n\n## \ud83e\udde9 Components\n\n### \ud83d\udcdd Doris Connector\n\nDoris provides support for Spark/Flink to read data stored in Doris through Connector, and also supports to write data to Doris through Connector.\n\n\ud83d\udd17[apache/doris-flink-connector](https://github.com/apache/doris-flink-connector)\n\n\ud83d\udd17[apache/doris-spark-connector](https://github.com/apache/doris-spark-connector)\n\n### \ud83d\udee0 Doris Manager \n\nDoris provides one-click visual automatic installation and deployment, cluster management and monitoring tools for clusters.\n\n\ud83d\udd17[apache/doris-manager](https://github.com/apache/doris-manager)\n\n## \ud83c\udf08 Community and Support\n\n### \ud83d\udce4 Subscribe Mailing Lists\n\nMail List is the most recognized form of communication in Apache community. See how to \ud83d\udd17[Subscribe Mailing Lists](https://doris.apache.org/community/subscribe-mail-list)\n\n### \ud83d\ude4b Report Issues or Submit Pull Request\n\nIf you meet any questions, feel free to file a \ud83d\udd17[GitHub Issue](https://github.com/apache/doris/issues) or post it in \ud83d\udd17[GitHub Discussion](https://github.com/apache/doris/discussions) and fix it by submitting a \ud83d\udd17[Pull Request](https://github.com/apache/doris/pulls) \n\n### \ud83c\udf7b How to Contribute\n\nWe welcome your suggestions, comments (including criticisms), comments and contributions. See \ud83d\udd17[How to Contribute](https://doris.apache.org/community/how-to-contribute/) and \ud83d\udd17[Code Submission Guide](https://doris.apache.org/community/how-to-contribute/pull-request/)\n\n### \u2328\ufe0f Doris Improvement Proposals (DSIP)\n\n\ud83d\udd17[Doris Improvement Proposal (DSIP)](https://cwiki.apache.org/confluence/display/DORIS/Doris+Improvement+Proposals) can be thought of as **A Collection of Design Documents for all Major Feature Updates or Improvements**.\n\n\n\n\n## \ud83d\udcac Contact Us\n\nContact us through the following mailing list.\n\n| Name                                                                          | Scope                           |                                                                 |                                                                     |                                                                              |\n|:------------------------------------------------------------------------------|:--------------------------------|:----------------------------------------------------------------|:--------------------------------------------------------------------|:-----------------------------------------------------------------------------|\n| [dev@doris.apache.org](mailto:dev@doris.apache.org)     | Development-related discussions | [Subscribe](mailto:dev-subscribe@doris.apache.org)   | [Unsubscribe](mailto:dev-unsubscribe@doris.apache.org)   | [Archives](http://mail-archives.apache.org/mod_mbox/doris-dev/)   |\n\n## \ud83e\uddf0 Links\n\n* Apache Doris Official Website - [https://doris.apache.org](https://doris.apache.org)\n* Developer Mailing list - <dev@doris.apache.org>. Mail to <dev-subscribe@doris.apache.org>, follow the reply to subscribe the mail list.\n* Slack channel - [Join the Slack](https://join.slack.com/t/apachedoriscommunity/shared_invite/zt-1h153f1ar-sTJB_QahY1SHvZdtPFoIOQ)\n* Twitter - [Follow @doris_apache](https://twitter.com/doris_apache)\n\n\n## \ud83d\udcdc License\n\n[Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\n> **Note**\n> Some licenses of the third-party dependencies are not compatible with Apache 2.0 License. So you need to disable\nsome Doris features to be complied with Apache 2.0 License. For details, refer to the `thirdparty/LICENSE.txt`\n\n\n\n",
	"automl big-data data-science deep-learning distributed ensemble-learning gbm gpu h2o h2o-automl hadoop java machine-learning naive-bayes opensource pca python r random-forest spark": "# H2O\n\n[![Join the chat at https://gitter.im/h2oai/h2o-3](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/h2oai/h2o-3?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nH2O is an in-memory platform for distributed, scalable machine learning. H2O uses familiar interfaces like R, Python, Scala, Java, JSON and the Flow notebook/web interface, and works seamlessly with big data technologies like Hadoop and Spark. H2O provides implementations of many popular [algorithms](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science.html) such as Generalized Linear Models (GLM), Gradient Boosting Machines (including XGBoost), Random Forests, Deep Neural Networks, Stacked Ensembles, Naive Bayes, Generalized Additive Models (GAM), Cox Proportional Hazards, K-Means, PCA, Word2Vec, as well as a fully automatic machine learning algorithm ([H2O AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html)). \n\nH2O is extensible so that developers can add data transformations and custom algorithms of their choice and access them through all of those clients.  H2O models can be [downloaded](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/save-and-load-model.html) and loaded into H2O memory for scoring, or exported into POJO or MOJO format for extemely fast scoring in [production](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html).  More information can be found in the [H2O User Guide](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html).\n\nH2O-3 (this repository) is the third incarnation of H2O, and the successor to [H2O-2](https://github.com/h2oai/h2o-2).  \n\n### Table of Contents\n\n* [Downloading H2O-3](#Downloading)\n* [Open Source Resources](#Resources)\n    * [Issue Tracking and Feature Requests](#IssueTracking)\n    * [List of H2O Resources](#OpenSourceResources)\n* [Using H2O-3 Code Artifacts (libraries)](#Artifacts)\n* [Building H2O-3](#Building)\n* [Launching H2O after Building](#Launching)\n* [Building H2O on Hadoop](#BuildingHadoop)\n* [Sparkling Water](#Sparkling)\n* [Documentation](#Documentation)\n* [Citing H2O](#Citing)\n* [Roadmap](#Roadmap)\n* [Community](#Community) / [Advisors](#Advisors) / [Investors](#Investors)\n\n<a name=\"Downloading\"></a>\n## 1. Downloading H2O-3\n\nWhile most of this README is written for developers who do their own builds, most H2O users just download and use a pre-built version.  If you are a Python or R user, the easiest way to install H2O is via [PyPI](https://pypi.python.org/pypi/h2o) or [Anaconda](https://anaconda.org/h2oai/h2o) (for Python) or [CRAN](https://CRAN.R-project.org/package=h2o) (for R):  \n\n### Python\n\n```bash\npip install h2o\n```\n\n### R\n\n```r\ninstall.packages(\"h2o\")\n```\n\nFor the latest stable, nightly, Hadoop (or Spark / Sparkling Water) releases, or the stand-alone H2O jar, please visit: [https://h2o.ai/download](https://h2o.ai/download)\n\nMore info on downloading & installing H2O is available in the [H2O User Guide](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html).\n\n<a name=\"Resources\"></a>\n## 2. Open Source Resources\n\nMost people interact with three or four primary open source resources:  **GitHub** (which you've already found), **JIRA** (for bug reports and issue tracking), **Stack Overflow** for H2O code/software-specific questions, and **h2ostream** (a Google Group / email discussion forum) for questions not suitable for Stack Overflow.  There is also a **Gitter** H2O developer chat group, however for archival purposes & to maximize accessibility, we'd prefer that standard H2O Q&A be conducted on Stack Overflow.\n\n<a name=\"IssueTracking\"></a>\n### 2.1 Issue Tracking and Feature Requests\n\n> (Note: There is only one issue tracking system for the project.  GitHub issues are not enabled; you must use JIRA.)\n\nYou can browse and create new issues in our open source **JIRA**:  <http://jira.h2o.ai>\n\n*  You can **browse** and search for **issues** without logging in to JIRA:\n    1.  Click the `Issues` menu\n    1.  Click `Search for issues`\n*  To **create** an **issue** (either a bug or a feature request), please create yourself an account first:\n    1.  Click the `Log In` button on the top right of the screen\n    1.  Click `Create an acccount` near the bottom of the login box\n    1.  Once you have created an account and logged in, use the `Create` button on the menu to create an issue\n    1.  Create H2O-3 issues in the [PUBDEV](https://0xdata.atlassian.net/projects/PUBDEV/issues) project.  (Note: Sparkling Water questions should be filed under the [SW](https://0xdata.atlassian.net/projects/SW/issues) project.)\n*\tYou can also vote for feature requests and/or other issues. Voting can help H2O prioritize the features that are included in each release.\n\t1. Go to the [H2O JIRA page](https://0xdata.atlassian.net/).\n\t2. Click **Log In** to either log in or create an account if you do not already have one.\n\t3. Search for the feature that you want to prioritize, or create a new feature.\n\t4. Click on the **Vote for this issue** link. This is located on the right side of the issue under the **People** section.\n\n<a name=\"OpenSourceResources\"></a>\n### 2.2 List of H2O Resources\n\n*  GitHub\n    * <https://github.com/h2oai/h2o-3>\n*  JIRA -- file bug reports / track issues here\n    * The [PUBDEV](https://0xdata.atlassian.net/projects/PUBDEV/issues) project contains issues for the current H2O-3 project)\n*  Stack Overflow -- ask all code/software questions here\n    * <http://stackoverflow.com/questions/tagged/h2o>\n*  Cross Validated (Stack Exchange) -- ask algorithm/theory questions here\n    * <https://stats.stackexchange.com/questions/tagged/h2o>\n*  h2ostream Google Group -- ask non-code related questions here\n    * Web: <https://groups.google.com/d/forum/h2ostream>\n    * Mail to: [h2ostream@googlegroups.com](mailto:h2ostream@googlegroups.com)\n* Gitter H2O Developer Chat\n    * <https://gitter.im/h2oai/h2o-3>    \n*  Documentation\n    * H2O User Guide (main docs): <http://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html>\n    * All H2O documenation links: <http://docs.h2o.ai>\n    * Nightly build page (nightly docs linked in page): <https://s3.amazonaws.com/h2o-release/h2o/master/latest.html>\n*  Download (pre-built packages)\n    * <http://h2o.ai/download>\n*  Jenkins (H2O build and test system)\n    * <http://test.h2o.ai>\n*  Website\n    * <http://h2o.ai>\n*  Twitter -- follow us for updates and H2O news!\n    * <https://twitter.com/h2oai>\n\n*  Awesome H2O -- share your H2O-powered creations with us\n   * <https://github.com/h2oai/awesome-h2o>\n\n\n<a name=\"Artifacts\"></a>\n## 3. Using H2O-3 Artifacts\n\nEvery nightly build publishes R, Python, Java, and Scala artifacts to a build-specific repository.  In particular, you can find Java artifacts in the maven/repo directory.\n\nHere is an example snippet of a gradle build file using h2o-3 as a dependency.  Replace x, y, z, and nnnn with valid numbers.\n\n```\n// h2o-3 dependency information\ndef h2oBranch = 'master'\ndef h2oBuildNumber = 'nnnn'\ndef h2oProjectVersion = \"x.y.z.${h2oBuildNumber}\"\n\nrepositories {\n  // h2o-3 dependencies\n  maven {\n    url \"https://s3.amazonaws.com/h2o-release/h2o-3/${h2oBranch}/${h2oBuildNumber}/maven/repo/\"\n  }\n}\n\ndependencies {\n  compile \"ai.h2o:h2o-core:${h2oProjectVersion}\"\n  compile \"ai.h2o:h2o-algos:${h2oProjectVersion}\"\n  compile \"ai.h2o:h2o-web:${h2oProjectVersion}\"\n  compile \"ai.h2o:h2o-app:${h2oProjectVersion}\"\n}\n```\n\nRefer to the latest H2O-3 bleeding edge [nightly build page](http://s3.amazonaws.com/h2o-release/h2o-3/master/latest.html) for information about installing nightly build artifacts.\n\nRefer to the [h2o-droplets GitHub repository](https://github.com/h2oai/h2o-droplets) for a working example of how to use Java artifacts with gradle.\n\n> Note: Stable H2O-3 artifacts are periodically published to Maven Central ([click here to search](http://search.maven.org/#search%7Cga%7C1%7Cai.h2o)) but may substantially lag behind H2O-3 Bleeding Edge nightly builds.\n\n\n<a name=\"Building\"></a>\n## 4. Building H2O-3\n\nGetting started with H2O development requires [JDK 1.8+](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/welcome.html#java-requirements), [Node.js](https://nodejs.org/), [Gradle](https://gradle.org/), [Python](https://www.python.org/) and [R](http://www.r-project.org/).  We use the Gradle wrapper (called `gradlew`) to ensure up-to-date local versions of Gradle and other dependencies are installed in your development directory.\n\n### 4.1. Before building\n\nBuilding `h2o` requires a properly set up R environment with [required packages](#InstallRPackagesInUnix) and Python environment with the following packages:\n\n```\ngrip\nfuture\ntabulate\nrequests\nwheel\n```\n\nTo install these packages you can use [pip](https://pip.pypa.io/en/stable/installing/) or [conda](https://conda.io/).\nIf you have troubles installing these packages on *Windows*, please follow section [Setup on Windows](#SetupWin) of this guide.\n> (Note: It is recommended to use some virtual environment such as [VirtualEnv](https://virtualenv.pypa.io/), to install all packages. )\n\n\n### 4.2. Building from the command line (Quick Start)\n\nTo build H2O from the repository, perform the following steps.\n\n\n#### Recipe 1: Clone fresh, build, skip tests, and run H2O\n\n```\n# Build H2O\ngit clone https://github.com/h2oai/h2o-3.git\ncd h2o-3\n./gradlew build -x test\n\nYou may encounter problems: e.g. npm missing. Install it:\nbrew install npm\n\n# Start H2O\njava -jar build/h2o.jar\n\n# Point browser to http://localhost:54321\n\n```\n\n#### Recipe 2: Clone fresh, build, and run tests (requires a working install of R)\n\n```\ngit clone https://github.com/h2oai/h2o-3.git\ncd h2o-3\n./gradlew syncSmalldata\n./gradlew syncRPackages\n./gradlew build\n```\n\n>**Notes**:\n>\n> - Running tests starts five test JVMs that form an H2O cluster and requires at least 8GB of RAM (preferably 16GB of RAM).\n> - Running `./gradlew syncRPackages` is supported on Windows, OS X, and Linux, and is strongly recommended but not required. `./gradlew syncRPackages` ensures a complete and consistent environment with pre-approved versions of the packages required for tests and builds. The packages can be installed manually, but we recommend setting an ENV variable and using `./gradlew syncRPackages`. To set the ENV variable, use the following format (where `${WORKSPACE} can be any path):\n>  \n> ```\n> mkdir -p ${WORKSPACE}/Rlibrary\n> export R_LIBS_USER=${WORKSPACE}/Rlibrary\n> ```\n\n#### Recipe 3:  Pull, clean, build, and run tests\n\n```\ngit pull\n./gradlew syncSmalldata\n./gradlew syncRPackages\n./gradlew clean\n./gradlew build\n```\n\n#### Notes\n\n - We recommend using `./gradlew clean` after each `git pull`.\n\n- Skip tests by adding `-x test` at the end the gradle build command line.  Tests typically run for 7-10 minutes on a Macbook Pro laptop with 4 CPUs (8 hyperthreads) and 16 GB of RAM.\n\n- Syncing smalldata is not required after each pull, but if tests fail due to missing data files, then try `./gradlew syncSmalldata` as the first troubleshooting step.  Syncing smalldata downloads data files from AWS S3 to the smalldata directory in your workspace.  The sync is incremental.  Do not check in these files.  The smalldata directory is in .gitignore.  If you do not run any tests, you do not need the smalldata directory.\n- Running `./gradlew syncRPackages` is supported on Windows, OS X, and Linux, and is strongly recommended but not required. `./gradlew syncRPackages` ensures a complete and consistent environment with pre-approved versions of the packages required for tests and builds. The packages can be installed manually, but we recommend setting an ENV variable and using `./gradlew syncRPackages`. To set the ENV variable, use the following format (where `${WORKSPACE}` can be any path):\n\n  ```\n  mkdir -p ${WORKSPACE}/Rlibrary\n  export R_LIBS_USER=${WORKSPACE}/Rlibrary\n  ```\n\n#### Recipe 4:  Just building the docs\n\n```\n./gradlew clean && ./gradlew build -x test && (export DO_FAST=1; ./gradlew dist)\nopen target/docs-website/h2o-docs/index.html\n```\n\n#### Recipe 5:  Building using a Makefile\n\nRoot of the git repository contains a Makefile with convenient shortcuts for frequent build targets used in development.\nTo build `h2o.jar` while skipping tests and also the building of alternative assemblies, execute \n\n```\nmake\n```\n\nTo build `h2o.jar` using the minimal assembly, run\n```\nmake minimal\n```\n\nThe minimal assembly is well suited for developement of H2O machine learning algorithms. It doesn't bundle some heavyweight\ndependencies (like Hadoop) and using it saves build time as well as need to download large libraries from Maven repositories.\n\n<a name=\"SetupWin\"></a>\n### 4.3. Setup on Windows\n\n##### Step 1: Download and install [WinPython](https://winpython.github.io).\n  From the command line, validate `python` is using the newly installed package by using `which python` (or `sudo which python`). [Update the Environment variable](https://github.com/winpython/winpython/wiki/Environment) with the WinPython path.\n\n##### Step 2: Install required Python packages:\n\n    pip install grip future tabulate wheel\n\n##### Step 3: Install JDK\n\nInstall [Java 1.8+](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/welcome.html#java-requirements) and add the appropriate directory `C:\\Program Files\\Java\\jdk1.7.0_65\\bin` with java.exe to PATH in Environment Variables. To make sure the command prompt is detecting the correct Java version, run:\n\n    javac -version\n\nThe CLASSPATH variable also needs to be set to the lib subfolder of the JDK:\n\n    CLASSPATH=/<path>/<to>/<jdk>/lib\n\n##### Step 4. Install Node.js\n\nInstall [Node.js](http://nodejs.org/download/) and add the installed directory `C:\\Program Files\\nodejs`, which must include node.exe and npm.cmd to PATH if not already prepended.\n\n##### Step 5. Install R, the required packages, and Rtools:\n\nInstall [R](http://www.r-project.org/) and add the bin directory to your PATH if not already included.\n\n<a name=\"InstallRPackagesInUnix\"></a>\nInstall the following R packages:\n\n- [RCurl](http://cran.r-project.org/package=RCurl)\n- [jsonlite](http://cran.r-project.org/package=jsonlite)\n- [statmod](http://cran.r-project.org/package=statmod)\n- [devtools](http://cran.r-project.org/package=devtools)\n- [roxygen2](http://cran.r-project.org/package=roxygen2)\n- [testthat](http://cran.r-project.org/package=testthat)\n\nTo install these packages from within an R session:\n\n```r\npkgs <- c(\"RCurl\", \"jsonlite\", \"statmod\", \"devtools\", \"roxygen2\", \"testthat\")\nfor (pkg in pkgs) {\n  if (! (pkg %in% rownames(installed.packages()))) install.packages(pkg)\n}\n```\nNote that [libcurl](http://curl.haxx.se) is required for installation of the **RCurl** R package.\n\nNote that this packages don't cover running tests, they for building H2O only.\n\nFinally, install [Rtools](http://cran.r-project.org/bin/windows/Rtools/), which is a collection of command line tools to facilitate R development on Windows.\n>**NOTE**: During Rtools installation, do **not** install Cygwin.dll.\n\n##### Step 6. Install [Cygwin](https://cygwin.com/setup-x86_64.exe)\n**NOTE**: During installation of Cygwin, deselect the Python packages to avoid a conflict with the Python.org package.\n\n###### Step 6b. Validate Cygwin\nIf Cygwin is already installed, remove the Python packages or ensure that Native Python is before Cygwin in the PATH variable.\n\n##### Step 7. Update or validate the Windows PATH variable to include R, Java JDK, Cygwin.\n\n##### Step 8. Git Clone [h2o-3](https://github.com/h2oai/h2o-3.git)\n\nIf you don't already have a Git client, please install one.  The default one can be found here http://git-scm.com/downloads.  Make sure that command prompt support is enabled before the installation.\n\nDownload and update h2o-3 source codes:\n\n    git clone https://github.com/h2oai/h2o-3\n\n##### Step 9. Run the top-level gradle build:\n\n    cd h2o-3\n    ./gradlew.bat build\n\n> If you encounter errors run again with `--stacktrace` for more instructions on missing dependencies.\n\n\n### 4.4. Setup on OS X\n\nIf you don't have [Homebrew](http://brew.sh/), we recommend installing it.  It makes package management for OS X easy.\n\n##### Step 1. Install JDK\n\nInstall [Java 1.8+](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/welcome.html#java-requirementsl). To make sure the command prompt is detecting the correct Java version, run:\n\n    javac -version\n\n##### Step 2. Install Node.js:\n\nUsing Homebrew:\n\n    brew install node\n\nOtherwise, install from the [NodeJS website](http://nodejs.org/download/).\n\n##### Step 3. Install R and the required packages:\n\nInstall [R](http://www.r-project.org/) and add the bin directory to your PATH if not already included.\n\n<a name=\"InstallRPackagesInUnix\"></a>\nInstall the following R packages:\n\n- [RCurl](http://cran.r-project.org/package=RCurl)\n- [jsonlite](http://cran.r-project.org/package=jsonlite)\n- [statmod](http://cran.r-project.org/package=statmod)\n- [devtools](http://cran.r-project.org/package=devtools)\n- [roxygen2](http://cran.r-project.org/package=roxygen2)\n- [testthat](http://cran.r-project.org/package=testthat)\n\nTo install these packages from within an R session:\n\n```r\npkgs <- c(\"RCurl\", \"jsonlite\", \"statmod\", \"devtools\", \"roxygen2\", \"testthat\")\nfor (pkg in pkgs) {\n  if (! (pkg %in% rownames(installed.packages()))) install.packages(pkg)\n}\n```\nNote that [libcurl](http://curl.haxx.se) is required for installation of the **RCurl** R package.\n\nNote that this packages don't cover running tests, they for building H2O only.\n\n##### Step 4. Install python and the required packages:\n\nInstall python:\n\n    brew install python\n\nInstall pip package manager:\n\n    sudo easy_install pip\n\nNext install required packages:\n\n    sudo pip install wheel requests future tabulate  \n\n##### Step 5. Git Clone [h2o-3](https://github.com/h2oai/h2o-3.git)\n\nOS X should already have Git installed. To download and update h2o-3 source codes:\n\n    git clone https://github.com/h2oai/h2o-3\n\n##### Step 6. Run the top-level gradle build:\n\n    cd h2o-3\n    ./gradlew build\n\nNote: on a regular machine it may take very long time (about an hour) to run all the tests.\n\n> If you encounter errors run again with `--stacktrace` for more instructions on missing dependencies.\n\n### 4.5. Setup on Ubuntu 14.04\n\n##### Step 1. Install Node.js\n\n    curl -sL https://deb.nodesource.com/setup_0.12 | sudo bash -\n    sudo apt-get install -y nodejs\n\n##### Step 2. Install JDK:\n\nInstall [Java 8](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/welcome.html#java-requirements). Installation instructions can be found here [JDK installation](http://askubuntu.com/questions/56104/how-can-i-install-sun-oracles-proprietary-java-jdk-6-7-8-or-jre). To make sure the command prompt is detecting the correct Java version, run:\n\n    javac -version\n\n##### Step 3. Install R and the required packages:\n\nInstallation instructions can be found here [R installation](http://cran.r-project.org).  Click \u201cDownload R for Linux\u201d.  Click \u201cubuntu\u201d.  Follow the given instructions.\n\nTo install the required packages, follow the [same instructions as for OS X above](#InstallRPackagesInUnix).\n\n>**Note**: If the process fails to install RStudio Server on Linux, run one of the following:\n>\n>`sudo apt-get install libcurl4-openssl-dev`\n>\n>or\n>\n>`sudo apt-get install libcurl4-gnutls-dev`\n\n##### Step 4. Git Clone [h2o-3](https://github.com/h2oai/h2o-3.git)\n\nIf you don't already have a Git client:\n\n    sudo apt-get install git\n\nDownload and update h2o-3 source codes:\n\n    git clone https://github.com/h2oai/h2o-3\n\n##### Step 5. Run the top-level gradle build:\n\n    cd h2o-3\n    ./gradlew build\n\n> If you encounter errors, run again using `--stacktrace` for more instructions on missing dependencies.\n\n> Make sure that you are not running as root, since `bower` will reject such a run.\n\n### 4.6. Setup on Ubuntu 13.10\n\n##### Step 1. Install Node.js\n\n    curl -sL https://deb.nodesource.com/setup_16.x | sudo bash -\n    sudo apt-get install -y nodejs\n\n##### Steps 2-4. Follow steps 2-4 for Ubuntu 14.04 (above)\n\n### 4.7. Setup on CentOS 7\n\n```\ncd /opt\nsudo wget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/7u79-b15/jdk-7u79-linux-x64.tar.gz\"\n\nsudo tar xzf jdk-7u79-linux-x64.tar.gz\ncd jdk1.7.0_79\n\nsudo alternatives --install /usr/bin/java java /opt/jdk1.7.0_79/bin/java 2\n\nsudo alternatives --install /usr/bin/jar jar /opt/jdk1.7.0_79/bin/jar 2\nsudo alternatives --install /usr/bin/javac javac /opt/jdk1.7.0_79/bin/javac 2\nsudo alternatives --set jar /opt/jdk1.7.0_79/bin/jar\nsudo alternatives --set javac /opt/jdk1.7.0_79/bin/javac\n\ncd /opt\n\nsudo wget http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm\nsudo rpm -ivh epel-release-7-5.noarch.rpm\n\nsudo echo \"multilib_policy=best\" >> /etc/yum.conf\nsudo yum -y update\n\nsudo yum -y install R R-devel git python-pip openssl-devel libxml2-devel libcurl-devel gcc gcc-c++ make openssl-devel kernel-devel texlive texinfo texlive-latex-fonts libX11-devel mesa-libGL-devel mesa-libGL nodejs npm python-devel numpy scipy python-pandas\n\nsudo pip install scikit-learn grip tabulate statsmodels wheel\n\nmkdir ~/Rlibrary\nexport JAVA_HOME=/opt/jdk1.7.0_79\nexport JRE_HOME=/opt/jdk1.7.0_79/jre\nexport PATH=$PATH:/opt/jdk1.7.0_79/bin:/opt/jdk1.7.0_79/jre/bin\nexport R_LIBS_USER=~/Rlibrary\n\n# install local R packages\nR -e 'install.packages(c(\"RCurl\",\"jsonlite\",\"statmod\",\"devtools\",\"roxygen2\",\"testthat\"), dependencies=TRUE, repos=\"http://cran.rstudio.com/\")'\n\ncd\ngit clone https://github.com/h2oai/h2o-3.git\ncd h2o-3\n\n# Build H2O\n./gradlew syncSmalldata\n./gradlew syncRPackages\n./gradlew build -x test\n\n```\n\n\n<a name=\"Launching\"></a>\n\n## 5. Launching H2O after Building\n\nTo start the H2O cluster locally, execute the following on the command line:\n\n    java -jar build/h2o.jar\n\nA list of available start-up JVM and H2O options (e.g. `-Xmx`, `-nthreads`, `-ip`), is available in the [H2O User Guide](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/starting-h2o.html#from-the-command-line).\n\n<a name=\"BuildingHadoop\"></a>\n## 6. Building H2O on Hadoop\n\nPre-built H2O-on-Hadoop zip files are available on the [download page](http://h2o.ai/download).  Each Hadoop distribution version has a separate zip file in h2o-3.\n\nTo build H2O with Hadoop support yourself, first install sphinx for python: `pip install sphinx`\nThen start the build by entering  the following from the top-level h2o-3 directory:\n\n    export BUILD_HADOOP=1;\n    ./gradlew build -x test;\n    ./gradlew dist;\n\nThis will create a directory called 'target' and generate zip files there.  Note that `BUILD_HADOOP` is the default behavior when the username is `jenkins` (refer to `settings.gradle`); otherwise you have to request it, as shown above.\n\nTo build the zip files only for selected distributions use the `H2O_TARGET` env variable together with `BUILD_HADOOP`, for example:\n\n    export BUILD_HADOOP=1;\n    export H2O_TARGET=hdp2.5,hdp2.6\n    ./gradlew build -x test;\n    ./gradlew dist;\n\n### Adding support for a new version of Hadoop\n\nIn the `h2o-hadoop` directory, each Hadoop version has a build directory for the driver and an assembly directory for the fatjar.\n\nYou need to:\n\n1.  Add a new driver directory and assembly directory (each with a `build.gradle` file) in `h2o-hadoop`\n2.  Add these new projects to `h2o-3/settings.gradle`\n3.  Add the new Hadoop version to `HADOOP_VERSIONS` in `make-dist.sh`\n4.  Add the new Hadoop version to the list in `h2o-dist/buildinfo.json`\n\n\n### Secure user impersonation\n\nHadoop supports [secure user impersonation](https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/Superusers.html) through its Java API.  A kerberos-authenticated user can be allowed to proxy any username that meets specified criteria entered in the NameNode's core-site.xml file.  This impersonation only applies to interactions with the Hadoop API or the APIs of Hadoop-related services that support it (this is not the same as switching to that user on the machine of origin).\n\nSetting up secure user impersonation (for h2o):\n\n1.  Create or find an id to use as proxy which has limited-to-no access to HDFS or related services; the proxy user need only be used to impersonate a user\n2.  (Required if not using h2odriver) If you are not using the driver (e.g. you wrote your own code against h2o's API using Hadoop), make the necessary code changes to impersonate users (see [org.apache.hadoop.security.UserGroupInformation](http://hadoop.apache.org/docs/r2.8.0/api/org/apache/hadoop/security/UserGroupInformation.html))\n3.  In either of Ambari/Cloudera Manager or directly on the NameNode's core-site.xml file, add 2/3 properties for the user we wish to use as a proxy (replace <proxyusername> with the simple user name - not the fully-qualified principal name).\n    * `hadoop.proxyuser.<proxyusername>.hosts`: the hosts the proxy user is allowed to perform impersonated actions on behalf of a valid user from\n    * `hadoop.proxyuser.<proxyusername>.groups`: the groups an impersonated user must belong to for impersonation to work with that proxy user\n    * `hadoop.proxyuser.<proxyusername>.users`: the users a proxy user is allowed to impersonate\n    * Example: ```\n               <property>\n                 <name>hadoop.proxyuser.myproxyuser.hosts</name>\n                 <value>host1,host2</value>\n               </property>\n               <property>\n                 <name>hadoop.proxyuser.myproxyuser.groups</name>\n                 <value>group1,group2</value>\n               </property>\n               <property>\n                 <name>hadoop.proxyuser.myproxyuser.users</name>\n                 <value>user1,user2</value>\n               </property>\n               ```\n4.  Restart core services such as HDFS & YARN for the changes to take effect\n\nImpersonated HDFS actions can be viewed in the hdfs audit log ('auth:PROXY' should appear in the `ugi=` field in entries where this is applicable).  YARN similarly should show 'auth:PROXY' somewhere in the Resource Manager UI.\n\n\nTo use secure impersonation with h2o's Hadoop driver:\n\n*Before this is attempted, see Risks with impersonation, below*\n\nWhen using the h2odriver (e.g. when running with `hadoop jar ...`), specify `-principal <proxy user kerberos principal>`, `-keytab <proxy user keytab path>`, and `-run_as_user <hadoop username to impersonate>`, in addition to any other arguments needed.  If the configuration was successful, the proxy user will log in and impersonate the `-run_as_user` as long as that user is allowed by either the users or groups configuration property (configured above); this is enforced by HDFS & YARN, not h2o's code.  The driver effectively sets its security context as the impersonated user so all supported Hadoop actions will be performed as that user (e.g. YARN, HDFS APIs support securely impersonated users, but others may not).\n\n#### Precautions to take when leveraging secure impersonation\n\n*  The target use case for secure impersonation is applications or services that pre-authenticate a user and then use (in this case) the h2odriver on behalf of that user.  H2O's Steam is a perfect example: auth user in web app over SSL, impersonate that user when creating the h2o YARN container.\n*  The proxy user should have limited permissions in the Hadoop cluster; this means no permissions to access data or make API calls.  In this way, if it's compromised it would only have the power to impersonate a specific subset of the users in the cluster and only from specific machines.\n*  Use the `hadoop.proxyuser.<proxyusername>.hosts` property whenever possible or practical.\n*  Don't give the proxyusername's password or keytab to any user you don't want to impersonate another user (this is generally *any* user).  The point of impersonation is not to allow users to impersonate each other.  See the first bullet for the typical use case.\n*  Limit user logon to the machine the proxying is occurring from whenever practical.\n*  Make sure the keytab used to login the proxy user is properly secured and that users can't login as that id (via `su`, for instance)\n*  Never set hadoop.proxyuser.<proxyusername>.{users,groups} to '*' or 'hdfs', 'yarn', etc.  Allowing any user to impersonate hdfs, yarn, or any other important user/group should be done with extreme caution and *strongly* analyzed before it's allowed.\n\n#### Risks with secure impersonation\n\n*  The id performing the impersonation can be compromised like any other user id.\n*  Setting any `hadoop.proxyuser.<proxyusername>.{hosts,groups,users}` property to '*' can greatly increase exposure to security risk.\n*  When users aren't authenticated before being used with the driver (e.g. like Steam does via a secure web app/API), auditability of the process/system is difficult.\n\n\n```\n$ git diff\ndiff --git a/h2o-app/build.gradle b/h2o-app/build.gradle\nindex af3b929..097af85 100644\n--- a/h2o-app/build.gradle\n+++ b/h2o-app/build.gradle\n@@ -8,5 +8,6 @@ dependencies {\n   compile project(\":h2o-algos\")\n   compile project(\":h2o-core\")\n   compile project(\":h2o-genmodel\")\n+  compile project(\":h2o-persist-hdfs\")\n }\n\ndiff --git a/h2o-persist-hdfs/build.gradle b/h2o-persist-hdfs/build.gradle\nindex 41b96b2..6368ea9 100644\n--- a/h2o-persist-hdfs/build.gradle\n+++ b/h2o-persist-hdfs/build.gradle\n@@ -2,5 +2,6 @@ description = \"H2O Persist HDFS\"\n\n dependencies {\n   compile project(\":h2o-core\")\n-  compile(\"org.apache.hadoop:hadoop-client:2.0.0-cdh4.3.0\")\n+  compile(\"org.apache.hadoop:hadoop-client:2.4.1-mapr-1408\")\n+  compile(\"org.json:org.json:chargebee-1.0\")\n }\n```\n\n<a name=\"Sparkling\"></a>\n## 7. Sparkling Water\n\nSparkling Water combines two open-source technologies: Apache Spark and the H2O Machine Learning platform.  It makes H2O\u2019s library of advanced algorithms, including Deep Learning, GLM, GBM, K-Means, and Distributed Random Forest, accessible from Spark workflows. Spark users can select the best features from either platform to meet their Machine Learning needs.  Users can combine Spark's RDD API and Spark MLLib with H2O\u2019s machine learning algorithms, or use H2O independently of Spark for the model building process and post-process the results in Spark.\n\n**Sparkling Water Resources**:\n\n* [Download page for pre-built packages](http://h2o.ai/download/)\n* [Sparkling Water GitHub repository](https://github.com/h2oai/sparkling-water)  \n* [README](https://github.com/h2oai/sparkling-water/blob/master/README.md)\n* [Developer documentation](https://github.com/h2oai/sparkling-water/blob/master/DEVEL.md)\n\n<a name=\"Documentation\"></a>\n## 8. Documentation\n\n### Documenation Homepage\n\nThe main H2O documentation is the [H2O User Guide](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html).  Visit <http://docs.h2o.ai> for the top-level introduction to documentation on H2O projects.\n\n\n### Generate REST API documentation\n\nTo generate the REST API documentation, use the following commands:\n\n    cd ~/h2o-3\n    cd py\n    python ./generate_rest_api_docs.py  # to generate Markdown only\n    python ./generate_rest_api_docs.py --generate_html  --github_user GITHUB_USER --github_password GITHUB_PASSWORD # to generate Markdown and HTML\n\nThe default location for the generated documentation is `build/docs/REST`.\n\nIf the build fails, try `gradlew clean`, then `git clean -f`.\n\n### Bleeding edge build documentation\n\nDocumentation for each bleeding edge nightly build is available on the [nightly build page](http://s3.amazonaws.com/h2o-release/h2o/master/latest.html).\n\n\n<a name=\"Citing\"></a>\n## 9. Citing H2O\n\nIf you use H2O as part of your workflow in a publication, please cite your H2O resource(s) using the following BibTex entry:\n\n### H2O Software\n\n\t@Manual{h2o_package_or_module,\n\t    title = {package_or_module_title},\n\t    author = {H2O.ai},\n\t    year = {year},\n\t    month = {month},\n\t    note = {version_information},\n\t    url = {resource_url},\n\t}\n\n**Formatted H2O Software citation examples**:\n\n- H2O.ai (Oct. 2016). _Python Interface for H2O_, Python module version 3.10.0.8. [https://github.com/h2oai/h2o-3](https://github.com/h2oai/h2o-3).\n- H2O.ai (Oct. 2016). _R Interface for H2O_, R package version 3.10.0.8. [https://github.com/h2oai/h2o-3](https://github.com/h2oai/h2o-3).\n- H2O.ai (Oct. 2016). _H2O_, H2O version 3.10.0.8. [https://github.com/h2oai/h2o-3](https://github.com/h2oai/h2o-3).\n\n### H2O Booklets\n\nH2O algorithm booklets are available at the [Documentation Homepage](http://docs.h2o.ai/h2o/latest-stable/index.html).\n\n\t@Manual{h2o_booklet_name,\n\t    title = {booklet_title},\n\t    author = {list_of_authors},\n\t    year = {year},\n\t    month = {month},\n\t    url = {link_url},\n\t}\n\n**Formatted booklet citation examples**:\n\nArora, A., Candel, A., Lanford, J., LeDell, E., and Parmar, V. (Oct. 2016). _Deep Learning with H2O_. <http://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/DeepLearningBooklet.pdf>.\n\nClick, C., Lanford, J., Malohlava, M., Parmar, V., and Roark, H. (Oct. 2016). _Gradient Boosted Models with H2O_. <http://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/GBMBooklet.pdf>.\n\n<a name=\"Roadmap\"></a>\n## 10. Roadmap\n\n### H2O 3.36.0.1 - Winter 2021\n\n* [[PUBDEV-4940]](https://h2oai.atlassian.net/browse/PUBDEV-4940) Uplift Trees\n* [[PUBDEV-8074]](https://h2oai.atlassian.net/browse/PUBDEV-8074) Admissible ML - Infogram\n* RuleFit improvements (multinomial support, rule deduplication and consolidation)\n* Backward elimination in MAXR\n* Improved support for CDP (S3A with IDBroker)\n* Support for Java 16 and 17, Python 3.8\n\n### H2O 3.38.0.1 - Spring 2022\n\n* [[PUBDEV-8074]](https://h2oai.atlassian.net/browse/PUBDEV-8074) Admissible ML - stage 2 (algos)\n* Multi-Output Regression in Deep Learning\n* GAM Improvements (support for Monotonic Splines)\n* XGBoost Upgrade\n* Data Ingest Improvements (Secured Hive in Standalone/K8S)\n* Extended Isolation Forest MOJO\n* Uplift MOJO\n* New features ICE plots\n\n<a name=\"Community\"></a>\n## 11. Community\n\nH2O has been built by a great many number of contributors over the years both within H2O.ai (the company) and the greater open source community.  You can begin to contribute to H2O by answering [Stack Overflow](http://stackoverflow.com/questions/tagged/h2o) questions or [filing bug reports](https://0xdata.atlassian.net/projects/PUBDEV/issues).  Please join us!  \n\n\n### Team & Committers\n\n```\nSriSatish Ambati\nCliff Click\nTom Kraljevic\nTomas Nykodym\nMichal Malohlava\nKevin Normoyle\nSpencer Aiello\nAnqi Fu\nNidhi Mehta\nArno Candel\nJosephine Wang\nAmy Wang\nMax Schloemer\nRay Peck\nPrithvi Prabhu\nBrandon Hill\nJeff Gambera\nAriel Rao\nViraj Parmar\nKendall Harris\nAnand Avati\nJessica Lanford\nAlex Tellez\nAllison Washburn\nAmy Wang\nErik Eckstrand\nNeeraja Madabhushi\nSebastian Vidrio\nBen Sabrin\nMatt Dowle\nMark Landry\nErin LeDell\nAndrey Spiridonov\nOleg Rogynskyy\nNick Martin\nNancy Jordan\nNishant Kalonia\nNadine Hussami\nJeff Cramer\nStacie Spreitzer\nVinod Iyengar\nCharlene Windom\nParag Sanghavi\nNavdeep Gill\nLauren DiPerna\nAnmol Bal\nMark Chan\nNick Karpov\nAvni Wadhwa\nAshrith Barthur\nKaren Hayrapetyan\nJo-fai Chow\nDmitry Larko\nBranden Murray\nJakub Hava\nWen Phan\nMagnus Stensmo\nPasha Stetsenko\nAngela Bartz\nMateusz Dymczyk\nMicah Stubbs\nIvy Wang\nTerone Ward\nLeland Wilkinson\nWendy Wong\nNikhil Shekhar\nPavel Pscheidl\nMichal Kurka\nVeronika Maurerova\nJan Sterba\nJan Jendrusak\nSebastien Poirier\nTom\u00e1\u0161 Fr\u00fdda\nArd Kelmendi\n```\n\n<a name=\"Advisors\"></a>\n## Advisors\n\nScientific Advisory Council\n\n```\nStephen Boyd\nRob Tibshirani\nTrevor Hastie\n```\n\nSystems, Data, FileSystems and Hadoop\n\n```\nDoug Lea\nChris Pouliot\nDhruba Borthakur\n```\n\n<a name=\"Investors\"></a>\n## Investors\n\n```\nJishnu Bhattacharjee, Nexus Venture Partners\nAnand Babu Periasamy\nAnand Rajaraman\nAsh Bhardwaj\nRakesh Mathur\nMichael Marks\nEgbert Bierman\nRajesh Ambati\n```\n",
	"batch beam big-data golang java python sql streaming": "<!--\n    Licensed to the Apache Software Foundation (ASF) under one\n    or more contributor license agreements.  See the NOTICE file\n    distributed with this work for additional information\n    regarding copyright ownership.  The ASF licenses this file\n    to you under the Apache License, Version 2.0 (the\n    \"License\"); you may not use this file except in compliance\n    with the License.  You may obtain a copy of the License at\n\n      http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing,\n    software distributed under the License is distributed on an\n    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n    KIND, either express or implied.  See the License for the\n    specific language governing permissions and limitations\n    under the License.\n-->\n\n# Apache Beam\n\n[Apache Beam](http://beam.apache.org/) is a unified model for defining both batch and streaming data-parallel processing pipelines, as well as a set of language-specific SDKs for constructing pipelines and Runners for executing them on distributed processing backends, including [Apache Flink](http://flink.apache.org/), [Apache Spark](http://spark.apache.org/), [Google Cloud Dataflow](http://cloud.google.com/dataflow/), and [Hazelcast Jet](https://jet.hazelcast.org/).\n\n## Status\n\n[![Maven Version](https://maven-badges.herokuapp.com/maven-central/org.apache.beam/beam-sdks-java-core/badge.svg)](http://search.maven.org/#search|gav|1|g:\"org.apache.beam\")\n[![PyPI version](https://badge.fury.io/py/apache-beam.svg)](https://badge.fury.io/py/apache-beam)\n[![Go version](https://pkg.go.dev/badge/github.com/apache/beam/sdks/v2/go.svg)](https://pkg.go.dev/github.com/apache/beam/sdks/v2/go)\n[![Python coverage](https://codecov.io/gh/apache/beam/branch/master/graph/badge.svg)](https://codecov.io/gh/apache/beam)\n[![Build python source distribution and wheels](https://github.com/apache/beam/workflows/Build%20python%20source%20distribution%20and%20wheels/badge.svg?branch=master&event=schedule)](https://github.com/apache/beam/actions?query=workflow%3A%22Build+python+source+distribution+and+wheels%22+branch%3Amaster+event%3Aschedule)\n[![Python tests](https://github.com/apache/beam/workflows/Python%20tests/badge.svg?branch=master&event=schedule)](https://github.com/apache/beam/actions?query=workflow%3A%22Python+Tests%22+branch%3Amaster+event%3Aschedule)\n[![Java tests](https://github.com/apache/beam/workflows/Java%20Tests/badge.svg?branch=master&event=schedule)](https://github.com/apache/beam/actions?query=workflow%3A%22Java+Tests%22+branch%3Amaster+event%3Aschedule)\n[![Go tests (Jenkins)](https://ci-beam.apache.org/job/beam_PreCommit_Go_Cron/lastCompletedBuild/badge/icon?subject=Go%20Tests%28Jenkins%29)](https://ci-beam.apache.org/job/beam_PreCommit_Go_Cron/lastCompletedBuild/)\n[![Java tests (Jenkins)](https://ci-beam.apache.org/job/beam_PreCommit_Java_Cron/lastCompletedBuild/badge/icon?subject=Java%20Tests%28Jenkins%29)](https://ci-beam.apache.org/job/beam_PreCommit_Java_Cron/lastCompletedBuild/)\n[![Python tests (Jenkins)](https://ci-beam.apache.org/job/beam_PreCommit_Python_Cron/lastCompletedBuild/badge/icon?subject=Python%20Tests%28Jenkins%29)](https://ci-beam.apache.org/job/beam_PreCommit_Python_Cron/lastCompletedBuild/)\n\n## Overview\n\nBeam provides a general approach to expressing [embarrassingly parallel](https://en.wikipedia.org/wiki/Embarrassingly_parallel) data processing pipelines and supports three categories of users, each of which have relatively disparate backgrounds and needs.\n\n1. _End Users_: Writing pipelines with an existing SDK, running it on an existing runner. These users want to focus on writing their application logic and have everything else just work.\n2. _SDK Writers_: Developing a Beam SDK targeted at a specific user community (Java, Python, Scala, Go, R, graphical, etc). These users are language geeks and would prefer to be shielded from all the details of various runners and their implementations.\n3. _Runner Writers_: Have an execution environment for distributed processing and would like to support programs written against the Beam Model. Would prefer to be shielded from details of multiple SDKs.\n\n### The Beam Model\n\nThe model behind Beam evolved from several internal Google data processing projects, including [MapReduce](http://research.google.com/archive/mapreduce.html), [FlumeJava](http://research.google.com/pubs/pub35650.html), and [Millwheel](http://research.google.com/pubs/pub41378.html). This model was originally known as the \u201c[Dataflow Model](http://www.vldb.org/pvldb/vol8/p1792-Akidau.pdf)\u201d.\n\nTo learn more about the Beam Model (though still under the original name of Dataflow), see the World Beyond Batch: [Streaming 101](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101) and [Streaming 102](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-102) posts on O\u2019Reilly\u2019s Radar site, and the [VLDB 2015 paper](http://www.vldb.org/pvldb/vol8/p1792-Akidau.pdf).\n\nThe key concepts in the Beam programming model are:\n\n* `PCollection`: represents a collection of data, which could be bounded or unbounded in size.\n* `PTransform`: represents a computation that transforms input PCollections into output PCollections.\n* `Pipeline`: manages a directed acyclic graph of PTransforms and PCollections that is ready for execution.\n* `PipelineRunner`: specifies where and how the pipeline should execute.\n\n### SDKs\n\nBeam supports multiple language-specific SDKs for writing pipelines against the Beam Model.\n\nCurrently, this repository contains SDKs for Java, Python and Go.\n\nHave ideas for new SDKs or DSLs? See the [sdk-ideas label](https://github.com/apache/beam/issues?q=is%3Aopen+is%3Aissue+label%3Asdk-ideas).\n\n### Runners\n\nBeam supports executing programs on multiple distributed processing backends through PipelineRunners. Currently, the following PipelineRunners are available:\n\n- The `DirectRunner` runs the pipeline on your local machine.\n- The `DataflowRunner` submits the pipeline to the [Google Cloud Dataflow](http://cloud.google.com/dataflow/).\n- The `FlinkRunner` runs the pipeline on an Apache Flink cluster. The code has been donated from [dataArtisans/flink-dataflow](https://github.com/dataArtisans/flink-dataflow) and is now part of Beam.\n- The `SparkRunner` runs the pipeline on an Apache Spark cluster. The code has been donated from [cloudera/spark-dataflow](https://github.com/cloudera/spark-dataflow) and is now part of Beam.\n- The `JetRunner` runs the pipeline on a Hazelcast Jet cluster. The code has been donated from [hazelcast/hazelcast-jet](https://github.com/hazelcast/hazelcast-jet) and is now part of Beam.\n- The `Twister2Runner` runs the pipeline on a Twister2 cluster. The code has been donated from [DSC-SPIDAL/twister2](https://github.com/DSC-SPIDAL/twister2) and is now part of Beam.\n\nHave ideas for new Runners? See the [runner-ideas label](https://github.com/apache/beam/issues?q=is%3Aopen+is%3Aissue+label%3Arunner-ideas).\n\n## Getting Started\n\nTo learn how to write Beam pipelines, read the Quickstart for [[Java](https://beam.apache.org/get-started/quickstart-java), [Python](https://beam.apache.org/get-started/quickstart-py), or\n[Go](https://beam.apache.org/get-started/quickstart-go)] available on our website.\n\n## Contact Us\n\nTo get involved in Apache Beam:\n\n* [Subscribe](mailto:user-subscribe@beam.apache.org) or [mail](mailto:user@beam.apache.org) the [user@beam.apache.org](http://mail-archives.apache.org/mod_mbox/beam-user/) list.\n* [Subscribe](mailto:dev-subscribe@beam.apache.org) or [mail](mailto:dev@beam.apache.org) the [dev@beam.apache.org](http://mail-archives.apache.org/mod_mbox/beam-dev/) list.\n* [Join ASF Slack](https://s.apache.org/slack-invite) on [#beam channel](https://s.apache.org/beam-slack-channel)\n* [Report an issue](https://github.com/apache/beam/issues/new/choose).\n\nInstructions for building and testing Beam itself\nare in the [contribution guide](https://beam.apache.org/contribute/).\n\n## More Information\n\n* [Apache Beam](https://beam.apache.org)\n* [Overview](https://beam.apache.org/use/beam-overview/)\n* Quickstart: [Java](https://beam.apache.org/get-started/quickstart-java), [Python](https://beam.apache.org/get-started/quickstart-py), [Go](https://beam.apache.org/get-started/quickstart-go)\n* [Community metrics](https://s.apache.org/beam-community-metrics)\n",
	"analytics bi business-intelligence businessintelligence clojure dashboard data data-analysis data-visualization database metabase mysql postgres postgresql reporting slack sql-editor visualization": "# Metabase\n\n[Metabase](https://www.metabase.com) is the easy, open-source way for everyone in your company to ask questions and learn from data.\n\n![Metabase Product Screenshot](docs/images/metabase-product-screenshot.svg)\n\n[![Latest Release](https://img.shields.io/github/release/metabase/metabase.svg?label=latest%20release)](https://github.com/metabase/metabase/releases)\n[![Circle CI](https://circleci.com/gh/metabase/metabase.svg?style=svg&circle-token=3ccf0aa841028af027f2ac9e8df17ce603e90ef9)](https://circleci.com/gh/metabase/metabase)\n[![codecov](https://codecov.io/gh/metabase/metabase/branch/master/graph/badge.svg)](https://codecov.io/gh/metabase/metabase)\n![Docker Pulls](https://img.shields.io/docker/pulls/metabase/metabase)\n\n## Features\n\n- [Set up in five minutes](https://www.metabase.com/docs/latest/setting-up-metabase.html) (we're not kidding).\n- Let anyone on your team [ask questions](https://www.metabase.com/docs/latest/users-guide/04-asking-questions.html) without knowing SQL.\n- Use the [SQL editor](https://www.metabase.com/docs/latest/users-guide/writing-sql.html) for more complex queries.\n- Build handsome, interactive [dashboards](https://www.metabase.com/docs/latest/users-guide/07-dashboards.html) with filters, auto-refresh, fullscreen, and custom click behavior.\n- Create [models](https://www.metabase.com/learn/getting-started/models) that clean up, annotate, and/or combine raw tables.\n- Define canonical [segments and metrics](https://www.metabase.com/docs/latest/administration-guide/07-segments-and-metrics.html) for your team to use.\n- Send data to Slack or email on a schedule with [dashboard subscriptions](https://www.metabase.com/docs/latest/users-guide/dashboard-subscriptions).\n- Set up [alerts](https://www.metabase.com/docs/latest/users-guide/15-alerts.html) to have Metabase notify you when your data changes.\n- [Embed charts and dashboards](https://www.metabase.com/docs/latest/administration-guide/13-embedding.html) in your app, or even [your entire Metabase](https://www.metabase.com/docs/latest/enterprise-guide/full-app-embedding.html).\n\nTake a [tour of Metabase](https://www.metabase.com/learn/getting-started/tour-of-metabase).\n\n## Supported databases\n\n- [Officially supported databases](./docs/databases/connecting.md#connecting-to-supported-databases)\n- [Partner and Community drivers](./docs/developers-guide/partner-and-community-drivers.md)\n\n## Installation\n\nMetabase can be run just about anywhere. Check out our [Installation Guides](https://www.metabase.com/docs/latest/operations-guide/installing-metabase.html).\n\n## Contributing\n\nTo get started with a development installation of the Metabase, check out our [Developers Guide](https://www.metabase.com/docs/latest/developers-guide/start).\n\n## Internationalization\n\nWe want Metabase to be available in as many languages as possible. See which translations are available and help contribute to internationalization using our project over at [POEditor](https://poeditor.com/join/project/ynjQmwSsGh). You can also check out our [policies on translations](https://www.metabase.com/docs/latest/administration-guide/localization.html).\n\n## Extending Metabase\n\nHit our Query API from Javascript to integrate analytics. Metabase enables your application to:\n\n- Build moderation interfaces.\n- Export subsets of your users to third party marketing automation software.\n- Provide a custom customer lookup application for the people in your company.\n\nCheck out our guide, [Working with the Metabase API](https://www.metabase.com/learn/administration/metabase-api).\n\n## Security Disclosure\n\nSee [SECURITY.md](./SECURITY.md) for details.\n\n## License\n\nThis repository contains the source code for both the Open Source edition of Metabase, released under the AGPL, as well as the [commercial editions of Metabase](https://www.metabase.com/pricing), which are released under the Metabase Commercial Software License.\n\nSee [LICENSE.txt](./LICENSE.txt) for details.\n\nUnless otherwise noted, all files \u00a9 2022 Metabase, Inc.\n\n## [Metabase Experts](https://www.metabase.com/partners/)\n\nIf you\u2019d like more technical resources to set up your data stack with Metabase, connect with a [Metabase Expert](https://www.metabase.com/partners/?utm_source=readme&utm_medium=metabase-expetrs&utm_campaign=readme).\n",
	"compression data-analysis data-manipulation encoding encryption hashing parsing": "# CyberChef\n\n[![](https://github.com/gchq/CyberChef/workflows/Master%20Build,%20Test%20&%20Deploy/badge.svg)](https://github.com/gchq/CyberChef/actions?query=workflow%3A%22Master+Build%2C+Test+%26+Deploy%22)\n[![Language grade: JavaScript](https://img.shields.io/lgtm/grade/javascript/g/gchq/CyberChef.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/gchq/CyberChef/context:javascript)\n[![npm](https://img.shields.io/npm/v/cyberchef.svg)](https://www.npmjs.com/package/cyberchef)\n[![](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/gchq/CyberChef/blob/master/LICENSE)\n[![Gitter](https://badges.gitter.im/gchq/CyberChef.svg)](https://gitter.im/gchq/CyberChef?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\n\n#### *The Cyber Swiss Army Knife*\n\nCyberChef is a simple, intuitive web app for carrying out all manner of \"cyber\" operations within a web browser. These operations include simple encoding like XOR and Base64, more complex encryption like AES, DES and Blowfish, creating binary and hexdumps, compression and decompression of data, calculating hashes and checksums, IPv6 and X.509 parsing, changing character encodings, and much more.\n\nThe tool is designed to enable both technical and non-technical analysts to manipulate data in complex ways without having to deal with complex tools or algorithms. It was conceived, designed, built and incrementally improved by an analyst in their 10% innovation time over several years.\n\n## Live demo\n\nCyberChef is still under active development. As a result, it shouldn't be considered a finished product. There is still testing and bug fixing to do, new features to be added and additional documentation to write. Please contribute!\n\nCryptographic operations in CyberChef should not be relied upon to provide security in any situation. No guarantee is offered for their correctness.\n\n[A live demo can be found here][1] - have fun!\n\n\n## How it works\n\nThere are four main areas in CyberChef:\n\n 1. The **input** box in the top right, where you can paste, type or drag the text or file you want to operate on.\n 2. The **output** box in the bottom right, where the outcome of your processing will be displayed.\n 3. The **operations** list on the far left, where you can find all the operations that CyberChef is capable of in categorised lists, or by searching.\n 4. The **recipe** area in the middle, where you can drag the operations that you want to use and specify arguments and options.\n\nYou can use as many operations as you like in simple or complex ways. Some examples are as follows:\n\n - [Decode a Base64-encoded string][2]\n - [Convert a date and time to a different time zone][3]\n - [Parse a Teredo IPv6 address][4]\n - [Convert data from a hexdump, then decompress][5]\n - [Decrypt and disassemble shellcode][6]\n - [Display multiple timestamps as full dates][7]\n - [Carry out different operations on data of different types][8]\n - [Use parts of the input as arguments to operations][9]\n - [Perform AES decryption, extracting the IV from the beginning of the cipher stream][10]\n - [Automagically detect several layers of nested encoding][12]\n\n\n## Features\n\n - Drag and drop\n     - Operations can be dragged in and out of the recipe list, or reorganised.\n     - Files up to 2GB can be dragged over the input box to load them directly into the browser.\n - Auto Bake\n     - Whenever you modify the input or the recipe, CyberChef will automatically \"bake\" for you and produce the output immediately.\n     - This can be turned off and operated manually if it is affecting performance (if the input is very large, for instance).\n - Automated encoding detection\n     - CyberChef uses [a number of techniques](https://github.com/gchq/CyberChef/wiki/Automatic-detection-of-encoded-data-using-CyberChef-Magic) to attempt to automatically detect which encodings your data is under. If it finds a suitable operation that make sense of your data, it displays the 'magic' icon in the Output field which you can click to decode your data.\n - Breakpoints\n     - You can set breakpoints on any operation in your recipe to pause execution before running it.\n     - You can also step through the recipe one operation at a time to see what the data looks like at each stage.\n - Save and load recipes\n     - If you come up with an awesome recipe that you know you\u2019ll want to use again, just click \"Save recipe\" and add it to your local storage. It'll be waiting for you next time you visit CyberChef.\n     - You can also copy the URL, which includes your recipe and input, to easily share it with others.\n - Search\n     - If you know the name of the operation you want or a word associated with it, start typing it into the search field and any matching operations will immediately be shown.\n - Highlighting\n     - When you highlight text in the input or output, the offset and length values will be displayed and, if possible, the corresponding data will be highlighted in the output or input respectively (example: [highlight the word 'question' in the input to see where it appears in the output][11]).\n - Save to file and load from file\n     - You can save the output to a file at any time or load a file by dragging and dropping it into the input field. Files up to around 2GB are supported (depending on your browser), however, some operations may take a very long time to run over this much data.\n - CyberChef is entirely client-side\n     - It should be noted that none of your recipe configuration or input (either text or files) is ever sent to the CyberChef web server - all processing is carried out within your browser, on your own computer.\n     - Due to this feature, CyberChef can be downloaded and run locally. You can use the link in the top left corner of the app to download a full copy of CyberChef and drop it into a virtual machine, share it with other people, or host it in a closed network.\n\n\n## Deep linking\n\nBy manipulating CyberChef's URL hash, you can change the initial settings with which the page opens.\nThe format is `https://gchq.github.io/CyberChef/#recipe=Operation()&input=...`\n\nSupported arguments are `recipe`, `input` (encoded in Base64), and `theme`.\n\n\n## Browser support\n\nCyberChef is built to support\n\n - Google Chrome 50+\n - Mozilla Firefox 38+\n\n\n## Node.js support\n\nCyberChef is built to fully support Node.js `v16`. For more information, see the Node API page in the project [wiki pages](https://github.com/gchq/CyberChef/wiki)\n\n\n## Contributing\n\nContributing a new operation to CyberChef is super easy! The quickstart script will walk you through the process. If you can write basic JavaScript, you can write a CyberChef operation.\n\nAn installation walkthrough, how-to guides for adding new operations and themes, descriptions of the repository structure, available data types and coding conventions can all be found in the project [wiki pages](https://github.com/gchq/CyberChef/wiki).\n\n - Push your changes to your fork.\n - Submit a pull request. If you are doing this for the first time, you will be prompted to sign the [GCHQ Contributor Licence Agreement](https://cla-assistant.io/gchq/CyberChef) via the CLA assistant on the pull request. This will also ask whether you are happy for GCHQ to contact you about a token of thanks for your contribution, or about job opportunities at GCHQ.\n\n\n## Licencing\n\nCyberChef is released under the [Apache 2.0 Licence](https://www.apache.org/licenses/LICENSE-2.0) and is covered by [Crown Copyright](https://www.nationalarchives.gov.uk/information-management/re-using-public-sector-information/uk-government-licensing-framework/crown-copyright/).\n\n\n  [1]: https://gchq.github.io/CyberChef\n  [2]: https://gchq.github.io/CyberChef/#recipe=From_Base64('A-Za-z0-9%2B/%3D',true)&input=VTI4Z2JHOXVaeUJoYm1RZ2RHaGhibXR6SUdadmNpQmhiR3dnZEdobElHWnBjMmd1\n  [3]: https://gchq.github.io/CyberChef/#recipe=Translate_DateTime_Format('Standard%20date%20and%20time','DD/MM/YYYY%20HH:mm:ss','UTC','dddd%20Do%20MMMM%20YYYY%20HH:mm:ss%20Z%20z','Australia/Queensland')&input=MTUvMDYvMjAxNSAyMDo0NTowMA\n  [4]: https://gchq.github.io/CyberChef/#recipe=Parse_IPv6_address()&input=MjAwMTowMDAwOjQxMzY6ZTM3ODo4MDAwOjYzYmY6M2ZmZjpmZGQy\n  [5]: https://gchq.github.io/CyberChef/#recipe=From_Hexdump()Gunzip()&input=MDAwMDAwMDAgIDFmIDhiIDA4IDAwIDEyIGJjIGYzIDU3IDAwIGZmIDBkIGM3IGMxIDA5IDAwIDIwICB8Li4uLi6881cu/y7HwS4uIHwKMDAwMDAwMTAgIDA4IDA1IGQwIDU1IGZlIDA0IDJkIGQzIDA0IDFmIGNhIDhjIDQ0IDIxIDViIGZmICB8Li7QVf4uLdMuLsouRCFb/3wKMDAwMDAwMjAgIDYwIGM3IGQ3IDAzIDE2IGJlIDQwIDFmIDc4IDRhIDNmIDA5IDg5IDBiIDlhIDdkICB8YMfXLi6%2BQC54Sj8uLi4ufXwKMDAwMDAwMzAgIDRlIGM4IDRlIDZkIDA1IDFlIDAxIDhiIDRjIDI0IDAwIDAwIDAwICAgICAgICAgICB8TshObS4uLi5MJC4uLnw\n  [6]: https://gchq.github.io/CyberChef/#recipe=RC4(%7B'option':'UTF8','string':'secret'%7D,'Hex','Hex')Disassemble_x86('64','Full%20x86%20architecture',16,0,true,true)&input=MjFkZGQyNTQwMTYwZWU2NWZlMDc3NzEwM2YyYTM5ZmJlNWJjYjZhYTBhYWJkNDE0ZjkwYzZjYWY1MzEyNzU0YWY3NzRiNzZiM2JiY2QxOTNjYjNkZGZkYmM1YTI2NTMzYTY4NmI1OWI4ZmVkNGQzODBkNDc0NDIwMWFlYzIwNDA1MDcxMzhlMmZlMmIzOTUwNDQ2ZGIzMWQyYmM2MjliZTRkM2YyZWIwMDQzYzI5M2Q3YTVkMjk2MmMwMGZlNmRhMzAwNzJkOGM1YTZiNGZlN2Q4NTlhMDQwZWVhZjI5OTczMzYzMDJmNWEwZWMxOQ\n  [7]: https://gchq.github.io/CyberChef/#recipe=Fork('%5C%5Cn','%5C%5Cn',false)From_UNIX_Timestamp('Seconds%20(s)')&input=OTc4MzQ2ODAwCjEwMTI2NTEyMDAKMTA0NjY5NjQwMAoxMDgxMDg3MjAwCjExMTUzMDUyMDAKMTE0OTYwOTYwMA\n  [8]: https://gchq.github.io/CyberChef/#recipe=Fork('%5C%5Cn','%5C%5Cn',false)Conditional_Jump('1',false,'base64',10)To_Hex('Space')Return()Label('base64')To_Base64('A-Za-z0-9%2B/%3D')&input=U29tZSBkYXRhIHdpdGggYSAxIGluIGl0ClNvbWUgZGF0YSB3aXRoIGEgMiBpbiBpdA\n  [9]: https://gchq.github.io/CyberChef/#recipe=Register('key%3D(%5B%5C%5Cda-f%5D*)',true,false)Find_/_Replace(%7B'option':'Regex','string':'.*data%3D(.*)'%7D,'$1',true,false,true)RC4(%7B'option':'Hex','string':'$R0'%7D,'Hex','Latin1')&input=aHR0cDovL21hbHdhcmV6LmJpei9iZWFjb24ucGhwP2tleT0wZTkzMmE1YyZkYXRhPThkYjdkNWViZTM4NjYzYTU0ZWNiYjMzNGUzZGIxMQ\n  [10]: https://gchq.github.io/CyberChef/#recipe=Register('(.%7B32%7D)',true,false)Drop_bytes(0,32,false)AES_Decrypt(%7B'option':'Hex','string':'1748e7179bd56570d51fa4ba287cc3e5'%7D,%7B'option':'Hex','string':'$R0'%7D,'CTR','Hex','Raw',%7B'option':'Hex','string':''%7D)&input=NTFlMjAxZDQ2MzY5OGVmNWY3MTdmNzFmNWI0NzEyYWYyMGJlNjc0YjNiZmY1M2QzODU0NjM5NmVlNjFkYWFjNDkwOGUzMTljYTNmY2Y3MDg5YmZiNmIzOGVhOTllNzgxZDI2ZTU3N2JhOWRkNmYzMTFhMzk0MjBiODk3OGU5MzAxNGIwNDJkNDQ3MjZjYWVkZjU0MzZlYWY2NTI0MjljMGRmOTRiNTIxNjc2YzdjMmNlODEyMDk3YzI3NzI3M2M3YzcyY2Q4OWFlYzhkOWZiNGEyNzU4NmNjZjZhYTBhZWUyMjRjMzRiYTNiZmRmN2FlYjFkZGQ0Nzc2MjJiOTFlNzJjOWU3MDlhYjYwZjhkYWY3MzFlYzBjYzg1Y2UwZjc0NmZmMTU1NGE1YTNlYzI5MWNhNDBmOWU2MjlhODcyNTkyZDk4OGZkZDgzNDUzNGFiYTc5YzFhZDE2NzY3NjlhN2MwMTBiZjA0NzM5ZWNkYjY1ZDk1MzAyMzcxZDYyOWQ5ZTM3ZTdiNGEzNjFkYTQ2OGYxZWQ1MzU4OTIyZDJlYTc1MmRkMTFjMzY2ZjMwMTdiMTRhYTAxMWQyYWYwM2M0NGY5NTU3OTA5OGExNWUzY2Y5YjQ0ODZmOGZmZTljMjM5ZjM0ZGU3MTUxZjZjYTY1MDBmZTRiODUwYzNmMWMwMmU4MDFjYWYzYTI0NDY0NjE0ZTQyODAxNjE1YjhmZmFhMDdhYzgyNTE0OTNmZmRhN2RlNWRkZjMzNjg4ODBjMmI5NWIwMzBmNDFmOGYxNTA2NmFkZDA3MWE2NmNmNjBlNWY0NmYzYTIzMGQzOTdiNjUyOTYzYTIxYTUzZg\n  [11]: https://gchq.github.io/CyberChef/#recipe=XOR(%7B'option':'Hex','string':'3a'%7D,'Standard',false)To_Hexdump(16,false,false)&input=VGhlIGFuc3dlciB0byB0aGUgdWx0aW1hdGUgcXVlc3Rpb24gb2YgbGlmZSwgdGhlIFVuaXZlcnNlLCBhbmQgZXZlcnl0aGluZyBpcyA0Mi4\n  [12]: https://gchq.github.io/CyberChef/#recipe=Magic(3,false,false)&input=V1VhZ3dzaWFlNm1QOGdOdENDTFVGcENwQ0IyNlJtQkRvREQ4UGFjZEFtekF6QlZqa0syUXN0RlhhS2hwQzZpVVM3UkhxWHJKdEZpc29SU2dvSjR3aGptMWFybTg2NHFhTnE0UmNmVW1MSHJjc0FhWmM1VFhDWWlmTmRnUzgzZ0RlZWpHWDQ2Z2FpTXl1QlY2RXNrSHQxc2NnSjg4eDJ0TlNvdFFEd2JHWTFtbUNvYjJBUkdGdkNLWU5xaU45aXBNcTFaVTFtZ2tkYk51R2NiNzZhUnRZV2hDR1VjOGc5M1VKdWRoYjhodHNoZVpud1RwZ3FoeDgzU1ZKU1pYTVhVakpUMnptcEM3dVhXdHVtcW9rYmRTaTg4WXRrV0RBYzFUb291aDJvSDRENGRkbU5LSldVRHBNd21uZ1VtSzE0eHdtb21jY1BRRTloTTE3MkFQblNxd3hkS1ExNzJSa2NBc3lzbm1qNWdHdFJtVk5OaDJzMzU5d3I2bVMyUVJQ\n",
	"analytics apache c cli command-line dashboard data-analysis gdpr goaccess google-analytics monitoring ncurses nginx privacy real-time terminal tui web-analytics webserver": "GoAccess [![C build](https://github.com/allinurl/goaccess/actions/workflows/build-test.yml/badge.svg)](https://github.com/allinurl/goaccess/actions/workflows/build-test.yml) [![GoAccess](https://goaccess.io/badge)](https://goaccess.io)\n========\n\n## What is it? ##\nGoAccess is an open source **real-time web log analyzer** and interactive\nviewer that runs in a **terminal** on &ast;nix systems or through your\n**browser**. It provides **fast** and valuable HTTP statistics for system\nadministrators that require a visual server report on the fly.\nMore info at: [https://goaccess.io](https://goaccess.io/?src=gh).\n\n[![GoAccess Terminal Dashboard](https://goaccess.io/images/goaccess-real-time-term-gh.png?2022011901)](https://goaccess.io/)\n[![GoAccess HTML Dashboard](https://goaccess.io/images/goaccess-real-time-html-gh.png?202201190)](https://rt.goaccess.io/?src=gh)\n\n## Features ##\nGoAccess parses the specified web log file and outputs the data to the X\nterminal. Features include:\n\n* **Completely Real Time**<br>\n  All panels and metrics are timed to be updated every 200 ms on the terminal\n  output and every second on the HTML output.\n\n* **Minimal Configuration needed**<br>\n  You can just run it against your access log file, pick the log format and let\n  GoAccess parse the access log and show you the stats.\n\n* **Track Application Response Time**<br>\n  Track the time taken to serve the request. Extremely useful if you want to\n  track pages that are slowing down your site.\n\n* **Nearly All Web Log Formats**<br>\n  GoAccess allows any custom log format string.  Predefined options include,\n  Apache, Nginx, Amazon S3, Elastic Load Balancing, CloudFront, etc.\n\n* **Incremental Log Processing**<br>\n  Need data persistence? GoAccess has the ability to process logs incrementally\n  through the on-disk persistence options.\n\n* **Only one dependency**<br>\n  GoAccess is written in C. To run it, you only need ncurses as a dependency.\n  That's it. It even features its own Web Socket server \u2014 http://gwsocket.io/.\n\n* **Visitors**<br>\n  Determine the amount of hits, visitors, bandwidth, and metrics for slowest\n  running requests by the hour, or date.\n\n* **Metrics per Virtual Host**<br>\n  Have multiple Virtual Hosts (Server Blocks)? It features a panel that\n  displays which virtual host is consuming most of the web server resources.\n\n* **Color Scheme Customizable**<br>\n  Tailor GoAccess to suit your own color taste/schemes. Either through the\n  terminal, or by simply applying the stylesheet on the HTML output.\n\n* **Support for Large Datasets**<br>\n  GoAccess features the ability to parse large logs due to its optimized\n  in-memory hash tables. It has very good memory usage and pretty good\n  performance. This storage has support for on-disk persistence as well.\n\n* **Docker Support**<br>\n  Ability to build GoAccess' Docker image from upstream. You can still fully\n  configure it, by using Volume mapping and editing `goaccess.conf`.  See\n  [Docker](https://github.com/allinurl/goaccess#docker) section below.\n\n### Nearly all web log formats... ###\nGoAccess allows any custom log format string. Predefined options include, but\nnot limited to:\n\n* Amazon CloudFront (Download Distribution).\n* Amazon Simple Storage Service (S3)\n* AWS Elastic Load Balancing\n* Combined Log Format (XLF/ELF) Apache | Nginx\n* Common Log Format (CLF) Apache\n* Google Cloud Storage.\n* Apache virtual hosts\n* Squid Native Format.\n* W3C format (IIS).\n* Caddy's JSON Structured format.\n\n## Why GoAccess? ##\nGoAccess was designed to be a fast, terminal-based log analyzer. Its core idea\nis to quickly analyze and view web server statistics in real time without\nneeding to use your browser (_great if you want to do a quick analysis of your\naccess log via SSH, or if you simply love working in the terminal_).\n\nWhile the terminal output is the default output, it has the capability to\ngenerate a complete, self-contained, real-time [**`HTML`**](https://rt.goaccess.io/?src=gh)\nreport, as well as a [**`JSON`**](https://goaccess.io/json?src=gh), and\n[**`CSV`**](https://goaccess.io/goaccess_csv_report.csv?src=gh) report.\n\nYou can see it more of a monitor command tool than anything else.\n\n## Installation ##\n\n### Build from release\n\nGoAccess can be compiled and used on *nix systems.\n\nDownload, extract and compile GoAccess with:\n\n    $ wget https://tar.goaccess.io/goaccess-1.6.5.tar.gz\n    $ tar -xzvf goaccess-1.6.5.tar.gz\n    $ cd goaccess-1.6.5/\n    $ ./configure --enable-utf8 --enable-geoip=mmdb\n    $ make\n    # make install\n\n### Build from GitHub (Development) ###\n\n    $ git clone https://github.com/allinurl/goaccess.git\n    $ cd goaccess\n    $ autoreconf -fiv\n    $ ./configure --enable-utf8 --enable-geoip=mmdb\n    $ make\n    # make install\n\n#### Build in isolated container\n\nYou can also build the binary for Debian based systems in an isolated container environment to prevent cluttering your local system with the development libraries:\n\n    $ curl -L \"https://github.com/allinurl/goaccess/archive/refs/heads/master.tar.gz\" | tar -xz && cd goaccess-master\n    $ docker build -t goaccess/build.debian-10 -f Dockerfile.debian-10 .\n    $ docker run -i --rm -v $PWD:/goaccess goaccess/build.debian-10 > goaccess\n\n### Distributions ###\n\nIt is easiest to install GoAccess on GNU+Linux using the preferred package manager\nof your GNU+Linux distribution. Please note that not all distributions will have\nthe latest version of GoAccess available.\n\n#### Debian/Ubuntu ####\n\n    # apt-get install goaccess\n\n**Note:** It is likely this will install an outdated version of GoAccess. To\nmake sure that you're running the latest stable version of GoAccess see\nalternative option below.\n\n#### Official GoAccess Debian & Ubuntu repository ####\n\n    $ wget -O - https://deb.goaccess.io/gnugpg.key | gpg --dearmor \\\n        | sudo tee /usr/share/keyrings/goaccess.gpg >/dev/null\n    $ echo \"deb [signed-by=/usr/share/keyrings/goaccess.gpg arch=$(dpkg --print-architecture)] https://deb.goaccess.io/ $(lsb_release -cs) main\" \\\n        | sudo tee /etc/apt/sources.list.d/goaccess.list\n    $ sudo apt-get update\n    $ sudo apt-get install goaccess\n\n**Note**:\n* `.deb` packages in the official repo are available through HTTPS as well. You may need to install `apt-transport-https`.\n\n#### Fedora ####\n\n    # yum install goaccess\n\n#### Arch ####\n\n    # pacman -S goaccess\n\n#### Gentoo ####\n\n    # emerge net-analyzer/goaccess\n\n#### OS X / Homebrew ####\n\n    # brew install goaccess\n\n#### FreeBSD ####\n\n    # cd /usr/ports/sysutils/goaccess/ && make install clean\n    # pkg install sysutils/goaccess\n\n#### OpenBSD ####\n\n    # cd /usr/ports/www/goaccess && make install clean\n    # pkg_add goaccess\n\n#### openSUSE  ####\n\n    # zypper ar -f obs://server:http http\n    # zypper in goaccess\n\n#### OpenIndiana ####\n\n    # pkg install goaccess\n\n#### pkgsrc (NetBSD, Solaris, SmartOS, ...) ####\n\n    # pkgin install goaccess\n\n#### Windows ####\n\nGoAccess can be used in Windows through Cygwin. See Cygwin's <a\nhref=\"https://goaccess.io/faq#installation\">packages</a>.  Or through the\nGNU+Linux Subsystem on Windows 10.\n\n#### Distribution Packages ####\n\nGoAccess has minimal requirements, it's written in C and requires only ncurses.\nHowever, below is a table of some optional dependencies in some distros to\nbuild GoAccess from source.\n\nDistro                 | NCurses          | GeoIP (opt)      |GeoIP2 (opt)           |  OpenSSL (opt)\n---------------------- | -----------------|------------------|---------------------- | -------------------\n**Ubuntu/Debian**      | libncursesw6-dev | libgeoip-dev     | libmaxminddb-dev      |  libssl-dev\n**RHEL/CentOS**        | ncurses-devel    | geoip-devel      | libmaxminddb-devel    |  openssl-devel\n**Arch**               | ncurses          | geoip            | libmaxminddb          |  openssl\n**Gentoo**             | sys-libs/ncurses | dev-libs/geoip   | dev-libs/libmaxminddb |  dev-libs/openssl\n**Slackware**          | ncurses          | GeoIP            | libmaxminddb          |  openssl\n\n**Note**: You may need to install build tools like `gcc`, `autoconf`,\n`gettext`, `autopoint` etc for compiling/building software from source. e.g.,\n`base-devel`, `build-essential`, `\"Development Tools\"`.\n\n#### Docker ####\n\nA Docker image has been updated, capable of directing output from an access log. If you only want to output a report, you can pipe a log from the external environment to a Docker-based process:\n\n    cat access.log | docker run --rm -i -e LANG=$LANG allinurl/goaccess -a -o html --log-format COMBINED - > report.html\n\nOR real-time\n\n    tail -F access.log | docker run -p 7890:7890 --rm -i -e LANG=$LANG allinurl/goaccess -a -o html --log-format COMBINED --real-time-html - > report.html\n\nYou can read more about using the docker image in [DOCKER.md](https://github.com/allinurl/goaccess/blob/master/DOCKER.md).\n\n## Storage ##\n\n#### Default Hash Tables ####\n\nIn-memory storage provides better performance at the cost of limiting the\ndataset size to the amount of available physical memory. GoAccess uses\nin-memory hash tables.  It has very good memory usage and pretty good\nperformance. This storage has support for on-disk persistence as well.\n\n## Command Line / Config Options ##\nSee [**options**](https://goaccess.io/man#options) that can be supplied to the command or\nspecified in the configuration file. If specified in the configuration file, long\noptions need to be used without prepending `--`.\n\n## Usage / Examples ##\n**Note**: Piping data into GoAccess won't prompt a log/date/time\nconfiguration dialog, you will need to previously define it in your\nconfiguration file or in the command line.\n\n### Getting Started ###\n\nTo output to a terminal and generate an interactive report:\n\n    # goaccess access.log\n\nTo generate an HTML report:\n\n    # goaccess access.log -a > report.html\n    \nTo generate a JSON report:\n\n    # goaccess access.log -a -d -o json > report.json\n    \nTo generate a CSV file:\n\n    # goaccess access.log --no-csv-summary -o csv > report.csv\n\nGoAccess also allows great flexibility for real-time filtering and parsing. For\ninstance, to quickly diagnose issues by monitoring logs since goaccess was\nstarted:\n\n    # tail -f access.log | goaccess -\n\nAnd even better, to filter while maintaining opened a pipe to preserve\nreal-time analysis, we can make use of `tail -f` and a matching pattern tool\nsuch as `grep`, `awk`, `sed`, etc:\n\n    # tail -f access.log | grep -i --line-buffered 'firefox' | goaccess --log-format=COMBINED -\n\nor to parse from the beginning of the file while maintaining the pipe opened\nand applying a filter\n\n    # tail -f -n +0 access.log | grep -i --line-buffered 'firefox' | goaccess -o report.html --real-time-html -\n\n\n### Multiple Log files ###\n\nThere are several ways to parse multiple logs with GoAccess. The simplest is to\npass multiple log files to the command line:\n\n    # goaccess access.log access.log.1\n\nIt's even possible to parse files from a pipe while reading regular files:\n\n    # cat access.log.2 | goaccess access.log access.log.1 -\n\n**Note**: the single dash is appended to the command line to let GoAccess\nknow that it should read from the pipe.\n\nNow if we want to add more flexibility to GoAccess, we can use `zcat --force`\nto read compressed and uncompressed files. For instance, if we would\nlike to process all log files `access.log*`, we can do:\n\n    # zcat --force access.log* | goaccess -\n\n_Note_: On Mac OS X, use `gunzip -c` instead of `zcat`.\n\n### Real-time HTML outputs ###\n\nGoAccess has the ability the output real-time data in the HTML report. You can\neven email the HTML file since it is composed of a single file with no external\nfile dependencies, how neat is that!\n\nThe process of generating a real-time HTML report is very similar to the\nprocess of creating a static report. Only `--real-time-html` is needed to make\nit real-time.\n\n    # goaccess access.log -o /usr/share/nginx/html/your_site/report.html --real-time-html\n\nTo view the report you can navigate to `http://your_site/report.html`.\n\nBy default, GoAccess will use the host name of the generated report.\nOptionally, you can specify the URL to which the client's browser will connect\nto. See [FAQ](https://goaccess.io/faq) for a more detailed example.\n\n    # goaccess access.log -o report.html --real-time-html --ws-url=goaccess.io\n\nBy default, GoAccess listens on port 7890, to use a different port other than\n7890, you can specify it as (make sure the port is opened):\n\n    # goaccess access.log -o report.html --real-time-html --port=9870\n\nAnd to bind the WebSocket server to a different address other than 0.0.0.0, you\ncan specify it as:\n\n    # goaccess access.log -o report.html --real-time-html --addr=127.0.0.1\n\n**Note**: To output real time data over a TLS/SSL connection, you need to use\n`--ssl-cert=<cert.crt>` and `--ssl-key=<priv.key>`.\n\n### Filtering ###\n\n#### Working with dates ####\n\nAnother useful pipe would be filtering dates out of the web log\n\nThe following will get all HTTP requests starting on `05/Dec/2010` until the\nend of the file.\n\n    # sed -n '/05\\/Dec\\/2010/,$ p' access.log | goaccess -a -\n\nor using relative dates such as yesterdays or tomorrows day:\n\n    # sed -n '/'$(date '+%d\\/%b\\/%Y' -d '1 week ago')'/,$ p' access.log | goaccess -a -\n\nIf we want to parse only a certain time-frame from DATE a to DATE b, we can do:\n\n    # sed -n '/5\\/Nov\\/2010/,/5\\/Dec\\/2010/ p' access.log | goaccess -a -\n\nIf we want to preserve only certain amount of data and recycle storage, we can\nkeep only a certain number of days. For instance to keep & show the last 5\ndays:\n\n    # goaccess access.log --keep-last=5\n\n#### Virtual hosts ####\n\nAssuming your log contains the virtual host field. For instance:\n\n    vhost.io:80 8.8.4.4 - - [02/Mar/2016:08:14:04 -0600] \"GET /shop HTTP/1.1\" 200 615 \"-\" \"Googlebot-Image/1.0\"\n\nAnd you would like to append the virtual host to the request in order to see\nwhich virtual host the top urls belong to:\n\n    awk '$8=$1$8' access.log | goaccess -a -\n    \nTo do the same, but also use real-time filtering and parsing:\n\n    tail -f  access.log | unbuffer -p awk '$8=$1$8' | goaccess -a -\n\nTo exclude a list of virtual hosts you can do the following:\n\n    # grep -v \"`cat exclude_vhost_list_file`\" vhost_access.log | goaccess -\n\n#### Files, status codes and bots ####\n\nTo parse specific pages, e.g., page views, `html`, `htm`, `php`, etc. within a\nrequest:\n\n    # awk '$7~/\\.html|\\.htm|\\.php/' access.log | goaccess -\n\nNote, `$7` is the request field for the common and combined log format,\n(without Virtual Host), if your log includes Virtual Host, then you probably\nwant to use `$8` instead. It's best to check which field you are shooting for,\ne.g.:\n\n    # tail -10 access.log | awk '{print $8}'\n\nOr to parse a specific status code, e.g., 500 (Internal Server Error):\n\n    # awk '$9~/500/' access.log | goaccess -\n\nOr multiple status codes, e.g., all 3xx and 5xx:\n\n    # tail -f -n +0 access.log | awk '$9~/3[0-9]{2}|5[0-9]{2}/' | goaccess -o out.html -\n\nAnd to get an estimated overview of how many bots (crawlers) are hitting your server:\n\n    # tail -F -n +0 access.log | grep -i --line-buffered 'bot' | goaccess -\n\n### Tips ###\n\nAlso, it is worth pointing out that if we want to run GoAccess at lower\npriority, we can run it as:\n\n    # nice -n 19 goaccess -f access.log -a\n\nand if you don't want to install it on your server, you can still run it from\nyour local machine!\n\n    # ssh -n root@server 'tail -f /var/log/apache2/access.log' | goaccess -\n\n**Note:** SSH requires `-n` so GoAccess can read from stdin. Also, make sure to\nuse SSH keys for authentication as it won't work if a passphrase is required. \n\n#### Troubleshooting ####\n\nWe receive many questions and issues that have been answered previously.\n\n* Date/time matching problems? Check that your log format and the system locale in which you run GoAccess match. See [#1571](https://github.com/allinurl/goaccess/issues/1571#issuecomment-543186858)\n* Problems with pattern matching? Spaces are often a problem, see for instance [#136](https://github.com/allinurl/goaccess/issues/136), [#1579](https://github.com/allinurl/goaccess/issues/1579)\n* Other issues matching log entries: See [>200 closed issues regarding log/date/time formats](https://github.com/allinurl/goaccess/issues?q=is%3Aissue+is%3Aclosed+label%3A%22log%2Fdate%2Ftime+format%22)\n* Problems with log processing? See [>111 issues regarding log processing](https://github.com/allinurl/goaccess/issues?q=is%3Aissue+is%3Aclosed+label%3Alog-processing)\n\n\n#### Incremental log processing ####\n\nGoAccess has the ability to process logs incrementally through its internal\nstorage and dump its data to disk. It works in the following way:\n\n1. A dataset must be persisted first with `--persist`, then the same dataset\ncan be loaded with.\n2. `--restore`.  If new data is passed (piped or through a log file), it will\nappend it to the original dataset.\n\n##### NOTES #####\n\nGoAccess keeps track of inodes of all the files processed (assuming files will\nstay on the same partition), in addition, it extracts a snippet of data from\nthe log along with the last line parsed of each file and the timestamp of the\nlast line parsed. e.g., inode:29627417|line:20012|ts:20171231235059\n\nFirst, it compares if the snippet matches the log being parsed, if it does, it\nassumes the log hasn't changed drastically, e.g., hasn't been truncated. If\nthe inode does not match the current file, it parses all lines. If the current\nfile matches the inode, it then reads the remaining lines and updates the count\nof lines parsed and the timestamp. As an extra precaution, it won't parse log\nlines with a timestamp \u2264 than the one stored.\n\nPiped  data works based off the timestamp of the last line read. For instance,\nit will parse and discard all incoming entries until it finds a timestamp >=\nthan the one stored.\n\n##### Examples #####\n\n    // last month access log\n    # goaccess access.log.1 --persist\n\nthen, load it with\n\n    // append this month access log, and preserve new data\n    # goaccess access.log --restore --persist\n\nTo read persisted data only (without parsing new data)\n\n    # goaccess --restore\n\n## Contributing ##\n\nAny help on GoAccess is welcome. The most helpful way is to try it out and give\nfeedback. Feel free to use the Github issue tracker and pull requests to\ndiscuss and submit code changes.\n\nEnjoy!\n",
	"automl awesome best-of data-analysis data-science data-visualization data-visualizations deep-learning jax keras machine-learning ml nlp python python-library pytorch scikit-learn tensorflow transformer": "<!-- markdownlint-disable -->\n<h1 align=\"center\">\n    Best-of Machine Learning with Python\n    <br>\n</h1>\n\n<p align=\"center\">\n    <strong>\ud83c\udfc6&nbsp; A ranked list of awesome machine learning Python libraries. Updated weekly.</strong>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://github.com/ml-tooling/best-of\" title=\"Best-of-badge\"><img src=\"http://bit.ly/3o3EHNN\"></a>\n    <a href=\"#Contents\" title=\"Project Count\"><img src=\"https://img.shields.io/badge/projects-910-blue.svg?color=5ac4bf\"></a>\n    <a href=\"#Contribution\" title=\"Contributions are welcome\"><img src=\"https://img.shields.io/badge/contributions-welcome-green.svg\"></a>\n    <a href=\"https://github.com/ml-tooling/best-of-ml-python/releases\" title=\"Best-of Updates\"><img src=\"https://img.shields.io/github/release-date/ml-tooling/best-of-ml-python?color=green&label=updated\"></a>\n    <a href=\"https://mltooling.substack.com/subscribe\" title=\"Subscribe to newsletter\"><img src=\"http://bit.ly/2Md9rxM\"></a>\n    <a href=\"https://twitter.com/mltooling\" title=\"Follow on Twitter\"><img src=\"https://img.shields.io/twitter/follow/mltooling.svg?style=social&label=Follow\"></a>\n</p>\n\nThis curated list contains 910 awesome open-source projects with a total of 3.5M stars grouped into 34 categories. All projects are ranked by a project-quality score, which is calculated based on various metrics automatically collected from GitHub and different package managers. If you like to add or update projects, feel free to open an [issue](https://github.com/ml-tooling/best-of-ml-python/issues/new/choose), submit a [pull request](https://github.com/ml-tooling/best-of-ml-python/pulls), or directly edit the [projects.yaml](https://github.com/ml-tooling/best-of-ml-python/edit/main/projects.yaml). Contributions are very welcome!\n\n---\n\n<p align=\"center\">\n     \ud83e\uddd9\u200d\u2642\ufe0f&nbsp; Discover other <a href=\"https://best-of.org\">best-of lists</a> or create <a href=\"https://github.com/best-of-lists/best-of/blob/main/create-best-of-list.md\">your own</a>.<br>\n    \ud83d\udceb&nbsp; Subscribe to our <a href=\"https://mltooling.substack.com/subscribe\">newsletter</a> for updates and trending projects.\n</p>\n\n---\n\n\n## Contents\n\n- [Machine Learning Frameworks](#machine-learning-frameworks) _58 projects_\n- [Data Visualization](#data-visualization) _54 projects_\n- [Text Data & NLP](#text-data--nlp) _100 projects_\n- [Image Data](#image-data) _64 projects_\n- [Graph Data](#graph-data) _36 projects_\n- [Audio Data](#audio-data) _29 projects_\n- [Geospatial Data](#geospatial-data) _22 projects_\n- [Financial Data](#financial-data) _25 projects_\n- [Time Series Data](#time-series-data) _28 projects_\n- [Medical Data](#medical-data) _20 projects_\n- [Tabular Data](#tabular-data) _5 projects_\n- [Optical Character Recognition](#optical-character-recognition) _12 projects_\n- [Data Containers & Structures](#data-containers--structures) _1 projects_\n- [Data Loading & Extraction](#data-loading--extraction) _1 projects_\n- [Web Scraping & Crawling](#web-scraping--crawling) _1 projects_\n- [Data Pipelines & Streaming](#data-pipelines--streaming) _1 projects_\n- [Distributed Machine Learning](#distributed-machine-learning) _36 projects_\n- [Hyperparameter Optimization & AutoML](#hyperparameter-optimization--automl) _52 projects_\n- [Reinforcement Learning](#reinforcement-learning) _23 projects_\n- [Recommender Systems](#recommender-systems) _17 projects_\n- [Privacy Machine Learning](#privacy-machine-learning) _7 projects_\n- [Workflow & Experiment Tracking](#workflow--experiment-tracking) _39 projects_\n- [Model Serialization & Deployment](#model-serialization--deployment) _20 projects_\n- [Model Interpretability](#model-interpretability) _54 projects_\n- [Vector Similarity Search (ANN)](#vector-similarity-search-ann) _12 projects_\n- [Probabilistics & Statistics](#probabilistics--statistics) _23 projects_\n- [Adversarial Robustness](#adversarial-robustness) _9 projects_\n- [GPU & Accelerator Utilities](#gpu--accelerator-utilities) _20 projects_\n- [Tensorflow Utilities](#tensorflow-utilities) _16 projects_\n- [Jax Utilities](#jax-utilities) _3 projects_\n- [Sklearn Utilities](#sklearn-utilities) _19 projects_\n- [Pytorch Utilities](#pytorch-utilities) _32 projects_\n- [Database Clients](#database-clients) _1 projects_\n- [Others](#others) _65 projects_\n\n## Explanation\n- \ud83e\udd47\ud83e\udd48\ud83e\udd49&nbsp; Combined project-quality score\n- \u2b50\ufe0f&nbsp; Star count from GitHub\n- \ud83d\udc23&nbsp; New project _(less than 6 months old)_\n- \ud83d\udca4&nbsp; Inactive project _(6 months no activity)_\n- \ud83d\udc80&nbsp; Dead project _(12 months no activity)_\n- \ud83d\udcc8\ud83d\udcc9&nbsp; Project is trending up or down\n- \u2795&nbsp; Project was recently added\n- \u2757\ufe0f&nbsp; Warning _(e.g. missing/risky license)_\n- \ud83d\udc68\u200d\ud83d\udcbb&nbsp; Contributors count from GitHub\n- \ud83d\udd00&nbsp; Fork count from GitHub\n- \ud83d\udccb&nbsp; Issue count from GitHub\n- \u23f1\ufe0f&nbsp; Last update timestamp on package manager\n- \ud83d\udce5&nbsp; Download count from package manager\n- \ud83d\udce6&nbsp; Number of dependent projects\n- <img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\">&nbsp; Tensorflow related project\n- <img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\">&nbsp; Sklearn related project\n- <img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\">&nbsp; PyTorch related project\n- <img src=\"https://git.io/JLy1X\" style=\"display:inline;\" width=\"13\" height=\"13\">&nbsp; MxNet related project\n- <img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\">&nbsp; Apache Spark related project\n- <img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\">&nbsp; Jupyter related project\n- <img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\">&nbsp; PaddlePaddle related project\n- <img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\">&nbsp; Pandas related project\n- <img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\">&nbsp; Jax related project\n\n<br>\n\n## Machine Learning Frameworks\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_General-purpose machine learning and deep learning frameworks._\n\n<details><summary><b><a href=\"https://github.com/tensorflow/tensorflow\">Tensorflow</a></b> (\ud83e\udd4755 \u00b7  \u2b50 170K \u00b7 \ud83d\udcc8) - An Open Source Machine Learning Framework for Everyone. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/tensorflow) (\ud83d\udc68\u200d\ud83d\udcbb 4.2K \u00b7 \ud83d\udd00 87K \u00b7 \ud83d\udce6 230K \u00b7 \ud83d\udccb 36K - 6% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/tensorflow\n\t```\n- [PyPi](https://pypi.org/project/tensorflow) (\ud83d\udce5 15M / month \u00b7 \ud83d\udce6 14K \u00b7 \u23f1\ufe0f 18.11.2022):\n\t```\n\tpip install tensorflow\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensorflow) (\ud83d\udce5 3.8M \u00b7 \u23f1\ufe0f 25.09.2022):\n\t```\n\tconda install -c conda-forge tensorflow\n\t```\n- [Docker Hub](https://hub.docker.com/r/tensorflow/tensorflow) (\ud83d\udce5 70M \u00b7 \u2b50 2.1K \u00b7 \u23f1\ufe0f 24.11.2022):\n\t```\n\tdocker pull tensorflow/tensorflow\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/scikit-learn/scikit-learn\">scikit-learn</a></b> (\ud83e\udd4752 \u00b7  \u2b50 52K) - scikit-learn: machine learning in Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/scikit-learn/scikit-learn) (\ud83d\udc68\u200d\ud83d\udcbb 2.8K \u00b7 \ud83d\udd00 24K \u00b7 \ud83d\udce5 830 \u00b7 \ud83d\udce6 420K \u00b7 \ud83d\udccb 10K - 20% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/scikit-learn/scikit-learn\n\t```\n- [PyPi](https://pypi.org/project/scikit-learn) (\ud83d\udce5 35M / month \u00b7 \ud83d\udce6 26K \u00b7 \u23f1\ufe0f 05.08.2022):\n\t```\n\tpip install scikit-learn\n\t```\n- [Conda](https://anaconda.org/conda-forge/scikit-learn) (\ud83d\udce5 17M \u00b7 \u23f1\ufe0f 27.10.2022):\n\t```\n\tconda install -c conda-forge scikit-learn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/pytorch\">PyTorch</a></b> (\ud83e\udd4750 \u00b7  \u2b50 61K) - Tensors and Dynamic neural networks in Python with strong GPU.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pytorch/pytorch) (\ud83d\udc68\u200d\ud83d\udcbb 3.7K \u00b7 \ud83d\udd00 17K \u00b7 \ud83d\udce5 8.2K \u00b7 \ud83d\udccb 30K - 34% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/pytorch\n\t```\n- [PyPi](https://pypi.org/project/torch) (\ud83d\udce5 8.8M / month \u00b7 \ud83d\udce6 7.6K \u00b7 \u23f1\ufe0f 28.06.2022):\n\t```\n\tpip install torch\n\t```\n- [Conda](https://anaconda.org/pytorch/pytorch) (\ud83d\udce5 21M \u00b7 \u23f1\ufe0f 26.10.2022):\n\t```\n\tconda install -c pytorch pytorch\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/keras-team/keras\">Keras</a></b> (\ud83e\udd4745 \u00b7  \u2b50 57K) - Deep Learning for humans. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/keras-team/keras) (\ud83d\udc68\u200d\ud83d\udcbb 1.1K \u00b7 \ud83d\udd00 19K \u00b7 \ud83d\udccb 12K - 2% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/keras-team/keras\n\t```\n- [PyPi](https://pypi.org/project/keras) (\ud83d\udce5 9.8M / month \u00b7 \ud83d\udce6 330 \u00b7 \u23f1\ufe0f 13.05.2022):\n\t```\n\tpip install keras\n\t```\n- [Conda](https://anaconda.org/conda-forge/keras) (\ud83d\udce5 2.7M \u00b7 \u23f1\ufe0f 21.11.2022):\n\t```\n\tconda install -c conda-forge keras\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dmlc/xgboost\">XGBoost</a></b> (\ud83e\udd4744 \u00b7  \u2b50 23K) - Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/dmlc/xgboost) (\ud83d\udc68\u200d\ud83d\udcbb 580 \u00b7 \ud83d\udd00 8.5K \u00b7 \ud83d\udce5 5.5K \u00b7 \ud83d\udce6 39K \u00b7 \ud83d\udccb 4.7K - 7% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/dmlc/xgboost\n\t```\n- [PyPi](https://pypi.org/project/xgboost) (\ud83d\udce5 8.6M / month \u00b7 \ud83d\udce6 1.4K \u00b7 \u23f1\ufe0f 09.05.2022):\n\t```\n\tpip install xgboost\n\t```\n- [Conda](https://anaconda.org/conda-forge/xgboost) (\ud83d\udce5 3.4M \u00b7 \u23f1\ufe0f 07.11.2022):\n\t```\n\tconda install -c conda-forge xgboost\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/jax\">jax</a></b> (\ud83e\udd4744 \u00b7  \u2b50 21K) - Composable transformations of Python+NumPy programs: differentiate,.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/google/jax) (\ud83d\udc68\u200d\ud83d\udcbb 480 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce6 6.1K \u00b7 \ud83d\udccb 3.9K - 29% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/google/jax\n\t```\n- [PyPi](https://pypi.org/project/jax) (\ud83d\udce5 630K / month \u00b7 \ud83d\udce6 320 \u00b7 \u23f1\ufe0f 28.06.2022):\n\t```\n\tpip install jax\n\t```\n- [Conda](https://anaconda.org/conda-forge/jaxlib) (\ud83d\udce5 530K \u00b7 \u23f1\ufe0f 16.11.2022):\n\t```\n\tconda install -c conda-forge jaxlib\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/statsmodels/statsmodels\">StatsModels</a></b> (\ud83e\udd4744 \u00b7  \u2b50 7.9K) - Statsmodels: statistical modeling and econometrics in Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/statsmodels/statsmodels) (\ud83d\udc68\u200d\ud83d\udcbb 390 \u00b7 \ud83d\udd00 2.6K \u00b7 \ud83d\udce5 26 \u00b7 \ud83d\udce6 74K \u00b7 \ud83d\udccb 5K - 48% open \u00b7 \u23f1\ufe0f 13.11.2022):\n\n\t```\n\tgit clone https://github.com/statsmodels/statsmodels\n\t```\n- [PyPi](https://pypi.org/project/statsmodels) (\ud83d\udce5 9.5M / month \u00b7 \ud83d\udce6 4.7K \u00b7 \u23f1\ufe0f 08.02.2022):\n\t```\n\tpip install statsmodels\n\t```\n- [Conda](https://anaconda.org/conda-forge/statsmodels) (\ud83d\udce5 7.9M \u00b7 \u23f1\ufe0f 04.11.2022):\n\t```\n\tconda install -c conda-forge statsmodels\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/apache/spark\">PySpark</a></b> (\ud83e\udd4843 \u00b7  \u2b50 34K) - Apache Spark Python API. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/apache/spark) (\ud83d\udc68\u200d\ud83d\udcbb 2.8K \u00b7 \ud83d\udd00 26K \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/apache/spark\n\t```\n- [PyPi](https://pypi.org/project/pyspark) (\ud83d\udce5 28M / month \u00b7 \ud83d\udce6 850 \u00b7 \u23f1\ufe0f 15.06.2022):\n\t```\n\tpip install pyspark\n\t```\n- [Conda](https://anaconda.org/conda-forge/pyspark) (\ud83d\udce5 2.2M \u00b7 \u23f1\ufe0f 25.10.2022):\n\t```\n\tconda install -c conda-forge pyspark\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PaddlePaddle/Paddle\">PaddlePaddle</a></b> (\ud83e\udd4842 \u00b7  \u2b50 19K) - PArallel Distributed Deep LEarning: Machine Learning.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/PaddlePaddle/Paddle) (\ud83d\udc68\u200d\ud83d\udcbb 870 \u00b7 \ud83d\udd00 4.8K \u00b7 \ud83d\udce5 15K \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 17K - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/PaddlePaddle/Paddle\n\t```\n- [PyPi](https://pypi.org/project/paddlepaddle) (\ud83d\udce5 93K / month \u00b7 \ud83d\udce6 50 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install paddlepaddle\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/microsoft/LightGBM\">LightGBM</a></b> (\ud83e\udd4842 \u00b7  \u2b50 14K) - A fast, distributed, high performance gradient boosting (GBT, GBDT, GBRT,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/microsoft/LightGBM) (\ud83d\udc68\u200d\ud83d\udcbb 270 \u00b7 \ud83d\udd00 3.6K \u00b7 \ud83d\udce5 170K \u00b7 \ud83d\udce6 16K \u00b7 \ud83d\udccb 2.9K - 8% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/microsoft/LightGBM\n\t```\n- [PyPi](https://pypi.org/project/lightgbm) (\ud83d\udce5 6.9M / month \u00b7 \ud83d\udce6 640 \u00b7 \u23f1\ufe0f 07.01.2022):\n\t```\n\tpip install lightgbm\n\t```\n- [Conda](https://anaconda.org/conda-forge/lightgbm) (\ud83d\udce5 1.3M \u00b7 \u23f1\ufe0f 28.10.2022):\n\t```\n\tconda install -c conda-forge lightgbm\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/fastai/fastai\">Fastai</a></b> (\ud83e\udd4840 \u00b7  \u2b50 23K) - The fastai deep learning library. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/fastai/fastai) (\ud83d\udc68\u200d\ud83d\udcbb 650 \u00b7 \ud83d\udd00 7.3K \u00b7 \ud83d\udce6 12K \u00b7 \ud83d\udccb 1.7K - 7% open \u00b7 \u23f1\ufe0f 02.11.2022):\n\n\t```\n\tgit clone https://github.com/fastai/fastai\n\t```\n- [PyPi](https://pypi.org/project/fastai) (\ud83d\udce5 370K / month \u00b7 \ud83d\udce6 300 \u00b7 \u23f1\ufe0f 04.07.2022):\n\t```\n\tpip install fastai\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Lightning-AI/lightning\">pytorch-lightning</a></b> (\ud83e\udd4840 \u00b7  \u2b50 21K \u00b7 \ud83d\udcc9) - Build and train PyTorch models and connect them to.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/Lightning-AI/lightning) (\ud83d\udc68\u200d\ud83d\udcbb 800 \u00b7 \ud83d\udd00 2.7K \u00b7 \ud83d\udce5 9.4K \u00b7 \ud83d\udce6 120 \u00b7 \ud83d\udccb 5.7K - 10% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/Lightning-AI/lightning\n\t```\n- [PyPi](https://pypi.org/project/pytorch-lightning) (\ud83d\udce5 3M / month \u00b7 \ud83d\udce6 400 \u00b7 \u23f1\ufe0f 01.06.2022):\n\t```\n\tpip install pytorch-lightning\n\t```\n- [Conda](https://anaconda.org/conda-forge/pytorch-lightning) (\ud83d\udce5 610K \u00b7 \u23f1\ufe0f 23.09.2022):\n\t```\n\tconda install -c conda-forge pytorch-lightning\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/catboost/catboost\">Catboost</a></b> (\ud83e\udd4840 \u00b7  \u2b50 6.8K \u00b7 \ud83d\udcc8) - A fast, scalable, high performance Gradient Boosting on.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/catboost/catboost) (\ud83d\udc68\u200d\ud83d\udcbb 1K \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce5 100K \u00b7 \ud83d\udccb 1.9K - 23% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/catboost/catboost\n\t```\n- [PyPi](https://pypi.org/project/catboost) (\ud83d\udce5 2.4M / month \u00b7 \ud83d\udce6 240 \u00b7 \u23f1\ufe0f 19.05.2022):\n\t```\n\tpip install catboost\n\t```\n- [Conda](https://anaconda.org/conda-forge/catboost) (\ud83d\udce5 1.2M \u00b7 \u23f1\ufe0f 01.11.2022):\n\t```\n\tconda install -c conda-forge catboost\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jina-ai/jina\">Jina</a></b> (\ud83e\udd4839 \u00b7  \u2b50 17K) - The most advanced MLOps platform for multimodal AI on the cloud Neural.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/jina-ai/jina) (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 2K \u00b7 \ud83d\udce6 390 \u00b7 \ud83d\udccb 1.7K - 1% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/jina-ai/jina\n\t```\n- [PyPi](https://pypi.org/project/jina) (\ud83d\udce5 87K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 06.07.2022):\n\t```\n\tpip install jina\n\t```\n- [Conda](https://anaconda.org/conda-forge/jina-core) (\ud83d\udce5 31K \u00b7 \u23f1\ufe0f 16.08.2022):\n\t```\n\tconda install -c conda-forge jina-core\n\t```\n- [Docker Hub](https://hub.docker.com/r/jinaai/jina) (\ud83d\udce5 1.1M \u00b7 \u2b50 7 \u00b7 \u23f1\ufe0f 24.11.2022):\n\t```\n\tdocker pull jinaai/jina\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/apache/flink\">PyFlink</a></b> (\ud83e\udd4837 \u00b7  \u2b50 20K) - Apache Flink Python API. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/apache/flink) (\ud83d\udc68\u200d\ud83d\udcbb 1.7K \u00b7 \ud83d\udd00 11K \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/apache/flink\n\t```\n- [PyPi](https://pypi.org/project/apache-flink) (\ud83d\udce5 68K / month \u00b7 \ud83d\udce6 16 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install apache-flink\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/apache/mxnet\">MXNet</a></b> (\ud83e\udd4837 \u00b7  \u2b50 20K) - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1X\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/apache/mxnet) (\ud83d\udc68\u200d\ud83d\udcbb 980 \u00b7 \ud83d\udd00 6.9K \u00b7 \ud83d\udce5 26K \u00b7 \ud83d\udccb 9.5K - 18% open \u00b7 \u23f1\ufe0f 26.09.2022):\n\n\t```\n\tgit clone https://github.com/apache/incubator-mxnet\n\t```\n- [PyPi](https://pypi.org/project/mxnet) (\ud83d\udce5 400K / month \u00b7 \ud83d\udce6 280 \u00b7 \u23f1\ufe0f 17.05.2022):\n\t```\n\tpip install mxnet\n\t```\n- [Conda](https://anaconda.org/anaconda/mxnet) (\ud83d\udce5 8.5K \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 24.10.2022):\n\t```\n\tconda install -c anaconda mxnet\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Theano/Theano\">Theano</a></b> (\ud83e\udd4837 \u00b7  \u2b50 9.6K \u00b7 \ud83d\udca4) - Theano was a Python library that allows you to define, optimize, and.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/Theano/Theano) (\ud83d\udc68\u200d\ud83d\udcbb 380 \u00b7 \ud83d\udd00 2.5K \u00b7 \ud83d\udce6 13K \u00b7 \ud83d\udccb 2.8K - 24% open \u00b7 \u23f1\ufe0f 23.11.2021):\n\n\t```\n\tgit clone https://github.com/Theano/Theano\n\t```\n- [PyPi](https://pypi.org/project/theano) (\ud83d\udce5 270K / month \u00b7 \ud83d\udce6 2.8K \u00b7 \u23f1\ufe0f 27.07.2020):\n\t```\n\tpip install theano\n\t```\n- [Conda](https://anaconda.org/conda-forge/theano) (\ud83d\udce5 2.2M \u00b7 \u23f1\ufe0f 16.03.2022):\n\t```\n\tconda install -c conda-forge theano\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/flax\">Flax</a></b> (\ud83e\udd4836 \u00b7  \u2b50 3.8K) - Flax is a neural network library for JAX that is designed for.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/google/flax) (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 430 \u00b7 \ud83d\udce5 42 \u00b7 \ud83d\udce6 1.6K \u00b7 \ud83d\udccb 640 - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/google/flax\n\t```\n- [PyPi](https://pypi.org/project/flax) (\ud83d\udce5 250K / month \u00b7 \ud83d\udce6 75 \u00b7 \u23f1\ufe0f 21.06.2022):\n\t```\n\tpip install flax\n\t```\n- [Conda](https://anaconda.org/conda-forge/flax) (\ud83d\udce5 14K \u00b7 \u23f1\ufe0f 04.10.2022):\n\t```\n\tconda install -c conda-forge flax\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/explosion/thinc\">Thinc</a></b> (\ud83e\udd4836 \u00b7  \u2b50 2.6K) - A refreshing functional take on deep learning, compatible with your favorite.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/explosion/thinc) (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 25K \u00b7 \ud83d\udccb 140 - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/explosion/thinc\n\t```\n- [PyPi](https://pypi.org/project/thinc) (\ud83d\udce5 4M / month \u00b7 \ud83d\udce6 620 \u00b7 \u23f1\ufe0f 22.06.2022):\n\t```\n\tpip install thinc\n\t```\n- [Conda](https://anaconda.org/conda-forge/thinc) (\ud83d\udce5 2.3M \u00b7 \u23f1\ufe0f 15.11.2022):\n\t```\n\tconda install -c conda-forge thinc\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/VowpalWabbit/vowpal_wabbit\">Vowpal Wabbit</a></b> (\ud83e\udd4835 \u00b7  \u2b50 8.1K) - Vowpal Wabbit is a machine learning system which pushes the.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/VowpalWabbit/vowpal_wabbit) (\ud83d\udc68\u200d\ud83d\udcbb 320 \u00b7 \ud83d\udd00 1.8K \u00b7 \ud83d\udccb 1.2K - 12% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/VowpalWabbit/vowpal_wabbit\n\t```\n- [PyPi](https://pypi.org/project/vowpalwabbit) (\ud83d\udce5 120K / month \u00b7 \ud83d\udce6 31 \u00b7 \u23f1\ufe0f 06.04.2022):\n\t```\n\tpip install vowpalwabbit\n\t```\n- [Conda](https://anaconda.org/conda-forge/vowpalwabbit) (\ud83d\udce5 91K \u00b7 \u23f1\ufe0f 09.11.2022):\n\t```\n\tconda install -c conda-forge vowpalwabbit\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/chainer/chainer\">Chainer</a></b> (\ud83e\udd4835 \u00b7  \u2b50 5.7K) - A flexible framework of neural networks for deep learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/chainer/chainer) (\ud83d\udc68\u200d\ud83d\udcbb 320 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce6 2.8K \u00b7 \ud83d\udccb 2K - 0% open \u00b7 \u23f1\ufe0f 17.10.2022):\n\n\t```\n\tgit clone https://github.com/chainer/chainer\n\t```\n- [PyPi](https://pypi.org/project/chainer) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 400 \u00b7 \u23f1\ufe0f 05.01.2022):\n\t```\n\tpip install chainer\n\t```\n- [Conda](https://anaconda.org/conda-forge/chainer) (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 21.01.2022):\n\t```\n\tconda install -c conda-forge chainer\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/apple/turicreate\">Turi Create</a></b> (\ud83e\udd4933 \u00b7  \u2b50 11K \u00b7 \ud83d\udca4) - Turi Create simplifies the development of custom machine.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/apple/turicreate) (\ud83d\udc68\u200d\ud83d\udcbb 85 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce5 7.6K \u00b7 \ud83d\udce6 320 \u00b7 \ud83d\udccb 1.8K - 27% open \u00b7 \u23f1\ufe0f 29.11.2021):\n\n\t```\n\tgit clone https://github.com/apple/turicreate\n\t```\n- [PyPi](https://pypi.org/project/turicreate) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 30.09.2020):\n\t```\n\tpip install turicreate\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ludwig-ai/ludwig\">Ludwig</a></b> (\ud83e\udd4933 \u00b7  \u2b50 8.6K) - Data-centric declarative deep learning framework. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/ludwig-ai/ludwig) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udce6 140 \u00b7 \ud83d\udccb 890 - 25% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/ludwig-ai/ludwig\n\t```\n- [PyPi](https://pypi.org/project/ludwig) (\ud83d\udce5 1.5K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 25.06.2022):\n\t```\n\tpip install ludwig\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/unifyai/ivy\">ivy</a></b> (\ud83e\udd4933 \u00b7  \u2b50 7.6K) - The Unified Machine Learning Framework. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/unifyai/ivy) (\ud83d\udc68\u200d\ud83d\udcbb 580 \u00b7 \ud83d\udd00 2.5K \u00b7 \ud83d\udccb 3.5K - 16% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/unifyai/ivy\n\t```\n- [PyPi](https://pypi.org/project/ivy-core) (\ud83d\udce5 250 / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 01.06.2022):\n\t```\n\tpip install ivy-core\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/mlpack/mlpack\">mlpack</a></b> (\ud83e\udd4933 \u00b7  \u2b50 4.1K) - mlpack: a fast, header-only C++ machine learning library. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/mlpack/mlpack) (\ud83d\udc68\u200d\ud83d\udcbb 300 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udccb 1.5K - 2% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/mlpack/mlpack\n\t```\n- [PyPi](https://pypi.org/project/mlpack) (\ud83d\udce5 6K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 28.10.2020):\n\t```\n\tpip install mlpack\n\t```\n- [Conda](https://anaconda.org/conda-forge/mlpack) (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 11.11.2022):\n\t```\n\tconda install -c conda-forge mlpack\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ROCmSoftwarePlatform/tensorflow-upstream\">tensorflow-upstream</a></b> (\ud83e\udd4933 \u00b7  \u2b50 620) - TensorFlow ROCm port. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream) (\ud83d\udc68\u200d\ud83d\udcbb 4.2K \u00b7 \ud83d\udd00 74 \u00b7 \ud83d\udce5 20 \u00b7 \ud83d\udccb 340 - 19% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/ROCmSoftwarePlatform/tensorflow-upstream\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-rocm) (\ud83d\udce5 2.9K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 05.06.2022):\n\t```\n\tpip install tensorflow-rocm\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorpack/tensorpack\">tensorpack</a></b> (\ud83e\udd4932 \u00b7  \u2b50 6.2K) - A Neural Net Training Interface on TensorFlow, with focus.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorpack/tensorpack) (\ud83d\udc68\u200d\ud83d\udcbb 58 \u00b7 \ud83d\udd00 1.8K \u00b7 \ud83d\udce5 140 \u00b7 \ud83d\udce6 1.1K \u00b7 \ud83d\udccb 1.4K - 0% open \u00b7 \u23f1\ufe0f 04.05.2022):\n\n\t```\n\tgit clone https://github.com/tensorpack/tensorpack\n\t```\n- [PyPi](https://pypi.org/project/tensorpack) (\ud83d\udce5 15K / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 22.01.2021):\n\t```\n\tpip install tensorpack\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensorpack) (\ud83d\udce5 5.3K \u00b7 \u23f1\ufe0f 06.02.2022):\n\t```\n\tconda install -c conda-forge tensorpack\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/arogozhnikov/einops\">einops</a></b> (\ud83e\udd4932 \u00b7  \u2b50 6K) - Deep learning operations reinvented (for pytorch, tensorflow, jax and others). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/arogozhnikov/einops) (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udccb 130 - 25% open \u00b7 \u23f1\ufe0f 09.11.2022):\n\n\t```\n\tgit clone https://github.com/arogozhnikov/einops\n\t```\n- [PyPi](https://pypi.org/project/einops) (\ud83d\udce5 1.9M / month \u00b7 \ud83d\udce6 260 \u00b7 \u23f1\ufe0f 04.03.2022):\n\t```\n\tpip install einops\n\t```\n- [Conda](https://anaconda.org/conda-forge/einops) (\ud83d\udce5 51K \u00b7 \u23f1\ufe0f 04.03.2022):\n\t```\n\tconda install -c conda-forge einops\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deepmind/sonnet\">Sonnet</a></b> (\ud83e\udd4931 \u00b7  \u2b50 9.4K) - TensorFlow-based neural network library. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/deepmind/sonnet) (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 1.3K \u00b7 \ud83d\udce6 940 \u00b7 \ud83d\udccb 180 - 15% open \u00b7 \u23f1\ufe0f 02.11.2022):\n\n\t```\n\tgit clone https://github.com/deepmind/sonnet\n\t```\n- [PyPi](https://pypi.org/project/dm-sonnet) (\ud83d\udce5 19K / month \u00b7 \ud83d\udce6 52 \u00b7 \u23f1\ufe0f 27.03.2020):\n\t```\n\tpip install dm-sonnet\n\t```\n- [Conda](https://anaconda.org/conda-forge/sonnet) (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 14.11.2020):\n\t```\n\tconda install -c conda-forge sonnet\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/skorch-dev/skorch\">skorch</a></b> (\ud83e\udd4931 \u00b7  \u2b50 4.8K) - A scikit-learn compatible neural network library that wraps.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/skorch-dev/skorch) (\ud83d\udc68\u200d\ud83d\udcbb 52 \u00b7 \ud83d\udd00 330 \u00b7 \ud83d\udce6 600 \u00b7 \ud83d\udccb 460 - 11% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/skorch-dev/skorch\n\t```\n- [PyPi](https://pypi.org/project/skorch) (\ud83d\udce5 59K / month \u00b7 \ud83d\udce6 41 \u00b7 \u23f1\ufe0f 31.10.2021):\n\t```\n\tpip install skorch\n\t```\n- [Conda](https://anaconda.org/conda-forge/skorch) (\ud83d\udce5 670K \u00b7 \u23f1\ufe0f 30.11.2021):\n\t```\n\tconda install -c conda-forge skorch\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/clab/dynet\">dyNET</a></b> (\ud83e\udd4931 \u00b7  \u2b50 3.3K) - DyNet: The Dynamic Neural Network Toolkit. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/clab/dynet) (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 700 \u00b7 \ud83d\udce5 7.9K \u00b7 \ud83d\udce6 230 \u00b7 \ud83d\udccb 930 - 28% open \u00b7 \u23f1\ufe0f 14.08.2022):\n\n\t```\n\tgit clone https://github.com/clab/dynet\n\t```\n- [PyPi](https://pypi.org/project/dyNET) (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 28 \u00b7 \u23f1\ufe0f 21.10.2020):\n\t```\n\tpip install dyNET\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/microsoft/CNTK\">CNTK</a></b> (\ud83e\udd4930 \u00b7  \u2b50 17K) - Microsoft Cognitive Toolkit (CNTK), an open source deep-learning toolkit. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/microsoft/CNTK) (\ud83d\udc68\u200d\ud83d\udcbb 270 \u00b7 \ud83d\udd00 4.4K \u00b7 \ud83d\udce5 14K \u00b7 \ud83d\udccb 3.4K - 24% open \u00b7 \u23f1\ufe0f 23.09.2022):\n\n\t```\n\tgit clone https://github.com/microsoft/CNTK\n\t```\n- [PyPi](https://pypi.org/project/cntk) (\ud83d\udce5 900 / month \u00b7 \ud83d\udce6 18 \u00b7 \u23f1\ufe0f 09.12.2020):\n\t```\n\tpip install cntk\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/ignite\">Ignite</a></b> (\ud83e\udd4930 \u00b7  \u2b50 4.1K) - High-level library to help with training and evaluating neural.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pytorch/ignite) (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 560 \u00b7 \ud83d\udccb 1.2K - 12% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/ignite\n\t```\n- [PyPi](https://pypi.org/project/pytorch-ignite) (\ud83d\udce5 81K / month \u00b7 \u23f1\ufe0f 08.11.2022):\n\t```\n\tpip install pytorch-ignite\n\t```\n- [Conda](https://anaconda.org/pytorch/ignite) (\ud83d\udce5 110K \u00b7 \u23f1\ufe0f 05.09.2022):\n\t```\n\tconda install -c pytorch ignite\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/sony/nnabla\">Neural Network Libraries</a></b> (\ud83e\udd4930 \u00b7  \u2b50 2.6K) - Neural Network Libraries. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/sony/nnabla) (\ud83d\udc68\u200d\ud83d\udcbb 69 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce5 540 \u00b7 \ud83d\udccb 92 - 40% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/sony/nnabla\n\t```\n- [PyPi](https://pypi.org/project/nnabla) (\ud83d\udce5 2.6K / month \u00b7 \ud83d\udce6 51 \u00b7 \u23f1\ufe0f 19.06.2022):\n\t```\n\tpip install nnabla\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deepmind/dm-haiku\">Haiku</a></b> (\ud83e\udd4930 \u00b7  \u2b50 2.3K) - JAX-based neural network library. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/deepmind/dm-haiku) (\ud83d\udc68\u200d\ud83d\udcbb 68 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 630 \u00b7 \ud83d\udccb 240 - 38% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/deepmind/dm-haiku\n\t```\n- [PyPi](https://pypi.org/project/dm-haiku) (\ud83d\udce5 130K / month \u00b7 \ud83d\udce6 42 \u00b7 \u23f1\ufe0f 04.07.2022):\n\t```\n\tpip install dm-haiku\n\t```\n- [Conda](https://anaconda.org/conda-forge/dm-haiku) (\ud83d\udce5 6.9K \u00b7 \u23f1\ufe0f 21.09.2022):\n\t```\n\tconda install -c conda-forge dm-haiku\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/amaiya/ktrain\">ktrain</a></b> (\ud83e\udd4929 \u00b7  \u2b50 1.1K) - ktrain is a Python library that makes deep learning and AI more.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/amaiya/ktrain) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 350 \u00b7 \ud83d\udccb 430 - 0% open \u00b7 \u23f1\ufe0f 08.11.2022):\n\n\t```\n\tgit clone https://github.com/amaiya/ktrain\n\t```\n- [PyPi](https://pypi.org/project/ktrain) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 20.05.2022):\n\t```\n\tpip install ktrain\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/towhee-io/towhee\">Towhee</a></b> (\ud83e\udd4927 \u00b7  \u2b50 1.6K) - Towhee is a framework that is dedicated to making neural data.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/towhee-io/towhee) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce5 250 \u00b7 \ud83d\udccb 520 - 2% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/towhee-io/towhee\n\t```\n- [PyPi](https://pypi.org/project/towhee) (\ud83d\udce5 670 / month \u00b7 \u23f1\ufe0f 07.07.2022):\n\t```\n\tpip install towhee\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/neural-tangents\">Neural Tangents</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.9K) - Fast and Easy Infinite Neural Networks in Python. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/google/neural-tangents) (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 210 \u00b7 \ud83d\udce5 260 \u00b7 \ud83d\udce6 54 \u00b7 \ud83d\udccb 130 - 38% open \u00b7 \u23f1\ufe0f 18.10.2022):\n\n\t```\n\tgit clone https://github.com/google/neural-tangents\n\t```\n- [PyPi](https://pypi.org/project/neural-tangents) (\ud83d\udce5 4.9K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 23.02.2022):\n\t```\n\tpip install neural-tangents\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/geomstats/geomstats\">Geomstats</a></b> (\ud83e\udd4926 \u00b7  \u2b50 860) - Computations and statistics on manifolds with geometric structures. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/geomstats/geomstats) (\ud83d\udc68\u200d\ud83d\udcbb 72 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udccb 470 - 37% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/geomstats/geomstats\n\t```\n- [PyPi](https://pypi.org/project/geomstats) (\ud83d\udce5 760 / month \u00b7 \u23f1\ufe0f 22.04.2022):\n\t```\n\tpip install geomstats\n\t```\n- [Conda](https://anaconda.org/conda-forge/geomstats) (\ud83d\udce5 810 \u00b7 \u23f1\ufe0f 01.06.2022):\n\t```\n\tconda install -c conda-forge geomstats\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/aksnzhy/xlearn\">xLearn</a></b> (\ud83e\udd4925 \u00b7  \u2b50 3K) - High performance, easy-to-use, and scalable machine learning (ML).. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/aksnzhy/xlearn) (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 530 \u00b7 \ud83d\udce5 3.5K \u00b7 \ud83d\udce6 99 \u00b7 \ud83d\udccb 310 - 62% open \u00b7 \u23f1\ufe0f 05.06.2022):\n\n\t```\n\tgit clone https://github.com/aksnzhy/xlearn\n\t```\n- [PyPi](https://pypi.org/project/xlearn) (\ud83d\udce5 4.1K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 04.12.2018):\n\t```\n\tpip install xlearn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nubank/fklearn\">fklearn</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.4K) - fklearn: Functional Machine Learning. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/nubank/fklearn) (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 13 \u00b7 \ud83d\udccb 59 - 61% open \u00b7 \u23f1\ufe0f 21.10.2022):\n\n\t```\n\tgit clone https://github.com/nubank/fklearn\n\t```\n- [PyPi](https://pypi.org/project/fklearn) (\ud83d\udce5 2.7K / month \u00b7 \u23f1\ufe0f 30.12.2021):\n\t```\n\tpip install fklearn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/XiaoMi/mace\">mace</a></b> (\ud83e\udd4922 \u00b7  \u2b50 4.7K) - MACE is a deep learning inference framework optimized for mobile.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/XiaoMi/mace) (\ud83d\udc68\u200d\ud83d\udcbb 64 \u00b7 \ud83d\udd00 810 \u00b7 \ud83d\udce5 1.4K \u00b7 \ud83d\udccb 670 - 8% open \u00b7 \u23f1\ufe0f 30.05.2022):\n\n\t```\n\tgit clone https://github.com/XiaoMi/mace\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/objax\">Objax</a></b> (\ud83e\udd4922 \u00b7  \u2b50 720) - Objax is a machine learning framework that provides an Object.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/google/objax) (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 67 \u00b7 \ud83d\udce6 25 \u00b7 \ud83d\udccb 110 - 43% open \u00b7 \u23f1\ufe0f 30.08.2022):\n\n\t```\n\tgit clone https://github.com/google/objax\n\t```\n- [PyPi](https://pypi.org/project/objax) (\ud83d\udce5 1.7K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 31.01.2022):\n\t```\n\tpip install objax\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Xtra-Computing/thundersvm\">ThunderSVM</a></b> (\ud83e\udd4920 \u00b7  \u2b50 1.4K \u00b7 \ud83d\udca4) - ThunderSVM: A Fast SVM Library on GPUs and CPUs. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Xtra-Computing/thundersvm) (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce5 2.5K \u00b7 \ud83d\udccb 210 - 29% open \u00b7 \u23f1\ufe0f 09.04.2022):\n\n\t```\n\tgit clone https://github.com/Xtra-Computing/thundersvm\n\t```\n- [PyPi](https://pypi.org/project/thundersvm) (\ud83d\udce5 330 / month \u00b7 \u23f1\ufe0f 13.03.2020):\n\t```\n\tpip install thundersvm\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/neoml-lib/neoml\">NeoML</a></b> (\ud83e\udd4920 \u00b7  \u2b50 700) - Machine learning framework for both deep learning and traditional.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/neoml-lib/neoml) (\ud83d\udc68\u200d\ud83d\udcbb 32 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udccb 78 - 37% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/neoml-lib/neoml\n\t```\n- [PyPi](https://pypi.org/project/neoml) (\ud83d\udce5 75 / month \u00b7 \u23f1\ufe0f 31.05.2022):\n\t```\n\tpip install neoml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/serengil/chefboost\">chefboost</a></b> (\ud83e\udd4919 \u00b7  \u2b50 370) - A Lightweight Decision Tree Framework supporting regular algorithms:.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/serengil/chefboost) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 92 \u00b7 \ud83d\udce6 29 \u00b7 \ud83d\udccb 31 - 16% open \u00b7 \u23f1\ufe0f 21.05.2022):\n\n\t```\n\tgit clone https://github.com/serengil/chefboost\n\t```\n- [PyPi](https://pypi.org/project/chefboost) (\ud83d\udce5 1.6K / month \u00b7 \u23f1\ufe0f 16.02.2022):\n\t```\n\tpip install chefboost\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Xtra-Computing/thundergbm\">ThunderGBM</a></b> (\ud83e\udd4917 \u00b7  \u2b50 650) - ThunderGBM: Fast GBDTs and Random Forests on GPUs. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Xtra-Computing/thundergbm) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 84 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 75 - 44% open \u00b7 \u23f1\ufe0f 13.09.2022):\n\n\t```\n\tgit clone https://github.com/Xtra-Computing/thundergbm\n\t```\n- [PyPi](https://pypi.org/project/thundergbm) (\ud83d\udce5 130 / month \u00b7 \u23f1\ufe0f 01.05.2020):\n\t```\n\tpip install thundergbm\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/poets-ai/elegy\">elegy</a></b> (\ud83e\udd4917 \u00b7  \u2b50 420) - A High Level API for Deep Learning in JAX. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/poets-ai/elegy) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 26 \u00b7 \ud83d\udccb 100 - 35% open \u00b7 \u23f1\ufe0f 23.05.2022):\n\n\t```\n\tgit clone https://github.com/poets-ai/elegy\n\t```\n- [PyPi](https://pypi.org/project/elegy) (\ud83d\udce5 330 / month \u00b7 \u23f1\ufe0f 22.04.2022):\n\t```\n\tpip install elegy\n\t```\n</details>\n<details><summary>Show 10 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/davisking/dlib\">dlib</a></b> (\ud83e\udd4838 \u00b7  \u2b50 12K) - A toolkit for making real world machine learning and data analysis.. <code><a href=\"https://tldrlegal.com/search?q=BSL-1.0\">\u2757\ufe0fBSL-1.0</a></code>\n- <b><a href=\"https://github.com/mindsdb/mindsdb\">MindsDB</a></b> (\ud83e\udd4834 \u00b7  \u2b50 11K) - In-Database Machine Learning. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/tflearn/tflearn\">TFlearn</a></b> (\ud83e\udd4932 \u00b7  \u2b50 9.6K \u00b7 \ud83d\udc80) - Deep learning library featuring a higher-level API for TensorFlow. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/numenta/nupic\">NuPIC</a></b> (\ud83e\udd4928 \u00b7  \u2b50 6.3K \u00b7 \ud83d\udc80) - Numenta Platform for Intelligent Computing is an implementation.. <code><a href=\"http://bit.ly/3pwmjO5\">\u2757\ufe0fAGPL-3.0</a></code>\n- <b><a href=\"https://github.com/Lasagne/Lasagne\">Lasagne</a></b> (\ud83e\udd4928 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udc80) - Lightweight library to build and train neural networks in Theano. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/shogun-toolbox/shogun\">SHOGUN</a></b> (\ud83e\udd4926 \u00b7  \u2b50 2.9K \u00b7 \ud83d\udc80) - Unified and efficient Machine Learning. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/itdxer/neupy\">NeuPy</a></b> (\ud83e\udd4925 \u00b7  \u2b50 730 \u00b7 \ud83d\udc80) - NeuPy is a Tensorflow based python library for prototyping and building.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/NervanaSystems/neon\">neon</a></b> (\ud83e\udd4922 \u00b7  \u2b50 3.9K \u00b7 \ud83d\udc80) - Intel Nervana reference deep learning framework committed to best.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/pytorchbearer/torchbearer\">Torchbearer</a></b> (\ud83e\udd4921 \u00b7  \u2b50 630 \u00b7 \ud83d\udc80) - torchbearer: A model fitting library for PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/facebookresearch/StarSpace\">StarSpace</a></b> (\ud83e\udd4916 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udc80) - Learning embeddings for classification, retrieval and ranking. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n</details>\n<br>\n\n## Data Visualization\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_General-purpose and task-specific data visualization libraries._\n\n<details><summary><b><a href=\"https://github.com/matplotlib/matplotlib\">Matplotlib</a></b> (\ud83e\udd4749 \u00b7  \u2b50 16K) - matplotlib: plotting with Python. <code><a href=\"http://bit.ly/35wkF7y\">Python-2.0</a></code></summary>\n\n- [GitHub](https://github.com/matplotlib/matplotlib) (\ud83d\udc68\u200d\ud83d\udcbb 1.4K \u00b7 \ud83d\udd00 6.6K \u00b7 \ud83d\udce6 660K \u00b7 \ud83d\udccb 9.4K - 20% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/matplotlib/matplotlib\n\t```\n- [PyPi](https://pypi.org/project/matplotlib) (\ud83d\udce5 32M / month \u00b7 \ud83d\udce6 55K \u00b7 \u23f1\ufe0f 08.10.2022):\n\t```\n\tpip install matplotlib\n\t```\n- [Conda](https://anaconda.org/conda-forge/matplotlib) (\ud83d\udce5 15M \u00b7 \u23f1\ufe0f 04.11.2022):\n\t```\n\tconda install -c conda-forge matplotlib\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/bokeh/bokeh\">Bokeh</a></b> (\ud83e\udd4743 \u00b7  \u2b50 17K) - Interactive Data Visualization in the browser, from Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/bokeh/bokeh) (\ud83d\udc68\u200d\ud83d\udcbb 620 \u00b7 \ud83d\udd00 4K \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 7.1K - 9% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/bokeh/bokeh\n\t```\n- [PyPi](https://pypi.org/project/bokeh) (\ud83d\udce5 3.6M / month \u00b7 \ud83d\udce6 3.6K \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install bokeh\n\t```\n- [Conda](https://anaconda.org/conda-forge/bokeh) (\ud83d\udce5 9.3M \u00b7 \u23f1\ufe0f 15.11.2022):\n\t```\n\tconda install -c conda-forge bokeh\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/mwaskom/seaborn\">Seaborn</a></b> (\ud83e\udd4742 \u00b7  \u2b50 10K) - Statistical data visualization in Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/mwaskom/seaborn) (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce5 240 \u00b7 \ud83d\udccb 2.2K - 4% open \u00b7 \u23f1\ufe0f 14.11.2022):\n\n\t```\n\tgit clone https://github.com/mwaskom/seaborn\n\t```\n- [PyPi](https://pypi.org/project/seaborn) (\ud83d\udce5 8.6M / month \u00b7 \ud83d\udce6 9.4K \u00b7 \u23f1\ufe0f 27.06.2022):\n\t```\n\tpip install seaborn\n\t```\n- [Conda](https://anaconda.org/conda-forge/seaborn) (\ud83d\udce5 5.2M \u00b7 \u23f1\ufe0f 18.10.2022):\n\t```\n\tconda install -c conda-forge seaborn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/plotly/plotly.py\">Plotly</a></b> (\ud83e\udd4741 \u00b7  \u2b50 12K) - The interactive graphing library for Python (includes Plotly Express). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/plotly/plotly.py) (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 2.2K \u00b7 \ud83d\udce6 13 \u00b7 \ud83d\udccb 2.5K - 51% open \u00b7 \u23f1\ufe0f 27.10.2022):\n\n\t```\n\tgit clone https://github.com/plotly/plotly.py\n\t```\n- [PyPi](https://pypi.org/project/plotly) (\ud83d\udce5 8.5M / month \u00b7 \ud83d\udce6 4.1K \u00b7 \u23f1\ufe0f 24.06.2022):\n\t```\n\tpip install plotly\n\t```\n- [Conda](https://anaconda.org/conda-forge/plotly) (\ud83d\udce5 3.4M \u00b7 \u23f1\ufe0f 29.10.2022):\n\t```\n\tconda install -c conda-forge plotly\n\t```\n- [npm](https://www.npmjs.com/package/plotlywidget) (\ud83d\udce5 45K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 12.01.2021):\n\t```\n\tnpm install plotlywidget\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/plotly/dash\">dash</a></b> (\ud83e\udd4740 \u00b7  \u2b50 18K) - Analytical Web Apps for Python, R, Julia, and Jupyter. No JavaScript Required. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/plotly/dash) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 1.8K \u00b7 \ud83d\udce6 37K \u00b7 \ud83d\udccb 1.4K - 49% open \u00b7 \u23f1\ufe0f 07.11.2022):\n\n\t```\n\tgit clone https://github.com/plotly/dash\n\t```\n- [PyPi](https://pypi.org/project/dash) (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 1.2K \u00b7 \u23f1\ufe0f 13.06.2022):\n\t```\n\tpip install dash\n\t```\n- [Conda](https://anaconda.org/conda-forge/dash) (\ud83d\udce5 710K \u00b7 \u23f1\ufe0f 03.11.2022):\n\t```\n\tconda install -c conda-forge dash\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ydataai/pandas-profiling\">pandas-profiling</a></b> (\ud83e\udd4739 \u00b7  \u2b50 9.9K) - Create HTML profiling reports from pandas DataFrame.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/ydataai/pandas-profiling) (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce6 9.7K \u00b7 \ud83d\udccb 630 - 21% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/ydataai/pandas-profiling\n\t```\n- [PyPi](https://pypi.org/project/pandas-profiling) (\ud83d\udce5 1M / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 27.09.2021):\n\t```\n\tpip install pandas-profiling\n\t```\n- [Conda](https://anaconda.org/conda-forge/pandas-profiling) (\ud83d\udce5 310K \u00b7 \u23f1\ufe0f 23.11.2022):\n\t```\n\tconda install -c conda-forge pandas-profiling\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/altair-viz/altair\">Altair</a></b> (\ud83e\udd4739 \u00b7  \u2b50 7.9K) - Declarative statistical visualization library for Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/altair-viz/altair) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 700 \u00b7 \ud83d\udce6 38K \u00b7 \ud83d\udccb 1.7K - 14% open \u00b7 \u23f1\ufe0f 18.11.2022):\n\n\t```\n\tgit clone https://github.com/altair-viz/altair\n\t```\n- [PyPi](https://pypi.org/project/altair) (\ud83d\udce5 9.2M / month \u00b7 \ud83d\udce6 340 \u00b7 \u23f1\ufe0f 29.12.2021):\n\t```\n\tpip install altair\n\t```\n- [Conda](https://anaconda.org/conda-forge/altair) (\ud83d\udce5 1.5M \u00b7 \u23f1\ufe0f 29.12.2021):\n\t```\n\tconda install -c conda-forge altair\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pyqtgraph/pyqtgraph\">PyQtGraph</a></b> (\ud83e\udd4836 \u00b7  \u2b50 3K) - Fast data visualization and GUI tools for scientific / engineering.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/pyqtgraph/pyqtgraph) (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 970 \u00b7 \ud83d\udccb 1.1K - 29% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/pyqtgraph/pyqtgraph\n\t```\n- [PyPi](https://pypi.org/project/pyqtgraph) (\ud83d\udce5 150K / month \u00b7 \ud83d\udce6 820 \u00b7 \u23f1\ufe0f 04.03.2022):\n\t```\n\tpip install pyqtgraph\n\t```\n- [Conda](https://anaconda.org/conda-forge/pyqtgraph) (\ud83d\udce5 320K \u00b7 \u23f1\ufe0f 03.10.2022):\n\t```\n\tconda install -c conda-forge pyqtgraph\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/lmcinnes/umap\">UMAP</a></b> (\ud83e\udd4835 \u00b7  \u2b50 5.9K) - Uniform Manifold Approximation and Projection. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/lmcinnes/umap) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 690 \u00b7 \ud83d\udce6 6.7K \u00b7 \ud83d\udccb 670 - 54% open \u00b7 \u23f1\ufe0f 11.11.2022):\n\n\t```\n\tgit clone https://github.com/lmcinnes/umap\n\t```\n- [PyPi](https://pypi.org/project/umap-learn) (\ud83d\udce5 810K / month \u00b7 \ud83d\udce6 330 \u00b7 \u23f1\ufe0f 13.04.2022):\n\t```\n\tpip install umap-learn\n\t```\n- [Conda](https://anaconda.org/conda-forge/umap-learn) (\ud83d\udce5 1.5M \u00b7 \u23f1\ufe0f 14.04.2022):\n\t```\n\tconda install -c conda-forge umap-learn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/holoviz/holoviews\">HoloViews</a></b> (\ud83e\udd4835 \u00b7  \u2b50 2.3K) - With Holoviews, your data visualizes itself. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/holoviz/holoviews) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udccb 2.9K - 32% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/holoviz/holoviews\n\t```\n- [PyPi](https://pypi.org/project/holoviews) (\ud83d\udce5 520K / month \u00b7 \ud83d\udce6 220 \u00b7 \u23f1\ufe0f 07.07.2022):\n\t```\n\tpip install holoviews\n\t```\n- [Conda](https://anaconda.org/conda-forge/holoviews) (\ud83d\udce5 980K \u00b7 \u23f1\ufe0f 04.11.2022):\n\t```\n\tconda install -c conda-forge holoviews\n\t```\n- [npm](https://www.npmjs.com/package/@pyviz/jupyterlab_pyviz) (\ud83d\udce5 1K / month \u00b7 \u23f1\ufe0f 24.05.2020):\n\t```\n\tnpm install @pyviz/jupyterlab_pyviz\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pyecharts/pyecharts\">pyecharts</a></b> (\ud83e\udd4834 \u00b7  \u2b50 13K) - Python Echarts Plotting Library. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pyecharts/pyecharts) (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 2.7K \u00b7 \ud83d\udce6 2.6K \u00b7 \ud83d\udccb 1.6K - 2% open \u00b7 \u23f1\ufe0f 30.08.2022):\n\n\t```\n\tgit clone https://github.com/pyecharts/pyecharts\n\t```\n- [PyPi](https://pypi.org/project/pyecharts) (\ud83d\udce5 74K / month \u00b7 \ud83d\udce6 220 \u00b7 \u23f1\ufe0f 16.11.2021):\n\t```\n\tpip install pyecharts\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/has2k1/plotnine\">plotnine</a></b> (\ud83e\udd4834 \u00b7  \u2b50 3.3K) - A grammar of graphics for Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/has2k1/plotnine) (\ud83d\udc68\u200d\ud83d\udcbb 99 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udccb 530 - 13% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/has2k1/plotnine\n\t```\n- [PyPi](https://pypi.org/project/plotnine) (\ud83d\udce5 440K / month \u00b7 \ud83d\udce6 220 \u00b7 \u23f1\ufe0f 01.07.2022):\n\t```\n\tpip install plotnine\n\t```\n- [Conda](https://anaconda.org/conda-forge/plotnine) (\ud83d\udce5 220K \u00b7 \u23f1\ufe0f 10.10.2022):\n\t```\n\tconda install -c conda-forge plotnine\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/vispy/vispy\">VisPy</a></b> (\ud83e\udd4834 \u00b7  \u2b50 3K) - High-performance interactive 2D/3D data visualization library. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/vispy/vispy) (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 600 \u00b7 \ud83d\udce6 910 \u00b7 \ud83d\udccb 1.4K - 22% open \u00b7 \u23f1\ufe0f 14.11.2022):\n\n\t```\n\tgit clone https://github.com/vispy/vispy\n\t```\n- [PyPi](https://pypi.org/project/vispy) (\ud83d\udce5 50K / month \u00b7 \ud83d\udce6 100 \u00b7 \u23f1\ufe0f 04.07.2022):\n\t```\n\tpip install vispy\n\t```\n- [Conda](https://anaconda.org/conda-forge/vispy) (\ud83d\udce5 310K \u00b7 \u23f1\ufe0f 14.11.2022):\n\t```\n\tconda install -c conda-forge vispy\n\t```\n- [npm](https://www.npmjs.com/package/vispy) (\ud83d\udce5 21 / month \u00b7 \u23f1\ufe0f 15.03.2020):\n\t```\n\tnpm install vispy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/voxel51/fiftyone\">FiftyOne</a></b> (\ud83e\udd4834 \u00b7  \u2b50 2.2K) - Visualize, create, and debug image and video datasets.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/voxel51/fiftyone) (\ud83d\udc68\u200d\ud83d\udcbb 63 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 200 \u00b7 \ud83d\udccb 1K - 35% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/voxel51/fiftyone\n\t```\n- [PyPi](https://pypi.org/project/fiftyone) (\ud83d\udce5 48K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 24.06.2022):\n\t```\n\tpip install fiftyone\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/xflr6/graphviz\">Graphviz</a></b> (\ud83e\udd4834 \u00b7  \u2b50 1.3K) - Simple Python interface for Graphviz. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/xflr6/graphviz) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 37K \u00b7 \ud83d\udccb 140 - 4% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/xflr6/graphviz\n\t```\n- [PyPi](https://pypi.org/project/graphviz) (\ud83d\udce5 8.9M / month \u00b7 \ud83d\udce6 3K \u00b7 \u23f1\ufe0f 16.04.2022):\n\t```\n\tpip install graphviz\n\t```\n- [Conda](https://anaconda.org/anaconda/python-graphviz) (\ud83d\udce5 31K \u00b7 \u23f1\ufe0f 10.08.2022):\n\t```\n\tconda install -c anaconda python-graphviz\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/amueller/word_cloud\">wordcloud</a></b> (\ud83e\udd4832 \u00b7  \u2b50 9.1K) - A little word cloud generator in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/amueller/word_cloud) (\ud83d\udc68\u200d\ud83d\udcbb 65 \u00b7 \ud83d\udd00 2.2K \u00b7 \ud83d\udccb 500 - 25% open \u00b7 \u23f1\ufe0f 10.11.2022):\n\n\t```\n\tgit clone https://github.com/amueller/word_cloud\n\t```\n- [PyPi](https://pypi.org/project/wordcloud) (\ud83d\udce5 920K / month \u00b7 \ud83d\udce6 740 \u00b7 \u23f1\ufe0f 27.06.2022):\n\t```\n\tpip install wordcloud\n\t```\n- [Conda](https://anaconda.org/conda-forge/wordcloud) (\ud83d\udce5 350K \u00b7 \u23f1\ufe0f 25.08.2022):\n\t```\n\tconda install -c conda-forge wordcloud\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/holoviz/datashader\">datashader</a></b> (\ud83e\udd4832 \u00b7  \u2b50 2.9K) - Quickly and accurately render even the largest data. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/holoviz/datashader) (\ud83d\udc68\u200d\ud83d\udcbb 51 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udce6 1.6K \u00b7 \ud83d\udccb 520 - 23% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/holoviz/datashader\n\t```\n- [PyPi](https://pypi.org/project/datashader) (\ud83d\udce5 51K / month \u00b7 \ud83d\udce6 96 \u00b7 \u23f1\ufe0f 21.06.2022):\n\t```\n\tpip install datashader\n\t```\n- [Conda](https://anaconda.org/conda-forge/datashader) (\ud83d\udce5 440K \u00b7 \u23f1\ufe0f 18.11.2022):\n\t```\n\tconda install -c conda-forge datashader\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pyvista/pyvista\">PyVista</a></b> (\ud83e\udd4832 \u00b7  \u2b50 1.6K \u00b7 \ud83d\udcc9) - 3D plotting and mesh analysis through a streamlined interface.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pyvista/pyvista) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udce5 680 \u00b7 \ud83d\udccb 1K - 32% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/pyvista/pyvista\n\t```\n- [PyPi](https://pypi.org/project/pyvista) (\ud83d\udce5 84K / month \u00b7 \ud83d\udce6 110 \u00b7 \u23f1\ufe0f 30.06.2022):\n\t```\n\tpip install pyvista\n\t```\n- [Conda](https://anaconda.org/conda-forge/pyvista) (\ud83d\udce5 260K \u00b7 \u23f1\ufe0f 03.11.2022):\n\t```\n\tconda install -c conda-forge pyvista\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/man-group/dtale\">D-Tale</a></b> (\ud83e\udd4830 \u00b7  \u2b50 3.7K) - Visualizer for pandas data structures. <code><a href=\"https://tldrlegal.com/search?q=LGPL-2.1\">\u2757\ufe0fLGPL-2.1</a></code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/man-group/dtale) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce6 550 \u00b7 \ud83d\udccb 490 - 9% open \u00b7 \u23f1\ufe0f 04.11.2022):\n\n\t```\n\tgit clone https://github.com/man-group/dtale\n\t```\n- [PyPi](https://pypi.org/project/dtale) (\ud83d\udce5 210K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 17.06.2022):\n\t```\n\tpip install dtale\n\t```\n- [Conda](https://anaconda.org/conda-forge/dtale) (\ud83d\udce5 170K \u00b7 \u23f1\ufe0f 04.11.2022):\n\t```\n\tconda install -c conda-forge dtale\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/bqplot/bqplot\">bqplot</a></b> (\ud83e\udd4830 \u00b7  \u2b50 3.4K) - Plotting library for IPython/Jupyter notebooks. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/bqplot/bqplot) (\ud83d\udc68\u200d\ud83d\udcbb 59 \u00b7 \ud83d\udd00 470 \u00b7 \ud83d\udce6 35 \u00b7 \ud83d\udccb 600 - 39% open \u00b7 \u23f1\ufe0f 29.09.2022):\n\n\t```\n\tgit clone https://github.com/bqplot/bqplot\n\t```\n- [PyPi](https://pypi.org/project/bqplot) (\ud83d\udce5 140K / month \u00b7 \ud83d\udce6 97 \u00b7 \u23f1\ufe0f 11.02.2022):\n\t```\n\tpip install bqplot\n\t```\n- [Conda](https://anaconda.org/conda-forge/bqplot) (\ud83d\udce5 1.1M \u00b7 \u23f1\ufe0f 02.09.2022):\n\t```\n\tconda install -c conda-forge bqplot\n\t```\n- [npm](https://www.npmjs.com/package/bqplot) (\ud83d\udce5 4.9K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 02.09.2022):\n\t```\n\tnpm install bqplot\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/holoviz/hvplot\">hvPlot</a></b> (\ud83e\udd4830 \u00b7  \u2b50 670) - A high-level plotting API for pandas, dask, xarray, and networkx built on.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/holoviz/hvplot) (\ud83d\udc68\u200d\ud83d\udcbb 39 \u00b7 \ud83d\udd00 76 \u00b7 \ud83d\udce6 2K \u00b7 \ud83d\udccb 570 - 39% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/holoviz/hvplot\n\t```\n- [PyPi](https://pypi.org/project/hvplot) (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 65 \u00b7 \u23f1\ufe0f 23.06.2022):\n\t```\n\tpip install hvplot\n\t```\n- [Conda](https://anaconda.org/conda-forge/hvplot) (\ud83d\udce5 270K \u00b7 \u23f1\ufe0f 26.08.2022):\n\t```\n\tconda install -c conda-forge hvplot\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/finos/perspective\">Perspective</a></b> (\ud83e\udd4929 \u00b7  \u2b50 5K) - A data visualization and analytics component, especially.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/finos/perspective) (\ud83d\udc68\u200d\ud83d\udcbb 72 \u00b7 \ud83d\udd00 540 \u00b7 \ud83d\udce6 6 \u00b7 \ud83d\udccb 580 - 16% open \u00b7 \u23f1\ufe0f 20.11.2022):\n\n\t```\n\tgit clone https://github.com/finos/perspective\n\t```\n- [PyPi](https://pypi.org/project/perspective-python) (\ud83d\udce5 2.4K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 06.06.2022):\n\t```\n\tpip install perspective-python\n\t```\n- [Conda](https://anaconda.org/conda-forge/perspective) (\ud83d\udce5 210K \u00b7 \u23f1\ufe0f 09.10.2022):\n\t```\n\tconda install -c conda-forge perspective\n\t```\n- [npm](https://www.npmjs.com/package/@finos/perspective-jupyterlab) (\ud83d\udce5 810 / month \u00b7 \u23f1\ufe0f 07.10.2022):\n\t```\n\tnpm install @finos/perspective-jupyterlab\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ResidentMario/missingno\">missingno</a></b> (\ud83e\udd4929 \u00b7  \u2b50 3.4K \u00b7 \ud83d\udca4) - Missing data visualization module for Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/ResidentMario/missingno) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 430 \u00b7 \ud83d\udce6 9.2K \u00b7 \ud83d\udccb 120 - 6% open \u00b7 \u23f1\ufe0f 27.02.2022):\n\n\t```\n\tgit clone https://github.com/ResidentMario/missingno\n\t```\n- [PyPi](https://pypi.org/project/missingno) (\ud83d\udce5 850K / month \u00b7 \ud83d\udce6 120 \u00b7 \u23f1\ufe0f 27.02.2022):\n\t```\n\tpip install missingno\n\t```\n- [Conda](https://anaconda.org/conda-forge/missingno) (\ud83d\udce5 240K \u00b7 \u23f1\ufe0f 15.02.2020):\n\t```\n\tconda install -c conda-forge missingno\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jupyter-widgets/pythreejs\">pythreejs</a></b> (\ud83e\udd4929 \u00b7  \u2b50 840) - A Jupyter - Three.js bridge. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/jupyter-widgets/pythreejs) (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 21 \u00b7 \ud83d\udccb 220 - 25% open \u00b7 \u23f1\ufe0f 25.08.2022):\n\n\t```\n\tgit clone https://github.com/jupyter-widgets/pythreejs\n\t```\n- [PyPi](https://pypi.org/project/pythreejs) (\ud83d\udce5 68K / month \u00b7 \ud83d\udce6 42 \u00b7 \u23f1\ufe0f 26.02.2021):\n\t```\n\tpip install pythreejs\n\t```\n- [Conda](https://anaconda.org/conda-forge/pythreejs) (\ud83d\udce5 440K \u00b7 \u23f1\ufe0f 06.09.2022):\n\t```\n\tconda install -c conda-forge pythreejs\n\t```\n- [npm](https://www.npmjs.com/package/jupyter-threejs) (\ud83d\udce5 4.7K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 24.08.2022):\n\t```\n\tnpm install jupyter-threejs\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/data-validation\">data-validation</a></b> (\ud83e\udd4929 \u00b7  \u2b50 680) - Library for exploring and validating machine learning.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/data-validation) (\ud83d\udc68\u200d\ud83d\udcbb 25 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce5 370 \u00b7 \ud83d\udce6 570 \u00b7 \ud83d\udccb 170 - 22% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/data-validation\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-data-validation) (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 27 \u00b7 \u23f1\ufe0f 29.06.2022):\n\t```\n\tpip install tensorflow-data-validation\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/mpld3/mpld3\">mpld3</a></b> (\ud83e\udd4927 \u00b7  \u2b50 2.2K) - D3 Renderings of Matplotlib Graphics. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/mpld3/mpld3) (\ud83d\udc68\u200d\ud83d\udcbb 51 \u00b7 \ud83d\udd00 350 \u00b7 \ud83d\udce6 30 \u00b7 \ud83d\udccb 360 - 59% open \u00b7 \u23f1\ufe0f 03.08.2022):\n\n\t```\n\tgit clone https://github.com/mpld3/mpld3\n\t```\n- [PyPi](https://pypi.org/project/mpld3) (\ud83d\udce5 270K / month \u00b7 \ud83d\udce6 400 \u00b7 \u23f1\ufe0f 27.05.2022):\n\t```\n\tpip install mpld3\n\t```\n- [Conda](https://anaconda.org/conda-forge/mpld3) (\ud83d\udce5 160K \u00b7 \u23f1\ufe0f 27.05.2022):\n\t```\n\tconda install -c conda-forge mpld3\n\t```\n- [npm](https://www.npmjs.com/package/mpld3) (\ud83d\udce5 340 / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 27.05.2022):\n\t```\n\tnpm install mpld3\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/AutoViML/AutoViz\">AutoViz</a></b> (\ud83e\udd4927 \u00b7  \u2b50 1K) - Automatically Visualize any dataset, any size with a single line of.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/AutoViML/AutoViz) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 300 \u00b7 \ud83d\udccb 61 - 4% open \u00b7 \u23f1\ufe0f 26.10.2022):\n\n\t```\n\tgit clone https://github.com/AutoViML/AutoViz\n\t```\n- [PyPi](https://pypi.org/project/autoviz) (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 17.06.2022):\n\t```\n\tpip install autoviz\n\t```\n- [Conda](https://anaconda.org/conda-forge/autoviz) (\ud83d\udce5 22K \u00b7 \u23f1\ufe0f 03.10.2022):\n\t```\n\tconda install -c conda-forge autoviz\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/spotify/chartify\">Chartify</a></b> (\ud83e\udd4926 \u00b7  \u2b50 3.2K) - Python library that makes it easy for data scientists to create.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/spotify/chartify) (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udce6 69 \u00b7 \ud83d\udccb 74 - 58% open \u00b7 \u23f1\ufe0f 18.10.2022):\n\n\t```\n\tgit clone https://github.com/spotify/chartify\n\t```\n- [PyPi](https://pypi.org/project/chartify) (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 02.11.2020):\n\t```\n\tpip install chartify\n\t```\n- [Conda](https://anaconda.org/conda-forge/chartify) (\ud83d\udce5 23K \u00b7 \u23f1\ufe0f 07.11.2020):\n\t```\n\tconda install -c conda-forge chartify\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pavlin-policar/openTSNE\">openTSNE</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.1K) - Extensible, parallel implementations of t-SNE. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/pavlin-policar/openTSNE) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 410 \u00b7 \ud83d\udccb 110 - 5% open \u00b7 \u23f1\ufe0f 09.11.2022):\n\n\t```\n\tgit clone https://github.com/pavlin-policar/openTSNE\n\t```\n- [PyPi](https://pypi.org/project/opentsne) (\ud83d\udce5 97K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 18.03.2022):\n\t```\n\tpip install opentsne\n\t```\n- [Conda](https://anaconda.org/conda-forge/opentsne) (\ud83d\udce5 170K \u00b7 \u23f1\ufe0f 28.10.2022):\n\t```\n\tconda install -c conda-forge opentsne\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/JetBrains/lets-plot\">lets-plot</a></b> (\ud83e\udd4926 \u00b7  \u2b50 810) - An open-source plotting library for statistical data. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/JetBrains/lets-plot) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 39 \u00b7 \ud83d\udce5 340 \u00b7 \ud83d\udce6 18 \u00b7 \ud83d\udccb 300 - 24% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/JetBrains/lets-plot\n\t```\n- [PyPi](https://pypi.org/project/lets-plot) (\ud83d\udce5 3K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 20.06.2022):\n\t```\n\tpip install lets-plot\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ContextLab/hypertools\">HyperTools</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.8K \u00b7 \ud83d\udca4) - A Python toolbox for gaining geometric insights into high-.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/ContextLab/hypertools) (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce5 23 \u00b7 \ud83d\udce6 220 \u00b7 \ud83d\udccb 200 - 34% open \u00b7 \u23f1\ufe0f 12.02.2022):\n\n\t```\n\tgit clone https://github.com/ContextLab/hypertools\n\t```\n- [PyPi](https://pypi.org/project/hypertools) (\ud83d\udce5 890 / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 12.02.2022):\n\t```\n\tpip install hypertools\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/hiplot\">HiPlot</a></b> (\ud83e\udd4923 \u00b7  \u2b50 2.4K) - HiPlot makes understanding high dimensional data easy. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/hiplot) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 120 \u00b7 \ud83d\udce6 5 \u00b7 \ud83d\udccb 82 - 14% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/hiplot\n\t```\n- [PyPi](https://pypi.org/project/hiplot) (\ud83d\udce5 38K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install hiplot\n\t```\n- [Conda](https://anaconda.org/conda-forge/hiplot) (\ud83d\udce5 110K \u00b7 \u23f1\ufe0f 31.05.2022):\n\t```\n\tconda install -c conda-forge hiplot\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/fbdesignpro/sweetviz\">Sweetviz</a></b> (\ud83e\udd4923 \u00b7  \u2b50 2.2K) - Visualize and compare datasets, target values and associations, with one.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/fbdesignpro/sweetviz) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 210 \u00b7 \ud83d\udccb 100 - 30% open \u00b7 \u23f1\ufe0f 08.06.2022):\n\n\t```\n\tgit clone https://github.com/fbdesignpro/sweetviz\n\t```\n- [PyPi](https://pypi.org/project/sweetviz) (\ud83d\udce5 75K / month \u00b7 \ud83d\udce6 8 \u00b7 \u23f1\ufe0f 14.06.2022):\n\t```\n\tpip install sweetviz\n\t```\n- [Conda](https://anaconda.org/conda-forge/sweetviz) (\ud83d\udce5 16K \u00b7 \u23f1\ufe0f 15.06.2022):\n\t```\n\tconda install -c conda-forge sweetviz\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ing-bank/popmon\">Popmon</a></b> (\ud83e\udd4923 \u00b7  \u2b50 400) - Monitor the stability of a Pandas or Spark dataframe. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/ing-bank/popmon) (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 32 \u00b7 \ud83d\udce5 35 \u00b7 \ud83d\udce6 17 \u00b7 \ud83d\udccb 46 - 28% open \u00b7 \u23f1\ufe0f 19.10.2022):\n\n\t```\n\tgit clone https://github.com/ing-bank/popmon\n\t```\n- [PyPi](https://pypi.org/project/popmon) (\ud83d\udce5 33K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 21.06.2022):\n\t```\n\tpip install popmon\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/vega/ipyvega\">vega</a></b> (\ud83e\udd4923 \u00b7  \u2b50 330) - IPython/Jupyter notebook module for Vega and Vega-Lite. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/vega/ipyvega) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 59 \u00b7 \ud83d\udccb 95 - 13% open \u00b7 \u23f1\ufe0f 01.10.2022):\n\n\t```\n\tgit clone https://github.com/vega/ipyvega\n\t```\n- [PyPi](https://pypi.org/project/vega) (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 84 \u00b7 \u23f1\ufe0f 10.02.2022):\n\t```\n\tpip install vega\n\t```\n- [Conda](https://anaconda.org/conda-forge/vega) (\ud83d\udce5 520K \u00b7 \u23f1\ufe0f 10.02.2022):\n\t```\n\tconda install -c conda-forge vega\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PatrikHlobil/Pandas-Bokeh\">Pandas-Bokeh</a></b> (\ud83e\udd4922 \u00b7  \u2b50 820 \u00b7 \ud83d\udca4) - Bokeh Plotting Backend for Pandas and GeoPandas. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/PatrikHlobil/Pandas-Bokeh) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udccb 100 - 33% open \u00b7 \u23f1\ufe0f 25.03.2022):\n\n\t```\n\tgit clone https://github.com/PatrikHlobil/Pandas-Bokeh\n\t```\n- [PyPi](https://pypi.org/project/pandas-bokeh) (\ud83d\udce5 23K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 11.04.2021):\n\t```\n\tpip install pandas-bokeh\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/marcharper/python-ternary\">python-ternary</a></b> (\ud83e\udd4922 \u00b7  \u2b50 610) - Ternary plotting library for python with matplotlib. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/marcharper/python-ternary) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce5 18 \u00b7 \ud83d\udce6 110 \u00b7 \ud83d\udccb 140 - 28% open \u00b7 \u23f1\ufe0f 06.11.2022):\n\n\t```\n\tgit clone https://github.com/marcharper/python-ternary\n\t```\n- [PyPi](https://pypi.org/project/python-ternary) (\ud83d\udce5 58K / month \u00b7 \ud83d\udce6 21 \u00b7 \u23f1\ufe0f 17.02.2021):\n\t```\n\tpip install python-ternary\n\t```\n- [Conda](https://anaconda.org/conda-forge/python-ternary) (\ud83d\udce5 69K \u00b7 \u23f1\ufe0f 17.02.2021):\n\t```\n\tconda install -c conda-forge python-ternary\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/predict-idlab/plotly-resampler\">Plotly-Resampler</a></b> (\ud83e\udd4921 \u00b7  \u2b50 580) - Visualize large time series data with plotly.py. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/predict-idlab/plotly-resampler) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 34 \u00b7 \ud83d\udccb 70 - 30% open \u00b7 \u23f1\ufe0f 08.11.2022):\n\n\t```\n\tgit clone https://github.com/predict-idlab/plotly-resampler\n\t```\n- [PyPi](https://pypi.org/project/plotly-resampler) (\ud83d\udce5 27K / month \u00b7 \u23f1\ufe0f 29.06.2022):\n\t```\n\tpip install plotly-resampler\n\t```\n- [Conda](https://anaconda.org/conda-forge/plotly-resampler) (\ud83d\udce5 9.8K \u00b7 \u23f1\ufe0f 25.08.2022):\n\t```\n\tconda install -c conda-forge plotly-resampler\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/gyli/PyWaffle\">PyWaffle</a></b> (\ud83e\udd4921 \u00b7  \u2b50 520) - Make Waffle Charts in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/gyli/PyWaffle) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 98 \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 18 - 22% open \u00b7 \u23f1\ufe0f 08.06.2022):\n\n\t```\n\tgit clone https://github.com/gyli/PyWaffle\n\t```\n- [PyPi](https://pypi.org/project/pywaffle) (\ud83d\udce5 10K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 08.06.2022):\n\t```\n\tpip install pywaffle\n\t```\n- [Conda](https://anaconda.org/conda-forge/pywaffle) (\ud83d\udce5 7.7K \u00b7 \u23f1\ufe0f 05.06.2022):\n\t```\n\tconda install -c conda-forge pywaffle\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/leotac/joypy\">joypy</a></b> (\ud83e\udd4921 \u00b7  \u2b50 450 \u00b7 \ud83d\udca4) - Joyplots in Python with matplotlib & pandas. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/leotac/joypy) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 47 \u00b7 \ud83d\udce6 210 \u00b7 \ud83d\udccb 48 - 22% open \u00b7 \u23f1\ufe0f 19.12.2021):\n\n\t```\n\tgit clone https://github.com/leotac/joypy\n\t```\n- [PyPi](https://pypi.org/project/joypy) (\ud83d\udce5 18K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 19.12.2021):\n\t```\n\tpip install joypy\n\t```\n- [Conda](https://anaconda.org/conda-forge/joypy) (\ud83d\udce5 17K \u00b7 \u23f1\ufe0f 28.12.2020):\n\t```\n\tconda install -c conda-forge joypy\n\t```\n</details>\n<details><summary>Show 14 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/SciTools/cartopy\">cartopy</a></b> (\ud83e\udd4832 \u00b7  \u2b50 1.1K) - Cartopy - a cartographic python library with matplotlib support. <code><a href=\"http://bit.ly/37RvQcA\">\u2757\ufe0fLGPL-3.0</a></code>\n- <b><a href=\"https://github.com/santosjorge/cufflinks\">Cufflinks</a></b> (\ud83e\udd4929 \u00b7  \u2b50 2.7K \u00b7 \ud83d\udc80) - Productivity Tools for Plotly + Pandas. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/PAIR-code/facets\">Facets Overview</a></b> (\ud83e\udd4928 \u00b7  \u2b50 7K \u00b7 \ud83d\udc80) - Visualizations for machine learning datasets. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/DmitryUlyanov/Multicore-TSNE\">Multicore-TSNE</a></b> (\ud83e\udd4924 \u00b7  \u2b50 1.7K \u00b7 \ud83d\udc80) - Parallel t-SNE implementation with Python and Torch.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/adamerose/PandasGUI\">PandasGUI</a></b> (\ud83e\udd4923 \u00b7  \u2b50 2.8K \u00b7 \ud83d\udca4) - A GUI for Pandas DataFrames. <code><a href=\"https://tldrlegal.com/search?q=MIT-0\">\u2757\ufe0fMIT-0</a></code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/SauceCat/PDPbox\">PDPbox</a></b> (\ud83e\udd4923 \u00b7  \u2b50 710 \u00b7 \ud83d\udc80) - python partial dependence plot toolbox. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/nicolaskruchten/jupyter_pivottablejs\">pivottablejs</a></b> (\ud83e\udd4922 \u00b7  \u2b50 500 \u00b7 \ud83d\udc80) - Dragndrop Pivot Tables and Charts for Jupyter/IPython.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/beringresearch/ivis\">ivis</a></b> (\ud83e\udd4919 \u00b7  \u2b50 280) - Dimensionality reduction in very large datasets using Siamese.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/t-makaro/animatplot\">animatplot</a></b> (\ud83e\udd4917 \u00b7  \u2b50 390 \u00b7 \ud83d\udc80) - A python package for animating plots build on matplotlib. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/altair-viz/pdvega\">pdvega</a></b> (\ud83e\udd4917 \u00b7  \u2b50 340 \u00b7 \ud83d\udc80) - Interactive plotting for Pandas using Vega-Lite. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/data-describe/data-describe\">data-describe</a></b> (\ud83e\udd4917 \u00b7  \u2b50 290 \u00b7 \ud83d\udca4) - datadescribe: Pythonic EDA Accelerator for Data Science. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/vegafusion/vegafusion\">vegafusion</a></b> (\ud83e\udd4917 \u00b7  \u2b50 120) - Serverside acceleration for the Vega visualization grammar. <code><a href=\"http://bit.ly/3pwmjO5\">\u2757\ufe0fAGPL-3.0</a></code>\n- <b><a href=\"https://github.com/Zsailer/nx_altair\">nx-altair</a></b> (\ud83e\udd4915 \u00b7  \u2b50 200 \u00b7 \ud83d\udc80) - Draw interactive NetworkX graphs with Altair. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/biovault/nptsne\">nptsne</a></b> (\ud83e\udd4912 \u00b7  \u2b50 29 \u00b7 \ud83d\udc80) - nptsne is a numpy compatible python binary package that offers a.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n</details>\n<br>\n\n## Text Data & NLP\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for processing, cleaning, manipulating, and analyzing text data as well as libraries for NLP tasks such as language detection, fuzzy matching, classification, seq2seq learning, conversational AI, keyword extraction, and translation._\n\n<details><summary><b><a href=\"https://github.com/huggingface/transformers\">transformers</a></b> (\ud83e\udd4750 \u00b7  \u2b50 75K) - Transformers: State-of-the-art Machine Learning for.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/huggingface/transformers) (\ud83d\udc68\u200d\ud83d\udcbb 1.6K \u00b7 \ud83d\udd00 17K \u00b7 \ud83d\udce5 620 \u00b7 \ud83d\udce6 41K \u00b7 \ud83d\udccb 11K - 5% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/huggingface/transformers\n\t```\n- [PyPi](https://pypi.org/project/transformers) (\ud83d\udce5 8.4M / month \u00b7 \ud83d\udce6 980 \u00b7 \u23f1\ufe0f 21.06.2022):\n\t```\n\tpip install transformers\n\t```\n- [Conda](https://anaconda.org/conda-forge/transformers) (\ud83d\udce5 610K \u00b7 \u23f1\ufe0f 03.11.2022):\n\t```\n\tconda install -c conda-forge transformers\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/explosion/spaCy\">spaCy</a></b> (\ud83e\udd4744 \u00b7  \u2b50 25K) - Industrial-strength Natural Language Processing (NLP) in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/explosion/spaCy) (\ud83d\udc68\u200d\ud83d\udcbb 700 \u00b7 \ud83d\udd00 4K \u00b7 \ud83d\udce5 3.1K \u00b7 \ud83d\udce6 46K \u00b7 \ud83d\udccb 5.3K - 1% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/explosion/spaCy\n\t```\n- [PyPi](https://pypi.org/project/spacy) (\ud83d\udce5 4.4M / month \u00b7 \ud83d\udce6 2.4K \u00b7 \u23f1\ufe0f 05.04.2022):\n\t```\n\tpip install spacy\n\t```\n- [Conda](https://anaconda.org/conda-forge/spacy) (\ud83d\udce5 2.9M \u00b7 \u23f1\ufe0f 16.11.2022):\n\t```\n\tconda install -c conda-forge spacy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nltk/nltk\">nltk</a></b> (\ud83e\udd4744 \u00b7  \u2b50 11K) - Suite of libraries and programs for symbolic and statistical natural.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/nltk/nltk) (\ud83d\udc68\u200d\ud83d\udcbb 430 \u00b7 \ud83d\udd00 2.7K \u00b7 \ud83d\udce6 160K \u00b7 \ud83d\udccb 1.7K - 14% open \u00b7 \u23f1\ufe0f 05.11.2022):\n\n\t```\n\tgit clone https://github.com/nltk/nltk\n\t```\n- [PyPi](https://pypi.org/project/nltk) (\ud83d\udce5 12M / month \u00b7 \ud83d\udce6 12K \u00b7 \u23f1\ufe0f 09.02.2022):\n\t```\n\tpip install nltk\n\t```\n- [Conda](https://anaconda.org/conda-forge/nltk) (\ud83d\udce5 1.6M \u00b7 \u23f1\ufe0f 17.11.2022):\n\t```\n\tconda install -c conda-forge nltk\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/fairseq\">fairseq</a></b> (\ud83e\udd4739 \u00b7  \u2b50 20K \u00b7 \ud83d\udcc8) - Facebook AI Research Sequence-to-Sequence Toolkit written in.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/fairseq) (\ud83d\udc68\u200d\ud83d\udcbb 410 \u00b7 \ud83d\udd00 5K \u00b7 \ud83d\udce5 280 \u00b7 \ud83d\udce6 1K \u00b7 \ud83d\udccb 3.8K - 22% open \u00b7 \u23f1\ufe0f 08.11.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/fairseq\n\t```\n- [PyPi](https://pypi.org/project/fairseq) (\ud83d\udce5 60K / month \u00b7 \ud83d\udce6 39 \u00b7 \u23f1\ufe0f 27.06.2022):\n\t```\n\tpip install fairseq\n\t```\n- [Conda](https://anaconda.org/conda-forge/fairseq) (\ud83d\udce5 22K \u00b7 \u23f1\ufe0f 13.07.2022):\n\t```\n\tconda install -c conda-forge fairseq\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/RasaHQ/rasa\">Rasa</a></b> (\ud83e\udd4739 \u00b7  \u2b50 15K) - Open source machine learning framework to automate text- and voice-.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/RasaHQ/rasa) (\ud83d\udc68\u200d\ud83d\udcbb 560 \u00b7 \ud83d\udd00 4.2K \u00b7 \ud83d\udccb 6.7K - 10% open \u00b7 \u23f1\ufe0f 18.11.2022):\n\n\t```\n\tgit clone https://github.com/RasaHQ/rasa\n\t```\n- [PyPi](https://pypi.org/project/rasa) (\ud83d\udce5 170K / month \u00b7 \ud83d\udce6 60 \u00b7 \u23f1\ufe0f 06.07.2022):\n\t```\n\tpip install rasa\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/RaRe-Technologies/gensim\">gensim</a></b> (\ud83e\udd4739 \u00b7  \u2b50 14K \u00b7 \ud83d\udcc9) - Topic Modelling for Humans. <code><a href=\"https://tldrlegal.com/search?q=LGPL-2.1\">\u2757\ufe0fLGPL-2.1</a></code></summary>\n\n- [GitHub](https://github.com/RaRe-Technologies/gensim) (\ud83d\udc68\u200d\ud83d\udcbb 430 \u00b7 \ud83d\udd00 4.3K \u00b7 \ud83d\udce5 4K \u00b7 \ud83d\udce6 38K \u00b7 \ud83d\udccb 1.8K - 21% open \u00b7 \u23f1\ufe0f 03.11.2022):\n\n\t```\n\tgit clone https://github.com/RaRe-Technologies/gensim\n\t```\n- [PyPi](https://pypi.org/project/gensim) (\ud83d\udce5 4.8M / month \u00b7 \ud83d\udce6 2.9K \u00b7 \u23f1\ufe0f 01.05.2022):\n\t```\n\tpip install gensim\n\t```\n- [Conda](https://anaconda.org/conda-forge/gensim) (\ud83d\udce5 920K \u00b7 \u23f1\ufe0f 29.07.2022):\n\t```\n\tconda install -c conda-forge gensim\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/flairNLP/flair\">flair</a></b> (\ud83e\udd4738 \u00b7  \u2b50 12K) - A very simple framework for state-of-the-art Natural Language Processing.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/flairNLP/flair) (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 2K \u00b7 \ud83d\udce6 1.7K \u00b7 \ud83d\udccb 2K - 4% open \u00b7 \u23f1\ufe0f 20.11.2022):\n\n\t```\n\tgit clone https://github.com/flairNLP/flair\n\t```\n- [PyPi](https://pypi.org/project/flair) (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 76 \u00b7 \u23f1\ufe0f 20.05.2022):\n\t```\n\tpip install flair\n\t```\n- [Conda](https://anaconda.org/conda-forge/python-flair) (\ud83d\udce5 14K \u00b7 \u23f1\ufe0f 21.05.2022):\n\t```\n\tconda install -c conda-forge python-flair\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/allenai/allennlp\">AllenNLP</a></b> (\ud83e\udd4737 \u00b7  \u2b50 11K) - An open-source NLP research library, built on PyTorch. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/allenai/allennlp) (\ud83d\udc68\u200d\ud83d\udcbb 260 \u00b7 \ud83d\udd00 2.2K \u00b7 \ud83d\udce5 47 \u00b7 \ud83d\udce6 2.9K \u00b7 \ud83d\udccb 2.6K - 3% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/allenai/allennlp\n\t```\n- [PyPi](https://pypi.org/project/allennlp) (\ud83d\udce5 99K / month \u00b7 \ud83d\udce6 180 \u00b7 \u23f1\ufe0f 14.04.2022):\n\t```\n\tpip install allennlp\n\t```\n- [Conda](https://anaconda.org/conda-forge/allennlp) (\ud83d\udce5 91K \u00b7 \u23f1\ufe0f 15.07.2022):\n\t```\n\tconda install -c conda-forge allennlp\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/UKPLab/sentence-transformers\">sentence-transformers</a></b> (\ud83e\udd4737 \u00b7  \u2b50 8.9K) - Multilingual Sentence & Image Embeddings with BERT. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/UKPLab/sentence-transformers) (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce6 4.7K \u00b7 \ud83d\udccb 1.6K - 52% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/UKPLab/sentence-transformers\n\t```\n- [PyPi](https://pypi.org/project/sentence-transformers) (\ud83d\udce5 2M / month \u00b7 \ud83d\udce6 130 \u00b7 \u23f1\ufe0f 26.06.2022):\n\t```\n\tpip install sentence-transformers\n\t```\n- [Conda](https://anaconda.org/conda-forge/sentence-transformers) (\ud83d\udce5 51K \u00b7 \u23f1\ufe0f 27.06.2022):\n\t```\n\tconda install -c conda-forge sentence-transformers\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/JohnSnowLabs/spark-nlp\">spark-nlp</a></b> (\ud83e\udd4736 \u00b7  \u2b50 3K \u00b7 \ud83d\udcc9) - State of the Art Natural Language Processing. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/JohnSnowLabs/spark-nlp) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 610 \u00b7 \ud83d\udce6 200 \u00b7 \ud83d\udccb 740 - 4% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/JohnSnowLabs/spark-nlp\n\t```\n- [PyPi](https://pypi.org/project/spark-nlp) (\ud83d\udce5 2.8M / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 01.07.2022):\n\t```\n\tpip install spark-nlp\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/fastText\">fastText</a></b> (\ud83e\udd4834 \u00b7  \u2b50 24K \u00b7 \ud83d\udca4) - Library for fast text representation and classification. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/fastText) (\ud83d\udc68\u200d\ud83d\udcbb 59 \u00b7 \ud83d\udd00 4.5K \u00b7 \ud83d\udce6 3.5K \u00b7 \ud83d\udccb 1.1K - 45% open \u00b7 \u23f1\ufe0f 04.03.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/fastText\n\t```\n- [PyPi](https://pypi.org/project/fasttext) (\ud83d\udce5 970K / month \u00b7 \ud83d\udce6 190 \u00b7 \u23f1\ufe0f 28.04.2020):\n\t```\n\tpip install fasttext\n\t```\n- [Conda](https://anaconda.org/conda-forge/fasttext) (\ud83d\udce5 43K \u00b7 \u23f1\ufe0f 01.11.2022):\n\t```\n\tconda install -c conda-forge fasttext\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/ParlAI\">ParlAI</a></b> (\ud83e\udd4834 \u00b7  \u2b50 9.6K) - A framework for training and evaluating AI models on a variety of.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/ParlAI) (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce6 95 \u00b7 \ud83d\udccb 1.5K - 6% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/ParlAI\n\t```\n- [PyPi](https://pypi.org/project/parlai) (\ud83d\udce5 3.3K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 30.03.2022):\n\t```\n\tpip install parlai\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/stanfordnlp/stanza\">stanza</a></b> (\ud83e\udd4834 \u00b7  \u2b50 6.4K) - Official Stanford NLP Python Library for Many Human Languages. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/stanfordnlp/stanza) (\ud83d\udc68\u200d\ud83d\udcbb 54 \u00b7 \ud83d\udd00 820 \u00b7 \ud83d\udce6 1.3K \u00b7 \ud83d\udccb 730 - 9% open \u00b7 \u23f1\ufe0f 15.09.2022):\n\n\t```\n\tgit clone https://github.com/stanfordnlp/stanza\n\t```\n- [PyPi](https://pypi.org/project/stanza) (\ud83d\udce5 190K / month \u00b7 \ud83d\udce6 70 \u00b7 \u23f1\ufe0f 23.04.2022):\n\t```\n\tpip install stanza\n\t```\n- [Conda](https://anaconda.org/stanfordnlp/stanza) (\ud83d\udce5 6K \u00b7 \u23f1\ufe0f 14.09.2022):\n\t```\n\tconda install -c stanfordnlp stanza\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/sentencepiece\">sentencepiece</a></b> (\ud83e\udd4834 \u00b7  \u2b50 6.3K) - Unsupervised text tokenizer for Neural Network-based text.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/google/sentencepiece) (\ud83d\udc68\u200d\ud83d\udcbb 69 \u00b7 \ud83d\udd00 840 \u00b7 \ud83d\udce5 22K \u00b7 \ud83d\udce6 20K \u00b7 \ud83d\udccb 570 - 5% open \u00b7 \u23f1\ufe0f 09.09.2022):\n\n\t```\n\tgit clone https://github.com/google/sentencepiece\n\t```\n- [PyPi](https://pypi.org/project/sentencepiece) (\ud83d\udce5 7.4M / month \u00b7 \ud83d\udce6 410 \u00b7 \u23f1\ufe0f 18.06.2021):\n\t```\n\tpip install sentencepiece\n\t```\n- [Conda](https://anaconda.org/conda-forge/sentencepiece) (\ud83d\udce5 270K \u00b7 \u23f1\ufe0f 08.04.2022):\n\t```\n\tconda install -c conda-forge sentencepiece\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/OpenNMT/OpenNMT-py\">OpenNMT</a></b> (\ud83e\udd4834 \u00b7  \u2b50 5.8K) - Open Source Neural Machine Translation in PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/OpenNMT/OpenNMT-py) (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 2.1K \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 1.4K - 7% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/OpenNMT/OpenNMT-py\n\t```\n- [PyPi](https://pypi.org/project/OpenNMT-py) (\ud83d\udce5 4.3K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 14.09.2021):\n\t```\n\tpip install OpenNMT-py\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/text\">torchtext</a></b> (\ud83e\udd4834 \u00b7  \u2b50 3.1K) - Data loaders and abstractions for text and NLP. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pytorch/text) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 750 \u00b7 \ud83d\udccb 760 - 38% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/text\n\t```\n- [PyPi](https://pypi.org/project/torchtext) (\ud83d\udce5 410K / month \u00b7 \ud83d\udce6 440 \u00b7 \u23f1\ufe0f 28.06.2022):\n\t```\n\tpip install torchtext\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/huggingface/tokenizers\">Tokenizers</a></b> (\ud83e\udd4833 \u00b7  \u2b50 6K) - Fast State-of-the-Art Tokenizers optimized for Research and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/huggingface/tokenizers) (\ud83d\udc68\u200d\ud83d\udcbb 61 \u00b7 \ud83d\udd00 510 \u00b7 \ud83d\udce6 52 \u00b7 \ud83d\udccb 700 - 31% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/huggingface/tokenizers\n\t```\n- [PyPi](https://pypi.org/project/tokenizers) (\ud83d\udce5 8.2M / month \u00b7 \ud83d\udce6 130 \u00b7 \u23f1\ufe0f 13.04.2022):\n\t```\n\tpip install tokenizers\n\t```\n- [Conda](https://anaconda.org/conda-forge/tokenizers) (\ud83d\udce5 560K \u00b7 \u23f1\ufe0f 28.10.2022):\n\t```\n\tconda install -c conda-forge tokenizers\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/NVIDIA/NeMo\">NeMo</a></b> (\ud83e\udd4833 \u00b7  \u2b50 5.1K) - NeMo: a toolkit for conversational AI. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/NVIDIA/NeMo) (\ud83d\udc68\u200d\ud83d\udcbb 190 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udce5 10K \u00b7 \ud83d\udccb 1.4K - 5% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/NVIDIA/NeMo\n\t```\n- [PyPi](https://pypi.org/project/nemo-toolkit) (\ud83d\udce5 16K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 01.07.2022):\n\t```\n\tpip install nemo-toolkit\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/text\">TensorFlow Text</a></b> (\ud83e\udd4833 \u00b7  \u2b50 1K) - Making text a first-class citizen in TensorFlow. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/text) (\ud83d\udc68\u200d\ud83d\udcbb 98 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 2.5K \u00b7 \ud83d\udccb 250 - 39% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/text\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-text) (\ud83d\udce5 3M / month \u00b7 \ud83d\udce6 83 \u00b7 \u23f1\ufe0f 18.05.2022):\n\t```\n\tpip install tensorflow-text\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deeppavlov/DeepPavlov\">DeepPavlov</a></b> (\ud83e\udd4832 \u00b7  \u2b50 5.9K) - An open source library for deep learning end-to-end dialog.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/deeppavlov/DeepPavlov) (\ud83d\udc68\u200d\ud83d\udcbb 73 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 300 \u00b7 \ud83d\udccb 620 - 8% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/deepmipt/DeepPavlov\n\t```\n- [PyPi](https://pypi.org/project/deeppavlov) (\ud83d\udce5 8.3K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 31.05.2022):\n\t```\n\tpip install deeppavlov\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jamesturk/jellyfish\">jellyfish</a></b> (\ud83e\udd4832 \u00b7  \u2b50 1.7K) - a python library for doing approximate and phonetic matching of.. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/jamesturk/jellyfish) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 4.6K \u00b7 \ud83d\udccb 120 - 10% open \u00b7 \u23f1\ufe0f 07.11.2022):\n\n\t```\n\tgit clone https://github.com/jamesturk/jellyfish\n\t```\n- [PyPi](https://pypi.org/project/jellyfish) (\ud83d\udce5 2.6M / month \u00b7 \ud83d\udce6 410 \u00b7 \u23f1\ufe0f 07.01.2022):\n\t```\n\tpip install jellyfish\n\t```\n- [Conda](https://anaconda.org/conda-forge/jellyfish) (\ud83d\udce5 390K \u00b7 \u23f1\ufe0f 28.10.2022):\n\t```\n\tconda install -c conda-forge jellyfish\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/snowballstem/snowball\">snowballstemmer</a></b> (\ud83e\udd4832 \u00b7  \u2b50 600) - Snowball compiler and stemming algorithms. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/snowballstem/snowball) (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 4 \u00b7 \ud83d\udccb 82 - 40% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/snowballstem/snowball\n\t```\n- [PyPi](https://pypi.org/project/snowballstemmer) (\ud83d\udce5 8.1M / month \u00b7 \ud83d\udce6 6.7K \u00b7 \u23f1\ufe0f 16.11.2021):\n\t```\n\tpip install snowballstemmer\n\t```\n- [Conda](https://anaconda.org/conda-forge/snowballstemmer) (\ud83d\udce5 5.5M \u00b7 \u23f1\ufe0f 17.11.2021):\n\t```\n\tconda install -c conda-forge snowballstemmer\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deepset-ai/haystack\">haystack</a></b> (\ud83e\udd4831 \u00b7  \u2b50 6.1K) - Haystack is an open source NLP framework that leverages pre-trained.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/deepset-ai/haystack) (\ud83d\udc68\u200d\ud83d\udcbb 150 \u00b7 \ud83d\udd00 940 \u00b7 \ud83d\udce5 15 \u00b7 \ud83d\udccb 1.7K - 16% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/deepset-ai/haystack\n\t```\n- [PyPi](https://pypi.org/project/haystack) (\ud83d\udce5 1K / month \u00b7 \ud83d\udce6 85 \u00b7 \u23f1\ufe0f 15.12.2021):\n\t```\n\tpip install haystack\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dedupeio/dedupe\">Dedupe</a></b> (\ud83e\udd4831 \u00b7  \u2b50 3.6K) - A python library for accurate and scalable fuzzy matching, record.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/dedupeio/dedupe) (\ud83d\udc68\u200d\ud83d\udcbb 67 \u00b7 \ud83d\udd00 480 \u00b7 \ud83d\udccb 780 - 8% open \u00b7 \u23f1\ufe0f 31.10.2022):\n\n\t```\n\tgit clone https://github.com/dedupeio/dedupe\n\t```\n- [PyPi](https://pypi.org/project/dedupe) (\ud83d\udce5 310K / month \u00b7 \ud83d\udce6 48 \u00b7 \u23f1\ufe0f 06.07.2022):\n\t```\n\tpip install dedupe\n\t```\n- [Conda](https://anaconda.org/conda-forge/dedupe) (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 02.11.2022):\n\t```\n\tconda install -c conda-forge dedupe\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/makcedward/nlpaug\">nlpaug</a></b> (\ud83e\udd4830 \u00b7  \u2b50 3.6K) - Data augmentation for NLP. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/makcedward/nlpaug) (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 410 \u00b7 \ud83d\udce6 460 \u00b7 \ud83d\udccb 200 - 22% open \u00b7 \u23f1\ufe0f 07.07.2022):\n\n\t```\n\tgit clone https://github.com/makcedward/nlpaug\n\t```\n- [PyPi](https://pypi.org/project/nlpaug) (\ud83d\udce5 190K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 07.07.2022):\n\t```\n\tpip install nlpaug\n\t```\n- [Conda](https://anaconda.org/conda-forge/nlpaug) (\ud83d\udce5 5.8K \u00b7 \u23f1\ufe0f 07.07.2022):\n\t```\n\tconda install -c conda-forge nlpaug\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/life4/textdistance\">TextDistance</a></b> (\ud83e\udd4830 \u00b7  \u2b50 3K) - Compute distance between sequences. 30+ algorithms, pure python.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/life4/textdistance) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udce5 870 \u00b7 \ud83d\udce6 3.1K \u00b7 \u23f1\ufe0f 18.09.2022):\n\n\t```\n\tgit clone https://github.com/life4/textdistance\n\t```\n- [PyPi](https://pypi.org/project/textdistance) (\ud83d\udce5 630K / month \u00b7 \ud83d\udce6 43 \u00b7 \u23f1\ufe0f 29.06.2022):\n\t```\n\tpip install textdistance\n\t```\n- [Conda](https://anaconda.org/conda-forge/textdistance) (\ud83d\udce5 260K \u00b7 \u23f1\ufe0f 18.09.2022):\n\t```\n\tconda install -c conda-forge textdistance\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/allenai/scispacy\">SciSpacy</a></b> (\ud83e\udd4830 \u00b7  \u2b50 1.3K) - A full spaCy pipeline and models for scientific/biomedical documents. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/allenai/scispacy) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udce6 540 \u00b7 \ud83d\udccb 270 - 10% open \u00b7 \u23f1\ufe0f 06.11.2022):\n\n\t```\n\tgit clone https://github.com/allenai/scispacy\n\t```\n- [PyPi](https://pypi.org/project/scispacy) (\ud83d\udce5 38K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 10.03.2022):\n\t```\n\tpip install scispacy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/miso-belica/sumy\">Sumy</a></b> (\ud83e\udd4829 \u00b7  \u2b50 3K) - Module for automatic summarization of text documents and HTML pages. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/miso-belica/sumy) (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 480 \u00b7 \ud83d\udce6 1.5K \u00b7 \ud83d\udccb 110 - 13% open \u00b7 \u23f1\ufe0f 23.10.2022):\n\n\t```\n\tgit clone https://github.com/miso-belica/sumy\n\t```\n- [PyPi](https://pypi.org/project/sumy) (\ud83d\udce5 19K / month \u00b7 \ud83d\udce6 100 \u00b7 \u23f1\ufe0f 21.04.2022):\n\t```\n\tpip install sumy\n\t```\n- [Conda](https://anaconda.org/conda-forge/sumy) (\ud83d\udce5 3.2K \u00b7 \u23f1\ufe0f 25.10.2022):\n\t```\n\tconda install -c conda-forge sumy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/fastnlp/fastNLP\">fastNLP</a></b> (\ud83e\udd4829 \u00b7  \u2b50 2.7K) - fastNLP: A Modularized and Extensible NLP Framework. Currently still.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/fastnlp/fastNLP) (\ud83d\udc68\u200d\ud83d\udcbb 61 \u00b7 \ud83d\udd00 440 \u00b7 \ud83d\udce5 66 \u00b7 \ud83d\udce6 100 \u00b7 \ud83d\udccb 200 - 25% open \u00b7 \u23f1\ufe0f 31.10.2022):\n\n\t```\n\tgit clone https://github.com/fastnlp/fastNLP\n\t```\n- [PyPi](https://pypi.org/project/fastnlp) (\ud83d\udce5 3K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 04.02.2019):\n\t```\n\tpip install fastnlp\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/cltk/cltk\">CLTK</a></b> (\ud83e\udd4829 \u00b7  \u2b50 750) - The Classical Language Toolkit. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/cltk/cltk) (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce5 25 \u00b7 \ud83d\udce6 210 \u00b7 \ud83d\udccb 530 - 5% open \u00b7 \u23f1\ufe0f 16.10.2022):\n\n\t```\n\tgit clone https://github.com/cltk/cltk\n\t```\n- [PyPi](https://pypi.org/project/cltk) (\ud83d\udce5 1.3K / month \u00b7 \ud83d\udce6 42 \u00b7 \u23f1\ufe0f 09.06.2022):\n\t```\n\tpip install cltk\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google-research/text-to-text-transfer-transformer\">T5</a></b> (\ud83e\udd4828 \u00b7  \u2b50 4.5K) - Code for the paper Exploring the Limits of Transfer Learning with a.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/google-research/text-to-text-transfer-transformer) (\ud83d\udc68\u200d\ud83d\udcbb 53 \u00b7 \ud83d\udd00 610 \u00b7 \ud83d\udce6 120 \u00b7 \ud83d\udccb 400 - 15% open \u00b7 \u23f1\ufe0f 10.11.2022):\n\n\t```\n\tgit clone https://github.com/google-research/text-to-text-transfer-transformer\n\t```\n- [PyPi](https://pypi.org/project/t5) (\ud83d\udce5 8.8K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 18.10.2021):\n\t```\n\tpip install t5\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/cjhutto/vaderSentiment\">vaderSentiment</a></b> (\ud83e\udd4828 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udca4) - VADER Sentiment Analysis. VADER (Valence Aware Dictionary.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/cjhutto/vaderSentiment) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 900 \u00b7 \ud83d\udce6 4.4K \u00b7 \ud83d\udccb 110 - 31% open \u00b7 \u23f1\ufe0f 01.04.2022):\n\n\t```\n\tgit clone https://github.com/cjhutto/vaderSentiment\n\t```\n- [PyPi](https://pypi.org/project/vadersentiment) (\ud83d\udce5 150K / month \u00b7 \ud83d\udce6 170 \u00b7 \u23f1\ufe0f 22.05.2020):\n\t```\n\tpip install vadersentiment\n\t```\n- [Conda](https://anaconda.org/conda-forge/vadersentiment) (\ud83d\udce5 10K \u00b7 \u23f1\ufe0f 22.03.2021):\n\t```\n\tconda install -c conda-forge vadersentiment\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rspeer/python-ftfy\">ftfy</a></b> (\ud83e\udd4828 \u00b7  \u2b50 3.4K) - Fixes mojibake and other glitches in Unicode text, after the fact. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/rspeer/python-ftfy) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 7.6K \u00b7 \ud83d\udccb 130 - 9% open \u00b7 \u23f1\ufe0f 25.10.2022):\n\n\t```\n\tgit clone https://github.com/rspeer/python-ftfy\n\t```\n- [PyPi](https://pypi.org/project/ftfy) (\ud83d\udce5 2.7M / month \u00b7 \ud83d\udce6 490 \u00b7 \u23f1\ufe0f 09.02.2022):\n\t```\n\tpip install ftfy\n\t```\n- [Conda](https://anaconda.org/conda-forge/ftfy) (\ud83d\udce5 210K \u00b7 \u23f1\ufe0f 13.03.2022):\n\t```\n\tconda install -c conda-forge ftfy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/chartbeat-labs/textacy\">textacy</a></b> (\ud83e\udd4828 \u00b7  \u2b50 2K \u00b7 \ud83d\udca4) - NLP, before and after spaCy. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/chartbeat-labs/textacy) (\ud83d\udc68\u200d\ud83d\udcbb 32 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udccb 250 - 11% open \u00b7 \u23f1\ufe0f 06.03.2022):\n\n\t```\n\tgit clone https://github.com/chartbeat-labs/textacy\n\t```\n- [PyPi](https://pypi.org/project/textacy) (\ud83d\udce5 32K / month \u00b7 \ud83d\udce6 100 \u00b7 \u23f1\ufe0f 06.12.2021):\n\t```\n\tpip install textacy\n\t```\n- [Conda](https://anaconda.org/conda-forge/textacy) (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 06.02.2022):\n\t```\n\tconda install -c conda-forge textacy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/DerwenAI/pytextrank\">PyTextRank</a></b> (\ud83e\udd4828 \u00b7  \u2b50 1.9K) - Python implementation of TextRank algorithms (textgraphs) for phrase.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/DerwenAI/pytextrank) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 330 \u00b7 \ud83d\udce6 310 \u00b7 \ud83d\udccb 92 - 21% open \u00b7 \u23f1\ufe0f 27.07.2022):\n\n\t```\n\tgit clone https://github.com/DerwenAI/pytextrank\n\t```\n- [PyPi](https://pypi.org/project/pytextrank) (\ud83d\udce5 76K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 06.03.2022):\n\t```\n\tpip install pytextrank\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/explosion/spacy-transformers\">spacy-transformers</a></b> (\ud83e\udd4828 \u00b7  \u2b50 1.2K) - Use pretrained transformers like BERT, XLNet and GPT-2.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code>spacy</code></summary>\n\n- [GitHub](https://github.com/explosion/spacy-transformers) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 710 \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/explosion/spacy-transformers\n\t```\n- [PyPi](https://pypi.org/project/spacy-transformers) (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 22 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install spacy-transformers\n\t```\n- [Conda](https://anaconda.org/conda-forge/spacy-transformers) (\ud83d\udce5 6.6K \u00b7 \u23f1\ufe0f 13.08.2022):\n\t```\n\tconda install -c conda-forge spacy-transformers\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Ciphey/Ciphey\">Ciphey</a></b> (\ud83e\udd4927 \u00b7  \u2b50 11K) - Automatically decrypt encryptions without knowing the key or cipher, decode.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/Ciphey/Ciphey) (\ud83d\udc68\u200d\ud83d\udcbb 46 \u00b7 \ud83d\udd00 680 \u00b7 \ud83d\udccb 290 - 16% open \u00b7 \u23f1\ufe0f 28.06.2022):\n\n\t```\n\tgit clone https://github.com/Ciphey/Ciphey\n\t```\n- [PyPi](https://pypi.org/project/ciphey) (\ud83d\udce5 28K / month \u00b7 \u23f1\ufe0f 06.06.2021):\n\t```\n\tpip install ciphey\n\t```\n- [Docker Hub](https://hub.docker.com/r/remnux/ciphey) (\ud83d\udce5 17K \u00b7 \u2b50 9 \u00b7 \u23f1\ufe0f 27.05.2022):\n\t```\n\tdocker pull remnux/ciphey\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dwyl/english-words\">english-words</a></b> (\ud83e\udd4927 \u00b7  \u2b50 8.4K) - A text file containing 479k English words for all your.. <code><a href=\"http://bit.ly/3rvuUlR\">Unlicense</a></code></summary>\n\n- [GitHub](https://github.com/dwyl/english-words) (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 1.5K \u00b7 \ud83d\udccb 100 - 68% open \u00b7 \u23f1\ufe0f 08.11.2022):\n\n\t```\n\tgit clone https://github.com/dwyl/english-words\n\t```\n- [PyPi](https://pypi.org/project/english-words) (\ud83d\udce5 130K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 29.01.2022):\n\t```\n\tpip install english-words\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/zjunlp/DeepKE\">DeepKE</a></b> (\ud83e\udd4927 \u00b7  \u2b50 1.5K) - An Open Toolkit for Knowledge Graph Extraction and Construction.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/zjunlp/DeepKE) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 400 \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/zjunlp/deepke\n\t```\n- [PyPi](https://pypi.org/project/deepke) (\ud83d\udce5 2.1K / month \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install deepke\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/JasonKessler/scattertext\">scattertext</a></b> (\ud83e\udd4926 \u00b7  \u2b50 2K) - Beautiful visualizations of how language differs among document.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/JasonKessler/scattertext) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 310 \u00b7 \ud83d\udccb 92 - 19% open \u00b7 \u23f1\ufe0f 11.11.2022):\n\n\t```\n\tgit clone https://github.com/JasonKessler/scattertext\n\t```\n- [PyPi](https://pypi.org/project/scattertext) (\ud83d\udce5 5.7K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 26.03.2022):\n\t```\n\tpip install scattertext\n\t```\n- [Conda](https://anaconda.org/conda-forge/scattertext) (\ud83d\udce5 71K \u00b7 \u23f1\ufe0f 11.11.2022):\n\t```\n\tconda install -c conda-forge scattertext\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/pytext\">PyText</a></b> (\ud83e\udd4925 \u00b7  \u2b50 6.4K \u00b7 \ud83d\udcc9) - A natural language modeling framework based on PyTorch. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/pytext) (\ud83d\udc68\u200d\ud83d\udcbb 230 \u00b7 \ud83d\udd00 800 \u00b7 \ud83d\udce5 310 \u00b7 \ud83d\udccb 220 - 66% open \u00b7 \u23f1\ufe0f 17.10.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/pytext\n\t```\n- [PyPi](https://pypi.org/project/pytext-nlp) (\ud83d\udce5 180 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 08.06.2020):\n\t```\n\tpip install pytext-nlp\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/argilla-io/argilla\">rubrix</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.4K) - Open-source tool for data-centric NLP. Argilla helps domain experts.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/argilla-io/argilla) (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udccb 720 - 12% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/recognai/rubrix\n\t```\n- [PyPi](https://pypi.org/project/rubrix) (\ud83d\udce5 910 / month \u00b7 \u23f1\ufe0f 08.06.2022):\n\t```\n\tpip install rubrix\n\t```\n- [Conda](https://anaconda.org/conda-forge/rubrix) (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 06.10.2022):\n\t```\n\tconda install -c conda-forge rubrix\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/thunlp/OpenPrompt\">OpenPrompt</a></b> (\ud83e\udd4924 \u00b7  \u2b50 2.1K) - An Open-Source Framework for Prompt-Learning. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/thunlp/OpenPrompt) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udce6 27 \u00b7 \ud83d\udccb 180 - 18% open \u00b7 \u23f1\ufe0f 09.11.2022):\n\n\t```\n\tgit clone https://github.com/thunlp/OpenPrompt\n\t```\n- [PyPi](https://pypi.org/project/openprompt) (\ud83d\udce5 1.7K / month \u00b7 \u23f1\ufe0f 06.07.2022):\n\t```\n\tpip install openprompt\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/bigscience-workshop/promptsource\">promptsource</a></b> (\ud83e\udd4924 \u00b7  \u2b50 900) - Toolkit for creating, sharing and using natural language.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/bigscience-workshop/promptsource) (\ud83d\udc68\u200d\ud83d\udcbb 59 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udce6 16 \u00b7 \ud83d\udccb 160 - 14% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/bigscience-workshop/promptsource\n\t```\n- [PyPi](https://pypi.org/project/promptsource) (\ud83d\udce5 5.5K / month \u00b7 \u23f1\ufe0f 18.04.2022):\n\t```\n\tpip install promptsource\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/minimaxir/gpt-2-simple\">gpt-2-simple</a></b> (\ud83e\udd4923 \u00b7  \u2b50 3.1K) - Python package to easily retrain OpenAIs GPT-2 text-.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/minimaxir/gpt-2-simple) (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 600 \u00b7 \ud83d\udce5 360 \u00b7 \ud83d\udccb 250 - 60% open \u00b7 \u23f1\ufe0f 22.05.2022):\n\n\t```\n\tgit clone https://github.com/minimaxir/gpt-2-simple\n\t```\n- [PyPi](https://pypi.org/project/gpt-2-simple) (\ud83d\udce5 8.2K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 18.10.2021):\n\t```\n\tpip install gpt-2-simple\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/bytedance/lightseq\">lightseq</a></b> (\ud83e\udd4923 \u00b7  \u2b50 2.5K) - LightSeq: A High Performance Library for Sequence Processing and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/bytedance/lightseq) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udce5 650 \u00b7 \ud83d\udccb 230 - 56% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/bytedance/lightseq\n\t```\n- [PyPi](https://pypi.org/project/lightseq) (\ud83d\udce5 5.7K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 26.01.2022):\n\t```\n\tpip install lightseq\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/utterworks/fast-bert\">fast-bert</a></b> (\ud83e\udd4923 \u00b7  \u2b50 1.8K) - Super easy library for BERT based NLP models. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/utterworks/fast-bert) (\ud83d\udc68\u200d\ud83d\udcbb 36 \u00b7 \ud83d\udd00 340 \u00b7 \ud83d\udccb 250 - 62% open \u00b7 \u23f1\ufe0f 27.09.2022):\n\n\t```\n\tgit clone https://github.com/utterworks/fast-bert\n\t```\n- [PyPi](https://pypi.org/project/fast-bert) (\ud83d\udce5 1.6K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 03.06.2022):\n\t```\n\tpip install fast-bert\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/awslabs/sockeye\">Sockeye</a></b> (\ud83e\udd4923 \u00b7  \u2b50 1.1K) - Sequence-to-sequence framework with a focus on Neural Machine.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1X\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/awslabs/sockeye) (\ud83d\udc68\u200d\ud83d\udcbb 58 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce5 15 \u00b7 \ud83d\udccb 290 - 3% open \u00b7 \u23f1\ufe0f 06.11.2022):\n\n\t```\n\tgit clone https://github.com/awslabs/sockeye\n\t```\n- [PyPi](https://pypi.org/project/sockeye) (\ud83d\udce5 690 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 05.05.2022):\n\t```\n\tpip install sockeye\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/qdrant/qdrant\">qdrant</a></b> (\ud83e\udd4922 \u00b7  \u2b50 3.1K) - Qdrant - Vector Search Engine for the next generation of AI.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/qdrant/qdrant) (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 330 - 7% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/qdrant/qdrant\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jbesomi/texthero\">Texthero</a></b> (\ud83e\udd4922 \u00b7  \u2b50 2.6K) - Text preprocessing, representation and visualization from zero to hero. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/jbesomi/texthero) (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce5 96 \u00b7 \ud83d\udccb 140 - 56% open \u00b7 \u23f1\ufe0f 28.10.2022):\n\n\t```\n\tgit clone https://github.com/jbesomi/texthero\n\t```\n- [PyPi](https://pypi.org/project/texthero) (\ud83d\udce5 26K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 01.07.2021):\n\t```\n\tpip install texthero\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nyu-mll/jiant\">jiant</a></b> (\ud83e\udd4922 \u00b7  \u2b50 1.4K) - jiant is an nlp toolkit. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/nyu-mll/jiant) (\ud83d\udc68\u200d\ud83d\udcbb 59 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 550 - 11% open \u00b7 \u23f1\ufe0f 17.10.2022):\n\n\t```\n\tgit clone https://github.com/nyu-mll/jiant\n\t```\n- [PyPi](https://pypi.org/project/jiant) (\ud83d\udce5 99 / month \u00b7 \u23f1\ufe0f 10.05.2021):\n\t```\n\tpip install jiant\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deepset-ai/FARM\">FARM</a></b> (\ud83e\udd4921 \u00b7  \u2b50 1.6K) - Fast & easy transfer learning for NLP. Harvesting language models.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/deepset-ai/FARM) (\ud83d\udc68\u200d\ud83d\udcbb 37 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udccb 440 - 8% open \u00b7 \u23f1\ufe0f 31.08.2022):\n\n\t```\n\tgit clone https://github.com/deepset-ai/FARM\n\t```\n- [PyPi](https://pypi.org/project/farm) (\ud83d\udce5 3.4K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 10.06.2021):\n\t```\n\tpip install farm\n\t```\n- [Conda](https://anaconda.org/conda-forge/farm) (\ud83d\udce5 1.9K \u00b7 \u23f1\ufe0f 14.06.2021):\n\t```\n\tconda install -c conda-forge farm\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/unitaryai/detoxify\">detoxify</a></b> (\ud83e\udd4921 \u00b7  \u2b50 500) - Trained models & code to predict toxic comments on all 3 Jigsaw.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/unitaryai/detoxify) (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 69 \u00b7 \ud83d\udce5 100K \u00b7 \ud83d\udce6 150 \u00b7 \ud83d\udccb 43 - 53% open \u00b7 \u23f1\ufe0f 15.11.2022):\n\n\t```\n\tgit clone https://github.com/unitaryai/detoxify\n\t```\n- [PyPi](https://pypi.org/project/detoxify) (\ud83d\udce5 44K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 12.04.2022):\n\t```\n\tpip install detoxify\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/webis-de/small-text\">small-text</a></b> (\ud83e\udd4921 \u00b7  \u2b50 360) - Active Learning for Text Classification in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/webis-de/small-text) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 39 \u00b7 \ud83d\udce6 14 \u00b7 \ud83d\udccb 23 - 26% open \u00b7 \u23f1\ufe0f 13.11.2022):\n\n\t```\n\tgit clone https://github.com/webis-de/small-text\n\t```\n- [PyPi](https://pypi.org/project/small-text) (\ud83d\udce5 400 / month \u00b7 \u23f1\ufe0f 14.06.2022):\n\t```\n\tpip install small-text\n\t```\n- [Conda](https://anaconda.org/conda-forge/small-text) (\ud83d\udce5 1.1K \u00b7 \u23f1\ufe0f 14.10.2022):\n\t```\n\tconda install -c conda-forge small-text\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/EricFillion/happy-transformer\">happy-transformer</a></b> (\ud83e\udd4921 \u00b7  \u2b50 350) - A package built on top of Hugging Faces transformers.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code>huggingface</code></summary>\n\n- [GitHub](https://github.com/EricFillion/happy-transformer) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 43 \u00b7 \ud83d\udce6 97 \u00b7 \ud83d\udccb 110 - 12% open \u00b7 \u23f1\ufe0f 31.10.2022):\n\n\t```\n\tgit clone https://github.com/EricFillion/happy-transformer\n\t```\n- [PyPi](https://pypi.org/project/happytransformer) (\ud83d\udce5 4.3K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 06.02.2022):\n\t```\n\tpip install happytransformer\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/IntelLabs/nlp-architect\">NLP Architect</a></b> (\ud83e\udd4920 \u00b7  \u2b50 2.9K) - A model library for exploring state-of-the-art deep learning.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/IntelLabs/nlp-architect) (\ud83d\udc68\u200d\ud83d\udcbb 38 \u00b7 \ud83d\udd00 450 \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 130 - 16% open \u00b7 \u23f1\ufe0f 07.11.2022):\n\n\t```\n\tgit clone https://github.com/IntelLabs/nlp-architect\n\t```\n- [PyPi](https://pypi.org/project/nlp-architect) (\ud83d\udce5 100 / month \u00b7 \u23f1\ufe0f 12.04.2020):\n\t```\n\tpip install nlp-architect\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/IndicoDataSolutions/finetune\">finetune</a></b> (\ud83e\udd4920 \u00b7  \u2b50 660) - Scikit-learn style model finetuning for NLP. <code><a href=\"http://bit.ly/3postzC\">MPL-2.0</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/IndicoDataSolutions/finetune) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 71 \u00b7 \ud83d\udce6 9 \u00b7 \ud83d\udccb 140 - 16% open \u00b7 \u23f1\ufe0f 16.06.2022):\n\n\t```\n\tgit clone https://github.com/IndicoDataSolutions/finetune\n\t```\n- [PyPi](https://pypi.org/project/finetune) (\ud83d\udce5 49 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 20.12.2021):\n\t```\n\tpip install finetune\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/RUCAIBox/TextBox\">TextBox</a></b> (\ud83e\udd4919 \u00b7  \u2b50 420) - TextBox 2.0 is a text generation library with pre-trained language models. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/RUCAIBox/TextBox) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 74 \u00b7 \ud83d\udce6 5 \u00b7 \ud83d\udccb 24 - 16% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/RUCAIBox/TextBox\n\t```\n- [PyPi](https://pypi.org/project/textbox) (\ud83d\udce5 42 / month \u00b7 \u23f1\ufe0f 15.04.2021):\n\t```\n\tpip install textbox\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Ki6an/fastT5\">fastT5</a></b> (\ud83e\udd4918 \u00b7  \u2b50 380 \u00b7 \ud83d\udca4) - boost inference speed of T5 models by 5x & reduce the model size.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Ki6an/fastT5) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 45 \u00b7 \ud83d\udce6 24 \u00b7 \ud83d\udccb 53 - 24% open \u00b7 \u23f1\ufe0f 05.04.2022):\n\n\t```\n\tgit clone https://github.com/Ki6an/fastT5\n\t```\n- [PyPi](https://pypi.org/project/fastt5) (\ud83d\udce5 1.2K / month \u00b7 \u23f1\ufe0f 05.04.2022):\n\t```\n\tpip install fastt5\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/thunlp/OpenNRE\">OpenNRE</a></b> (\ud83e\udd4916 \u00b7  \u2b50 3.8K) - An Open-Source Package for Neural Relation Extraction (NRE). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/thunlp/OpenNRE) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udccb 360 - 4% open \u00b7 \u23f1\ufe0f 03.11.2022):\n\n\t```\n\tgit clone https://github.com/thunlp/OpenNRE\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/translate\">Translate</a></b> (\ud83e\udd4915 \u00b7  \u2b50 770) - Translate - a PyTorch Language Library. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pytorch/translate) (\ud83d\udc68\u200d\ud83d\udcbb 87 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udccb 55 - 50% open \u00b7 \u23f1\ufe0f 10.06.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/translate\n\t```\n- [PyPi](https://pypi.org/project/pytorch-translate) (\ud83d\udce5 6 / month \u00b7 \u23f1\ufe0f 01.05.2018):\n\t```\n\tpip install pytorch-translate\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/vizseq\">VizSeq</a></b> (\ud83e\udd4914 \u00b7  \u2b50 410) - An Analysis Toolkit for Natural Language Generation (Translation,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/vizseq) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 51 \u00b7 \ud83d\udce6 6 \u00b7 \ud83d\udccb 16 - 43% open \u00b7 \u23f1\ufe0f 20.07.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/vizseq\n\t```\n- [PyPi](https://pypi.org/project/vizseq) (\ud83d\udce5 120 / month \u00b7 \u23f1\ufe0f 07.08.2020):\n\t```\n\tpip install vizseq\n\t```\n</details>\n<details><summary>Show 38 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/gunthercox/ChatterBot\">ChatterBot</a></b> (\ud83e\udd4736 \u00b7  \u2b50 13K \u00b7 \ud83d\udc80) - ChatterBot is a machine learning, conversational dialog engine.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/sloria/TextBlob\">TextBlob</a></b> (\ud83e\udd4834 \u00b7  \u2b50 8.4K \u00b7 \ud83d\udc80) - Simple, Pythonic, text processing--Sentiment analysis, part-of-.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/seatgeek/fuzzywuzzy\">fuzzywuzzy</a></b> (\ud83e\udd4833 \u00b7  \u2b50 8.8K \u00b7 \ud83d\udc80) - Fuzzy String Matching in Python. <code><a href=\"http://bit.ly/2KucAZR\">\u2757\ufe0fGPL-2.0</a></code>\n- <b><a href=\"https://github.com/dmlc/gluon-nlp\">GluonNLP</a></b> (\ud83e\udd4830 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udc80) - Toolkit that enables easy text preprocessing, datasets.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1X\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/huggingface/neuralcoref\">neuralcoref</a></b> (\ud83e\udd4828 \u00b7  \u2b50 2.6K \u00b7 \ud83d\udc80) - Fast Coreference Resolution in spaCy with Neural Networks. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/aboSamoor/polyglot\">polyglot</a></b> (\ud83e\udd4927 \u00b7  \u2b50 2.1K \u00b7 \ud83d\udc80) - Multilingual text (NLP) processing toolkit. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/saffsd/langid.py\">langid</a></b> (\ud83e\udd4927 \u00b7  \u2b50 2K \u00b7 \ud83d\udc80) - Stand-alone language identification system. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/vi3k6i5/flashtext\">flashtext</a></b> (\ud83e\udd4926 \u00b7  \u2b50 5.3K \u00b7 \ud83d\udc80) - Extract Keywords from sentence or Replace keywords in sentences. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/undertheseanlp/underthesea\">underthesea</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1K) - Underthesea - Vietnamese NLP Toolkit. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/snipsco/snips-nlu\">Snips NLU</a></b> (\ud83e\udd4925 \u00b7  \u2b50 3.7K \u00b7 \ud83d\udc80) - Snips Python library to extract meaning from text. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/explosion/sense2vec\">sense2vec</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.4K \u00b7 \ud83d\udc80) - Contextually-keyed word vectors. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/minimaxir/textgenrnn\">textgenrnn</a></b> (\ud83e\udd4924 \u00b7  \u2b50 4.8K \u00b7 \ud83d\udc80) - Easily train your own text-generating neural network of any.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/NTMC-Community/MatchZoo\">MatchZoo</a></b> (\ud83e\udd4924 \u00b7  \u2b50 3.7K \u00b7 \ud83d\udc80) - Facilitating the design, comparison and sharing of deep.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/PetrochukM/PyTorch-NLP\">pytorch-nlp</a></b> (\ud83e\udd4924 \u00b7  \u2b50 2.1K \u00b7 \ud83d\udc80) - Basic Utilities for PyTorch Natural Language Processing.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/mchaput/whoosh\">whoosh</a></b> (\ud83e\udd4924 \u00b7  \u2b50 330 \u00b7 \ud83d\udca4) - Pure-Python full-text search library. <code><a href=\"https://tldrlegal.com/search?q=BSD-1-Clause\">\u2757\ufe0fBSD-1-Clause</a></code>\n- <b><a href=\"https://github.com/BrikerMan/Kashgari\">Kashgari</a></b> (\ud83e\udd4923 \u00b7  \u2b50 2.3K \u00b7 \ud83d\udc80) - Kashgari is a production-level NLP Transfer learning.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/VKCOM/YouTokenToMe\">YouTokenToMe</a></b> (\ud83e\udd4923 \u00b7  \u2b50 840 \u00b7 \ud83d\udc80) - Unsupervised text tokenizer focused on computational efficiency. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/nipunsadvilkar/pySBD\">pySBD</a></b> (\ud83e\udd4923 \u00b7  \u2b50 520 \u00b7 \ud83d\udc80) - pySBD (Python Sentence Boundary Disambiguation) is a rule-based sentence.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/anhaidgroup/deepmatcher\">DeepMatcher</a></b> (\ud83e\udd4922 \u00b7  \u2b50 4.5K \u00b7 \ud83d\udc80) - Python package for performing Entity and Text Matching using.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/asyml/texar\">Texar</a></b> (\ud83e\udd4922 \u00b7  \u2b50 2.3K \u00b7 \ud83d\udc80) - Toolkit for Machine Learning, Natural Language Processing, and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/Hironsan/anago\">anaGo</a></b> (\ud83e\udd4922 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Bidirectional LSTM-CRF and ELMo for Named-Entity Recognition,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/Delta-ML/delta\">DELTA</a></b> (\ud83e\udd4921 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - DELTA is a deep learning based natural language and speech.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/Alir3z4/python-stop-words\">stop-words</a></b> (\ud83e\udd4921 \u00b7  \u2b50 140 \u00b7 \ud83d\udc80) - Get list of common stop words in various languages in Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/vrasneur/pyfasttext\">pyfasttext</a></b> (\ud83e\udd4920 \u00b7  \u2b50 230 \u00b7 \ud83d\udc80) - Yet another Python binding for fastText. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/textpipe/textpipe\">textpipe</a></b> (\ud83e\udd4919 \u00b7  \u2b50 300 \u00b7 \ud83d\udc80) - Textpipe: clean and extract metadata from text. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/Franck-Dernoncourt/NeuroNER\">NeuroNER</a></b> (\ud83e\udd4918 \u00b7  \u2b50 1.6K \u00b7 \ud83d\udc80) - Named-entity recognition using neural networks. Easy-to-use and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/dsfsi/textaugment\">textaugment</a></b> (\ud83e\udd4918 \u00b7  \u2b50 290) - TextAugment: Text Augmentation Library. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/koursaros-ai/nboost\">nboost</a></b> (\ud83e\udd4917 \u00b7  \u2b50 640 \u00b7 \ud83d\udc80) - NBoost is a scalable, search-api-boosting platform for deploying.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/shaypal5/skift\">skift</a></b> (\ud83e\udd4917 \u00b7  \u2b50 230) - scikit-learn wrappers for Python fastText. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/jaidevd/numerizer\">numerizer</a></b> (\ud83e\udd4916 \u00b7  \u2b50 190) - A Python module to convert natural language numerics into ints and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/PKSHATechnology-Research/camphr\">Camphr</a></b> (\ud83e\udd4915 \u00b7  \u2b50 340 \u00b7 \ud83d\udc80) - Camphr - NLP libary for creating pipeline components. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code>spacy</code>\n- <b><a href=\"https://github.com/victordibia/neuralqa\">NeuralQA</a></b> (\ud83e\udd4915 \u00b7  \u2b50 220 \u00b7 \ud83d\udc80) - NeuralQA: A Usable Library for Question Answering on Large Datasets.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/MartinoMensio/spacy-dbpedia-spotlight\">spacy-dbpedia-spotlight</a></b> (\ud83e\udd4915 \u00b7  \u2b50 83) - A spaCy wrapper for DBpedia Spotlight. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code>spacy</code>\n- <b><a href=\"https://github.com/facebookresearch/BLINK\">BLINK</a></b> (\ud83e\udd4914 \u00b7  \u2b50 970 \u00b7 \ud83d\udc80) - Entity Linker solution. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/as-ideas/headliner\">Headliner</a></b> (\ud83e\udd4914 \u00b7  \u2b50 230 \u00b7 \ud83d\udc80) - Easy training and deployment of seq2seq models. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/abelriboulot/onnxt5\">ONNX-T5</a></b> (\ud83e\udd4914 \u00b7  \u2b50 210 \u00b7 \ud83d\udc80) - Summarization, translation, sentiment-analysis, text-generation.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/feedly/transfer-nlp\">TransferNLP</a></b> (\ud83e\udd4913 \u00b7  \u2b50 290 \u00b7 \ud83d\udc80) - NLP library designed for reproducible experimentation.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/textvec/textvec\">textvec</a></b> (\ud83e\udd4912 \u00b7  \u2b50 180) - Text vectorization tool to outperform TFIDF for classification tasks. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Image Data\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for image & video processing, manipulation, and augmentation as well as libraries for computer vision tasks such as facial recognition, object detection, and classification._\n\n<details><summary><b><a href=\"https://github.com/python-pillow/Pillow\">Pillow</a></b> (\ud83e\udd4747 \u00b7  \u2b50 10K) - The friendly PIL fork (Python Imaging Library). <code><a href=\"https://tldrlegal.com/search?q=PIL\">\u2757\ufe0fPIL</a></code></summary>\n\n- [GitHub](https://github.com/python-pillow/Pillow) (\ud83d\udc68\u200d\ud83d\udcbb 420 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce6 910K \u00b7 \ud83d\udccb 2.7K - 4% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/python-pillow/Pillow\n\t```\n- [PyPi](https://pypi.org/project/Pillow) (\ud83d\udce5 51M / month \u00b7 \ud83d\udce6 63K \u00b7 \u23f1\ufe0f 29.10.2022):\n\t```\n\tpip install Pillow\n\t```\n- [Conda](https://anaconda.org/conda-forge/pillow) (\ud83d\udce5 21M \u00b7 \u23f1\ufe0f 28.10.2022):\n\t```\n\tconda install -c conda-forge pillow\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/scikit-image/scikit-image\">scikit-image</a></b> (\ud83e\udd4744 \u00b7  \u2b50 5.1K) - Image processing in Python. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/scikit-image/scikit-image) (\ud83d\udc68\u200d\ud83d\udcbb 580 \u00b7 \ud83d\udd00 2.1K \u00b7 \ud83d\udce6 120K \u00b7 \ud83d\udccb 2.5K - 25% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/scikit-image/scikit-image\n\t```\n- [PyPi](https://pypi.org/project/scikit-image) (\ud83d\udce5 5.9M / month \u00b7 \ud83d\udce6 9.4K \u00b7 \u23f1\ufe0f 12.06.2022):\n\t```\n\tpip install scikit-image\n\t```\n- [Conda](https://anaconda.org/conda-forge/scikit-image) (\ud83d\udce5 4.2M \u00b7 \u23f1\ufe0f 30.10.2022):\n\t```\n\tconda install -c conda-forge scikit-image\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/vision\">torchvision</a></b> (\ud83e\udd4742 \u00b7  \u2b50 13K) - Datasets, Transforms and Models specific to Computer Vision. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pytorch/vision) (\ud83d\udc68\u200d\ud83d\udcbb 510 \u00b7 \ud83d\udd00 6.3K \u00b7 \ud83d\udce5 16K \u00b7 \ud83d\udccb 2.8K - 29% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/vision\n\t```\n- [PyPi](https://pypi.org/project/torchvision) (\ud83d\udce5 7.5M / month \u00b7 \ud83d\udce6 3.7K \u00b7 \u23f1\ufe0f 28.06.2022):\n\t```\n\tpip install torchvision\n\t```\n- [Conda](https://anaconda.org/conda-forge/torchvision) (\ud83d\udce5 440K \u00b7 \u23f1\ufe0f 24.07.2022):\n\t```\n\tconda install -c conda-forge torchvision\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rwightman/pytorch-image-models\">PyTorch Image Models</a></b> (\ud83e\udd4739 \u00b7  \u2b50 22K) - PyTorch image models, scripts, pretrained weights --.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/rwightman/pytorch-image-models) (\ud83d\udc68\u200d\ud83d\udcbb 86 \u00b7 \ud83d\udd00 3.7K \u00b7 \ud83d\udce5 2.4M \u00b7 \ud83d\udce6 6K \u00b7 \ud83d\udccb 630 - 12% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/rwightman/pytorch-image-models\n\t```\n- [PyPi](https://pypi.org/project/timm) (\ud83d\udce5 1.4M / month \u00b7 \ud83d\udce6 110 \u00b7 \u23f1\ufe0f 15.05.2022):\n\t```\n\tpip install timm\n\t```\n- [Conda](https://anaconda.org/conda-forge/timm) (\ud83d\udce5 37K \u00b7 \u23f1\ufe0f 24.11.2022):\n\t```\n\tconda install -c conda-forge timm\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/open-mmlab/mmdetection\">MMDetection</a></b> (\ud83e\udd4738 \u00b7  \u2b50 22K \u00b7 \ud83d\udcc8) - OpenMMLab Detection Toolbox and Benchmark. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/open-mmlab/mmdetection) (\ud83d\udc68\u200d\ud83d\udcbb 380 \u00b7 \ud83d\udd00 8.1K \u00b7 \ud83d\udce6 730 \u00b7 \ud83d\udccb 6.6K - 9% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/open-mmlab/mmdetection\n\t```\n- [PyPi](https://pypi.org/project/mmdet) (\ud83d\udce5 89K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 01.06.2022):\n\t```\n\tpip install mmdet\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Zulko/moviepy\">MoviePy</a></b> (\ud83e\udd4737 \u00b7  \u2b50 9.8K) - Video editing with Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/Zulko/moviepy) (\ud83d\udc68\u200d\ud83d\udcbb 150 \u00b7 \ud83d\udd00 1.3K \u00b7 \ud83d\udce6 19K \u00b7 \ud83d\udccb 1.3K - 24% open \u00b7 \u23f1\ufe0f 10.10.2022):\n\n\t```\n\tgit clone https://github.com/Zulko/moviepy\n\t```\n- [PyPi](https://pypi.org/project/moviepy) (\ud83d\udce5 2.4M / month \u00b7 \ud83d\udce6 780 \u00b7 \u23f1\ufe0f 05.10.2020):\n\t```\n\tpip install moviepy\n\t```\n- [Conda](https://anaconda.org/conda-forge/moviepy) (\ud83d\udce5 140K \u00b7 \u23f1\ufe0f 07.10.2022):\n\t```\n\tconda install -c conda-forge moviepy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/imageio/imageio\">imageio</a></b> (\ud83e\udd4737 \u00b7  \u2b50 1.1K) - Python library for reading and writing image data. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/imageio/imageio) (\ud83d\udc68\u200d\ud83d\udcbb 94 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce5 410 \u00b7 \ud83d\udce6 72K \u00b7 \ud83d\udccb 500 - 13% open \u00b7 \u23f1\ufe0f 07.11.2022):\n\n\t```\n\tgit clone https://github.com/imageio/imageio\n\t```\n- [PyPi](https://pypi.org/project/imageio) (\ud83d\udce5 13M / month \u00b7 \ud83d\udce6 2.6K \u00b7 \u23f1\ufe0f 30.05.2022):\n\t```\n\tpip install imageio\n\t```\n- [Conda](https://anaconda.org/conda-forge/imageio) (\ud83d\udce5 3.9M \u00b7 \u23f1\ufe0f 24.11.2022):\n\t```\n\tconda install -c conda-forge imageio\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/albumentations-team/albumentations\">Albumentations</a></b> (\ud83e\udd4836 \u00b7  \u2b50 11K) - Fast image augmentation library and an easy-to-use wrapper.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/albumentations-team/albumentations) (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce6 10K \u00b7 \ud83d\udccb 710 - 43% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/albumentations-team/albumentations\n\t```\n- [PyPi](https://pypi.org/project/albumentations) (\ud83d\udce5 560K / month \u00b7 \ud83d\udce6 220 \u00b7 \u23f1\ufe0f 15.06.2022):\n\t```\n\tpip install albumentations\n\t```\n- [Conda](https://anaconda.org/conda-forge/albumentations) (\ud83d\udce5 75K \u00b7 \u23f1\ufe0f 20.09.2022):\n\t```\n\tconda install -c conda-forge albumentations\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/kornia/kornia\">Kornia</a></b> (\ud83e\udd4834 \u00b7  \u2b50 7.4K) - Open Source Differentiable Computer Vision Library. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/kornia/kornia) (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 740 \u00b7 \ud83d\udce5 480 \u00b7 \ud83d\udccb 680 - 30% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/kornia/kornia\n\t```\n- [PyPi](https://pypi.org/project/kornia) (\ud83d\udce5 970K / month \u00b7 \ud83d\udce6 58 \u00b7 \u23f1\ufe0f 17.05.2022):\n\t```\n\tpip install kornia\n\t```\n- [Conda](https://anaconda.org/conda-forge/kornia) (\ud83d\udce5 49K \u00b7 \u23f1\ufe0f 13.10.2022):\n\t```\n\tconda install -c conda-forge kornia\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/JohannesBuchner/imagehash\">ImageHash</a></b> (\ud83e\udd4834 \u00b7  \u2b50 2.6K) - A Python Perceptual Image Hashing Module. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/JohannesBuchner/imagehash) (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce6 6.5K \u00b7 \ud83d\udccb 120 - 9% open \u00b7 \u23f1\ufe0f 28.09.2022):\n\n\t```\n\tgit clone https://github.com/JohannesBuchner/imagehash\n\t```\n- [PyPi](https://pypi.org/project/ImageHash) (\ud83d\udce5 1.3M / month \u00b7 \ud83d\udce6 340 \u00b7 \u23f1\ufe0f 15.07.2021):\n\t```\n\tpip install ImageHash\n\t```\n- [Conda](https://anaconda.org/conda-forge/imagehash) (\ud83d\udce5 260K \u00b7 \u23f1\ufe0f 28.09.2022):\n\t```\n\tconda install -c conda-forge imagehash\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/emcconville/wand\">Wand</a></b> (\ud83e\udd4834 \u00b7  \u2b50 1.2K) - The ctypes-based simple ImageMagick binding for Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/emcconville/wand) (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce5 8.5K \u00b7 \ud83d\udce6 13K \u00b7 \ud83d\udccb 390 - 4% open \u00b7 \u23f1\ufe0f 13.10.2022):\n\n\t```\n\tgit clone https://github.com/emcconville/wand\n\t```\n- [PyPi](https://pypi.org/project/wand) (\ud83d\udce5 490K / month \u00b7 \ud83d\udce6 690 \u00b7 \u23f1\ufe0f 17.08.2021):\n\t```\n\tpip install wand\n\t```\n- [Conda](https://anaconda.org/conda-forge/wand) (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 22.08.2022):\n\t```\n\tconda install -c conda-forge wand\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/detectron2\">detectron2</a></b> (\ud83e\udd4833 \u00b7  \u2b50 23K) - Detectron2 is a platform for object detection, segmentation.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/detectron2) (\ud83d\udc68\u200d\ud83d\udcbb 220 \u00b7 \ud83d\udd00 6.2K \u00b7 \ud83d\udce6 800 \u00b7 \ud83d\udccb 3.2K - 9% open \u00b7 \u23f1\ufe0f 11.11.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/detectron2\n\t```\n- [PyPi](https://pypi.org/project/detectron2) (\ud83d\udce5 3 / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 06.02.2020):\n\t```\n\tpip install detectron2\n\t```\n- [Conda](https://anaconda.org/conda-forge/detectron2) (\ud83d\udce5 100K \u00b7 \u23f1\ufe0f 25.04.2022):\n\t```\n\tconda install -c conda-forge detectron2\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deepinsight/insightface\">InsightFace</a></b> (\ud83e\udd4833 \u00b7  \u2b50 13K) - State-of-the-art 2D and 3D Face Analysis Project. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1X\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/deepinsight/insightface) (\ud83d\udc68\u200d\ud83d\udcbb 49 \u00b7 \ud83d\udd00 4.1K \u00b7 \ud83d\udce6 210 \u00b7 \ud83d\udccb 2.1K - 56% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/deepinsight/insightface\n\t```\n- [PyPi](https://pypi.org/project/insightface) (\ud83d\udce5 24K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 29.01.2022):\n\t```\n\tpip install insightface\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PaddlePaddle/PaddleDetection\">PaddleDetection</a></b> (\ud83e\udd4833 \u00b7  \u2b50 9.1K) - Object Detection toolkit based on PaddlePaddle. It.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/PaddlePaddle/PaddleDetection) (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 2.3K \u00b7 \ud83d\udce6 42 \u00b7 \ud83d\udccb 4.2K - 20% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/PaddlePaddle/PaddleDetection\n\t```\n- [PyPi](https://pypi.org/project/paddledet) (\ud83d\udce5 1.6K / month \u00b7 \u23f1\ufe0f 24.04.2022):\n\t```\n\tpip install paddledet\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ageitgey/face_recognition\">Face Recognition</a></b> (\ud83e\udd4832 \u00b7  \u2b50 47K) - The worlds simplest facial recognition api for Python and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/ageitgey/face_recognition) (\ud83d\udc68\u200d\ud83d\udcbb 54 \u00b7 \ud83d\udd00 13K \u00b7 \ud83d\udce5 470 \u00b7 \ud83d\udccb 1.3K - 54% open \u00b7 \u23f1\ufe0f 10.06.2022):\n\n\t```\n\tgit clone https://github.com/ageitgey/face_recognition\n\t```\n- [PyPi](https://pypi.org/project/face_recognition) (\ud83d\udce5 52K / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 20.02.2020):\n\t```\n\tpip install face_recognition\n\t```\n- [Conda](https://anaconda.org/conda-forge/face_recognition) (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 30.04.2021):\n\t```\n\tconda install -c conda-forge face_recognition\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PaddlePaddle/PaddleSeg\">PaddleSeg</a></b> (\ud83e\udd4832 \u00b7  \u2b50 6K) - Easy-to-use image segmentation library with awesome pre-.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/PaddlePaddle/PaddleSeg) (\ud83d\udc68\u200d\ud83d\udcbb 84 \u00b7 \ud83d\udd00 1.3K \u00b7 \ud83d\udce6 730 \u00b7 \ud83d\udccb 1.4K - 45% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/PaddlePaddle/PaddleSeg\n\t```\n- [PyPi](https://pypi.org/project/paddleseg) (\ud83d\udce5 3.6K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 20.04.2022):\n\t```\n\tpip install paddleseg\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dmlc/gluon-cv\">GluonCV</a></b> (\ud83e\udd4832 \u00b7  \u2b50 5.4K) - Gluon CV Toolkit. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1X\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/dmlc/gluon-cv) (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udce6 920 \u00b7 \ud83d\udccb 830 - 7% open \u00b7 \u23f1\ufe0f 11.08.2022):\n\n\t```\n\tgit clone https://github.com/dmlc/gluon-cv\n\t```\n- [PyPi](https://pypi.org/project/gluoncv) (\ud83d\udce5 610K / month \u00b7 \ud83d\udce6 59 \u00b7 \u23f1\ufe0f 07.07.2022):\n\t```\n\tpip install gluoncv\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/opencv/opencv-python\">opencv-python</a></b> (\ud83e\udd4832 \u00b7  \u2b50 3.1K) - Automated CI toolchain to produce precompiled opencv-python,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/opencv/opencv-python) (\ud83d\udc68\u200d\ud83d\udcbb 40 \u00b7 \ud83d\udd00 610 \u00b7 \ud83d\udccb 600 - 9% open \u00b7 \u23f1\ufe0f 29.08.2022):\n\n\t```\n\tgit clone https://github.com/opencv/opencv-python\n\t```\n- [PyPi](https://pypi.org/project/opencv-python) (\ud83d\udce5 6.4M / month \u00b7 \ud83d\udce6 9.4K \u00b7 \u23f1\ufe0f 08.06.2022):\n\t```\n\tpip install opencv-python\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/serengil/deepface\">deepface</a></b> (\ud83e\udd4831 \u00b7  \u2b50 5K) - A Lightweight Face Recognition and Facial Attribute Analysis (Age, Gender,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/serengil/deepface) (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 890 \u00b7 \ud83d\udccb 560 - 1% open \u00b7 \u23f1\ufe0f 24.10.2022):\n\n\t```\n\tgit clone https://github.com/serengil/deepface\n\t```\n- [PyPi](https://pypi.org/project/deepface) (\ud83d\udce5 62K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 10.05.2022):\n\t```\n\tpip install deepface\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PyImageSearch/imutils\">imutils</a></b> (\ud83e\udd4831 \u00b7  \u2b50 4.2K \u00b7 \ud83d\udca4) - A series of convenience functions to make basic image processing.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/PyImageSearch/imutils) (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udce6 29K \u00b7 \ud83d\udccb 230 - 65% open \u00b7 \u23f1\ufe0f 27.01.2022):\n\n\t```\n\tgit clone https://github.com/PyImageSearch/imutils\n\t```\n- [PyPi](https://pypi.org/project/imutils) (\ud83d\udce5 340K / month \u00b7 \ud83d\udce6 780 \u00b7 \u23f1\ufe0f 15.01.2021):\n\t```\n\tpip install imutils\n\t```\n- [Conda](https://anaconda.org/conda-forge/imutils) (\ud83d\udce5 110K \u00b7 \u23f1\ufe0f 06.11.2022):\n\t```\n\tconda install -c conda-forge imutils\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/lucidrains/vit-pytorch\">vit-pytorch</a></b> (\ud83e\udd4828 \u00b7  \u2b50 12K) - Implementation of Vision Transformer, a simple way to achieve.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/lucidrains/vit-pytorch) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 2K \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 210 - 48% open \u00b7 \u23f1\ufe0f 29.10.2022):\n\n\t```\n\tgit clone https://github.com/lucidrains/vit-pytorch\n\t```\n- [PyPi](https://pypi.org/project/vit-pytorch) (\ud83d\udce5 21K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 30.06.2022):\n\t```\n\tpip install vit-pytorch\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/obss/sahi\">sahi</a></b> (\ud83e\udd4828 \u00b7  \u2b50 2.2K) - Framework agnostic sliced/tiled inference + interactive ui + error analysis.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/obss/sahi) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 330 \u00b7 \ud83d\udce5 9.2K \u00b7 \ud83d\udce6 180 \u00b7 \u23f1\ufe0f 15.11.2022):\n\n\t```\n\tgit clone https://github.com/obss/sahi\n\t```\n- [PyPi](https://pypi.org/project/sahi) (\ud83d\udce5 86K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 25.06.2022):\n\t```\n\tpip install sahi\n\t```\n- [Conda](https://anaconda.org/conda-forge/sahi) (\ud83d\udce5 23K \u00b7 \u23f1\ufe0f 16.11.2022):\n\t```\n\tconda install -c conda-forge sahi\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/lightly-ai/lightly\">lightly</a></b> (\ud83e\udd4828 \u00b7  \u2b50 1.9K) - A python library for self-supervised learning on images. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/lightly-ai/lightly) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 65 \u00b7 \ud83d\udccb 340 - 22% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/lightly-ai/lightly\n\t```\n- [PyPi](https://pypi.org/project/lightly) (\ud83d\udce5 3.3K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install lightly\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/luispedro/mahotas\">mahotas</a></b> (\ud83e\udd4828 \u00b7  \u2b50 780) - Computer Vision in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/luispedro/mahotas) (\ud83d\udc68\u200d\ud83d\udcbb 32 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 900 \u00b7 \ud83d\udccb 82 - 23% open \u00b7 \u23f1\ufe0f 14.11.2022):\n\n\t```\n\tgit clone https://github.com/luispedro/mahotas\n\t```\n- [PyPi](https://pypi.org/project/mahotas) (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 120 \u00b7 \u23f1\ufe0f 28.06.2022):\n\t```\n\tpip install mahotas\n\t```\n- [Conda](https://anaconda.org/conda-forge/mahotas) (\ud83d\udce5 350K \u00b7 \u23f1\ufe0f 05.11.2022):\n\t```\n\tconda install -c conda-forge mahotas\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/CellProfiler/CellProfiler\">CellProfiler</a></b> (\ud83e\udd4828 \u00b7  \u2b50 730) - An open-source application for biological image analysis. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/CellProfiler/CellProfiler) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 330 \u00b7 \ud83d\udce5 4.2K \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 3.1K - 6% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/CellProfiler/CellProfiler\n\t```\n- [PyPi](https://pypi.org/project/cellprofiler) (\ud83d\udce5 520 / month \u00b7 \u23f1\ufe0f 22.07.2021):\n\t```\n\tpip install cellprofiler\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/mindee/doctr\">doctr</a></b> (\ud83e\udd4927 \u00b7  \u2b50 1.4K) - docTR (Document Text Recognition) - a seamless, high-.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/mindee/doctr) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udce5 850K \u00b7 \ud83d\udce6 40 \u00b7 \ud83d\udccb 220 - 16% open \u00b7 \u23f1\ufe0f 12.10.2022):\n\n\t```\n\tgit clone https://github.com/mindee/doctr\n\t```\n- [PyPi](https://pypi.org/project/python-doctr) (\ud83d\udce5 5K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 22.03.2022):\n\t```\n\tpip install python-doctr\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/mdbloice/Augmentor\">Augmentor</a></b> (\ud83e\udd4926 \u00b7  \u2b50 4.8K) - Image augmentation library in Python for machine learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/mdbloice/Augmentor) (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 850 \u00b7 \ud83d\udce6 500 \u00b7 \ud83d\udccb 200 - 63% open \u00b7 \u23f1\ufe0f 23.09.2022):\n\n\t```\n\tgit clone https://github.com/mdbloice/Augmentor\n\t```\n- [PyPi](https://pypi.org/project/Augmentor) (\ud83d\udce5 26K / month \u00b7 \ud83d\udce6 29 \u00b7 \u23f1\ufe0f 27.04.2022):\n\t```\n\tpip install Augmentor\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/timesler/facenet-pytorch\">facenet-pytorch</a></b> (\ud83e\udd4926 \u00b7  \u2b50 3.2K \u00b7 \ud83d\udca4) - Pretrained Pytorch face detection (MTCNN) and facial.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/timesler/facenet-pytorch) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 700 \u00b7 \ud83d\udce5 490K \u00b7 \ud83d\udce6 920 \u00b7 \ud83d\udccb 160 - 41% open \u00b7 \u23f1\ufe0f 13.12.2021):\n\n\t```\n\tgit clone https://github.com/timesler/facenet-pytorch\n\t```\n- [PyPi](https://pypi.org/project/facenet-pytorch) (\ud83d\udce5 18K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 10.03.2021):\n\t```\n\tpip install facenet-pytorch\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/abhiTronix/vidgear\">vidgear</a></b> (\ud83e\udd4926 \u00b7  \u2b50 2.5K) - A High-performance cross-platform Video Processing Python framework.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/abhiTronix/vidgear) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce5 680 \u00b7 \ud83d\udce6 240 \u00b7 \ud83d\udccb 240 - 3% open \u00b7 \u23f1\ufe0f 06.07.2022):\n\n\t```\n\tgit clone https://github.com/abhiTronix/vidgear\n\t```\n- [PyPi](https://pypi.org/project/vidgear) (\ud83d\udce5 5.1K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install vidgear\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tryolabs/norfair\">Norfair</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.7K) - Lightweight Python library for adding real-time multi-object tracking.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/tryolabs/norfair) (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce5 230 \u00b7 \ud83d\udccb 100 - 5% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/tryolabs/norfair\n\t```\n- [PyPi](https://pypi.org/project/norfair) (\ud83d\udce5 5.2K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 30.05.2022):\n\t```\n\tpip install norfair\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/idealo/imagededup\">Image Deduplicator</a></b> (\ud83e\udd4925 \u00b7  \u2b50 4.3K) - Finding duplicate images made easy!. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/idealo/imagededup) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 390 \u00b7 \ud83d\udce6 29 \u00b7 \ud83d\udccb 120 - 39% open \u00b7 \u23f1\ufe0f 15.11.2022):\n\n\t```\n\tgit clone https://github.com/idealo/imagededup\n\t```\n- [PyPi](https://pypi.org/project/imagededup) (\ud83d\udce5 1.2K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 22.11.2020):\n\t```\n\tpip install imagededup\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/qubvel/segmentation_models\">segmentation_models</a></b> (\ud83e\udd4925 \u00b7  \u2b50 4.1K) - Segmentation models with pretrained backbones. Keras.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/qubvel/segmentation_models) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 940 \u00b7 \ud83d\udccb 500 - 47% open \u00b7 \u23f1\ufe0f 29.07.2022):\n\n\t```\n\tgit clone https://github.com/qubvel/segmentation_models\n\t```\n- [PyPi](https://pypi.org/project/segmentation_models) (\ud83d\udce5 21K / month \u00b7 \ud83d\udce6 24 \u00b7 \u23f1\ufe0f 10.01.2020):\n\t```\n\tpip install segmentation_models\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Layout-Parser/layout-parser\">layout-parser</a></b> (\ud83e\udd4925 \u00b7  \u2b50 3.3K) - A Unified Toolkit for Deep Learning Based Document Image.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Layout-Parser/layout-parser) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce6 110 \u00b7 \ud83d\udccb 110 - 54% open \u00b7 \u23f1\ufe0f 06.08.2022):\n\n\t```\n\tgit clone https://github.com/Layout-Parser/layout-parser\n\t```\n- [PyPi](https://pypi.org/project/layoutparser) (\ud83d\udce5 44K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 06.04.2022):\n\t```\n\tpip install layoutparser\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/pytorchvideo\">pytorchvideo</a></b> (\ud83e\udd4925 \u00b7  \u2b50 2.7K) - A deep learning library for video understanding research. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/pytorchvideo) (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udccb 170 - 40% open \u00b7 \u23f1\ufe0f 02.11.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/pytorchvideo\n\t```\n- [PyPi](https://pypi.org/project/pytorchvideo) (\ud83d\udce5 18K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 20.01.2022):\n\t```\n\tpip install pytorchvideo\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/libvips/pyvips\">pyvips</a></b> (\ud83e\udd4925 \u00b7  \u2b50 460) - python binding for libvips using cffi. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/libvips/pyvips) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 42 \u00b7 \ud83d\udce6 390 \u00b7 \ud83d\udccb 310 - 36% open \u00b7 \u23f1\ufe0f 06.11.2022):\n\n\t```\n\tgit clone https://github.com/libvips/pyvips\n\t```\n- [PyPi](https://pypi.org/project/pyvips) (\ud83d\udce5 21K / month \u00b7 \ud83d\udce6 40 \u00b7 \u23f1\ufe0f 12.06.2022):\n\t```\n\tpip install pyvips\n\t```\n- [Conda](https://anaconda.org/conda-forge/pyvips) (\ud83d\udce5 41K \u00b7 \u23f1\ufe0f 29.10.2022):\n\t```\n\tconda install -c conda-forge pyvips\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/mmf\">MMF</a></b> (\ud83e\udd4924 \u00b7  \u2b50 5.1K) - A modular framework for vision & language multimodal research from.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/mmf) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 880 \u00b7 \ud83d\udce6 13 \u00b7 \ud83d\udccb 670 - 35% open \u00b7 \u23f1\ufe0f 19.10.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/mmf\n\t```\n- [PyPi](https://pypi.org/project/mmf) (\ud83d\udce5 250 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 12.06.2020):\n\t```\n\tpip install mmf\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/lucidrains/deep-daze\">deep-daze</a></b> (\ud83e\udd4923 \u00b7  \u2b50 4.4K \u00b7 \ud83d\udca4) - Simple command line tool for text to image generation using.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/lucidrains/deep-daze) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce6 47 \u00b7 \ud83d\udccb 170 - 56% open \u00b7 \u23f1\ufe0f 13.03.2022):\n\n\t```\n\tgit clone https://github.com/lucidrains/deep-daze\n\t```\n- [PyPi](https://pypi.org/project/deep-daze) (\ud83d\udce5 1.9K / month \u00b7 \u23f1\ufe0f 13.03.2022):\n\t```\n\tpip install deep-daze\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/vissl\">vissl</a></b> (\ud83e\udd4923 \u00b7  \u2b50 2.9K) - VISSL is FAIRs library of extensible, modular and scalable components.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/vissl) (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udce6 13 \u00b7 \ud83d\udccb 160 - 37% open \u00b7 \u23f1\ufe0f 12.10.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/vissl\n\t```\n- [PyPi](https://pypi.org/project/vissl) (\ud83d\udce5 360 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 02.11.2021):\n\t```\n\tpip install vissl\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/graphics\">tensorflow-graphics</a></b> (\ud83e\udd4923 \u00b7  \u2b50 2.7K) - TensorFlow Graphics: Differentiable Graphics Layers.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/graphics) (\ud83d\udc68\u200d\ud83d\udcbb 37 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udccb 230 - 60% open \u00b7 \u23f1\ufe0f 11.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/graphics\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-graphics) (\ud83d\udce5 4.3K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 03.12.2021):\n\t```\n\tpip install tensorflow-graphics\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/airctic/icevision\">icevision</a></b> (\ud83e\udd4923 \u00b7  \u2b50 780) - An Agnostic Computer Vision Framework - Pluggable to any Training.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/airctic/icevision) (\ud83d\udc68\u200d\ud83d\udcbb 41 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udccb 560 - 9% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/airctic/icevision\n\t```\n- [PyPi](https://pypi.org/project/icevision) (\ud83d\udce5 3.7K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 10.02.2022):\n\t```\n\tpip install icevision\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/pycls\">pycls</a></b> (\ud83e\udd4921 \u00b7  \u2b50 2K) - Codebase for Image Classification Research, written in PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/pycls) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 81 - 30% open \u00b7 \u23f1\ufe0f 12.07.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/pycls\n\t```\n- [PyPi](https://pypi.org/project/pycls) (\ud83d\udce5 150K / month \u00b7 \u23f1\ufe0f 05.09.2020):\n\t```\n\tpip install pycls\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google-research/kubric\">kubric</a></b> (\ud83e\udd4921 \u00b7  \u2b50 1.7K) - A data generation pipeline for creating semi-realistic synthetic.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/google-research/kubric) (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 160 - 28% open \u00b7 \u23f1\ufe0f 21.09.2022):\n\n\t```\n\tgit clone https://github.com/google-research/kubric\n\t```\n- [PyPi](https://pypi.org/project/kubric-nightly) (\ud83d\udce5 3.7K / month \u00b7 \u23f1\ufe0f 06.07.2022):\n\t```\n\tpip install kubric-nightly\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google-research/scenic\">scenic</a></b> (\ud83e\udd4921 \u00b7  \u2b50 1.6K) - Scenic: A Jax Library for Computer Vision Research and Beyond. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/google-research/scenic) (\ud83d\udc68\u200d\ud83d\udcbb 54 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce6 28 \u00b7 \ud83d\udccb 89 - 41% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/google-research/scenic\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/ClassyVision\">Classy Vision</a></b> (\ud83e\udd4921 \u00b7  \u2b50 1.5K) - An end-to-end PyTorch framework for image and video.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/ClassyVision) (\ud83d\udc68\u200d\ud83d\udcbb 77 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udccb 120 - 45% open \u00b7 \u23f1\ufe0f 27.09.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/ClassyVision\n\t```\n- [PyPi](https://pypi.org/project/classy_vision) (\ud83d\udce5 2K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 09.07.2021):\n\t```\n\tpip install classy_vision\n\t```\n- [Conda](https://anaconda.org/conda-forge/classy_vision) (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 22.03.2022):\n\t```\n\tconda install -c conda-forge classy_vision\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/SlowFast\">PySlowFast</a></b> (\ud83e\udd4920 \u00b7  \u2b50 5.3K) - PySlowFast: video understanding codebase from FAIR for.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/SlowFast) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udce6 10 \u00b7 \ud83d\udccb 590 - 54% open \u00b7 \u23f1\ufe0f 27.09.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/SlowFast\n\t```\n- [PyPi](https://pypi.org/project/pyslowfast) (\ud83d\udce5 21 / month \u00b7 \u23f1\ufe0f 15.01.2020):\n\t```\n\tpip install pyslowfast\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/libffcv/ffcv\">ffcv</a></b> (\ud83e\udd4920 \u00b7  \u2b50 2.3K) - FFCV: Fast Forward Computer Vision (and other ML workloads!). <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/libffcv/ffcv) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 200 - 26% open \u00b7 \u23f1\ufe0f 21.07.2022):\n\n\t```\n\tgit clone https://github.com/libffcv/ffcv\n\t```\n- [PyPi](https://pypi.org/project/ffcv) (\ud83d\udce5 660 / month \u00b7 \u23f1\ufe0f 28.01.2022):\n\t```\n\tpip install ffcv\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/alankbi/detecto\">detecto</a></b> (\ud83e\udd4920 \u00b7  \u2b50 560 \u00b7 \ud83d\udca4) - Build fully-functioning computer vision models with PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/alankbi/detecto) (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 97 \u00b7 \ud83d\udce6 110 \u00b7 \ud83d\udccb 98 - 37% open \u00b7 \u23f1\ufe0f 09.02.2022):\n\n\t```\n\tgit clone https://github.com/alankbi/detecto\n\t```\n- [PyPi](https://pypi.org/project/detecto) (\ud83d\udce5 3.3K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 02.02.2022):\n\t```\n\tpip install detecto\n\t```\n- [Conda](https://anaconda.org/conda-forge/detecto) (\ud83d\udce5 1.8K \u00b7 \u23f1\ufe0f 02.02.2022):\n\t```\n\tconda install -c conda-forge detecto\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/detr\">DE\u2af6TR</a></b> (\ud83e\udd4919 \u00b7  \u2b50 10K \u00b7 \ud83d\udca4) - End-to-End Object Detection with Transformers. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/detr) (\ud83d\udc68\u200d\ud83d\udcbb 25 \u00b7 \ud83d\udd00 1.8K \u00b7 \ud83d\udccb 470 - 40% open \u00b7 \u23f1\ufe0f 07.03.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/detr\n\t```\n</details>\n<details><summary>Show 16 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/glfw/glfw\">glfw</a></b> (\ud83e\udd4835 \u00b7  \u2b50 9.9K \u00b7 \ud83d\udcc9) - A multi-platform library for OpenGL, OpenGL ES, Vulkan, window and.. <code><a href=\"https://tldrlegal.com/search?q=Zlib\">\u2757\ufe0fZlib</a></code>\n- <b><a href=\"https://github.com/aleju/imgaug\">imgaug</a></b> (\ud83e\udd4834 \u00b7  \u2b50 13K \u00b7 \ud83d\udc80) - Image augmentation for machine learning experiments. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/OlafenwaMoses/ImageAI\">imageai</a></b> (\ud83e\udd4830 \u00b7  \u2b50 7.4K \u00b7 \ud83d\udc80) - A python library built to empower developers to build applications.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/facebookresearch/pytorch3d\">PyTorch3D</a></b> (\ud83e\udd4829 \u00b7  \u2b50 6.8K) - PyTorch3D is FAIRs library of reusable components for.. <code>\u2757Unlicensed</code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/1adrianb/face-alignment\">Face Alignment</a></b> (\ud83e\udd4927 \u00b7  \u2b50 6K \u00b7 \ud83d\udc80) - 2D and 3D Face alignment library build using pytorch. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/chainer/chainercv\">chainercv</a></b> (\ud83e\udd4927 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - ChainerCV: a Library for Deep Learning in Computer Vision. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/uploadcare/pillow-simd\">Pillow-SIMD</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.9K) - The friendly PIL fork. <code><a href=\"https://tldrlegal.com/search?q=PIL\">\u2757\ufe0fPIL</a></code>\n- <b><a href=\"https://github.com/ipazc/mtcnn\">mtcnn</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.9K \u00b7 \ud83d\udc80) - MTCNN face detection implementation for TensorFlow, as a PIP.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/idealo/image-super-resolution\">Image Super-Resolution</a></b> (\ud83e\udd4923 \u00b7  \u2b50 3.9K \u00b7 \ud83d\udc80) - Super-scale your images and run experiments with.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/tryolabs/luminoth\">Luminoth</a></b> (\ud83e\udd4923 \u00b7  \u2b50 2.4K \u00b7 \ud83d\udc80) - Deep Learning toolkit for Computer Vision. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/hhatto/nude.py\">nude.py</a></b> (\ud83e\udd4921 \u00b7  \u2b50 870 \u00b7 \ud83d\udc80) - Nudity detection with Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/ProvenanceLabs/image-match\">image-match</a></b> (\ud83e\udd4920 \u00b7  \u2b50 2.8K \u00b7 \ud83d\udc80) - Quickly search over billions of images. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/jasmcaus/caer\">Caer</a></b> (\ud83e\udd4918 \u00b7  \u2b50 660 \u00b7 \ud83d\udc80) - A lightweight Computer Vision library. Scale your models, not boilerplate. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/Oulu-IMEDS/solt\">solt</a></b> (\ud83e\udd4917 \u00b7  \u2b50 260) - Streaming over lightweight data transformations. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/nicolas-chaulet/torch-points3d\">Torch Points 3D</a></b> (\ud83e\udd4916 \u00b7  \u2b50 110 \u00b7 \ud83d\udca4) - Pytorch framework for doing deep learning on point.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/qanastek/HugsVision\">HugsVision</a></b> (\ud83e\udd4914 \u00b7  \u2b50 170 \u00b7 \ud83d\udca4) - HugsVision is a easy to use huggingface wrapper for state-of-.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code>huggingface</code>\n</details>\n<br>\n\n## Graph Data\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for graph processing, clustering, embedding, and machine learning tasks._\n\n<details><summary><b><a href=\"https://github.com/networkx/networkx\">networkx</a></b> (\ud83e\udd4744 \u00b7  \u2b50 12K) - Network Analysis in Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/networkx/networkx) (\ud83d\udc68\u200d\ud83d\udcbb 630 \u00b7 \ud83d\udd00 2.8K \u00b7 \ud83d\udce5 60 \u00b7 \ud83d\udce6 120K \u00b7 \ud83d\udccb 3.1K - 12% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/networkx/networkx\n\t```\n- [PyPi](https://pypi.org/project/networkx) (\ud83d\udce5 21M / month \u00b7 \ud83d\udce6 13K \u00b7 \u23f1\ufe0f 14.06.2022):\n\t```\n\tpip install networkx\n\t```\n- [Conda](https://anaconda.org/conda-forge/networkx) (\ud83d\udce5 8.9M \u00b7 \u23f1\ufe0f 02.11.2022):\n\t```\n\tconda install -c conda-forge networkx\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pyg-team/pytorch_geometric\">PyTorch Geometric</a></b> (\ud83e\udd4738 \u00b7  \u2b50 16K) - Graph Neural Network Library for PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pyg-team/pytorch_geometric) (\ud83d\udc68\u200d\ud83d\udcbb 340 \u00b7 \ud83d\udd00 3K \u00b7 \ud83d\udccb 2.9K - 23% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/pyg-team/pytorch_geometric\n\t```\n- [PyPi](https://pypi.org/project/torch-geometric) (\ud83d\udce5 120K / month \u00b7 \ud83d\udce6 50 \u00b7 \u23f1\ufe0f 12.03.2022):\n\t```\n\tpip install torch-geometric\n\t```\n- [Conda](https://anaconda.org/conda-forge/pytorch_geometric) (\ud83d\udce5 14K \u00b7 \u23f1\ufe0f 19.08.2022):\n\t```\n\tconda install -c conda-forge pytorch_geometric\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dmlc/dgl\">dgl</a></b> (\ud83e\udd4737 \u00b7  \u2b50 11K) - Python package built to ease deep learning on graph, on top of existing DL.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/dmlc/dgl) (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 2.6K \u00b7 \ud83d\udce6 39 \u00b7 \ud83d\udccb 2K - 16% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/dmlc/dgl\n\t```\n- [PyPi](https://pypi.org/project/dgl) (\ud83d\udce5 34K / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 16.03.2022):\n\t```\n\tpip install dgl\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/snap-stanford/ogb\">ogb</a></b> (\ud83e\udd4829 \u00b7  \u2b50 1.5K) - Benchmark datasets, data loaders, and evaluators for graph machine learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/snap-stanford/ogb) (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 340 \u00b7 \ud83d\udce6 500 \u00b7 \ud83d\udccb 240 - 1% open \u00b7 \u23f1\ufe0f 02.11.2022):\n\n\t```\n\tgit clone https://github.com/snap-stanford/ogb\n\t```\n- [PyPi](https://pypi.org/project/ogb) (\ud83d\udce5 22K / month \u00b7 \ud83d\udce6 18 \u00b7 \u23f1\ufe0f 23.02.2022):\n\t```\n\tpip install ogb\n\t```\n- [Conda](https://anaconda.org/conda-forge/ogb) (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 03.11.2022):\n\t```\n\tconda install -c conda-forge ogb\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/graphistry/pygraphistry\">pygraphistry</a></b> (\ud83e\udd4827 \u00b7  \u2b50 1.8K) - PyGraphistry is a Python library to quickly load, shape,.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/graphistry/pygraphistry) (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 80 \u00b7 \ud83d\udccb 250 - 47% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/graphistry/pygraphistry\n\t```\n- [PyPi](https://pypi.org/project/graphistry) (\ud83d\udce5 2.9K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 02.07.2022):\n\t```\n\tpip install graphistry\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PaddlePaddle/PGL\">Paddle Graph Learning</a></b> (\ud83e\udd4827 \u00b7  \u2b50 1.4K) - Paddle Graph Learning (PGL) is an efficient and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/PaddlePaddle/PGL) (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 280 \u00b7 \ud83d\udce6 35 \u00b7 \ud83d\udccb 160 - 38% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/PaddlePaddle/PGL\n\t```\n- [PyPi](https://pypi.org/project/pgl) (\ud83d\udce5 5.3K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 21.04.2022):\n\t```\n\tpip install pgl\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/danielegrattarola/spektral\">Spektral</a></b> (\ud83e\udd4826 \u00b7  \u2b50 2.2K) - Graph Neural Networks with Keras and Tensorflow 2. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/danielegrattarola/spektral) (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 240 - 19% open \u00b7 \u23f1\ufe0f 19.10.2022):\n\n\t```\n\tgit clone https://github.com/danielegrattarola/spektral\n\t```\n- [PyPi](https://pypi.org/project/spektral) (\ud83d\udce5 5.4K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 09.04.2022):\n\t```\n\tpip install spektral\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/benedekrozemberczki/pytorch_geometric_temporal\">pytorch_geometric_temporal</a></b> (\ud83e\udd4825 \u00b7  \u2b50 1.8K) - PyTorch Geometric Temporal: Spatiotemporal Signal.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/benedekrozemberczki/pytorch_geometric_temporal) (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udccb 130 - 7% open \u00b7 \u23f1\ufe0f 25.10.2022):\n\n\t```\n\tgit clone https://github.com/benedekrozemberczki/pytorch_geometric_temporal\n\t```\n- [PyPi](https://pypi.org/project/torch-geometric-temporal) (\ud83d\udce5 3.1K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 04.04.2022):\n\t```\n\tpip install torch-geometric-temporal\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pykeen/pykeen\">PyKEEN</a></b> (\ud83e\udd4825 \u00b7  \u2b50 1K) - A Python library for learning and evaluating knowledge graph embeddings. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/pykeen/pykeen) (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce5 140 \u00b7 \ud83d\udccb 460 - 16% open \u00b7 \u23f1\ufe0f 20.11.2022):\n\n\t```\n\tgit clone https://github.com/pykeen/pykeen\n\t```\n- [PyPi](https://pypi.org/project/pykeen) (\ud83d\udce5 3.3K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 24.05.2022):\n\t```\n\tpip install pykeen\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/PyTorch-BigGraph\">PyTorch-BigGraph</a></b> (\ud83e\udd4824 \u00b7  \u2b50 3.1K) - Generate embeddings from large-scale graph-structured.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/PyTorch-BigGraph) (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 420 \u00b7 \ud83d\udce5 140 \u00b7 \ud83d\udccb 190 - 28% open \u00b7 \u23f1\ufe0f 09.09.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/PyTorch-BigGraph\n\t```\n- [PyPi](https://pypi.org/project/torchbiggraph) (\ud83d\udce5 210K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 01.05.2019):\n\t```\n\tpip install torchbiggraph\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/eliorc/node2vec\">Node2Vec</a></b> (\ud83e\udd4923 \u00b7  \u2b50 990) - Implementation of the node2vec algorithm. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/eliorc/node2vec) (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udccb 82 - 1% open \u00b7 \u23f1\ufe0f 19.10.2022):\n\n\t```\n\tgit clone https://github.com/eliorc/node2vec\n\t```\n- [PyPi](https://pypi.org/project/node2vec) (\ud83d\udce5 100K / month \u00b7 \ud83d\udce6 16 \u00b7 \u23f1\ufe0f 30.04.2022):\n\t```\n\tpip install node2vec\n\t```\n- [Conda](https://anaconda.org/conda-forge/node2vec) (\ud83d\udce5 23K \u00b7 \u23f1\ufe0f 25.04.2020):\n\t```\n\tconda install -c conda-forge node2vec\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/graph4ai/graph4nlp\">graph4nlp</a></b> (\ud83e\udd4922 \u00b7  \u2b50 1.5K) - Graph4nlp is the library for the easy use of Graph Neural.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/graph4ai/graph4nlp) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udccb 170 - 6% open \u00b7 \u23f1\ufe0f 13.11.2022):\n\n\t```\n\tgit clone https://github.com/graph4ai/graph4nlp\n\t```\n- [PyPi](https://pypi.org/project/graph4nlp) (\ud83d\udce5 190 / month \u00b7 \u23f1\ufe0f 20.01.2022):\n\t```\n\tpip install graph4nlp\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rusty1s/pytorch_cluster\">torch-cluster</a></b> (\ud83e\udd4922 \u00b7  \u2b50 590) - PyTorch Extension Library of Optimized Graph Cluster.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/rusty1s/pytorch_cluster) (\ud83d\udc68\u200d\ud83d\udcbb 26 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udccb 110 - 20% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/rusty1s/pytorch_cluster\n\t```\n- [PyPi](https://pypi.org/project/torch-cluster) (\ud83d\udce5 15K / month \u00b7 \ud83d\udce6 30 \u00b7 \u23f1\ufe0f 11.03.2022):\n\t```\n\tpip install torch-cluster\n\t```\n- [Conda](https://anaconda.org/conda-forge/pytorch_cluster) (\ud83d\udce5 47K \u00b7 \u23f1\ufe0f 25.10.2022):\n\t```\n\tconda install -c conda-forge pytorch_cluster\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deepmind/jraph\">jraph</a></b> (\ud83e\udd4919 \u00b7  \u2b50 1.1K) - A Graph Neural Network Library in Jax. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/deepmind/jraph) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 66 \u00b7 \ud83d\udce6 36 \u00b7 \ud83d\udccb 41 - 36% open \u00b7 \u23f1\ufe0f 31.08.2022):\n\n\t```\n\tgit clone https://github.com/deepmind/jraph\n\t```\n- [PyPi](https://pypi.org/project/jraph) (\ud83d\udce5 3.4K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 06.06.2022):\n\t```\n\tpip install jraph\n\t```\n- [Conda](https://anaconda.org/conda-forge/jraph) (\ud83d\udce5 1.2K \u00b7 \u23f1\ufe0f 31.10.2021):\n\t```\n\tconda install -c conda-forge jraph\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/vaticle/typedb-ml\">kglib</a></b> (\ud83e\udd4918 \u00b7  \u2b50 530) - TypeDB-ML is the Machine Learning integrations library for TypeDB. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/vaticle/typedb-ml) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 94 \u00b7 \ud83d\udce5 210 \u00b7 \ud83d\udccb 61 - 18% open \u00b7 \u23f1\ufe0f 09.11.2022):\n\n\t```\n\tgit clone https://github.com/vaticle/kglib\n\t```\n- [PyPi](https://pypi.org/project/grakn-kglib) (\ud83d\udce5 25 / month \u00b7 \u23f1\ufe0f 19.08.2020):\n\t```\n\tpip install grakn-kglib\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/shenweichen/GraphEmbedding\">GraphEmbedding</a></b> (\ud83e\udd4916 \u00b7  \u2b50 3.1K) - Implementation and experiments of graph embedding algorithms. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/shenweichen/GraphEmbedding) (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 890 \u00b7 \ud83d\udce6 22 \u00b7 \ud83d\udccb 70 - 64% open \u00b7 \u23f1\ufe0f 21.06.2022):\n\n\t```\n\tgit clone https://github.com/shenweichen/GraphEmbedding\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/thunlp/OpenKE\">OpenKE</a></b> (\ud83e\udd4915 \u00b7  \u2b50 3.3K) - An Open-Source Package for Knowledge Embedding (KE). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/thunlp/OpenKE) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 920 \u00b7 \ud83d\udccb 360 - 1% open \u00b7 \u23f1\ufe0f 03.11.2022):\n\n\t```\n\tgit clone https://github.com/thunlp/OpenKE\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/snap-stanford/GraphGym\">GraphGym</a></b> (\ud83e\udd4915 \u00b7  \u2b50 1.2K) - Platform for designing and evaluating Graph Neural Networks (GNN). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/snap-stanford/GraphGym) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce5 18 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 35 - 22% open \u00b7 \u23f1\ufe0f 25.08.2022):\n\n\t```\n\tgit clone https://github.com/snap-stanford/GraphGym\n\t```\n- [PyPi](https://pypi.org/project/graphgym) (\ud83d\udce5 63 / month \u00b7 \u23f1\ufe0f 24.03.2022):\n\t```\n\tpip install graphgym\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/THUMNLab/AutoGL\">AutoGL</a></b> (\ud83e\udd4915 \u00b7  \u2b50 860 \u00b7 \ud83d\udca4) - An autoML framework & toolkit for machine learning on graphs. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/THUMNLab/AutoGL) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udccb 26 - 42% open \u00b7 \u23f1\ufe0f 19.04.2022):\n\n\t```\n\tgit clone https://github.com/THUMNLab/AutoGL\n\t```\n- [PyPi](https://pypi.org/project/auto-graph-learning) (\ud83d\udce5 5 / month \u00b7 \u23f1\ufe0f 23.12.2020):\n\t```\n\tpip install auto-graph-learning\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/thunlp/OpenNE\">OpenNE</a></b> (\ud83e\udd4914 \u00b7  \u2b50 1.6K) - An Open-Source Package for Network Embedding (NE). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/thunlp/OpenNE) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 480 \u00b7 \ud83d\udccb 100 - 4% open \u00b7 \u23f1\ufe0f 02.11.2022):\n\n\t```\n\tgit clone https://github.com/thunlp/OpenNE\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/microsoft/ptgnn\">ptgnn</a></b> (\ud83e\udd4913 \u00b7  \u2b50 360 \u00b7 \ud83d\udca4) - A PyTorch Graph Neural Network Library. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/microsoft/ptgnn) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 41 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 7 - 28% open \u00b7 \u23f1\ufe0f 01.02.2022):\n\n\t```\n\tgit clone https://github.com/microsoft/ptgnn\n\t```\n- [PyPi](https://pypi.org/project/ptgnn) (\ud83d\udce5 41 / month \u00b7 \u23f1\ufe0f 21.10.2021):\n\t```\n\tpip install ptgnn\n\t```\n</details>\n<details><summary>Show 15 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/igraph/python-igraph\">igraph</a></b> (\ud83e\udd4732 \u00b7  \u2b50 1K) - Python interface for igraph. <code><a href=\"http://bit.ly/2KucAZR\">\u2757\ufe0fGPL-2.0</a></code>\n- <b><a href=\"https://github.com/stellargraph/stellargraph\">StellarGraph</a></b> (\ud83e\udd4828 \u00b7  \u2b50 2.6K \u00b7 \ud83d\udc80) - StellarGraph - Machine Learning on Graphs. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/Kozea/pygal\">pygal</a></b> (\ud83e\udd4827 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udca4) - PYthon svg GrAph plotting Library. <code><a href=\"http://bit.ly/37RvQcA\">\u2757\ufe0fLGPL-3.0</a></code>\n- <b><a href=\"https://github.com/benedekrozemberczki/karateclub\">Karate Club</a></b> (\ud83e\udd4826 \u00b7  \u2b50 1.8K) - Karate Club: An API Oriented Open-source Python Framework for.. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/Accenture/AmpliGraph\">AmpliGraph</a></b> (\ud83e\udd4824 \u00b7  \u2b50 1.9K \u00b7 \ud83d\udc80) - Python library for Representation Learning on Knowledge.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/divelab/DIG\">DIG</a></b> (\ud83e\udd4923 \u00b7  \u2b50 1.3K) - A library for graph deep learning research. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/phanein/deepwalk\">DeepWalk</a></b> (\ud83e\udd4921 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udc80) - DeepWalk - Deep Learning for Graphs. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/deepmind/graph_nets\">graph-nets</a></b> (\ud83e\udd4920 \u00b7  \u2b50 5.2K \u00b7 \ud83d\udc80) - Build Graph Nets in Tensorflow. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/snap-stanford/deepsnap\">deepsnap</a></b> (\ud83e\udd4919 \u00b7  \u2b50 440 \u00b7 \ud83d\udc80) - Python library assists deep learning on graphs. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/IBCNServices/pyRDF2Vec\">pyRDF2Vec</a></b> (\ud83e\udd4919 \u00b7  \u2b50 170) - Python Implementation and Extension of RDF2Vec. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/gsi-upm/sematch\">Sematch</a></b> (\ud83e\udd4917 \u00b7  \u2b50 400 \u00b7 \ud83d\udc80) - semantic similarity framework for knowledge graph. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/deepgraph/deepgraph\">DeepGraph</a></b> (\ud83e\udd4917 \u00b7  \u2b50 270 \u00b7 \ud83d\udc80) - Analyze Data with Pandas-based Networks. Documentation:. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/alibaba/euler\">Euler</a></b> (\ud83e\udd4916 \u00b7  \u2b50 2.8K \u00b7 \ud83d\udc80) - A distributed graph deep learning framework. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/williamleif/GraphSAGE\">GraphSAGE</a></b> (\ud83e\udd4915 \u00b7  \u2b50 2.9K \u00b7 \ud83d\udc80) - Representation learning on large graphs using stochastic.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/DeepGraphLearning/graphvite\">GraphVite</a></b> (\ud83e\udd4913 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - GraphVite: A General and High-performance Graph Embedding.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n</details>\n<br>\n\n## Audio Data\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for audio analysis, manipulation, transformation, and extraction, as well as speech recognition and music generation tasks._\n\n<details><summary><b><a href=\"https://github.com/espnet/espnet\">espnet</a></b> (\ud83e\udd4736 \u00b7  \u2b50 5.7K) - End-to-End Speech Processing Toolkit. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/espnet/espnet) (\ud83d\udc68\u200d\ud83d\udcbb 310 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce5 77 \u00b7 \ud83d\udce6 91 \u00b7 \ud83d\udccb 2K - 18% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/espnet/espnet\n\t```\n- [PyPi](https://pypi.org/project/espnet) (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 28.05.2022):\n\t```\n\tpip install espnet\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/librosa/librosa\">librosa</a></b> (\ud83e\udd4734 \u00b7  \u2b50 5.5K) - Python library for audio and music analysis. <code><a href=\"http://bit.ly/3hkKRql\">ISC</a></code></summary>\n\n- [GitHub](https://github.com/librosa/librosa) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 850 \u00b7 \ud83d\udccb 1K - 4% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/librosa/librosa\n\t```\n- [PyPi](https://pypi.org/project/librosa) (\ud83d\udce5 1.3M / month \u00b7 \ud83d\udce6 1.2K \u00b7 \u23f1\ufe0f 27.06.2022):\n\t```\n\tpip install librosa\n\t```\n- [Conda](https://anaconda.org/conda-forge/librosa) (\ud83d\udce5 550K \u00b7 \u23f1\ufe0f 27.06.2022):\n\t```\n\tconda install -c conda-forge librosa\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/speechbrain/speechbrain\">speechbrain</a></b> (\ud83e\udd4734 \u00b7  \u2b50 4.9K) - A PyTorch-based Speech Toolkit. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/speechbrain/speechbrain) (\ud83d\udc68\u200d\ud83d\udcbb 190 \u00b7 \ud83d\udd00 920 \u00b7 \ud83d\udce6 320 \u00b7 \ud83d\udccb 890 - 22% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/speechbrain/speechbrain\n\t```\n- [PyPi](https://pypi.org/project/speechbrain) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 26.06.2022):\n\t```\n\tpip install speechbrain\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/audio\">torchaudio</a></b> (\ud83e\udd4734 \u00b7  \u2b50 1.9K) - Data manipulation and transformation for audio signal.. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pytorch/audio) (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 490 \u00b7 \ud83d\udccb 740 - 26% open \u00b7 \u23f1\ufe0f 19.11.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/audio\n\t```\n- [PyPi](https://pypi.org/project/torchaudio) (\ud83d\udce5 600K / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 28.06.2022):\n\t```\n\tpip install torchaudio\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/magenta/magenta\">Magenta</a></b> (\ud83e\udd4833 \u00b7  \u2b50 18K) - Magenta: Music and Art Generation with Machine Intelligence. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/magenta/magenta) (\ud83d\udc68\u200d\ud83d\udcbb 150 \u00b7 \ud83d\udd00 3.7K \u00b7 \ud83d\udce6 390 \u00b7 \ud83d\udccb 940 - 37% open \u00b7 \u23f1\ufe0f 04.10.2022):\n\n\t```\n\tgit clone https://github.com/magenta/magenta\n\t```\n- [PyPi](https://pypi.org/project/magenta) (\ud83d\udce5 5.2K / month \u00b7 \ud83d\udce6 38 \u00b7 \u23f1\ufe0f 12.11.2020):\n\t```\n\tpip install magenta\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Uberi/speech_recognition\">SpeechRecognition</a></b> (\ud83e\udd4832 \u00b7  \u2b50 6.6K) - Speech recognition module for Python, supporting several.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/Uberi/speech_recognition) (\ud83d\udc68\u200d\ud83d\udcbb 48 \u00b7 \ud83d\udd00 2.2K \u00b7 \ud83d\udccb 540 - 47% open \u00b7 \u23f1\ufe0f 07.11.2022):\n\n\t```\n\tgit clone https://github.com/Uberi/speech_recognition\n\t```\n- [PyPi](https://pypi.org/project/SpeechRecognition) (\ud83d\udce5 420K / month \u00b7 \ud83d\udce6 720 \u00b7 \u23f1\ufe0f 05.12.2017):\n\t```\n\tpip install SpeechRecognition\n\t```\n- [Conda](https://anaconda.org/conda-forge/speechrecognition) (\ud83d\udce5 150K \u00b7 \u23f1\ufe0f 15.11.2022):\n\t```\n\tconda install -c conda-forge speechrecognition\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jiaaro/pydub\">Pydub</a></b> (\ud83e\udd4832 \u00b7  \u2b50 6.5K) - Manipulate audio with a simple and easy high level interface. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/jiaaro/pydub) (\ud83d\udc68\u200d\ud83d\udcbb 94 \u00b7 \ud83d\udd00 860 \u00b7 \ud83d\udce6 15K \u00b7 \ud83d\udccb 530 - 50% open \u00b7 \u23f1\ufe0f 15.10.2022):\n\n\t```\n\tgit clone https://github.com/jiaaro/pydub\n\t```\n- [PyPi](https://pypi.org/project/pydub) (\ud83d\udce5 3.4M / month \u00b7 \ud83d\udce6 900 \u00b7 \u23f1\ufe0f 10.03.2021):\n\t```\n\tpip install pydub\n\t```\n- [Conda](https://anaconda.org/conda-forge/pydub) (\ud83d\udce5 34K \u00b7 \u23f1\ufe0f 13.03.2021):\n\t```\n\tconda install -c conda-forge pydub\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deezer/spleeter\">spleeter</a></b> (\ud83e\udd4829 \u00b7  \u2b50 21K) - Deezer source separation library including pretrained models. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/deezer/spleeter) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 2.3K \u00b7 \ud83d\udce5 2M \u00b7 \ud83d\udccb 710 - 23% open \u00b7 \u23f1\ufe0f 07.09.2022):\n\n\t```\n\tgit clone https://github.com/deezer/spleeter\n\t```\n- [PyPi](https://pypi.org/project/spleeter) (\ud83d\udce5 8.5K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 10.06.2022):\n\t```\n\tpip install spleeter\n\t```\n- [Conda](https://anaconda.org/conda-forge/spleeter) (\ud83d\udce5 71K \u00b7 \u23f1\ufe0f 30.06.2020):\n\t```\n\tconda install -c conda-forge spleeter\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/coqui-ai/TTS\">Coqui TTS</a></b> (\ud83e\udd4828 \u00b7  \u2b50 7.1K) - - a deep learning toolkit for Text-to-Speech, battle-.. <code><a href=\"http://bit.ly/3postzC\">MPL-2.0</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/coqui-ai/TTS) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 780 \u00b7 \ud83d\udce5 350K \u00b7 \ud83d\udccb 450 - 4% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/coqui-ai/TTS\n\t```\n- [PyPi](https://pypi.org/project/tts) (\ud83d\udce5 7.9K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 21.06.2022):\n\t```\n\tpip install tts\n\t```\n- [Conda](https://anaconda.org/conda-forge/tts) (\ud83d\udce5 5.6K \u00b7 \u23f1\ufe0f 15.12.2021):\n\t```\n\tconda install -c conda-forge tts\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tyiannak/pyAudioAnalysis\">pyAudioAnalysis</a></b> (\ud83e\udd4828 \u00b7  \u2b50 5K) - Python Audio Analysis Library: Feature Extraction,.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/tyiannak/pyAudioAnalysis) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 320 \u00b7 \ud83d\udccb 300 - 59% open \u00b7 \u23f1\ufe0f 18.09.2022):\n\n\t```\n\tgit clone https://github.com/tyiannak/pyAudioAnalysis\n\t```\n- [PyPi](https://pypi.org/project/pyAudioAnalysis) (\ud83d\udce5 9.8K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 07.02.2022):\n\t```\n\tpip install pyAudioAnalysis\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/bastibe/python-soundfile\">python-soundfile</a></b> (\ud83e\udd4828 \u00b7  \u2b50 500) - SoundFile is an audio library based on libsndfile, CFFI, and.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/bastibe/python-soundfile) (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 81 \u00b7 \ud83d\udce5 7.2K \u00b7 \ud83d\udce6 15K \u00b7 \ud83d\udccb 190 - 41% open \u00b7 \u23f1\ufe0f 27.09.2022):\n\n\t```\n\tgit clone https://github.com/bastibe/python-soundfile\n\t```\n- [PyPi](https://pypi.org/project/soundfile) (\ud83d\udce5 1M / month \u00b7 \u23f1\ufe0f 27.09.2022):\n\t```\n\tpip install soundfile\n\t```\n- [Conda](https://anaconda.org/anaconda/pysoundfile):\n\t```\n\tconda install -c anaconda pysoundfile\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/beetbox/audioread\">audioread</a></b> (\ud83e\udd4828 \u00b7  \u2b50 410) - cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/beetbox/audioread) (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udccb 85 - 40% open \u00b7 \u23f1\ufe0f 18.11.2022):\n\n\t```\n\tgit clone https://github.com/beetbox/audioread\n\t```\n- [PyPi](https://pypi.org/project/audioread) (\ud83d\udce5 1.3M / month \u00b7 \ud83d\udce6 330 \u00b7 \u23f1\ufe0f 20.10.2020):\n\t```\n\tpip install audioread\n\t```\n- [Conda](https://anaconda.org/conda-forge/audioread) (\ud83d\udce5 540K \u00b7 \u23f1\ufe0f 29.10.2022):\n\t```\n\tconda install -c conda-forge audioread\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Picovoice/porcupine\">Porcupine</a></b> (\ud83e\udd4927 \u00b7  \u2b50 2.8K) - On-device wake word detection powered by deep learning. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Picovoice/porcupine) (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 400 \u00b7 \ud83d\udce6 10 \u00b7 \ud83d\udccb 410 - 0% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/Picovoice/Porcupine\n\t```\n- [PyPi](https://pypi.org/project/pvporcupine) (\ud83d\udce5 1.3K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 28.06.2022):\n\t```\n\tpip install pvporcupine\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/iver56/audiomentations\">audiomentations</a></b> (\ud83e\udd4927 \u00b7  \u2b50 1.2K) - A Python library for audio data augmentation. Inspired by.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/iver56/audiomentations) (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 180 \u00b7 \ud83d\udccb 140 - 28% open \u00b7 \u23f1\ufe0f 07.11.2022):\n\n\t```\n\tgit clone https://github.com/iver56/audiomentations\n\t```\n- [PyPi](https://pypi.org/project/audiomentations) (\ud83d\udce5 4.4K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 15.06.2022):\n\t```\n\tpip install audiomentations\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/CPJKU/madmom\">Madmom</a></b> (\ud83e\udd4926 \u00b7  \u2b50 990 \u00b7 \ud83d\udca4) - Python audio and music signal processing library. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/CPJKU/madmom) (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 240 \u00b7 \ud83d\udccb 270 - 22% open \u00b7 \u23f1\ufe0f 06.01.2022):\n\n\t```\n\tgit clone https://github.com/CPJKU/madmom\n\t```\n- [PyPi](https://pypi.org/project/madmom) (\ud83d\udce5 4.8K / month \u00b7 \ud83d\udce6 27 \u00b7 \u23f1\ufe0f 14.11.2018):\n\t```\n\tpip install madmom\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/devsnd/tinytag\">tinytag</a></b> (\ud83e\udd4926 \u00b7  \u2b50 570) - Read audio and music meta data and duration of MP3, OGG, OPUS, MP4, M4A,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/devsnd/tinytag) (\ud83d\udc68\u200d\ud83d\udcbb 25 \u00b7 \ud83d\udd00 90 \u00b7 \ud83d\udce6 620 \u00b7 \ud83d\udccb 96 - 14% open \u00b7 \u23f1\ufe0f 04.11.2022):\n\n\t```\n\tgit clone https://github.com/devsnd/tinytag\n\t```\n- [PyPi](https://pypi.org/project/tinytag) (\ud83d\udce5 19K / month \u00b7 \ud83d\udce6 70 \u00b7 \u23f1\ufe0f 12.03.2022):\n\t```\n\tpip install tinytag\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/magenta/ddsp\">DDSP</a></b> (\ud83e\udd4925 \u00b7  \u2b50 2.3K) - DDSP: Differentiable Digital Signal Processing. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/magenta/ddsp) (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udce6 32 \u00b7 \ud83d\udccb 150 - 20% open \u00b7 \u23f1\ufe0f 04.10.2022):\n\n\t```\n\tgit clone https://github.com/magenta/ddsp\n\t```\n- [PyPi](https://pypi.org/project/ddsp) (\ud83d\udce5 3.2K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 25.05.2022):\n\t```\n\tpip install ddsp\n\t```\n- [Conda](https://anaconda.org/conda-forge/ddsp) (\ud83d\udce5 12K \u00b7 \u23f1\ufe0f 08.06.2020):\n\t```\n\tconda install -c conda-forge ddsp\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/mozilla/DeepSpeech\">DeepSpeech</a></b> (\ud83e\udd4923 \u00b7  \u2b50 20K \u00b7 \ud83d\udcc9) - DeepSpeech is an open source embedded (offline, on-.. <code><a href=\"http://bit.ly/3postzC\">MPL-2.0</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/mozilla/DeepSpeech) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 3.6K):\n\n\t```\n\tgit clone https://github.com/mozilla/DeepSpeech\n\t```\n- [PyPi](https://pypi.org/project/deepspeech) (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 40 \u00b7 \u23f1\ufe0f 19.12.2020):\n\t```\n\tpip install deepspeech\n\t```\n- [Conda](https://anaconda.org/conda-forge/deepspeech) (\ud83d\udce5 1.2K \u00b7 \u23f1\ufe0f 29.07.2021):\n\t```\n\tconda install -c conda-forge deepspeech\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/keunwoochoi/kapre\">kapre</a></b> (\ud83e\udd4922 \u00b7  \u2b50 870) - kapre: Keras Audio Preprocessors. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/keunwoochoi/kapre) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce5 22 \u00b7 \ud83d\udce6 1.9K \u00b7 \ud83d\udccb 95 - 13% open \u00b7 \u23f1\ufe0f 04.07.2022):\n\n\t```\n\tgit clone https://github.com/keunwoochoi/kapre\n\t```\n- [PyPi](https://pypi.org/project/kapre) (\ud83d\udce5 3.7K / month \u00b7 \ud83d\udce6 14 \u00b7 \u23f1\ufe0f 21.01.2022):\n\t```\n\tpip install kapre\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/KinWaiCheuk/nnAudio\">nnAudio</a></b> (\ud83e\udd4921 \u00b7  \u2b50 760) - Audio processing by using pytorch 1D convolution network. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/KinWaiCheuk/nnAudio) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 72 \u00b7 \ud83d\udce6 68 \u00b7 \ud83d\udccb 53 - 22% open \u00b7 \u23f1\ufe0f 09.10.2022):\n\n\t```\n\tgit clone https://github.com/KinWaiCheuk/nnAudio\n\t```\n- [PyPi](https://pypi.org/project/nnAudio) (\ud83d\udce5 2.4K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 24.12.2021):\n\t```\n\tpip install nnAudio\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/adefossez/julius\">Julius</a></b> (\ud83e\udd4918 \u00b7  \u2b50 300) - Fast PyTorch based DSP for audio and 1D signals. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/adefossez/julius) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 19 \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 11 - 18% open \u00b7 \u23f1\ufe0f 19.09.2022):\n\n\t```\n\tgit clone https://github.com/adefossez/julius\n\t```\n- [PyPi](https://pypi.org/project/julius) (\ud83d\udce5 29K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 20.10.2021):\n\t```\n\tpip install julius\n\t```\n</details>\n<details><summary>Show 8 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/aubio/aubio\">aubio</a></b> (\ud83e\udd4828 \u00b7  \u2b50 2.8K \u00b7 \ud83d\udca4) - a library for audio and music analysis. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/MTG/essentia\">Essentia</a></b> (\ud83e\udd4926 \u00b7  \u2b50 2.2K) - C++ library for audio and music analysis, description and.. <code><a href=\"http://bit.ly/3pwmjO5\">\u2757\ufe0fAGPL-3.0</a></code>\n- <b><a href=\"https://github.com/jameslyons/python_speech_features\">python_speech_features</a></b> (\ud83e\udd4923 \u00b7  \u2b50 2.2K \u00b7 \ud83d\udc80) - This library provides common speech features for ASR.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/worldveil/dejavu\">Dejavu</a></b> (\ud83e\udd4922 \u00b7  \u2b50 5.9K \u00b7 \ud83d\udc80) - Audio fingerprinting and recognition in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/mozilla/TTS\">TTS</a></b> (\ud83e\udd4921 \u00b7  \u2b50 6.4K \u00b7 \ud83d\udc80) - Deep learning for Text to Speech (Discussion forum:.. <code><a href=\"http://bit.ly/3postzC\">MPL-2.0</a></code>\n- <b><a href=\"https://github.com/Parisson/TimeSide\">TimeSide</a></b> (\ud83e\udd4921 \u00b7  \u2b50 340) - Scalable audio processing framework written in Python with a.. <code><a href=\"http://bit.ly/3pwmjO5\">\u2757\ufe0fAGPL-3.0</a></code>\n- <b><a href=\"https://github.com/bmcfee/muda\">Muda</a></b> (\ud83e\udd4917 \u00b7  \u2b50 210 \u00b7 \ud83d\udc80) - A library for augmenting annotated audio data. <code><a href=\"http://bit.ly/3hkKRql\">ISC</a></code>\n- <b><a href=\"https://github.com/facebookresearch/textlesslib\">textlesslib</a></b> (\ud83e\udd499 \u00b7  \u2b50 370 \u00b7 \ud83d\udca4) - Library for Textless Spoken Language Processing. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Geospatial Data\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries to load, process, analyze, and write geographic data as well as libraries for spatial analysis, map visualization, and geocoding._\n\n<details><summary><b><a href=\"https://github.com/visgl/deck.gl\">pydeck</a></b> (\ud83e\udd4742 \u00b7  \u2b50 10K) - WebGL2 powered visualization framework. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/visgl/deck.gl) (\ud83d\udc68\u200d\ud83d\udcbb 210 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce6 4.9K \u00b7 \ud83d\udccb 2.6K - 7% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/visgl/deck.gl\n\t```\n- [PyPi](https://pypi.org/project/pydeck) (\ud83d\udce5 930K / month \u00b7 \ud83d\udce6 24 \u00b7 \u23f1\ufe0f 25.10.2021):\n\t```\n\tpip install pydeck\n\t```\n- [Conda](https://anaconda.org/conda-forge/pydeck) (\ud83d\udce5 230K \u00b7 \u23f1\ufe0f 04.11.2022):\n\t```\n\tconda install -c conda-forge pydeck\n\t```\n- [npm](https://www.npmjs.com/package/deck.gl) (\ud83d\udce5 360K / month \u00b7 \ud83d\udce6 420 \u00b7 \u23f1\ufe0f 15.11.2022):\n\t```\n\tnpm install deck.gl\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/python-visualization/folium\">folium</a></b> (\ud83e\udd4739 \u00b7  \u2b50 6K) - Python Data. Leaflet.js Maps. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/python-visualization/folium) (\ud83d\udc68\u200d\ud83d\udcbb 150 \u00b7 \ud83d\udd00 2.1K \u00b7 \ud83d\udce6 19K \u00b7 \ud83d\udccb 1.1K - 21% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/python-visualization/folium\n\t```\n- [PyPi](https://pypi.org/project/folium) (\ud83d\udce5 860K / month \u00b7 \ud83d\udce6 680 \u00b7 \u23f1\ufe0f 19.11.2021):\n\t```\n\tpip install folium\n\t```\n- [Conda](https://anaconda.org/conda-forge/folium) (\ud83d\udce5 1.4M \u00b7 \u23f1\ufe0f 07.10.2022):\n\t```\n\tconda install -c conda-forge folium\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rasterio/rasterio\">Rasterio</a></b> (\ud83e\udd4738 \u00b7  \u2b50 1.8K) - Rasterio reads and writes geospatial raster datasets. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/rasterio/rasterio) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 490 \u00b7 \ud83d\udce5 760 \u00b7 \ud83d\udce6 5.9K \u00b7 \ud83d\udccb 1.6K - 9% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/rasterio/rasterio\n\t```\n- [PyPi](https://pypi.org/project/rasterio) (\ud83d\udce5 1.5M / month \u00b7 \ud83d\udce6 800 \u00b7 \u23f1\ufe0f 06.07.2022):\n\t```\n\tpip install rasterio\n\t```\n- [Conda](https://anaconda.org/conda-forge/rasterio) (\ud83d\udce5 1.9M \u00b7 \u23f1\ufe0f 17.11.2022):\n\t```\n\tconda install -c conda-forge rasterio\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/shapely/shapely\">Shapely</a></b> (\ud83e\udd4837 \u00b7  \u2b50 3.1K) - Manipulation and analysis of geometric objects. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/shapely/shapely) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 490 \u00b7 \ud83d\udce5 330 \u00b7 \ud83d\udce6 35K \u00b7 \ud83d\udccb 960 - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/shapely/shapely\n\t```\n- [PyPi](https://pypi.org/project/shapely) (\ud83d\udce5 8.1M / month \u00b7 \u23f1\ufe0f 03.08.2022):\n\t```\n\tpip install shapely\n\t```\n- [Conda](https://anaconda.org/conda-forge/shapely) (\ud83d\udce5 4.9M \u00b7 \u23f1\ufe0f 15.11.2022):\n\t```\n\tconda install -c conda-forge shapely\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/geopy/geopy\">geopy</a></b> (\ud83e\udd4836 \u00b7  \u2b50 3.8K) - Geocoding library for Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/geopy/geopy) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 600 \u00b7 \ud83d\udccb 270 - 9% open \u00b7 \u23f1\ufe0f 13.11.2022):\n\n\t```\n\tgit clone https://github.com/geopy/geopy\n\t```\n- [PyPi](https://pypi.org/project/geopy) (\ud83d\udce5 4.5M / month \u00b7 \ud83d\udce6 3.9K \u00b7 \u23f1\ufe0f 11.07.2021):\n\t```\n\tpip install geopy\n\t```\n- [Conda](https://anaconda.org/conda-forge/geopy) (\ud83d\udce5 870K \u00b7 \u23f1\ufe0f 13.11.2022):\n\t```\n\tconda install -c conda-forge geopy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/geopandas/geopandas\">GeoPandas</a></b> (\ud83e\udd4836 \u00b7  \u2b50 3.4K) - Python tools for geographic data. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/geopandas/geopandas) (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 760 \u00b7 \ud83d\udce5 1.7K \u00b7 \ud83d\udccb 1.4K - 31% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/geopandas/geopandas\n\t```\n- [PyPi](https://pypi.org/project/geopandas) (\ud83d\udce5 2.9M / month \u00b7 \ud83d\udce6 1.2K \u00b7 \u23f1\ufe0f 21.06.2022):\n\t```\n\tpip install geopandas\n\t```\n- [Conda](https://anaconda.org/conda-forge/geopandas) (\ud83d\udce5 2.2M \u00b7 \u23f1\ufe0f 04.11.2022):\n\t```\n\tconda install -c conda-forge geopandas\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pyproj4/pyproj\">pyproj</a></b> (\ud83e\udd4836 \u00b7  \u2b50 820 \u00b7 \ud83d\udcc9) - Python interface to PROJ (cartographic projections and coordinate.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/pyproj4/pyproj) (\ud83d\udc68\u200d\ud83d\udcbb 55 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 17K \u00b7 \ud83d\udccb 530 - 3% open \u00b7 \u23f1\ufe0f 14.11.2022):\n\n\t```\n\tgit clone https://github.com/pyproj4/pyproj\n\t```\n- [PyPi](https://pypi.org/project/pyproj) (\ud83d\udce5 5M / month \u00b7 \ud83d\udce6 1.7K \u00b7 \u23f1\ufe0f 22.04.2022):\n\t```\n\tpip install pyproj\n\t```\n- [Conda](https://anaconda.org/conda-forge/pyproj) (\ud83d\udce5 4.7M \u00b7 \u23f1\ufe0f 28.10.2022):\n\t```\n\tconda install -c conda-forge pyproj\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jupyter-widgets/ipyleaflet\">ipyleaflet</a></b> (\ud83e\udd4833 \u00b7  \u2b50 1.3K) - A Jupyter - Leaflet.js bridge. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/jupyter-widgets/ipyleaflet) (\ud83d\udc68\u200d\ud83d\udcbb 81 \u00b7 \ud83d\udd00 350 \u00b7 \ud83d\udce6 3.2K \u00b7 \ud83d\udccb 540 - 39% open \u00b7 \u23f1\ufe0f 27.10.2022):\n\n\t```\n\tgit clone https://github.com/jupyter-widgets/ipyleaflet\n\t```\n- [PyPi](https://pypi.org/project/ipyleaflet) (\ud83d\udce5 170K / month \u00b7 \ud83d\udce6 110 \u00b7 \u23f1\ufe0f 07.07.2022):\n\t```\n\tpip install ipyleaflet\n\t```\n- [Conda](https://anaconda.org/conda-forge/ipyleaflet) (\ud83d\udce5 920K \u00b7 \u23f1\ufe0f 19.10.2022):\n\t```\n\tconda install -c conda-forge ipyleaflet\n\t```\n- [npm](https://www.npmjs.com/package/jupyter-leaflet) (\ud83d\udce5 58K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 19.10.2022):\n\t```\n\tnpm install jupyter-leaflet\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Toblerity/Fiona\">Fiona</a></b> (\ud83e\udd4833 \u00b7  \u2b50 980 \u00b7 \ud83d\udca4) - Fiona reads and writes geographic data files. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/Toblerity/Fiona) (\ud83d\udc68\u200d\ud83d\udcbb 66 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 10K \u00b7 \ud83d\udccb 710 - 12% open \u00b7 \u23f1\ufe0f 01.03.2022):\n\n\t```\n\tgit clone https://github.com/Toblerity/Fiona\n\t```\n- [PyPi](https://pypi.org/project/fiona) (\ud83d\udce5 2.9M / month \u00b7 \ud83d\udce6 790 \u00b7 \u23f1\ufe0f 10.06.2022):\n\t```\n\tpip install fiona\n\t```\n- [Conda](https://anaconda.org/conda-forge/fiona) (\ud83d\udce5 3.7M \u00b7 \u23f1\ufe0f 04.11.2022):\n\t```\n\tconda install -c conda-forge fiona\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Esri/arcgis-python-api\">ArcGIS API</a></b> (\ud83e\udd4929 \u00b7  \u2b50 1.5K) - Documentation and samples for ArcGIS API for Python. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Esri/arcgis-python-api) (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 940 \u00b7 \ud83d\udce5 6.4K \u00b7 \ud83d\udccb 540 - 10% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/Esri/arcgis-python-api\n\t```\n- [PyPi](https://pypi.org/project/arcgis) (\ud83d\udce5 57K / month \u00b7 \ud83d\udce6 26 \u00b7 \u23f1\ufe0f 02.06.2022):\n\t```\n\tpip install arcgis\n\t```\n- [Docker Hub](https://hub.docker.com/r/esridocker/arcgis-api-python-notebook) (\ud83d\udce5 7.5K \u00b7 \u2b50 37 \u00b7 \u23f1\ufe0f 17.06.2022):\n\t```\n\tdocker pull esridocker/arcgis-api-python-notebook\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jazzband/geojson\">geojson</a></b> (\ud83e\udd4928 \u00b7  \u2b50 760) - Python bindings and utilities for GeoJSON. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/jazzband/geojson) (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 11K \u00b7 \ud83d\udccb 87 - 26% open \u00b7 \u23f1\ufe0f 13.11.2022):\n\n\t```\n\tgit clone https://github.com/jazzband/geojson\n\t```\n- [PyPi](https://pypi.org/project/geojson) (\ud83d\udce5 850K / month \u00b7 \ud83d\udce6 1.1K \u00b7 \u23f1\ufe0f 09.08.2019):\n\t```\n\tpip install geojson\n\t```\n- [Conda](https://anaconda.org/conda-forge/geojson) (\ud83d\udce5 620K \u00b7 \u23f1\ufe0f 11.08.2019):\n\t```\n\tconda install -c conda-forge geojson\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pysal/pysal\">PySAL</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.1K) - PySAL: Python Spatial Analysis Library Meta-Package. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/pysal/pysal) (\ud83d\udc68\u200d\ud83d\udcbb 77 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udccb 610 - 1% open \u00b7 \u23f1\ufe0f 23.07.2022):\n\n\t```\n\tgit clone https://github.com/pysal/pysal\n\t```\n- [PyPi](https://pypi.org/project/pysal) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 32 \u00b7 \u23f1\ufe0f 30.01.2022):\n\t```\n\tpip install pysal\n\t```\n- [Conda](https://anaconda.org/conda-forge/pysal) (\ud83d\udce5 460K \u00b7 \u23f1\ufe0f 01.08.2022):\n\t```\n\tconda install -c conda-forge pysal\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/holoviz/geoviews\">GeoViews</a></b> (\ud83e\udd4926 \u00b7  \u2b50 440) - Simple, concise geographical visualization in Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/holoviz/geoviews) (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 68 \u00b7 \ud83d\udce6 510 \u00b7 \ud83d\udccb 310 - 35% open \u00b7 \u23f1\ufe0f 18.11.2022):\n\n\t```\n\tgit clone https://github.com/holoviz/geoviews\n\t```\n- [PyPi](https://pypi.org/project/geoviews) (\ud83d\udce5 7.4K / month \u00b7 \ud83d\udce6 28 \u00b7 \u23f1\ufe0f 08.03.2022):\n\t```\n\tpip install geoviews\n\t```\n- [Conda](https://anaconda.org/conda-forge/geoviews) (\ud83d\udce5 140K \u00b7 \u23f1\ufe0f 08.03.2022):\n\t```\n\tconda install -c conda-forge geoviews\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/earthlab/earthpy\">EarthPy</a></b> (\ud83e\udd4925 \u00b7  \u2b50 410 \u00b7 \ud83d\udca4) - A package built to support working with spatial data using open.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/earthlab/earthpy) (\ud83d\udc68\u200d\ud83d\udcbb 41 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 230 - 8% open \u00b7 \u23f1\ufe0f 20.12.2021):\n\n\t```\n\tgit clone https://github.com/earthlab/earthpy\n\t```\n- [PyPi](https://pypi.org/project/earthpy) (\ud83d\udce5 6.2K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 01.10.2021):\n\t```\n\tpip install earthpy\n\t```\n- [Conda](https://anaconda.org/conda-forge/earthpy) (\ud83d\udce5 55K \u00b7 \u23f1\ufe0f 04.10.2021):\n\t```\n\tconda install -c conda-forge earthpy\n\t```\n</details>\n<details><summary>Show 8 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/DenisCarriere/geocoder\">Geocoder</a></b> (\ud83e\udd4932 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Python Geocoder. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/pytroll/satpy\">Satpy</a></b> (\ud83e\udd4930 \u00b7  \u2b50 880) - Python package for earth-observing satellite data processing. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/sentinelsat/sentinelsat\">Sentinelsat</a></b> (\ud83e\udd4926 \u00b7  \u2b50 830) - Search and download Copernicus Sentinel satellite images. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/geospace-code/pymap3d\">pymap3d</a></b> (\ud83e\udd4924 \u00b7  \u2b50 290) - pure-Python (Numpy optional) 3D coordinate conversions for geospace ecef.. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code>\n- <b><a href=\"https://github.com/marceloprates/prettymaps\">prettymaps</a></b> (\ud83e\udd4923 \u00b7  \u2b50 8.9K) - A small set of Python functions to draw pretty maps from.. <code><a href=\"http://bit.ly/3pwmjO5\">\u2757\ufe0fAGPL-3.0</a></code>\n- <b><a href=\"https://github.com/pbugnion/gmaps\">gmaps</a></b> (\ud83e\udd4923 \u00b7  \u2b50 750 \u00b7 \ud83d\udc80) - Google maps for Jupyter notebooks. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/mapbox/mapboxgl-jupyter\">Mapbox GL</a></b> (\ud83e\udd4923 \u00b7  \u2b50 620 \u00b7 \ud83d\udc80) - Use Mapbox GL JS to visualize data in a Python Jupyter notebook. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/andrea-cuttone/geoplotlib\">geoplotlib</a></b> (\ud83e\udd4921 \u00b7  \u2b50 980 \u00b7 \ud83d\udc80) - python toolbox for visualizing geographical data and making maps. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n</details>\n<br>\n\n## Financial Data\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for algorithmic stock/crypto trading, risk analytics, backtesting, technical analysis, and other tasks on financial data._\n\n<details><summary><b><a href=\"https://github.com/ranaroussi/yfinance\">yfinance</a></b> (\ud83e\udd4737 \u00b7  \u2b50 8K) - Download market data from Yahoo! Finances API. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/ranaroussi/yfinance) (\ud83d\udc68\u200d\ud83d\udcbb 65 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce6 15K \u00b7 \ud83d\udccb 890 - 49% open \u00b7 \u23f1\ufe0f 19.11.2022):\n\n\t```\n\tgit clone https://github.com/ranaroussi/yfinance\n\t```\n- [PyPi](https://pypi.org/project/yfinance) (\ud83d\udce5 590K / month \u00b7 \ud83d\udce6 140 \u00b7 \u23f1\ufe0f 16.06.2022):\n\t```\n\tpip install yfinance\n\t```\n- [Conda](https://anaconda.org/ranaroussi/yfinance) (\ud83d\udce5 62K \u00b7 \u23f1\ufe0f 10.07.2021):\n\t```\n\tconda install -c ranaroussi yfinance\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/microsoft/qlib\">Qlib</a></b> (\ud83e\udd4731 \u00b7  \u2b50 10K) - Qlib is an AI-oriented quantitative investment platform, which aims to.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/microsoft/qlib) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 1.8K \u00b7 \ud83d\udce5 330 \u00b7 \ud83d\udce6 28 \u00b7 \ud83d\udccb 690 - 32% open \u00b7 \u23f1\ufe0f 20.11.2022):\n\n\t```\n\tgit clone https://github.com/microsoft/qlib\n\t```\n- [PyPi](https://pypi.org/project/pyqlib) (\ud83d\udce5 3K / month \u00b7 \u23f1\ufe0f 15.06.2022):\n\t```\n\tpip install pyqlib\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/bukosabino/ta\">ta</a></b> (\ud83e\udd4829 \u00b7  \u2b50 3.3K) - Technical Analysis Library using Pandas and Numpy. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/bukosabino/ta) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 740 \u00b7 \ud83d\udce6 1.5K \u00b7 \ud83d\udccb 220 - 54% open \u00b7 \u23f1\ufe0f 23.08.2022):\n\n\t```\n\tgit clone https://github.com/bukosabino/ta\n\t```\n- [PyPi](https://pypi.org/project/ta) (\ud83d\udce5 93K / month \u00b7 \ud83d\udce6 34 \u00b7 \u23f1\ufe0f 16.04.2022):\n\t```\n\tpip install ta\n\t```\n- [Conda](https://anaconda.org/conda-forge/ta) (\ud83d\udce5 9K \u00b7 \u23f1\ufe0f 23.08.2022):\n\t```\n\tconda install -c conda-forge ta\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/erdewit/ib_insync\">IB-insync</a></b> (\ud83e\udd4829 \u00b7  \u2b50 2K) - Python sync/async framework for Interactive Brokers API. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/erdewit/ib_insync) (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 510 \u00b7 \ud83d\udccb 440 - 1% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/erdewit/ib_insync\n\t```\n- [PyPi](https://pypi.org/project/ib_insync) (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 22 \u00b7 \u23f1\ufe0f 28.11.2021):\n\t```\n\tpip install ib_insync\n\t```\n- [Conda](https://anaconda.org/conda-forge/ib-insync) (\ud83d\udce5 24K \u00b7 \u23f1\ufe0f 19.11.2022):\n\t```\n\tconda install -c conda-forge ib-insync\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pmorissette/ffn\">ffn</a></b> (\ud83e\udd4827 \u00b7  \u2b50 1.4K) - ffn - a financial function library for Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/pmorissette/ffn) (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 250 \u00b7 \ud83d\udccb 100 - 19% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/pmorissette/ffn\n\t```\n- [PyPi](https://pypi.org/project/ffn) (\ud83d\udce5 210K / month \u00b7 \ud83d\udce6 25 \u00b7 \u23f1\ufe0f 21.04.2021):\n\t```\n\tpip install ffn\n\t```\n- [Conda](https://anaconda.org/conda-forge/ffn) (\ud83d\udce5 2K \u00b7 \u23f1\ufe0f 22.04.2021):\n\t```\n\tconda install -c conda-forge ffn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pmorissette/bt\">bt</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.5K) - bt - flexible backtesting for Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/pmorissette/bt) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 340 \u00b7 \ud83d\udce6 150 \u00b7 \ud83d\udccb 310 - 22% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/pmorissette/bt\n\t```\n- [PyPi](https://pypi.org/project/bt) (\ud83d\udce5 5K / month \u00b7 \ud83d\udce6 21 \u00b7 \u23f1\ufe0f 21.04.2021):\n\t```\n\tpip install bt\n\t```\n- [Conda](https://anaconda.org/conda-forge/bt) (\ud83d\udce5 9.7K \u00b7 \u23f1\ufe0f 12.11.2022):\n\t```\n\tconda install -c conda-forge bt\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensortrade-org/tensortrade\">TensorTrade</a></b> (\ud83e\udd4925 \u00b7  \u2b50 4K) - An open source reinforcement learning framework for training,.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/tensortrade-org/tensortrade) (\ud83d\udc68\u200d\ud83d\udcbb 61 \u00b7 \ud83d\udd00 930 \u00b7 \ud83d\udce6 36 \u00b7 \ud83d\udccb 240 - 17% open \u00b7 \u23f1\ufe0f 23.08.2022):\n\n\t```\n\tgit clone https://github.com/tensortrade-org/tensortrade\n\t```\n- [PyPi](https://pypi.org/project/tensortrade) (\ud83d\udce5 430 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 10.05.2021):\n\t```\n\tpip install tensortrade\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensortrade) (\ud83d\udce5 1.9K \u00b7 \u23f1\ufe0f 10.05.2021):\n\t```\n\tconda install -c conda-forge tensortrade\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jealous/stockstats\">stockstats</a></b> (\ud83e\udd4924 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udcc8) - Supply a wrapper ``StockDataFrame`` based on the.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/jealous/stockstats) (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udce6 560 \u00b7 \ud83d\udccb 94 - 17% open \u00b7 \u23f1\ufe0f 19.11.2022):\n\n\t```\n\tgit clone https://github.com/jealous/stockstats\n\t```\n- [PyPi](https://pypi.org/project/stockstats) (\ud83d\udce5 7.4K / month \u00b7 \ud83d\udce6 29 \u00b7 \u23f1\ufe0f 07.01.2022):\n\t```\n\tpip install stockstats\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/CryptoSignal/Crypto-Signal\">Crypto Signals</a></b> (\ud83e\udd4923 \u00b7  \u2b50 4.2K) - Github.com/CryptoSignal - Trading & Technical Analysis Bot -.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/CryptoSignal/Crypto-Signal) (\ud83d\udc68\u200d\ud83d\udcbb 28 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udccb 260 - 22% open \u00b7 \u23f1\ufe0f 09.08.2022):\n\n\t```\n\tgit clone https://github.com/CryptoSignal/crypto-signal\n\t```\n- [Docker Hub](https://hub.docker.com/r/shadowreaver/crypto-signal) (\ud83d\udce5 140K \u00b7 \u2b50 8 \u00b7 \u23f1\ufe0f 03.09.2020):\n\t```\n\tdocker pull shadowreaver/crypto-signal\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/tf-quant-finance\">tf-quant-finance</a></b> (\ud83e\udd4922 \u00b7  \u2b50 3.4K) - High-performance TensorFlow library for quantitative.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/google/tf-quant-finance) (\ud83d\udc68\u200d\ud83d\udcbb 43 \u00b7 \ud83d\udd00 460 \u00b7 \ud83d\udccb 49 - 48% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/google/tf-quant-finance\n\t```\n- [PyPi](https://pypi.org/project/tf-quant-finance) (\ud83d\udce5 740 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 31.05.2022):\n\t```\n\tpip install tf-quant-finance\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/cuemacro/finmarketpy\">finmarketpy</a></b> (\ud83e\udd4919 \u00b7  \u2b50 3K \u00b7 \ud83d\udca4) - Python library for backtesting trading strategies & analyzing.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/cuemacro/finmarketpy) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 450 \u00b7 \ud83d\udce5 42 \u00b7 \ud83d\udce6 5 \u00b7 \ud83d\udccb 26 - 88% open \u00b7 \u23f1\ufe0f 05.04.2022):\n\n\t```\n\tgit clone https://github.com/cuemacro/finmarketpy\n\t```\n- [PyPi](https://pypi.org/project/finmarketpy) (\ud83d\udce5 100 / month \u00b7 \u23f1\ufe0f 07.10.2021):\n\t```\n\tpip install finmarketpy\n\t```\n</details>\n<details><summary>Show 14 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/quantopian/zipline\">zipline</a></b> (\ud83e\udd4733 \u00b7  \u2b50 16K \u00b7 \ud83d\udc80) - Zipline, a Pythonic Algorithmic Trading Library. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/quantopian/pyfolio\">pyfolio</a></b> (\ud83e\udd4830 \u00b7  \u2b50 4.7K \u00b7 \ud83d\udc80) - Portfolio and risk analytics in Python. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/mementum/backtrader\">backtrader</a></b> (\ud83e\udd4829 \u00b7  \u2b50 9.6K \u00b7 \ud83d\udc80) - Python Backtesting library for trading strategies. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/bashtage/arch\">arch</a></b> (\ud83e\udd4829 \u00b7  \u2b50 1K) - ARCH models in Python. <code><a href=\"https://tldrlegal.com/search?q=NCSA\">\u2757\ufe0fNCSA</a></code>\n- <b><a href=\"https://github.com/RomelTorres/alpha_vantage\">Alpha Vantage</a></b> (\ud83e\udd4827 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udc80) - A python wrapper for Alpha Vantage API for financial data. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/quantopian/alphalens\">Alphalens</a></b> (\ud83e\udd4827 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udc80) - Performance analysis of predictive (alpha) stock factors. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/scrtlabs/catalyst\">Enigma Catalyst</a></b> (\ud83e\udd4926 \u00b7  \u2b50 2.4K \u00b7 \ud83d\udc80) - An Algorithmic Trading Library for Crypto-Assets in.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/quantopian/empyrical\">empyrical</a></b> (\ud83e\udd4926 \u00b7  \u2b50 990 \u00b7 \ud83d\udc80) - Common financial risk and performance metrics. Used by zipline.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/gbeced/pyalgotrade\">PyAlgoTrade</a></b> (\ud83e\udd4924 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udc80) - Python Algorithmic Trading Library. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/peerchemist/finta\">FinTA</a></b> (\ud83e\udd4923 \u00b7  \u2b50 1.8K \u00b7 \ud83d\udcc8) - Common financial technical indicators implemented in Pandas. <code><a href=\"http://bit.ly/37RvQcA\">\u2757\ufe0fLGPL-3.0</a></code>\n- <b><a href=\"https://github.com/kernc/backtesting.py\">Backtesting.py</a></b> (\ud83e\udd4920 \u00b7  \u2b50 3K \u00b7 \ud83d\udca4) - Backtest trading strategies in Python. <code><a href=\"http://bit.ly/3pwmjO5\">\u2757\ufe0fAGPL-3.0</a></code>\n- <b><a href=\"https://github.com/fmilthaler/FinQuant\">FinQuant</a></b> (\ud83e\udd4919 \u00b7  \u2b50 860 \u00b7 \ud83d\udc80) - A program for financial portfolio management, analysis and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/tradytics/surpriver\">surpriver</a></b> (\ud83e\udd4912 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Find big moving stocks before they move using machine.. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/alvarobartt/pyrtfolio\">pyrtfolio</a></b> (\ud83e\udd497 \u00b7  \u2b50 120 \u00b7 \ud83d\udc80) - Python package to generate stock portfolios. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n</details>\n<br>\n\n## Time Series Data\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for forecasting, anomaly detection, feature extraction, and machine learning on time-series and sequential data._\n\n<details><summary><b><a href=\"https://github.com/facebook/prophet\">Prophet</a></b> (\ud83e\udd4736 \u00b7  \u2b50 15K) - Tool for producing high quality forecasts for time series data that has.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/facebook/prophet) (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 4.3K \u00b7 \ud83d\udce5 1K \u00b7 \ud83d\udccb 1.9K - 14% open \u00b7 \u23f1\ufe0f 21.09.2022):\n\n\t```\n\tgit clone https://github.com/facebook/prophet\n\t```\n- [PyPi](https://pypi.org/project/fbprophet) (\ud83d\udce5 1.5M / month \u00b7 \ud83d\udce6 130 \u00b7 \u23f1\ufe0f 05.09.2020):\n\t```\n\tpip install fbprophet\n\t```\n- [Conda](https://anaconda.org/conda-forge/prophet) (\ud83d\udce5 210K \u00b7 \u23f1\ufe0f 10.09.2022):\n\t```\n\tconda install -c conda-forge prophet\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/sktime/sktime\">sktime</a></b> (\ud83e\udd4735 \u00b7  \u2b50 5.9K) - A unified framework for machine learning with time series. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/sktime/sktime) (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 950 \u00b7 \ud83d\udce5 76 \u00b7 \ud83d\udce6 700 \u00b7 \ud83d\udccb 1.5K - 32% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/alan-turing-institute/sktime\n\t```\n- [PyPi](https://pypi.org/project/sktime) (\ud83d\udce5 400K / month \u00b7 \ud83d\udce6 26 \u00b7 \u23f1\ufe0f 29.06.2022):\n\t```\n\tpip install sktime\n\t```\n- [Conda](https://anaconda.org/conda-forge/sktime-all-extras) (\ud83d\udce5 85K \u00b7 \u23f1\ufe0f 05.10.2022):\n\t```\n\tconda install -c conda-forge sktime-all-extras\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ourownstory/neural_prophet\">NeuralProphet</a></b> (\ud83e\udd4733 \u00b7  \u2b50 2.6K) - NeuralProphet: A simple forecasting package. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/ourownstory/neural_prophet) (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 350 \u00b7 \ud83d\udce6 140 \u00b7 \ud83d\udccb 380 - 28% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/ourownstory/neural_prophet\n\t```\n- [PyPi](https://pypi.org/project/neuralprophet) (\ud83d\udce5 100K / month \u00b7 \u23f1\ufe0f 22.03.2022):\n\t```\n\tpip install neuralprophet\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/alkaline-ml/pmdarima\">pmdarima</a></b> (\ud83e\udd4832 \u00b7  \u2b50 1.3K) - A statistical library designed to fill the void in Pythons time series.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/alkaline-ml/pmdarima) (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 2.8K \u00b7 \ud83d\udccb 300 - 10% open \u00b7 \u23f1\ufe0f 03.11.2022):\n\n\t```\n\tgit clone https://github.com/alkaline-ml/pmdarima\n\t```\n- [PyPi](https://pypi.org/project/pmdarima) (\ud83d\udce5 1.7M / month \u00b7 \ud83d\udce6 57 \u00b7 \u23f1\ufe0f 22.02.2022):\n\t```\n\tpip install pmdarima\n\t```\n- [Conda](https://anaconda.org/conda-forge/pmdarima) (\ud83d\udce5 140K \u00b7 \u23f1\ufe0f 24.08.2022):\n\t```\n\tconda install -c conda-forge pmdarima\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/TDAmeritrade/stumpy\">STUMPY</a></b> (\ud83e\udd4831 \u00b7  \u2b50 2.4K) - STUMPY is a powerful and scalable Python library for modern time series.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/TDAmeritrade/stumpy) (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 300 \u00b7 \ud83d\udccb 360 - 12% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/TDAmeritrade/stumpy\n\t```\n- [PyPi](https://pypi.org/project/stumpy) (\ud83d\udce5 190K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 31.03.2022):\n\t```\n\tpip install stumpy\n\t```\n- [Conda](https://anaconda.org/conda-forge/stumpy) (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 31.03.2022):\n\t```\n\tconda install -c conda-forge stumpy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/unit8co/darts\">Darts</a></b> (\ud83e\udd4830 \u00b7  \u2b50 5K) - A python library for easy manipulation and forecasting of time series. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/unit8co/darts) (\ud83d\udc68\u200d\ud83d\udcbb 69 \u00b7 \ud83d\udd00 540 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 760 - 28% open \u00b7 \u23f1\ufe0f 20.11.2022):\n\n\t```\n\tgit clone https://github.com/unit8co/darts\n\t```\n- [PyPi](https://pypi.org/project/u8darts) (\ud83d\udce5 8.1K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 22.06.2022):\n\t```\n\tpip install u8darts\n\t```\n- [Conda](https://anaconda.org/conda-forge/u8darts-all) (\ud83d\udce5 18K \u00b7 \u23f1\ufe0f 05.10.2022):\n\t```\n\tconda install -c conda-forge u8darts-all\n\t```\n- [Docker Hub](https://hub.docker.com/r/unit8/darts) (\ud83d\udce5 360 \u00b7 \u23f1\ufe0f 04.10.2022):\n\t```\n\tdocker pull unit8/darts\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/awslabs/gluonts\">GluonTS</a></b> (\ud83e\udd4830 \u00b7  \u2b50 3.2K) - Probabilistic time series modeling in Python. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1X\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/awslabs/gluonts) (\ud83d\udc68\u200d\ud83d\udcbb 97 \u00b7 \ud83d\udd00 640 \u00b7 \ud83d\udccb 780 - 31% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/awslabs/gluon-ts\n\t```\n- [PyPi](https://pypi.org/project/gluonts) (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 30.06.2022):\n\t```\n\tpip install gluonts\n\t```\n- [Conda](https://anaconda.org/anaconda/gluonts) (\ud83d\udce5 190 \u00b7 \u23f1\ufe0f 14.10.2021):\n\t```\n\tconda install -c anaconda gluonts\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jdb78/pytorch-forecasting\">pytorch-forecasting</a></b> (\ud83e\udd4830 \u00b7  \u2b50 2.4K) - Time series forecasting with PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/jdb78/pytorch-forecasting) (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 380 \u00b7 \ud83d\udccb 540 - 52% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/jdb78/pytorch-forecasting\n\t```\n- [PyPi](https://pypi.org/project/pytorch-forecasting) (\ud83d\udce5 130K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 23.05.2022):\n\t```\n\tpip install pytorch-forecasting\n\t```\n- [Conda](https://anaconda.org/conda-forge/pytorch-forecasting) (\ud83d\udce5 32K \u00b7 \u23f1\ufe0f 23.05.2022):\n\t```\n\tconda install -c conda-forge pytorch-forecasting\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tslearn-team/tslearn\">tslearn</a></b> (\ud83e\udd4830 \u00b7  \u2b50 2.3K) - A machine learning toolkit dedicated to time-series data. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tslearn-team/tslearn) (\ud83d\udc68\u200d\ud83d\udcbb 40 \u00b7 \ud83d\udd00 300 \u00b7 \ud83d\udce6 620 \u00b7 \ud83d\udccb 290 - 35% open \u00b7 \u23f1\ufe0f 27.10.2022):\n\n\t```\n\tgit clone https://github.com/tslearn-team/tslearn\n\t```\n- [PyPi](https://pypi.org/project/tslearn) (\ud83d\udce5 140K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 16.08.2021):\n\t```\n\tpip install tslearn\n\t```\n- [Conda](https://anaconda.org/conda-forge/tslearn) (\ud83d\udce5 400K \u00b7 \u23f1\ufe0f 15.01.2022):\n\t```\n\tconda install -c conda-forge tslearn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/blue-yonder/tsfresh\">tsfresh</a></b> (\ud83e\udd4829 \u00b7  \u2b50 6.9K) - Automatic extraction of relevant features from time series:. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/blue-yonder/tsfresh) (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udccb 510 - 12% open \u00b7 \u23f1\ufe0f 18.11.2022):\n\n\t```\n\tgit clone https://github.com/blue-yonder/tsfresh\n\t```\n- [PyPi](https://pypi.org/project/tsfresh) (\ud83d\udce5 320K / month \u00b7 \ud83d\udce6 60 \u00b7 \u23f1\ufe0f 21.12.2021):\n\t```\n\tpip install tsfresh\n\t```\n- [Conda](https://anaconda.org/conda-forge/tsfresh) (\ud83d\udce5 360K \u00b7 \u23f1\ufe0f 21.12.2021):\n\t```\n\tconda install -c conda-forge tsfresh\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Nixtla/statsforecast\">StatsForecast</a></b> (\ud83e\udd4828 \u00b7  \u2b50 1.6K) - Lightning fast forecasting with statistical and econometric.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Nixtla/statsforecast) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 92 \u00b7 \ud83d\udccb 120 - 40% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/Nixtla/statsforecast\n\t```\n- [PyPi](https://pypi.org/project/statsforecast) (\ud83d\udce5 240K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 27.06.2022):\n\t```\n\tpip install statsforecast\n\t```\n- [Conda](https://anaconda.org/conda-forge/statsforecast) (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 15.11.2022):\n\t```\n\tconda install -c conda-forge statsforecast\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/johannfaouzi/pyts\">pyts</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.4K) - A Python package for time series classification. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/johannfaouzi/pyts) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce6 280 \u00b7 \ud83d\udccb 68 - 55% open \u00b7 \u23f1\ufe0f 16.06.2022):\n\n\t```\n\tgit clone https://github.com/johannfaouzi/pyts\n\t```\n- [PyPi](https://pypi.org/project/pyts) (\ud83d\udce5 91K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 31.10.2021):\n\t```\n\tpip install pyts\n\t```\n- [Conda](https://anaconda.org/conda-forge/pyts) (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 31.10.2021):\n\t```\n\tconda install -c conda-forge pyts\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/python-streamz/streamz\">Streamz</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.1K) - Real-time stream processing for python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/python-streamz/streamz) (\ud83d\udc68\u200d\ud83d\udcbb 46 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce6 340 \u00b7 \ud83d\udccb 250 - 41% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/python-streamz/streamz\n\t```\n- [PyPi](https://pypi.org/project/streamz) (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 35 \u00b7 \u23f1\ufe0f 04.10.2021):\n\t```\n\tpip install streamz\n\t```\n- [Conda](https://anaconda.org/conda-forge/streamz) (\ud83d\udce5 460K \u00b7 \u23f1\ufe0f 28.07.2022):\n\t```\n\tconda install -c conda-forge streamz\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/uber/orbit\">uber/orbit</a></b> (\ud83e\udd4924 \u00b7  \u2b50 1.5K) - A Python package for Bayesian forecasting with object-oriented.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/uber/orbit) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 380 - 15% open \u00b7 \u23f1\ufe0f 14.09.2022):\n\n\t```\n\tgit clone https://github.com/uber/orbit\n\t```\n- [PyPi](https://pypi.org/project/orbit-ml) (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 28.04.2022):\n\t```\n\tpip install orbit-ml\n\t```\n- [Conda](https://anaconda.org/conda-forge/orbit-ml) (\ud83d\udce5 1.9K \u00b7 \u23f1\ufe0f 08.03.2022):\n\t```\n\tconda install -c conda-forge orbit-ml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Nixtla/neuralforecast\">NeuralForecast</a></b> (\ud83e\udd4923 \u00b7  \u2b50 970) - Scalable and user friendly neural forecasting algorithms for.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Nixtla/neuralforecast) (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 88 \u00b7 \ud83d\udce6 5 \u00b7 \ud83d\udccb 120 - 16% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/Nixtla/neuralforecast\n\t```\n- [PyPi](https://pypi.org/project/neuralforecast) (\ud83d\udce5 4.2K / month \u00b7 \u23f1\ufe0f 02.06.2022):\n\t```\n\tpip install neuralforecast\n\t```\n- [Conda](https://anaconda.org/conda-forge/neuralforecast) (\ud83d\udce5 3.3K \u00b7 \u23f1\ufe0f 09.11.2022):\n\t```\n\tconda install -c conda-forge neuralforecast\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/fraunhoferportugal/tsfel\">TSFEL</a></b> (\ud83e\udd4922 \u00b7  \u2b50 570 \u00b7 \ud83d\udca4) - An intuitive library to extract features from time series. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/fraunhoferportugal/tsfel) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 44 \u00b7 \ud83d\udccb 62 - 29% open \u00b7 \u23f1\ufe0f 16.03.2022):\n\n\t```\n\tgit clone https://github.com/fraunhoferportugal/tsfel\n\t```\n- [PyPi](https://pypi.org/project/tsfel) (\ud83d\udce5 8.1K / month \u00b7 \u23f1\ufe0f 14.02.2021):\n\t```\n\tpip install tsfel\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/linkedin/greykite\">greykite</a></b> (\ud83e\udd4921 \u00b7  \u2b50 1.6K) - A flexible, intuitive and fast forecasting library. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/linkedin/greykite) (\ud83d\udc68\u200d\ud83d\udcbb 8 \u00b7 \ud83d\udd00 84 \u00b7 \ud83d\udce6 12 \u00b7 \ud83d\udccb 79 - 20% open \u00b7 \u23f1\ufe0f 31.08.2022):\n\n\t```\n\tgit clone https://github.com/linkedin/greykite\n\t```\n- [PyPi](https://pypi.org/project/greykite) (\ud83d\udce5 23K / month \u00b7 \u23f1\ufe0f 15.12.2021):\n\t```\n\tpip install greykite\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dmbee/seglearn\">seglearn</a></b> (\ud83e\udd4921 \u00b7  \u2b50 530) - Python module for machine learning time series:. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/dmbee/seglearn) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 62 \u00b7 \ud83d\udce6 17 \u00b7 \ud83d\udccb 29 - 20% open \u00b7 \u23f1\ufe0f 27.08.2022):\n\n\t```\n\tgit clone https://github.com/dmbee/seglearn\n\t```\n- [PyPi](https://pypi.org/project/seglearn) (\ud83d\udce5 3.7K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 13.03.2021):\n\t```\n\tpip install seglearn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/AutoViML/Auto_TS\">Auto TS</a></b> (\ud83e\udd4919 \u00b7  \u2b50 510) - Automatically build ARIMA, SARIMAX, VAR, FB Prophet and XGBoost.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/AutoViML/Auto_TS) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 92 \u00b7 \ud83d\udccb 78 - 10% open \u00b7 \u23f1\ufe0f 16.08.2022):\n\n\t```\n\tgit clone https://github.com/AutoViML/Auto_TS\n\t```\n- [PyPi](https://pypi.org/project/auto-ts) (\ud83d\udce5 6.5K / month \u00b7 \u23f1\ufe0f 31.01.2022):\n\t```\n\tpip install auto-ts\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/firmai/atspy\">atspy</a></b> (\ud83e\udd4915 \u00b7  \u2b50 460 \u00b7 \ud83d\udca4) - AtsPy: Automated Time Series Models in Python (by @firmai). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/firmai/atspy) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 87 \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 22 - 90% open \u00b7 \u23f1\ufe0f 18.12.2021):\n\n\t```\n\tgit clone https://github.com/firmai/atspy\n\t```\n- [PyPi](https://pypi.org/project/atspy) (\ud83d\udce5 310 / month \u00b7 \u23f1\ufe0f 24.04.2020):\n\t```\n\tpip install atspy\n\t```\n</details>\n<details><summary>Show 8 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/RJT1990/pyflux\">PyFlux</a></b> (\ud83e\udd4924 \u00b7  \u2b50 2K \u00b7 \ud83d\udc80) - Open source time series library for Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/linkedin/luminol\">luminol</a></b> (\ud83e\udd4921 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - Anomaly Detection and Correlation library. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/wwrechard/pydlm\">pydlm</a></b> (\ud83e\udd4920 \u00b7  \u2b50 430 \u00b7 \ud83d\udc80) - A python library for Bayesian time series modeling. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/X-DataInitiative/tick\">tick</a></b> (\ud83e\udd4920 \u00b7  \u2b50 400 \u00b7 \ud83d\udc80) - Module for statistical learning, with a particular emphasis on time-.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/arundo/adtk\">ADTK</a></b> (\ud83e\udd4919 \u00b7  \u2b50 880 \u00b7 \ud83d\udc80) - A Python toolkit for rule-based/unsupervised anomaly detection in time.. <code><a href=\"http://bit.ly/3postzC\">MPL-2.0</a></code>\n- <b><a href=\"https://github.com/target/matrixprofile-ts\">matrixprofile-ts</a></b> (\ud83e\udd4919 \u00b7  \u2b50 690 \u00b7 \ud83d\udc80) - A Python library for detecting patterns and anomalies.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/predict-idlab/tsflex\">tsflex</a></b> (\ud83e\udd4917 \u00b7  \u2b50 190) - Flexible time series feature extraction & processing. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/arundo/tsaug\">tsaug</a></b> (\ud83e\udd4913 \u00b7  \u2b50 270 \u00b7 \ud83d\udc80) - A Python package for time series augmentation. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n</details>\n<br>\n\n## Medical Data\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for processing and analyzing medical data such as MRIs, EEGs, genomic data, and other medical imaging formats._\n\n<details><summary><b><a href=\"https://github.com/mne-tools/mne-python\">MNE</a></b> (\ud83e\udd4737 \u00b7  \u2b50 2.1K) - MNE: Magnetoencephalography (MEG) and Electroencephalography (EEG) in Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/mne-tools/mne-python) (\ud83d\udc68\u200d\ud83d\udcbb 320 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 2K \u00b7 \ud83d\udccb 4.3K - 10% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/mne-tools/mne-python\n\t```\n- [PyPi](https://pypi.org/project/mne) (\ud83d\udce5 42K / month \u00b7 \ud83d\udce6 220 \u00b7 \u23f1\ufe0f 12.05.2022):\n\t```\n\tpip install mne\n\t```\n- [Conda](https://anaconda.org/conda-forge/mne) (\ud83d\udce5 250K \u00b7 \u23f1\ufe0f 11.11.2022):\n\t```\n\tconda install -c conda-forge mne\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nipy/nipype\">NIPYPE</a></b> (\ud83e\udd4735 \u00b7  \u2b50 650) - Workflows and interfaces for neuroimaging packages. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/nipy/nipype) (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 510 \u00b7 \ud83d\udce6 1.1K \u00b7 \ud83d\udccb 1.3K - 29% open \u00b7 \u23f1\ufe0f 17.10.2022):\n\n\t```\n\tgit clone https://github.com/nipy/nipype\n\t```\n- [PyPi](https://pypi.org/project/nipype) (\ud83d\udce5 57K / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 06.06.2022):\n\t```\n\tpip install nipype\n\t```\n- [Conda](https://anaconda.org/conda-forge/nipype) (\ud83d\udce5 520K \u00b7 \u23f1\ufe0f 06.11.2022):\n\t```\n\tconda install -c conda-forge nipype\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Project-MONAI/MONAI\">MONAI</a></b> (\ud83e\udd4834 \u00b7  \u2b50 3.6K) - AI Toolkit for Healthcare Imaging. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/Project-MONAI/MONAI) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 680 \u00b7 \ud83d\udce6 590 \u00b7 \ud83d\udccb 2.1K - 11% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/Project-MONAI/MONAI\n\t```\n- [PyPi](https://pypi.org/project/monai) (\ud83d\udce5 44K / month \u00b7 \ud83d\udce6 20 \u00b7 \u23f1\ufe0f 13.06.2022):\n\t```\n\tpip install monai\n\t```\n- [Conda](https://anaconda.org/conda-forge/monai) (\ud83d\udce5 6.7K \u00b7 \u23f1\ufe0f 24.10.2022):\n\t```\n\tconda install -c conda-forge monai\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/CamDavidsonPilon/lifelines\">Lifelines</a></b> (\ud83e\udd4834 \u00b7  \u2b50 2K) - Survival analysis in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/CamDavidsonPilon/lifelines) (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 510 \u00b7 \ud83d\udce6 1.2K \u00b7 \ud83d\udccb 890 - 26% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/CamDavidsonPilon/lifelines\n\t```\n- [PyPi](https://pypi.org/project/lifelines) (\ud83d\udce5 480K / month \u00b7 \ud83d\udce6 110 \u00b7 \u23f1\ufe0f 26.06.2022):\n\t```\n\tpip install lifelines\n\t```\n- [Conda](https://anaconda.org/conda-forge/lifelines) (\ud83d\udce5 230K \u00b7 \u23f1\ufe0f 17.11.2022):\n\t```\n\tconda install -c conda-forge lifelines\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nilearn/nilearn\">Nilearn</a></b> (\ud83e\udd4834 \u00b7  \u2b50 900) - Machine learning for NeuroImaging in Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/nilearn/nilearn) (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 470 \u00b7 \ud83d\udce5 73 \u00b7 \ud83d\udce6 1.8K \u00b7 \ud83d\udccb 1.7K - 16% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/nilearn/nilearn\n\t```\n- [PyPi](https://pypi.org/project/nilearn) (\ud83d\udce5 35K / month \u00b7 \ud83d\udce6 240 \u00b7 \u23f1\ufe0f 13.04.2022):\n\t```\n\tpip install nilearn\n\t```\n- [Conda](https://anaconda.org/conda-forge/nilearn) (\ud83d\udce5 200K \u00b7 \u23f1\ufe0f 24.08.2022):\n\t```\n\tconda install -c conda-forge nilearn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/hail-is/hail\">Hail</a></b> (\ud83e\udd4833 \u00b7  \u2b50 840) - Scalable genomic data analysis. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/hail-is/hail) (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 85 \u00b7 \ud83d\udccb 2.1K - 2% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/hail-is/hail\n\t```\n- [PyPi](https://pypi.org/project/hail) (\ud83d\udce5 46K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 07.07.2022):\n\t```\n\tpip install hail\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nipy/nibabel\">NiBabel</a></b> (\ud83e\udd4833 \u00b7  \u2b50 500) - Python package to access a cacophony of neuro-imaging file formats. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/nipy/nibabel) (\ud83d\udc68\u200d\ud83d\udcbb 94 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udccb 470 - 30% open \u00b7 \u23f1\ufe0f 20.11.2022):\n\n\t```\n\tgit clone https://github.com/nipy/nibabel\n\t```\n- [PyPi](https://pypi.org/project/nibabel) (\ud83d\udce5 220K / month \u00b7 \ud83d\udce6 1K \u00b7 \u23f1\ufe0f 18.06.2022):\n\t```\n\tpip install nibabel\n\t```\n- [Conda](https://anaconda.org/conda-forge/nibabel) (\ud83d\udce5 500K \u00b7 \u23f1\ufe0f 31.08.2022):\n\t```\n\tconda install -c conda-forge nibabel\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dipy/dipy\">DIPY</a></b> (\ud83e\udd4830 \u00b7  \u2b50 550) - DIPY is the paragon 3D/4D+ imaging library in Python. Contains generic.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/dipy/dipy) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udce6 630 \u00b7 \ud83d\udccb 830 - 18% open \u00b7 \u23f1\ufe0f 02.11.2022):\n\n\t```\n\tgit clone https://github.com/dipy/dipy\n\t```\n- [PyPi](https://pypi.org/project/dipy) (\ud83d\udce5 13K / month \u00b7 \ud83d\udce6 80 \u00b7 \u23f1\ufe0f 11.03.2022):\n\t```\n\tpip install dipy\n\t```\n- [Conda](https://anaconda.org/conda-forge/dipy) (\ud83d\udce5 340K \u00b7 \u23f1\ufe0f 15.03.2022):\n\t```\n\tconda install -c conda-forge dipy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/deepvariant\">DeepVariant</a></b> (\ud83e\udd4925 \u00b7  \u2b50 2.7K) - DeepVariant is an analysis pipeline that uses a deep neural.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/google/deepvariant) (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 640 \u00b7 \ud83d\udce5 4.2K \u00b7 \ud83d\udccb 540 - 1% open \u00b7 \u23f1\ufe0f 17.10.2022):\n\n\t```\n\tgit clone https://github.com/google/deepvariant\n\t```\n- [Conda](https://anaconda.org/bioconda/deepvariant) (\ud83d\udce5 46K \u00b7 \u23f1\ufe0f 05.06.2022):\n\t```\n\tconda install -c bioconda deepvariant\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pyRiemann/pyRiemann\">pyRiemann</a></b> (\ud83e\udd4924 \u00b7  \u2b50 440) - Python machine learning package based on sklearn API for multivariate.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/pyRiemann/pyRiemann) (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 96 - 16% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/pyRiemann/pyRiemann\n\t```\n- [PyPi](https://pypi.org/project/pyriemann) (\ud83d\udce5 23K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 27.06.2021):\n\t```\n\tpip install pyriemann\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/MIC-DKFZ/medicaldetectiontoolkit\">Medical Detection Toolkit</a></b> (\ud83e\udd4915 \u00b7  \u2b50 1.2K \u00b7 \ud83d\udca4) - The Medical Detection Toolkit contains 2D + 3D.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/MIC-DKFZ/medicaldetectiontoolkit) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udccb 130 - 33% open \u00b7 \u23f1\ufe0f 04.04.2022):\n\n\t```\n\tgit clone https://github.com/MIC-DKFZ/medicaldetectiontoolkit\n\t```\n</details>\n<details><summary>Show 9 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/NifTK/NiftyNet\">NiftyNet</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.3K \u00b7 \ud83d\udc80) - [unmaintained] An open-source convolutional neural.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/loli/medpy\">MedPy</a></b> (\ud83e\udd4923 \u00b7  \u2b50 440) - Medical image processing in Python. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/nipy/nipy\">NIPY</a></b> (\ud83e\udd4923 \u00b7  \u2b50 320 \u00b7 \ud83d\udc80) - Neuroimaging in Python FMRI analysis package. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/DLTK/DLTK\">DLTK</a></b> (\ud83e\udd4922 \u00b7  \u2b50 1.3K \u00b7 \ud83d\udc80) - Deep Learning Toolkit for Medical Image Analysis. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/brainiak/brainiak\">Brainiak</a></b> (\ud83e\udd4921 \u00b7  \u2b50 290 \u00b7 \ud83d\udc80) - Brain Imaging Analysis Kit. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/projectglow/glow\">Glow</a></b> (\ud83e\udd4919 \u00b7  \u2b50 220) - An open-source toolkit for large-scale genomic analysis. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/perone/medicaltorch\">MedicalTorch</a></b> (\ud83e\udd4916 \u00b7  \u2b50 790 \u00b7 \ud83d\udc80) - A medical imaging framework for Pytorch. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/QTIM-Lab/DeepNeuro\">DeepNeuro</a></b> (\ud83e\udd4913 \u00b7  \u2b50 110 \u00b7 \ud83d\udc80) - A deep learning python package for neuroimaging data. Made by:. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/Tencent/MedicalNet\">MedicalNet</a></b> (\ud83e\udd4912 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Many studies have shown that the performance on deep learning is.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n</details>\n<br>\n\n## Tabular Data\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for processing tabular and structured data._\n\n<details><summary><b><a href=\"https://github.com/carefree0910/carefree-learn\">carefree-learn</a></b> (\ud83e\udd4722 \u00b7  \u2b50 380) - Deep Learning PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/carefree0910/carefree-learn) (\ud83d\udc68\u200d\ud83d\udcbb 1 \u00b7 \ud83d\udd00 35 \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/carefree0910/carefree-learn\n\t```\n- [PyPi](https://pypi.org/project/carefree-learn) (\ud83d\udce5 1.1K / month \u00b7 \u23f1\ufe0f 20.06.2022):\n\t```\n\tpip install carefree-learn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/manujosephv/pytorch_tabular\">pytorch_tabular</a></b> (\ud83e\udd4917 \u00b7  \u2b50 780) - A standard framework for modelling Deep Learning Models.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/manujosephv/pytorch_tabular) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 83 \u00b7 \ud83d\udccb 79 - 30% open \u00b7 \u23f1\ufe0f 02.11.2022):\n\n\t```\n\tgit clone https://github.com/manujosephv/pytorch_tabular\n\t```\n- [PyPi](https://pypi.org/project/pytorch_tabular) (\ud83d\udce5 1.7K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 01.09.2021):\n\t```\n\tpip install pytorch_tabular\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/firmai/deltapy\">deltapy</a></b> (\ud83e\udd4911 \u00b7  \u2b50 460 \u00b7 \ud83d\udca4) - DeltaPy - Tabular Data Augmentation (by @firmai). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/firmai/deltapy) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 46 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 3 - 66% open \u00b7 \u23f1\ufe0f 01.03.2022):\n\n\t```\n\tgit clone https://github.com/firmai/deltapy\n\t```\n- [PyPi](https://pypi.org/project/deltapy) (\ud83d\udce5 61 / month \u00b7 \u23f1\ufe0f 09.04.2020):\n\t```\n\tpip install deltapy\n\t```\n</details>\n<details><summary>Show 2 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/AnotherSamWilson/miceforest\">miceforest</a></b> (\ud83e\udd4821 \u00b7  \u2b50 200) - Multiple Imputation with LightGBM in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/upgini/upgini\">upgini</a></b> (\ud83e\udd4919 \u00b7  \u2b50 160) - Free automated data enrichment library for machine learning searches.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n</details>\n<br>\n\n## Optical Character Recognition\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for optical character recognition (OCR) and text extraction from images or videos._\n\n<details><summary><b><a href=\"https://github.com/PaddlePaddle/PaddleOCR\">PaddleOCR</a></b> (\ud83e\udd4738 \u00b7  \u2b50 27K) - Awesome multilingual OCR toolkits based on PaddlePaddle.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/PaddlePaddle/PaddleOCR) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 5.5K \u00b7 \ud83d\udce6 960 \u00b7 \ud83d\udccb 6K - 22% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/PaddlePaddle/PaddleOCR\n\t```\n- [PyPi](https://pypi.org/project/paddleocr) (\ud83d\udce5 45K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 10.05.2022):\n\t```\n\tpip install paddleocr\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/JaidedAI/EasyOCR\">EasyOCR</a></b> (\ud83e\udd4735 \u00b7  \u2b50 16K) - Ready-to-use OCR with 80+ supported languages and all popular writing.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/JaidedAI/EasyOCR) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 2.3K \u00b7 \ud83d\udce5 2.7M \u00b7 \ud83d\udce6 1.8K \u00b7 \ud83d\udccb 680 - 19% open \u00b7 \u23f1\ufe0f 18.11.2022):\n\n\t```\n\tgit clone https://github.com/JaidedAI/EasyOCR\n\t```\n- [PyPi](https://pypi.org/project/easyocr) (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 37 \u00b7 \u23f1\ufe0f 20.09.2022):\n\t```\n\tpip install easyocr\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/madmaze/pytesseract\">Tesseract</a></b> (\ud83e\udd4833 \u00b7  \u2b50 4.5K) - Python-tesseract is an optical character recognition (OCR) tool.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/madmaze/pytesseract) (\ud83d\udc68\u200d\ud83d\udcbb 43 \u00b7 \ud83d\udd00 630 \u00b7 \ud83d\udccb 320 - 6% open \u00b7 \u23f1\ufe0f 19.11.2022):\n\n\t```\n\tgit clone https://github.com/madmaze/pytesseract\n\t```\n- [PyPi](https://pypi.org/project/pytesseract) (\ud83d\udce5 660K / month \u00b7 \ud83d\udce6 960 \u00b7 \u23f1\ufe0f 19.02.2022):\n\t```\n\tpip install pytesseract\n\t```\n- [Conda](https://anaconda.org/conda-forge/pytesseract) (\ud83d\udce5 540K \u00b7 \u23f1\ufe0f 15.03.2022):\n\t```\n\tconda install -c conda-forge pytesseract\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ocrmypdf/OCRmyPDF\">OCRmyPDF</a></b> (\ud83e\udd4829 \u00b7  \u2b50 7.7K) - OCRmyPDF adds an OCR text layer to scanned PDF files, allowing them.. <code><a href=\"http://bit.ly/3postzC\">MPL-2.0</a></code></summary>\n\n- [GitHub](https://github.com/ocrmypdf/OCRmyPDF) (\ud83d\udc68\u200d\ud83d\udcbb 74 \u00b7 \ud83d\udd00 630 \u00b7 \ud83d\udccb 910 - 10% open \u00b7 \u23f1\ufe0f 04.10.2022):\n\n\t```\n\tgit clone https://github.com/ocrmypdf/OCRmyPDF\n\t```\n- [PyPi](https://pypi.org/project/ocrmypdf) (\ud83d\udce5 24K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 04.07.2022):\n\t```\n\tpip install ocrmypdf\n\t```\n- [Conda](https://anaconda.org/conda-forge/ocrmypdf) (\ud83d\udce5 32K \u00b7 \u23f1\ufe0f 04.10.2022):\n\t```\n\tconda install -c conda-forge ocrmypdf\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/open-mmlab/mmocr\">MMOCR</a></b> (\ud83e\udd4828 \u00b7  \u2b50 3K) - OpenMMLab Text Detection, Recognition and Understanding Toolbox. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/open-mmlab/mmocr) (\ud83d\udc68\u200d\ud83d\udcbb 67 \u00b7 \ud83d\udd00 550 \u00b7 \ud83d\udce6 33 \u00b7 \ud83d\udccb 780 - 16% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/open-mmlab/mmocr\n\t```\n- [PyPi](https://pypi.org/project/mmocr) (\ud83d\udce5 14K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 05.05.2022):\n\t```\n\tpip install mmocr\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/sirfz/tesserocr\">tesserocr</a></b> (\ud83e\udd4828 \u00b7  \u2b50 1.7K) - A Python wrapper for the tesseract-ocr API. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/sirfz/tesserocr) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 730 \u00b7 \ud83d\udccb 250 - 31% open \u00b7 \u23f1\ufe0f 26.08.2022):\n\n\t```\n\tgit clone https://github.com/sirfz/tesserocr\n\t```\n- [PyPi](https://pypi.org/project/tesserocr) (\ud83d\udce5 47K / month \u00b7 \ud83d\udce6 67 \u00b7 \u23f1\ufe0f 19.06.2021):\n\t```\n\tpip install tesserocr\n\t```\n- [Conda](https://anaconda.org/conda-forge/tesserocr) (\ud83d\udce5 93K \u00b7 \u23f1\ufe0f 06.11.2022):\n\t```\n\tconda install -c conda-forge tesserocr\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/faustomorales/keras-ocr\">keras-ocr</a></b> (\ud83e\udd4922 \u00b7  \u2b50 1.1K) - A packaged and flexible version of the CRAFT text detector and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/faustomorales/keras-ocr) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 280 \u00b7 \ud83d\udce5 380K \u00b7 \ud83d\udccb 180 - 40% open \u00b7 \u23f1\ufe0f 19.05.2022):\n\n\t```\n\tgit clone https://github.com/faustomorales/keras-ocr\n\t```\n- [PyPi](https://pypi.org/project/keras-ocr) (\ud83d\udce5 5.8K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 19.05.2022):\n\t```\n\tpip install keras-ocr\n\t```\n- [Conda](https://anaconda.org/anaconda/keras-ocr) (\ud83d\udce5 120 \u00b7 \u23f1\ufe0f 14.01.2022):\n\t```\n\tconda install -c anaconda keras-ocr\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/WZBSocialScienceCenter/pdftabextract\">pdftabextract</a></b> (\ud83e\udd4921 \u00b7  \u2b50 2K) - A set of tools for extracting tables from PDF files helping to.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/WZBSocialScienceCenter/pdftabextract) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 350 \u00b7 \ud83d\udce6 42 \u00b7 \ud83d\udccb 21 - 14% open \u00b7 \u23f1\ufe0f 24.06.2022):\n\n\t```\n\tgit clone https://github.com/WZBSocialScienceCenter/pdftabextract\n\t```\n- [PyPi](https://pypi.org/project/pdftabextract) (\ud83d\udce5 420 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 09.01.2018):\n\t```\n\tpip install pdftabextract\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Calamari-OCR/calamari\">calamari</a></b> (\ud83e\udd4919 \u00b7  \u2b50 940) - Line based ATR Engine based on OCRopy. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Calamari-OCR/calamari) (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udccb 250 - 19% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/Calamari-OCR/calamari\n\t```\n- [PyPi](https://pypi.org/project/calamari_ocr) (\ud83d\udce5 910 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 13.11.2018):\n\t```\n\tpip install calamari_ocr\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/aashrafh/Mozart\">Mozart</a></b> (\ud83e\udd4910 \u00b7  \u2b50 420) - An optical music recognition (OMR) system. Converts sheet music.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/aashrafh/Mozart) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 59 \u00b7 \ud83d\udccb 13 - 30% open \u00b7 \u23f1\ufe0f 24.08.2022):\n\n\t```\n\tgit clone https://github.com/aashrafh/Mozart\n\t```\n</details>\n<details><summary>Show 2 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/emedvedev/attention-ocr\">attention-ocr</a></b> (\ud83e\udd4921 \u00b7  \u2b50 930 \u00b7 \ud83d\udc80) - A Tensorflow model for text recognition (CNN + seq2seq.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/jlsutherland/doc2text\">doc2text</a></b> (\ud83e\udd4920 \u00b7  \u2b50 1.3K \u00b7 \ud83d\udc80) - Detect text blocks and OCR poorly scanned PDFs in bulk. Python.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n</details>\n<br>\n\n## Data Containers & Structures\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_General-purpose data containers & structures as well as utilities & extensions for pandas._\n\n\ud83d\udd17&nbsp;<b><a href=\"https://github.com/ml-tooling/best-of-python#data-containers--dataframes\">best-of-python - Data Containers</a></b> ( \u2b50 2.6K)  - Collection of data-container, dataframe, and pandas-..\n\n<br>\n\n## Data Loading & Extraction\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for loading, collecting, and extracting data from a variety of data sources and formats._\n\n\ud83d\udd17&nbsp;<b><a href=\"https://github.com/ml-tooling/best-of-python#data-loading--extraction\">best-of-python - Data Extraction</a></b> ( \u2b50 2.6K)  - Collection of data-loading and -extraction libraries.\n\n<br>\n\n## Web Scraping & Crawling\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for web scraping, crawling, downloading, and mining as well as libraries._\n\n\ud83d\udd17&nbsp;<b><a href=\"https://github.com/ml-tooling/best-of-web-python#web-scraping--crawling\">best-of-web-python - Web Scraping</a></b> ( \u2b50 1.7K)  - Collection of web-scraping and crawling libraries.\n\n<br>\n\n## Data Pipelines & Streaming\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for data batch- and stream-processing, workflow automation, job scheduling, and other data pipeline tasks._\n\n\ud83d\udd17&nbsp;<b><a href=\"https://github.com/ml-tooling/best-of-python#data-pipelines--streaming\">best-of-python - Data Pipelines</a></b> ( \u2b50 2.6K)  - Libraries for data batch- and stream-processing,..\n\n<br>\n\n## Distributed Machine Learning\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries that provide capabilities to distribute and parallelize machine learning tasks across large-scale compute infrastructure._\n\n<details><summary><b><a href=\"https://github.com/ray-project/ray\">Ray</a></b> (\ud83e\udd4744 \u00b7  \u2b50 23K) - Ray is a unified framework for scaling AI and Python applications. Ray.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/ray-project/ray) (\ud83d\udc68\u200d\ud83d\udcbb 780 \u00b7 \ud83d\udd00 4K \u00b7 \ud83d\udce6 6.4K \u00b7 \ud83d\udccb 12K - 22% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/ray-project/ray\n\t```\n- [PyPi](https://pypi.org/project/ray) (\ud83d\udce5 2.2M / month \u00b7 \ud83d\udce6 280 \u00b7 \u23f1\ufe0f 09.06.2022):\n\t```\n\tpip install ray\n\t```\n- [Conda](https://anaconda.org/conda-forge/ray-tune) (\ud83d\udce5 78K \u00b7 \u23f1\ufe0f 18.11.2022):\n\t```\n\tconda install -c conda-forge ray-tune\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dask/dask\">dask</a></b> (\ud83e\udd4743 \u00b7  \u2b50 11K) - Parallel computing with task scheduling. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/dask/dask) (\ud83d\udc68\u200d\ud83d\udcbb 570 \u00b7 \ud83d\udd00 1.6K \u00b7 \ud83d\udce6 42K \u00b7 \ud83d\udccb 4.7K - 17% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/dask/dask\n\t```\n- [PyPi](https://pypi.org/project/dask) (\ud83d\udce5 7.6M / month \u00b7 \ud83d\udce6 2.7K \u00b7 \u23f1\ufe0f 24.06.2022):\n\t```\n\tpip install dask\n\t```\n- [Conda](https://anaconda.org/conda-forge/dask) (\ud83d\udce5 7.3M \u00b7 \u23f1\ufe0f 18.11.2022):\n\t```\n\tconda install -c conda-forge dask\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dask/distributed\">dask.distributed</a></b> (\ud83e\udd4740 \u00b7  \u2b50 1.4K \u00b7 \ud83d\udcc9) - A distributed task scheduler for Dask. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/dask/distributed) (\ud83d\udc68\u200d\ud83d\udcbb 300 \u00b7 \ud83d\udd00 660 \u00b7 \ud83d\udce6 26K \u00b7 \ud83d\udccb 3.3K - 38% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/dask/distributed\n\t```\n- [PyPi](https://pypi.org/project/distributed) (\ud83d\udce5 4.1M / month \u00b7 \ud83d\udce6 1.2K \u00b7 \u23f1\ufe0f 24.06.2022):\n\t```\n\tpip install distributed\n\t```\n- [Conda](https://anaconda.org/conda-forge/distributed) (\ud83d\udce5 8.7M \u00b7 \u23f1\ufe0f 18.11.2022):\n\t```\n\tconda install -c conda-forge distributed\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/horovod/horovod\">horovod</a></b> (\ud83e\udd4738 \u00b7  \u2b50 13K \u00b7 \ud83d\udcc8) - Distributed training framework for TensorFlow, Keras, PyTorch,.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/horovod/horovod) (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 2.1K \u00b7 \ud83d\udce6 700 \u00b7 \ud83d\udccb 2.1K - 15% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/horovod/horovod\n\t```\n- [PyPi](https://pypi.org/project/horovod) (\ud83d\udce5 88K / month \u00b7 \ud83d\udce6 30 \u00b7 \u23f1\ufe0f 21.06.2022):\n\t```\n\tpip install horovod\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/microsoft/DeepSpeed\">DeepSpeed</a></b> (\ud83e\udd4835 \u00b7  \u2b50 8.2K) - DeepSpeed is a deep learning optimization library that makes.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/microsoft/DeepSpeed) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 950 \u00b7 \ud83d\udce6 500 \u00b7 \ud83d\udccb 1.2K - 48% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/microsoft/DeepSpeed\n\t```\n- [PyPi](https://pypi.org/project/deepspeed) (\ud83d\udce5 560K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 25.05.2022):\n\t```\n\tpip install deepspeed\n\t```\n- [Docker Hub](https://hub.docker.com/r/deepspeed/deepspeed) (\ud83d\udce5 14K \u00b7 \u2b50 3 \u00b7 \u23f1\ufe0f 02.09.2022):\n\t```\n\tdocker pull deepspeed/deepspeed\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/intel-analytics/BigDL\">BigDL</a></b> (\ud83e\udd4835 \u00b7  \u2b50 4.1K) - Fast, distributed, secure AI for Big Data. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/intel-analytics/BigDL) (\ud83d\udc68\u200d\ud83d\udcbb 170 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 40 \u00b7 \ud83d\udccb 1.7K - 37% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/intel-analytics/BigDL\n\t```\n- [PyPi](https://pypi.org/project/bigdl) (\ud83d\udce5 3.8K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 07.07.2022):\n\t```\n\tpip install bigdl\n\t```\n- [Maven](https://search.maven.org/artifact/com.intel.analytics.bigdl/bigdl-SPARK_2.4) (\ud83d\udce6 4 \u00b7 \u23f1\ufe0f 20.04.2021):\n\t```\n\t<dependency>\n\t\t<groupId>com.intel.analytics.bigdl</groupId>\n\t\t<artifactId>bigdl-SPARK_2.4</artifactId>\n\t\t<version>[VERSION]</version>\n\t</dependency>\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Lightning-AI/metrics\">metrics</a></b> (\ud83e\udd4834 \u00b7  \u2b50 1.2K) - Machine learning metrics for distributed, scalable PyTorch.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/Lightning-AI/metrics) (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udce5 1.2K \u00b7 \ud83d\udce6 5.8K \u00b7 \ud83d\udccb 500 - 11% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/Lightning-AI/metrics\n\t```\n- [PyPi](https://pypi.org/project/metrics) (\ud83d\udce5 3.9K / month \u00b7 \ud83d\udce6 14 \u00b7 \u23f1\ufe0f 28.04.2018):\n\t```\n\tpip install metrics\n\t```\n- [Conda](https://anaconda.org/conda-forge/torchmetrics) (\ud83d\udce5 580K \u00b7 \u23f1\ufe0f 17.11.2022):\n\t```\n\tconda install -c conda-forge torchmetrics\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/h2oai/h2o-3\">H2O-3</a></b> (\ud83e\udd4833 \u00b7  \u2b50 6.1K) - H2O is an Open Source, Distributed, Fast & Scalable Machine Learning.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/h2oai/h2o-3) (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 1.9K \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/h2oai/h2o-3\n\t```\n- [PyPi](https://pypi.org/project/h2o) (\ud83d\udce5 420K / month \u00b7 \ud83d\udce6 76 \u00b7 \u23f1\ufe0f 26.05.2022):\n\t```\n\tpip install h2o\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/fairscale\">FairScale</a></b> (\ud83e\udd4833 \u00b7  \u2b50 1.9K) - PyTorch extensions for high performance and large scale training. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/fairscale) (\ud83d\udc68\u200d\ud83d\udcbb 64 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 930 \u00b7 \ud83d\udccb 330 - 19% open \u00b7 \u23f1\ufe0f 21.10.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/fairscale\n\t```\n- [PyPi](https://pypi.org/project/fairscale) (\ud83d\udce5 760K / month \u00b7 \ud83d\udce6 20 \u00b7 \u23f1\ufe0f 09.03.2022):\n\t```\n\tpip install fairscale\n\t```\n- [Conda](https://anaconda.org/conda-forge/fairscale) (\ud83d\udce5 71K \u00b7 \u23f1\ufe0f 20.06.2022):\n\t```\n\tconda install -c conda-forge fairscale\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/microsoft/SynapseML\">SynapseML</a></b> (\ud83e\udd4829 \u00b7  \u2b50 3.8K) - Simple and Distributed Machine Learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/microsoft/SynapseML) (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 720 \u00b7 \ud83d\udccb 630 - 41% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/microsoft/SynapseML\n\t```\n- [PyPi](https://pypi.org/project/synapseml) (\ud83d\udce5 78K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 12.01.2022):\n\t```\n\tpip install synapseml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/maxpumperla/elephas\">Elephas</a></b> (\ud83e\udd4829 \u00b7  \u2b50 1.6K) - Distributed Deep learning with Keras & Spark. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code>keras</code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/maxpumperla/elephas) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 300 \u00b7 \ud83d\udce6 61 \u00b7 \ud83d\udccb 170 - 10% open \u00b7 \u23f1\ufe0f 31.08.2022):\n\n\t```\n\tgit clone https://github.com/maxpumperla/elephas\n\t```\n- [PyPi](https://pypi.org/project/elephas) (\ud83d\udce5 78K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 30.03.2022):\n\t```\n\tpip install elephas\n\t```\n- [Conda](https://anaconda.org/conda-forge/elephas) (\ud83d\udce5 10K \u00b7 \u23f1\ufe0f 02.06.2021):\n\t```\n\tconda install -c conda-forge elephas\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/mpi4py/mpi4py\">mpi4py</a></b> (\ud83e\udd4829 \u00b7  \u2b50 590) - Python bindings for MPI. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/mpi4py/mpi4py) (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 84 \u00b7 \ud83d\udce5 7.6K \u00b7 \ud83d\udccb 95 - 9% open \u00b7 \u23f1\ufe0f 18.11.2022):\n\n\t```\n\tgit clone https://github.com/mpi4py/mpi4py\n\t```\n- [PyPi](https://pypi.org/project/mpi4py) (\ud83d\udce5 250K / month \u00b7 \ud83d\udce6 620 \u00b7 \u23f1\ufe0f 25.11.2021):\n\t```\n\tpip install mpi4py\n\t```\n- [Conda](https://anaconda.org/conda-forge/mpi4py) (\ud83d\udce5 1.5M \u00b7 \u23f1\ufe0f 03.11.2022):\n\t```\n\tconda install -c conda-forge mpi4py\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/hpcaitech/ColossalAI\">ColossalAI</a></b> (\ud83e\udd4827 \u00b7  \u2b50 6.7K) - Colossal-AI: A Unified Deep Learning System for Big Model Era. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/hpcaitech/ColossalAI) (\ud83d\udc68\u200d\ud83d\udcbb 81 \u00b7 \ud83d\udd00 620 \u00b7 \ud83d\udce6 140 \u00b7 \ud83d\udccb 270 - 37% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/hpcaitech/colossalai\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/yahoo/TensorFlowOnSpark\">TensorFlowOnSpark</a></b> (\ud83e\udd4827 \u00b7  \u2b50 3.8K \u00b7 \ud83d\udca4) - TensorFlowOnSpark brings TensorFlow programs to.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/yahoo/TensorFlowOnSpark) (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 960 \u00b7 \ud83d\udccb 360 - 2% open \u00b7 \u23f1\ufe0f 21.04.2022):\n\n\t```\n\tgit clone https://github.com/yahoo/TensorFlowOnSpark\n\t```\n- [PyPi](https://pypi.org/project/tensorflowonspark) (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 21.04.2022):\n\t```\n\tpip install tensorflowonspark\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensorflowonspark) (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 21.08.2022):\n\t```\n\tconda install -c conda-forge tensorflowonspark\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dask/dask-ml\">dask-ml</a></b> (\ud83e\udd4827 \u00b7  \u2b50 830) - Scalable Machine Learning with Dask. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/dask/dask-ml) (\ud83d\udc68\u200d\ud83d\udcbb 76 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 690 \u00b7 \ud83d\udccb 490 - 50% open \u00b7 \u23f1\ufe0f 19.10.2022):\n\n\t```\n\tgit clone https://github.com/dask/dask-ml\n\t```\n- [PyPi](https://pypi.org/project/dask-ml) (\ud83d\udce5 55K / month \u00b7 \ud83d\udce6 57 \u00b7 \u23f1\ufe0f 27.05.2022):\n\t```\n\tpip install dask-ml\n\t```\n- [Conda](https://anaconda.org/conda-forge/dask-ml) (\ud83d\udce5 610K \u00b7 \u23f1\ufe0f 27.05.2022):\n\t```\n\tconda install -c conda-forge dask-ml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/uber/petastorm\">petastorm</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.5K) - Petastorm library enables single machine or distributed training.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/uber/petastorm) (\ud83d\udc68\u200d\ud83d\udcbb 45 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce5 340 \u00b7 \ud83d\udce6 85 \u00b7 \ud83d\udccb 300 - 51% open \u00b7 \u23f1\ufe0f 14.09.2022):\n\n\t```\n\tgit clone https://github.com/uber/petastorm\n\t```\n- [PyPi](https://pypi.org/project/petastorm) (\ud83d\udce5 52K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 19.02.2022):\n\t```\n\tpip install petastorm\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/intel-analytics/analytics-zoo\">analytics-zoo</a></b> (\ud83e\udd4925 \u00b7  \u2b50 2.5K) - Distributed Tensorflow, Keras and PyTorch on Apache.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/intel-analytics/analytics-zoo) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 720 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 1.4K - 39% open \u00b7 \u23f1\ufe0f 15.11.2022):\n\n\t```\n\tgit clone https://github.com/intel-analytics/analytics-zoo\n\t```\n- [PyPi](https://pypi.org/project/analytics-zoo) (\ud83d\udce5 760 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 07.07.2022):\n\t```\n\tpip install analytics-zoo\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/mesh\">Mesh</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.3K) - Mesh TensorFlow: Model Parallelism Made Easier. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/mesh) (\ud83d\udc68\u200d\ud83d\udcbb 48 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 740 \u00b7 \ud83d\udccb 110 - 87% open \u00b7 \u23f1\ufe0f 04.10.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/mesh\n\t```\n- [PyPi](https://pypi.org/project/mesh-tensorflow) (\ud83d\udce5 19K / month \u00b7 \ud83d\udce6 32 \u00b7 \u23f1\ufe0f 15.05.2022):\n\t```\n\tpip install mesh-tensorflow\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/learning-at-home/hivemind\">Hivemind</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.2K) - Decentralized deep learning in PyTorch. Built to train models on.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/learning-at-home/hivemind) (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 70 \u00b7 \ud83d\udce6 22 \u00b7 \ud83d\udccb 140 - 31% open \u00b7 \u23f1\ufe0f 01.11.2022):\n\n\t```\n\tgit clone https://github.com/learning-at-home/hivemind\n\t```\n- [PyPi](https://pypi.org/project/hivemind) (\ud83d\udce5 3.6K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 20.06.2022):\n\t```\n\tpip install hivemind\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/microsoft/SynapseML\">MMLSpark</a></b> (\ud83e\udd4924 \u00b7  \u2b50 3.8K) - Simple and Distributed Machine Learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/microsoft/SynapseML) (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 720 \u00b7 \ud83d\udccb 630 - 41% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/microsoft/SynapseML\n\t```\n- [PyPi](https://pypi.org/project/mmlspark) (\u23f1\ufe0f 18.03.2020):\n\t```\n\tpip install mmlspark\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/apache/singa\">Apache Singa</a></b> (\ud83e\udd4921 \u00b7  \u2b50 2.7K) - a distributed deep learning platform. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/apache/singa) (\ud83d\udc68\u200d\ud83d\udcbb 79 \u00b7 \ud83d\udd00 880 \u00b7 \ud83d\udce6 2 \u00b7 \ud83d\udccb 100 - 37% open \u00b7 \u23f1\ufe0f 01.06.2022):\n\n\t```\n\tgit clone https://github.com/apache/singa\n\t```\n- [Conda](https://anaconda.org/nusdbsystem/singa) (\ud83d\udce5 550 \u00b7 \u23f1\ufe0f 09.08.2021):\n\t```\n\tconda install -c nusdbsystem singa\n\t```\n- [Docker Hub](https://hub.docker.com/r/apache/singa) (\ud83d\udce5 2.2K \u00b7 \u2b50 4 \u00b7 \u23f1\ufe0f 31.05.2022):\n\t```\n\tdocker pull apache/singa\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookincubator/submitit\">Submit it</a></b> (\ud83e\udd4920 \u00b7  \u2b50 740) - Python 3.6+ toolbox for submitting jobs to Slurm. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/facebookincubator/submitit) (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 81 \u00b7 \ud83d\udccb 82 - 40% open \u00b7 \u23f1\ufe0f 28.09.2022):\n\n\t```\n\tgit clone https://github.com/facebookincubator/submitit\n\t```\n- [PyPi](https://pypi.org/project/submitit) (\ud83d\udce5 36K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 07.04.2022):\n\t```\n\tpip install submitit\n\t```\n- [Conda](https://anaconda.org/conda-forge/submitit) (\ud83d\udce5 12K \u00b7 \u23f1\ufe0f 10.02.2021):\n\t```\n\tconda install -c conda-forge submitit\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/bytedance/byteps\">BytePS</a></b> (\ud83e\udd4919 \u00b7  \u2b50 3.3K \u00b7 \ud83d\udca4) - A high performance and generic framework for distributed DNN.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/bytedance/byteps) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 460 \u00b7 \ud83d\udccb 260 - 38% open \u00b7 \u23f1\ufe0f 10.02.2022):\n\n\t```\n\tgit clone https://github.com/bytedance/byteps\n\t```\n- [PyPi](https://pypi.org/project/byteps) (\ud83d\udce5 59 / month \u00b7 \u23f1\ufe0f 02.08.2021):\n\t```\n\tpip install byteps\n\t```\n- [Docker Hub](https://hub.docker.com/r/bytepsimage/tensorflow) (\ud83d\udce5 1.3K \u00b7 \u23f1\ufe0f 03.03.2020):\n\t```\n\tdocker pull bytepsimage/tensorflow\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tunib-ai/parallelformers\">parallelformers</a></b> (\ud83e\udd4918 \u00b7  \u2b50 550) - Parallelformers: An Efficient Model Parallelization.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/tunib-ai/parallelformers) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 38 \u00b7 \ud83d\udce6 12 \u00b7 \ud83d\udccb 35 - 51% open \u00b7 \u23f1\ufe0f 27.07.2022):\n\n\t```\n\tgit clone https://github.com/tunib-ai/parallelformers\n\t```\n- [PyPi](https://pypi.org/project/parallelformers) (\ud83d\udce5 5.9K / month \u00b7 \u23f1\ufe0f 29.12.2021):\n\t```\n\tpip install parallelformers\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/kingoflolz/mesh-transformer-jax\">mesh-transformer-jax</a></b> (\ud83e\udd4916 \u00b7  \u2b50 4.6K \u00b7 \ud83d\udca4) - Model parallel transformers in JAX and Haiku. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/kingoflolz/mesh-transformer-jax) (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 640 \u00b7 \ud83d\udccb 190 - 16% open \u00b7 \u23f1\ufe0f 28.01.2022):\n\n\t```\n\tgit clone https://github.com/kingoflolz/mesh-transformer-jax\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/moolib\">moolib</a></b> (\ud83e\udd4912 \u00b7  \u2b50 340) - A library for distributed ML training with PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/moolib) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 15 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 17 - 35% open \u00b7 \u23f1\ufe0f 07.11.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/moolib\n\t```\n</details>\n<details><summary>Show 10 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/DEAP/deap\">DEAP</a></b> (\ud83e\udd4832 \u00b7  \u2b50 4.9K) - Distributed Evolutionary Algorithms in Python. <code><a href=\"http://bit.ly/37RvQcA\">\u2757\ufe0fLGPL-3.0</a></code>\n- <b><a href=\"https://github.com/ipython/ipyparallel\">ipyparallel</a></b> (\ud83e\udd4830 \u00b7  \u2b50 2.3K) - IPython Parallel: Interactive Parallel Computing in.. <code>\u2757Unlicensed</code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/databricks/tensorframes\">TensorFrames</a></b> (\ud83e\udd4921 \u00b7  \u2b50 760 \u00b7 \ud83d\udc80) - [DEPRECATED] Tensorflow wrapper for DataFrames on.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/deepmind/launchpad\">launchpad</a></b> (\ud83e\udd4921 \u00b7  \u2b50 280) - Launchpad is a library that simplifies writing distributed.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/Ibotta/sk-dist\">sk-dist</a></b> (\ud83e\udd4920 \u00b7  \u2b50 280 \u00b7 \ud83d\udc80) - Distributed scikit-learn meta-estimators in PySpark. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/peterwittek/somoclu\">somoclu</a></b> (\ud83e\udd4919 \u00b7  \u2b50 240) - Massively parallel self-organizing maps: accelerate training on multicore.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/uber/fiber\">Fiber</a></b> (\ud83e\udd4918 \u00b7  \u2b50 990 \u00b7 \ud83d\udc80) - Distributed Computing for AI Made Simple. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/Bluefog-Lib/bluefog\">bluefog</a></b> (\ud83e\udd4916 \u00b7  \u2b50 280) - Distributed and decentralized training framework for PyTorch.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/ml-tooling/lazycluster\">LazyCluster</a></b> (\ud83e\udd4914 \u00b7  \u2b50 44 \u00b7 \ud83d\udc80) - Distributed machine learning made simple. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/petuum/autodist\">autodist</a></b> (\ud83e\udd4912 \u00b7  \u2b50 120 \u00b7 \ud83d\udc80) - Simple Distributed Deep Learning on TensorFlow. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Hyperparameter Optimization & AutoML\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for hyperparameter optimization, automl and neural architecture search._\n\n<details><summary><b><a href=\"https://github.com/optuna/optuna\">Optuna</a></b> (\ud83e\udd4740 \u00b7  \u2b50 7.2K) - A hyperparameter optimization framework. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/optuna/optuna) (\ud83d\udc68\u200d\ud83d\udcbb 220 \u00b7 \ud83d\udd00 770 \u00b7 \ud83d\udce6 4.7K \u00b7 \ud83d\udccb 1.3K - 7% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/optuna/optuna\n\t```\n- [PyPi](https://pypi.org/project/optuna) (\ud83d\udce5 2.1M / month \u00b7 \ud83d\udce6 240 \u00b7 \u23f1\ufe0f 13.06.2022):\n\t```\n\tpip install optuna\n\t```\n- [Conda](https://anaconda.org/conda-forge/optuna) (\ud83d\udce5 350K \u00b7 \u23f1\ufe0f 13.10.2022):\n\t```\n\tconda install -c conda-forge optuna\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/microsoft/nni\">NNI</a></b> (\ud83e\udd4736 \u00b7  \u2b50 12K) - An open source AutoML toolkit for automate machine learning lifecycle,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/microsoft/nni) (\ud83d\udc68\u200d\ud83d\udcbb 180 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce6 320 \u00b7 \ud83d\udccb 1.8K - 15% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/microsoft/nni\n\t```\n- [PyPi](https://pypi.org/project/nni) (\ud83d\udce5 27K / month \u00b7 \ud83d\udce6 30 \u00b7 \u23f1\ufe0f 22.06.2022):\n\t```\n\tpip install nni\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/keras-team/autokeras\">AutoKeras</a></b> (\ud83e\udd4734 \u00b7  \u2b50 8.7K) - AutoML library for deep learning. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/keras-team/autokeras) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce5 9.8K \u00b7 \ud83d\udce6 390 \u00b7 \ud83d\udccb 850 - 12% open \u00b7 \u23f1\ufe0f 10.11.2022):\n\n\t```\n\tgit clone https://github.com/keras-team/autokeras\n\t```\n- [PyPi](https://pypi.org/project/autokeras) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 30.04.2022):\n\t```\n\tpip install autokeras\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/automl/auto-sklearn\">auto-sklearn</a></b> (\ud83e\udd4733 \u00b7  \u2b50 6.6K) - Automated Machine Learning with scikit-learn. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/automl/auto-sklearn) (\ud83d\udc68\u200d\ud83d\udcbb 88 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udce5 39 \u00b7 \ud83d\udce6 350 \u00b7 \ud83d\udccb 940 - 14% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/automl/auto-sklearn\n\t```\n- [PyPi](https://pypi.org/project/auto-sklearn) (\ud83d\udce5 38K / month \u00b7 \ud83d\udce6 30 \u00b7 \u23f1\ufe0f 20.09.2022):\n\t```\n\tpip install auto-sklearn\n\t```\n- [Conda](https://anaconda.org/conda-forge/auto-sklearn) (\ud83d\udce5 12K \u00b7 \u23f1\ufe0f 21.09.2022):\n\t```\n\tconda install -c conda-forge auto-sklearn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/fmfn/BayesianOptimization\">Bayesian Optimization</a></b> (\ud83e\udd4733 \u00b7  \u2b50 6.4K) - A Python implementation of global optimization with.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/fmfn/BayesianOptimization) (\ud83d\udc68\u200d\ud83d\udcbb 36 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce5 110 \u00b7 \ud83d\udce6 1.4K \u00b7 \ud83d\udccb 280 - 6% open \u00b7 \u23f1\ufe0f 27.10.2022):\n\n\t```\n\tgit clone https://github.com/fmfn/BayesianOptimization\n\t```\n- [PyPi](https://pypi.org/project/bayesian-optimization) (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 91 \u00b7 \u23f1\ufe0f 16.05.2020):\n\t```\n\tpip install bayesian-optimization\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/alteryx/featuretools\">featuretools</a></b> (\ud83e\udd4733 \u00b7  \u2b50 6.4K) - An open source python library for automated feature engineering. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/alteryx/featuretools) (\ud83d\udc68\u200d\ud83d\udcbb 68 \u00b7 \ud83d\udd00 840 \u00b7 \ud83d\udccb 880 - 18% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/alteryx/featuretools\n\t```\n- [PyPi](https://pypi.org/project/featuretools) (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 64 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install featuretools\n\t```\n- [Conda](https://anaconda.org/conda-forge/featuretools) (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 22.11.2022):\n\t```\n\tconda install -c conda-forge featuretools\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/autogluon/autogluon\">AutoGluon</a></b> (\ud83e\udd4733 \u00b7  \u2b50 5.1K) - AutoGluon: AutoML for Image, Text, Time Series, and Tabular.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1X\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/autogluon/autogluon) (\ud83d\udc68\u200d\ud83d\udcbb 95 \u00b7 \ud83d\udd00 660 \u00b7 \ud83d\udce6 190 \u00b7 \ud83d\udccb 800 - 23% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/awslabs/autogluon\n\t```\n- [PyPi](https://pypi.org/project/autogluon) (\ud83d\udce5 32K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 07.07.2022):\n\t```\n\tpip install autogluon\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/keras-team/keras-tuner\">Keras Tuner</a></b> (\ud83e\udd4733 \u00b7  \u2b50 2.6K) - A Hyperparameter Tuning Library for Keras. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/keras-team/keras-tuner) (\ud83d\udc68\u200d\ud83d\udcbb 51 \u00b7 \ud83d\udd00 340 \u00b7 \ud83d\udce6 1.8K \u00b7 \ud83d\udccb 420 - 43% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/keras-team/keras-tuner\n\t```\n- [PyPi](https://pypi.org/project/keras-tuner) (\ud83d\udce5 570K / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 25.03.2022):\n\t```\n\tpip install keras-tuner\n\t```\n- [Conda](https://anaconda.org/conda-forge/keras-tuner) (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 16.10.2022):\n\t```\n\tconda install -c conda-forge keras-tuner\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/botorch\">BoTorch</a></b> (\ud83e\udd4733 \u00b7  \u2b50 2.5K) - Bayesian optimization in PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pytorch/botorch) (\ud83d\udc68\u200d\ud83d\udcbb 85 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udce6 370 \u00b7 \ud83d\udccb 340 - 21% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/botorch\n\t```\n- [PyPi](https://pypi.org/project/botorch) (\ud83d\udce5 170K / month \u00b7 \ud83d\udce6 18 \u00b7 \u23f1\ufe0f 21.04.2022):\n\t```\n\tpip install botorch\n\t```\n- [Conda](https://anaconda.org/conda-forge/botorch) (\ud83d\udce5 48K \u00b7 \u23f1\ufe0f 11.11.2022):\n\t```\n\tconda install -c conda-forge botorch\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebook/Ax\">Ax</a></b> (\ud83e\udd4733 \u00b7  \u2b50 1.9K) - Adaptive Experimentation Platform. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebook/Ax) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 360 \u00b7 \ud83d\udccb 490 - 11% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/facebook/Ax\n\t```\n- [PyPi](https://pypi.org/project/ax-platform) (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 15 \u00b7 \u23f1\ufe0f 26.04.2022):\n\t```\n\tpip install ax-platform\n\t```\n- [Conda](https://anaconda.org/conda-forge/ax-platform) (\ud83d\udce5 4.7K \u00b7 \u23f1\ufe0f 13.11.2022):\n\t```\n\tconda install -c conda-forge ax-platform\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/hyperopt/hyperopt\">Hyperopt</a></b> (\ud83e\udd4832 \u00b7  \u2b50 6.5K \u00b7 \ud83d\udca4) - Distributed Asynchronous Hyperparameter Optimization in Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/hyperopt/hyperopt) (\ud83d\udc68\u200d\ud83d\udcbb 93 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udce6 8.1K \u00b7 \ud83d\udccb 620 - 61% open \u00b7 \u23f1\ufe0f 29.11.2021):\n\n\t```\n\tgit clone https://github.com/hyperopt/hyperopt\n\t```\n- [PyPi](https://pypi.org/project/hyperopt) (\ud83d\udce5 1.8M / month \u00b7 \ud83d\udce6 430 \u00b7 \u23f1\ufe0f 17.11.2021):\n\t```\n\tpip install hyperopt\n\t```\n- [Conda](https://anaconda.org/conda-forge/hyperopt) (\ud83d\udce5 610K \u00b7 \u23f1\ufe0f 30.04.2022):\n\t```\n\tconda install -c conda-forge hyperopt\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/nevergrad\">nevergrad</a></b> (\ud83e\udd4828 \u00b7  \u2b50 3.4K) - A Python toolbox for performing gradient-free optimization. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/nevergrad) (\ud83d\udc68\u200d\ud83d\udcbb 49 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udce6 400 \u00b7 \ud83d\udccb 260 - 39% open \u00b7 \u23f1\ufe0f 10.08.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/nevergrad\n\t```\n- [PyPi](https://pypi.org/project/nevergrad) (\ud83d\udce5 33K / month \u00b7 \ud83d\udce6 20 \u00b7 \u23f1\ufe0f 08.03.2022):\n\t```\n\tpip install nevergrad\n\t```\n- [Conda](https://anaconda.org/conda-forge/nevergrad) (\ud83d\udce5 34K \u00b7 \u23f1\ufe0f 14.06.2021):\n\t```\n\tconda install -c conda-forge nevergrad\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/maxpumperla/hyperas\">Hyperas</a></b> (\ud83e\udd4827 \u00b7  \u2b50 2.1K \u00b7 \ud83d\udca4) - Keras + Hyperopt: A very simple wrapper for convenient.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/maxpumperla/hyperas) (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce6 260 \u00b7 \ud83d\udccb 250 - 37% open \u00b7 \u23f1\ufe0f 19.11.2021):\n\n\t```\n\tgit clone https://github.com/maxpumperla/hyperas\n\t```\n- [PyPi](https://pypi.org/project/hyperas) (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 24 \u00b7 \u23f1\ufe0f 28.02.2019):\n\t```\n\tpip install hyperas\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/mljar/mljar-supervised\">mljar-supervised</a></b> (\ud83e\udd4825 \u00b7  \u2b50 2.3K) - Python package for AutoML on Tabular Data with Feature.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/mljar/mljar-supervised) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 300 \u00b7 \ud83d\udce6 57 \u00b7 \ud83d\udccb 520 - 21% open \u00b7 \u23f1\ufe0f 03.11.2022):\n\n\t```\n\tgit clone https://github.com/mljar/mljar-supervised\n\t```\n- [PyPi](https://pypi.org/project/mljar-supervised) (\ud83d\udce5 6.5K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 02.03.2022):\n\t```\n\tpip install mljar-supervised\n\t```\n- [Conda](https://anaconda.org/conda-forge/mljar-supervised) (\ud83d\udce5 5.4K \u00b7 \u23f1\ufe0f 17.08.2022):\n\t```\n\tconda install -c conda-forge mljar-supervised\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/aimclub/FEDOT\">FEDOT</a></b> (\ud83e\udd4825 \u00b7  \u2b50 470) - Automated modeling and machine learning framework FEDOT. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/aimclub/FEDOT) (\ud83d\udc68\u200d\ud83d\udcbb 26 \u00b7 \ud83d\udd00 60 \u00b7 \ud83d\udce6 25 \u00b7 \ud83d\udccb 440 - 26% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/nccr-itmo/FEDOT\n\t```\n- [PyPi](https://pypi.org/project/fedot) (\ud83d\udce5 1.2K / month \u00b7 \u23f1\ufe0f 28.03.2022):\n\t```\n\tpip install fedot\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/autonomio/talos\">Talos</a></b> (\ud83e\udd4824 \u00b7  \u2b50 1.6K) - Hyperparameter Optimization for TensorFlow, Keras and PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/autonomio/talos) (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 150 \u00b7 \ud83d\udccb 400 - 2% open \u00b7 \u23f1\ufe0f 18.09.2022):\n\n\t```\n\tgit clone https://github.com/autonomio/talos\n\t```\n- [PyPi](https://pypi.org/project/talos) (\ud83d\udce5 1.2K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 28.05.2022):\n\t```\n\tpip install talos\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/shankarpandala/lazypredict\">lazypredict</a></b> (\ud83e\udd4824 \u00b7  \u2b50 540) - Lazy Predict help build a lot of basic models without much code.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/shankarpandala/lazypredict) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 83 \u00b7 \ud83d\udce6 360 \u00b7 \ud83d\udccb 75 - 52% open \u00b7 \u23f1\ufe0f 28.09.2022):\n\n\t```\n\tgit clone https://github.com/shankarpandala/lazypredict\n\t```\n- [PyPi](https://pypi.org/project/lazypredict) (\ud83d\udce5 7.7K / month \u00b7 \u23f1\ufe0f 17.02.2021):\n\t```\n\tpip install lazypredict\n\t```\n- [Conda](https://anaconda.org/conda-forge/lazypredict) (\ud83d\udce5 1.2K \u00b7 \u23f1\ufe0f 29.09.2022):\n\t```\n\tconda install -c conda-forge lazypredict\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/automl/HpBandSter\">HpBandSter</a></b> (\ud83e\udd4923 \u00b7  \u2b50 550 \u00b7 \ud83d\udca4) - a distributed Hyperband implementation on Steroids. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/automl/HpBandSter) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 270 \u00b7 \ud83d\udccb 92 - 61% open \u00b7 \u23f1\ufe0f 22.04.2022):\n\n\t```\n\tgit clone https://github.com/automl/HpBandSter\n\t```\n- [PyPi](https://pypi.org/project/hpbandster) (\ud83d\udce5 18K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 06.11.2018):\n\t```\n\tpip install hpbandster\n\t```\n- [Conda](https://anaconda.org/conda-forge/hpbandster) (\ud83d\udce5 4.3K \u00b7 \u23f1\ufe0f 11.12.2020):\n\t```\n\tconda install -c conda-forge hpbandster\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/AutoViML/featurewiz\">featurewiz</a></b> (\ud83e\udd4923 \u00b7  \u2b50 330) - Use advanced feature engineering strategies and select best.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/AutoViML/featurewiz) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 64 \u00b7 \ud83d\udce6 23 \u00b7 \ud83d\udccb 53 - 1% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/AutoViML/featurewiz\n\t```\n- [PyPi](https://pypi.org/project/featurewiz) (\ud83d\udce5 13K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install featurewiz\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/SimonBlanke/Hyperactive\">Hyperactive</a></b> (\ud83e\udd4922 \u00b7  \u2b50 420) - An optimization and data collection toolbox for convenient and fast.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/SimonBlanke/Hyperactive) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 36 \u00b7 \ud83d\udce5 100 \u00b7 \ud83d\udce6 16 \u00b7 \ud83d\udccb 50 - 16% open \u00b7 \u23f1\ufe0f 19.11.2022):\n\n\t```\n\tgit clone https://github.com/SimonBlanke/Hyperactive\n\t```\n- [PyPi](https://pypi.org/project/hyperactive) (\ud83d\udce5 770 / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 04.05.2022):\n\t```\n\tpip install hyperactive\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Neuraxio/Neuraxle\">Neuraxle</a></b> (\ud83e\udd4921 \u00b7  \u2b50 550) - The worlds cleanest AutoML library - Do hyperparameter tuning with.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Neuraxio/Neuraxle) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 54 \u00b7 \ud83d\udce6 35 \u00b7 \ud83d\udccb 320 - 19% open \u00b7 \u23f1\ufe0f 16.08.2022):\n\n\t```\n\tgit clone https://github.com/Neuraxio/Neuraxle\n\t```\n- [PyPi](https://pypi.org/project/neuraxle) (\ud83d\udce5 420 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 15.04.2022):\n\t```\n\tpip install neuraxle\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dragonfly/dragonfly\">Dragonfly</a></b> (\ud83e\udd4920 \u00b7  \u2b50 740) - An open source python library for scalable Bayesian optimisation. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/dragonfly/dragonfly) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 210 \u00b7 \ud83d\udccb 58 - 65% open \u00b7 \u23f1\ufe0f 01.10.2022):\n\n\t```\n\tgit clone https://github.com/dragonfly/dragonfly\n\t```\n- [PyPi](https://pypi.org/project/dragonfly-opt) (\ud83d\udce5 38K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 03.07.2020):\n\t```\n\tpip install dragonfly-opt\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/AutoViML/Auto_ViML\">Auto ViML</a></b> (\ud83e\udd4919 \u00b7  \u2b50 380) - Automatically Build Multiple ML Models with a Single Line of Code... <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/AutoViML/Auto_ViML) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 82 \u00b7 \ud83d\udce6 20 \u00b7 \ud83d\udccb 22 - 18% open \u00b7 \u23f1\ufe0f 16.08.2022):\n\n\t```\n\tgit clone https://github.com/AutoViML/Auto_ViML\n\t```\n- [PyPi](https://pypi.org/project/autoviml) (\ud83d\udce5 370 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 01.06.2022):\n\t```\n\tpip install autoviml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nidhaloff/igel\">igel</a></b> (\ud83e\udd4918 \u00b7  \u2b50 3K \u00b7 \ud83d\udca4) - a delightful machine learning tool that allows you to train, test, and use.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/nidhaloff/igel) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce5 33 \u00b7 \ud83d\udccb 50 - 12% open \u00b7 \u23f1\ufe0f 06.02.2022):\n\n\t```\n\tgit clone https://github.com/nidhaloff/igel\n\t```\n- [PyPi](https://pypi.org/project/igel) (\ud83d\udce5 130 / month \u00b7 \u23f1\ufe0f 19.11.2021):\n\t```\n\tpip install igel\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ScottfreeLLC/AlphaPy\">AlphaPy</a></b> (\ud83e\udd4918 \u00b7  \u2b50 820 \u00b7 \ud83d\udca4) - Automated Machine Learning [AutoML] with Python, scikit-learn,.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/ScottfreeLLC/AlphaPy) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 41 - 29% open \u00b7 \u23f1\ufe0f 23.04.2022):\n\n\t```\n\tgit clone https://github.com/ScottfreeLLC/AlphaPy\n\t```\n- [PyPi](https://pypi.org/project/alphapy) (\ud83d\udce5 50 / month \u00b7 \u23f1\ufe0f 29.08.2020):\n\t```\n\tpip install alphapy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/gugarosa/opytimizer\">opytimizer</a></b> (\ud83e\udd4918 \u00b7  \u2b50 540) - Opytimizer is a Python library consisting of meta-heuristic.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/gugarosa/opytimizer) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 33 \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 06.10.2022):\n\n\t```\n\tgit clone https://github.com/gugarosa/opytimizer\n\t```\n- [PyPi](https://pypi.org/project/opytimizer) (\ud83d\udce5 910 / month \u00b7 \u23f1\ufe0f 04.05.2022):\n\t```\n\tpip install opytimizer\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/cerlymarco/shap-hypetune\">shap-hypetune</a></b> (\ud83e\udd4917 \u00b7  \u2b50 400) - A python package for simultaneous Hyperparameters Tuning and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/cerlymarco/shap-hypetune) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 50 \u00b7 \ud83d\udce6 9 \u00b7 \ud83d\udccb 17 - 5% open \u00b7 \u23f1\ufe0f 24.08.2022):\n\n\t```\n\tgit clone https://github.com/cerlymarco/shap-hypetune\n\t```\n- [PyPi](https://pypi.org/project/shap-hypetune) (\ud83d\udce5 4K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 16.01.2022):\n\t```\n\tpip install shap-hypetune\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/model_search\">model_search</a></b> (\ud83e\udd4911 \u00b7  \u2b50 3.2K \u00b7 \ud83d\udca4) - AutoML algorithms for model architecture search at scale. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/google/model_search) (\ud83d\udc68\u200d\ud83d\udcbb 1 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udccb 52 - 71% open \u00b7 \u23f1\ufe0f 09.02.2022):\n\n\t```\n\tgit clone https://github.com/google/model_search\n\t```\n</details>\n<details><summary>Show 24 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/EpistasisLab/tpot\">TPOT</a></b> (\ud83e\udd4832 \u00b7  \u2b50 8.8K) - A Python Automated Machine Learning tool that optimizes machine.. <code><a href=\"http://bit.ly/37RvQcA\">\u2757\ufe0fLGPL-3.0</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/scikit-optimize/scikit-optimize\">scikit-optimize</a></b> (\ud83e\udd4831 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udc80) - Sequential model-based optimization with a.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/SheffieldML/GPyOpt\">GPyOpt</a></b> (\ud83e\udd4827 \u00b7  \u2b50 840 \u00b7 \ud83d\udc80) - Gaussian Process Optimization using GPy. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/Epistimio/orion\">Orion</a></b> (\ud83e\udd4827 \u00b7  \u2b50 250) - Asynchronous Distributed Hyperparameter Optimization. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/automl/SMAC3\">SMAC3</a></b> (\ud83e\udd4826 \u00b7  \u2b50 760) - SMAC3: A Versatile Bayesian Optimization Package for.. <code><a href=\"https://tldrlegal.com/search?q=BSD-1-Clause\">\u2757\ufe0fBSD-1-Clause</a></code>\n- <b><a href=\"https://github.com/tensorflow/adanet\">AdaNet</a></b> (\ud83e\udd4824 \u00b7  \u2b50 3.4K \u00b7 \ud83d\udc80) - Fast and flexible AutoML with learning guarantees. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/AxeldeRomblay/MLBox\">MLBox</a></b> (\ud83e\udd4923 \u00b7  \u2b50 1.4K \u00b7 \ud83d\udc80) - MLBox is a powerful Automated Machine Learning python library. <code><a href=\"https://tldrlegal.com/search?q=BSD-1-Clause\">\u2757\ufe0fBSD-1-Clause</a></code>\n- <b><a href=\"https://github.com/mindsdb/lightwood\">lightwood</a></b> (\ud83e\udd4923 \u00b7  \u2b50 300) - Lightwood is Legos for Machine Learning. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/ClimbsRocks/auto_ml\">auto_ml</a></b> (\ud83e\udd4922 \u00b7  \u2b50 1.6K \u00b7 \ud83d\udc80) - [UNMAINTAINED] Automated machine learning for analytics & production. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/williamFalcon/test-tube\">Test Tube</a></b> (\ud83e\udd4922 \u00b7  \u2b50 730 \u00b7 \ud83d\udc80) - Python library to easily log experiments and parallelize.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/claesenm/optunity\">optunity</a></b> (\ud83e\udd4922 \u00b7  \u2b50 400 \u00b7 \ud83d\udc80) - optimization routines for hyperparameter tuning. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/rsteca/sklearn-deap\">sklearn-deap</a></b> (\ud83e\udd4920 \u00b7  \u2b50 710 \u00b7 \ud83d\udc80) - Use evolutionary algorithms instead of gridsearch in.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/HDI-Project/ATM\">Auto Tune Models</a></b> (\ud83e\udd4918 \u00b7  \u2b50 520 \u00b7 \ud83d\udc80) - Auto Tune Models - A multi-tenant, multi-data system for.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/sherpa-ai/sherpa\">Sherpa</a></b> (\ud83e\udd4918 \u00b7  \u2b50 320 \u00b7 \ud83d\udc80) - Hyperparameter optimization that enables researchers to.. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/tobegit3hub/advisor\">Advisor</a></b> (\ud83e\udd4917 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Open-source implementation of Google Vizier for hyper parameters.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/jmcarpenter2/parfit\">Parfit</a></b> (\ud83e\udd4917 \u00b7  \u2b50 200 \u00b7 \ud83d\udc80) - A package for parallelizing the fit and flexibly scoring of.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/minimaxir/automl-gs\">automl-gs</a></b> (\ud83e\udd4916 \u00b7  \u2b50 1.8K \u00b7 \ud83d\udc80) - Provide an input CSV and a target field to predict, generate a.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/HunterMcGushion/hyperparameter_hunter\">HyperparameterHunter</a></b> (\ud83e\udd4916 \u00b7  \u2b50 700 \u00b7 \ud83d\udc80) - Easy hyperparameter optimization and automatic result.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/reiinakano/xcessiv\">Xcessiv</a></b> (\ud83e\udd4915 \u00b7  \u2b50 1.3K \u00b7 \ud83d\udc80) - A web-based application for quick, scalable, and automated.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/carpedm20/ENAS-pytorch\">ENAS</a></b> (\ud83e\udd4913 \u00b7  \u2b50 2.6K \u00b7 \ud83d\udc80) - PyTorch implementation of Efficient Neural Architecture Search via.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/LGE-ARC-AdvancedAI/auptimizer\">Auptimizer</a></b> (\ud83e\udd4913 \u00b7  \u2b50 190 \u00b7 \ud83d\udc80) - An automatic ML model optimization tool. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/joeddav/devol\">Devol</a></b> (\ud83e\udd4911 \u00b7  \u2b50 940 \u00b7 \ud83d\udc80) - Genetic neural architecture search with Keras. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/electricbrainio/hypermax\">Hypermax</a></b> (\ud83e\udd4911 \u00b7  \u2b50 100 \u00b7 \ud83d\udc80) - Better, faster hyper-parameter optimization. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/gdikov/hypertunity\">Hypertunity</a></b> (\ud83e\udd499 \u00b7  \u2b50 120 \u00b7 \ud83d\udc80) - A toolset for black-box hyperparameter optimisation. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n</details>\n<br>\n\n## Reinforcement Learning\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for building and evaluating reinforcement learning & agent-based systems._\n\n<details><summary><b><a href=\"https://github.com/openai/gym\">OpenAI Gym</a></b> (\ud83e\udd4741 \u00b7  \u2b50 29K \u00b7 \ud83d\udcc9) - A toolkit for developing and comparing reinforcement learning.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/openai/gym) (\ud83d\udc68\u200d\ud83d\udcbb 380 \u00b7 \ud83d\udd00 8K \u00b7 \ud83d\udce6 34K \u00b7 \ud83d\udccb 1.7K - 1% open \u00b7 \u23f1\ufe0f 25.10.2022):\n\n\t```\n\tgit clone https://github.com/openai/gym\n\t```\n- [PyPi](https://pypi.org/project/gym) (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 2.5K \u00b7 \u23f1\ufe0f 07.06.2022):\n\t```\n\tpip install gym\n\t```\n- [Conda](https://anaconda.org/conda-forge/gym) (\ud83d\udce5 160K \u00b7 \u23f1\ufe0f 10.07.2022):\n\t```\n\tconda install -c conda-forge gym\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/agents\">TF-Agents</a></b> (\ud83e\udd4734 \u00b7  \u2b50 2.4K) - TF-Agents: A reliable, scalable and easy to use TensorFlow.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/agents) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 660 \u00b7 \ud83d\udce6 960 \u00b7 \ud83d\udccb 590 - 25% open \u00b7 \u23f1\ufe0f 19.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/agents\n\t```\n- [PyPi](https://pypi.org/project/tf-agents) (\ud83d\udce5 120K / month \u00b7 \u23f1\ufe0f 23.10.2022):\n\t```\n\tpip install tf-agents\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/dopamine\">Dopamine</a></b> (\ud83e\udd4729 \u00b7  \u2b50 9.9K) - Dopamine is a research framework for fast prototyping of.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/google/dopamine) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 1.3K \u00b7 \ud83d\udccb 170 - 50% open \u00b7 \u23f1\ufe0f 20.09.2022):\n\n\t```\n\tgit clone https://github.com/google/dopamine\n\t```\n- [PyPi](https://pypi.org/project/dopamine-rl) (\ud83d\udce5 32K / month \u00b7 \ud83d\udce6 37 \u00b7 \u23f1\ufe0f 20.05.2022):\n\t```\n\tpip install dopamine-rl\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/AI4Finance-Foundation/FinRL\">FinRL</a></b> (\ud83e\udd4729 \u00b7  \u2b50 6.3K) - FinRL: Financial Reinforcement Learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/AI4Finance-Foundation/FinRL) (\ud83d\udc68\u200d\ud83d\udcbb 79 \u00b7 \ud83d\udd00 1.5K \u00b7 \ud83d\udce6 17 \u00b7 \ud83d\udccb 470 - 17% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/AI4Finance-Foundation/FinRL\n\t```\n- [PyPi](https://pypi.org/project/finrl) (\ud83d\udce5 420 / month \u00b7 \u23f1\ufe0f 08.01.2022):\n\t```\n\tpip install finrl\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deepmind/acme\">Acme</a></b> (\ud83e\udd4729 \u00b7  \u2b50 2.9K) - A library of reinforcement learning components and agents. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/deepmind/acme) (\ud83d\udc68\u200d\ud83d\udcbb 80 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udce6 110 \u00b7 \ud83d\udccb 230 - 16% open \u00b7 \u23f1\ufe0f 10.11.2022):\n\n\t```\n\tgit clone https://github.com/deepmind/acme\n\t```\n- [PyPi](https://pypi.org/project/dm-acme) (\ud83d\udce5 3.5K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 10.02.2022):\n\t```\n\tpip install dm-acme\n\t```\n- [Conda](https://anaconda.org/conda-forge/dm-acme) (\ud83d\udce5 4.9K \u00b7 \u23f1\ufe0f 09.12.2021):\n\t```\n\tconda install -c conda-forge dm-acme\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorlayer/TensorLayer\">TensorLayer</a></b> (\ud83e\udd4827 \u00b7  \u2b50 7.1K \u00b7 \ud83d\udca4) - Deep Learning and Reinforcement Learning Library for.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorlayer/TensorLayer) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 1.6K \u00b7 \ud83d\udce5 1.4K \u00b7 \ud83d\udccb 470 - 6% open \u00b7 \u23f1\ufe0f 23.04.2022):\n\n\t```\n\tgit clone https://github.com/tensorlayer/tensorlayer\n\t```\n- [PyPi](https://pypi.org/project/tensorlayer) (\ud83d\udce5 2.1K / month \u00b7 \ud83d\udce6 40 \u00b7 \u23f1\ufe0f 15.02.2022):\n\t```\n\tpip install tensorlayer\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Farama-Foundation/ViZDoom\">ViZDoom</a></b> (\ud83e\udd4827 \u00b7  \u2b50 1.4K) - Doom-based AI Research Platform for Reinforcement Learning from Raw.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/Farama-Foundation/ViZDoom) (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 340 \u00b7 \ud83d\udce5 12K \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 440 - 20% open \u00b7 \u23f1\ufe0f 03.11.2022):\n\n\t```\n\tgit clone https://github.com/mwydmuch/ViZDoom\n\t```\n- [PyPi](https://pypi.org/project/vizdoom) (\ud83d\udce5 920 / month \u00b7 \ud83d\udce6 14 \u00b7 \u23f1\ufe0f 18.04.2022):\n\t```\n\tpip install vizdoom\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PaddlePaddle/PARL\">PARL</a></b> (\ud83e\udd4926 \u00b7  \u2b50 2.8K) - A high-performance distributed training framework for Reinforcement.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/PaddlePaddle/PARL) (\ud83d\udc68\u200d\ud83d\udcbb 35 \u00b7 \ud83d\udd00 760 \u00b7 \ud83d\udce6 98 \u00b7 \ud83d\udccb 450 - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/PaddlePaddle/PARL\n\t```\n- [PyPi](https://pypi.org/project/parl) (\ud83d\udce5 620 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 13.05.2022):\n\t```\n\tpip install parl\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rlworkgroup/garage\">garage</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.6K) - A toolkit for reproducible reinforcement learning research. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/rlworkgroup/garage) (\ud83d\udc68\u200d\ud83d\udcbb 78 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udce6 58 \u00b7 \ud83d\udccb 1K - 20% open \u00b7 \u23f1\ufe0f 20.05.2022):\n\n\t```\n\tgit clone https://github.com/rlworkgroup/garage\n\t```\n- [PyPi](https://pypi.org/project/garage) (\ud83d\udce5 520 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 23.03.2021):\n\t```\n\tpip install garage\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/hill-a/stable-baselines\">Stable Baselines</a></b> (\ud83e\udd4924 \u00b7  \u2b50 3.7K) - A fork of OpenAI Baselines, implementations of reinforcement.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/hill-a/stable-baselines) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 700 \u00b7 \ud83d\udccb 940 - 12% open \u00b7 \u23f1\ufe0f 04.09.2022):\n\n\t```\n\tgit clone https://github.com/hill-a/stable-baselines\n\t```\n- [PyPi](https://pypi.org/project/stable-baselines) (\ud83d\udce5 7.4K / month \u00b7 \ud83d\udce6 34 \u00b7 \u23f1\ufe0f 06.04.2021):\n\t```\n\tpip install stable-baselines\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorforce/tensorforce\">TensorForce</a></b> (\ud83e\udd4923 \u00b7  \u2b50 3.2K \u00b7 \ud83d\udca4) - Tensorforce: a TensorFlow library for applied.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorforce/tensorforce) (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 520 \u00b7 \ud83d\udccb 650 - 4% open \u00b7 \u23f1\ufe0f 10.02.2022):\n\n\t```\n\tgit clone https://github.com/tensorforce/tensorforce\n\t```\n- [PyPi](https://pypi.org/project/tensorforce) (\ud83d\udce5 1K / month \u00b7 \u23f1\ufe0f 30.08.2021):\n\t```\n\tpip install tensorforce\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deepmind/rlax\">RLax</a></b> (\ud83e\udd4922 \u00b7  \u2b50 940) - A library of reinforcement learning building blocks in JAX. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/deepmind/rlax) (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 68 \u00b7 \ud83d\udce6 83 \u00b7 \ud83d\udccb 28 - 46% open \u00b7 \u23f1\ufe0f 02.11.2022):\n\n\t```\n\tgit clone https://github.com/deepmind/rlax\n\t```\n- [PyPi](https://pypi.org/project/rlax) (\ud83d\udce5 3.6K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 24.02.2022):\n\t```\n\tpip install rlax\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/ReAgent\">ReAgent</a></b> (\ud83e\udd4921 \u00b7  \u2b50 3.3K) - A platform for Reasoning systems (Reinforcement Learning,.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/ReAgent) (\ud83d\udc68\u200d\ud83d\udcbb 150 \u00b7 \ud83d\udd00 470 \u00b7 \ud83d\udccb 140 - 47% open \u00b7 \u23f1\ufe0f 15.11.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/ReAgent\n\t```\n- [PyPi](https://pypi.org/project/reagent) (\ud83d\udce5 16 / month \u00b7 \u23f1\ufe0f 27.05.2020):\n\t```\n\tpip install reagent\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/IntelLabs/coach\">Coach</a></b> (\ud83e\udd4921 \u00b7  \u2b50 2.2K) - Reinforcement Learning Coach by Intel AI Lab enables easy.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/IntelLabs/coach) (\ud83d\udc68\u200d\ud83d\udcbb 35 \u00b7 \ud83d\udd00 440 \u00b7 \ud83d\udccb 270 - 32% open \u00b7 \u23f1\ufe0f 08.11.2022):\n\n\t```\n\tgit clone https://github.com/IntelLabs/coach\n\t```\n- [PyPi](https://pypi.org/project/rl_coach) (\ud83d\udce5 190 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 10.10.2019):\n\t```\n\tpip install rl_coach\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pfnet/pfrl\">PFRL</a></b> (\ud83e\udd4920 \u00b7  \u2b50 940) - PFRL: a PyTorch-based deep reinforcement learning library. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/pfnet/pfrl) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 120 \u00b7 \ud83d\udce6 62 \u00b7 \ud83d\udccb 67 - 40% open \u00b7 \u23f1\ufe0f 21.09.2022):\n\n\t```\n\tgit clone https://github.com/pfnet/pfrl\n\t```\n- [PyPi](https://pypi.org/project/pfrl) (\ud83d\udce5 390 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 07.07.2021):\n\t```\n\tpip install pfrl\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google-research/rliable\">rliable</a></b> (\ud83e\udd4913 \u00b7  \u2b50 520) - [NeurIPS21 Outstanding Paper] Library for reliable evaluation on RL.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/google-research/rliable) (\ud83d\udc68\u200d\ud83d\udcbb 5 \u00b7 \ud83d\udd00 32 \u00b7 \ud83d\udce6 27 \u00b7 \u23f1\ufe0f 14.09.2022):\n\n\t```\n\tgit clone https://github.com/google-research/rliable\n\t```\n- [PyPi](https://pypi.org/project/rliable`):\n\t```\n\tpip install rliable`\n\t```\n</details>\n<details><summary>Show 7 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/openai/baselines\">baselines</a></b> (\ud83e\udd4729 \u00b7  \u2b50 13K \u00b7 \ud83d\udc80) - OpenAI Baselines: high-quality implementations of reinforcement.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/keras-rl/keras-rl\">keras-rl</a></b> (\ud83e\udd4828 \u00b7  \u2b50 5.3K \u00b7 \ud83d\udc80) - Deep Reinforcement Learning for Keras. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/chainer/chainerrl\">ChainerRL</a></b> (\ud83e\udd4923 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - ChainerRL is a deep reinforcement learning library built on top of.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/deepmind/trfl\">TRFL</a></b> (\ud83e\udd4922 \u00b7  \u2b50 3.1K \u00b7 \ud83d\udc80) - TensorFlow Reinforcement Learning. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/SerpentAI/SerpentAI\">SerpentAI</a></b> (\ud83e\udd4919 \u00b7  \u2b50 6.4K \u00b7 \ud83d\udc80) - Game Agent Framework. Helping you create AIs / Bots that learn to.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/deepmind/lab\">DeepMind Lab</a></b> (\ud83e\udd4917 \u00b7  \u2b50 6.8K) - A customisable 3D platform for agent-based AI research. <code>\u2757Unlicensed</code>\n- <b><a href=\"https://github.com/enlite-ai/maze\">Maze</a></b> (\ud83e\udd4915 \u00b7  \u2b50 220 \u00b7 \ud83d\udcc8) - Maze Applied Reinforcement Learning Framework. <code><a href=\"https://tldrlegal.com/search?q=Custom\">\u2757\ufe0fCustom</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Recommender Systems\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for building and evaluating recommendation systems._\n\n<details><summary><b><a href=\"https://github.com/microsoft/recommenders\">Recommenders</a></b> (\ud83e\udd4735 \u00b7  \u2b50 15K) - Best Practices on Recommendation Systems. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/microsoft/recommenders) (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 2.5K \u00b7 \ud83d\udce5 280 \u00b7 \ud83d\udce6 45 \u00b7 \ud83d\udccb 730 - 19% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/microsoft/recommenders\n\t```\n- [PyPi](https://pypi.org/project/recommenders) (\ud83d\udce5 34K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 01.04.2022):\n\t```\n\tpip install recommenders\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/recommenders\">TF Recommenders</a></b> (\ud83e\udd4731 \u00b7  \u2b50 1.5K) - TensorFlow Recommenders is a library for building.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/recommenders) (\ud83d\udc68\u200d\ud83d\udcbb 39 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 330 - 53% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/recommenders\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-recommenders) (\ud83d\udce5 680K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 23.08.2021):\n\t```\n\tpip install tensorflow-recommenders\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/NicolasHug/Surprise\">scikit-surprise</a></b> (\ud83e\udd4830 \u00b7  \u2b50 5.6K) - A Python scikit for building and analyzing recommender.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/NicolasHug/Surprise) (\ud83d\udc68\u200d\ud83d\udcbb 44 \u00b7 \ud83d\udd00 960 \u00b7 \ud83d\udccb 370 - 18% open \u00b7 \u23f1\ufe0f 31.10.2022):\n\n\t```\n\tgit clone https://github.com/NicolasHug/Surprise\n\t```\n- [PyPi](https://pypi.org/project/scikit-surprise) (\ud83d\udce5 120K / month \u00b7 \ud83d\udce6 49 \u00b7 \u23f1\ufe0f 19.07.2020):\n\t```\n\tpip install scikit-surprise\n\t```\n- [Conda](https://anaconda.org/conda-forge/scikit-surprise) (\ud83d\udce5 270K \u00b7 \u23f1\ufe0f 31.10.2022):\n\t```\n\tconda install -c conda-forge scikit-surprise\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/benfred/implicit\">implicit</a></b> (\ud83e\udd4830 \u00b7  \u2b50 3K) - Fast Python Collaborative Filtering for Implicit Feedback Datasets. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/benfred/implicit) (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 560 \u00b7 \ud83d\udce5 190 \u00b7 \ud83d\udce6 710 \u00b7 \ud83d\udccb 440 - 16% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/benfred/implicit\n\t```\n- [PyPi](https://pypi.org/project/implicit) (\ud83d\udce5 140K / month \u00b7 \ud83d\udce6 32 \u00b7 \u23f1\ufe0f 29.01.2022):\n\t```\n\tpip install implicit\n\t```\n- [Conda](https://anaconda.org/conda-forge/implicit) (\ud83d\udce5 430K \u00b7 \u23f1\ufe0f 29.01.2022):\n\t```\n\tconda install -c conda-forge implicit\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/lyst/lightfm\">lightfm</a></b> (\ud83e\udd4829 \u00b7  \u2b50 4.2K) - A Python implementation of LightFM, a hybrid recommendation algorithm. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/lyst/lightfm) (\ud83d\udc68\u200d\ud83d\udcbb 44 \u00b7 \ud83d\udd00 650 \u00b7 \ud83d\udce6 850 \u00b7 \ud83d\udccb 470 - 25% open \u00b7 \u23f1\ufe0f 19.07.2022):\n\n\t```\n\tgit clone https://github.com/lyst/lightfm\n\t```\n- [PyPi](https://pypi.org/project/lightfm) (\ud83d\udce5 410K / month \u00b7 \ud83d\udce6 45 \u00b7 \u23f1\ufe0f 27.11.2020):\n\t```\n\tpip install lightfm\n\t```\n- [Conda](https://anaconda.org/conda-forge/lightfm) (\ud83d\udce5 140K \u00b7 \u23f1\ufe0f 09.03.2022):\n\t```\n\tconda install -c conda-forge lightfm\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/ranking\">TF Ranking</a></b> (\ud83e\udd4829 \u00b7  \u2b50 2.6K) - Learning to Rank in TensorFlow. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/ranking) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 440 \u00b7 \ud83d\udccb 310 - 23% open \u00b7 \u23f1\ufe0f 26.10.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/ranking\n\t```\n- [PyPi](https://pypi.org/project/tensorflow_ranking) (\ud83d\udce5 96K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 16.11.2021):\n\t```\n\tpip install tensorflow_ranking\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/RUCAIBox/RecBole\">RecBole</a></b> (\ud83e\udd4828 \u00b7  \u2b50 2.3K) - A unified, comprehensive and efficient recommendation library. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/RUCAIBox/RecBole) (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 420 \u00b7 \ud83d\udccb 550 - 15% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/RUCAIBox/RecBole\n\t```\n- [PyPi](https://pypi.org/project/recbole) (\ud83d\udce5 2.4K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 25.02.2022):\n\t```\n\tpip install recbole\n\t```\n- [Conda](https://anaconda.org/aibox/recbole) (\ud83d\udce5 2.4K \u00b7 \u23f1\ufe0f 05.10.2022):\n\t```\n\tconda install -c aibox recbole\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/torchrec\">torchrec</a></b> (\ud83e\udd4924 \u00b7  \u2b50 1.2K) - Pytorch domain library for recommendation systems. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/pytorch/torchrec) (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udccb 120 - 59% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/torchrec\n\t```\n- [PyPi](https://pypi.org/project/torchrec-nightly-cpu) (\ud83d\udce5 310 / month \u00b7 \u23f1\ufe0f 12.05.2022):\n\t```\n\tpip install torchrec-nightly-cpu\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PreferredAI/cornac\">Cornac</a></b> (\ud83e\udd4923 \u00b7  \u2b50 660) - A Comparative Framework for Multimodal Recommender Systems. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/PreferredAI/cornac) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 110 - 7% open \u00b7 \u23f1\ufe0f 18.10.2022):\n\n\t```\n\tgit clone https://github.com/PreferredAI/cornac\n\t```\n- [PyPi](https://pypi.org/project/cornac) (\ud83d\udce5 41K / month \u00b7 \ud83d\udce6 15 \u00b7 \u23f1\ufe0f 19.02.2022):\n\t```\n\tpip install cornac\n\t```\n- [Conda](https://anaconda.org/conda-forge/cornac) (\ud83d\udce5 260K \u00b7 \u23f1\ufe0f 10.11.2022):\n\t```\n\tconda install -c conda-forge cornac\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/statisticianinstilettos/recmetrics\">recmetrics</a></b> (\ud83e\udd4918 \u00b7  \u2b50 440 \u00b7 \ud83d\udca4) - A library of metrics for evaluating recommender systems. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/statisticianinstilettos/recmetrics) (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 85 \u00b7 \ud83d\udce6 33 \u00b7 \ud83d\udccb 21 - 42% open \u00b7 \u23f1\ufe0f 17.04.2022):\n\n\t```\n\tgit clone https://github.com/statisticianinstilettos/recmetrics\n\t```\n- [PyPi](https://pypi.org/project/recmetrics) (\ud83d\udce5 4.4K / month \u00b7 \u23f1\ufe0f 26.04.2022):\n\t```\n\tpip install recmetrics\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/caserec/CaseRecommender\">Case Recommender</a></b> (\ud83e\udd4917 \u00b7  \u2b50 430 \u00b7 \ud83d\udca4) - Case Recommender: A Flexible and Extensible Python.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/caserec/CaseRecommender) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 80 \u00b7 \ud83d\udce6 10 \u00b7 \ud83d\udccb 27 - 25% open \u00b7 \u23f1\ufe0f 25.11.2021):\n\n\t```\n\tgit clone https://github.com/caserec/CaseRecommender\n\t```\n- [PyPi](https://pypi.org/project/caserecommender) (\ud83d\udce5 86 / month \u00b7 \u23f1\ufe0f 25.11.2021):\n\t```\n\tpip install caserecommender\n\t```\n</details>\n<details><summary>Show 6 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/jfkirk/tensorrec\">tensorrec</a></b> (\ud83e\udd4924 \u00b7  \u2b50 1.2K \u00b7 \ud83d\udc80) - A TensorFlow recommendation algorithm and framework in.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/ibayer/fastFM\">fastFM</a></b> (\ud83e\udd4921 \u00b7  \u2b50 1K \u00b7 \ud83d\udc80) - fastFM: A Library for Factorization Machines. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/lenskit/lkpy\">lkpy</a></b> (\ud83e\udd4919 \u00b7  \u2b50 220) - Python recommendation toolkit. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/maciejkula/spotlight\">Spotlight</a></b> (\ud83e\udd4918 \u00b7  \u2b50 2.8K \u00b7 \ud83d\udc80) - Deep recommender models using PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/ShopRunner/collie\">Collie</a></b> (\ud83e\udd4917 \u00b7  \u2b50 94) - A library for preparing, training, and evaluating scalable deep.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/ylongqi/openrec\">OpenRec</a></b> (\ud83e\udd4916 \u00b7  \u2b50 400 \u00b7 \ud83d\udc80) - OpenRec is an open-source and modular library for neural network-.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n</details>\n<br>\n\n## Privacy Machine Learning\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for encrypted and privacy-preserving machine learning using methods like federated learning & differential privacy._\n\n<details><summary><b><a href=\"https://github.com/OpenMined/PySyft\">PySyft</a></b> (\ud83e\udd4736 \u00b7  \u2b50 8.4K) - Data science on data without acquiring a copy. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/OpenMined/PySyft) (\ud83d\udc68\u200d\ud83d\udcbb 480 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udccb 3.4K - 5% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/OpenMined/PySyft\n\t```\n- [PyPi](https://pypi.org/project/syft) (\ud83d\udce5 4.7K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 29.06.2022):\n\t```\n\tpip install syft\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/opacus\">Opacus</a></b> (\ud83e\udd4829 \u00b7  \u2b50 1.3K) - Training PyTorch models with differential privacy. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pytorch/opacus) (\ud83d\udc68\u200d\ud83d\udcbb 65 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce5 51 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 220 - 22% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/opacus\n\t```\n- [PyPi](https://pypi.org/project/opacus) (\ud83d\udce5 13K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 06.05.2022):\n\t```\n\tpip install opacus\n\t```\n- [Conda](https://anaconda.org/conda-forge/opacus) (\ud83d\udce5 5.7K \u00b7 \u23f1\ufe0f 09.09.2022):\n\t```\n\tconda install -c conda-forge opacus\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/FederatedAI/FATE\">FATE</a></b> (\ud83e\udd4826 \u00b7  \u2b50 4.7K) - An Industrial Grade Federated Learning Framework. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/FederatedAI/FATE) (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udccb 1.4K - 38% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/FederatedAI/FATE\n\t```\n- [PyPi](https://pypi.org/project/ETAF) (\ud83d\udce5 11 / month \u00b7 \u23f1\ufe0f 06.05.2020):\n\t```\n\tpip install ETAF\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/privacy\">TensorFlow Privacy</a></b> (\ud83e\udd4826 \u00b7  \u2b50 1.7K) - Library for training machine learning models with.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/privacy) (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 380 \u00b7 \ud83d\udce5 88 \u00b7 \ud83d\udccb 180 - 50% open \u00b7 \u23f1\ufe0f 08.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/privacy\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-privacy) (\ud83d\udce5 39K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 22.02.2022):\n\t```\n\tpip install tensorflow-privacy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tf-encrypted/tf-encrypted\">TFEncrypted</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.1K) - A Framework for Encrypted Machine Learning in TensorFlow. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tf-encrypted/tf-encrypted) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 63 \u00b7 \ud83d\udccb 430 - 33% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/tf-encrypted/tf-encrypted\n\t```\n- [PyPi](https://pypi.org/project/tf-encrypted) (\ud83d\udce5 880 / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 07.03.2022):\n\t```\n\tpip install tf-encrypted\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/CrypTen\">CrypTen</a></b> (\ud83e\udd4924 \u00b7  \u2b50 1.2K) - A framework for Privacy Preserving Machine Learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/CrypTen) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce6 22 \u00b7 \ud83d\udccb 190 - 17% open \u00b7 \u23f1\ufe0f 10.06.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/CrypTen\n\t```\n- [PyPi](https://pypi.org/project/crypten) (\ud83d\udce5 190 / month \u00b7 \u23f1\ufe0f 09.09.2021):\n\t```\n\tpip install crypten\n\t```\n</details>\n<details><summary>Show 1 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/OpenMined/PipelineDP\">PipelineDP</a></b> (\ud83e\udd4921 \u00b7  \u2b50 240) - PipelineDP is a Python framework for applying differentially.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n</details>\n<br>\n\n## Workflow & Experiment Tracking\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries to organize, track, and visualize machine learning experiments._\n\n<details><summary><b><a href=\"https://github.com/tensorflow/tensorboard\">Tensorboard</a></b> (\ud83e\udd4743 \u00b7  \u2b50 6K) - TensorFlows Visualization Toolkit. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/tensorboard) (\ud83d\udc68\u200d\ud83d\udcbb 290 \u00b7 \ud83d\udd00 1.6K \u00b7 \ud83d\udce6 130K \u00b7 \ud83d\udccb 1.8K - 34% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/tensorboard\n\t```\n- [PyPi](https://pypi.org/project/tensorboard) (\ud83d\udce5 18M / month \u00b7 \ud83d\udce6 2.4K \u00b7 \u23f1\ufe0f 08.06.2022):\n\t```\n\tpip install tensorboard\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensorboard) (\ud83d\udce5 3.5M \u00b7 \u23f1\ufe0f 09.11.2022):\n\t```\n\tconda install -c conda-forge tensorboard\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/mlflow/mlflow\">mlflow</a></b> (\ud83e\udd4741 \u00b7  \u2b50 13K) - Open source platform for the machine learning lifecycle. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/mlflow/mlflow) (\ud83d\udc68\u200d\ud83d\udcbb 510 \u00b7 \ud83d\udd00 3K \u00b7 \ud83d\udccb 2.7K - 35% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/mlflow/mlflow\n\t```\n- [PyPi](https://pypi.org/project/mlflow) (\ud83d\udce5 11M / month \u00b7 \ud83d\udce6 330 \u00b7 \u23f1\ufe0f 29.06.2022):\n\t```\n\tpip install mlflow\n\t```\n- [Conda](https://anaconda.org/conda-forge/mlflow) (\ud83d\udce5 1.1M \u00b7 \u23f1\ufe0f 16.11.2022):\n\t```\n\tconda install -c conda-forge mlflow\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/iterative/dvc\">DVC</a></b> (\ud83e\udd4741 \u00b7  \u2b50 11K) - Data Version Control | Git for Data & Models | ML Experiments Management. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/iterative/dvc) (\ud83d\udc68\u200d\ud83d\udcbb 280 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udce5 110K \u00b7 \ud83d\udce6 5.4K \u00b7 \ud83d\udccb 4K - 16% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/iterative/dvc\n\t```\n- [PyPi](https://pypi.org/project/dvc) (\ud83d\udce5 1.4M / month \u00b7 \ud83d\udce6 47 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install dvc\n\t```\n- [Conda](https://anaconda.org/conda-forge/dvc) (\ud83d\udce5 1.3M \u00b7 \u23f1\ufe0f 15.11.2022):\n\t```\n\tconda install -c conda-forge dvc\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/wandb/wandb\">wandb client</a></b> (\ud83e\udd4737 \u00b7  \u2b50 5K) - A tool for visualizing and tracking your machine learning.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/wandb/wandb) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 380 \u00b7 \ud83d\udce6 13K \u00b7 \ud83d\udccb 2.1K - 26% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/wandb/client\n\t```\n- [PyPi](https://pypi.org/project/wandb) (\ud83d\udce5 1.5M / month \u00b7 \ud83d\udce6 270 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install wandb\n\t```\n- [Conda](https://anaconda.org/conda-forge/wandb) (\ud83d\udce5 130K \u00b7 \u23f1\ufe0f 04.11.2022):\n\t```\n\tconda install -c conda-forge wandb\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/aws/sagemaker-python-sdk\">SageMaker SDK</a></b> (\ud83e\udd4737 \u00b7  \u2b50 1.7K) - A library for training and deploying machine learning.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1X\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/aws/sagemaker-python-sdk) (\ud83d\udc68\u200d\ud83d\udcbb 290 \u00b7 \ud83d\udd00 880 \u00b7 \ud83d\udce6 1.8K \u00b7 \ud83d\udccb 1.2K - 37% open \u00b7 \u23f1\ufe0f 15.11.2022):\n\n\t```\n\tgit clone https://github.com/aws/sagemaker-python-sdk\n\t```\n- [PyPi](https://pypi.org/project/sagemaker) (\ud83d\udce5 9.7M / month \u00b7 \ud83d\udce6 52 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install sagemaker\n\t```\n- [Conda](https://anaconda.org/conda-forge/sagemaker-python-sdk) (\ud83d\udce5 460K \u00b7 \u23f1\ufe0f 03.11.2022):\n\t```\n\tconda install -c conda-forge sagemaker-python-sdk\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pycaret/pycaret\">PyCaret</a></b> (\ud83e\udd4836 \u00b7  \u2b50 6.6K) - An open-source, low-code machine learning library in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/pycaret/pycaret) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 1.5K \u00b7 \ud83d\udce5 620 \u00b7 \ud83d\udce6 2.8K \u00b7 \ud83d\udccb 1.9K - 16% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/pycaret/pycaret\n\t```\n- [PyPi](https://pypi.org/project/pycaret) (\ud83d\udce5 980K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 06.06.2022):\n\t```\n\tpip install pycaret\n\t```\n- [Conda](https://anaconda.org/conda-forge/pycaret) (\ud83d\udce5 23K \u00b7 \u23f1\ufe0f 18.04.2022):\n\t```\n\tconda install -c conda-forge pycaret\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Azure/MachineLearningNotebooks\">AzureML SDK</a></b> (\ud83e\udd4835 \u00b7  \u2b50 3.5K) - Python notebooks with ML and deep learning examples with Azure.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/Azure/MachineLearningNotebooks) (\ud83d\udc68\u200d\ud83d\udcbb 61 \u00b7 \ud83d\udd00 2.2K \u00b7 \ud83d\udce5 480 \u00b7 \ud83d\udccb 1.4K - 23% open \u00b7 \u23f1\ufe0f 08.11.2022):\n\n\t```\n\tgit clone https://github.com/Azure/MachineLearningNotebooks\n\t```\n- [PyPi](https://pypi.org/project/azureml-sdk) (\ud83d\udce5 2.3M / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 27.06.2022):\n\t```\n\tpip install azureml-sdk\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/lanpa/tensorboardX\">tensorboardX</a></b> (\ud83e\udd4834 \u00b7  \u2b50 7.5K) - tensorboard for pytorch (and chainer, mxnet, numpy, ...). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/lanpa/tensorboardX) (\ud83d\udc68\u200d\ud83d\udcbb 73 \u00b7 \ud83d\udd00 870 \u00b7 \ud83d\udce5 350 \u00b7 \ud83d\udce6 24K \u00b7 \ud83d\udccb 440 - 16% open \u00b7 \u23f1\ufe0f 04.09.2022):\n\n\t```\n\tgit clone https://github.com/lanpa/tensorboardX\n\t```\n- [PyPi](https://pypi.org/project/tensorboardX) (\ud83d\udce5 1.9M / month \u00b7 \ud83d\udce6 890 \u00b7 \u23f1\ufe0f 05.06.2022):\n\t```\n\tpip install tensorboardX\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensorboardx) (\ud83d\udce5 880K \u00b7 \u23f1\ufe0f 07.06.2022):\n\t```\n\tconda install -c conda-forge tensorboardx\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/allegroai/clearml\">ClearML</a></b> (\ud83e\udd4834 \u00b7  \u2b50 3.8K) - ClearML - Auto-Magical CI/CD to streamline your ML workflow... <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/allegroai/clearml) (\ud83d\udc68\u200d\ud83d\udcbb 58 \u00b7 \ud83d\udd00 500 \u00b7 \ud83d\udce5 570 \u00b7 \ud83d\udce6 340 \u00b7 \ud83d\udccb 670 - 45% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/allegroai/clearml\n\t```\n- [PyPi](https://pypi.org/project/clearml) (\ud83d\udce5 470K / month \u00b7 \ud83d\udce6 8 \u00b7 \u23f1\ufe0f 04.07.2022):\n\t```\n\tpip install clearml\n\t```\n- [Docker Hub](https://hub.docker.com/r/allegroai/trains) (\ud83d\udce5 30K \u00b7 \u23f1\ufe0f 05.10.2020):\n\t```\n\tdocker pull allegroai/trains\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/snakemake/snakemake\">snakemake</a></b> (\ud83e\udd4834 \u00b7  \u2b50 1.5K) - This is the development home of the workflow management system.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/snakemake/snakemake) (\ud83d\udc68\u200d\ud83d\udcbb 270 \u00b7 \ud83d\udd00 380 \u00b7 \ud83d\udce6 1.3K \u00b7 \ud83d\udccb 1.2K - 60% open \u00b7 \u23f1\ufe0f 10.11.2022):\n\n\t```\n\tgit clone https://github.com/snakemake/snakemake\n\t```\n- [PyPi](https://pypi.org/project/snakemake) (\ud83d\udce5 66K / month \u00b7 \ud83d\udce6 210 \u00b7 \u23f1\ufe0f 30.06.2022):\n\t```\n\tpip install snakemake\n\t```\n- [Conda](https://anaconda.org/bioconda/snakemake) (\ud83d\udce5 590K \u00b7 \u23f1\ufe0f 12.11.2022):\n\t```\n\tconda install -c bioconda snakemake\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Netflix/metaflow\">Metaflow</a></b> (\ud83e\udd4832 \u00b7  \u2b50 6.2K) - Build and manage real-life data science projects with ease!. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Netflix/metaflow) (\ud83d\udc68\u200d\ud83d\udcbb 59 \u00b7 \ud83d\udd00 560 \u00b7 \ud83d\udce6 340 \u00b7 \ud83d\udccb 490 - 48% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/Netflix/metaflow\n\t```\n- [PyPi](https://pypi.org/project/metaflow) (\ud83d\udce5 61K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 17.06.2022):\n\t```\n\tpip install metaflow\n\t```\n- [Conda](https://anaconda.org/conda-forge/metaflow) (\ud83d\udce5 85K \u00b7 \u23f1\ufe0f 04.11.2022):\n\t```\n\tconda install -c conda-forge metaflow\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PaddlePaddle/VisualDL\">VisualDL</a></b> (\ud83e\udd4832 \u00b7  \u2b50 4.5K) - Deep Learning Visualization Toolkit. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/PaddlePaddle/VisualDL) (\ud83d\udc68\u200d\ud83d\udcbb 32 \u00b7 \ud83d\udd00 600 \u00b7 \ud83d\udce5 240 \u00b7 \ud83d\udce6 1.5K \u00b7 \ud83d\udccb 440 - 22% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/PaddlePaddle/VisualDL\n\t```\n- [PyPi](https://pypi.org/project/visualdl) (\ud83d\udce5 71K / month \u00b7 \ud83d\udce6 25 \u00b7 \u23f1\ufe0f 01.07.2022):\n\t```\n\tpip install visualdl\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/aimhubio/aim\">aim</a></b> (\ud83e\udd4831 \u00b7  \u2b50 2.9K) - Aim easy-to-use and performant open-source ML experiment tracker. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/aimhubio/aim) (\ud83d\udc68\u200d\ud83d\udcbb 47 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 730 - 24% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/aimhubio/aim\n\t```\n- [PyPi](https://pypi.org/project/aim) (\ud83d\udce5 26K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 07.07.2022):\n\t```\n\tpip install aim\n\t```\n- [Conda](https://anaconda.org/conda-forge/aim) (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 15.10.2021):\n\t```\n\tconda install -c conda-forge aim\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/IDSIA/sacred\">sacred</a></b> (\ud83e\udd4830 \u00b7  \u2b50 4K) - Sacred is a tool to help you configure, organize, log and reproduce.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/IDSIA/sacred) (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 350 \u00b7 \ud83d\udce6 1.7K \u00b7 \ud83d\udccb 540 - 16% open \u00b7 \u23f1\ufe0f 17.10.2022):\n\n\t```\n\tgit clone https://github.com/IDSIA/sacred\n\t```\n- [PyPi](https://pypi.org/project/sacred) (\ud83d\udce5 53K / month \u00b7 \ud83d\udce6 100 \u00b7 \u23f1\ufe0f 14.12.2020):\n\t```\n\tpip install sacred\n\t```\n- [Conda](https://anaconda.org/conda-forge/sacred) (\ud83d\udce5 1.9K \u00b7 \u23f1\ufe0f 14.11.2021):\n\t```\n\tconda install -c conda-forge sacred\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/ml-metadata\">ml-metadata</a></b> (\ud83e\udd4829 \u00b7  \u2b50 500) - For recording and retrieving metadata associated with ML.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/google/ml-metadata) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce5 1.7K \u00b7 \ud83d\udce6 260 \u00b7 \ud83d\udccb 95 - 27% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/google/ml-metadata\n\t```\n- [PyPi](https://pypi.org/project/ml-metadata) (\ud83d\udce5 680K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 21.06.2022):\n\t```\n\tpip install ml-metadata\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/neptune-ai/neptune-client\">Neptune.ai</a></b> (\ud83e\udd4829 \u00b7  \u2b50 350) - Experiment tracking tool and model registry. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/neptune-ai/neptune-client) (\ud83d\udc68\u200d\ud83d\udcbb 38 \u00b7 \ud83d\udd00 35 \u00b7 \ud83d\udccb 180 - 13% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/neptune-ai/neptune-client\n\t```\n- [PyPi](https://pypi.org/project/neptune-client) (\ud83d\udce5 530K / month \u00b7 \ud83d\udce6 28 \u00b7 \u23f1\ufe0f 01.07.2022):\n\t```\n\tpip install neptune-client\n\t```\n- [Conda](https://anaconda.org/conda-forge/neptune-client) (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 23.11.2022):\n\t```\n\tconda install -c conda-forge neptune-client\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/catalyst-team/catalyst\">Catalyst</a></b> (\ud83e\udd4928 \u00b7  \u2b50 3K \u00b7 \ud83d\udca4) - Accelerated deep learning R&D. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/catalyst-team/catalyst) (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udce6 650 \u00b7 \ud83d\udccb 340 - 1% open \u00b7 \u23f1\ufe0f 29.04.2022):\n\n\t```\n\tgit clone https://github.com/catalyst-team/catalyst\n\t```\n- [PyPi](https://pypi.org/project/catalyst) (\ud83d\udce5 45K / month \u00b7 \ud83d\udce6 29 \u00b7 \u23f1\ufe0f 29.04.2022):\n\t```\n\tpip install catalyst\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/guildai/guildai\">Guild AI</a></b> (\ud83e\udd4927 \u00b7  \u2b50 750) - Experiment tracking, ML developer tools. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/guildai/guildai) (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 68 \u00b7 \ud83d\udce5 7 \u00b7 \ud83d\udce6 61 \u00b7 \ud83d\udccb 390 - 45% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/guildai/guildai\n\t```\n- [PyPi](https://pypi.org/project/guildai) (\ud83d\udce5 3.1K / month \u00b7 \u23f1\ufe0f 11.05.2022):\n\t```\n\tpip install guildai\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/tnt\">TNT</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.4K) - A lightweight library for PyTorch training tools and utilities. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pytorch/tnt) (\ud83d\udc68\u200d\ud83d\udcbb 74 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udccb 62 - 4% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/tnt\n\t```\n- [PyPi](https://pypi.org/project/torchnet) (\ud83d\udce5 6.3K / month \u00b7 \ud83d\udce6 37 \u00b7 \u23f1\ufe0f 29.07.2018):\n\t```\n\tpip install torchnet\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/stared/livelossplot\">livelossplot</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.2K \u00b7 \ud83d\udca4) - Live training loss plot in Jupyter Notebook for Keras,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/stared/livelossplot) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce6 890 \u00b7 \ud83d\udccb 76 - 7% open \u00b7 \u23f1\ufe0f 04.04.2022):\n\n\t```\n\tgit clone https://github.com/stared/livelossplot\n\t```\n- [PyPi](https://pypi.org/project/livelossplot) (\ud83d\udce5 46K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 04.04.2022):\n\t```\n\tpip install livelossplot\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/labmlai/labml\">Labml</a></b> (\ud83e\udd4924 \u00b7  \u2b50 1.2K) - Monitor deep learning model training and hardware usage from your mobile.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/labmlai/labml) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 87 \u00b7 \ud83d\udce6 57 \u00b7 \ud83d\udccb 35 - 51% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/labmlai/labml\n\t```\n- [PyPi](https://pypi.org/project/labml) (\ud83d\udce5 2K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install labml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/instacart/lore\">lore</a></b> (\ud83e\udd4920 \u00b7  \u2b50 1.5K) - Lore makes machine learning approachable for Software Engineers and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/instacart/lore) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 20 \u00b7 \ud83d\udccb 45 - 57% open \u00b7 \u23f1\ufe0f 27.09.2022):\n\n\t```\n\tgit clone https://github.com/instacart/lore\n\t```\n- [PyPi](https://pypi.org/project/lore) (\ud83d\udce5 330 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 02.02.2022):\n\t```\n\tpip install lore\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/replicate/keepsake\">keepsake</a></b> (\ud83e\udd4918 \u00b7  \u2b50 1.6K) - Version control for machine learning. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/replicate/keepsake) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 64 \u00b7 \ud83d\udccb 190 - 65% open \u00b7 \u23f1\ufe0f 24.05.2022):\n\n\t```\n\tgit clone https://github.com/replicate/keepsake\n\t```\n- [PyPi](https://pypi.org/project/keepsake) (\ud83d\udce5 270 / month \u00b7 \u23f1\ufe0f 11.03.2021):\n\t```\n\tpip install keepsake\n\t```\n</details>\n<details><summary>Show 16 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/Kaggle/kaggle-api\">kaggle</a></b> (\ud83e\udd4829 \u00b7  \u2b50 5K \u00b7 \ud83d\udc80) - Official Kaggle API. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/huggingface/knockknock\">knockknock</a></b> (\ud83e\udd4925 \u00b7  \u2b50 2.5K \u00b7 \ud83d\udc80) - Knock Knock: Get notified when your training ends with only two.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/EducationalTestingService/skll\">SKLL</a></b> (\ud83e\udd4925 \u00b7  \u2b50 530) - SciKit-Learn Laboratory (SKLL) makes it easy to run machine.. <code><a href=\"https://tldrlegal.com/search?q=BSD-1-Clause\">\u2757\ufe0fBSD-1-Clause</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/waleedka/hiddenlayer\">hiddenlayer</a></b> (\ud83e\udd4921 \u00b7  \u2b50 1.7K \u00b7 \ud83d\udc80) - Neural network graphs and training metrics for.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/microsoft/tensorwatch\">TensorWatch</a></b> (\ud83e\udd4920 \u00b7  \u2b50 3.3K \u00b7 \ud83d\udc80) - Debugging, monitoring and visualization for Python Machine.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/TeamHG-Memex/tensorboard_logger\">TensorBoard Logger</a></b> (\ud83e\udd4920 \u00b7  \u2b50 620 \u00b7 \ud83d\udc80) - Log TensorBoard events without touching TensorFlow. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/studioml/studio\">Studio.ml</a></b> (\ud83e\udd4920 \u00b7  \u2b50 380 \u00b7 \ud83d\udc80) - Studio: Simplify and expedite model building process. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/MrPowers/quinn\">quinn</a></b> (\ud83e\udd4920 \u00b7  \u2b50 370 \u00b7 \ud83d\udc80) - pyspark methods to enhance developer productivity. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/m3dev/gokart\">gokart</a></b> (\ud83e\udd4920 \u00b7  \u2b50 270) - Gokart solves reproducibility, task dependencies, constraints of good code,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/awslabs/mxboard\">MXBoard</a></b> (\ud83e\udd4919 \u00b7  \u2b50 330 \u00b7 \ud83d\udc80) - Logging MXNet data for visualization in TensorBoard. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1X\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/datmo/datmo\">datmo</a></b> (\ud83e\udd4917 \u00b7  \u2b50 340 \u00b7 \ud83d\udc80) - Open source production model management tool for data scientists. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/gradsflow/chitra\">chitra</a></b> (\ud83e\udd4916 \u00b7  \u2b50 210) - A multi-functional library for full-stack Deep Learning. Simplifies.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/minerva-ml/steppy\">steppy</a></b> (\ud83e\udd4915 \u00b7  \u2b50 130 \u00b7 \ud83d\udc80) - Lightweight, Python library for fast and reproducible experimentation. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/google/caliban\">caliban</a></b> (\ud83e\udd4914 \u00b7  \u2b50 440 \u00b7 \ud83d\udc80) - Research workflows made easy, locally and in the Cloud. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/ModelChimp/modelchimp\">ModelChimp</a></b> (\ud83e\udd4913 \u00b7  \u2b50 120 \u00b7 \ud83d\udc80) - Experiment tracking for machine and deep learning projects. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code>\n- <b><a href=\"https://github.com/jrieke/traintool\">traintool</a></b> (\ud83e\udd498 \u00b7  \u2b50 11 \u00b7 \ud83d\udc80) - Train off-the-shelf machine learning models in one.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Model Serialization & Deployment\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries to serialize models to files, convert between a variety of model formats, and optimize models for deployment._\n\n<details><summary><b><a href=\"https://github.com/onnx/onnx\">onnx</a></b> (\ud83e\udd4741 \u00b7  \u2b50 14K) - Open standard for machine learning interoperability. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/onnx/onnx) (\ud83d\udc68\u200d\ud83d\udcbb 260 \u00b7 \ud83d\udd00 3.1K \u00b7 \ud83d\udce5 18K \u00b7 \ud83d\udce6 9.4K \u00b7 \ud83d\udccb 2.2K - 15% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/onnx/onnx\n\t```\n- [PyPi](https://pypi.org/project/onnx) (\ud83d\udce5 2M / month \u00b7 \ud83d\udce6 390 \u00b7 \u23f1\ufe0f 18.06.2022):\n\t```\n\tpip install onnx\n\t```\n- [Conda](https://anaconda.org/conda-forge/onnx) (\ud83d\udce5 580K \u00b7 \u23f1\ufe0f 28.10.2022):\n\t```\n\tconda install -c conda-forge onnx\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/apple/coremltools\">Core ML Tools</a></b> (\ud83e\udd4731 \u00b7  \u2b50 3K) - Core ML tools contain supporting tools for Core ML model.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/apple/coremltools) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 470 \u00b7 \ud83d\udce5 4.6K \u00b7 \ud83d\udce6 1.1K \u00b7 \ud83d\udccb 1K - 16% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/apple/coremltools\n\t```\n- [PyPi](https://pypi.org/project/coremltools) (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 150 \u00b7 \u23f1\ufe0f 07.06.2022):\n\t```\n\tpip install coremltools\n\t```\n- [Conda](https://anaconda.org/conda-forge/coremltools) (\ud83d\udce5 40K \u00b7 \u23f1\ufe0f 15.10.2021):\n\t```\n\tconda install -c conda-forge coremltools\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/huggingface/huggingface_hub\">huggingface_hub</a></b> (\ud83e\udd4731 \u00b7  \u2b50 590) - All the open source things related to the Hugging Face Hub. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/huggingface/huggingface_hub) (\ud83d\udc68\u200d\ud83d\udcbb 76 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 360 - 23% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/huggingface/huggingface_hub\n\t```\n- [PyPi](https://pypi.org/project/huggingface_hub) (\ud83d\udce5 6.9M / month \u00b7 \ud83d\udce6 87 \u00b7 \u23f1\ufe0f 21.06.2022):\n\t```\n\tpip install huggingface_hub\n\t```\n- [Conda](https://anaconda.org/conda-forge/huggingface_hub) (\ud83d\udce5 540K \u00b7 \u23f1\ufe0f 16.11.2022):\n\t```\n\tconda install -c conda-forge huggingface_hub\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/openai/triton\">triton</a></b> (\ud83e\udd4830 \u00b7  \u2b50 4.3K) - Development repository for the Triton language and compiler. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/openai/triton) (\ud83d\udc68\u200d\ud83d\udcbb 65 \u00b7 \ud83d\udd00 360 \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 330 - 40% open \u00b7 \u23f1\ufe0f 20.11.2022):\n\n\t```\n\tgit clone https://github.com/openai/triton\n\t```\n- [PyPi](https://pypi.org/project/triton) (\ud83d\udce5 190K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 04.07.2022):\n\t```\n\tpip install triton\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/bentoml/BentoML\">BentoML</a></b> (\ud83e\udd4829 \u00b7  \u2b50 4.3K) - Unified Model Serving Framework. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/bentoml/BentoML) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 480 \u00b7 \ud83d\udce5 1.6K \u00b7 \ud83d\udccb 760 - 13% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/bentoml/BentoML\n\t```\n- [PyPi](https://pypi.org/project/bentoml) (\ud83d\udce5 36K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 01.07.2022):\n\t```\n\tpip install bentoml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/microsoft/hummingbird\">Hummingbird</a></b> (\ud83e\udd4829 \u00b7  \u2b50 3K) - Hummingbird compiles trained ML models into tensor computation for.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/microsoft/hummingbird) (\ud83d\udc68\u200d\ud83d\udcbb 35 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce5 190 \u00b7 \ud83d\udce6 46 \u00b7 \ud83d\udccb 260 - 17% open \u00b7 \u23f1\ufe0f 10.11.2022):\n\n\t```\n\tgit clone https://github.com/microsoft/hummingbird\n\t```\n- [PyPi](https://pypi.org/project/hummingbird-ml) (\ud83d\udce5 36K / month \u00b7 \u23f1\ufe0f 25.04.2022):\n\t```\n\tpip install hummingbird-ml\n\t```\n- [Conda](https://anaconda.org/conda-forge/hummingbird-ml) (\ud83d\udce5 18K \u00b7 \u23f1\ufe0f 11.11.2022):\n\t```\n\tconda install -c conda-forge hummingbird-ml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/serve\">TorchServe</a></b> (\ud83e\udd4829 \u00b7  \u2b50 3K) - Serve, optimize and scale PyTorch models in production. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pytorch/serve) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 650 \u00b7 \ud83d\udce5 2.3K \u00b7 \ud83d\udccb 1.1K - 17% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/serve\n\t```\n- [PyPi](https://pypi.org/project/torchserve) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 13.05.2022):\n\t```\n\tpip install torchserve\n\t```\n- [Conda](https://anaconda.org/pytorch/torchserve) (\ud83d\udce5 48K \u00b7 \u23f1\ufe0f 14.11.2022):\n\t```\n\tconda install -c pytorch torchserve\n\t```\n- [Docker Hub](https://hub.docker.com/r/pytorch/torchserve) (\ud83d\udce5 1.1M \u00b7 \u2b50 16 \u00b7 \u23f1\ufe0f 14.11.2022):\n\t```\n\tdocker pull pytorch/torchserve\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/cortexlabs/cortex\">cortex</a></b> (\ud83e\udd4825 \u00b7  \u2b50 7.8K) - Production infrastructure for machine learning at scale. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/cortexlabs/cortex) (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 600 \u00b7 \ud83d\udccb 1.1K - 10% open \u00b7 \u23f1\ufe0f 23.09.2022):\n\n\t```\n\tgit clone https://github.com/cortexlabs/cortex\n\t```\n- [PyPi](https://pypi.org/project/cortex) (\ud83d\udce5 1.7K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 10.01.2022):\n\t```\n\tpip install cortex\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/microsoft/MMdnn\">mmdnn</a></b> (\ud83e\udd4825 \u00b7  \u2b50 5.6K) - MMdnn is a set of tools to help users inter-operate among different deep.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/microsoft/MMdnn) (\ud83d\udc68\u200d\ud83d\udcbb 86 \u00b7 \ud83d\udd00 970 \u00b7 \ud83d\udce5 3.6K \u00b7 \ud83d\udce6 94 \u00b7 \ud83d\udccb 620 - 53% open \u00b7 \u23f1\ufe0f 22.09.2022):\n\n\t```\n\tgit clone https://github.com/Microsoft/MMdnn\n\t```\n- [PyPi](https://pypi.org/project/mmdnn) (\ud83d\udce5 430 / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 24.07.2020):\n\t```\n\tpip install mmdnn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/BayesWitnesses/m2cgen\">m2cgen</a></b> (\ud83e\udd4825 \u00b7  \u2b50 2.3K) - Transform ML models into a native code (Java, C, Python, Go, JavaScript,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/BayesWitnesses/m2cgen) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce5 42 \u00b7 \ud83d\udce6 76 \u00b7 \ud83d\udccb 100 - 30% open \u00b7 \u23f1\ufe0f 05.10.2022):\n\n\t```\n\tgit clone https://github.com/BayesWitnesses/m2cgen\n\t```\n- [PyPi](https://pypi.org/project/m2cgen) (\ud83d\udce5 58K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 26.04.2022):\n\t```\n\tpip install m2cgen\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/fastmachinelearning/hls4ml\">hls4ml</a></b> (\ud83e\udd4924 \u00b7  \u2b50 730) - Machine learning on FPGAs using HLS. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/fastmachinelearning/hls4ml) (\ud83d\udc68\u200d\ud83d\udcbb 47 \u00b7 \ud83d\udd00 270 \u00b7 \ud83d\udccb 340 - 42% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/fastmachinelearning/hls4ml\n\t```\n- [PyPi](https://pypi.org/project/hls4ml) (\ud83d\udce5 750 / month \u00b7 \u23f1\ufe0f 12.11.2021):\n\t```\n\tpip install hls4ml\n\t```\n- [Conda](https://anaconda.org/conda-forge/hls4ml) (\ud83d\udce5 4.6K \u00b7 \u23f1\ufe0f 12.11.2021):\n\t```\n\tconda install -c conda-forge hls4ml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nok/sklearn-porter\">sklearn-porter</a></b> (\ud83e\udd4923 \u00b7  \u2b50 1.2K) - Transpile trained scikit-learn estimators to C, Java,.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/nok/sklearn-porter) (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 45 \u00b7 \ud83d\udccb 76 - 55% open \u00b7 \u23f1\ufe0f 22.05.2022):\n\n\t```\n\tgit clone https://github.com/nok/sklearn-porter\n\t```\n- [PyPi](https://pypi.org/project/sklearn-porter) (\ud83d\udce5 370 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 18.12.2019):\n\t```\n\tpip install sklearn-porter\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nebuly-ai/nebullvm\">nebullvm</a></b> (\ud83e\udd4920 \u00b7  \u2b50 1.5K) - Accelerate AI models inference leveraging best-of-breed.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/nebuly-ai/nebullvm) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 68 \u00b7 \ud83d\udce6 4 \u00b7 \ud83d\udccb 75 - 38% open \u00b7 \u23f1\ufe0f 11.11.2022):\n\n\t```\n\tgit clone https://github.com/nebuly-ai/nebullvm\n\t```\n- [PyPi](https://pypi.org/project/nebullvm) (\ud83d\udce5 500 / month \u00b7 \u23f1\ufe0f 28.06.2022):\n\t```\n\tpip install nebullvm\n\t```\n</details>\n<details><summary>Show 7 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/larq/compute-engine\">Larq Compute Engine</a></b> (\ud83e\udd4921 \u00b7  \u2b50 210) - Highly optimized inference engine for Binarized.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/cog-imperial/OMLT\">OMLT</a></b> (\ud83e\udd4920 \u00b7  \u2b50 170) - Represent trained machine learning models as Pyomo optimization formulations. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/gmalivenko/pytorch2keras\">pytorch2keras</a></b> (\ud83e\udd4919 \u00b7  \u2b50 820 \u00b7 \ud83d\udc80) - PyTorch to Keras model convertor. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/riga/tfdeploy\">tfdeploy</a></b> (\ud83e\udd4916 \u00b7  \u2b50 350 \u00b7 \ud83d\udc80) - Deploy tensorflow graphs for fast evaluation and export to.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/Cornerstone-OnDemand/modelkit\">modelkit</a></b> (\ud83e\udd4915 \u00b7  \u2b50 140) - Toolkit for developing and maintaining ML models. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/backprop-ai/backprop\">backprop</a></b> (\ud83e\udd4913 \u00b7  \u2b50 230 \u00b7 \ud83d\udc80) - Backprop makes it simple to use, finetune, and deploy state-of-.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/apple/ml-ane-transformers\">ml-ane-transformers</a></b> (\ud83e\udd4910 \u00b7  \u2b50 480 \u00b7 \ud83d\udc23) - Reference implementation of the Transformer.. <code>\u2757Unlicensed</code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Model Interpretability\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries to visualize, explain, debug, evaluate, and interpret machine learning models._\n\n<details><summary><b><a href=\"https://github.com/slundberg/shap\">shap</a></b> (\ud83e\udd4739 \u00b7  \u2b50 18K) - A game theoretic approach to explain the output of any machine learning model. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/slundberg/shap) (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 2.6K \u00b7 \ud83d\udce6 7.3K \u00b7 \ud83d\udccb 2.1K - 70% open \u00b7 \u23f1\ufe0f 16.06.2022):\n\n\t```\n\tgit clone https://github.com/slundberg/shap\n\t```\n- [PyPi](https://pypi.org/project/shap) (\ud83d\udce5 4.6M / month \u00b7 \ud83d\udce6 280 \u00b7 \u23f1\ufe0f 16.06.2022):\n\t```\n\tpip install shap\n\t```\n- [Conda](https://anaconda.org/conda-forge/shap) (\ud83d\udce5 1.6M \u00b7 \u23f1\ufe0f 20.06.2022):\n\t```\n\tconda install -c conda-forge shap\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/arviz-devs/arviz\">arviz</a></b> (\ud83e\udd4734 \u00b7  \u2b50 1.3K) - Exploratory analysis of Bayesian models with Python. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/arviz-devs/arviz) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce5 110 \u00b7 \ud83d\udce6 3K \u00b7 \ud83d\udccb 800 - 22% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/arviz-devs/arviz\n\t```\n- [PyPi](https://pypi.org/project/arviz) (\ud83d\udce5 910K / month \u00b7 \ud83d\udce6 100 \u00b7 \u23f1\ufe0f 13.05.2022):\n\t```\n\tpip install arviz\n\t```\n- [Conda](https://anaconda.org/conda-forge/arviz) (\ud83d\udce5 1M \u00b7 \u23f1\ufe0f 16.11.2022):\n\t```\n\tconda install -c conda-forge arviz\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/lutzroeder/netron\">Netron</a></b> (\ud83e\udd4733 \u00b7  \u2b50 21K) - Visualizer for neural network, deep learning, and machine.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/lutzroeder/netron) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 2.3K \u00b7 \ud83d\udce5 33K \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 880 - 3% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/lutzroeder/netron\n\t```\n- [PyPi](https://pypi.org/project/netron) (\ud83d\udce5 9.3K / month \u00b7 \ud83d\udce6 67 \u00b7 \u23f1\ufe0f 04.07.2022):\n\t```\n\tpip install netron\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/interpretml/interpret\">InterpretML</a></b> (\ud83e\udd4733 \u00b7  \u2b50 5.1K) - Fit interpretable models. Explain blackbox machine learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/interpretml/interpret) (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 620 \u00b7 \ud83d\udce6 310 \u00b7 \ud83d\udccb 330 - 35% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/interpretml/interpret\n\t```\n- [PyPi](https://pypi.org/project/interpret) (\ud83d\udce5 140K / month \u00b7 \ud83d\udce6 16 \u00b7 \u23f1\ufe0f 23.09.2021):\n\t```\n\tpip install interpret\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pytorch/captum\">Captum</a></b> (\ud83e\udd4731 \u00b7  \u2b50 3.6K) - Model interpretability and understanding for PyTorch. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pytorch/captum) (\ud83d\udc68\u200d\ud83d\udcbb 94 \u00b7 \ud83d\udd00 370 \u00b7 \ud83d\udce6 780 \u00b7 \ud83d\udccb 420 - 30% open \u00b7 \u23f1\ufe0f 18.11.2022):\n\n\t```\n\tgit clone https://github.com/pytorch/captum\n\t```\n- [PyPi](https://pypi.org/project/captum) (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 23 \u00b7 \u23f1\ufe0f 03.03.2022):\n\t```\n\tpip install captum\n\t```\n- [Conda](https://anaconda.org/conda-forge/captum) (\ud83d\udce5 4.2K \u00b7 \u23f1\ufe0f 04.03.2022):\n\t```\n\tconda install -c conda-forge captum\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/model-analysis\">Model Analysis</a></b> (\ud83e\udd4731 \u00b7  \u2b50 1.2K) - Model analysis tools for TensorFlow. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/model-analysis) (\ud83d\udc68\u200d\ud83d\udcbb 52 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udccb 79 - 36% open \u00b7 \u23f1\ufe0f 18.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/model-analysis\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-model-analysis) (\ud83d\udce5 820K / month \u00b7 \ud83d\udce6 21 \u00b7 \u23f1\ufe0f 16.05.2022):\n\t```\n\tpip install tensorflow-model-analysis\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/parrt/dtreeviz\">dtreeviz</a></b> (\ud83e\udd4830 \u00b7  \u2b50 2.3K) - A python library for decision tree visualization and model interpretation. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/parrt/dtreeviz) (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 290 \u00b7 \ud83d\udce6 540 \u00b7 \ud83d\udccb 130 - 23% open \u00b7 \u23f1\ufe0f 29.10.2022):\n\n\t```\n\tgit clone https://github.com/parrt/dtreeviz\n\t```\n- [PyPi](https://pypi.org/project/dtreeviz) (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 14 \u00b7 \u23f1\ufe0f 29.04.2022):\n\t```\n\tpip install dtreeviz\n\t```\n- [Conda](https://anaconda.org/conda-forge/dtreeviz) (\ud83d\udce5 28K \u00b7 \u23f1\ufe0f 05.11.2022):\n\t```\n\tconda install -c conda-forge dtreeviz\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/MAIF/shapash\">shapash</a></b> (\ud83e\udd4830 \u00b7  \u2b50 2K) - Shapash makes Machine Learning models transparent and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/MAIF/shapash) (\ud83d\udc68\u200d\ud83d\udcbb 35 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 92 \u00b7 \ud83d\udccb 140 - 14% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/MAIF/shapash\n\t```\n- [PyPi](https://pypi.org/project/shapash) (\ud83d\udce5 14K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 09.05.2022):\n\t```\n\tpip install shapash\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/SeldonIO/alibi\">Alibi</a></b> (\ud83e\udd4830 \u00b7  \u2b50 1.9K) - Algorithms for explaining machine learning models. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/SeldonIO/alibi) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce6 210 \u00b7 \ud83d\udccb 320 - 38% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/SeldonIO/alibi\n\t```\n- [PyPi](https://pypi.org/project/alibi) (\ud83d\udce5 30K / month \u00b7 \ud83d\udce6 24 \u00b7 \u23f1\ufe0f 18.05.2022):\n\t```\n\tpip install alibi\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/DistrictDataLabs/yellowbrick\">yellowbrick</a></b> (\ud83e\udd4829 \u00b7  \u2b50 3.8K) - Visual analysis and diagnostic tools to facilitate machine.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/DistrictDataLabs/yellowbrick) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 520 \u00b7 \ud83d\udccb 680 - 12% open \u00b7 \u23f1\ufe0f 21.08.2022):\n\n\t```\n\tgit clone https://github.com/DistrictDataLabs/yellowbrick\n\t```\n- [PyPi](https://pypi.org/project/yellowbrick) (\ud83d\udce5 1M / month \u00b7 \ud83d\udce6 67 \u00b7 \u23f1\ufe0f 19.02.2022):\n\t```\n\tpip install yellowbrick\n\t```\n- [Conda](https://anaconda.org/conda-forge/yellowbrick) (\ud83d\udce5 45K \u00b7 \u23f1\ufe0f 22.08.2022):\n\t```\n\tconda install -c conda-forge yellowbrick\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Trusted-AI/AIF360\">Fairness 360</a></b> (\ud83e\udd4829 \u00b7  \u2b50 1.9K) - A comprehensive set of fairness metrics for datasets and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Trusted-AI/AIF360) (\ud83d\udc68\u200d\ud83d\udcbb 63 \u00b7 \ud83d\udd00 630 \u00b7 \ud83d\udce6 190 \u00b7 \ud83d\udccb 220 - 62% open \u00b7 \u23f1\ufe0f 04.11.2022):\n\n\t```\n\tgit clone https://github.com/Trusted-AI/AIF360\n\t```\n- [PyPi](https://pypi.org/project/aif360) (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 04.03.2021):\n\t```\n\tpip install aif360\n\t```\n- [Conda](https://anaconda.org/conda-forge/aif360) (\ud83d\udce5 4.3K \u00b7 \u23f1\ufe0f 04.09.2022):\n\t```\n\tconda install -c conda-forge aif360\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/fairlearn/fairlearn\">fairlearn</a></b> (\ud83e\udd4829 \u00b7  \u2b50 1.4K) - A Python package to assess and improve fairness of machine.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/fairlearn/fairlearn) (\ud83d\udc68\u200d\ud83d\udcbb 68 \u00b7 \ud83d\udd00 330 \u00b7 \ud83d\udccb 400 - 42% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/fairlearn/fairlearn\n\t```\n- [PyPi](https://pypi.org/project/fairlearn) (\ud83d\udce5 120K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 07.07.2021):\n\t```\n\tpip install fairlearn\n\t```\n- [Conda](https://anaconda.org/conda-forge/fairlearn) (\ud83d\udce5 23K \u00b7 \u23f1\ufe0f 07.07.2021):\n\t```\n\tconda install -c conda-forge fairlearn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/oegedijk/explainerdashboard\">explainerdashboard</a></b> (\ud83e\udd4829 \u00b7  \u2b50 1.4K) - Quickly build Explainable AI dashboards that show the inner.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/oegedijk/explainerdashboard) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 200 \u00b7 \ud83d\udccb 190 - 10% open \u00b7 \u23f1\ufe0f 16.06.2022):\n\n\t```\n\tgit clone https://github.com/oegedijk/explainerdashboard\n\t```\n- [PyPi](https://pypi.org/project/explainerdashboard) (\ud83d\udce5 73K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 15.06.2022):\n\t```\n\tpip install explainerdashboard\n\t```\n- [Conda](https://anaconda.org/conda-forge/explainerdashboard) (\ud83d\udce5 26K \u00b7 \u23f1\ufe0f 15.02.2022):\n\t```\n\tconda install -c conda-forge explainerdashboard\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/microsoft/responsible-ai-toolbox\">responsible-ai-widgets</a></b> (\ud83e\udd4829 \u00b7  \u2b50 620) - This project provides responsible AI user interfaces.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/microsoft/responsible-ai-toolbox) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 40 \u00b7 \ud83d\udccb 280 - 21% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/microsoft/responsible-ai-toolbox\n\t```\n- [PyPi](https://pypi.org/project/raiwidgets) (\ud83d\udce5 9.8K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 10.06.2022):\n\t```\n\tpip install raiwidgets\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/py-why/dowhy\">DoWhy</a></b> (\ud83e\udd4828 \u00b7  \u2b50 5.4K) - DoWhy is a Python library for causal inference that supports explicit.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/py-why/dowhy) (\ud83d\udc68\u200d\ud83d\udcbb 63 \u00b7 \ud83d\udd00 760 \u00b7 \ud83d\udce5 31 \u00b7 \ud83d\udccb 310 - 33% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/py-why/dowhy\n\t```\n- [PyPi](https://pypi.org/project/dowhy) (\ud83d\udce5 92K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 20.03.2022):\n\t```\n\tpip install dowhy\n\t```\n- [Conda](https://anaconda.org/conda-forge/dowhy) (\ud83d\udce5 10K \u00b7 \u23f1\ufe0f 19.07.2022):\n\t```\n\tconda install -c conda-forge dowhy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/huggingface/evaluate\">evaluate</a></b> (\ud83e\udd4828 \u00b7  \u2b50 970) - Evaluate: A library for easily evaluating machine learning models.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/huggingface/evaluate) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 73 \u00b7 \ud83d\udce6 420 \u00b7 \ud83d\udccb 150 - 40% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/huggingface/evaluate\n\t```\n- [PyPi](https://pypi.org/project/evaluate) (\ud83d\udce5 200K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 16.06.2022):\n\t```\n\tpip install evaluate\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/quantumblacklabs/causalnex\">CausalNex</a></b> (\ud83e\udd4827 \u00b7  \u2b50 1.7K) - A Python library that helps data scientists to infer.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/quantumblacklabs/causalnex) (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce6 61 \u00b7 \ud83d\udccb 120 - 8% open \u00b7 \u23f1\ufe0f 14.11.2022):\n\n\t```\n\tgit clone https://github.com/quantumblacklabs/causalnex\n\t```\n- [PyPi](https://pypi.org/project/causalnex) (\ud83d\udce5 3.5K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 11.11.2021):\n\t```\n\tpip install causalnex\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Trusted-AI/AIX360\">Explainability 360</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.2K) - Interpretability and explainability of data and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Trusted-AI/AIX360) (\ud83d\udc68\u200d\ud83d\udcbb 39 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 64 \u00b7 \ud83d\udccb 75 - 62% open \u00b7 \u23f1\ufe0f 03.11.2022):\n\n\t```\n\tgit clone https://github.com/Trusted-AI/AIX360\n\t```\n- [PyPi](https://pypi.org/project/aix360) (\ud83d\udce5 1.1K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 28.10.2020):\n\t```\n\tpip install aix360\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/marcotcr/checklist\">checklist</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.8K) - Beyond Accuracy: Behavioral Testing of NLP models with CheckList. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/marcotcr/checklist) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 180 \u00b7 \ud83d\udccb 100 - 22% open \u00b7 \u23f1\ufe0f 12.08.2022):\n\n\t```\n\tgit clone https://github.com/marcotcr/checklist\n\t```\n- [PyPi](https://pypi.org/project/checklist) (\ud83d\udce5 9.5K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 24.05.2021):\n\t```\n\tpip install checklist\n\t```\n- [Conda](https://anaconda.org/conda-forge/checklist) (\ud83d\udce5 4.6K \u00b7 \u23f1\ufe0f 15.07.2021):\n\t```\n\tconda install -c conda-forge checklist\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/csinva/imodels\">imodels</a></b> (\ud83e\udd4925 \u00b7  \u2b50 960) - Interpretable ML package for concise, transparent, and accurate predictive.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/csinva/imodels) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 93 \u00b7 \ud83d\udce6 26 \u00b7 \ud83d\udccb 46 - 39% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/csinva/imodels\n\t```\n- [PyPi](https://pypi.org/project/imodels) (\ud83d\udce5 67K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 03.07.2022):\n\t```\n\tpip install imodels\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ploomber/sklearn-evaluation\">sklearn-evaluation</a></b> (\ud83e\udd4924 \u00b7  \u2b50 340) - Machine learning model evaluation made easy: plots,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/ploomber/sklearn-evaluation) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 36 \u00b7 \ud83d\udce6 54 \u00b7 \ud83d\udccb 64 - 42% open \u00b7 \u23f1\ufe0f 17.11.2022):\n\n\t```\n\tgit clone https://github.com/edublancas/sklearn-evaluation\n\t```\n- [PyPi](https://pypi.org/project/sklearn-evaluation) (\ud83d\udce5 2.6K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install sklearn-evaluation\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PAIR-code/lit\">LIT</a></b> (\ud83e\udd4923 \u00b7  \u2b50 3K \u00b7 \ud83d\udca4) - The Language Interpretability Tool: Interactively analyze NLP models.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/PAIR-code/lit) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 130 - 47% open \u00b7 \u23f1\ufe0f 15.03.2022):\n\n\t```\n\tgit clone https://github.com/PAIR-code/lit\n\t```\n- [PyPi](https://pypi.org/project/lit-nlp) (\ud83d\udce5 1.2K / month \u00b7 \u23f1\ufe0f 21.12.2021):\n\t```\n\tpip install lit-nlp\n\t```\n- [Conda](https://anaconda.org/conda-forge/lit-nlp) (\ud83d\udce5 48K \u00b7 \u23f1\ufe0f 09.11.2021):\n\t```\n\tconda install -c conda-forge lit-nlp\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/philipperemy/keract\">keract</a></b> (\ud83e\udd4923 \u00b7  \u2b50 1K) - Layers Outputs and Gradients in Keras. Made easy. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/philipperemy/keract) (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 89 - 3% open \u00b7 \u23f1\ufe0f 03.11.2022):\n\n\t```\n\tgit clone https://github.com/philipperemy/keract\n\t```\n- [PyPi](https://pypi.org/project/keract) (\ud83d\udce5 4.6K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 19.06.2021):\n\t```\n\tpip install keract\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PAIR-code/what-if-tool\">What-If Tool</a></b> (\ud83e\udd4922 \u00b7  \u2b50 760 \u00b7 \ud83d\udca4) - Source code/webpage/demos for the What-If Tool. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/PAIR-code/what-if-tool) (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 120 - 53% open \u00b7 \u23f1\ufe0f 05.01.2022):\n\n\t```\n\tgit clone https://github.com/PAIR-code/what-if-tool\n\t```\n- [PyPi](https://pypi.org/project/witwidget) (\ud83d\udce5 9.5K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 12.10.2021):\n\t```\n\tpip install witwidget\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensorboard-plugin-wit) (\ud83d\udce5 1.4M \u00b7 \u23f1\ufe0f 06.01.2022):\n\t```\n\tconda install -c conda-forge tensorboard-plugin-wit\n\t```\n- [npm](https://www.npmjs.com/package/wit-widget) (\ud83d\udce5 2K / month \u00b7 \u23f1\ufe0f 12.10.2021):\n\t```\n\tnpm install wit-widget\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/albermax/innvestigate\">iNNvestigate</a></b> (\ud83e\udd4921 \u00b7  \u2b50 1.1K) - A toolbox to iNNvestigate neural networks predictions!. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/albermax/innvestigate) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce5 38 \u00b7 \ud83d\udccb 250 - 21% open \u00b7 \u23f1\ufe0f 12.10.2022):\n\n\t```\n\tgit clone https://github.com/albermax/innvestigate\n\t```\n- [PyPi](https://pypi.org/project/innvestigate) (\ud83d\udce5 450 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 14.11.2020):\n\t```\n\tpip install innvestigate\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/interpretml/DiCE\">DiCE</a></b> (\ud83e\udd4921 \u00b7  \u2b50 960) - Generate Diverse Counterfactual Explanations for any machine.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/interpretml/DiCE) (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 140 - 37% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/interpretml/DiCE\n\t```\n- [PyPi](https://pypi.org/project/dice-ml) (\ud83d\udce5 28K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 02.06.2022):\n\t```\n\tpip install dice-ml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/sicara/tf-explain\">tf-explain</a></b> (\ud83e\udd4921 \u00b7  \u2b50 950) - Interpretability Methods for tf.keras models with Tensorflow 2.x. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/sicara/tf-explain) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 140 \u00b7 \ud83d\udccb 92 - 44% open \u00b7 \u23f1\ufe0f 30.06.2022):\n\n\t```\n\tgit clone https://github.com/sicara/tf-explain\n\t```\n- [PyPi](https://pypi.org/project/tf-explain) (\ud83d\udce5 2.3K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 18.11.2021):\n\t```\n\tpip install tf-explain\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/kundajelab/deeplift\">deeplift</a></b> (\ud83e\udd4921 \u00b7  \u2b50 690 \u00b7 \ud83d\udca4) - Public facing deeplift repo. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/kundajelab/deeplift) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 63 \u00b7 \ud83d\udccb 86 - 43% open \u00b7 \u23f1\ufe0f 11.11.2021):\n\n\t```\n\tgit clone https://github.com/kundajelab/deeplift\n\t```\n- [PyPi](https://pypi.org/project/deeplift) (\ud83d\udce5 340 / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 11.11.2020):\n\t```\n\tpip install deeplift\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jalammar/ecco\">ecco</a></b> (\ud83e\udd4919 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udca4) - Explain, analyze, and visualize NLP language models. Ecco creates.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/jalammar/ecco) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce5 23 \u00b7 \ud83d\udce6 16 \u00b7 \ud83d\udccb 41 - 31% open \u00b7 \u23f1\ufe0f 18.01.2022):\n\n\t```\n\tgit clone https://github.com/jalammar/ecco\n\t```\n- [PyPi](https://pypi.org/project/ecco) (\ud83d\udce5 760 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 09.01.2022):\n\t```\n\tpip install ecco\n\t```\n- [Conda](https://anaconda.org/conda-forge/ecco) (\ud83d\udce5 2.4K \u00b7 \u23f1\ufe0f 10.01.2022):\n\t```\n\tconda install -c conda-forge ecco\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/model-card-toolkit\">model-card-toolkit</a></b> (\ud83e\udd4919 \u00b7  \u2b50 320) - a tool that leverages rich metadata and lineage.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/tensorflow/model-card-toolkit) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 65 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 21 - 76% open \u00b7 \u23f1\ufe0f 14.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/model-card-toolkit\n\t```\n- [PyPi](https://pypi.org/project/model-card-toolkit) (\ud83d\udce5 1K / month \u00b7 \u23f1\ufe0f 28.04.2022):\n\t```\n\tpip install model-card-toolkit\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/aerdem4/lofo-importance\">LOFO</a></b> (\ud83e\udd4917 \u00b7  \u2b50 670 \u00b7 \ud83d\udca4) - Leave One Feature Out Importance. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/aerdem4/lofo-importance) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 71 \u00b7 \ud83d\udce6 22 \u00b7 \ud83d\udccb 20 - 20% open \u00b7 \u23f1\ufe0f 27.04.2022):\n\n\t```\n\tgit clone https://github.com/aerdem4/lofo-importance\n\t```\n- [PyPi](https://pypi.org/project/lofo-importance) (\ud83d\udce5 2.4K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 27.04.2022):\n\t```\n\tpip install lofo-importance\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/marcotcr/anchor\">Anchor</a></b> (\ud83e\udd4916 \u00b7  \u2b50 730) - Code for High-Precision Model-Agnostic Explanations paper. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/marcotcr/anchor) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udccb 74 - 31% open \u00b7 \u23f1\ufe0f 19.07.2022):\n\n\t```\n\tgit clone https://github.com/marcotcr/anchor\n\t```\n- [PyPi](https://pypi.org/project/anchor_exp) (\ud83d\udce5 1.5K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 10.09.2020):\n\t```\n\tpip install anchor_exp\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/explainX/explainx\">ExplainX.ai</a></b> (\ud83e\udd4915 \u00b7  \u2b50 320) - Explainable AI framework for data scientists. Explain & debug any.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/explainX/explainx) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 42 \u00b7 \ud83d\udce5 5 \u00b7 \ud83d\udccb 27 - 37% open \u00b7 \u23f1\ufe0f 15.09.2022):\n\n\t```\n\tgit clone https://github.com/explainX/explainx\n\t```\n- [PyPi](https://pypi.org/project/explainx) (\ud83d\udce5 2K / month \u00b7 \u23f1\ufe0f 04.02.2021):\n\t```\n\tpip install explainx\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/interpretml/interpret-text\">interpret-text</a></b> (\ud83e\udd4914 \u00b7  \u2b50 340 \u00b7 \ud83d\udca4) - A library that incorporates state-of-the-art explainers.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/interpretml/interpret-text) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 58 \u00b7 \ud83d\udccb 74 - 78% open \u00b7 \u23f1\ufe0f 06.12.2021):\n\n\t```\n\tgit clone https://github.com/interpretml/interpret-text\n\t```\n- [PyPi](https://pypi.org/project/interpret-text) (\ud83d\udce5 48 / month \u00b7 \u23f1\ufe0f 07.12.2021):\n\t```\n\tpip install interpret-text\n\t```\n</details>\n<details><summary>Show 20 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/marcotcr/lime\">Lime</a></b> (\ud83e\udd4733 \u00b7  \u2b50 10K \u00b7 \ud83d\udc80) - Lime: Explaining the predictions of any machine learning classifier. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code>\n- <b><a href=\"https://github.com/bmabey/pyLDAvis\">pyLDAvis</a></b> (\ud83e\udd4731 \u00b7  \u2b50 1.7K \u00b7 \ud83d\udc80) - Python library for interactive topic model visualization... <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/deepchecks/deepchecks\">Deep Checks</a></b> (\ud83e\udd4829 \u00b7  \u2b50 2.2K) - Tests for Continuous Validation of ML Models & Data... <code><a href=\"http://bit.ly/3pwmjO5\">\u2757\ufe0fAGPL-3.0</a></code>\n- <b><a href=\"https://github.com/TeamHG-Memex/eli5\">eli5</a></b> (\ud83e\udd4827 \u00b7  \u2b50 2.6K \u00b7 \ud83d\udc80) - A library for debugging/inspecting machine learning classifiers and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/reiinakano/scikit-plot\">scikit-plot</a></b> (\ud83e\udd4827 \u00b7  \u2b50 2.3K \u00b7 \ud83d\udc80) - An intuitive library to add plotting functionality to.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/tensorflow/lucid\">Lucid</a></b> (\ud83e\udd4926 \u00b7  \u2b50 4.5K \u00b7 \ud83d\udc80) - A collection of infrastructure and tools for research in.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/raghakot/keras-vis\">keras-vis</a></b> (\ud83e\udd4925 \u00b7  \u2b50 2.9K \u00b7 \ud83d\udc80) - Neural network visualization toolkit for keras. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/ModelOriented/DALEX\">DALEX</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udcc8) - moDel Agnostic Language for Exploration and eXplanation. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/andosa/treeinterpreter\">TreeInterpreter</a></b> (\ud83e\udd4922 \u00b7  \u2b50 720 \u00b7 \ud83d\udc80) - Package for interpreting scikit-learns decision tree.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/parrt/random-forest-importances\">random-forest-importances</a></b> (\ud83e\udd4922 \u00b7  \u2b50 530 \u00b7 \ud83d\udc80) - Code to compute permutation and drop-column.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/dssg/aequitas\">aequitas</a></b> (\ud83e\udd4922 \u00b7  \u2b50 500 \u00b7 \ud83d\udc80) - Bias and Fairness Audit Toolkit. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/oracle/Skater\">Skater</a></b> (\ud83e\udd4921 \u00b7  \u2b50 1K \u00b7 \ud83d\udca4) - Python Library for Model Interpretation/Explanations. <code><a href=\"https://tldrlegal.com/search?q=UPL-1.0\">\u2757\ufe0fUPL-1.0</a></code>\n- <b><a href=\"https://github.com/understandable-machine-intelligence-lab/Quantus\">Quantus</a></b> (\ud83e\udd4921 \u00b7  \u2b50 260) - Quantus is an eXplainable AI toolkit for responsible evaluation of.. <code><a href=\"http://bit.ly/37RvQcA\">\u2757\ufe0fLGPL-3.0</a></code>\n- <b><a href=\"https://github.com/tensorflow/tcav\">tcav</a></b> (\ud83e\udd4919 \u00b7  \u2b50 550 \u00b7 \ud83d\udc80) - Code for the TCAV ML interpretability project. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/tensorflow/fairness-indicators\">fairness-indicators</a></b> (\ud83e\udd4919 \u00b7  \u2b50 280) - Tensorflows Fairness Evaluation and Visualization.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/MisaOgura/flashtorch\">FlashTorch</a></b> (\ud83e\udd4917 \u00b7  \u2b50 690 \u00b7 \ud83d\udc80) - Visualization toolkit for neural networks in PyTorch! Demo --. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/EthicalML/xai\">XAI</a></b> (\ud83e\udd4916 \u00b7  \u2b50 870 \u00b7 \ud83d\udc80) - XAI - An eXplainability toolbox for machine learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/SAP/contextual-ai\">contextual-ai</a></b> (\ud83e\udd4912 \u00b7  \u2b50 82 \u00b7 \ud83d\udca4) - Contextual AI adds explainability to different stages of.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/suinleelab/attributionpriors\">Attribution Priors</a></b> (\ud83e\udd4911 \u00b7  \u2b50 110 \u00b7 \ud83d\udc80) - Tools for training explainable models using.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/intuit/bias-detector\">bias-detector</a></b> (\ud83e\udd4911 \u00b7  \u2b50 40) - Bias Detector is a python package for detecting bias in machine.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n</details>\n<br>\n\n## Vector Similarity Search (ANN)\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for Approximate Nearest Neighbor Search and Vector Indexing/Similarity Search._\n\n\ud83d\udd17&nbsp;<b><a href=\"https://github.com/erikbern/ann-benchmarks\">ANN Benchmarks</a></b> ( \u2b50 3.1K)  - Benchmarks of approximate nearest neighbor libraries in Python.\n\n<details><summary><b><a href=\"https://github.com/milvus-io/milvus\">Milvus</a></b> (\ud83e\udd4738 \u00b7  \u2b50 14K) - Vector database for scalable similarity search and AI applications. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/milvus-io/milvus) (\ud83d\udc68\u200d\ud83d\udcbb 230 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce5 25K \u00b7 \ud83d\udccb 6.5K - 5% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/milvus-io/milvus\n\t```\n- [PyPi](https://pypi.org/project/pymilvus) (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 17 \u00b7 \u23f1\ufe0f 02.04.2022):\n\t```\n\tpip install pymilvus\n\t```\n- [Docker Hub](https://hub.docker.com/r/milvusdb/milvus) (\ud83d\udce5 2.4M \u00b7 \u2b50 23 \u00b7 \u23f1\ufe0f 24.11.2022):\n\t```\n\tdocker pull milvusdb/milvus\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/faiss\">Faiss</a></b> (\ud83e\udd4736 \u00b7  \u2b50 19K) - A library for efficient similarity search and clustering of dense vectors. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/faiss) (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 2.7K \u00b7 \ud83d\udce6 810 \u00b7 \ud83d\udccb 1.9K - 11% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/faiss\n\t```\n- [PyPi](https://pypi.org/project/pymilvus) (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 17 \u00b7 \u23f1\ufe0f 02.04.2022):\n\t```\n\tpip install pymilvus\n\t```\n- [Conda](https://anaconda.org/conda-forge/faiss) (\ud83d\udce5 570K \u00b7 \u23f1\ufe0f 02.11.2022):\n\t```\n\tconda install -c conda-forge faiss\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/spotify/annoy\">Annoy</a></b> (\ud83e\udd4833 \u00b7  \u2b50 10K) - Approximate Nearest Neighbors in C++/Python optimized for memory usage.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/spotify/annoy) (\ud83d\udc68\u200d\ud83d\udcbb 82 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 2.4K \u00b7 \ud83d\udccb 360 - 11% open \u00b7 \u23f1\ufe0f 27.10.2022):\n\n\t```\n\tgit clone https://github.com/spotify/annoy\n\t```\n- [PyPi](https://pypi.org/project/annoy) (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 240 \u00b7 \u23f1\ufe0f 18.09.2020):\n\t```\n\tpip install annoy\n\t```\n- [Conda](https://anaconda.org/conda-forge/python-annoy) (\ud83d\udce5 290K \u00b7 \u23f1\ufe0f 31.10.2022):\n\t```\n\tconda install -c conda-forge python-annoy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nmslib/nmslib\">NMSLIB</a></b> (\ud83e\udd4830 \u00b7  \u2b50 2.9K) - Non-Metric Space Library (NMSLIB): An efficient similarity search.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/nmslib/nmslib) (\ud83d\udc68\u200d\ud83d\udcbb 48 \u00b7 \ud83d\udd00 410 \u00b7 \ud83d\udce6 700 \u00b7 \ud83d\udccb 410 - 15% open \u00b7 \u23f1\ufe0f 31.05.2022):\n\n\t```\n\tgit clone https://github.com/nmslib/nmslib\n\t```\n- [PyPi](https://pypi.org/project/nmslib) (\ud83d\udce5 120K / month \u00b7 \ud83d\udce6 52 \u00b7 \u23f1\ufe0f 03.02.2021):\n\t```\n\tpip install nmslib\n\t```\n- [Conda](https://anaconda.org/conda-forge/nmslib) (\ud83d\udce5 72K \u00b7 \u23f1\ufe0f 30.10.2022):\n\t```\n\tconda install -c conda-forge nmslib\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nmslib/hnswlib\">hnswlib</a></b> (\ud83e\udd4828 \u00b7  \u2b50 2.2K \u00b7 \ud83d\udca4) - Header-only C++/python library for fast approximate nearest.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/nmslib/hnswlib) (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 410 \u00b7 \ud83d\udce6 330 \u00b7 \ud83d\udccb 280 - 53% open \u00b7 \u23f1\ufe0f 16.04.2022):\n\n\t```\n\tgit clone https://github.com/nmslib/hnswlib\n\t```\n- [PyPi](https://pypi.org/project/hnswlib) (\ud83d\udce5 360K / month \u00b7 \ud83d\udce6 28 \u00b7 \u23f1\ufe0f 14.02.2022):\n\t```\n\tpip install hnswlib\n\t```\n- [Conda](https://anaconda.org/conda-forge/hnswlib) (\ud83d\udce5 63K \u00b7 \u23f1\ufe0f 01.11.2022):\n\t```\n\tconda install -c conda-forge hnswlib\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/lmcinnes/pynndescent\">PyNNDescent</a></b> (\ud83e\udd4828 \u00b7  \u2b50 690) - A Python nearest neighbor descent for approximate nearest neighbors. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/lmcinnes/pynndescent) (\ud83d\udc68\u200d\ud83d\udcbb 24 \u00b7 \ud83d\udd00 90 \u00b7 \ud83d\udce6 2.4K \u00b7 \ud83d\udccb 110 - 49% open \u00b7 \u23f1\ufe0f 01.11.2022):\n\n\t```\n\tgit clone https://github.com/lmcinnes/pynndescent\n\t```\n- [PyPi](https://pypi.org/project/pynndescent) (\ud83d\udce5 800K / month \u00b7 \ud83d\udce6 26 \u00b7 \u23f1\ufe0f 14.05.2022):\n\t```\n\tpip install pynndescent\n\t```\n- [Conda](https://anaconda.org/conda-forge/pynndescent) (\ud83d\udce5 1M \u00b7 \u23f1\ufe0f 01.11.2022):\n\t```\n\tconda install -c conda-forge pynndescent\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/yahoojapan/NGT\">NGT</a></b> (\ud83e\udd4923 \u00b7  \u2b50 940) - Nearest Neighbor Search with Neighborhood Graph and Tree for High-.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/yahoojapan/NGT) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 96 \u00b7 \ud83d\udccb 100 - 12% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/yahoojapan/NGT\n\t```\n- [PyPi](https://pypi.org/project/ngt) (\ud83d\udce5 16K / month \u00b7 \ud83d\udce6 8 \u00b7 \u23f1\ufe0f 20.06.2022):\n\t```\n\tpip install ngt\n\t```\n</details>\n<details><summary>Show 4 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/plasticityai/magnitude\">Magnitude</a></b> (\ud83e\udd4924 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - A fast, efficient universal vector embedding utility package. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/pixelogik/NearPy\">NearPy</a></b> (\ud83e\udd4921 \u00b7  \u2b50 720 \u00b7 \ud83d\udc80) - Python framework for fast (approximated) nearest neighbour search in.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/kakao/n2\">N2</a></b> (\ud83e\udd4919 \u00b7  \u2b50 530 \u00b7 \ud83d\udc80) - TOROS N2 - lightweight approximate Nearest Neighbor library which runs.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/facebookresearch/pysparnn\">PySparNN</a></b> (\ud83e\udd4911 \u00b7  \u2b50 900 \u00b7 \ud83d\udc80) - Approximate Nearest Neighbor Search for Sparse Data in Python!. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n</details>\n<br>\n\n## Probabilistics & Statistics\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries providing capabilities for probabilistic programming/reasoning, bayesian inference, gaussian processes, or statistics._\n\n<details><summary><b><a href=\"https://github.com/pymc-devs/pymc\">PyMC3</a></b> (\ud83e\udd4740 \u00b7  \u2b50 7.1K) - Probabilistic Programming in Python: Bayesian Modeling and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/pymc-devs/pymc) (\ud83d\udc68\u200d\ud83d\udcbb 420 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce5 1.9K \u00b7 \ud83d\udce6 890 \u00b7 \ud83d\udccb 2.9K - 5% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/pymc-devs/pymc\n\t```\n- [PyPi](https://pypi.org/project/pymc3) (\ud83d\udce5 380K / month \u00b7 \ud83d\udce6 240 \u00b7 \u23f1\ufe0f 15.03.2022):\n\t```\n\tpip install pymc3\n\t```\n- [Conda](https://anaconda.org/conda-forge/pymc3) (\ud83d\udce5 470K \u00b7 \u23f1\ufe0f 20.05.2022):\n\t```\n\tconda install -c conda-forge pymc3\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/probability\">tensorflow-probability</a></b> (\ud83e\udd4737 \u00b7  \u2b50 3.8K) - Probabilistic reasoning and statistical analysis in.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/probability) (\ud83d\udc68\u200d\ud83d\udcbb 460 \u00b7 \ud83d\udd00 1K \u00b7 \ud83d\udccb 1.3K - 45% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/probability\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-probability) (\ud83d\udce5 930K / month \u00b7 \ud83d\udce6 340 \u00b7 \u23f1\ufe0f 07.06.2022):\n\t```\n\tpip install tensorflow-probability\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensorflow-probability) (\ud83d\udce5 82K \u00b7 \u23f1\ufe0f 10.11.2022):\n\t```\n\tconda install -c conda-forge tensorflow-probability\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pyro-ppl/pyro\">Pyro</a></b> (\ud83e\udd4734 \u00b7  \u2b50 7.7K) - Deep universal probabilistic programming with Python and PyTorch. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pyro-ppl/pyro) (\ud83d\udc68\u200d\ud83d\udcbb 130 \u00b7 \ud83d\udd00 940 \u00b7 \ud83d\udce6 920 \u00b7 \ud83d\udccb 1K - 22% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/pyro-ppl/pyro\n\t```\n- [PyPi](https://pypi.org/project/pyro-ppl) (\ud83d\udce5 360K / month \u00b7 \ud83d\udce6 60 \u00b7 \u23f1\ufe0f 24.03.2022):\n\t```\n\tpip install pyro-ppl\n\t```\n- [Conda](https://anaconda.org/conda-forge/pyro-ppl) (\ud83d\udce5 30K \u00b7 \u23f1\ufe0f 23.11.2022):\n\t```\n\tconda install -c conda-forge pyro-ppl\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/cornellius-gp/gpytorch\">GPyTorch</a></b> (\ud83e\udd4833 \u00b7  \u2b50 2.9K) - A highly efficient and modular implementation of Gaussian Processes.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/cornellius-gp/gpytorch) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 440 \u00b7 \ud83d\udce6 820 \u00b7 \ud83d\udccb 1.2K - 25% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/cornellius-gp/gpytorch\n\t```\n- [PyPi](https://pypi.org/project/gpytorch) (\ud83d\udce5 180K / month \u00b7 \ud83d\udce6 41 \u00b7 \u23f1\ufe0f 27.06.2022):\n\t```\n\tpip install gpytorch\n\t```\n- [Conda](https://anaconda.org/conda-forge/gpytorch) (\ud83d\udce5 63K \u00b7 \u23f1\ufe0f 08.09.2022):\n\t```\n\tconda install -c conda-forge gpytorch\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/GPflow/GPflow\">GPflow</a></b> (\ud83e\udd4832 \u00b7  \u2b50 1.7K) - Gaussian processes in TensorFlow. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/GPflow/GPflow) (\ud83d\udc68\u200d\ud83d\udcbb 79 \u00b7 \ud83d\udd00 430 \u00b7 \ud83d\udce6 430 \u00b7 \ud83d\udccb 800 - 16% open \u00b7 \u23f1\ufe0f 14.11.2022):\n\n\t```\n\tgit clone https://github.com/GPflow/GPflow\n\t```\n- [PyPi](https://pypi.org/project/gpflow) (\ud83d\udce5 88K / month \u00b7 \ud83d\udce6 29 \u00b7 \u23f1\ufe0f 10.05.2022):\n\t```\n\tpip install gpflow\n\t```\n- [Conda](https://anaconda.org/conda-forge/gpflow) (\ud83d\udce5 17K \u00b7 \u23f1\ufe0f 24.05.2022):\n\t```\n\tconda install -c conda-forge gpflow\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/hmmlearn/hmmlearn\">hmmlearn</a></b> (\ud83e\udd4831 \u00b7  \u2b50 2.7K) - Hidden Markov Models in Python, with scikit-learn like API. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/hmmlearn/hmmlearn) (\ud83d\udc68\u200d\ud83d\udcbb 41 \u00b7 \ud83d\udd00 710 \u00b7 \ud83d\udce6 1.4K \u00b7 \ud83d\udccb 400 - 14% open \u00b7 \u23f1\ufe0f 07.11.2022):\n\n\t```\n\tgit clone https://github.com/hmmlearn/hmmlearn\n\t```\n- [PyPi](https://pypi.org/project/hmmlearn) (\ud83d\udce5 96K / month \u00b7 \ud83d\udce6 130 \u00b7 \u23f1\ufe0f 10.02.2022):\n\t```\n\tpip install hmmlearn\n\t```\n- [Conda](https://anaconda.org/conda-forge/hmmlearn) (\ud83d\udce5 150K \u00b7 \u23f1\ufe0f 05.11.2022):\n\t```\n\tconda install -c conda-forge hmmlearn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rlabbe/filterpy\">filterpy</a></b> (\ud83e\udd4831 \u00b7  \u2b50 2.5K) - Python Kalman filtering and optimal estimation library. Implements.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/rlabbe/filterpy) (\ud83d\udc68\u200d\ud83d\udcbb 43 \u00b7 \ud83d\udd00 540 \u00b7 \ud83d\udce6 1.8K \u00b7 \ud83d\udccb 210 - 25% open \u00b7 \u23f1\ufe0f 22.08.2022):\n\n\t```\n\tgit clone https://github.com/rlabbe/filterpy\n\t```\n- [PyPi](https://pypi.org/project/filterpy) (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 130 \u00b7 \u23f1\ufe0f 10.10.2018):\n\t```\n\tpip install filterpy\n\t```\n- [Conda](https://anaconda.org/conda-forge/filterpy) (\ud83d\udce5 170K \u00b7 \u23f1\ufe0f 05.05.2020):\n\t```\n\tconda install -c conda-forge filterpy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pgmpy/pgmpy\">pgmpy</a></b> (\ud83e\udd4831 \u00b7  \u2b50 2.2K) - Python Library for learning (Structure and Parameter), inference.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/pgmpy/pgmpy) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 650 \u00b7 \ud83d\udce5 180 \u00b7 \ud83d\udce6 440 \u00b7 \ud83d\udccb 810 - 27% open \u00b7 \u23f1\ufe0f 03.11.2022):\n\n\t```\n\tgit clone https://github.com/pgmpy/pgmpy\n\t```\n- [PyPi](https://pypi.org/project/pgmpy) (\ud83d\udce5 64K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 30.06.2022):\n\t```\n\tpip install pgmpy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dfm/emcee\">emcee</a></b> (\ud83e\udd4831 \u00b7  \u2b50 1.3K) - The Python ensemble sampling toolkit for affine-invariant MCMC. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/dfm/emcee) (\ud83d\udc68\u200d\ud83d\udcbb 65 \u00b7 \ud83d\udd00 420 \u00b7 \ud83d\udce6 1.6K \u00b7 \ud83d\udccb 270 - 16% open \u00b7 \u23f1\ufe0f 12.10.2022):\n\n\t```\n\tgit clone https://github.com/dfm/emcee\n\t```\n- [PyPi](https://pypi.org/project/emcee) (\ud83d\udce5 97K / month \u00b7 \ud83d\udce6 310 \u00b7 \u23f1\ufe0f 10.05.2022):\n\t```\n\tpip install emcee\n\t```\n- [Conda](https://anaconda.org/conda-forge/emcee) (\ud83d\udce5 250K \u00b7 \u23f1\ufe0f 28.09.2022):\n\t```\n\tconda install -c conda-forge emcee\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pydata/patsy\">patsy</a></b> (\ud83e\udd4831 \u00b7  \u2b50 860) - Describing statistical models in Python using symbolic formulas. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/pydata/patsy) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 60K \u00b7 \ud83d\udccb 140 - 48% open \u00b7 \u23f1\ufe0f 09.10.2022):\n\n\t```\n\tgit clone https://github.com/pydata/patsy\n\t```\n- [PyPi](https://pypi.org/project/patsy) (\ud83d\udce5 8.2M / month \u00b7 \ud83d\udce6 2.7K \u00b7 \u23f1\ufe0f 26.09.2021):\n\t```\n\tpip install patsy\n\t```\n- [Conda](https://anaconda.org/conda-forge/patsy) (\ud83d\udce5 6.4M \u00b7 \u23f1\ufe0f 09.10.2022):\n\t```\n\tconda install -c conda-forge patsy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/twopirllc/pandas-ta\">pandas-ta</a></b> (\ud83e\udd4929 \u00b7  \u2b50 3.1K) - Technical Analysis Indicators - Pandas TA is an easy to use.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/twopirllc/pandas-ta) (\ud83d\udc68\u200d\ud83d\udcbb 45 \u00b7 \ud83d\udd00 660 \u00b7 \ud83d\udce6 940 \u00b7 \ud83d\udccb 450 - 18% open \u00b7 \u23f1\ufe0f 24.09.2022):\n\n\t```\n\tgit clone https://github.com/twopirllc/pandas-ta\n\t```\n- [PyPi](https://pypi.org/project/pandas-ta) (\ud83d\udce5 67K / month \u00b7 \ud83d\udce6 19 \u00b7 \u23f1\ufe0f 28.07.2021):\n\t```\n\tpip install pandas-ta\n\t```\n- [Conda](https://anaconda.org/conda-forge/pandas-ta) (\ud83d\udce5 3K \u00b7 \u23f1\ufe0f 05.10.2021):\n\t```\n\tconda install -c conda-forge pandas-ta\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/SALib/SALib\">SALib</a></b> (\ud83e\udd4929 \u00b7  \u2b50 650) - Sensitivity Analysis Library in Python. Contains Sobol, Morris, FAST, and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/SALib/SALib) (\ud83d\udc68\u200d\ud83d\udcbb 39 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udccb 300 - 13% open \u00b7 \u23f1\ufe0f 29.10.2022):\n\n\t```\n\tgit clone https://github.com/SALib/SALib\n\t```\n- [PyPi](https://pypi.org/project/salib) (\ud83d\udce5 270K / month \u00b7 \ud83d\udce6 63 \u00b7 \u23f1\ufe0f 22.06.2022):\n\t```\n\tpip install salib\n\t```\n- [Conda](https://anaconda.org/conda-forge/salib) (\ud83d\udce5 99K \u00b7 \u23f1\ufe0f 19.10.2022):\n\t```\n\tconda install -c conda-forge salib\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jmschrei/pomegranate\">pomegranate</a></b> (\ud83e\udd4928 \u00b7  \u2b50 3K) - Fast, flexible and easy to use probabilistic modelling in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/jmschrei/pomegranate) (\ud83d\udc68\u200d\ud83d\udcbb 66 \u00b7 \ud83d\udd00 540 \u00b7 \ud83d\udce6 780 \u00b7 \ud83d\udccb 690 - 10% open \u00b7 \u23f1\ufe0f 04.07.2022):\n\n\t```\n\tgit clone https://github.com/jmschrei/pomegranate\n\t```\n- [PyPi](https://pypi.org/project/pomegranate) (\ud83d\udce5 55K / month \u00b7 \ud83d\udce6 46 \u00b7 \u23f1\ufe0f 21.02.2022):\n\t```\n\tpip install pomegranate\n\t```\n- [Conda](https://anaconda.org/conda-forge/pomegranate) (\ud83d\udce5 110K \u00b7 \u23f1\ufe0f 19.09.2022):\n\t```\n\tconda install -c conda-forge pomegranate\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/bambinos/bambi\">bambi</a></b> (\ud83e\udd4927 \u00b7  \u2b50 850) - BAyesian Model-Building Interface (Bambi) in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/bambinos/bambi) (\ud83d\udc68\u200d\ud83d\udcbb 26 \u00b7 \ud83d\udd00 92 \u00b7 \ud83d\udce6 43 \u00b7 \ud83d\udccb 290 - 21% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/bambinos/bambi\n\t```\n- [PyPi](https://pypi.org/project/bambi) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 06.06.2022):\n\t```\n\tpip install bambi\n\t```\n- [Conda](https://anaconda.org/conda-forge/bambi) (\ud83d\udce5 15K \u00b7 \u23f1\ufe0f 29.08.2022):\n\t```\n\tconda install -c conda-forge bambi\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/uber/orbit\">Orbit</a></b> (\ud83e\udd4924 \u00b7  \u2b50 1.5K) - A Python package for Bayesian forecasting with object-oriented design.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/uber/orbit) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 380 - 15% open \u00b7 \u23f1\ufe0f 14.09.2022):\n\n\t```\n\tgit clone https://github.com/uber/orbit\n\t```\n- [PyPi](https://pypi.org/project/orbit-ml) (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 28.04.2022):\n\t```\n\tpip install orbit-ml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/baal-org/baal\">Baal</a></b> (\ud83e\udd4918 \u00b7  \u2b50 680) - Library to enable Bayesian active learning in your research or labeling.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/baal-org/baal) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 64 \u00b7 \ud83d\udccb 90 - 24% open \u00b7 \u23f1\ufe0f 19.11.2022):\n\n\t```\n\tgit clone https://github.com/baal-org/baal\n\t```\n- [PyPi](https://pypi.org/project/baal) (\ud83d\udce5 570 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 03.05.2022):\n\t```\n\tpip install baal\n\t```\n- [Conda](https://anaconda.org/conda-forge/baal) (\ud83d\udce5 3.9K \u00b7 \u23f1\ufe0f 31.10.2022):\n\t```\n\tconda install -c conda-forge baal\n\t```\n</details>\n<details><summary>Show 7 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/raphaelvallat/pingouin\">pingouin</a></b> (\ud83e\udd4929 \u00b7  \u2b50 1.2K) - Statistical package in Python based on Pandas. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/blei-lab/edward\">Edward</a></b> (\ud83e\udd4928 \u00b7  \u2b50 4.7K \u00b7 \ud83d\udc80) - A probabilistic programming language in TensorFlow. Deep.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/stan-dev/pystan\">PyStan</a></b> (\ud83e\udd4927 \u00b7  \u2b50 220) - PyStan, a Python interface to Stan, a platform for statistical modeling... <code><a href=\"http://bit.ly/3hkKRql\">ISC</a></code>\n- <b><a href=\"https://github.com/mattjj/pyhsmm\">pyhsmm</a></b> (\ud83e\udd4921 \u00b7  \u2b50 530 \u00b7 \ud83d\udc80) - Bayesian inference in HSMMs and HMMs. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/maximtrp/scikit-posthocs\">scikit-posthocs</a></b> (\ud83e\udd4921 \u00b7  \u2b50 270) - Multiple Pairwise Comparisons (Post Hoc) Tests in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/pyro-ppl/funsor\">Funsor</a></b> (\ud83e\udd4918 \u00b7  \u2b50 200) - Functional tensors for probabilistic programming. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/thu-ml/zhusuan\">ZhuSuan</a></b> (\ud83e\udd4916 \u00b7  \u2b50 2.2K \u00b7 \ud83d\udc80) - A probabilistic programming library for Bayesian deep learning,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Adversarial Robustness\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for testing the robustness of machine learning models against attacks with adversarial/malicious examples._\n\n<details><summary><b><a href=\"https://github.com/Trusted-AI/adversarial-robustness-toolbox\">ART</a></b> (\ud83e\udd4734 \u00b7  \u2b50 3.4K) - Adversarial Robustness Toolbox (ART) - Python Library for Machine Learning.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/Trusted-AI/adversarial-robustness-toolbox) (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 910 \u00b7 \ud83d\udce6 270 \u00b7 \ud83d\udccb 740 - 12% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/Trusted-AI/adversarial-robustness-toolbox\n\t```\n- [PyPi](https://pypi.org/project/adversarial-robustness-toolbox) (\ud83d\udce5 41K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 01.07.2022):\n\t```\n\tpip install adversarial-robustness-toolbox\n\t```\n- [Conda](https://anaconda.org/conda-forge/adversarial-robustness-toolbox) (\ud83d\udce5 18K \u00b7 \u23f1\ufe0f 16.11.2022):\n\t```\n\tconda install -c conda-forge adversarial-robustness-toolbox\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/QData/TextAttack\">TextAttack</a></b> (\ud83e\udd4830 \u00b7  \u2b50 2.1K) - TextAttack is a Python framework for adversarial attacks, data.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/QData/TextAttack) (\ud83d\udc68\u200d\ud83d\udcbb 55 \u00b7 \ud83d\udd00 280 \u00b7 \ud83d\udce6 100 \u00b7 \ud83d\udccb 230 - 10% open \u00b7 \u23f1\ufe0f 06.11.2022):\n\n\t```\n\tgit clone https://github.com/QData/TextAttack\n\t```\n- [PyPi](https://pypi.org/project/textattack) (\ud83d\udce5 9.1K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 25.05.2022):\n\t```\n\tpip install textattack\n\t```\n- [Conda](https://anaconda.org/conda-forge/textattack) (\ud83d\udce5 4.5K \u00b7 \u23f1\ufe0f 29.06.2021):\n\t```\n\tconda install -c conda-forge textattack\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/bethgelab/foolbox\">Foolbox</a></b> (\ud83e\udd4828 \u00b7  \u2b50 2.4K) - A Python toolbox to create adversarial examples that fool neural networks.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/bethgelab/foolbox) (\ud83d\udc68\u200d\ud83d\udcbb 32 \u00b7 \ud83d\udd00 400 \u00b7 \ud83d\udce6 340 \u00b7 \ud83d\udccb 360 - 6% open \u00b7 \u23f1\ufe0f 25.05.2022):\n\n\t```\n\tgit clone https://github.com/bethgelab/foolbox\n\t```\n- [PyPi](https://pypi.org/project/foolbox) (\ud83d\udce5 7.6K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 02.04.2022):\n\t```\n\tpip install foolbox\n\t```\n- [Conda](https://anaconda.org/conda-forge/foolbox) (\ud83d\udce5 8.6K \u00b7 \u23f1\ufe0f 30.04.2021):\n\t```\n\tconda install -c conda-forge foolbox\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/advboxes/AdvBox\">AdvBox</a></b> (\ud83e\udd4919 \u00b7  \u2b50 1.3K) - Advbox is a toolbox to generate adversarial examples that fool neural.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/advboxes/AdvBox) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udccb 38 - 21% open \u00b7 \u23f1\ufe0f 08.08.2022):\n\n\t```\n\tgit clone https://github.com/advboxes/AdvBox\n\t```\n- [PyPi](https://pypi.org/project/advbox) (\ud83d\udce5 29 / month \u00b7 \u23f1\ufe0f 05.12.2018):\n\t```\n\tpip install advbox\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/MadryLab/robustness\">robustness</a></b> (\ud83e\udd4919 \u00b7  \u2b50 750 \u00b7 \ud83d\udca4) - A library for experimenting with, training and evaluating neural.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/MadryLab/robustness) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 89 \u00b7 \ud83d\udccb 76 - 26% open \u00b7 \u23f1\ufe0f 14.02.2022):\n\n\t```\n\tgit clone https://github.com/MadryLab/robustness\n\t```\n- [PyPi](https://pypi.org/project/robustness) (\ud83d\udce5 5.3K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 01.12.2020):\n\t```\n\tpip install robustness\n\t```\n- [Conda](https://anaconda.org/conda-forge/robustness) (\ud83d\udce5 5.2K \u00b7 \u23f1\ufe0f 30.04.2021):\n\t```\n\tconda install -c conda-forge robustness\n\t```\n</details>\n<details><summary>Show 4 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/cleverhans-lab/cleverhans\">CleverHans</a></b> (\ud83e\udd4830 \u00b7  \u2b50 5.7K \u00b7 \ud83d\udc80) - An adversarial example library for constructing attacks,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/BorealisAI/advertorch\">advertorch</a></b> (\ud83e\udd4922 \u00b7  \u2b50 1.1K) - A Toolbox for Adversarial Robustness Research. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/textflint/textflint\">textflint</a></b> (\ud83e\udd4916 \u00b7  \u2b50 580) - Unified Multilingual Robustness Evaluation Toolkit for Natural.. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code>\n- <b><a href=\"https://github.com/airbnb/artificial-adversary\">Adversary</a></b> (\ud83e\udd4914 \u00b7  \u2b50 370 \u00b7 \ud83d\udc80) - Tool to generate adversarial text examples and test machine.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n</details>\n<br>\n\n## GPU & Accelerator Utilities\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries that require and make use of CUDA/GPU or other accelerator hardware capabilities to optimize machine learning tasks._\n\n<details><summary><b><a href=\"https://github.com/cupy/cupy\">CuPy</a></b> (\ud83e\udd4738 \u00b7  \u2b50 6.5K) - NumPy & SciPy for GPU. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/cupy/cupy) (\ud83d\udc68\u200d\ud83d\udcbb 320 \u00b7 \ud83d\udd00 640 \u00b7 \ud83d\udce5 49K \u00b7 \ud83d\udce6 1.3K \u00b7 \ud83d\udccb 1.9K - 23% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/cupy/cupy\n\t```\n- [PyPi](https://pypi.org/project/cupy) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 30.06.2022):\n\t```\n\tpip install cupy\n\t```\n- [Conda](https://anaconda.org/conda-forge/cupy) (\ud83d\udce5 2.1M \u00b7 \u23f1\ufe0f 20.11.2022):\n\t```\n\tconda install -c conda-forge cupy\n\t```\n- [Docker Hub](https://hub.docker.com/r/cupy/cupy) (\ud83d\udce5 56K \u00b7 \u2b50 8 \u00b7 \u23f1\ufe0f 11.11.2022):\n\t```\n\tdocker pull cupy/cupy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rapidsai/cudf\">cuDF</a></b> (\ud83e\udd4731 \u00b7  \u2b50 5.2K) - cuDF - GPU DataFrame Library. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/rapidsai/cudf) (\ud83d\udc68\u200d\ud83d\udcbb 260 \u00b7 \ud83d\udd00 650 \u00b7 \ud83d\udccb 5K - 13% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/rapidsai/cudf\n\t```\n- [PyPi](https://pypi.org/project/cudf) (\ud83d\udce5 1.8K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 01.06.2020):\n\t```\n\tpip install cudf\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/wookayin/gpustat\">gpustat</a></b> (\ud83e\udd4731 \u00b7  \u2b50 3.1K) - A simple command-line utility for querying and monitoring GPU status. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/wookayin/gpustat) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 2.4K \u00b7 \ud83d\udccb 99 - 23% open \u00b7 \u23f1\ufe0f 20.11.2022):\n\n\t```\n\tgit clone https://github.com/wookayin/gpustat\n\t```\n- [PyPi](https://pypi.org/project/gpustat) (\ud83d\udce5 1M / month \u00b7 \ud83d\udce6 120 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install gpustat\n\t```\n- [Conda](https://anaconda.org/conda-forge/gpustat) (\ud83d\udce5 150K \u00b7 \u23f1\ufe0f 11.10.2022):\n\t```\n\tconda install -c conda-forge gpustat\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/inducer/pycuda\">PyCUDA</a></b> (\ud83e\udd4731 \u00b7  \u2b50 1.4K) - CUDA integration for Python, plus shiny features. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/inducer/pycuda) (\ud83d\udc68\u200d\ud83d\udcbb 79 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 1.6K \u00b7 \ud83d\udccb 250 - 31% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/inducer/pycuda\n\t```\n- [PyPi](https://pypi.org/project/pycuda) (\ud83d\udce5 37K / month \u00b7 \ud83d\udce6 200 \u00b7 \u23f1\ufe0f 24.06.2022):\n\t```\n\tpip install pycuda\n\t```\n- [Conda](https://anaconda.org/conda-forge/pycuda) (\ud83d\udce5 140K \u00b7 \u23f1\ufe0f 23.11.2022):\n\t```\n\tconda install -c conda-forge pycuda\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rapidsai/cuml\">cuML</a></b> (\ud83e\udd4829 \u00b7  \u2b50 3K) - cuML - RAPIDS Machine Learning Library. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/rapidsai/cuml) (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 430 \u00b7 \ud83d\udccb 2.1K - 33% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/rapidsai/cuml\n\t```\n- [PyPi](https://pypi.org/project/cuml) (\ud83d\udce5 930 / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 01.06.2020):\n\t```\n\tpip install cuml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/arrayfire/arrayfire\">ArrayFire</a></b> (\ud83e\udd4828 \u00b7  \u2b50 4K) - ArrayFire: a general purpose GPU library. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/arrayfire/arrayfire) (\ud83d\udc68\u200d\ud83d\udcbb 86 \u00b7 \ud83d\udd00 490 \u00b7 \ud83d\udce5 3K \u00b7 \ud83d\udccb 1.6K - 16% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/arrayfire/arrayfire\n\t```\n- [PyPi](https://pypi.org/project/arrayfire) (\ud83d\udce5 650 / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 22.02.2022):\n\t```\n\tpip install arrayfire\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/NVIDIA/apex\">Apex</a></b> (\ud83e\udd4827 \u00b7  \u2b50 6.8K) - A PyTorch Extension: Tools for easy mixed precision and distributed.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/NVIDIA/apex) (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce6 1.3K \u00b7 \ud83d\udccb 1.1K - 55% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/NVIDIA/apex\n\t```\n- [Conda](https://anaconda.org/conda-forge/nvidia-apex) (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 06.04.2022):\n\t```\n\tconda install -c conda-forge nvidia-apex\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/huggingface/optimum\">optimum</a></b> (\ud83e\udd4827 \u00b7  \u2b50 790) - Accelerate training and inference of Transformers with easy to use.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/huggingface/optimum) (\ud83d\udc68\u200d\ud83d\udcbb 31 \u00b7 \ud83d\udd00 84 \u00b7 \ud83d\udce6 50 \u00b7 \ud83d\udccb 160 - 43% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/huggingface/optimum\n\t```\n- [PyPi](https://pypi.org/project/optimum) (\ud83d\udce5 46K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 13.06.2022):\n\t```\n\tpip install optimum\n\t```\n- [Conda](https://anaconda.org/conda-forge/optimum) (\ud83d\udce5 4.8K \u00b7 \u23f1\ufe0f 12.07.2022):\n\t```\n\tconda install -c conda-forge optimum\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rapidsai/cugraph\">cuGraph</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.2K) - cuGraph - RAPIDS Graph Analytics Library. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/rapidsai/cugraph) (\ud83d\udc68\u200d\ud83d\udcbb 91 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udccb 1.1K - 18% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/rapidsai/cugraph\n\t```\n- [PyPi](https://pypi.org/project/cugraph) (\ud83d\udce5 130 / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 01.06.2020):\n\t```\n\tpip install cugraph\n\t```\n- [Conda](https://anaconda.org/conda-forge/libcugraph) (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 29.04.2021):\n\t```\n\tconda install -c conda-forge libcugraph\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/NVIDIA/DALI\">DALI</a></b> (\ud83e\udd4924 \u00b7  \u2b50 4.1K) - A GPU-accelerated library containing highly optimized building blocks.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/NVIDIA/DALI) (\ud83d\udc68\u200d\ud83d\udcbb 79 \u00b7 \ud83d\udd00 530 \u00b7 \ud83d\udccb 1.3K - 17% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/NVIDIA/DALI\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/lebedov/scikit-cuda\">scikit-cuda</a></b> (\ud83e\udd4924 \u00b7  \u2b50 920 \u00b7 \ud83d\udca4) - Python interface to GPU-powered libraries. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/lebedov/scikit-cuda) (\ud83d\udc68\u200d\ud83d\udcbb 46 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udce6 210 \u00b7 \ud83d\udccb 220 - 22% open \u00b7 \u23f1\ufe0f 31.03.2022):\n\n\t```\n\tgit clone https://github.com/lebedov/scikit-cuda\n\t```\n- [PyPi](https://pypi.org/project/scikit-cuda) (\ud83d\udce5 550 / month \u00b7 \ud83d\udce6 44 \u00b7 \u23f1\ufe0f 27.05.2019):\n\t```\n\tpip install scikit-cuda\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/NVIDIA-Merlin/Merlin\">Merlin</a></b> (\ud83e\udd4924 \u00b7  \u2b50 390) - NVIDIA Merlin is an open source library providing end-to-end GPU-.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/NVIDIA-Merlin/Merlin) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 65 \u00b7 \ud83d\udccb 300 - 46% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/NVIDIA-Merlin/Merlin\n\t```\n- [PyPi](https://pypi.org/project/merlin-core) (\ud83d\udce5 9.7K / month \u00b7 \u23f1\ufe0f 14.06.2022):\n\t```\n\tpip install merlin-core\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/KomputeProject/kompute\">Vulkan Kompute</a></b> (\ud83e\udd4920 \u00b7  \u2b50 1K) - General purpose GPU compute framework built on Vulkan to.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/KomputeProject/kompute) (\ud83d\udc68\u200d\ud83d\udcbb 20 \u00b7 \ud83d\udd00 69 \u00b7 \ud83d\udce5 210 \u00b7 \ud83d\udce6 5 \u00b7 \ud83d\udccb 180 - 32% open \u00b7 \u23f1\ufe0f 20.11.2022):\n\n\t```\n\tgit clone https://github.com/KomputeProject/kompute\n\t```\n- [PyPi](https://pypi.org/project/kp) (\ud83d\udce5 82 / month \u00b7 \u23f1\ufe0f 13.04.2022):\n\t```\n\tpip install kp\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rapidsai/cusignal\">cuSignal</a></b> (\ud83e\udd4919 \u00b7  \u2b50 640) - GPU accelerated signal processing. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/rapidsai/cusignal) (\ud83d\udc68\u200d\ud83d\udcbb 42 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udccb 140 - 11% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/rapidsai/cusignal\n\t```\n</details>\n<details><summary>Show 6 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/BlazingDB/blazingsql\">BlazingSQL</a></b> (\ud83e\udd4922 \u00b7  \u2b50 1.8K \u00b7 \ud83d\udc80) - BlazingSQL is a lightweight, GPU accelerated, SQL engine for.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n- <b><a href=\"https://github.com/anderskm/gputil\">GPUtil</a></b> (\ud83e\udd4922 \u00b7  \u2b50 920 \u00b7 \ud83d\udc80) - A Python module for getting the GPU status from NVIDA GPUs using.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/fbcotter/py3nvml\">py3nvml</a></b> (\ud83e\udd4922 \u00b7  \u2b50 210 \u00b7 \ud83d\udca4) - Python 3 Bindings for NVML library. Get NVIDIA GPU status inside.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/nicolargo/nvidia-ml-py3\">nvidia-ml-py3</a></b> (\ud83e\udd4920 \u00b7  \u2b50 92 \u00b7 \ud83d\udc80) - Python 3 Bindings for the NVIDIA Management Library. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/Santosh-Gupta/SpeedTorch\">SpeedTorch</a></b> (\ud83e\udd4915 \u00b7  \u2b50 660 \u00b7 \ud83d\udc80) - Library for faster pinned CPU - GPU transfer in Pytorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/stas00/ipyexperiments\">ipyexperiments</a></b> (\ud83e\udd4914 \u00b7  \u2b50 150 \u00b7 \ud83d\udca4) - jupyter/ipython experiment containers for GPU and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Tensorflow Utilities\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries that extend TensorFlow with additional capabilities._\n\n<details><summary><b><a href=\"https://github.com/tensorflow/datasets\">TensorFlow Datasets</a></b> (\ud83e\udd4736 \u00b7  \u2b50 3.5K) - TFDS is a collection of datasets ready to use with.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/datasets) (\ud83d\udc68\u200d\ud83d\udcbb 270 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udccb 1.3K - 50% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/datasets\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-datasets) (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 02.06.2022):\n\t```\n\tpip install tensorflow-datasets\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensorflow-datasets) (\ud83d\udce5 10K \u00b7 \u23f1\ufe0f 06.10.2022):\n\t```\n\tconda install -c conda-forge tensorflow-datasets\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/hub\">tensorflow-hub</a></b> (\ud83e\udd4736 \u00b7  \u2b50 3.2K) - A library for transfer learning by reusing parts of.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/hub) (\ud83d\udc68\u200d\ud83d\udcbb 98 \u00b7 \ud83d\udd00 1.7K \u00b7 \ud83d\udce6 14K \u00b7 \ud83d\udccb 670 - 2% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/hub\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-hub) (\ud83d\udce5 4.1M / month \u00b7 \ud83d\udce6 300 \u00b7 \u23f1\ufe0f 14.04.2021):\n\t```\n\tpip install tensorflow-hub\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensorflow-hub) (\ud83d\udce5 72K \u00b7 \u23f1\ufe0f 18.04.2021):\n\t```\n\tconda install -c conda-forge tensorflow-hub\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/addons\">TF Addons</a></b> (\ud83e\udd4835 \u00b7  \u2b50 1.6K) - Useful extra functionality for TensorFlow 2.x maintained by.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/addons) (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 590 \u00b7 \ud83d\udce6 7.8K \u00b7 \ud83d\udccb 970 - 25% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/addons\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-addons) (\ud83d\udce5 1.3M / month \u00b7 \ud83d\udce6 180 \u00b7 \u23f1\ufe0f 14.06.2022):\n\t```\n\tpip install tensorflow-addons\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/tensor2tensor\">tensor2tensor</a></b> (\ud83e\udd4833 \u00b7  \u2b50 13K) - Library of deep learning models and datasets designed to.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/tensor2tensor) (\ud83d\udc68\u200d\ud83d\udcbb 240 \u00b7 \ud83d\udd00 3.1K \u00b7 \ud83d\udce6 1.2K \u00b7 \ud83d\udccb 1.3K - 46% open \u00b7 \u23f1\ufe0f 24.10.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/tensor2tensor\n\t```\n- [PyPi](https://pypi.org/project/tensor2tensor) (\ud83d\udce5 11K / month \u00b7 \ud83d\udce6 93 \u00b7 \u23f1\ufe0f 17.06.2020):\n\t```\n\tpip install tensor2tensor\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/tfx\">TFX</a></b> (\ud83e\udd4833 \u00b7  \u2b50 1.9K) - TFX is an end-to-end platform for deploying production ML pipelines. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/tfx) (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 620 \u00b7 \ud83d\udccb 850 - 26% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/tfx\n\t```\n- [PyPi](https://pypi.org/project/tfx) (\ud83d\udce5 380K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 26.05.2022):\n\t```\n\tpip install tfx\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/transform\">TensorFlow Transform</a></b> (\ud83e\udd4833 \u00b7  \u2b50 940) - Input pipeline framework. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/transform) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce6 1.1K \u00b7 \ud83d\udccb 190 - 19% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/transform\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-transform) (\ud83d\udce5 4.2M / month \u00b7 \ud83d\udce6 56 \u00b7 \u23f1\ufe0f 29.06.2022):\n\t```\n\tpip install tensorflow-transform\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/model-optimization\">TF Model Optimization</a></b> (\ud83e\udd4832 \u00b7  \u2b50 1.3K) - A toolkit to optimize ML models for deployment for.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/model-optimization) (\ud83d\udc68\u200d\ud83d\udcbb 74 \u00b7 \ud83d\udd00 300 \u00b7 \ud83d\udce6 2.3K \u00b7 \ud83d\udccb 340 - 53% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/model-optimization\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-model-optimization) (\ud83d\udce5 160K / month \u00b7 \ud83d\udce6 21 \u00b7 \u23f1\ufe0f 18.03.2022):\n\t```\n\tpip install tensorflow-model-optimization\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/keras-team/keras-preprocessing\">Keras-Preprocessing</a></b> (\ud83e\udd4929 \u00b7  \u2b50 1K \u00b7 \ud83d\udca4) - Utilities for working with image data, text data, and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/keras-team/keras-preprocessing) (\ud83d\udc68\u200d\ud83d\udcbb 52 \u00b7 \ud83d\udd00 440 \u00b7 \ud83d\udccb 200 - 47% open \u00b7 \u23f1\ufe0f 17.02.2022):\n\n\t```\n\tgit clone https://github.com/keras-team/keras-preprocessing\n\t```\n- [PyPi](https://pypi.org/project/keras-preprocessing) (\ud83d\udce5 8.5M / month \u00b7 \ud83d\udce6 1.5K \u00b7 \u23f1\ufe0f 14.05.2020):\n\t```\n\tpip install keras-preprocessing\n\t```\n- [Conda](https://anaconda.org/conda-forge/keras-preprocessing) (\ud83d\udce5 1.6M \u00b7 \u23f1\ufe0f 15.01.2021):\n\t```\n\tconda install -c conda-forge keras-preprocessing\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/io\">TensorFlow I/O</a></b> (\ud83e\udd4929 \u00b7  \u2b50 590) - Dataset, streaming, and file system extensions.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/io) (\ud83d\udc68\u200d\ud83d\udcbb 95 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udccb 560 - 38% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/io\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-io) (\ud83d\udce5 760K / month \u00b7 \ud83d\udce6 25 \u00b7 \u23f1\ufe0f 18.05.2022):\n\t```\n\tpip install tensorflow-io\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/neural-structured-learning\">Neural Structured Learning</a></b> (\ud83e\udd4928 \u00b7  \u2b50 950) - Training neural models with structured signals. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/neural-structured-learning) (\ud83d\udc68\u200d\ud83d\udcbb 36 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 280 \u00b7 \ud83d\udccb 68 - 4% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/neural-structured-learning\n\t```\n- [PyPi](https://pypi.org/project/neural-structured-learning) (\ud83d\udce5 15K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 18.08.2020):\n\t```\n\tpip install neural-structured-learning\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/cloud\">TensorFlow Cloud</a></b> (\ud83e\udd4925 \u00b7  \u2b50 330) - The TensorFlow Cloud repository provides APIs that.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/cloud) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 72 \u00b7 \ud83d\udce6 180 \u00b7 \ud83d\udccb 87 - 68% open \u00b7 \u23f1\ufe0f 11.10.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/cloud\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-cloud) (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 17.06.2021):\n\t```\n\tpip install tensorflow-cloud\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PAIR-code/saliency\">Saliency</a></b> (\ud83e\udd4923 \u00b7  \u2b50 840) - Framework-agnostic implementation for state-of-the-art saliency.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/PAIR-code/saliency) (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 47 \u00b7 \ud83d\udccb 29 - 10% open \u00b7 \u23f1\ufe0f 13.05.2022):\n\n\t```\n\tgit clone https://github.com/PAIR-code/saliency\n\t```\n- [PyPi](https://pypi.org/project/saliency) (\ud83d\udce5 2.1K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 14.06.2022):\n\t```\n\tpip install saliency\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorflow/compression\">TF Compression</a></b> (\ud83e\udd4922 \u00b7  \u2b50 690) - Data compression in TensorFlow. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/tensorflow/compression) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udccb 93 - 3% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorflow/compression\n\t```\n- [PyPi](https://pypi.org/project/tensorflow-compression) (\ud83d\udce5 6.8K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 30.05.2022):\n\t```\n\tpip install tensorflow-compression\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/geffy/tffm\">tffm</a></b> (\ud83e\udd4920 \u00b7  \u2b50 780 \u00b7 \ud83d\udca4) - TensorFlow implementation of an arbitrary order Factorization Machine. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/geffy/tffm) (\ud83d\udc68\u200d\ud83d\udcbb 10 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 11 \u00b7 \ud83d\udccb 40 - 45% open \u00b7 \u23f1\ufe0f 17.01.2022):\n\n\t```\n\tgit clone https://github.com/geffy/tffm\n\t```\n- [PyPi](https://pypi.org/project/tffm) (\ud83d\udce5 1.5K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 17.01.2022):\n\t```\n\tpip install tffm\n\t```\n</details>\n<details><summary>Show 2 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/qubvel/efficientnet\">efficientnet</a></b> (\ud83e\udd4925 \u00b7  \u2b50 2K \u00b7 \ud83d\udc80) - Implementation of EfficientNet model. Keras and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/taehoonlee/tensornets\">TensorNets</a></b> (\ud83e\udd4920 \u00b7  \u2b50 1K \u00b7 \ud83d\udc80) - High level network definitions with pre-trained weights in.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Jax Utilities\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries that extend Jax with additional capabilities._\n\n<details><summary><b><a href=\"https://github.com/patrick-kidger/equinox\">equinox</a></b> (\ud83e\udd4725 \u00b7  \u2b50 870) - Callable PyTrees and filtered transforms = neural networks in.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/patrick-kidger/equinox) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 46 \u00b7 \ud83d\udce6 68 \u00b7 \ud83d\udccb 120 - 22% open \u00b7 \u23f1\ufe0f 18.11.2022):\n\n\t```\n\tgit clone https://github.com/patrick-kidger/equinox\n\t```\n- [PyPi](https://pypi.org/project/equinox) (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install equinox\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/evojax\">evojax</a></b> (\ud83e\udd4919 \u00b7  \u2b50 580) - EvoJAX: Hardware-accelerated Neuroevolution. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/google/evojax) (\ud83d\udc68\u200d\ud83d\udcbb 12 \u00b7 \ud83d\udd00 48 \u00b7 \ud83d\udce6 1 \u00b7 \ud83d\udccb 14 - 28% open \u00b7 \u23f1\ufe0f 07.11.2022):\n\n\t```\n\tgit clone https://github.com/google/evojax\n\t```\n- [PyPi](https://pypi.org/project/evojax) (\ud83d\udce5 760 / month \u00b7 \u23f1\ufe0f 15.06.2022):\n\t```\n\tpip install evojax\n\t```\n- [Conda](https://anaconda.org/conda-forge/evojax) (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 05.10.2022):\n\t```\n\tconda install -c conda-forge evojax\n\t```\n</details>\n<details><summary>Show 1 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/ucl-bug/jaxdf\">jaxdf</a></b> (\ud83e\udd499 \u00b7  \u2b50 63) - A JAX-based research framework for writing differentiable.. <code><a href=\"http://bit.ly/37RvQcA\">\u2757\ufe0fLGPL-3.0</a></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Sklearn Utilities\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries that extend scikit-learn with additional capabilities._\n\n<details><summary><b><a href=\"https://github.com/rasbt/mlxtend\">MLxtend</a></b> (\ud83e\udd4736 \u00b7  \u2b50 4.2K) - A library of extension and helper modules for Pythons data.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/rasbt/mlxtend) (\ud83d\udc68\u200d\ud83d\udcbb 90 \u00b7 \ud83d\udd00 780 \u00b7 \ud83d\udce6 7.3K \u00b7 \ud83d\udccb 450 - 28% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/rasbt/mlxtend\n\t```\n- [PyPi](https://pypi.org/project/mlxtend) (\ud83d\udce5 1.9M / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 27.05.2022):\n\t```\n\tpip install mlxtend\n\t```\n- [Conda](https://anaconda.org/conda-forge/mlxtend) (\ud83d\udce5 240K \u00b7 \u23f1\ufe0f 17.09.2022):\n\t```\n\tconda install -c conda-forge mlxtend\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/scikit-learn-contrib/imbalanced-learn\">imbalanced-learn</a></b> (\ud83e\udd4734 \u00b7  \u2b50 6.2K) - A Python Package to Tackle the Curse of Imbalanced.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/scikit-learn-contrib/imbalanced-learn) (\ud83d\udc68\u200d\ud83d\udcbb 63 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udce6 13K \u00b7 \ud83d\udccb 530 - 11% open \u00b7 \u23f1\ufe0f 16.05.2022):\n\n\t```\n\tgit clone https://github.com/scikit-learn-contrib/imbalanced-learn\n\t```\n- [PyPi](https://pypi.org/project/imbalanced-learn) (\ud83d\udce5 3.5M / month \u00b7 \ud83d\udce6 270 \u00b7 \u23f1\ufe0f 16.05.2022):\n\t```\n\tpip install imbalanced-learn\n\t```\n- [Conda](https://anaconda.org/conda-forge/imbalanced-learn) (\ud83d\udce5 300K \u00b7 \u23f1\ufe0f 16.05.2022):\n\t```\n\tconda install -c conda-forge imbalanced-learn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/scikit-learn-contrib/category_encoders\">category_encoders</a></b> (\ud83e\udd4734 \u00b7  \u2b50 2.1K) - A library of sklearn compatible categorical variable.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/scikit-learn-contrib/category_encoders) (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 370 \u00b7 \ud83d\udce6 4.1K \u00b7 \ud83d\udccb 260 - 23% open \u00b7 \u23f1\ufe0f 20.11.2022):\n\n\t```\n\tgit clone https://github.com/scikit-learn-contrib/category_encoders\n\t```\n- [PyPi](https://pypi.org/project/category_encoders) (\ud83d\udce5 950K / month \u00b7 \ud83d\udce6 120 \u00b7 \u23f1\ufe0f 02.06.2022):\n\t```\n\tpip install category_encoders\n\t```\n- [Conda](https://anaconda.org/conda-forge/category_encoders) (\ud83d\udce5 200K \u00b7 \u23f1\ufe0f 06.10.2022):\n\t```\n\tconda install -c conda-forge category_encoders\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/intel/scikit-learn-intelex\">scikit-learn-intelex</a></b> (\ud83e\udd4830 \u00b7  \u2b50 840) - Intel(R) Extension for Scikit-learn is a seamless way.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/intel/scikit-learn-intelex) (\ud83d\udc68\u200d\ud83d\udcbb 60 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 3.5K \u00b7 \ud83d\udccb 210 - 53% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/intel/scikit-learn-intelex\n\t```\n- [PyPi](https://pypi.org/project/scikit-learn-intelex) (\ud83d\udce5 110K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 16.06.2022):\n\t```\n\tpip install scikit-learn-intelex\n\t```\n- [Conda](https://anaconda.org/conda-forge/scikit-learn-intelex) (\ud83d\udce5 95K \u00b7 \u23f1\ufe0f 20.09.2022):\n\t```\n\tconda install -c conda-forge scikit-learn-intelex\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/scikit-multilearn/scikit-multilearn\">scikit-multilearn</a></b> (\ud83e\udd4827 \u00b7  \u2b50 800) - A scikit-learn based module for multi-label et. al... <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/scikit-multilearn/scikit-multilearn) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 150 \u00b7 \ud83d\udce6 890 \u00b7 \ud83d\udccb 200 - 53% open \u00b7 \u23f1\ufe0f 09.07.2022):\n\n\t```\n\tgit clone https://github.com/scikit-multilearn/scikit-multilearn\n\t```\n- [PyPi](https://pypi.org/project/scikit-multilearn) (\ud83d\udce5 100K / month \u00b7 \ud83d\udce6 18 \u00b7 \u23f1\ufe0f 10.12.2018):\n\t```\n\tpip install scikit-multilearn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/koaning/scikit-lego\">scikit-lego</a></b> (\ud83e\udd4925 \u00b7  \u2b50 930) - Extra blocks for scikit-learn pipelines. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/koaning/scikit-lego) (\ud83d\udc68\u200d\ud83d\udcbb 56 \u00b7 \ud83d\udd00 99 \u00b7 \ud83d\udce6 69 \u00b7 \ud83d\udccb 260 - 9% open \u00b7 \u23f1\ufe0f 02.11.2022):\n\n\t```\n\tgit clone https://github.com/koaning/scikit-lego\n\t```\n- [PyPi](https://pypi.org/project/scikit-lego) (\ud83d\udce5 28K / month \u00b7 \ud83d\udce6 7 \u00b7 \u23f1\ufe0f 05.06.2022):\n\t```\n\tpip install scikit-lego\n\t```\n- [Conda](https://anaconda.org/conda-forge/scikit-lego) (\ud83d\udce5 28K \u00b7 \u23f1\ufe0f 03.11.2022):\n\t```\n\tconda install -c conda-forge scikit-lego\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/guofei9987/scikit-opt\">scikit-opt</a></b> (\ud83e\udd4924 \u00b7  \u2b50 3.7K) - Genetic Algorithm, Particle Swarm Optimization, Simulated.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/guofei9987/scikit-opt) (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 840 \u00b7 \ud83d\udce6 91 \u00b7 \ud83d\udccb 160 - 32% open \u00b7 \u23f1\ufe0f 15.07.2022):\n\n\t```\n\tgit clone https://github.com/guofei9987/scikit-opt\n\t```\n- [PyPi](https://pypi.org/project/scikit-opt) (\ud83d\udce5 2.7K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 14.01.2022):\n\t```\n\tpip install scikit-opt\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/scikit-learn-contrib/lightning\">sklearn-contrib-lightning</a></b> (\ud83e\udd4923 \u00b7  \u2b50 1.6K \u00b7 \ud83d\udca4) - Large-scale linear classification, regression and.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/scikit-learn-contrib/lightning) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 210 \u00b7 \ud83d\udce5 240 \u00b7 \ud83d\udce6 110 \u00b7 \ud83d\udccb 96 - 56% open \u00b7 \u23f1\ufe0f 30.01.2022):\n\n\t```\n\tgit clone https://github.com/scikit-learn-contrib/lightning\n\t```\n- [PyPi](https://pypi.org/project/sklearn-contrib-lightning) (\ud83d\udce5 2K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 30.01.2022):\n\t```\n\tpip install sklearn-contrib-lightning\n\t```\n- [Conda](https://anaconda.org/conda-forge/sklearn-contrib-lightning) (\ud83d\udce5 180K \u00b7 \u23f1\ufe0f 31.10.2022):\n\t```\n\tconda install -c conda-forge sklearn-contrib-lightning\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/trent-b/iterative-stratification\">iterative-stratification</a></b> (\ud83e\udd4921 \u00b7  \u2b50 730) - scikit-learn cross validators for iterative.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/trent-b/iterative-stratification) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 66 \u00b7 \ud83d\udce6 240 \u00b7 \ud83d\udccb 23 - 17% open \u00b7 \u23f1\ufe0f 06.06.2022):\n\n\t```\n\tgit clone https://github.com/trent-b/iterative-stratification\n\t```\n- [PyPi](https://pypi.org/project/iterative-stratification) (\ud83d\udce5 67K / month \u00b7 \ud83d\udce6 10 \u00b7 \u23f1\ufe0f 03.10.2021):\n\t```\n\tpip install iterative-stratification\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/yzhao062/combo\">combo</a></b> (\ud83e\udd4921 \u00b7  \u2b50 600) - (AAAI 20) A Python Toolbox for Machine Learning Model Combination. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code>xgboost</code></summary>\n\n- [GitHub](https://github.com/yzhao062/combo) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 500 \u00b7 \ud83d\udccb 14 - 78% open \u00b7 \u23f1\ufe0f 07.07.2022):\n\n\t```\n\tgit clone https://github.com/yzhao062/combo\n\t```\n- [PyPi](https://pypi.org/project/combo) (\ud83d\udce5 57K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 02.04.2022):\n\t```\n\tpip install combo\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/scikit-learn-contrib/DESlib\">DESlib</a></b> (\ud83e\udd4918 \u00b7  \u2b50 420) - A Python library for dynamic classifier and ensemble selection. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/scikit-learn-contrib/DESlib) (\ud83d\udc68\u200d\ud83d\udcbb 14 \u00b7 \ud83d\udd00 73 \u00b7 \ud83d\udce6 35 \u00b7 \ud83d\udccb 150 - 10% open \u00b7 \u23f1\ufe0f 07.06.2022):\n\n\t```\n\tgit clone https://github.com/scikit-learn-contrib/DESlib\n\t```\n- [PyPi](https://pypi.org/project/deslib) (\ud83d\udce5 780 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 08.02.2021):\n\t```\n\tpip install deslib\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/scikit-tda/scikit-tda\">scikit-tda</a></b> (\ud83e\udd4916 \u00b7  \u2b50 370 \u00b7 \ud83d\udca4) - Topological Data Analysis for Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/scikit-tda/scikit-tda) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 45 \u00b7 \ud83d\udce6 36 \u00b7 \ud83d\udccb 19 - 78% open \u00b7 \u23f1\ufe0f 13.03.2022):\n\n\t```\n\tgit clone https://github.com/scikit-tda/scikit-tda\n\t```\n- [PyPi](https://pypi.org/project/scikit-tda) (\ud83d\udce5 810 / month \u00b7 \u23f1\ufe0f 03.08.2021):\n\t```\n\tpip install scikit-tda\n\t```\n</details>\n<details><summary>Show 7 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/sebp/scikit-survival\">scikit-survival</a></b> (\ud83e\udd4827 \u00b7  \u2b50 860) - Survival analysis built on top of scikit-learn. <code><a href=\"http://bit.ly/2M0xdwT\">\u2757\ufe0fGPL-3.0</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/iskandr/fancyimpute\">fancyimpute</a></b> (\ud83e\udd4826 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - Multivariate imputation and matrix completion.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/TeamHG-Memex/sklearn-crfsuite\">sklearn-crfsuite</a></b> (\ud83e\udd4826 \u00b7  \u2b50 410 \u00b7 \ud83d\udc80) - scikit-learn inspired API for CRFsuite. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/scikit-learn-contrib/skope-rules\">skope-rules</a></b> (\ud83e\udd4921 \u00b7  \u2b50 490 \u00b7 \ud83d\udc80) - machine learning with logical rules in Python. <code><a href=\"https://tldrlegal.com/search?q=BSD-1-Clause\">\u2757\ufe0fBSD-1-Clause</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/mathurinm/celer\">celer</a></b> (\ud83e\udd4920 \u00b7  \u2b50 170) - Fast solver for L1-type problems: Lasso, sparse Logisitic regression,.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/skggm/skggm\">skggm</a></b> (\ud83e\udd4917 \u00b7  \u2b50 210 \u00b7 \ud83d\udca4) - Scikit-learn compatible estimation of general graphical models. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/amueller/dabl\">dabl</a></b> (\ud83e\udd4917 \u00b7  \u2b50 120 \u00b7 \ud83d\udc80) - Data Analysis Baseline Library. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Pytorch Utilities\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries that extend Pytorch with additional capabilities._\n\n<details><summary><b><a href=\"https://github.com/huggingface/accelerate\">accelerate</a></b> (\ud83e\udd4734 \u00b7  \u2b50 3.2K) - A simple way to train and use PyTorch models with multi-.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/huggingface/accelerate) (\ud83d\udc68\u200d\ud83d\udcbb 73 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 1.5K \u00b7 \ud83d\udccb 420 - 10% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/huggingface/accelerate\n\t```\n- [PyPi](https://pypi.org/project/accelerate) (\ud83d\udce5 800K / month \u00b7 \ud83d\udce6 23 \u00b7 \u23f1\ufe0f 15.06.2022):\n\t```\n\tpip install accelerate\n\t```\n- [Conda](https://anaconda.org/conda-forge/accelerate) (\ud83d\udce5 11K \u00b7 \u23f1\ufe0f 13.11.2022):\n\t```\n\tconda install -c conda-forge accelerate\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/KevinMusgrave/pytorch-metric-learning\">PML</a></b> (\ud83e\udd4731 \u00b7  \u2b50 4.9K) - The easiest way to use deep metric learning in your application. Modular,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/KevinMusgrave/pytorch-metric-learning) (\ud83d\udc68\u200d\ud83d\udcbb 29 \u00b7 \ud83d\udd00 590 \u00b7 \ud83d\udce6 390 \u00b7 \ud83d\udccb 400 - 13% open \u00b7 \u23f1\ufe0f 01.11.2022):\n\n\t```\n\tgit clone https://github.com/KevinMusgrave/pytorch-metric-learning\n\t```\n- [PyPi](https://pypi.org/project/pytorch-metric-learning) (\ud83d\udce5 150K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 29.06.2022):\n\t```\n\tpip install pytorch-metric-learning\n\t```\n- [Conda](https://anaconda.org/metric-learning/pytorch-metric-learning) (\ud83d\udce5 9K \u00b7 \u23f1\ufe0f 01.11.2022):\n\t```\n\tconda install -c metric-learning pytorch-metric-learning\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rtqichen/torchdiffeq\">torchdiffeq</a></b> (\ud83e\udd4729 \u00b7  \u2b50 4.3K) - Differentiable ODE solvers with full GPU support and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/rtqichen/torchdiffeq) (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 740 \u00b7 \ud83d\udce6 540 \u00b7 \ud83d\udccb 180 - 22% open \u00b7 \u23f1\ufe0f 10.08.2022):\n\n\t```\n\tgit clone https://github.com/rtqichen/torchdiffeq\n\t```\n- [PyPi](https://pypi.org/project/torchdiffeq) (\ud83d\udce5 720K / month \u00b7 \ud83d\udce6 20 \u00b7 \u23f1\ufe0f 22.04.2022):\n\t```\n\tpip install torchdiffeq\n\t```\n- [Conda](https://anaconda.org/conda-forge/torchdiffeq) (\ud83d\udce5 8.4K \u00b7 \u23f1\ufe0f 03.06.2021):\n\t```\n\tconda install -c conda-forge torchdiffeq\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Lightning-AI/lightning-flash\">lightning-flash</a></b> (\ud83e\udd4828 \u00b7  \u2b50 1.6K) - Your PyTorch AI Factory - Flash enables you to easily.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/Lightning-AI/lightning-flash) (\ud83d\udc68\u200d\ud83d\udcbb 80 \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 490 - 4% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/Lightning-AI/lightning-flash\n\t```\n- [PyPi](https://pypi.org/project/lightning-flash) (\ud83d\udce5 3.8K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 11.05.2022):\n\t```\n\tpip install lightning-flash\n\t```\n- [Conda](https://anaconda.org/conda-forge/lightning-flash) (\ud83d\udce5 8.4K \u00b7 \u23f1\ufe0f 08.11.2022):\n\t```\n\tconda install -c conda-forge lightning-flash\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jettify/pytorch-optimizer\">pytorch-optimizer</a></b> (\ud83e\udd4827 \u00b7  \u2b50 2.6K \u00b7 \ud83d\udca4) - torch-optimizer -- collection of optimizers for.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/jettify/pytorch-optimizer) (\ud83d\udc68\u200d\ud83d\udcbb 25 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 740 \u00b7 \ud83d\udccb 54 - 44% open \u00b7 \u23f1\ufe0f 11.11.2021):\n\n\t```\n\tgit clone https://github.com/jettify/pytorch-optimizer\n\t```\n- [PyPi](https://pypi.org/project/torch_optimizer) (\ud83d\udce5 58K / month \u00b7 \ud83d\udce6 23 \u00b7 \u23f1\ufe0f 31.10.2021):\n\t```\n\tpip install torch_optimizer\n\t```\n- [Conda](https://anaconda.org/conda-forge/torch-optimizer) (\ud83d\udce5 5.9K \u00b7 \u23f1\ufe0f 31.10.2021):\n\t```\n\tconda install -c conda-forge torch-optimizer\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rusty1s/pytorch_scatter\">torch-scatter</a></b> (\ud83e\udd4826 \u00b7  \u2b50 1.1K) - PyTorch Extension Library of Optimized Scatter Operations. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/rusty1s/pytorch_scatter) (\ud83d\udc68\u200d\ud83d\udcbb 23 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udccb 290 - 7% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/rusty1s/pytorch_scatter\n\t```\n- [PyPi](https://pypi.org/project/torch-scatter) (\ud83d\udce5 38K / month \u00b7 \ud83d\udce6 53 \u00b7 \u23f1\ufe0f 22.10.2021):\n\t```\n\tpip install torch-scatter\n\t```\n- [Conda](https://anaconda.org/conda-forge/pytorch_scatter) (\ud83d\udce5 130K \u00b7 \u23f1\ufe0f 28.07.2022):\n\t```\n\tconda install -c conda-forge pytorch_scatter\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/geohot/tinygrad\">tinygrad</a></b> (\ud83e\udd4825 \u00b7  \u2b50 9.2K) - You like pytorch? You like micrograd? You love tinygrad!. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/geohot/tinygrad) (\ud83d\udc68\u200d\ud83d\udcbb 70 \u00b7 \ud83d\udd00 810 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 130 - 14% open \u00b7 \u23f1\ufe0f 15.11.2022):\n\n\t```\n\tgit clone https://github.com/geohot/tinygrad\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rusty1s/pytorch_sparse\">PyTorch Sparse</a></b> (\ud83e\udd4825 \u00b7  \u2b50 740) - PyTorch Extension Library of Optimized Autograd Sparse.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/rusty1s/pytorch_sparse) (\ud83d\udc68\u200d\ud83d\udcbb 34 \u00b7 \ud83d\udd00 120 \u00b7 \ud83d\udccb 220 - 15% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/rusty1s/pytorch_sparse\n\t```\n- [PyPi](https://pypi.org/project/torch-sparse) (\ud83d\udce5 34K / month \u00b7 \ud83d\udce6 47 \u00b7 \u23f1\ufe0f 30.06.2022):\n\t```\n\tpip install torch-sparse\n\t```\n- [Conda](https://anaconda.org/conda-forge/pytorch_sparse) (\ud83d\udce5 150K \u00b7 \u23f1\ufe0f 23.08.2022):\n\t```\n\tconda install -c conda-forge pytorch_sparse\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dreamquark-ai/tabnet\">TabNet</a></b> (\ud83e\udd4824 \u00b7  \u2b50 1.9K) - PyTorch implementation of TabNet paper :.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/dreamquark-ai/tabnet) (\ud83d\udc68\u200d\ud83d\udcbb 19 \u00b7 \ud83d\udd00 390 \u00b7 \ud83d\udccb 270 - 15% open \u00b7 \u23f1\ufe0f 27.06.2022):\n\n\t```\n\tgit clone https://github.com/dreamquark-ai/tabnet\n\t```\n- [PyPi](https://pypi.org/project/pytorch-tabnet) (\ud83d\udce5 42K / month \u00b7 \ud83d\udce6 9 \u00b7 \u23f1\ufe0f 02.02.2021):\n\t```\n\tpip install pytorch-tabnet\n\t```\n- [Conda](https://anaconda.org/conda-forge/pytorch-tabnet) (\ud83d\udce5 2.5K \u00b7 \u23f1\ufe0f 30.12.2021):\n\t```\n\tconda install -c conda-forge pytorch-tabnet\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/BloodAxe/pytorch-toolbelt\">Pytorch Toolbelt</a></b> (\ud83e\udd4824 \u00b7  \u2b50 1.3K) - PyTorch extensions for fast R&D prototyping and Kaggle.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/BloodAxe/pytorch-toolbelt) (\ud83d\udc68\u200d\ud83d\udcbb 7 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udccb 27 - 11% open \u00b7 \u23f1\ufe0f 25.10.2022):\n\n\t```\n\tgit clone https://github.com/BloodAxe/pytorch-toolbelt\n\t```\n- [PyPi](https://pypi.org/project/pytorch_toolbelt) (\ud83d\udce5 6.2K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 27.06.2022):\n\t```\n\tpip install pytorch_toolbelt\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/lucidrains/reformer-pytorch\">reformer-pytorch</a></b> (\ud83e\udd4920 \u00b7  \u2b50 1.8K) - Reformer, the efficient Transformer, in Pytorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/lucidrains/reformer-pytorch) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 240 \u00b7 \ud83d\udccb 120 - 11% open \u00b7 \u23f1\ufe0f 24.06.2022):\n\n\t```\n\tgit clone https://github.com/lucidrains/reformer-pytorch\n\t```\n- [PyPi](https://pypi.org/project/reformer-pytorch) (\ud83d\udce5 1.4K / month \u00b7 \u23f1\ufe0f 06.11.2021):\n\t```\n\tpip install reformer-pytorch\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/harvardnlp/pytorch-struct\">Torch-Struct</a></b> (\ud83e\udd4919 \u00b7  \u2b50 1K \u00b7 \ud83d\udca4) - Fast, general, and tested differentiable structured.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/harvardnlp/pytorch-struct) (\ud83d\udc68\u200d\ud83d\udcbb 16 \u00b7 \ud83d\udd00 85 \u00b7 \ud83d\udccb 54 - 44% open \u00b7 \u23f1\ufe0f 30.01.2022):\n\n\t```\n\tgit clone https://github.com/harvardnlp/pytorch-struct\n\t```\n- [PyPi](https://pypi.org/project/torch-struct) (\ud83d\udce5 69K / month \u00b7 \u23f1\ufe0f 14.02.2021):\n\t```\n\tpip install torch-struct\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/lucidrains/performer-pytorch\">Performer Pytorch</a></b> (\ud83e\udd4919 \u00b7  \u2b50 890 \u00b7 \ud83d\udca4) - An implementation of Performer, a linear attention-.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/lucidrains/performer-pytorch) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 130 \u00b7 \ud83d\udce6 66 \u00b7 \ud83d\udccb 79 - 45% open \u00b7 \u23f1\ufe0f 02.02.2022):\n\n\t```\n\tgit clone https://github.com/lucidrains/performer-pytorch\n\t```\n- [PyPi](https://pypi.org/project/performer-pytorch) (\ud83d\udce5 5.7K / month \u00b7 \ud83d\udce6 4 \u00b7 \u23f1\ufe0f 02.02.2022):\n\t```\n\tpip install performer-pytorch\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/abhishekkrthakur/tez\">Tez</a></b> (\ud83e\udd4917 \u00b7  \u2b50 1.1K) - Tez is a super-simple and lightweight Trainer for PyTorch. It also.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/abhishekkrthakur/tez) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 140 \u00b7 \ud83d\udce6 35 \u00b7 \ud83d\udccb 40 - 55% open \u00b7 \u23f1\ufe0f 16.09.2022):\n\n\t```\n\tgit clone https://github.com/abhishekkrthakur/tez\n\t```\n- [PyPi](https://pypi.org/project/tez) (\ud83d\udce5 830 / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 05.06.2022):\n\t```\n\tpip install tez\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/parrt/tensor-sensor\">Tensor Sensor</a></b> (\ud83e\udd4916 \u00b7  \u2b50 700 \u00b7 \ud83d\udca4) - The goal of this library is to generate more helpful.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/parrt/tensor-sensor) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 35 \u00b7 \ud83d\udce6 8 \u00b7 \ud83d\udccb 24 - 33% open \u00b7 \u23f1\ufe0f 07.04.2022):\n\n\t```\n\tgit clone https://github.com/parrt/tensor-sensor\n\t```\n- [PyPi](https://pypi.org/project/tensor-sensor) (\ud83d\udce5 1.8K / month \u00b7 \u23f1\ufe0f 11.12.2021):\n\t```\n\tpip install tensor-sensor\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensor-sensor) (\ud83d\udce5 1.6K \u00b7 \u23f1\ufe0f 11.12.2021):\n\t```\n\tconda install -c conda-forge tensor-sensor\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/madgrad\">madgrad</a></b> (\ud83e\udd4915 \u00b7  \u2b50 770 \u00b7 \ud83d\udca4) - MADGRAD Optimization Method. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/madgrad) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 55 \u00b7 \ud83d\udce6 37 \u00b7 \ud83d\udccb 9 - 22% open \u00b7 \u23f1\ufe0f 10.03.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/madgrad\n\t```\n- [PyPi](https://pypi.org/project/madgrad) (\ud83d\udce5 6.2K / month \u00b7 \u23f1\ufe0f 08.03.2022):\n\t```\n\tpip install madgrad\n\t```\n</details>\n<details><summary>Show 16 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/Cadene/pretrained-models.pytorch\">pretrainedmodels</a></b> (\ud83e\udd4731 \u00b7  \u2b50 8.7K \u00b7 \ud83d\udc80) - Pretrained ConvNets for pytorch: NASNet, ResNeXt,.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/sksq96/pytorch-summary\">pytorch-summary</a></b> (\ud83e\udd4828 \u00b7  \u2b50 3.7K \u00b7 \ud83d\udc80) - Model summary in PyTorch similar to `model.summary()`.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/lukemelas/EfficientNet-PyTorch\">EfficientNet-PyTorch</a></b> (\ud83e\udd4826 \u00b7  \u2b50 7.2K \u00b7 \ud83d\udc80) - A PyTorch implementation of EfficientNet and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/tristandeleu/pytorch-meta\">Torchmeta</a></b> (\ud83e\udd4824 \u00b7  \u2b50 1.7K \u00b7 \ud83d\udc80) - A collection of extensions and data-loaders for few-shot.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/asappresearch/sru\">SRU</a></b> (\ud83e\udd4923 \u00b7  \u2b50 2.1K \u00b7 \ud83d\udc80) - Training RNNs as Fast as CNNs (https://arxiv.org/abs/1709.02755). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/rwightman/gen-efficientnet-pytorch\">EfficientNets</a></b> (\ud83e\udd4923 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Pretrained EfficientNet, EfficientNet-Lite, MixNet,.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/facebookresearch/higher\">Higher</a></b> (\ud83e\udd4922 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - higher is a pytorch library allowing users to obtain higher.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/google-research/torchsde\">torchsde</a></b> (\ud83e\udd4922 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - Differentiable SDE solvers with GPU support and efficient.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/GRAAL-Research/poutyne\">Poutyne</a></b> (\ud83e\udd4921 \u00b7  \u2b50 530) - A simplified framework and utilities for PyTorch. <code><a href=\"http://bit.ly/37RvQcA\">\u2757\ufe0fLGPL-3.0</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/Luolc/AdaBound\">AdaBound</a></b> (\ud83e\udd4920 \u00b7  \u2b50 2.9K \u00b7 \ud83d\udc80) - An optimizer that trains as fast as Adam and as good as SGD. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/adobe/antialiased-cnns\">Antialiased CNNs</a></b> (\ud83e\udd4920 \u00b7  \u2b50 1.6K \u00b7 \ud83d\udc80) - pip install antialiased-cnns to improve stability and.. <code><a href=\"https://tldrlegal.com/search?q=CC%20BY-NC-SA%204.0\">\u2757\ufe0fCC BY-NC-SA 4.0</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/szagoruyko/pytorchviz\">pytorchviz</a></b> (\ud83e\udd4918 \u00b7  \u2b50 2.4K \u00b7 \ud83d\udc80) - A small package to create visualizations of PyTorch execution.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/karpathy/micrograd\">micrograd</a></b> (\ud83e\udd4917 \u00b7  \u2b50 3.3K \u00b7 \ud83d\udc80) - A tiny scalar-valued autograd engine and a neural net library.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/lucidrains/lambda-networks\">Lambda Networks</a></b> (\ud83e\udd4917 \u00b7  \u2b50 1.5K \u00b7 \ud83d\udc80) - Implementation of LambdaNetworks, a new approach to.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/achaiah/pywick\">Pywick</a></b> (\ud83e\udd4915 \u00b7  \u2b50 380 \u00b7 \ud83d\udc80) - High-level batteries-included neural network training library for.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/TorchDrift/TorchDrift\">TorchDrift</a></b> (\ud83e\udd4914 \u00b7  \u2b50 260) - Drift Detection for your PyTorch Models. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n</details>\n<br>\n\n## Database Clients\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n_Libraries for connecting to, operating, and querying databases._\n\n\ud83d\udd17&nbsp;<b><a href=\"https://github.com/ml-tooling/best-of-python#database-clients\">best-of-python - DB Clients</a></b> ( \u2b50 2.6K)  - Collection of database clients for python.\n\n<br>\n\n## Others\n\n<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>\n\n<details><summary><b><a href=\"https://github.com/scipy/scipy\">scipy</a></b> (\ud83e\udd4749 \u00b7  \u2b50 11K) - Ecosystem of open-source software for mathematics, science, and engineering. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/scipy/scipy) (\ud83d\udc68\u200d\ud83d\udcbb 1.4K \u00b7 \ud83d\udd00 4.5K \u00b7 \ud83d\udce5 360K \u00b7 \ud83d\udce6 600K \u00b7 \ud83d\udccb 8.9K - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/scipy/scipy\n\t```\n- [PyPi](https://pypi.org/project/scipy) (\ud83d\udce5 46M / month \u00b7 \ud83d\udce6 58K \u00b7 \u23f1\ufe0f 20.10.2022):\n\t```\n\tpip install scipy\n\t```\n- [Conda](https://anaconda.org/conda-forge/scipy) (\ud83d\udce5 30M \u00b7 \u23f1\ufe0f 09.11.2022):\n\t```\n\tconda install -c conda-forge scipy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/sympy/sympy\">SymPy</a></b> (\ud83e\udd4747 \u00b7  \u2b50 9.8K) - A computer algebra system written in pure Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/sympy/sympy) (\ud83d\udc68\u200d\ud83d\udcbb 1.2K \u00b7 \ud83d\udd00 3.8K \u00b7 \ud83d\udce5 470K \u00b7 \ud83d\udce6 48K \u00b7 \ud83d\udccb 13K - 35% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/sympy/sympy\n\t```\n- [PyPi](https://pypi.org/project/sympy) (\ud83d\udce5 3.3M / month \u00b7 \ud83d\udce6 4.2K \u00b7 \u23f1\ufe0f 20.03.2022):\n\t```\n\tpip install sympy\n\t```\n- [Conda](https://anaconda.org/conda-forge/sympy) (\ud83d\udce5 2.6M \u00b7 \u23f1\ufe0f 27.10.2022):\n\t```\n\tconda install -c conda-forge sympy\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/streamlit/streamlit\">Streamlit</a></b> (\ud83e\udd4741 \u00b7  \u2b50 22K) - Streamlit The fastest way to build data apps in Python. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/streamlit/streamlit) (\ud83d\udc68\u200d\ud83d\udcbb 160 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce6 500 \u00b7 \ud83d\udccb 2.9K - 19% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/streamlit/streamlit\n\t```\n- [PyPi](https://pypi.org/project/streamlit) (\ud83d\udce5 990K / month \u00b7 \ud83d\udce6 420 \u00b7 \u23f1\ufe0f 27.07.2022):\n\t```\n\tpip install streamlit\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PaddlePaddle/PaddleHub\">PaddleHub</a></b> (\ud83e\udd4736 \u00b7  \u2b50 11K) - Awesome pre-trained models toolkit based on PaddlePaddle... <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/PaddlePaddle/PaddleHub) (\ud83d\udc68\u200d\ud83d\udcbb 68 \u00b7 \ud83d\udd00 1.9K \u00b7 \ud83d\udce5 580 \u00b7 \ud83d\udce6 1K \u00b7 \ud83d\udccb 1.2K - 42% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/PaddlePaddle/PaddleHub\n\t```\n- [PyPi](https://pypi.org/project/paddlehub) (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 28.12.2021):\n\t```\n\tpip install paddlehub\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/gradio-app/gradio\">Gradio</a></b> (\ud83e\udd4735 \u00b7  \u2b50 11K) - Wrap UIs around any model, share with anyone. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/gradio-app/gradio) (\ud83d\udc68\u200d\ud83d\udcbb 110 \u00b7 \ud83d\udd00 680 \u00b7 \ud83d\udccb 1.4K - 19% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/gradio-app/gradio\n\t```\n- [PyPi](https://pypi.org/project/gradio) (\ud83d\udce5 910K / month \u00b7 \ud83d\udce6 22 \u00b7 \u23f1\ufe0f 04.07.2022):\n\t```\n\tpip install gradio\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/yzhao062/pyod\">PyOD</a></b> (\ud83e\udd4735 \u00b7  \u2b50 6.5K) - A Comprehensive and Scalable Python Library for Outlier Detection (Anomaly.. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/yzhao062/pyod) (\ud83d\udc68\u200d\ud83d\udcbb 44 \u00b7 \ud83d\udd00 1.2K \u00b7 \ud83d\udce6 1.7K \u00b7 \ud83d\udccb 280 - 50% open \u00b7 \u23f1\ufe0f 24.10.2022):\n\n\t```\n\tgit clone https://github.com/yzhao062/pyod\n\t```\n- [PyPi](https://pypi.org/project/pyod) (\ud83d\udce5 590K / month \u00b7 \ud83d\udce6 34 \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install pyod\n\t```\n- [Conda](https://anaconda.org/conda-forge/pyod) (\ud83d\udce5 46K \u00b7 \u23f1\ufe0f 24.10.2022):\n\t```\n\tconda install -c conda-forge pyod\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/simonw/datasette\">Datasette</a></b> (\ud83e\udd4734 \u00b7  \u2b50 6.7K) - An open source multi-tool for exploring and publishing data. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/simonw/datasette) (\ud83d\udc68\u200d\ud83d\udcbb 71 \u00b7 \ud83d\udd00 460 \u00b7 \ud83d\udce5 41 \u00b7 \ud83d\udce6 790 \u00b7 \ud83d\udccb 1.5K - 29% open \u00b7 \u23f1\ufe0f 19.11.2022):\n\n\t```\n\tgit clone https://github.com/simonw/datasette\n\t```\n- [PyPi](https://pypi.org/project/datasette) (\ud83d\udce5 250K / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 02.05.2022):\n\t```\n\tpip install datasette\n\t```\n- [Conda](https://anaconda.org/conda-forge/datasette) (\ud83d\udce5 13K \u00b7 \u23f1\ufe0f 21.11.2022):\n\t```\n\tconda install -c conda-forge datasette\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/HIPS/autograd\">Autograd</a></b> (\ud83e\udd4833 \u00b7  \u2b50 6.1K) - Efficiently computes derivatives of numpy code. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/HIPS/autograd) (\ud83d\udc68\u200d\ud83d\udcbb 52 \u00b7 \ud83d\udd00 840 \u00b7 \ud83d\udce6 4.2K \u00b7 \ud83d\udccb 400 - 42% open \u00b7 \u23f1\ufe0f 29.09.2022):\n\n\t```\n\tgit clone https://github.com/HIPS/autograd\n\t```\n- [PyPi](https://pypi.org/project/autograd) (\ud83d\udce5 1.1M / month \u00b7 \ud83d\udce6 290 \u00b7 \u23f1\ufe0f 08.04.2022):\n\t```\n\tpip install autograd\n\t```\n- [Conda](https://anaconda.org/conda-forge/autograd) (\ud83d\udce5 250K \u00b7 \u23f1\ufe0f 03.10.2022):\n\t```\n\tconda install -c conda-forge autograd\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deepchem/deepchem\">DeepChem</a></b> (\ud83e\udd4833 \u00b7  \u2b50 4K) - Democratizing Deep-Learning for Drug Discovery, Quantum Chemistry,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/deepchem/deepchem) (\ud83d\udc68\u200d\ud83d\udcbb 200 \u00b7 \ud83d\udd00 1.4K \u00b7 \ud83d\udce6 140 \u00b7 \ud83d\udccb 1.5K - 32% open \u00b7 \u23f1\ufe0f 16.11.2022):\n\n\t```\n\tgit clone https://github.com/deepchem/deepchem\n\t```\n- [PyPi](https://pypi.org/project/deepchem) (\ud83d\udce5 9.1K / month \u00b7 \ud83d\udce6 6 \u00b7 \u23f1\ufe0f 06.07.2022):\n\t```\n\tpip install deepchem\n\t```\n- [Conda](https://anaconda.org/conda-forge/deepchem) (\ud83d\udce5 64K \u00b7 \u23f1\ufe0f 19.01.2022):\n\t```\n\tconda install -c conda-forge deepchem\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/serge-sans-paille/pythran\">Pythran</a></b> (\ud83e\udd4833 \u00b7  \u2b50 1.8K) - Ahead of Time compiler for numeric kernels. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/serge-sans-paille/pythran) (\ud83d\udc68\u200d\ud83d\udcbb 68 \u00b7 \ud83d\udd00 180 \u00b7 \ud83d\udce6 340 \u00b7 \ud83d\udccb 780 - 15% open \u00b7 \u23f1\ufe0f 18.11.2022):\n\n\t```\n\tgit clone https://github.com/serge-sans-paille/pythran\n\t```\n- [PyPi](https://pypi.org/project/pythran) (\ud83d\udce5 570K / month \u00b7 \ud83d\udce6 17 \u00b7 \u23f1\ufe0f 14.12.2021):\n\t```\n\tpip install pythran\n\t```\n- [Conda](https://anaconda.org/conda-forge/pythran) (\ud83d\udce5 300K \u00b7 \u23f1\ufe0f 26.10.2022):\n\t```\n\tconda install -c conda-forge pythran\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/carla-simulator/carla\">carla</a></b> (\ud83e\udd4832 \u00b7  \u2b50 8.5K) - Open-source simulator for autonomous driving research. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/carla-simulator/carla) (\ud83d\udc68\u200d\ud83d\udcbb 140 \u00b7 \ud83d\udd00 2.6K \u00b7 \ud83d\udce6 290 \u00b7 \ud83d\udccb 4.1K - 17% open \u00b7 \u23f1\ufe0f 20.10.2022):\n\n\t```\n\tgit clone https://github.com/carla-simulator/carla\n\t```\n- [PyPi](https://pypi.org/project/carla) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 17.11.2021):\n\t```\n\tpip install carla\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/online-ml/river\">River</a></b> (\ud83e\udd4832 \u00b7  \u2b50 3.8K) - Online machine learning in Python. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/online-ml/river) (\ud83d\udc68\u200d\ud83d\udcbb 88 \u00b7 \ud83d\udd00 420 \u00b7 \ud83d\udce6 180 \u00b7 \ud83d\udccb 380 - 0% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/online-ml/river\n\t```\n- [PyPi](https://pypi.org/project/river) (\ud83d\udce5 18K / month \u00b7 \ud83d\udce6 14 \u00b7 \u23f1\ufe0f 06.06.2022):\n\t```\n\tpip install river\n\t```\n- [Conda](https://anaconda.org/conda-forge/river) (\ud83d\udce5 19K \u00b7 \u23f1\ufe0f 31.10.2022):\n\t```\n\tconda install -c conda-forge river\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/scikit-learn-contrib/hdbscan\">hdbscan</a></b> (\ud83e\udd4832 \u00b7  \u2b50 2.3K) - A high performance implementation of HDBSCAN clustering. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/scikit-learn-contrib/hdbscan) (\ud83d\udc68\u200d\ud83d\udcbb 81 \u00b7 \ud83d\udd00 430 \u00b7 \ud83d\udce6 1.7K \u00b7 \ud83d\udccb 460 - 65% open \u00b7 \u23f1\ufe0f 10.11.2022):\n\n\t```\n\tgit clone https://github.com/scikit-learn-contrib/hdbscan\n\t```\n- [PyPi](https://pypi.org/project/hdbscan) (\ud83d\udce5 470K / month \u00b7 \ud83d\udce6 160 \u00b7 \u23f1\ufe0f 08.02.2022):\n\t```\n\tpip install hdbscan\n\t```\n- [Conda](https://anaconda.org/conda-forge/hdbscan) (\ud83d\udce5 1.3M \u00b7 \u23f1\ufe0f 02.11.2022):\n\t```\n\tconda install -c conda-forge hdbscan\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/datalad/datalad\">datalad</a></b> (\ud83e\udd4832 \u00b7  \u2b50 370) - Keep code, data, containers under control with git and git-annex. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/datalad/datalad) (\ud83d\udc68\u200d\ud83d\udcbb 50 \u00b7 \ud83d\udd00 97 \u00b7 \ud83d\udccb 3.8K - 13% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/datalad/datalad\n\t```\n- [PyPi](https://pypi.org/project/datalad) (\ud83d\udce5 10K / month \u00b7 \ud83d\udce6 57 \u00b7 \u23f1\ufe0f 06.07.2022):\n\t```\n\tpip install datalad\n\t```\n- [Conda](https://anaconda.org/conda-forge/datalad) (\ud83d\udce5 280K \u00b7 \u23f1\ufe0f 07.11.2022):\n\t```\n\tconda install -c conda-forge datalad\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/PennyLaneAI/pennylane\">PennyLane</a></b> (\ud83e\udd4831 \u00b7  \u2b50 1.6K) - PennyLane is a cross-platform Python library for differentiable.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/PennyLaneAI/pennylane) (\ud83d\udc68\u200d\ud83d\udcbb 120 \u00b7 \ud83d\udd00 420 \u00b7 \ud83d\udce5 62 \u00b7 \ud83d\udccb 940 - 32% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/PennyLaneAI/PennyLane\n\t```\n- [PyPi](https://pypi.org/project/pennylane) (\ud83d\udce5 20K / month \u00b7 \ud83d\udce6 34 \u00b7 \u23f1\ufe0f 20.06.2022):\n\t```\n\tpip install pennylane\n\t```\n- [Conda](https://anaconda.org/conda-forge/pennylane) (\ud83d\udce5 6K \u00b7 \u23f1\ufe0f 01.05.2022):\n\t```\n\tconda install -c conda-forge pennylane\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/nicodv/kmodes\">kmodes</a></b> (\ud83e\udd4831 \u00b7  \u2b50 1.1K) - Python implementations of the k-modes and k-prototypes clustering.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/nicodv/kmodes) (\ud83d\udc68\u200d\ud83d\udcbb 21 \u00b7 \ud83d\udd00 380 \u00b7 \ud83d\udce6 1.6K \u00b7 \ud83d\udccb 150 - 11% open \u00b7 \u23f1\ufe0f 06.09.2022):\n\n\t```\n\tgit clone https://github.com/nicodv/kmodes\n\t```\n- [PyPi](https://pypi.org/project/kmodes) (\ud83d\udce5 470K / month \u00b7 \ud83d\udce6 26 \u00b7 \u23f1\ufe0f 14.04.2022):\n\t```\n\tpip install kmodes\n\t```\n- [Conda](https://anaconda.org/conda-forge/kmodes) (\ud83d\udce5 20K \u00b7 \u23f1\ufe0f 06.09.2022):\n\t```\n\tconda install -c conda-forge kmodes\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/adapter-hub/adapter-transformers\">adapter-transformers</a></b> (\ud83e\udd4831 \u00b7  \u2b50 1.1K) - Huggingface Transformers + Adapters =. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code>huggingface</code></summary>\n\n- [GitHub](https://github.com/adapter-hub/adapter-transformers) (\ud83d\udc68\u200d\ud83d\udcbb 1.4K \u00b7 \ud83d\udd00 190 \u00b7 \ud83d\udce6 100 \u00b7 \ud83d\udccb 250 - 17% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/Adapter-Hub/adapter-transformers\n\t```\n- [PyPi](https://pypi.org/project/adapter-transformers) (\ud83d\udce5 27K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 18.05.2022):\n\t```\n\tpip install adapter-transformers\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/inducer/pyopencl\">pyopencl</a></b> (\ud83e\udd4831 \u00b7  \u2b50 940) - OpenCL integration for Python, plus shiny features. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/inducer/pyopencl) (\ud83d\udc68\u200d\ud83d\udcbb 92 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 850 \u00b7 \ud83d\udccb 320 - 21% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/inducer/pyopencl\n\t```\n- [PyPi](https://pypi.org/project/pyopencl) (\ud83d\udce5 37K / month \u00b7 \ud83d\udce6 190 \u00b7 \u23f1\ufe0f 22.06.2022):\n\t```\n\tpip install pyopencl\n\t```\n- [Conda](https://anaconda.org/conda-forge/pyopencl) (\ud83d\udce5 750K \u00b7 \u23f1\ufe0f 22.11.2022):\n\t```\n\tconda install -c conda-forge pyopencl\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tensorly/tensorly\">tensorly</a></b> (\ud83e\udd4830 \u00b7  \u2b50 1.3K) - TensorLy: Tensor Learning in Python. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/tensorly/tensorly) (\ud83d\udc68\u200d\ud83d\udcbb 57 \u00b7 \ud83d\udd00 250 \u00b7 \ud83d\udce6 310 \u00b7 \ud83d\udccb 210 - 23% open \u00b7 \u23f1\ufe0f 22.11.2022):\n\n\t```\n\tgit clone https://github.com/tensorly/tensorly\n\t```\n- [PyPi](https://pypi.org/project/tensorly) (\ud83d\udce5 12K / month \u00b7 \ud83d\udce6 30 \u00b7 \u23f1\ufe0f 08.11.2021):\n\t```\n\tpip install tensorly\n\t```\n- [Conda](https://anaconda.org/conda-forge/tensorly) (\ud83d\udce5 350K \u00b7 \u23f1\ufe0f 09.12.2021):\n\t```\n\tconda install -c conda-forge tensorly\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/uber/causalml\">causalml</a></b> (\ud83e\udd4829 \u00b7  \u2b50 3.6K) - Uplift modeling and causal inference with machine learning.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/uber/causalml) (\ud83d\udc68\u200d\ud83d\udcbb 48 \u00b7 \ud83d\udd00 570 \u00b7 \ud83d\udce6 55 \u00b7 \ud83d\udccb 300 - 23% open \u00b7 \u23f1\ufe0f 10.11.2022):\n\n\t```\n\tgit clone https://github.com/uber/causalml\n\t```\n- [PyPi](https://pypi.org/project/causalml) (\ud83d\udce5 59K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 14.03.2022):\n\t```\n\tpip install causalml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/SeldonIO/alibi-detect\">alibi-detect</a></b> (\ud83e\udd4829 \u00b7  \u2b50 1.6K) - Algorithms for outlier, adversarial and drift detection. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/SeldonIO/alibi-detect) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 300 - 34% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/SeldonIO/alibi-detect\n\t```\n- [PyPi](https://pypi.org/project/alibi-detect) (\ud83d\udce5 33K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 01.06.2022):\n\t```\n\tpip install alibi-detect\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pyjanitor-devs/pyjanitor\">pyjanitor</a></b> (\ud83e\udd4829 \u00b7  \u2b50 1K) - Clean APIs for data cleaning. Python implementation of R package Janitor. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/pyjanitor-devs/pyjanitor) (\ud83d\udc68\u200d\ud83d\udcbb 100 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 250 \u00b7 \ud83d\udccb 510 - 21% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/pyjanitor-devs/pyjanitor\n\t```\n- [PyPi](https://pypi.org/project/pyjanitor) (\ud83d\udce5 39K / month \u00b7 \ud83d\udce6 12 \u00b7 \u23f1\ufe0f 03.05.2022):\n\t```\n\tpip install pyjanitor\n\t```\n- [Conda](https://anaconda.org/conda-forge/pyjanitor) (\ud83d\udce5 150K \u00b7 \u23f1\ufe0f 17.10.2022):\n\t```\n\tconda install -c conda-forge pyjanitor\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/deepmind/pysc2\">pysc2</a></b> (\ud83e\udd4828 \u00b7  \u2b50 7.6K) - StarCraft II Learning Environment. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/deepmind/pysc2) (\ud83d\udc68\u200d\ud83d\udcbb 36 \u00b7 \ud83d\udd00 1.1K \u00b7 \ud83d\udce5 30K \u00b7 \ud83d\udce6 450 \u00b7 \ud83d\udccb 280 - 18% open \u00b7 \u23f1\ufe0f 07.08.2022):\n\n\t```\n\tgit clone https://github.com/deepmind/pysc2\n\t```\n- [PyPi](https://pypi.org/project/pysc2) (\ud83d\udce5 2.7K / month \u00b7 \ud83d\udce6 26 \u00b7 \u23f1\ufe0f 27.09.2019):\n\t```\n\tpip install pysc2\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ContinualAI/avalanche\">avalanche</a></b> (\ud83e\udd4828 \u00b7  \u2b50 1.1K) - Avalanche: an End-to-End Library for Continual Learning based on.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/ContinualAI/avalanche) (\ud83d\udc68\u200d\ud83d\udcbb 60 \u00b7 \ud83d\udd00 200 \u00b7 \ud83d\udce5 4 \u00b7 \ud83d\udce6 16 \u00b7 \ud83d\udccb 610 - 12% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/ContinualAI/avalanche\n\t```\n- [PyPi](https://pypi.org/project/avalanche-lib) (\ud83d\udce5 760 / month \u00b7 \u23f1\ufe0f 14.06.2022):\n\t```\n\tpip install avalanche-lib\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/mars-project/mars\">Mars</a></b> (\ud83e\udd4927 \u00b7  \u2b50 2.5K) - Mars is a tensor-based unified framework for large-scale data.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/mars-project/mars) (\ud83d\udc68\u200d\ud83d\udcbb 45 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udccb 1.2K - 18% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/mars-project/mars\n\t```\n- [PyPi](https://pypi.org/project/pymars) (\ud83d\udce5 32K / month \u00b7 \ud83d\udce6 1 \u00b7 \u23f1\ufe0f 12.06.2022):\n\t```\n\tpip install pymars\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/openvinotoolkit/anomalib\">anomalib</a></b> (\ud83e\udd4927 \u00b7  \u2b50 1.4K) - An anomaly detection library comprising state-of-the-art algorithms.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/openvinotoolkit/anomalib) (\ud83d\udc68\u200d\ud83d\udcbb 27 \u00b7 \ud83d\udd00 230 \u00b7 \ud83d\udce6 4 \u00b7 \ud83d\udccb 320 - 10% open \u00b7 \u23f1\ufe0f 21.11.2022):\n\n\t```\n\tgit clone https://github.com/openvinotoolkit/anomalib\n\t```\n- [PyPi](https://pypi.org/project/anomalib) (\ud83d\udce5 2.6K / month \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install anomalib\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/tableau/TabPy\">TabPy</a></b> (\ud83e\udd4927 \u00b7  \u2b50 1.3K) - Execute Python code on the fly and display results in Tableau visualizations:. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/tableau/TabPy) (\ud83d\udc68\u200d\ud83d\udcbb 46 \u00b7 \ud83d\udd00 500 \u00b7 \ud83d\udce6 99 \u00b7 \ud83d\udccb 300 - 3% open \u00b7 \u23f1\ufe0f 06.10.2022):\n\n\t```\n\tgit clone https://github.com/tableau/TabPy\n\t```\n- [PyPi](https://pypi.org/project/tabpy) (\ud83d\udce5 19K / month \u00b7 \ud83d\udce6 2 \u00b7 \u23f1\ufe0f 20.01.2022):\n\t```\n\tpip install tabpy\n\t```\n- [Conda](https://anaconda.org/anaconda/tabpy-client) (\ud83d\udce5 3.4K \u00b7 \u23f1\ufe0f 02.05.2022):\n\t```\n\tconda install -c anaconda tabpy-client\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/sepandhaghighi/pycm\">pycm</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.3K) - Multi-class confusion matrix library in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/sepandhaghighi/pycm) (\ud83d\udc68\u200d\ud83d\udcbb 17 \u00b7 \ud83d\udd00 110 \u00b7 \ud83d\udce6 170 \u00b7 \ud83d\udccb 190 - 6% open \u00b7 \u23f1\ufe0f 17.08.2022):\n\n\t```\n\tgit clone https://github.com/sepandhaghighi/pycm\n\t```\n- [PyPi](https://pypi.org/project/pycm) (\ud83d\udce5 36K / month \u00b7 \ud83d\udce6 13 \u00b7 \u23f1\ufe0f 27.04.2022):\n\t```\n\tpip install pycm\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/scikit-learn-contrib/metric-learn\">metric-learn</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.3K) - Metric learning algorithms in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/scikit-learn-contrib/metric-learn) (\ud83d\udc68\u200d\ud83d\udcbb 22 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 240 \u00b7 \ud83d\udccb 170 - 30% open \u00b7 \u23f1\ufe0f 21.06.2022):\n\n\t```\n\tgit clone https://github.com/scikit-learn-contrib/metric-learn\n\t```\n- [PyPi](https://pypi.org/project/metric-learn) (\ud83d\udce5 37K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 02.07.2020):\n\t```\n\tpip install metric-learn\n\t```\n- [Conda](https://anaconda.org/conda-forge/metric-learn) (\ud83d\udce5 7.8K \u00b7 \u23f1\ufe0f 02.07.2020):\n\t```\n\tconda install -c conda-forge metric-learn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/google/trax\">Trax</a></b> (\ud83e\udd4925 \u00b7  \u2b50 7.2K) - Trax Deep Learning with Clear Code and Speed. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/google/trax) (\ud83d\udc68\u200d\ud83d\udcbb 78 \u00b7 \ud83d\udd00 740 \u00b7 \ud83d\udce6 84 \u00b7 \ud83d\udccb 210 - 42% open \u00b7 \u23f1\ufe0f 09.11.2022):\n\n\t```\n\tgit clone https://github.com/google/trax\n\t```\n- [PyPi](https://pypi.org/project/trax) (\ud83d\udce5 4.2K / month \u00b7 \u23f1\ufe0f 26.10.2021):\n\t```\n\tpip install trax\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/facebookresearch/AugLy\">AugLy</a></b> (\ud83e\udd4925 \u00b7  \u2b50 4.6K) - A data augmentations library for audio, image, text, and video. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/facebookresearch/AugLy) (\ud83d\udc68\u200d\ud83d\udcbb 26 \u00b7 \ud83d\udd00 260 \u00b7 \ud83d\udce6 46 \u00b7 \ud83d\udccb 70 - 22% open \u00b7 \u23f1\ufe0f 21.09.2022):\n\n\t```\n\tgit clone https://github.com/facebookresearch/AugLy\n\t```\n- [PyPi](https://pypi.org/project/augly) (\ud83d\udce5 2.1K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 28.03.2022):\n\t```\n\tpip install augly\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/trevorstephens/gplearn\">gplearn</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1.2K) - Genetic Programming in Python, with a scikit-learn inspired API. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/trevorstephens/gplearn) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 220 \u00b7 \ud83d\udce6 290 \u00b7 \ud83d\udccb 200 - 9% open \u00b7 \u23f1\ufe0f 04.08.2022):\n\n\t```\n\tgit clone https://github.com/trevorstephens/gplearn\n\t```\n- [PyPi](https://pypi.org/project/gplearn) (\ud83d\udce5 4.6K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 03.05.2022):\n\t```\n\tpip install gplearn\n\t```\n- [Conda](https://anaconda.org/conda-forge/gplearn) (\ud83d\udce5 3.9K \u00b7 \u23f1\ufe0f 04.05.2022):\n\t```\n\tconda install -c conda-forge gplearn\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/ljvmiranda921/pyswarms\">PySwarms</a></b> (\ud83e\udd4925 \u00b7  \u2b50 1K) - A research toolkit for particle swarm optimization in Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/ljvmiranda921/pyswarms) (\ud83d\udc68\u200d\ud83d\udcbb 44 \u00b7 \ud83d\udd00 310 \u00b7 \ud83d\udce6 200 \u00b7 \ud83d\udccb 210 - 5% open \u00b7 \u23f1\ufe0f 03.07.2022):\n\n\t```\n\tgit clone https://github.com/ljvmiranda921/pyswarms\n\t```\n- [PyPi](https://pypi.org/project/pyswarms) (\ud83d\udce5 7.7K / month \u00b7 \ud83d\udce6 11 \u00b7 \u23f1\ufe0f 03.01.2021):\n\t```\n\tpip install pyswarms\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/MaxHalford/prince\">Prince</a></b> (\ud83e\udd4924 \u00b7  \u2b50 900) - Python factor analysis library (PCA, CA, MCA, MFA, FAMD). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/MaxHalford/prince) (\ud83d\udc68\u200d\ud83d\udcbb 13 \u00b7 \ud83d\udd00 160 \u00b7 \ud83d\udce6 260 \u00b7 \ud83d\udccb 110 - 37% open \u00b7 \u23f1\ufe0f 07.09.2022):\n\n\t```\n\tgit clone https://github.com/MaxHalford/prince\n\t```\n- [PyPi](https://pypi.org/project/prince) (\ud83d\udce5 25K / month \u00b7 \ud83d\udce6 5 \u00b7 \u23f1\ufe0f 06.10.2020):\n\t```\n\tpip install prince\n\t```\n- [Conda](https://anaconda.org/conda-forge/prince-factor-analysis) (\ud83d\udce5 13K \u00b7 \u23f1\ufe0f 30.04.2021):\n\t```\n\tconda install -c conda-forge prince-factor-analysis\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/astroML/astroML\">AstroML</a></b> (\ud83e\udd4923 \u00b7  \u2b50 860) - Machine learning, statistics, and data mining for astronomy and.. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/astroML/astroML) (\ud83d\udc68\u200d\ud83d\udcbb 30 \u00b7 \ud83d\udd00 280 \u00b7 \ud83d\udccb 160 - 39% open \u00b7 \u23f1\ufe0f 03.10.2022):\n\n\t```\n\tgit clone https://github.com/astroML/astroML\n\t```\n- [PyPi](https://pypi.org/project/astroML) (\ud83d\udce5 1.2K / month \u00b7 \ud83d\udce6 33 \u00b7 \u23f1\ufe0f 01.03.2022):\n\t```\n\tpip install astroML\n\t```\n- [Conda](https://anaconda.org/conda-forge/astroml) (\ud83d\udce5 34K \u00b7 \u23f1\ufe0f 02.03.2022):\n\t```\n\tconda install -c conda-forge astroml\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/minrk/findspark\">findspark</a></b> (\ud83e\udd4923 \u00b7  \u2b50 460 \u00b7 \ud83d\udca4) - Find pyspark to make it importable. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1N\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/minrk/findspark) (\ud83d\udc68\u200d\ud83d\udcbb 15 \u00b7 \ud83d\udd00 70 \u00b7 \ud83d\udce6 2.9K \u00b7 \ud83d\udccb 23 - 52% open \u00b7 \u23f1\ufe0f 11.02.2022):\n\n\t```\n\tgit clone https://github.com/minrk/findspark\n\t```\n- [PyPi](https://pypi.org/project/findspark) (\ud83d\udce5 2.2M / month \u00b7 \ud83d\udce6 140 \u00b7 \u23f1\ufe0f 11.02.2022):\n\t```\n\tpip install findspark\n\t```\n- [Conda](https://anaconda.org/conda-forge/findspark) (\ud83d\udce5 740K \u00b7 \u23f1\ufe0f 11.02.2022):\n\t```\n\tconda install -c conda-forge findspark\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/Project-MONAI/MONAILabel\">MONAILabel</a></b> (\ud83e\udd4923 \u00b7  \u2b50 330) - MONAI Label is an intelligent open source image labeling and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/Project-MONAI/MONAILabel) (\ud83d\udc68\u200d\ud83d\udcbb 37 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce5 30K \u00b7 \ud83d\udccb 330 - 17% open \u00b7 \u23f1\ufe0f 24.11.2022):\n\n\t```\n\tgit clone https://github.com/Project-MONAI/MONAILabel\n\t```\n- [PyPi](https://pypi.org/project/monailabel-weekly) (\ud83d\udce5 560 / month \u00b7 \u23f1\ufe0f 03.07.2022):\n\t```\n\tpip install monailabel-weekly\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/solegalli/feature_engine\">Feature Engine</a></b> (\ud83e\udd4922 \u00b7  \u2b50 1.1K) - Feature engineering package with sklearn like functionality. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>\n\n- [GitHub](https://github.com/solegalli/feature_engine) (\ud83d\udc68\u200d\ud83d\udcbb 36 \u00b7 \ud83d\udd00 240 \u00b7 \u23f1\ufe0f 05.07.2022):\n\n\t```\n\tgit clone https://github.com/solegalli/feature_engine\n\t```\n- [PyPi](https://pypi.org/project/feature_engine) (\ud83d\udce5 150K / month \u00b7 \u23f1\ufe0f 24.10.2022):\n\t```\n\tpip install feature_engine\n\t```\n- [Conda](https://anaconda.org/conda-forge/feature_engine) (\ud83d\udce5 21K \u00b7 \u23f1\ufe0f 23.11.2022):\n\t```\n\tconda install -c conda-forge feature_engine\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/rasbt/biopandas\">BioPandas</a></b> (\ud83e\udd4922 \u00b7  \u2b50 540) - Working with molecular structures in pandas DataFrames. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/rasbt/biopandas) (\ud83d\udc68\u200d\ud83d\udcbb 9 \u00b7 \ud83d\udd00 100 \u00b7 \ud83d\udce6 130 \u00b7 \ud83d\udccb 49 - 40% open \u00b7 \u23f1\ufe0f 06.08.2022):\n\n\t```\n\tgit clone https://github.com/rasbt/biopandas\n\t```\n- [PyPi](https://pypi.org/project/biopandas) (\ud83d\udce5 10K / month \u00b7 \ud83d\udce6 16 \u00b7 \u23f1\ufe0f 13.05.2022):\n\t```\n\tpip install biopandas\n\t```\n- [Conda](https://anaconda.org/conda-forge/biopandas) (\ud83d\udce5 120K \u00b7 \u23f1\ufe0f 13.05.2022):\n\t```\n\tconda install -c conda-forge biopandas\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/airbnb/streamalert\">StreamAlert</a></b> (\ud83e\udd4921 \u00b7  \u2b50 2.7K) - StreamAlert is a serverless, realtime data analysis framework.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n\n- [GitHub](https://github.com/airbnb/streamalert) (\ud83d\udc68\u200d\ud83d\udcbb 33 \u00b7 \ud83d\udd00 320 \u00b7 \ud83d\udccb 340 - 24% open \u00b7 \u23f1\ufe0f 20.07.2022):\n\n\t```\n\tgit clone https://github.com/airbnb/streamalert\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/dstackai/dstack\">dstack</a></b> (\ud83e\udd4921 \u00b7  \u2b50 410) - An open-source tool for teams to build reproducible ML workflows. <code><a href=\"http://bit.ly/3postzC\">MPL-2.0</a></code></summary>\n\n- [GitHub](https://github.com/dstackai/dstack) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 22 \u00b7 \ud83d\udccb 130 - 25% open \u00b7 \u23f1\ufe0f 23.11.2022):\n\n\t```\n\tgit clone https://github.com/dstackai/dstack\n\t```\n- [PyPi](https://pypi.org/project/dstack) (\ud83d\udce5 460 / month \u00b7 \u23f1\ufe0f 29.06.2022):\n\t```\n\tpip install dstack\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/clementchadebec/benchmark_VAE\">benchmark_VAE</a></b> (\ud83e\udd4920 \u00b7  \u2b50 1.1K) - Unifying Generative Autoencoder implementations in.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/clementchadebec/benchmark_VAE) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 87 \u00b7 \ud83d\udce6 3 \u00b7 \ud83d\udccb 27 - 22% open \u00b7 \u23f1\ufe0f 20.10.2022):\n\n\t```\n\tgit clone https://github.com/clementchadebec/benchmark_VAE\n\t```\n- [PyPi](https://pypi.org/project/pythae) (\ud83d\udce5 340 / month \u00b7 \u23f1\ufe0f 05.07.2022):\n\t```\n\tpip install pythae\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/pykale/pykale\">pykale</a></b> (\ud83e\udd4920 \u00b7  \u2b50 370) - Knowledge-Aware machine LEarning (KALE): accessible machine learning.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/pykale/pykale) (\ud83d\udc68\u200d\ud83d\udcbb 18 \u00b7 \ud83d\udd00 49 \u00b7 \ud83d\udccb 93 - 6% open \u00b7 \u23f1\ufe0f 16.10.2022):\n\n\t```\n\tgit clone https://github.com/pykale/pykale\n\t```\n- [PyPi](https://pypi.org/project/pykale) (\ud83d\udce5 100 / month \u00b7 \u23f1\ufe0f 12.04.2022):\n\t```\n\tpip install pykale\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/eltonlaw/impyute\">impyute</a></b> (\ud83e\udd4920 \u00b7  \u2b50 330 \u00b7 \ud83d\udca4) - Data imputations library to preprocess datasets with missing data. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/eltonlaw/impyute) (\ud83d\udc68\u200d\ud83d\udcbb 11 \u00b7 \ud83d\udd00 46 \u00b7 \ud83d\udce6 160 \u00b7 \ud83d\udccb 64 - 42% open \u00b7 \u23f1\ufe0f 06.11.2021):\n\n\t```\n\tgit clone https://github.com/eltonlaw/impyute\n\t```\n- [PyPi](https://pypi.org/project/impyute) (\ud83d\udce5 4.6K / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 29.04.2019):\n\t```\n\tpip install impyute\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/yzhao062/SUOD\">SUOD</a></b> (\ud83e\udd4919 \u00b7  \u2b50 340) - (MLSys 21) An Acceleration System for Large-scare Unsupervised Heterogeneous.. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>\n\n- [GitHub](https://github.com/yzhao062/SUOD) (\ud83d\udc68\u200d\ud83d\udcbb 2 \u00b7 \ud83d\udd00 43 \u00b7 \ud83d\udce6 450 \u00b7 \ud83d\udccb 9 - 66% open \u00b7 \u23f1\ufe0f 07.07.2022):\n\n\t```\n\tgit clone https://github.com/yzhao062/SUOD\n\t```\n- [PyPi](https://pypi.org/project/suod) (\ud83d\udce5 43K / month \u00b7 \u23f1\ufe0f 01.10.2021):\n\t```\n\tpip install suod\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jmschrei/apricot\">apricot</a></b> (\ud83e\udd4917 \u00b7  \u2b50 450 \u00b7 \ud83d\udca4) - apricot implements submodular optimization for the purpose of.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/jmschrei/apricot) (\ud83d\udc68\u200d\ud83d\udcbb 4 \u00b7 \ud83d\udd00 46 \u00b7 \ud83d\udce5 19 \u00b7 \ud83d\udce6 33 \u00b7 \ud83d\udccb 29 - 34% open \u00b7 \u23f1\ufe0f 18.11.2021):\n\n\t```\n\tgit clone https://github.com/jmschrei/apricot\n\t```\n- [PyPi](https://pypi.org/project/apricot-select) (\ud83d\udce5 530 / month \u00b7 \ud83d\udce6 3 \u00b7 \u23f1\ufe0f 28.09.2020):\n\t```\n\tpip install apricot-select\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/SforAiDl/KD_Lib\">KD-Lib</a></b> (\ud83e\udd4916 \u00b7  \u2b50 450) - A Pytorch Knowledge Distillation library for benchmarking and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n\n- [GitHub](https://github.com/SforAiDl/KD_Lib) (\ud83d\udc68\u200d\ud83d\udcbb 6 \u00b7 \ud83d\udd00 40 \u00b7 \ud83d\udccb 61 - 21% open \u00b7 \u23f1\ufe0f 14.10.2022):\n\n\t```\n\tgit clone https://github.com/SforAiDl/KD_Lib\n\t```\n- [PyPi](https://pypi.org/project/KD-Lib) (\ud83d\udce5 42 / month \u00b7 \u23f1\ufe0f 18.05.2022):\n\t```\n\tpip install KD-Lib\n\t```\n</details>\n<details><summary><b><a href=\"https://github.com/jrieke/traingenerator\">traingenerator</a></b> (\ud83e\udd4913 \u00b7  \u2b50 1.2K) - A web app to generate template code for machine learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>\n\n- [GitHub](https://github.com/jrieke/traingenerator) (\ud83d\udc68\u200d\ud83d\udcbb 3 \u00b7 \ud83d\udd00 170 \u00b7 \ud83d\udccb 16 - 81% open \u00b7 \u23f1\ufe0f 30.06.2022):\n\n\t```\n\tgit clone https://github.com/jrieke/traingenerator\n\t```\n</details>\n<details><summary>Show 17 hidden projects...</summary>\n\n- <b><a href=\"https://github.com/wireservice/agate\">agate</a></b> (\ud83e\udd4831 \u00b7  \u2b50 1.1K \u00b7 \ud83d\udc80) - A Python data analysis library that is optimized for humans instead of.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/explosion/cython-blis\">Cython BLIS</a></b> (\ud83e\udd4831 \u00b7  \u2b50 190) - Fast matrix-multiplication as a self-contained Python library no.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/cleanlab/cleanlab\">cleanlab</a></b> (\ud83e\udd4829 \u00b7  \u2b50 4.2K) - The standard data-centric AI package for data quality and machine.. <code><a href=\"http://bit.ly/3pwmjO5\">\u2757\ufe0fAGPL-3.0</a></code>\n- <b><a href=\"https://github.com/annoviko/pyclustering\">pyclustering</a></b> (\ud83e\udd4927 \u00b7  \u2b50 1K \u00b7 \ud83d\udc80) - pyclustering is a Python, C++ data mining library. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/JustGlowing/minisom\">minisom</a></b> (\ud83e\udd4926 \u00b7  \u2b50 1.2K) - MiniSom is a minimalistic implementation of the Self Organizing.. <code><a href=\"https://tldrlegal.com/search?q=CC-BY-3.0\">\u2757\ufe0fCC-BY-3.0</a></code>\n- <b><a href=\"https://github.com/modAL-python/modAL\">modAL</a></b> (\ud83e\udd4924 \u00b7  \u2b50 1.9K \u00b7 \ud83d\udc80) - A modular active learning framework for Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/flennerhag/mlens\">mlens</a></b> (\ud83e\udd4923 \u00b7  \u2b50 760 \u00b7 \ud83d\udc80) - ML-Ensemble high performance ensemble learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/vecxoz/vecstack\">vecstack</a></b> (\ud83e\udd4922 \u00b7  \u2b50 670 \u00b7 \ud83d\udc80) - Python package for stacking (machine learning technique). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/transform-data/metricflow\">metricflow</a></b> (\ud83e\udd4921 \u00b7  \u2b50 710) - MetricFlow allows you to define, build, and maintain metrics in.. <code><a href=\"http://bit.ly/3pwmjO5\">\u2757\ufe0fAGPL-3.0</a></code>\n- <b><a href=\"https://github.com/kLabUM/rrcf\">rrcf</a></b> (\ud83e\udd4921 \u00b7  \u2b50 410 \u00b7 \ud83d\udc80) - Implementation of the Robust Random Cut Forest algorithm for anomaly.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/ml-tooling/opyrator\">opyrator</a></b> (\ud83e\udd4920 \u00b7  \u2b50 2.7K \u00b7 \ud83d\udc80) - Turns your machine learning code into microservices with web API,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/EpistasisLab/scikit-rebate\">scikit-rebate</a></b> (\ud83e\udd4919 \u00b7  \u2b50 370 \u00b7 \ud83d\udc80) - A scikit-learn-compatible Python implementation of.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/pandas-ml/pandas-ml\">pandas-ml</a></b> (\ud83e\udd4919 \u00b7  \u2b50 300 \u00b7 \ud83d\udc80) - pandas, scikit-learn, xgboost and seaborn integration. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n- <b><a href=\"https://github.com/infer-actively/pymdp\">pymdp</a></b> (\ud83e\udd4919 \u00b7  \u2b50 230) - A Python implementation of active inference for Markov Decision Processes. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/alegonz/baikal\">baikal</a></b> (\ud83e\udd4918 \u00b7  \u2b50 590 \u00b7 \ud83d\udc80) - A graph-based functional API for building complex scikit-learn.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code>\n- <b><a href=\"https://github.com/facebookresearch/NeuralCompression\">NeuralCompression</a></b> (\ud83e\udd4915 \u00b7  \u2b50 290) - A collection of tools for neural compression enthusiasts. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n- <b><a href=\"https://github.com/Palashio/nylon\">nylon</a></b> (\ud83e\udd4911 \u00b7  \u2b50 78 \u00b7 \ud83d\udc80) - An intelligent, flexible grammar of machine learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n</details>\n\n---\n\n## Related Resources\n\n- [**Papers With Code**](https://paperswithcode.com): Discover ML papers, code, and evaluation tables.\n- [**Sotabench**](https://sotabench.com): Discover & compare open-source ML models.\n- [**Google Dataset Search**](https://toolbox.google.com/datasetsearch): Dataset search engine by Google.\n- [**Dataset List**](https://www.datasetlist.com/): List of the biggest ML datasets from across the web.\n- [**Awesome Public Datasets**](https://github.com/awesomedata/awesome-public-datasets): A topic-centric list of open datasets.\n- [**Best-of lists**](https://best-of.org): Discover other best-of lists with awesome open-source projects on all kinds of topics.\n- [**best-of-python-dev**](https://github.com/ml-tooling/best-of-python-dev): A ranked list of awesome python developer tools and libraries.\n- [**best-of-web-python**](https://github.com/ml-tooling/best-of-web-python): A ranked list of awesome python libraries for web development.\n\n## Contribution\n\nContributions are encouraged and always welcome! If you like to add or update projects, choose one of the following ways:\n\n- Open an issue by selecting one of the provided categories from the [issue page](https://github.com/ml-tooling/best-of-ml-python/issues/new/choose) and fill in the requested information.\n- Modify the [projects.yaml](https://github.com/ml-tooling/best-of-ml-python/blob/main/projects.yaml) with your additions or changes, and submit a pull request. This can also be done directly via the [Github UI](https://github.com/ml-tooling/best-of-ml-python/edit/main/projects.yaml).\n\nIf you like to contribute to or share suggestions regarding the project metadata collection or markdown generation, please refer to the [best-of-generator](https://github.com/best-of-lists/best-of-generator) repository. If you like to create your own best-of list, we recommend to follow [this guide](https://github.com/best-of-lists/best-of/blob/main/create-best-of-list.md).\n\nFor more information on how to add or update projects, please read the [contribution guidelines](https://github.com/ml-tooling/best-of-ml-python/blob/main/CONTRIBUTING.md). By participating in this project, you agree to abide by its [Code of Conduct](https://github.com/ml-tooling/best-of-ml-python/blob/main/.github/CODE_OF_CONDUCT.md).\n\n## License\n\n[![CC0](https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by-sa.svg)](https://creativecommons.org/licenses/by-sa/4.0/)\n",
	"data-analysis data-science data-visualization deep-learning deploy gradio gradio-interface interface machine-learning models python python-notebook ui ui-components": "[![CircleCI](https://circleci.com/gh/gradio-app/gradio.svg?style=svg)](https://circleci.com/gh/gradio-app/gradio)  [![PyPI version](https://badge.fury.io/py/gradio.svg)](https://badge.fury.io/py/gradio)  [![codecov](https://codecov.io/gh/gradio-app/gradio/branch/master/graph/badge.svg?token=NNVPX9KEGS)](https://codecov.io/gh/gradio-app/gradio) [![PyPI - Downloads](https://img.shields.io/pypi/dm/gradio)](https://pypi.org/project/gradio/) [![Twitter Follow](https://img.shields.io/twitter/follow/gradio.svg?style=social&label=Follow)](https://twitter.com/gradio)\n\n#  Welcome to Gradio\n\nQuickly create beautiful user interfaces around your machine learning models. Gradio (pronounced GRAY-dee-oh) makes it easy for you to demo your model in your browser or let people \"try it out\" by dragging-and-dropping in their own images, pasting text, recording their own voice, etc. and seeing what the model outputs.  \n\n![Interface montage](website/homepage/src/assets/img/montage.gif)\n\nGradio is useful for:\n\n* **Demoing** your machine learning models for clients / collaborators / users / students\n\n* **Deploying** your models quickly with automatic shareable links and getting feedback on model performance\n\n* **Debugging** your model interactively during development using built-in manipulation and interpretation tools\n\n**You can find an interactive version of the following Getting Started at [https://gradio.app/getting_started](https://gradio.app/getting_started).**\n\n\n## Getting Started\n\n**Prerequisite**: Python 3.7+ and that's it! \n\n### Quick Start\n\nTo get Gradio running with a simple \"Hello, World\" example, follow these three steps:\n\n<span>1.</span> Install Gradio from pip.\n\n```bash\npip install gradio\n```\n\n<span>2.</span> Run the code below as a Python script or in a Python notebook (or in a  [colab notebook](https://colab.research.google.com/drive/18ODkJvyxHutTN0P5APWyGFO_xwNcgHDZ?usp=sharing)).\n\n```python\nimport gradio as gr\n\n\ndef greet(name):\n    return \"Hello \" + name + \"!!\"\n\n\niface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\niface.launch()\n\n```\n\n<span>3.</span> The interface below will appear automatically within the Python notebook, or pop in a browser on  [http://localhost:7860](http://localhost:7860/)  if running from a script.\n\n![hello_world interface](demo/hello_world/screenshot.gif)\n\n### Understanding the `Interface` class\n\nGradio can wrap almost any Python function with an easy-to-use user interface. In the example above, we saw a simple text-based function. But the function could be anything from image enhancer to a tax calculator to (most commonly) the prediction function of a pretrained machine learning model.\n\nThe core  `Interface`  class is initialized with three parameters:\n\n-   `fn`: the function to wrap\n-   `inputs`: the input component type(s), e.g. `\"image\"` or `\"audio\"` ([see docs for complete list](/docs))\n-   `outputs`: the output component type(s) e.g. `\"image\"` or `\"label\"` ([see docs for complete list](/docs))\n\nWith these three arguments, we can quickly create interfaces and  `launch()`  them. But what if you want to change how the UI components look or behave?\n\n### Customizable Components\n\nLet's say we want to customize the input text field - for example, we wanted it to be larger and have a text hint. If we use the actual input class for  `Textbox`  instead of using the string shortcut, we have access to much more customizability. To see a list of all the components we support and how you can customize them, check out the [Docs](https://gradio.app/docs).\n\n```python\nimport gradio as gr\n\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\n\niface = gr.Interface(\n    fn=greet,\n    inputs=gr.inputs.Textbox(lines=2, placeholder=\"Name Here...\"),\n    outputs=\"text\",\n)\niface.launch()\n\n```\n![hello_world_2 interface](demo/hello_world_2/screenshot.gif)\n\n### Multiple Inputs and Outputs\n\nLet's say we had a much more complex function, with multiple inputs and outputs. In the example below, we have a function that takes a string, boolean, and number, and returns a string and number. Take a look how we pass a list of input and output components.\n\n```python\nimport gradio as gr\n\n\ndef greet(name, is_morning, temperature):\n    salutation = \"Good morning\" if is_morning else \"Good evening\"\n    greeting = \"%s %s. It is %s degrees today\" % (salutation, name, temperature)\n    celsius = (temperature - 32) * 5 / 9\n    return greeting, round(celsius, 2)\n\n\niface = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"checkbox\", gr.inputs.Slider(0, 100)],\n    outputs=[\"text\", \"number\"],\n)\niface.launch()\n\n```\n![hello_world_3 interface](demo/hello_world_3/screenshot.gif)\n\nWe simply wrap the components in a list. Each component in the `inputs` list corresponds to one of the parameters of the function, in order. Each component in the `outputs` list corresponds to one of the values returned by the function, again in order. \n\n### Working with Images\n\nLet's try an image-to-image function. When using the  `Image`  component, your function will receive a numpy array of your specified size, with the shape  `(width, height, 3)`, where the last dimension represents the RGB values. We'll return an image as well in the form of a numpy array.\n\n```python\nimport numpy as np\n\nimport gradio as gr\n\n\ndef sepia(input_img):\n    sepia_filter = np.array(\n        [[0.393, 0.769, 0.189], [0.349, 0.686, 0.168], [0.272, 0.534, 0.131]]\n    )\n    sepia_img = input_img.dot(sepia_filter.T)\n    sepia_img /= sepia_img.max()\n    return sepia_img\n\n\niface = gr.Interface(sepia, gr.inputs.Image(shape=(200, 200)), \"image\")\n\niface.launch()\n\n```\n![sepia_filter interface](demo/sepia_filter/screenshot.gif)\n\nAdditionally, our  `Image`  input interface comes with an 'edit' button which opens tools for cropping, flipping, rotating, drawing over, and applying filters to images. We've found that manipulating images in this way will often reveal hidden flaws in a model.\n\nIn addition to images, Gradio supports other media input types, such as audio or video uploads, as well as many output components. Read about these in the [Docs](https://gradio.app/docs).\n\n### Working with DataFrames and Graphs\n\nYou can use Gradio to support inputs and outputs from your typical data libraries, such as numpy arrays, pandas dataframes, and plotly graphs. Take a look at the demo below (ignore the complicated data manipulation in the function!)\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport gradio as gr\n\n\ndef sales_projections(employee_data):\n    sales_data = employee_data.iloc[:, 1:4].astype(\"int\").to_numpy()\n    regression_values = np.apply_along_axis(\n        lambda row: np.array(np.poly1d(np.polyfit([0, 1, 2], row, 2))), 0, sales_data\n    )\n    projected_months = np.repeat(\n        np.expand_dims(np.arange(3, 12), 0), len(sales_data), axis=0\n    )\n    projected_values = np.array(\n        [\n            month * month * regression[0] + month * regression[1] + regression[2]\n            for month, regression in zip(projected_months, regression_values)\n        ]\n    )\n    plt.plot(projected_values.T)\n    plt.legend(employee_data[\"Name\"])\n    return employee_data, plt.gcf(), regression_values\n\n\niface = gr.Interface(\n    sales_projections,\n    gr.inputs.Dataframe(\n        headers=[\"Name\", \"Jan Sales\", \"Feb Sales\", \"Mar Sales\"],\n        default=[[\"Jon\", 12, 14, 18], [\"Alice\", 14, 17, 2], [\"Sana\", 8, 9.5, 12]],\n    ),\n    [\"dataframe\", \"plot\", \"numpy\"],\n    description=\"Enter sales figures for employees to predict sales trajectory over year.\",\n)\niface.launch()\n\n```\n![sales_projections interface](demo/sales_projections/screenshot.gif)\n\n### Example Inputs\n\nYou can provide example data that a user can easily load into the model. This can be helpful to demonstrate the types of inputs the model expects, as well as to provide a way to explore your dataset in conjunction with your model. To load example data, you provide a **nested list** to the  `examples=`  keyword argument of the Interface constructor. Each sublist within the outer list represents a data sample, and each element within the sublist represents an input for each input component. The format of example data for each component is specified in the  [Docs](https://gradio.app/docs).\n\n```python\nimport gradio as gr\n\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\n\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.inputs.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    examples=[\n        [5, \"add\", 3],\n        [4, \"divide\", 2],\n        [-4, \"multiply\", 2.5],\n        [0, \"subtract\", 1.2],\n    ],\n    title=\"test calculator\",\n    description=\"heres a sample toy calculator. enjoy!\",\n    flagging_options=[\"this\", \"or\", \"that\"],\n)\n\niface.launch()\n\n```\n![calculator interface](demo/calculator/screenshot.gif)\n\nYou can load a large dataset into the examples to browse and interact with the dataset through Gradio. The examples will be automatically paginated (you can configure this through the `examples_per_page` argument of Interface) and you can use CTRL + arrow keys to navigate through the examples quickly.\n\n### Live Interfaces\n\nYou can make interfaces automatically refresh by setting `live=True` in the interface. Now the interface will recalculate as soon as the user input changes.\n\n```python\nimport gradio as gr\n\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\n\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.inputs.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    live=True,\n)\n\niface.launch()\n\n```\n![calculator_live interface](demo/calculator_live/screenshot.gif)\n\nNote there is no submit button, because the interface resubmits automatically on change.\n\n### Using State\n\nYour function may use data that persists beyond a single function call. If the data is something accessible to all function calls and all users, you can create a global variable outside the function call and access it inside the function. For example, you may load a large model outside the function and use it inside the function so that every function call does not need to reload the model.\n\nAnother type of data persistence Gradio supports is session **state**, where data persists across multiple submits within a page load. However, data is *not* shared between different users of your model. To store data in a session state, you need to do three things: (1) Pass in an extra parameter into your function, which represents the state of the interface. (2) At the end of the function, return the updated value of the state as an extra return value (3) Add the `'state'` input and `'state'` output components when creating your `Interface`. See the chatbot example below: \n\n```python\nimport random\n\nimport gradio as gr\n\n\ndef chat(message, history):\n    history = history or []\n    if message.startswith(\"How many\"):\n        response = random.randint(1, 10)\n    elif message.startswith(\"How\"):\n        response = random.choice([\"Great\", \"Good\", \"Okay\", \"Bad\"])\n    elif message.startswith(\"Where\"):\n        response = random.choice([\"Here\", \"There\", \"Somewhere\"])\n    else:\n        response = \"I don't know\"\n    history.append((message, response))\n    html = \"<div class='chatbot'>\"\n    for user_msg, resp_msg in history:\n        html += f\"<div class='user_msg'>{user_msg}</div>\"\n        html += f\"<div class='resp_msg'>{resp_msg}</div>\"\n    html += \"</div>\"\n    return html, history\n\n\niface = gr.Interface(\n    chat,\n    [\"text\", \"state\"],\n    [\"html\", \"state\"],\n    css=\"\"\"\n    .chatbox {display:flex;flex-direction:column}\n    .user_msg, .resp_msg {padding:4px;margin-bottom:4px;border-radius:4px;width:80%}\n    .user_msg {background-color:cornflowerblue;color:white;align-self:start}\n    .resp_msg {background-color:lightgray;align-self:self-end}\n\"\"\",\n    allow_screenshot=False,\n    allow_flagging=\"never\",\n)\niface.launch()\n\n```\n![chatbot interface](demo/chatbot/screenshot.gif)\n\nNotice how the state persists across submits within each page, but the state is not shared between the two pages. Some more points to note: you can pass in a default value to the state parameter, which is used as the initial value of the state. The state must be a something that can be serialized to a JSON format (e.g. a dictionary, a list, or a single value. Typically, objects will not work).  \n\n### Flagging\n\nUnderneath the output interfaces, there is a button marked \"Flag\". When a user testing your model sees input with interesting output, such as erroneous or unexpected model behaviour, they can flag the input for the interface creator to review. Within the directory provided by the  `flagging_dir=`  argument to the Interface constructor, a CSV file will log the flagged inputs. If the interface involves file data, such as for Image and Audio components, folders will be created to store those flagged data as well.\n\nFor example, with the calculator interface shown above, we would have the flagged data stored in the flagged directory shown below:\n\n```directory\n+-- calculator.py\n+-- flagged/\n|   +-- logs.csv\n```\n\n*flagged/logs.csv*\n```csv\nnum1,operation,num2,Output\n5,add,7,12\n6,subtract,1.5,4.5\n```\n\nWith the sepia interface shown above, we would have the flagged data stored in the flagged directory shown below:\n\n```directory\n+-- sepia.py\n+-- flagged/\n|   +-- logs.csv\n|   +-- im/\n|   |   +-- 0.png\n|   |   +-- 1.png\n|   +-- Output/\n|   |   +-- 0.png\n|   |   +-- 1.png\n```\n\n*flagged/logs.csv*\n```csv\nim,Output\nim/0.png,Output/0.png\nim/1.png,Output/1.png\n```\n\nYou can review these flagged inputs by manually exploring the flagging directory, or load them into the examples of the Gradio interface by pointing the  `examples=`  argument to the flagged directory. If you wish for the user to provide a reason for flagging, you can pass a list of strings to the `flagging_options` argument of Interface. Users will have to select one of the strings when flagging, which will be saved as an additional column to the CSV.\n\n### Sharing Interfaces Publicly\n\nInterfaces can be easily shared publicly by setting `share=True` in the `launch()` method. Like this:\n\n```python\ngr.Interface(classify_image, \"image\", \"label\").launch(share=True)\n```\n\nThis generates a public, shareable link that you can send to anybody! When you send this link, the user on the other side can try out the model in their browser. Because the processing happens on your device (as long as your device stays on!), you don't have to worry about any packaging any dependencies. If you're working out of colab notebook, a share link is always automatically created. It usually looks something like this:  **XXXXX.gradio.app**. Although the link is served through a gradio link, we are only a proxy for your local server, and do not store any data sent through the interfaces.\n\nKeep in mind, however, that these links are publicly accessible, meaning that anyone can use your model for prediction! Therefore, make sure not to expose any sensitive information through the functions you write, or allow any critical changes to occur on your device. If you set `share=False` (the default), only a local link is created, which can be shared by  [port-forwarding](https://www.ssh.com/ssh/tunneling/example)  with specific users. \n\nShare links expire after 72 hours. For permanent hosting, see Hosting Gradio Apps on Spaces below.\n\n![Sharing diagram](website/homepage/src/assets/img/sharing.svg)\n\n### Hosting Gradio Apps on Spaces\n\nHuggingface provides the infrastructure to permanently host your Gradio model on the internet, for free! You can either drag and drop a folder containing your Gradio model and all related files, or you can point HF Spaces to your Git repository and HP Spaces will pull the Gradio interface from there. See [Huggingface Spaces](http://huggingface.co/spaces/) for more information. \n\n![Hosting Demo](website/homepage/src/assets/img/hf_demo.gif)\n\n## Advanced Features\n<span id=\"advanced-features\"></span>\n\nHere, we go through several advanced functionalities that your Gradio demo can include without you needing to write much more code!\n\n### Authentication\n\nYou may wish to put an authentication page in front of your interface to limit who can open your interface. With the `auth=` keyword argument in the `launch()` method, you can pass a list of acceptable username/password tuples; or, for more complex authentication handling, you can even pass a function that takes a username and password as arguments, and returns True to allow authentication, False otherwise. Here's an example that provides password-based authentication for a single user named \"admin\":\n\n```python\ngr.Interface(fn=classify_image, inputs=image, outputs=label).launch(auth=(\"admin\", \"pass1234\"))\n```\n\n### Interpreting your Predictions\n\nMost models are black boxes such that the internal logic of the function is hidden from the end user. To encourage transparency, we've made it very easy to add interpretation to your model by  simply setting the `interpretation` keyword in the `Interface` class to `default`. This allows your users to understand what parts of the input are responsible for the output. Take a look at the simple interface below which shows an image classifier that also includes interpretation:\n\n```python\nimport requests\nimport tensorflow as tf\n\nimport gradio as gr\n\ninception_net = tf.keras.applications.MobileNetV2()  # load the model\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\n\ndef classify_image(inp):\n    inp = inp.reshape((-1, 224, 224, 3))\n    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n    prediction = inception_net.predict(inp).flatten()\n    return {labels[i]: float(prediction[i]) for i in range(1000)}\n\n\nimage = gr.inputs.Image(shape=(224, 224))\nlabel = gr.outputs.Label(num_top_classes=3)\n\ngr.Interface(\n    fn=classify_image, inputs=image, outputs=label, interpretation=\"default\"\n).launch()\n\n```\n\n\nIn addition to `default`, Gradio also includes [Shapley-based interpretation](https://christophm.github.io/interpretable-ml-book/shap.html), which provides more accurate interpretations, albeit usually with a slower runtime. To use this, simply set the `interpretation` parameter to `\"shap\"` (note: also make sure the python package `shap` is installed). Optionally, you can modify the the `num_shap` parameter, which controls the tradeoff between accuracy and runtime (increasing this value generally increases accuracy). Here is an example:\n\n```python\ngr.Interface(fn=classify_image, inputs=image, outputs=label, interpretation=\"shap\", num_shap=5).launch()\n```\n\nThis will work for any function, even if internally, the model is a complex neural network or some other black box. If you use Gradio's `default` or `shap` interpretation, the output component must be a `Label`. All common input components are supported. Here is an example with text input.\n\n```python\nimport re\n\nimport gradio as gr\n\nmale_words, female_words = [\"he\", \"his\", \"him\"], [\"she\", \"hers\", \"her\"]\n\n\ndef gender_of_sentence(sentence):\n    male_count = len([word for word in sentence.split() if word.lower() in male_words])\n    female_count = len(\n        [word for word in sentence.split() if word.lower() in female_words]\n    )\n    total = max(male_count + female_count, 1)\n    return {\"male\": male_count / total, \"female\": female_count / total}\n\n\niface = gr.Interface(\n    fn=gender_of_sentence,\n    inputs=gr.inputs.Textbox(default=\"She went to his house to get her keys.\"),\n    outputs=\"label\",\n    interpretation=\"default\",\n)\niface.launch()\n\n```\n\nSo what is happening under the hood? With these interpretation methods, Gradio runs the prediction multiple times with modified versions of the input. Based on the results, you'll see that the interface automatically highlights the parts of the text (or image, etc.) that contributed increased the likelihood of the class as red. The intensity of color corresponds to the importance of that part of the input. The parts that decrease the class confidence are highlighted blue.\n\nYou can also write your own interpretation function. The demo below adds custom interpretation to the previous demo. This function will take the same inputs as the main wrapped function. The output of this interpretation function will be used to highlight the input of each input interface - therefore the number of outputs here corresponds to the number of input interfaces. To see the format for interpretation for each input interface, check the Docs.\n\n```python\nimport re\n\nimport gradio as gr\n\nmale_words, female_words = [\"he\", \"his\", \"him\"], [\"she\", \"hers\", \"her\"]\n\n\ndef gender_of_sentence(sentence):\n    male_count = len([word for word in sentence.split() if word.lower() in male_words])\n    female_count = len(\n        [word for word in sentence.split() if word.lower() in female_words]\n    )\n    total = max(male_count + female_count, 1)\n    return {\"male\": male_count / total, \"female\": female_count / total}\n\n\ndef interpret_gender(sentence):\n    result = gender_of_sentence(sentence)\n    is_male = result[\"male\"] > result[\"female\"]\n    interpretation = []\n    for word in re.split(\"( )\", sentence):\n        score = 0\n        token = word.lower()\n        if (is_male and token in male_words) or (not is_male and token in female_words):\n            score = 1\n        elif (is_male and token in female_words) or (\n            not is_male and token in male_words\n        ):\n            score = -1\n        interpretation.append((word, score))\n    return interpretation\n\n\niface = gr.Interface(\n    fn=gender_of_sentence,\n    inputs=gr.inputs.Textbox(default=\"She went to his house to get her keys.\"),\n    outputs=\"label\",\n    interpretation=interpret_gender,\n    enable_queue=True,\n)\niface.launch()\n\n```\n\n### Themes and Custom Styling\n\nIf you'd like to change how your interface looks, you can select a different theme by simply passing in the `theme` parameter, like so:\n\n```python\ngr.Interface(fn=classify_image, inputs=image, outputs=label, theme=\"huggingface\").launch()\n```\n\nHere are the themes we currently support: `\"default\"`, `\"huggingface\"`, `\"grass\"`, `\"peach\"`, and the dark themes corresponding to each of these: `\"darkdefault\"`, `\"darkhuggingface\"`, `\"darkgrass\"`, `\"darkpeach\"`.\n\nIf you'd like to have more fine-grained control over any aspect of the app, you can also write your own css or pass in a css file, with the `css` parameter of the `Interface` class.\n\n### Custom Flagging Options\n\nIn some cases, you might like to provide your users or testers with *more* than just a binary option to flag a sample. You can provide `flagging_options` that they select from a dropdown each time they click the flag button. This lets them provide additional feedback every time they flag a sample.\n\nHere's an example:\n\n```python\ngr.Interface(fn=classify_image, inputs=image, outputs=label, flagging_options=[\"incorrect\", \"ambiguous\", \"offensive\", \"other\"]).launch()\n```\n\n### Loading Hugging Face Models and Spaces\n\nGradio integrates nicely with the Hugging Face Hub, allowing you to load models and Spaces with just one line of code. To use this, simply use the `load()` method in the `Interface` class. So:\n\n- To load any model from the Hugging Face Hub and create an interface around it, you pass `\"model/\"` or `\"huggingface/\"` followed by the model name, like these examples:\n\n```python\ngr.Interface.load(\"huggingface/gpt2\").launch();\n```\n\n```python\ngr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\", \n    inputs=gr.inputs.Textbox(lines=5, label=\"Input Text\")  # customizes the input component\n).launch()\n```\n\n- To load any Space from the Hugging Face Hub and recreate it locally (so that you can customize the inputs and outputs for example), you pass `\"spaces/\"` followed by the model name:\n\n```python\ngr.Interface.load(\"spaces/eugenesiow/remove-bg\", inputs=\"webcam\", title=\"Remove your webcam background!\").launch()\n```\n\nOne of the great things about loading Hugging Face models or spaces using Gradio is that you can then immediately use the resulting `Interface` object just like function in your Python code (this works for every type of model/space: text, images, audio, video, and even multimodal models):\n\n```python\nio = gr.Interface.load(\"models/EleutherAI/gpt-neo-2.7B\")\nio(\"It was the best of times\")  # outputs model completion\n```\n\n### Putting Interfaces in Parallel and Series\n\nGradio also lets you mix interfaces very easily using the `gradio.Parallel` and `gradio.Series` classes. `Parallel` lets you put two similar models (if they have the same input type) in parallel to compare model predictions:\n\n```python\ngenerator1 = gr.Interface.load(\"huggingface/gpt2\")\ngenerator2 = gr.Interface.load(\"huggingface/EleutherAI/gpt-neo-2.7B\")\ngenerator3 = gr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\")\n\ngr.Parallel(generator1, generator2, generator3).launch()\n```\n\n`Series` lets you put models and spaces in series, piping the output of one model into the input of the next model. \n\n```python\ngenerator = gr.Interface.load(\"huggingface/gpt2\")\ntranslator = gr.Interface.load(\"huggingface/t5-small\")\n\ngr.Series(generator, translator).launch()  # this demo generates text, then translates it to German, and outputs the final result.\n```\n\nAnd of course, you can also mix `Parallel` and `Series` together whenever that makes sense!\n\n### Queuing to Manage Long Inference Times\n\nIf many people are using your interface or if the inference time of your function is long (> 1min), simply set the `enable_queue` parameter in the `launch` method to `True` to prevent timeouts.\n\n```python\ngr.Interface(fn=classify_image, inputs=image, outputs=label).launch(enable_queue=True)\n```\n\nThis sets up a queue of workers to handle the predictions and return the response to the front end. This is strongly recommended if you are planning on uploading your demo to Hugging Face Spaces (as described above) so that you can manage a large number of users simultaneously using your demo.\n\n\n\n\n\n##  System Requirements:\n\nGradio requires Python `3.7+` and has been tested on the latest versions of Windows, MacOS, and various common Linux distributions (e.g. Ubuntu). For Python package requirements, please see the `setup.py` file.\n\n##  Contributing:\n\nIf you would like to contribute and your contribution is small, you can directly open a pull request (PR). If you would like to contribute a larger feature, we recommend first creating an issue with a proposed design for discussion. Please see our [contributing guidelines](https://github.com/gradio-app/gradio/blob/master/CONTRIBUTING.md) for more info.\n\n##  License:\n\nGradio is licensed under the Apache License 2.0\n\n\n##  See more:\n\nYou can find many more examples as well as more info on usage on our website: www.gradio.app\n\nSee, also, the accompanying paper: [\"Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild\"](https://arxiv.org/pdf/1906.02569.pdf), *ICML HILL 2019*, and please use the citation below.\n\n```\n@article{abid2019gradio,\ntitle={Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild},\nauthor={Abid, Abubakar and Abdalla, Ali and Abid, Ali and Khan, Dawood and Alfozan, Abdulrahman and Zou, James},\njournal={arXiv preprint arXiv:1906.02569},\nyear={2019}\n}\n```",
	"big-data-analytics data-analysis data-exploration data-profiling data-quality data-science deep-learning eda exploration exploratory-data-analysis hacktoberfest html-report jupyter jupyter-notebook machine-learning pandas pandas-dataframe pandas-profiling python statistics": "# `pandas-profiling`\n\n![Pandas Profiling Logo Header](https://pandas-profiling.ydata.ai/docs/assets/logo_header.png)\n\n[![Build Status](https://github.com/ydataai/pandas-profiling/actions/workflows/tests.yml/badge.svg?branch=master)](https://github.com/ydataai/pandas-profiling/actions/workflows/tests.yml)\n[![PyPI download month](https://img.shields.io/pypi/dm/pandas-profiling.svg)](https://pypi.python.org/pypi/pandas-profiling/)\n[![](https://pepy.tech/badge/pandas-profiling)](https://pypi.org/project/pandas-profiling/)\n[![Code Coverage](https://codecov.io/gh/ydataai/pandas-profiling/branch/master/graph/badge.svg?token=gMptB4YUnF)](https://codecov.io/gh/ydataai/pandas-profiling)\n[![Release Version](https://img.shields.io/github/release/ydataai/pandas-profiling.svg)](https://github.com/ydataai/pandas-profiling/releases)\n[![Python Version](https://img.shields.io/pypi/pyversions/pandas-profiling)](https://pypi.org/project/pandas-profiling/)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)\n\n\n<p align=\"center\">\n  <a href=\"https://pandas-profiling.ydata.ai/docs/master/\">Documentation</a>\n  |\n  <a href=\"https://slack.datacentricai.community/\">Slack</a>\n  | \n  <a href=\"https://stackoverflow.com/questions/tagged/pandas-profiling\">Stack Overflow</a>\n  |\n  <a href=\"https://pandas-profiling.ydata.ai/docs/master/pages/reference/changelog.html#changelog\">Latest changelog</a>\n\n</p>\n\n<p align=\"center\">\n  Do you like this project? Show us your love and <a href=\"https://engage.ydata.ai\">give feedback!</a>\n</p>\n\n`pandas-profiling` generates profile reports from a pandas `DataFrame`. The pandas `df.describe()` function is handy yet a little basic for exploratory data analysis. `pandas-profiling` extends pandas `DataFrame` with `df.profile_report()`, which automatically generates a standardized univariate and multivariate report for data understanding.\n\nFor each column, the following information (whenever relevant for the column type) is presented in an interactive HTML report:\n\n- **Type inference**: detect the types of columns in a DataFrame\n- **Essentials**: type, unique values, indication of missing values\n- **Quantile statistics**: minimum value, Q1, median, Q3, maximum, range, interquartile range\n- **Descriptive statistics**: mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness\n- **Most frequent and extreme values**\n- **Histograms**: categorical and numerical\n- **Correlations**: high correlation warnings, based on different correlation metrics (Spearman, Pearson, Kendall, Cram\u00e9r\u2019s V, Phik)\n- **Missing values**: through counts, matrix and heatmap\n- **Duplicate rows**: list of the most common duplicated rows\n- **Text analysis**: most common categories (uppercase, lowercase, separator), scripts (Latin, Cyrillic) and blocks (ASCII, Cyrilic)\n- **File and Image analysis**: file sizes, creation dates, dimensions, indication of truncated images and existence of EXIF metadata\n\nThe report contains three additional sections:\n\n- **Overview**: mostly global details about the dataset (number of records, number of variables, overall missigness and duplicates, memory footprint)\n- **Alerts**: a comprehensive and automatic list of potential data quality issues (high correlation, skewness, uniformity, zeros, missing values, constant values, between others)\n- **Reproduction**: technical details about the analysis (time, version and configuration)\n\n\n> \u26a1 Looking for a Spark backend to profile large datasets? It's [work in progress](https://github.com/ydataai/pandas-profiling/projects/3).\n> \n> \u231b Interested in uncovering temporal patterns? Check out [popmon](https://github.com/ing-bank/popmon).\n\n## \u25b6\ufe0f Quickstart\n\nStart by loading your pandas `DataFrame` as you normally would, e.g. by using:\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom pandas_profiling import ProfileReport\n\ndf = pd.DataFrame(np.random.rand(100, 5), columns=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n```\n\nTo generate the standard profiling report, merely run:\n\n```python\nprofile = ProfileReport(df, title=\"Pandas Profiling Report\")\n```\n\n### Using inside Jupyter Notebooks\n\nThere are two interfaces to consume the report inside a Jupyter notebook: through widgets and through an embedded HTML report.\n\n<img alt=\"Notebook Widgets\" src=\"https://pandas-profiling.ydata.ai/docs/master/assets/widgets.gif\" width=\"800\" />\n\nThe above is achieved by simply displaying the report as a set of widgets. In a Jupyter Notebook, run:\n\n```python\nprofile.to_widgets()\n```\n\nThe HTML report can be directly embedded in a cell in a similar fashion:\n\n```python\nprofile.to_notebook_iframe()\n```\n\n<img alt=\"HTML\" src=\"https://pandas-profiling.ydata.ai/docs/master/assets/iframe.gif\" width=\"800\" />\n\n### Exporting the report to a file\n\nTo generate a HTML report file, save the `ProfileReport` to an object and use the `to_file()` function:\n\n```python\nprofile.to_file(\"your_report.html\")\n```\n\nAlternatively, the report's data can be obtained as a JSON file:\n\n```python\n# As a JSON string\njson_data = profile.to_json()\n\n# As a file\nprofile.to_file(\"your_report.json\")\n```\n\n### Using in the command line\n\nFor standard formatted CSV files (which can be read directly by pandas without additional settings), the `pandas_profiling` executable can be used in the command line. The example below generates a report named _Example Profiling Report_, using a configuration file called `default.yaml`, in the file `report.html` by processing a `data.csv` dataset.\n\n```sh\npandas_profiling --title \"Example Profiling Report\" --config_file default.yaml data.csv report.html\n```\n\nAdditional details on the CLI are available [on the documentation](https://pandas-profiling.ydata.ai/docs/master/pages/getting_started/quickstart.html#command-line-usage).\n\n## \ud83d\udc40 Examples\n\nThe following example reports showcase the potentialities of the package across a wide range of dataset and data types:\n\n* [Census Income](https://pandas-profiling.ydata.ai/examples/master/census/census_report.html) (US Adult Census data relating income with other demographic properties)\n* [NASA Meteorites](https://pandas-profiling.ydata.ai/examples/master/meteorites/meteorites_report.html) (comprehensive set of meteorite landing - object properties and locations) [![Open In Colab](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/ydataai/pandas-profiling/blob/master/examples/meteorites/meteorites.ipynb) [![Binder](https://camo.githubusercontent.com/483bae47a175c24dfbfc57390edd8b6982ac5fb3/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667)](https://mybinder.org/v2/gh/ydataai/pandas-profiling/master?filepath=examples%2Fmeteorites%2Fmeteorites.ipynb)\n* [Titanic](https://pandas-profiling.ydata.ai/examples/master/titanic/titanic_report.html) (the \"Wonderwall\" of datasets) [![Open In Colab](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/ydataai/pandas-profiling/blob/master/examples/titanic/titanic.ipynb) [![Binder](https://camo.githubusercontent.com/483bae47a175c24dfbfc57390edd8b6982ac5fb3/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667)](https://mybinder.org/v2/gh/ydataai/pandas-profiling/master?filepath=examples%2Ftitanic%2Ftitanic.ipynb)\n* [NZA](https://pandas-profiling.ydata.ai/examples/master/nza/nza_report.html) (open data from the Dutch Healthcare Authority)\n* [Stata Auto](https://pandas-profiling.ydata.ai/examples/master/stata_auto/stata_auto_report.html) (1978 Automobile data)\n* [Colors](https://pandas-profiling.ydata.ai/examples/master/colors/colors_report.html) (a simple colors dataset)\n* [Vektis](https://pandas-profiling.ydata.ai/examples/master/vektis/vektis_report.html) (Vektis Dutch Healthcare data)\n* [UCI Bank Dataset](https://pandas-profiling.ydata.ai/examples/master/bank_marketing_data/uci_bank_marketing_report.html) (marketing dataset from a bank)\n* [Russian Vocabulary](https://pandas-profiling.ydata.ai/examples/master/features/russian_vocabulary.html) (100 most common Russian words, showcasing unicode text analysis)\n* [Website Inaccessibility](https://pandas-profiling.ydata.ai/examples/master/features/website_inaccessibility_report.html) (website accessibility analysis, showcasing support for URL data)\n* [Orange prices](https://pandas-profiling.ydata.ai/examples/master/features/united_report.html) and [Coal prices](https://pandas-profiling.ydata.ai/examples/master/features/flatly_report.html) (simple pricing evolution datasets, showcasing the theming options)\n\n## \ud83d\udee0\ufe0f Installation\n\nAdditional details, including information about widget support, are available [on the documentation](https://pandas-profiling.ydata.ai/docs/master/pages/getting_started/installation.html).\n\n### Using pip\n[![PyPi Downloads](https://pepy.tech/badge/pandas-profiling)](https://pepy.tech/project/pandas-profiling)\n[![PyPi Monthly Downloads](https://pepy.tech/badge/pandas-profiling/month)](https://pepy.tech/project/pandas-profiling/month)\n[![PyPi Version](https://badge.fury.io/py/pandas-profiling.svg)](https://pypi.org/project/pandas-profiling/)\n\nYou can install using the `pip` package manager by running:\n\n```sh\npip install -U pandas-profiling\n```\n\n#### Extras\n\nThe package declares \"extras\", sets of additional dependencies.\n\n* `[notebook]`: support for rendering the report in Jupyter notebook widgets.\n* `[unicode]`: support for more detailed Unicode analysis, at the expense of additional disk space.\n\nInstall these with e.g.\n\n```sh\npip install -U pandas-profiling[notebook,unicode]\n```\n\n\n### Using conda\n[![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/pandas-profiling.svg)](https://anaconda.org/conda-forge/pandas-profiling)\n[![Conda Version](https://img.shields.io/conda/vn/conda-forge/pandas-profiling.svg)](https://anaconda.org/conda-forge/pandas-profiling) \n\n\nYou can install using the `conda` package manager by running:\n\n```sh\nconda install -c conda-forge pandas-profiling\n```\n\n### From source (development)\n\nDownload the source code by cloning the repository or click on [Download ZIP](https://github.com/ydataai/pandas-profiling/archive/master.zip) to download the latest stable version.\n\nInstall it by navigating to the proper directory and running:\n\n```sh\npip install -e .\n```\n\nThe profiling report is written in HTML and CSS, which means a modern browser is required. \n\nYou need [Python 3](https://python3statement.org/) to run the package. Other dependencies can be found in the requirements files:\n\n| Filename | Requirements|\n|----------|-------------|\n| [requirements.txt](https://github.com/ydataai/pandas-profiling/blob/master/requirements.txt) | Package requirements|\n| [requirements-dev.txt](https://github.com/ydataai/pandas-profiling/blob/master/requirements-dev.txt)  |  Requirements for development|\n| [requirements-test.txt](https://github.com/ydataai/pandas-profiling/blob/master/requirements-test.txt) | Requirements for testing|\n| [setup.py](https://github.com/ydataai/pandas-profiling/blob/master/setup.py) | Requirements for widgets etc. |\n\n## \ud83d\udcdd Use cases\n\nThe documentation includes guides, tips and tricks for tackling common use cases:\n\n| Use case                                                                                                                            | Description |\n|-------------------------------------------------------------------------------------------------------------------------------------|--|\n| [Profiling large datasets](https://pandas-profiling.ydata.ai/docs/master/pages/use_cases/big_data.html )                            | Tips on how to prepare data and configure `pandas-profiling` for working with large datasets |\n| [Handling sensitive data](https://pandas-profiling.ydata.ai/docs/master/pages/use_cases/sensitive_data.html )                       | Generating reports which are mindful about sensitive data in the input dataset |\n| [Comparing datasets](https://pandas-profiling.ydata.ai/docs/master/pages/use_cases/comparing_datasets.html )                        | Comparing multiple version of the same dataset |\n| [Dataset metadata and data dictionaries](https://pandas-profiling.ydata.ai/docs/master/pages/use_cases/metadata.html)               | Complementing the report with dataset details and column-specific data dictionaries |\n| [Customizing the report's appearance](https://pandas-profiling.ydata.ai/docs/master/pages/use_cases/custom_report_appearance.html ) | Changing the appearance of the report's page and of the contained visualizations |\n\n## \ud83d\udd17 Integrations\n\nTo maximize its usefulness in real world contexts, `pandas-profiling` has a set of implicit and explicit integrations with a variety of other actors in the Data Science ecosystem: \n\n| Integration type | Description |\n|---|---|\n| [Other DataFrame libraries](https://pandas-profiling.ydata.ai/docs/master/pages/integrations/other_dataframe_libraries.html) | How to compute the profiling of data stored in libraries other than pandas |\n| [Great Expectations](https://pandas-profiling.ydata.ai/docs/master/pages/integrations/great_expectations.html) | Generating [Great Expectations](https://greatexpectations.io) expectations suites directly from a profiling report |\n| [Interactive applications](https://pandas-profiling.ydata.ai/docs/master/pages/integrations/data_apps.html) | Embedding profiling reports in [Streamlit](http://streamlit.io), [Dash](http://dash.plotly.com) or [Panel](https://panel.holoviz.org) applications |\n| [Pipelines](https://pandas-profiling.ydata.ai/docs/master/pages/integrations/pipelines.html) | Integration with DAG workflow execution tools like [Airflow](https://airflow.apache.org) or [Kedro](https://kedro.org) |\n| [Cloud services](https://pandas-profiling.ydata.ai/docs/master/pages/integrations/cloud_services.html) | Using `pandas-profiling` in hosted computation services like [Lambda](https://lambdalabs.com), [Google Cloud](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/blob/master/retail/propensity-model/bqml/bqml_kfp_retail_propensity_to_purchase.ipynb) or [Kaggle](https://www.kaggle.com/code) |\n| [IDEs](https://pandas-profiling.ydata.ai/docs/master/pages/integrations/ides.html) | Using `pandas-profiling` directly from integrated development environments such as [PyCharm](https://www.jetbrains.com/pycharm/) |\n\n## \ud83d\ude4b Support\nNeed help? Want to share a perspective? Report a bug? Ideas for collaborations? Reach out via the following channels:\n\n- [Stack Overflow](https://stackoverflow.com/questions/tagged/pandas-profiling): ideal for asking questions on how to use the package\n- [GitHub Issues](https://github.com/ydataai/pandas-profiling/issues): bugs, proposals for changes, feature requests\n- [Slack](https://slack.datacentricai.community): general chat, questions, collaborations\n- [Email](mailto:developers@ydata.ai): project collaborations or sponsoring\n\n> \u2757 Before reporting an issue on GitHub, check out [Common Issues](https://pandas-profiling.ydata.ai/docs/master/pages/support_contrib/common_issues.html).\n\n## \ud83e\udd1d\ud83c\udffd Contributing\n\nLearn how to get involved in the [Contribution Guide](https://pandas-profiling.ydata.ai/docs/master/pages/support_contrib/contribution_guidelines.html).\n\nA low-threshold place to ask questions or start contributing is the [Data Centric AI Community's Slack](https://slack.datacentricai.community).\n",
	"data-analysis data-science data-wrangling datacleaning datacleansing datajournalism datamining java journalism opendata reconciliation wikidata": "# OpenRefine\n\n[![DOI](https://zenodo.org/badge/6220644.svg)](https://zenodo.org/badge/latestdoi/6220644)\n[![Join the chat at https://gitter.im/OpenRefine/OpenRefine](https://badges.gitter.im/OpenRefine/OpenRefine.svg)](https://gitter.im/OpenRefine/OpenRefine) ![Java CI](https://github.com/OpenRefine/OpenRefine/workflows/Continuous%20Integration/badge.svg) [![Coverage Status](https://coveralls.io/repos/github/OpenRefine/OpenRefine/badge.svg?branch=master)](https://coveralls.io/github/OpenRefine/OpenRefine?branch=master) [![Translation progress](https://hosted.weblate.org/widgets/openrefine/-/svg-badge.svg)](https://hosted.weblate.org/engage/openrefine/?utm_source=widget)\n\nOpenRefine is a Java-based power tool that allows you to load data, understand it,\nclean it up, reconcile it, and augment it with data coming from\nthe web. All from a web browser and the comfort and privacy of your own computer.\n\n[<img src=\"https://github.com/OpenRefine/OpenRefine/blob/master/graphics/icon/open-refine-320px.png\" align=\"right\">](http://openrefine.org)\n\n## Download\n\n* [OpenRefine Releases](https://github.com/OpenRefine/OpenRefine/releases)\n\n## Snapshot releases\n\nLatest development version, packaged for:\n* [Linux](https://oss.sonatype.org/service/local/artifact/maven/content?r=snapshots&g=org.openrefine&a=openrefine&v=3.7-SNAPSHOT&c=linux&p=tar.gz)\n* [MacOS](https://oss.sonatype.org/service/local/artifact/maven/content?r=snapshots&g=org.openrefine&a=openrefine&v=3.7-SNAPSHOT&c=mac&p=dmg)\n* [Windows without embedded JRE](https://oss.sonatype.org/service/local/artifact/maven/content?r=snapshots&g=org.openrefine&a=openrefine&v=3.7-SNAPSHOT&c=win&p=zip)\n* [Windows with embedded JRE](https://oss.sonatype.org/service/local/artifact/maven/content?r=snapshots&g=org.openrefine&a=openrefine&v=3.7-SNAPSHOT&c=win-with-java&p=zip)\n\n## Run from source\n\nIf you have cloned this repository to your computer, you can run OpenRefine with:\n\n* `./refine` on Mac OS and Linux\n* `refine.bat` on Windows\n\nThis requires [JDK 11](https://adoptium.net/), [Apache Maven](https://maven.apache.org/) and [NPM](https://www.npmjs.com/).\n\n## Documentation and Videos\n\n* [User Manual](https://docs.openrefine.org)\n* [FAQ](https://github.com/OpenRefine/OpenRefine/wiki/FAQ)\n* [Official Website and tutorial videos](http://openrefine.org)\n\n## Contributing to the project\n\n* [Developers Guide & Architecture](https://github.com/OpenRefine/OpenRefine/wiki/Documentation-For-Developers)\n* [Contributing Guide](https://github.com/OpenRefine/OpenRefine/blob/master/CONTRIBUTING.md)\n* [Project Governance](https://github.com/OpenRefine/OpenRefine/blob/master/GOVERNANCE.md)\n\n## Contact us\n\n* [Mailing List](https://groups.google.com/forum/#!forum/openrefine)\n* [Twitter](http://www.twitter.com/openrefine)\n* [Gitter](https://gitter.im/OpenRefine/OpenRefine)\n* [Matrix (bridged from Gitter)](https://matrix.to/#/#OpenRefine_OpenRefine:gitter.im)\n\n## Licensing and legal issues\n\nOpenRefine is open source software and is licensed under the BSD license\nlocated in the [LICENSE.txt](LICENSE.txt). See the folder `licenses` for information on open source\nlibraries that OpenRefine depends on.\n\n## Credits\n\nThis software was created by Metaweb Technologies, Inc. and originally written\nand conceived by David Huynh <dfhuynh@google.com>. Metaweb Technologies, Inc.\nwas acquired by Google, Inc. in July 2010 and the product was renamed Google Refine.\nIn October 2012, it was renamed OpenRefine as it transitioned to a\ncommunity-supported product.\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for instructions on how to contribute yourself.\n",
	"airbyte bigquery change-data-capture data data-analysis data-collection data-engineering data-ingestion data-integration elt etl java pipeline python redshift snowflake": "# Introduction\n\n[![GitHub stars](https://img.shields.io/github/stars/airbytehq/airbyte?style=social&label=Star&maxAge=2592000)](https://GitHub.com/airbytehq/airbyte/stargazers/) [![GitHub Workflow Status](https://img.shields.io/github/workflow/status/airbytehq/airbyte/Airbyte%20CI)](https://github.com/airbytehq/airbyte/actions/workflows/gradle.yml) [![License](https://img.shields.io/static/v1?label=license&message=MIT&color=brightgreen)](https://github.com/airbytehq/airbyte/tree/a9b1c6c0420550ad5069aca66c295223e0d05e27/LICENSE/README.md) [![License](https://img.shields.io/static/v1?label=license&message=ELv2&color=brightgreen)](https://github.com/airbytehq/airbyte/tree/a9b1c6c0420550ad5069aca66c295223e0d05e27/LICENSE/README.md)\n\n**Data integration is made simple, secure, and extensible.**\nThe new open-source standard to sync data from applications, APIs & databases to warehouses, lakes & other destinations.\n\nAirbyte is on a mission to make data integration pipelines a commodity.\n\n- **Maintenance-free connectors you can use in minutes**. Just authenticate your sources and warehouse, and get connectors that adapt to schema and API changes for you.\n- **Building new connectors made trivial.** We make it very easy to add new connectors that you need, using the language of your choice, by offering scheduling and orchestration.\n- Designed to **cover the long tail of connectors and needs**. Benefit from the community's battle-tested connectors and adapt them to your specific needs.\n- **Your data stays in your cloud**. Have full control over your data, and the costs of your data transfers.\n- **No more security compliance process** to go through as Airbyte is self-hosted.\n- **No more pricing indexed on volume**, as cloud-based solutions offer.\n\nHere's a list of our [connectors with their health status](docs/integrations/).\n\n## Quick start\n\n```bash\ngit clone https://github.com/airbytehq/airbyte.git\ncd airbyte\ndocker-compose up\n```\n\nNow visit [http://localhost:8000](http://localhost:8000). You will be asked for a username (default: `airbyte`) and password (default: `password`). You should update these values by changing `BASIC_AUTH_USERNAME` and `BASIC_AUTH_PASSWORD` in your local `.env` file.\n\nHere is a [step-by-step guide](https://github.com/airbytehq/airbyte/tree/e378d40236b6a34e1c1cb481c8952735ec687d88/docs/quickstart/getting-started.md) showing you how to load data from an API into a file, all on your computer.\n\n## Features\n\n- **Built for extensibility**: Adapt an existing connector to your needs or build a new one with ease.\n- **Optional normalized schemas**: Entirely customizable, start with raw data or from some suggestion of normalized data.\n- **Full-grade scheduler**: Automate your replications with the frequency you need.\n- **Real-time monitoring**: We log all errors in full detail to help you understand.\n- **Incremental updates**: Automated replications are based on incremental updates to reduce your data transfer costs.\n- **Manual full refresh**: Sometimes, you need to re-sync all your data to start again.\n- **Debugging autonomy**: Modify and debug pipelines as you see fit, without waiting.\n\n[See more on our website.](https://airbyte.io/features/)\n\n## Contributing\n\nWe love contributions to Airbyte, big or small.\n\nSee our [Contributing guide](docs/contributing-to-airbyte/README.md) on how to get started. Not sure where to start? We\u2019ve listed some [good first issues](https://github.com/airbytehq/airbyte/labels/good%20first%20issue) to start with. If you have any questions, please open a draft PR or visit our [slack channel](https://github.com/airbytehq/airbyte/tree/a9b1c6c0420550ad5069aca66c295223e0d05e27/slack.airbyte.io) where the core team can help answer your questions.\n\n**Note that you are able to create connectors using the language you want, as Airbyte connections run as Docker containers.**\n\n**Also, we will never ask you to maintain your connector. The goal is that the Airbyte team and the community help maintain it, let's call it crowdsourced maintenance!**\n\n## Community support\n\nFor general help using Airbyte, please refer to the official Airbyte documentation. For additional help, you can use one of these channels to ask a question:\n\n- [Slack](https://slack.airbyte.io) \\(For live discussion with the Community and Airbyte team\\)\n- [Forum](https://discuss.airbyte.io/) \\(For deeper conversations about features, connectors, or problems\\)\n- [GitHub](https://github.com/airbytehq/airbyte) \\(Bug reports, Contributions\\)\n- [Twitter](https://twitter.com/airbytehq) \\(Get the news fast\\)\n- [Weekly office hours](https://airbyte.io/weekly-office-hours/) \\(Live informal 30-minute video call sessions with the Airbyte team\\)\n\n## Reporting Vulnerabilities\n\n\u26a0\ufe0f Please do not file GitHub issues or post on our public forum for security vulnerabilities as they are public! \u26a0\ufe0f\n\nAirbyte takes security issues very seriously. If you have any concerns about Airbyte or believe you have uncovered a vulnerability, please get in touch via the e-mail address security@airbyte.io. In the message, try to provide a description of the issue and ideally a way of reproducing it. The security team will get back to you as soon as possible.\n\nNote that this security address should be used only for undisclosed vulnerabilities. Dealing with fixed issues or general questions on how to use the security features should be handled regularly via the user and the dev lists. Please report any security problems to us before disclosing it publicly.\n\n## Roadmap\n\nCheck out our [roadmap](https://app.harvestr.io/roadmap/view/pQU6gdCyc/launch-week-roadmap) to get informed on what we are currently working on, and what we have in mind for the next weeks, months, and years.\n\n## License\n\nSee the [LICENSE](docs/project-overview/licenses/) file for licensing information, and our [FAQ](docs/project-overview/licenses/license-faq.md) for any questions you may have on that topic.\n",
	"algorithms data-analysis data-science docker ipynb kaggle-inclass machine-learning math matplotlib numpy pandas plotly python scikit-learn scipy seaborn vowpal-wabbit": "<div align=\"center\">\n\n![ODS stickers](https://github.com/Yorko/mlcourse.ai/blob/main/img/ods_stickers.jpg)\n\n**[mlcourse.ai](https://mlcourse.ai) \u2013 Open Machine Learning Course**\n\n[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-green)](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n[![Slack](https://img.shields.io/badge/slack-ods.ai-orange)](https://opendatascience.slack.com/archives/C91N8TL83/p1567408586359500)\n[![Donate](https://img.shields.io/badge/support-patreon-red)](https://www.patreon.com/ods_mlcourse)\n[![Donate](https://img.shields.io/badge/support-ko--fi-red)](https://ko-fi.com/mlcourse_ai)\n\n</div>\n\n[mlcourse.ai](https://mlcourse.ai) is an open Machine Learning course by [OpenDataScience (ods.ai)](https://ods.ai/), led by [Yury Kashnitsky (yorko)](https://yorko.github.io/). Having both a Ph.D. degree in applied math and a Kaggle Competitions Master tier, Yury aimed at designing an ML course with a perfect balance between theory and practice. Thus, the course meets you with math formulae in lectures, and a lot of practice in a form of assignments and  Kaggle Inclass competitions. Currently, the course is in a **self-paced mode**. Here we guide you through the self-paced [mlcourse.ai](https://mlcourse.ai).\n\n__Bonus:__\nAdditionally, you can purchase a Bonus Assignments pack with the best non-demo versions of [mlcourse.ai](https://mlcourse.ai/) assignments. Select the [\"Bonus Assignments\" tier](https://www.patreon.com/ods_mlcourse). Refer to the details of the deal on the main page [mlcourse.ai](https://mlcourse.ai/).\n\nMirrors (:uk:-only): [mlcourse.ai](https://mlcourse.ai) (main site), [Kaggle Dataset](https://www.kaggle.com/kashnitsky/mlcourse) (same notebooks as Kaggle Notebooks)\n\n### Self-paced passing\nYou are guided through 10 weeks of [mlcourse.ai](https://mlcourse.ai). For each week, from Pandas to Gradient Boosting, instructions are given on which articles to read, lectures to watch, what assignments to accomplish.\n\n### Articles\nThis is the list of published articles on medium.com [:uk:](https://medium.com/open-machine-learning-course), habr.com [:ru:](https://habr.com/company/ods/blog/344044/). Also notebooks in Chinese are mentioned :cn: and links to Kaggle Notebooks (in English) are given. Icons are clickable.\n\n1. Exploratory Data Analysis with Pandas [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-1-exploratory-data-analysis-with-pandas-de57880f1a68)  [:ru:](https://habrahabr.ru/company/ods/blog/322626/) [:cn:](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_chinese/topic01-%E4%BD%BF%E7%94%A8-Pandas-%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-1-exploratory-data-analysis-with-pandas)\n2. Visual Data Analysis with Python [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-2-visual-data-analysis-in-python-846b989675cd)  [:ru:](https://habrahabr.ru/company/ods/blog/323210/) [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/main/jupyter_chinese/topic02-Python-%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90.ipynb), Kaggle Notebooks: [part1](https://www.kaggle.com/kashnitsky/topic-2-visual-data-analysis-in-python), [part2](https://www.kaggle.com/kashnitsky/topic-2-part-2-seaborn-and-plotly)\n3. Classification, Decision Trees and k Nearest Neighbors [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-3-classification-decision-trees-and-k-nearest-neighbors-8613c6b6d2cd) [:ru:](https://habrahabr.ru/company/ods/blog/322534/) [:cn:](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_chinese/topic03-%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8C-K-%E8%BF%91%E9%82%BB%E5%88%86%E7%B1%BB.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn)\n4. Linear Classification and Regression [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-4-linear-classification-and-regression-44a41b9b5220) [:ru:](https://habrahabr.ru/company/ods/blog/323890/) [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/main/jupyter_chinese/topic04-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%92%8C%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8.ipynb), Kaggle Notebooks: [part1](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-1-ols), [part2](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification), [part3](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-3-regularization), [part4](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit), [part5](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-5-validation)\n5. Bagging and Random Forest [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-5-ensembles-of-algorithms-and-random-forest-8e05246cbba7) [:ru:](https://habrahabr.ru/company/ods/blog/324402/) [:cn:](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_chinese/topic05-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%96%B9%E6%B3%95.ipynb), Kaggle Notebooks: [part1](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-1-bagging), [part2](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-2-random-forest), [part3](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-3-feature-importance)\n6. Feature Engineering and Feature Selection [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-6-feature-engineering-and-feature-selection-8b94f870706a) [:ru:](https://habrahabr.ru/company/ods/blog/325422/) [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/main/jupyter_chinese/topic06-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%92%8C%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection)\n7. Unsupervised Learning: Principal Component Analysis and Clustering [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-7-unsupervised-learning-pca-and-clustering-db7879568417) [:ru:](https://habrahabr.ru/company/ods/blog/325654/) [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/main/jupyter_chinese/topic07-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%E5%92%8C%E8%81%9A%E7%B1%BB.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-7-unsupervised-learning-pca-and-clustering)\n8. Vowpal Wabbit: Learning with Gigabytes of Data [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-8-vowpal-wabbit-fast-learning-with-gigabytes-of-data-60f750086237) [:ru:](https://habrahabr.ru/company/ods/blog/326418/) [:cn:](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_chinese/topic08-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%92%8C%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-8-online-learning-and-vowpal-wabbit)\n9. Time Series Analysis with Python, part 1 [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-time-series-analysis-in-python-a270cb05e0b3) [:ru:](https://habrahabr.ru/company/ods/blog/327242/) [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/main/jupyter_chinese/topic09-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%A4%84%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8.ipynb). Predicting future with Facebook Prophet, part 2 [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-part-3-predicting-the-future-with-facebook-prophet-3f3af145cdc), [:cn:](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/mlcourse.ai/main/jupyter_chinese/topic09-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%A4%84%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8.ipynb) Kaggle Notebooks: [part1](https://www.kaggle.com/kashnitsky/topic-9-part-1-time-series-analysis-in-python), [part2](https://www.kaggle.com/kashnitsky/topic-9-part-2-time-series-with-facebook-prophet)\n10. Gradient Boosting [:uk:](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-10-gradient-boosting-c751538131ac) [:ru:](https://habrahabr.ru/company/ods/blog/327250/), [:cn:](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_chinese/topic05-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%96%B9%E6%B3%95.ipynb), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/topic-10-gradient-boosting)\n\n### Lectures\nVideolectures are uploaded to [this](https://bit.ly/2zY6Xe2) YouTube playlist.\nIntroduction, [video](https://www.youtube.com/watch?v=DrohHdQa8u8), [slides](https://www.slideshare.net/festline/mlcourseai-fall2019-live-session-0)\n\n1. Exploratory data analysis with Pandas, [video](https://youtu.be/fwWCw_cE5aI)\n2. Visualization, main plots for EDA, [video](https://www.youtube.com/watch?v=WNoQTNOME5g)\n3. Decision trees: [theory](https://youtu.be/H4XlBTPv5rQ) and [practical part](https://youtu.be/RrVYO6Td9Js)\n4. Logistic regression: [theoretical foundations](https://www.youtube.com/watch?v=l3jiw-N544s), [practical part](https://www.youtube.com/watch?v=7o0SWgY89i8) (baselines in the \"Alice\" competition)\n5. Ensembles and Random Forest \u2013 [part 1](https://www.youtube.com/watch?v=neXJL-AqI_c). Classification metrics \u2013 [part 2](https://www.youtube.com/watch?v=aBOMYqGUlWQ). Example of a business task, predicting a customer payment \u2013 [part 3](https://www.youtube.com/watch?v=FmKU-1LZGoE)\n6. Linear regression and regularization - [theory](https://youtu.be/ne-MfRfYs_c), LASSO & Ridge, LTV prediction - [practice](https://youtu.be/B8yIaIEMyIc)\n7. Unsupervised learning - [Principal Component Analysis](https://youtu.be/-AswHf7h0I4) and [Clustering](https://youtu.be/eVplCo-w4XE)\n8. Stochastic Gradient Descent for classification and regression - [part 1](https://youtu.be/EUSXbdzaQE8), part 2 TBA\n9. Time series analysis with Python (ARIMA, Prophet) - [video](https://youtu.be/_9lBwXnbOd8)\n10. Gradient boosting: basic ideas - [part 1](https://youtu.be/g0ZOtzZqdqk), key ideas behind Xgboost, LightGBM, and CatBoost + practice - [part 2](https://youtu.be/V5158Oug4W8)\n\n### Assignments\n\nThe following are demo-assignments. Additionally, within the [\"Bonus Assignments\" tier](https://www.patreon.com/ods_mlcourse) you can get access to non-demo assignments.\n\n1. Exploratory data analysis with Pandas, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_english/assignments_demo/assignment01_pandas_uci_adult.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-1-pandas-and-uci-adult-dataset), [solution](https://www.kaggle.com/kashnitsky/a1-demo-pandas-and-uci-adult-dataset-solution)\n2. Analyzing cardiovascular disease data, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_english/assignments_demo/assignment02_analyzing_cardiovascular_desease_data.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-2-analyzing-cardiovascular-data), [solution](https://www.kaggle.com/kashnitsky/a2-demo-analyzing-cardiovascular-data-solution)\n3. Decision trees with a toy task and the UCI Adult dataset, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_english/assignments_demo/assignment03_decision_trees.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-3-decision-trees), [solution](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees-solution)\n4. Sarcasm detection, [Kaggle Notebook](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit), [solution](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit-solution). Linear Regression as an optimization problem, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_english/assignments_demo/assignment04_linreg_optimization.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-4-linear-regression-as-optimization)\n5. Logistic Regression and Random Forest in the credit scoring problem, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_english/assignments_demo/assignment05_logit_rf_credit_scoring.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-5-logit-and-rf-for-credit-scoring), [solution](https://www.kaggle.com/kashnitsky/a5-demo-logit-and-rf-for-credit-scoring-sol)\n6. Exploring OLS, Lasso and Random Forest in a regression task, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_english/assignments_demo/assignment06_regression_wine.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-6-linear-models-and-rf-for-regression), [solution](https://www.kaggle.com/kashnitsky/a6-demo-regression-solution)\n7. Unsupervised learning, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_english/assignments_demo/assignment07_unsupervised_learning.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-7-unupervised-learning), [solution](https://www.kaggle.com/kashnitsky/a7-demo-unsupervised-learning-solution)\n8. Implementing online regressor, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_english/assignments_demo/assignment08_implement_sgd_regressor.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-8-implementing-online-regressor), [solution](https://www.kaggle.com/kashnitsky/a8-demo-implementing-online-regressor-solution)\n9. Time series analysis, [nbviewer](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/main/jupyter_english/assignments_demo/assignment09_time_series.ipynb?flush_cache=true), [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-9-time-series-analysis), [solution](https://www.kaggle.com/kashnitsky/a9-demo-time-series-analysis-solution)\n10. Beating baseline in a competition, [Kaggle Notebook](https://www.kaggle.com/kashnitsky/assignment-10-gradient-boosting-and-flight-delays)\n\n### Bonus assignments\n\nAdditionally, you can purchase a **Bonus Assignments pack** with the best non-demo versions of [mlcourse.ai](https://mlcourse.ai/) assignments. Select the [\"Bonus Assignments\" tier](https://www.patreon.com/ods_mlcourse) on Patreon or a [similar tier](https://boosty.to/ods_mlcourse/purchase/1142055?ssource=DIRECT&share=subscription_link) on Boosty (rus).\n\n<div class=\"row\">\n  <div class=\"col-md-8\" markdown=\"1\">\n  <p align=\"center\">\n  <a href=\"https://www.patreon.com/ods_mlcourse\">\n         <img src=\"mlcourse_ai_jupyter_book/_static/img/become_a_patron.png\">\n  </a>\n  &nbsp;&nbsp;\n  <a href=\"https://boosty.to/ods_mlcourse\">\n         <img src=\"mlcourse_ai_jupyter_book/_static/img/boosty_logo.png\" width=200px%>\n  </a>\n  </p>\n\n</div>\n\n  <div class=\"col-md-4\" markdown=\"1\">\n  <details>\n  <summary>Details of the deal</summary>\n\nmlcourse.ai is still in self-paced mode but we offer you Bonus Assignments with solutions for a contribution of $17/month. The idea is that you pay for ~1-5 months while studying the course materials, but a single contribution is still fine and opens your access to the bonus pack.\n\nNote: the first payment is charged at the moment of joining the Tier Patreon, and the next payment is charged on the 1st day of the next month, thus it's better to purchase the pack in the 1st half of the month.\n\nmlcourse.ai is never supposed to go fully monetized (it's created in the wonderful open ODS.ai community and will remain open and free) but it'd help to cover some operational costs, and Yury also put in quite some effort into assembling all the best assignments into one pack. Please note that unlike the rest of the course content, Bonus Assignments are copyrighted. Informally, Yury's fine if you share the pack with 2-3 friends but public sharing of the Bonus Assignments pack is prohibited.\n</details>\n  </div>\n</div><br>\n\nThe bonus pack contains 10 assignments, in some of them you are challenged to beat a baseline in a Kaggle competition under thorough guidance ([\"Alice\"](https://mlcourse.ai/book/topic04/bonus_assignment04_alice_baselines.html) and [\"Medium\"](https://mlcourse.ai/book/topic06/bonus_assignment06.html)) or implement an algorithm from scratch -- efficient stochastic gradient descent [classifier](https://mlcourse.ai/book/topic08/bonus_assignment08.html) and [gradient boosting](https://mlcourse.ai/book/topic10/bonus_assignment10.html).\n\n### Kaggle competitions\n\n1. Catch Me If You Can: Intruder Detection through Webpage Session Tracking. [Kaggle Inclass](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2)\n2. Predicting popularity of a Medium article. [Kaggle Inclass](https://www.kaggle.com/c/how-good-is-your-medium-article)\n3. DotA 2 winner prediction. [Kaggle Inclass](https://www.kaggle.com/c/mlcourse-dota2-win-prediction)\n\n### Citing mlcourse.ai\n\nIf you happen to cite [mlcourse.ai](https://mlcourse.ai) in your work, you can use this BibTeX record:\n\n```\n@misc{mlcourse_ai,\n    author = {Kashnitsky, Yury},\n    title = {mlcourse.ai \u2013 Open Machine Learning Course},\n    year = {2020},\n    publisher = {GitHub},\n    journal = {GitHub repository},\n    howpublished = {\\url{https://github.com/Yorko/mlcourse.ai}},\n}\n```\n\n### Community\nDiscussions are held in the **#mlcourse\\_ai\\_eng** channel of the [OpenDataScience (ods.ai)](https://ods.ai) Slack team (however, as of Sept. 2022, ODS Slack can't invite new users, and only 90-day history is retained, transition to [Matrix](https://chat.ods.ai/#/welcome) is in progress).\n\n*The course is free but you can support organizers by making a pledge on [Patreon](https://www.patreon.com/ods_mlcourse) (monthly support) or a one-time payment on [Ko-fi](https://ko-fi.com/mlcourse_ai).*\n\n[![Donate](https://img.shields.io/badge/support-patreon-red)](https://www.patreon.com/ods_mlcourse)\n[![Donate](https://img.shields.io/badge/support-ko--fi-red)](https://ko-fi.com/mlcourse_ai)\n",
	"data-analysis exercise pandas practice tutorial": "# Pandas Exercises\n\nFed up with a ton of tutorials but no easy way to find exercises I decided to create a repo just with exercises to practice pandas.\nDon't get me wrong, tutorials are great resources, but to learn is to do. So unless you practice you won't learn.\n\nThere will be three different types of files:  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. Exercise instructions  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. Solutions without code  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3. Solutions with code and comments\n\nMy suggestion is that you learn a topic in a tutorial, video or documentation and then do the first exercises.\nLearn one more topic and do more exercises. If you are stuck, don't go directly to the solution with code files. Check the solutions only and try to get the correct answer.\n\nSuggestions and collaborations are more than welcome.\ud83d\ude42 Please open an issue or make a PR indicating the exercise and your problem/solution.\n\n# Lessons\n\n|\t\t\t\t                                  |\t\t\t\t                                   |                   |\n|:-----------------------------------------------:|:----------------------------------------------:|:-----------------:|\n|[Getting and knowing](#getting-and-knowing)      | [Merge](#merge)                                |[Time Series](#time-series)|\n|[Filtering and Sorting](#filtering-and-sorting)  | [Stats](#stats)                                |[Deleting](#deleting)       |\n|[Grouping](#grouping)\t\t\t\t\t\t\t  | [Visualization](#visualization)                |Indexing           |\n|[Apply](#apply)\t\t\t\t\t\t\t      | [Creating Series and DataFrames](#creating-series-and-dataframes) \t\t            |Exporting|\n\n### [Getting and knowing](https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data)  \n[Chipotle](https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/Chipotle)  \n[Occupation](https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/Occupation)  \n[World Food Facts](https://github.com/guipsamora/pandas_exercises/tree/master/01_Getting_%26_Knowing_Your_Data/World%20Food%20Facts)\n\n### [Filtering and Sorting](https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting)\n[Chipotle](https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Chipotle)  \n[Euro12](https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Euro12)  \n[Fictional Army](https://github.com/guipsamora/pandas_exercises/tree/master/02_Filtering_%26_Sorting/Fictional%20Army)\n\n### [Grouping](https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping)\n[Alcohol Consumption](https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Alcohol_Consumption)  \n[Occupation](https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Occupation)  \n[Regiment](https://github.com/guipsamora/pandas_exercises/tree/master/03_Grouping/Regiment)\n\n### [Apply](https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply)\n[Students Alcohol Consumption](https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply/Students_Alcohol_Consumption)  \n[US_Crime_Rates](https://github.com/guipsamora/pandas_exercises/tree/master/04_Apply/US_Crime_Rates)     \n\n### [Merge](https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge)\n[Auto_MPG](https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Auto_MPG)  \n[Fictitious Names](https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Fictitous%20Names)  \n[House Market](https://github.com/guipsamora/pandas_exercises/tree/master/05_Merge/Housing%20Market)  \n\n### [Stats](https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats)\n[US_Baby_Names](https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats/US_Baby_Names)  \n[Wind_Stats](https://github.com/guipsamora/pandas_exercises/tree/master/06_Stats/Wind_Stats)\n\n### [Visualization](https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization)\n[Chipotle](https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Chipotle)  \n[Titanic Disaster](https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Titanic_Desaster)  \n[Scores](https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Scores)  \n[Online Retail](https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Online_Retail)  \n[Tips](https://github.com/guipsamora/pandas_exercises/tree/master/07_Visualization/Tips)  \n\n### [Creating Series and DataFrames](https://github.com/guipsamora/pandas_exercises/tree/master/08_Creating_Series_and_DataFrames)  \n[Pokemon](https://github.com/guipsamora/pandas_exercises/tree/master/08_Creating_Series_and_DataFrames/Pokemon)  \n\n### [Time Series](https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series)  \n[Apple_Stock](https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Apple_Stock)  \n[Getting_Financial_Data](https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Getting_Financial_Data)  \n[Investor_Flow_of_Funds_US](https://github.com/guipsamora/pandas_exercises/tree/master/09_Time_Series/Getting_Financial_Data)  \n\n### [Deleting](https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting)  \n[Iris](https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting/Iris)  \n[Wine](https://github.com/guipsamora/pandas_exercises/tree/master/10_Deleting/Wine)  \n\n# Video Solutions\n\nVideo tutorials of data scientists working through the above exercises:\n\n[Data Talks - Pandas Learning By Doing](https://www.youtube.com/watch?v=pu3IpU937xs&list=PLgJhDSE2ZLxaY_DigHeiIDC1cD09rXgJv)\n",
	"apache-doris business-intelligence data-analysis data-visualization echarts kettle superset tableau": "<p align=\"center\"><a href=\"https://dataease.io\"><img src=\"https://dataease.oss-cn-hangzhou.aliyuncs.com/img/dataease-logo.png\" alt=\"DataEase\" width=\"300\" /></a></p>\n<h3 align=\"center\">\u4eba\u4eba\u53ef\u7528\u7684\u5f00\u6e90\u6570\u636e\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177</h3>\n<p align=\"center\">\n  <a href=\"https://www.gnu.org/licenses/old-licenses/gpl-3.0\"><img src=\"https://img.shields.io/github/license/dataease/dataease?color=%231890FF\" alt=\"License: GPL v3\"></a>\n  <a href=\"https://app.codacy.com/gh/dataease/dataease?utm_source=github.com&utm_medium=referral&utm_content=dataease/dataease&utm_campaign=Badge_Grade_Dashboard\"><img src=\"https://app.codacy.com/project/badge/Grade/da67574fd82b473992781d1386b937ef\" alt=\"Codacy\"></a>\n  <a href=\"https://github.com/dataease/dataease/releases/latest\"><img src=\"https://img.shields.io/github/v/release/dataease/dataease\" alt=\"Latest release\"></a>\n  <a href=\"https://github.com/dataease/dataease\"><img src=\"https://img.shields.io/github/stars/dataease/dataease?color=%231890FF&style=flat-square\" alt=\"Stars\"></a>\n  <a href=\"https://github.com/dataease/dataease/releases/latest\"><img src=\"https://img.shields.io/github/downloads/dataease/dataease/total\" alt=\"Downloads\"></a>\n</p>\n<hr/>\n\n## \u4ec0\u4e48\u662f DataEase\uff1f\n\nDataEase \u662f\u5f00\u6e90\u7684\u6570\u636e\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177\uff0c\u5e2e\u52a9\u7528\u6237\u5feb\u901f\u5206\u6790\u6570\u636e\u5e76\u6d1e\u5bdf\u4e1a\u52a1\u8d8b\u52bf\uff0c\u4ece\u800c\u5b9e\u73b0\u4e1a\u52a1\u7684\u6539\u8fdb\u4e0e\u4f18\u5316\u3002DataEase \u652f\u6301\u4e30\u5bcc\u7684\u6570\u636e\u6e90\u8fde\u63a5\uff0c\u80fd\u591f\u901a\u8fc7\u62d6\u62c9\u62fd\u65b9\u5f0f\u5feb\u901f\u5236\u4f5c\u56fe\u8868\uff0c\u5e76\u53ef\u4ee5\u65b9\u4fbf\u7684\u4e0e\u4ed6\u4eba\u5206\u4eab\u3002\n\n![de-architecture](https://dataease.io/images/screenshot/de-chart-new.jpg)\n\n**DataEase \u7684\u529f\u80fd\u5305\u62ec\uff1a**\n\n-   \u56fe\u8868\u5c55\u793a\uff1a\u652f\u6301 PC \u7aef\u3001\u79fb\u52a8\u7aef\u3001\u5927\u5c4f;\n-   \u56fe\u8868\u5236\u4f5c\uff1a\u652f\u6301\u4e30\u5bcc\u7684\u56fe\u8868\u7c7b\u578b(Apache ECharts / AntV)\u3001\u652f\u6301\u62d6\u62c9\u62fd\u65b9\u5f0f\u5feb\u901f\u5236\u4f5c\u4eea\u8868\u677f;\n-   \u6570\u636e\u5f15\u64ce\uff1a\u652f\u6301\u76f4\u8fde\u6a21\u5f0f\u3001\u672c\u5730\u6a21\u5f0f(\u57fa\u4e8e Apache Doris / Kettle \u5b9e\u73b0);\n-   \u6570\u636e\u8fde\u63a5\uff1a\u652f\u6301\u6570\u636e\u4ed3\u5e93/\u6570\u636e\u6e56\u3001OLAP \u6570\u636e\u5e93\u3001OLTP \u6570\u636e\u5e93\u3001Excel \u6570\u636e\u6587\u4ef6\u3001API \u7b49\u5404\u79cd\u6570\u636e\u6e90\u3002\n\n## DataEase \u7684\u4f18\u52bf\n\n-   \u5f00\u6e90\u5f00\u653e\uff1a\u96f6\u95e8\u69db\uff0c\u7ebf\u4e0a\u5feb\u901f\u83b7\u53d6\u548c\u5b89\u88c5\uff1b\u5feb\u901f\u83b7\u53d6\u7528\u6237\u53cd\u9988\u3001\u6309\u6708\u53d1\u5e03\u65b0\u7248\u672c\uff1b\n-   \u7b80\u5355\u6613\u7528\uff1a\u6781\u6613\u4e0a\u624b\uff0c\u901a\u8fc7\u9f20\u6807\u70b9\u51fb\u548c\u62d6\u62fd\u5373\u53ef\u5b8c\u6210\u5206\u6790\uff1b\n-   \u79d2\u7ea7\u54cd\u5e94\uff1a\u96c6\u6210 Apache Doris\uff0c\u8d85\u5927\u6570\u636e\u91cf\u4e0b\u79d2\u7ea7\u67e5\u8be2\u8fd4\u56de\u5ef6\u65f6\uff1b\n-   \u5b89\u5168\u5206\u4eab\uff1a\u652f\u6301\u591a\u79cd\u6570\u636e\u5206\u4eab\u65b9\u5f0f\uff0c\u786e\u4fdd\u6570\u636e\u5b89\u5168\u3002\n\n## DataEase \u652f\u6301\u7684\u6570\u636e\u6e90\n\n<p align=\"center\">\n  <img src=\"https://dataease.io/images/dataSource/excel.jpg\" alt=\"excel\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/mysql.png\" alt=\"mysql\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/oracle.jpg\" alt=\"oracle\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/sqlservel.jpg\" alt=\"sqlserver\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/mariadb.jpg\" alt=\"mariadb\" border=\"0\" width=\"155\" height=\"107\"/>  \n  <img src=\"https://dataease.io/images/dataSource/elasticsearch.jpg\" alt=\"elasticsearch\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/clickhouse.jpg\" alt=\"clickhouse\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/doris.jpg\" alt=\"doris\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/mongodb.jpg\" alt=\"mongodb\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/redshift.jpg\" alt=\"redshift\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/hive.png\" alt=\"hive\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/DB2.jpg\" alt=\"DB2\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/API.jpg\" alt=\"API\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/TiDB.jpg\" alt=\"TiDB\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/StarRocks.jpg\" alt=\"StarRocks\" border=\"0\" width=\"155\" height=\"107\"/>\n  <img src=\"https://dataease.io/images/dataSource/PrestoDB.jpg\" alt=\"PrestoDB\" border=\"0\" width=\"155\" height=\"107\"/>\n</p>\n\n> \u66f4\u591a\u6570\u636e\u6e90\u652f\u6301\u6301\u7eed\u589e\u52a0\u4e2d...\n\n## DataEase \u6a21\u677f\u5e02\u573a\n\n-   [\u6a21\u677f\u5e02\u573a](https://dataease.io/templates/)\n\n![\u6a21\u677f\u5e02\u573a](https://dataease.io/images/templates/templates.gif)\n\n> \u66f4\u591a\u4f18\u8d28\u6a21\u677f\u6301\u7eed\u589e\u52a0\u4e2d...\n\n## \u5feb\u901f\u5f00\u59cb\n\n**\u5728\u7ebf\u4f53\u9a8c**\n\n-   \u73af\u5883\u5730\u5740\uff1a<https://dataease.fit2cloud.com/>\n-   \u7528\u6237\u540d\uff1ademo\n-   \u5bc6\u7801\uff1adataease\n\n**\u4e00\u952e\u5b89\u88c5**\n\n\u4ec5\u9700\u4e24\u6b65\u5feb\u901f\u5b89\u88c5 DataEase\uff1a\n\n1. \u51c6\u5907\u4e00\u53f0\u4e0d\u5c0f\u4e8e 8 G\u5185\u5b58\u7684 64\u4f4d Linux \u4e3b\u673a\uff1b\n2. \u4ee5 root \u7528\u6237\u6267\u884c\u5982\u4e0b\u547d\u4ee4\u4e00\u952e\u5b89\u88c5 DataEase\u3002\n\n```sh\ncurl -sSL https://github.com/dataease/dataease/releases/latest/download/quick_start.sh | sh\n```\n\n**\u5b66\u4e60\u8d44\u6599**\n\n-   [\u5728\u7ebf\u6587\u6863](https://dataease.io/docs/)\n-   [\u6559\u5b66\u89c6\u9891](https://dataease.io/video.html)\n-   [\u5728\u7ebf\u5b66\u4e60\u73ed](https://edu.fit2cloud.com/page/2635362?navIndex=0)\n\n**\u52a0\u5165\u5fae\u4fe1\u4ea4\u6d41\u7fa4**\n\n<img src=\"https://dataease.oss-cn-hangzhou.aliyuncs.com/img/wechat-group.png\" width=\"156\" height=\"156\"/>\n\n## DataEase \u7684\u6280\u672f\u6808\n\n-   \u524d\u7aef\uff1a[Vue.js](https://vuejs.org/)\u3001[Element](https://element.eleme.cn/)\n-   \u56fe\u5e93\uff1a[Apache ECharts](https://github.com/apache/echarts)\u3001[AntV](https://antv.vision/zh)\n-   \u540e\u7aef\uff1a[Spring Boot](https://spring.io/projects/spring-boot)\n-   \u4e2d\u95f4\u4ef6\uff1a[MySQL](https://www.mysql.com/)\n-   \u6570\u636e\u5904\u7406\uff1a[Kettle](https://github.com/pentaho/pentaho-kettle)\u3001[Apache Doris](https://github.com/apache/incubator-doris/)\n-   \u57fa\u7840\u8bbe\u65bd\uff1a[Docker](https://www.docker.com/)\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=dataease/dataease&type=Date)](https://star-history.com/#dataease/dataease&Date)\n\n## License\n\nCopyright (c) 2014-2022 \u98de\u81f4\u4e91 FIT2CLOUD, All rights reserved.\n\nLicensed under The GNU General Public License version 3 (GPLv3)  (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n\n<https://www.gnu.org/licenses/gpl-3.0.html>\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
	"data-analysis go golang graph matrix scientific-computing statistics": "# Gonum\n\n[![Build status](https://github.com/gonum/gonum/workflows/CI/badge.svg)](https://github.com/gonum/gonum/actions)\n[![Build status](https://ci.appveyor.com/api/projects/status/valslkp8sr50eepn/branch/master?svg=true)](https://ci.appveyor.com/project/Gonum/gonum/branch/master)\n[![codecov.io](https://codecov.io/gh/gonum/gonum/branch/master/graph/badge.svg)](https://codecov.io/gh/gonum/gonum)\n[![go.dev reference](https://pkg.go.dev/badge/gonum.org/v1/gonum)](https://pkg.go.dev/gonum.org/v1/gonum)\n[![GoDoc](https://godoc.org/gonum.org/v1/gonum?status.svg)](https://godoc.org/gonum.org/v1/gonum)\n[![Go Report Card](https://goreportcard.com/badge/github.com/gonum/gonum)](https://goreportcard.com/report/github.com/gonum/gonum)\n[![stability-unstable](https://img.shields.io/badge/stability-unstable-yellow.svg)](https://github.com/emersion/stability-badges#unstable)\n\n## Installation\n\nThe core packages of the Gonum suite are written in pure Go with some assembly.\nInstallation is done using `go get`.\n```\ngo get -u gonum.org/v1/gonum/...\n```\n\n## Supported Go versions\n\nGonum supports and tests using the gc compiler on the [two most recent Go releases](https://github.com/gonum/gonum/blob/master/.github/workflows/ci.yml#L14-L15) on Linux (386, amd64 and arm64), macOS and Windows (both on amd64).\n\nNote that floating point behavior may differ between compiler versions and between architectures due to differences in floating point operation implementations.\n\n## Release schedule\n\nThe Gonum modules are released on a six-month release schedule, aligned with the Go releases.\n_i.e.:_ when `Go-1.x` is released, `Gonum-v0.n.0` is released around the same time.\nSix months after, `Go-1.x+1` is released, and `Gonum-v0.n+1.0` as well.\n\nThe release schedule, based on the current Go release schedule is thus:\n\n- `Gonum-v0.n.0`: February\n- `Gonum-v0.n+1.0`: August\n\n## Build tags\n\nThe Gonum packages use a variety of build tags to set non-standard build conditions.\nBuilding Gonum applications will work without knowing how to use these tags, but they can be used during testing and to control the use of assembly and CGO code.\n\nThe current list of non-internal tags is as follows:\n\n- safe \u2014 do not use assembly or unsafe\n- bounds \u2014 use bounds checks even in internal calls\n- noasm \u2014 do not use assembly implementations\n- tomita \u2014 use [Tomita, Tanaka, Takahashi pivot choice](https://doi.org/10.1016%2Fj.tcs.2006.06.015) for maximimal clique calculation, otherwise use random pivot (only in [topo package](https://godoc.org/gonum.org/v1/gonum/graph/topo))\n\n\n## Issues [![TODOs](https://badgen.net/https/api.tickgit.com/badgen/github.com/gonum/gonum)](https://www.tickgit.com/browse?repo=github.com/gonum/gonum)\n\nIf you find any bugs, feel free to file an issue on the github issue tracker. Discussions on API changes, added features, code review, or similar requests are preferred on the gonum-dev Google Group.\n\nhttps://groups.google.com/forum/#!forum/gonum-dev\n\n## License\n\nOriginal code is licensed under the Gonum License found in the LICENSE file. Portions of the code are subject to the additional licenses found in THIRD_PARTY_LICENSES. All third party code is licensed either under a BSD or MIT license.\n\nCode in graph/formats/dot is dual licensed [Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/) and Gonum License, and users are free to choose the license which suits their needs for this code.\n\nThe W3C test suites in graph/formats/rdf are distributed under both the [W3C Test Suite License](http://www.w3.org/Consortium/Legal/2008/04-testsuite-license) and the [W3C 3-clause BSD License](http://www.w3.org/Consortium/Legal/2008/03-bsd-license).\n",
	"data-mining decision-trees distributed gbdt gbm gbrt gradient-boosting kaggle lightgbm machine-learning microsoft parallel python r": "<img src=https://github.com/microsoft/LightGBM/blob/master/docs/logo/LightGBM_logo_black_text.svg width=300 />\n\nLight Gradient Boosting Machine\n===============================\n\n[![Python-package GitHub Actions Build Status](https://github.com/microsoft/LightGBM/workflows/Python-package/badge.svg?branch=master)](https://github.com/microsoft/LightGBM/actions)\n[![R-package GitHub Actions Build Status](https://github.com/microsoft/LightGBM/workflows/R-package/badge.svg?branch=master)](https://github.com/microsoft/LightGBM/actions)\n[![CUDA Version GitHub Actions Build Status](https://github.com/microsoft/LightGBM/workflows/CUDA%20Version/badge.svg?branch=master)](https://github.com/microsoft/LightGBM/actions)\n[![Static Analysis GitHub Actions Build Status](https://github.com/microsoft/LightGBM/workflows/Static%20Analysis/badge.svg?branch=master)](https://github.com/microsoft/LightGBM/actions)\n[![Azure Pipelines Build Status](https://lightgbm-ci.visualstudio.com/lightgbm-ci/_apis/build/status/Microsoft.LightGBM?branchName=master)](https://lightgbm-ci.visualstudio.com/lightgbm-ci/_build/latest?definitionId=1)\n[![Appveyor Build Status](https://ci.appveyor.com/api/projects/status/1ys5ot401m0fep6l/branch/master?svg=true)](https://ci.appveyor.com/project/guolinke/lightgbm/branch/master)\n[![Documentation Status](https://readthedocs.org/projects/lightgbm/badge/?version=latest)](https://lightgbm.readthedocs.io/)\n[![Link checks](https://github.com/microsoft/LightGBM/workflows/Link%20checks/badge.svg)](https://github.com/microsoft/LightGBM/actions?query=workflow%3A%22Link+checks%22)\n[![License](https://img.shields.io/github/license/microsoft/lightgbm.svg)](https://github.com/microsoft/LightGBM/blob/master/LICENSE)\n[![Python Versions](https://img.shields.io/pypi/pyversions/lightgbm.svg?logo=python&logoColor=white)](https://pypi.org/project/lightgbm)\n[![PyPI Version](https://img.shields.io/pypi/v/lightgbm.svg?logo=pypi&logoColor=white)](https://pypi.org/project/lightgbm)\n[![CRAN Version](https://www.r-pkg.org/badges/version/lightgbm)](https://cran.r-project.org/package=lightgbm)\n\nLightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n\n- Faster training speed and higher efficiency.\n- Lower memory usage.\n- Better accuracy.\n- Support of parallel, distributed, and GPU learning.\n- Capable of handling large-scale data.\n\nFor further details, please refer to [Features](https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst).\n\nBenefiting from these advantages, LightGBM is being widely-used in many [winning solutions](https://github.com/microsoft/LightGBM/blob/master/examples/README.md#machine-learning-challenge-winning-solutions) of machine learning competitions.\n\n[Comparison experiments](https://github.com/microsoft/LightGBM/blob/master/docs/Experiments.rst#comparison-experiment) on public datasets show that LightGBM can outperform existing boosting frameworks on both efficiency and accuracy, with significantly lower memory consumption. What's more, [distributed learning experiments](https://github.com/microsoft/LightGBM/blob/master/docs/Experiments.rst#parallel-experiment) show that LightGBM can achieve a linear speed-up by using multiple machines for training in specific settings.\n\nGet Started and Documentation\n-----------------------------\n\nOur primary documentation is at https://lightgbm.readthedocs.io/ and is generated from this repository. If you are new to LightGBM, follow [the installation instructions](https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html) on that site.\n\nNext you may want to read:\n\n- [**Examples**](https://github.com/microsoft/LightGBM/tree/master/examples) showing command line usage of common tasks.\n- [**Features**](https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst) and algorithms supported by LightGBM.\n- [**Parameters**](https://github.com/microsoft/LightGBM/blob/master/docs/Parameters.rst) is an exhaustive list of customization you can make.\n- [**Distributed Learning**](https://github.com/microsoft/LightGBM/blob/master/docs/Parallel-Learning-Guide.rst) and [**GPU Learning**](https://github.com/microsoft/LightGBM/blob/master/docs/GPU-Tutorial.rst) can speed up computation.\n- [**Laurae++ interactive documentation**](https://sites.google.com/view/lauraepp/parameters) is a detailed guide for hyperparameters.\n- [**FLAML**](https://www.microsoft.com/en-us/research/project/fast-and-lightweight-automl-for-large-scale-data/articles/flaml-a-fast-and-lightweight-automl-library/) provides automated tuning for LightGBM ([code examples](https://microsoft.github.io/FLAML/docs/Examples/AutoML-for-LightGBM/)).\n- [**Optuna Hyperparameter Tuner**](https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258) provides automated tuning for LightGBM hyperparameters ([code examples](https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_tuner_simple.py)).\n- [**Understanding LightGBM Parameters (and How to Tune Them using Neptune)**](https://neptune.ai/blog/lightgbm-parameters-guide).\n\nDocumentation for contributors:\n\n- [**How we update readthedocs.io**](https://github.com/microsoft/LightGBM/blob/master/docs/README.rst).\n- Check out the [**Development Guide**](https://github.com/microsoft/LightGBM/blob/master/docs/Development-Guide.rst).\n\nNews\n----\n\nPlease refer to changelogs at [GitHub releases](https://github.com/microsoft/LightGBM/releases) page.\n\nSome old update logs are available at [Key Events](https://github.com/microsoft/LightGBM/blob/master/docs/Key-Events.md) page.\n\nExternal (Unofficial) Repositories\n----------------------------------\n\nFLAML (AutoML library for hyperparameter optimization): https://github.com/microsoft/FLAML\n\nOptuna (hyperparameter optimization framework): https://github.com/optuna/optuna\n\nJulia-package: https://github.com/IQVIA-ML/LightGBM.jl\n\nJPMML (Java PMML converter): https://github.com/jpmml/jpmml-lightgbm\n\nNyoka (Python PMML converter): https://github.com/SoftwareAG/nyoka\n\nTreelite (model compiler for efficient deployment): https://github.com/dmlc/treelite\n\nlleaves (LLVM-based model compiler for efficient inference): https://github.com/siboehm/lleaves\n\nHummingbird (model compiler into tensor computations): https://github.com/microsoft/hummingbird\n\ncuML Forest Inference Library (GPU-accelerated inference): https://github.com/rapidsai/cuml\n\ndaal4py (Intel CPU-accelerated inference): https://github.com/intel/scikit-learn-intelex/tree/master/daal4py\n\nm2cgen (model appliers for various languages): https://github.com/BayesWitnesses/m2cgen\n\nleaves (Go model applier): https://github.com/dmitryikh/leaves\n\nONNXMLTools (ONNX converter): https://github.com/onnx/onnxmltools\n\nSHAP (model output explainer): https://github.com/slundberg/shap\n\nShapash (model visualization and interpretation): https://github.com/MAIF/shapash\n\ndtreeviz (decision tree visualization and model interpretation): https://github.com/parrt/dtreeviz\n\nSynapseML (LightGBM on Spark): https://github.com/microsoft/SynapseML\n\nKubeflow Fairing (LightGBM on Kubernetes): https://github.com/kubeflow/fairing\n\nKubeflow Operator (LightGBM on Kubernetes): https://github.com/kubeflow/xgboost-operator\n\nlightgbm_ray (LightGBM on Ray): https://github.com/ray-project/lightgbm_ray\n\nMars (LightGBM on Mars): https://github.com/mars-project/mars\n\nML.NET (.NET/C#-package): https://github.com/dotnet/machinelearning\n\nLightGBM.NET (.NET/C#-package): https://github.com/rca22/LightGBM.Net\n\nRuby gem: https://github.com/ankane/lightgbm-ruby\n\nLightGBM4j (Java high-level binding): https://github.com/metarank/lightgbm4j\n\nlightgbm-rs (Rust binding): https://github.com/vaaaaanquish/lightgbm-rs\n\nMLflow (experiment tracking, model monitoring framework): https://github.com/mlflow/mlflow\n\n`{treesnip}` (R `{parsnip}`-compliant interface): https://github.com/curso-r/treesnip\n\n`{mlr3extralearners}` (R `{mlr3}`-compliant interface): https://github.com/mlr-org/mlr3extralearners\n\nlightgbm-transform (feature transformation binding): https://github.com/microsoft/lightgbm-transform\n\nSupport\n-------\n\n- Ask a question [on Stack Overflow with the `lightgbm` tag](https://stackoverflow.com/questions/ask?tags=lightgbm), we monitor this for new questions.\n- Open **bug reports** and **feature requests** (not questions) on [GitHub issues](https://github.com/microsoft/LightGBM/issues).\n\nHow to Contribute\n-----------------\n\nCheck [CONTRIBUTING](https://github.com/microsoft/LightGBM/blob/master/CONTRIBUTING.md) page.\n\nMicrosoft Open Source Code of Conduct\n-------------------------------------\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\nReference Papers\n----------------\n\nGuolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu. \"[LightGBM: A Highly Efficient Gradient Boosting Decision Tree](https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree)\". Advances in Neural Information Processing Systems 30 (NIPS 2017), pp. 3149-3157.\n\nQi Meng, Guolin Ke, Taifeng Wang, Wei Chen, Qiwei Ye, Zhi-Ming Ma, Tie-Yan Liu. \"[A Communication-Efficient Parallel Algorithm for Decision Tree](http://papers.nips.cc/paper/6380-a-communication-efficient-parallel-algorithm-for-decision-tree)\". Advances in Neural Information Processing Systems 29 (NIPS 2016), pp. 1279-1287.\n\nHuan Zhang, Si Si and Cho-Jui Hsieh. \"[GPU Acceleration for Large-scale Tree Boosting](https://arxiv.org/abs/1706.08359)\". SysML Conference, 2018.\n\n**Note**: If you use LightGBM in your GitHub projects, please add `lightgbm` in the `requirements.txt`.\n\nLicense\n-------\n\nThis project is licensed under the terms of the MIT license. See [LICENSE](https://github.com/microsoft/LightGBM/blob/master/LICENSE) for additional details.\n",
	"data-mining data-science document-similarity fasttext gensim information-retrieval machine-learning natural-language-processing neural-network nlp python topic-modeling word-embeddings word-similarity word2vec": "gensim \u2013 Topic Modelling in Python\n==================================\n\n<!--\nThe following image URLs are obfuscated = proxied and cached through\nGoogle because of Github's proxying issues. See:\nhttps://github.com/RaRe-Technologies/gensim/issues/2805\n-->\n\n[![Build Status](https://github.com/RaRe-Technologies/gensim/actions/workflows/tests.yml/badge.svg?branch=develop)](https://github.com/RaRe-Technologies/gensim/actions)\n[![GitHub release](https://img.shields.io/github/release/rare-technologies/gensim.svg?maxAge=3600)](https://github.com/RaRe-Technologies/gensim/releases)\n[![Downloads](https://img.shields.io/pypi/dm/gensim?color=blue)](https://pepy.tech/project/gensim/)\n[![DOI](https://zenodo.org/badge/DOI/10.13140/2.1.2393.1847.svg)](https://doi.org/10.13140/2.1.2393.1847)\n[![Mailing List](https://img.shields.io/badge/-Mailing%20List-blue.svg)](https://groups.google.com/forum/#!forum/gensim)\n[![Follow](https://img.shields.io/twitter/follow/gensim_py.svg?style=social&style=flat&logo=twitter&label=Follow&color=blue)](https://twitter.com/gensim_py)\n\nGensim is a Python library for *topic modelling*, *document indexing*\nand *similarity retrieval* with large corpora. Target audience is the\n*natural language processing* (NLP) and *information retrieval* (IR)\ncommunity.\n\n## \u26a0\ufe0f  Please [sponsor Gensim](https://github.com/sponsors/piskvorky) to help sustain this open source project \u2764\ufe0f\n\n\nFeatures\n--------\n\n-   All algorithms are **memory-independent** w.r.t. the corpus size\n    (can process input larger than RAM, streamed, out-of-core),\n-   **Intuitive interfaces**\n    -   easy to plug in your own input corpus/datastream (trivial\n        streaming API)\n    -   easy to extend with other Vector Space algorithms (trivial\n        transformation API)\n-   Efficient multicore implementations of popular algorithms, such as\n    online **Latent Semantic Analysis (LSA/LSI/SVD)**, **Latent\n    Dirichlet Allocation (LDA)**, **Random Projections (RP)**,\n    **Hierarchical Dirichlet Process (HDP)** or **word2vec deep\n    learning**.\n-   **Distributed computing**: can run *Latent Semantic Analysis* and\n    *Latent Dirichlet Allocation* on a cluster of computers.\n-   Extensive [documentation and Jupyter Notebook tutorials].\n\nIf this feature list left you scratching your head, you can first read\nmore about the [Vector Space Model] and [unsupervised document analysis]\non Wikipedia.\n\nInstallation\n------------\n\nThis software depends on [NumPy and Scipy], two Python packages for\nscientific computing. You must have them installed prior to installing\ngensim.\n\nIt is also recommended you install a fast BLAS library before installing\nNumPy. This is optional, but using an optimized BLAS such as MKL, [ATLAS] or\n[OpenBLAS] is known to improve performance by as much as an order of\nmagnitude. On OSX, NumPy picks up its vecLib BLAS automatically,\nso you don\u2019t need to do anything special.\n\nInstall the latest version of gensim:\n\n```bash\n    pip install --upgrade gensim\n```\n\nOr, if you have instead downloaded and unzipped the [source tar.gz]\npackage:\n\n```bash\n    python setup.py install\n```\n\nFor alternative modes of installation, see the [documentation].\n\nGensim is being [continuously tested](http://radimrehurek.com/gensim/#testing) under all\n[supported Python versions](https://github.com/RaRe-Technologies/gensim/wiki/Gensim-And-Compatibility).\nSupport for Python 2.7 was dropped in gensim 4.0.0 \u2013 install gensim 3.8.3 if you must use Python 2.7.\n\nHow come gensim is so fast and memory efficient? Isn\u2019t it pure Python, and isn\u2019t Python slow and greedy?\n--------------------------------------------------------------------------------------------------------\n\nMany scientific algorithms can be expressed in terms of large matrix\noperations (see the BLAS note above). Gensim taps into these low-level\nBLAS libraries, by means of its dependency on NumPy. So while\ngensim-the-top-level-code is pure Python, it actually executes highly\noptimized Fortran/C under the hood, including multithreading (if your\nBLAS is so configured).\n\nMemory-wise, gensim makes heavy use of Python\u2019s built-in generators and\niterators for streamed data processing. Memory efficiency was one of\ngensim\u2019s [design goals], and is a central feature of gensim, rather than\nsomething bolted on as an afterthought.\n\nDocumentation\n-------------\n\n-   [QuickStart]\n-   [Tutorials]\n-   [Official API Documentation]\n\n  [QuickStart]: https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html\n  [Tutorials]: https://radimrehurek.com/gensim/auto_examples/\n  [Official Documentation and Walkthrough]: http://radimrehurek.com/gensim/\n  [Official API Documentation]: http://radimrehurek.com/gensim/apiref.html\n\nSupport\n-------\n\nFor commercial support, please see [Gensim sponsorship](https://github.com/sponsors/piskvorky).\n\nAsk open-ended questions on the public [Gensim Mailing List](https://groups.google.com/forum/#!forum/gensim).\n\nRaise bugs on [Github](https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md) but please **make sure you follow the [issue template](https://github.com/RaRe-Technologies/gensim/blob/develop/ISSUE_TEMPLATE.md)**. Issues that are not bugs or fail to provide the requested details will be closed without inspection.\n\n\n---------\n\nAdopters\n--------\n\n| Company | Logo | Industry | Use of Gensim |\n|---------|------|----------|---------------|\n| [RARE Technologies](http://rare-technologies.com) | ![rare](docs/src/readme_images/rare.png) | ML & NLP consulting | Creators of Gensim \u2013\u00a0this is us! |\n| [Amazon](http://www.amazon.com/) |  ![amazon](docs/src/readme_images/amazon.png) | Retail |  Document similarity. |\n| [National Institutes of Health](https://github.com/NIHOPA/pipeline_word2vec) | ![nih](docs/src/readme_images/nih.png) | Health | Processing grants and publications with word2vec. |\n| [Cisco Security](http://www.cisco.com/c/en/us/products/security/index.html) | ![cisco](docs/src/readme_images/cisco.png) | Security |  Large-scale fraud detection. |\n| [Mindseye](http://www.mindseyesolutions.com/) | ![mindseye](docs/src/readme_images/mindseye.png) | Legal | Similarities in legal documents. |\n| [Channel 4](http://www.channel4.com/) | ![channel4](docs/src/readme_images/channel4.png) | Media | Recommendation engine. |\n| [Talentpair](http://talentpair.com) | ![talent-pair](docs/src/readme_images/talent-pair.png) | HR | Candidate matching in high-touch recruiting. |\n| [Juju](http://www.juju.com/)  | ![juju](docs/src/readme_images/juju.png) | HR | Provide non-obvious related job suggestions. |\n| [Tailwind](https://www.tailwindapp.com/) | ![tailwind](docs/src/readme_images/tailwind.png) | Media | Post interesting and relevant content to Pinterest. |\n| [Issuu](https://issuu.com/) | ![issuu](docs/src/readme_images/issuu.png) | Media | Gensim's LDA module lies at the very core of the analysis we perform on each uploaded publication to figure out what it's all about. |\n| [Search Metrics](http://www.searchmetrics.com/) | ![search-metrics](docs/src/readme_images/search-metrics.png) | Content Marketing | Gensim word2vec used for entity disambiguation in Search Engine Optimisation. |\n| [12K Research](https://12k.co/) | ![12k](docs/src/readme_images/12k.png)| Media |   Document similarity analysis on media articles. |\n| [Stillwater Supercomputing](http://www.stillwater-sc.com/) | ![stillwater](docs/src/readme_images/stillwater.png) | Hardware | Document comprehension and association with word2vec. |\n| [SiteGround](https://www.siteground.com/) |  ![siteground](docs/src/readme_images/siteground.png) | Web hosting | An ensemble search engine which uses different embeddings models and similarities, including word2vec, WMD, and LDA. |\n| [Capital One](https://www.capitalone.com/) | ![capitalone](docs/src/readme_images/capitalone.png) | Finance | Topic modeling for customer complaints exploration. |\n\n-------\n\nCiting gensim\n------------\n\nWhen [citing gensim in academic papers and theses], please use this\nBibTeX entry:\n\n    @inproceedings{rehurek_lrec,\n          title = {{Software Framework for Topic Modelling with Large Corpora}},\n          author = {Radim {\\v R}eh{\\r u}{\\v r}ek and Petr Sojka},\n          booktitle = {{Proceedings of the LREC 2010 Workshop on New\n               Challenges for NLP Frameworks}},\n          pages = {45--50},\n          year = 2010,\n          month = May,\n          day = 22,\n          publisher = {ELRA},\n          address = {Valletta, Malta},\n          note={\\url{http://is.muni.cz/publication/884893/en}},\n          language={English}\n    }\n\n  [citing gensim in academic papers and theses]: https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9vG_kV0AAAAJ&citation_for_view=9vG_kV0AAAAJ:NaGl4SEjCO4C\n\n  [design goals]: http://radimrehurek.com/gensim/about.html\n  [RaRe Technologies]: http://rare-technologies.com/wp-content/uploads/2016/02/rare_image_only.png%20=10x20\n  [rare\\_tech]: //rare-technologies.com\n  [Talentpair]: https://avatars3.githubusercontent.com/u/8418395?v=3&s=100\n  [citing gensim in academic papers and theses]: https://scholar.google.cz/citations?view_op=view_citation&hl=en&user=9vG_kV0AAAAJ&citation_for_view=9vG_kV0AAAAJ:u-x6o8ySG0sC\n\n  [documentation and Jupyter Notebook tutorials]: https://github.com/RaRe-Technologies/gensim/#documentation\n  [Vector Space Model]: http://en.wikipedia.org/wiki/Vector_space_model\n  [unsupervised document analysis]: http://en.wikipedia.org/wiki/Latent_semantic_indexing\n  [NumPy and Scipy]: http://www.scipy.org/Download\n  [ATLAS]: http://math-atlas.sourceforge.net/\n  [OpenBLAS]: http://xianyi.github.io/OpenBLAS/\n  [source tar.gz]: http://pypi.python.org/pypi/gensim\n  [documentation]: http://radimrehurek.com/gensim/install.html\n",
	"awesome awesome-list data-mining deep-learning explainability interpretability large-scale-machine-learning large-scale-ml machine-learning machine-learning-operations ml-operations ml-ops mlops privacy-preserving privacy-preserving-machine-learning privacy-preserving-ml production-machine-learning production-ml responsible-ai": "[![Awesome](images/awesome.svg)](https://github.com/sindresorhus/awesome)\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-YES-green.svg)](https://github.com/EthicalML/awesome-production-machine-learning/graphs/commit-activity)\n![GitHub](https://img.shields.io/badge/Release-PROD-yellow.svg)\n![GitHub](https://img.shields.io/badge/Languages-MULTI-blue.svg)\n![GitHub](https://img.shields.io/badge/License-MIT-lightgrey.svg)\n[![GitHub](https://img.shields.io/twitter/follow/axsaucedo.svg?label=Follow)](https://twitter.com/AxSaucedo/)\n\n\n# Awesome Production Machine Learning\n\nThis repository contains a curated list of awesome open source libraries that will help you deploy, monitor, version, scale and secure your production machine learning \ud83d\ude80\n\n## Quick links to sections in this page\n\n| | | |\n|-|-|-|\n|[\ud83d\udd0d Explaining Predictions & Models](#explaining-black-box-models-and-datasets) |[\ud83d\udd0f Privacy Preserving ML](#privacy-preserving-ml) | [\ud83d\udcdc Model & Data Versioning](#model-and-data-versioning)|\n|[\ud83c\udfc1 Model Training Orchestration](#model-training-orchestration)|[\ud83d\udcaa Model Serving & Monitoring](#model-serving-and-monitoring)|[\ud83e\udd16 Neural Architecture Search](#neural-architecture-search)|\n| [\ud83d\udcd3 Data Science Notebook](#data-science-notebook) | [\ud83d\udcca Industry-strength Visualisation](#industrial-strength-visualisation) | [\ud83d\udd20 Industry-strength NLP](#industrial-strength-nlp) |\n| [\ud83e\uddf5 Data Pipeline](#data-pipeline) | [\ud83c\udff7\ufe0f Data Labelling](#data-labelling) |  [\ud83d\udcc5 Metadata Management](#metadata-management)  |\n| [\ud83d\udce1 Functions as a Service](#function-as-a-service)| [\ud83d\uddfa\ufe0f Computation Distribution](#computation-load-distribution) | [\ud83d\udce5 Model Serialisation](#model-serialisation) |\n| [\ud83e\uddee Optimized Computation](#optimized-computation)| [\ud83d\udcb8 Data Stream Processing](#data-stream-processing) | [:red_circle: Outlier & Anomaly Detection](#outlier-and-anomaly-detection) |\n| [\ud83c\udf00 Feature Engineering](#feature-engineering) | [\ud83c\udf81 Feature Store](#feature-store) | [\u2694 Adversarial Robustness](#adversarial-robustness) |\n|[\ud83d\udcbe Data Storage Optimization](#data-storage-optimisation) | [\ud83d\udcb0 Commercial Platform](#commercial-platform) |\n\n## 10 Min Video Overview\n\n<table>\n  <tr>\n    <td width=\"30%\">\n        This <a href=\"https://www.youtube.com/watch?v=Ynb6X0KZKxY\">10 minute video</a> provides an overview of the motivations for machine learning operations as well as a high level overview on some of the tools in this repo. This <a href=\"https://www.youtube.com/watch?v=xymbp8RWaCQ&t=1s\">newer video</a> covers the an updated 2022 version of the state of MLOps \n    </td>\n    <td width=\"70%\">\n        <a href=\"https://www.youtube.com/watch?v=Ynb6X0KZKxY\"><img src=\"images/video.png\"></a>\n    </td>\n  </tr>\n</table>\n\n## Want to receive recurrent updates on this repo and other advancements?\n\n<table>\n  <tr>\n    <td width=\"30%\">\n         You can join the <a href=\"https://ethical.institute/mle.html\">Machine Learning Engineer</a> newsletter. Join over 10,000 ML professionals and enthusiasts who receive weekly curated articles & tutorials on production Machine Learning.\n    </td>\n    <td width=\"70%\">\n        <a href=\"https://ethical.institute/mle.html\"><img src=\"images/mleng.png\"></a>\n    </td>\n  </tr>\n  <tr>\n    <td width=\"30%\">\n         Also check out the <a href=\"https://github.com/EthicalML/awesome-artificial-intelligence-guidelines/\">Awesome Artificial Intelligence Guidelines</a> List, where we aim to map the landscape of \"Frameworks\", \"Codes of Ethics\", \"Guidelines\", \"Regulations\", etc related to Artificial Intelligence.\n    </td>\n    <td width=\"70%\">\n        <a href=\"https://github.com/EthicalML/awesome-artificial-intelligence-guidelines/\"><img src=\"images/guidelines.jpg\"></a>\n    </td>\n  </tr>\n</table>\n\n\n# Main Content\n\n## Explaining Black Box Models and Datasets\n* [Aequitas](https://github.com/dssg/aequitas) ![](https://img.shields.io/github/stars/dssg/aequitas.svg?style=social) - An open-source bias audit toolkit for data scientists, machine learning researchers, and policymakers to audit machine learning models for discrimination and bias, and to make informed and equitable decisions around developing and deploying predictive risk-assessment tools.\n* [Alibi](https://github.com/SeldonIO/alibi) ![](https://img.shields.io/github/stars/SeldonIO/alibi.svg?style=social) - Alibi is an open source Python library aimed at machine learning model inspection and interpretation. The initial focus on the library is on black-box, instance based model explanations.\n* [anchor](https://github.com/marcotcr/anchor) ![](https://img.shields.io/github/stars/marcotcr/anchor.svg?style=social) - Code for the paper [\"High precision model agnostic explanations\"](https://homes.cs.washington.edu/~marcotcr/aaai18.pdf), a model-agnostic system that explains the behaviour of complex models with high-precision rules called anchors.\n* [captum](https://github.com/pytorch/captum) ![](https://img.shields.io/github/stars/pytorch/captum.svg?style=social) - model interpretability and understanding library for PyTorch developed by Facebook. It contains general purpose implementations of integrated gradients, saliency maps, smoothgrad, vargrad and others for PyTorch models.\n* [casme](https://github.com/kondiz/casme) ![](https://img.shields.io/github/stars/kondiz/casme.svg?style=social) - Example of using classifier-agnostic saliency map extraction on ImageNet presented on the paper [\"Classifier-agnostic saliency map extraction\"](https://arxiv.org/abs/1805.08249).\n* [ContrastiveExplanation (Foil Trees)](https://github.com/MarcelRobeer/ContrastiveExplanation) ![](https://img.shields.io/github/stars/MarcelRobeer/ContrastiveExplanation.svg?style=social) - Python script for model agnostic contrastive/counterfactual explanations for machine learning. Accompanying code for the paper [\"Contrastive Explanations with Local Foil Trees\"](https://arxiv.org/abs/1806.07470).\n* [DeepLIFT](https://github.com/kundajelab/deeplift) ![](https://img.shields.io/github/stars/kundajelab/deeplift.svg?style=social) - Codebase that contains the methods in the paper [\"Learning important features through propagating activation differences\"](https://arxiv.org/abs/1704.02685). Here is the [slides](https://docs.google.com/file/d/0B15F_QN41VQXSXRFMzgtS01UOU0/edit?filetype=mspresentation) and the [video](https://vimeo.com/238275076) of the 15 minute talk given at ICML.\n* [DeepVis Toolbox](https://github.com/yosinski/deep-visualization-toolbox) ![](https://img.shields.io/github/stars/yosinski/deep-visualization-toolbox.svg?style=social) - This is the code required to run the Deep Visualization Toolbox, as well as to generate the neuron-by-neuron visualizations using regularized optimization. The toolbox and methods are described casually [here](http://yosinski.com/deepvis) and more formally in this [paper](https://arxiv.org/abs/1506.06579).\n* [ELI5](https://github.com/TeamHG-Memex/eli5) ![](https://img.shields.io/github/stars/TeamHG-Memex/eli5.svg?style=social) - \"Explain Like I'm 5\" is a Python package which helps to debug machine learning classifiers and explain their predictions.\n* [FACETS](https://github.com/PAIR-code/facets) ![](https://img.shields.io/github/stars/PAIR-code/facets.svg?style=social) - Facets contains two robust visualizations to aid in understanding and analyzing machine learning datasets. Get a sense of the shape of each feature of your dataset using Facets Overview, or explore individual observations using Facets Dive.\n* [Fairness Indicators](https://github.com/tensorflow/fairness-indicators) ![](https://img.shields.io/github/stars/tensorflow/fairness-indicators.svg?style=social) - The tool supports teams in evaluating, improving, and comparing models for fairness concerns in partnership with the broader Tensorflow toolkit.\n* [Fairlearn](https://github.com/fairlearn/fairlearn) ![](https://img.shields.io/github/stars/fairlearn/fairlearn.svg?style=social) - Fairlearn is a python toolkit to assess and mitigate unfairness in machine learning models.\n* [FairML](https://github.com/adebayoj/fairml) ![](https://img.shields.io/github/stars/adebayoj/fairml.svg?style=social) - FairML is a python toolbox auditing the machine learning models for bias.\n* [fairness](https://github.com/algofairness/fairness-comparison) ![](https://img.shields.io/github/stars/algofairness/fairness-comparison.svg?style=social) - This repository is meant to facilitate the benchmarking of fairness aware machine learning algorithms based on [this paper](https://arxiv.org/abs/1802.04422).\n* [GEBI - Global Explanations for Bias Identification](https://github.com/AgaMiko/GEBI) ![](https://img.shields.io/github/stars/AgaMiko/GEBI.svg?style=social) - An attention-based summarized post-hoc explanations for detection and identification of bias in data. We propose a global explanation and introduce a step-by-step framework on how to detect and test bias. Python package for image data.\n* [AI Explainability 360](https://github.com/Trusted-AI/AIX360) ![](https://img.shields.io/github/stars/Trusted-AI/AIX360.svg?style=social) - Interpretability and explainability of data and machine learning models including a comprehensive set of algorithms that cover different dimensions of explanations along with proxy explainability metrics.\n* [AI Fairness 360](https://github.com/Trusted-AI/AIF360) ![](https://img.shields.io/github/stars/Trusted-AI/AIF360.svg?style=social) - A comprehensive set of fairness metrics for datasets and machine learning models, explanations for these metrics, and algorithms to mitigate bias in datasets and models.\n* [iNNvestigate](https://github.com/albermax/innvestigate) ![](https://img.shields.io/github/stars/albermax/innvestigate.svg?style=social) - An open-source library for analyzing Keras models visually by methods such as [DeepTaylor-Decomposition](https://www.sciencedirect.com/science/article/pii/S0031320316303582), [PatternNet](https://openreview.net/forum?id=Hkn7CBaTW), [Saliency Maps](https://arxiv.org/abs/1312.6034), and [Integrated Gradients](https://arxiv.org/abs/1703.01365).\n* [Integrated-Gradients](https://github.com/ankurtaly/Integrated-Gradients) ![](https://img.shields.io/github/stars/ankurtaly/Integrated-Gradients.svg?style=social) - This repository provides code for implementing integrated gradients for networks with image inputs.\n* [InterpretML](https://github.com/interpretml/interpret/) ![](https://img.shields.io/github/stars/InterpretML/interpret.svg?style=social) - InterpretML is an open-source package for training interpretable models and explaining blackbox systems.\n* [keras-vis](https://github.com/raghakot/keras-vis) ![](https://img.shields.io/github/stars/raghakot/keras-vis.svg?style=social) -  keras-vis is a high-level toolkit for visualizing and debugging your trained keras neural net models. Currently supported visualizations include: Activation maximization, Saliency maps, Class activation maps.\n* [L2X](https://github.com/Jianbo-Lab/L2X) ![](https://img.shields.io/github/stars/Jianbo-Lab/L2X.svg?style=social) - Code for replicating the experiments in the paper [\"Learning to Explain: An Information-Theoretic Perspective on Model Interpretation\"](https://arxiv.org/pdf/1802.07814.pdf) at ICML 2018.\n* [Lightly](https://github.com/lightly-ai/lightly) ![](https://img.shields.io/github/stars/lightly-ai/lightly.svg?style=social) - A python framework for self-supervised learning on images. The learned representations can be used to analyze the distribution in unlabeled data and rebalance datasets.\n* [Lightwood](https://github.com/mindsdb/lightwood) ![](https://img.shields.io/github/stars/mindsdb/lightwood.svg?style=social) -  A Pytorch based framework that breaks down machine learning problems into smaller blocks that can be glued together seamlessly with an objective to build predictive models with one line of code.\n* [LIME](https://github.com/marcotcr/lime) ![](https://img.shields.io/github/stars/marcotcr/lime.svg?style=social) - Local Interpretable Model-agnostic Explanations for machine learning models.\n* [LOFO Importance](https://github.com/aerdem4/lofo-importance) ![](https://img.shields.io/github/stars/aerdem4/lofo-importance.svg?style=social) - LOFO (Leave One Feature Out) Importance calculates the importances of a set of features based on a metric of choice, for a model of choice, by iteratively removing each feature from the set, and evaluating the performance of the model, with a validation scheme of choice, based on the chosen metric.\n* [MindsDB](https://github.com/mindsdb/mindsdb) ![](https://img.shields.io/github/stars/mindsdb/mindsdb.svg?style=social) -   MindsDB is an Explainable AutoML framework for developers. With MindsDB you can build, train and use state of the art ML models in as simple as one line of code.\n* [mljar-supervised](https://github.com/mljar/mljar-supervised) ![](https://img.shields.io/github/stars/mljar/mljar-supervised.svg?style=social) - An Automated Machine Learning (AutoML) python package for tabular data. It can handle: Binary Classification, MultiClass Classification and Regression. It provides feature engineering, explanations and markdown reports.\n* [NETRON](https://github.com/lutzroeder/netron) ![](https://img.shields.io/github/stars/lutzroeder/netron.svg?style=social) - Viewer for neural network, deep learning and machine learning models.\n* [pyBreakDown](https://github.com/MI2DataLab/pyBreakDown) ![](https://img.shields.io/github/stars/MI2DataLab/pyBreakDown.svg?style=social) - A model agnostic tool for decomposition of predictions from black boxes. Break Down Table shows contributions of every variable to a final prediction.\n* [responsibly](https://github.com/ResponsiblyAI/responsibly) ![](https://img.shields.io/github/stars/ResponsiblyAI/responsibly.svg?style=social) - Toolkit for auditing and mitigating bias and fairness of machine learning systems\n* [SHAP](https://github.com/slundberg/shap) ![](https://img.shields.io/github/stars/slundberg/shap.svg?style=social) - SHapley Additive exPlanations is a unified approach to explain the output of any machine learning model.\n* [SHAPash](https://github.com/MAIF/shapash) ![](https://img.shields.io/github/stars/MAIF/shapash.svg?style=social) - Shapash is a Python library that provides several types of visualization that display explicit labels that everyone can understand.\n* [Skater](https://github.com/datascienceinc/Skater) ![](https://img.shields.io/github/stars/datascienceinc/Skater.svg?style=social) - Skater is a unified framework to enable Model Interpretation for all forms of model to help one build an Interpretable machine learning system often needed for real world use-cases.\n* [WhatIf](https://github.com/pair-code/what-if-tool) ![](https://img.shields.io/github/stars/pair-code/what-if-tool.svg?style=social) - An easy-to-use interface for expanding understanding of a black-box classification or regression ML model.\n* [Tensorflow's cleverhans](https://github.com/tensorflow/cleverhans) ![](https://img.shields.io/github/stars/tensorflow/cleverhans.svg?style=social) - An adversarial example library for constructing attacks, building defenses, and benchmarking both. A python library to benchmark system's vulnerability to [adversarial examples](http://karpathy.github.io/2015/03/30/breaking-convnets/).\n* [tensorflow's lucid](https://github.com/tensorflow/lucid) ![](https://img.shields.io/github/stars/tensorflow/lucid.svg?style=social) - Lucid is a collection of infrastructure and tools for research in neural network interpretability.\n* [tensorflow's Model Analysis](https://github.com/tensorflow/model-analysis) ![](https://img.shields.io/github/stars/tensorflow/model-analysis.svg?style=social) - TensorFlow Model Analysis (TFMA) is a library for evaluating TensorFlow models. It allows users to evaluate their models on large amounts of data in a distributed manner, using the same metrics defined in their trainer.\n* [themis-ml](https://github.com/cosmicBboy/themis-ml) ![](https://img.shields.io/github/stars/cosmicBboy/themis-ml.svg?style=social) - themis-ml is a Python library built on top of pandas and sklearn that implements fairness-aware machine learning algorithms.\n* [Themis](https://github.com/LASER-UMASS/Themis) ![](https://img.shields.io/github/stars/LASER-UMASS/Themis.svg?style=social) - Themis is a testing-based approach for measuring discrimination in a software system.\n* [TreeInterpreter](https://github.com/andosa/treeinterpreter) ![](https://img.shields.io/github/stars/andosa/treeinterpreter.svg?style=social) - Package for interpreting scikit-learn's decision tree and random forest predictions. Allows decomposing each prediction into bias and feature contribution components as described [here](http://blog.datadive.net/interpreting-random-forests/).\n* [woe](https://github.com/boredbird/woe) ![](https://img.shields.io/github/stars/boredbird/woe.svg?style=social) - Tools for WoE Transformation mostly used in ScoreCard Model for credit rating\n* [XAI - eXplainableAI](https://github.com/EthicalML/xai) ![](https://img.shields.io/github/stars/EthicalML/XAI.svg?style=social) - An eXplainability toolbox for machine learning.\n\n\n## Privacy Preserving ML\n* [Flower](https://github.com/adap/flower) ![](https://img.shields.io/github/stars/adap/flower.svg?style=social) - Flower is a Federated Learning Framework with a unified approach. It enables the federation of any ML workload, with any ML framework, and any programming language.\n* [Google's Differential Privacy](https://github.com/google/differential-privacy) ![](https://img.shields.io/github/stars/google/differential-privacy.svg?style=social) - This is a C++ library of \u03b5-differentially private algorithms, which can be used to produce aggregate statistics over numeric data sets containing private or sensitive information.\n* [Intel Homomorphic Encryption Backend](https://github.com/NervanaSystems/he-transformer) ![](https://img.shields.io/github/stars/NervanaSystems/he-transformer.svg?style=social) - The Intel HE transformer for nGraph is a Homomorphic Encryption (HE) backend to the Intel nGraph Compiler, Intel's graph compiler for Artificial Neural Networks.\n* [Microsoft SEAL](https://github.com/microsoft/SEAL) ![](https://img.shields.io/github/stars/microsoft/SEAL.svg?style=social) - Microsoft SEAL is an easy-to-use open-source (MIT licensed) homomorphic encryption library developed by the Cryptography Research group at Microsoft.\n* [OpenFL](https://github.com/intel/openfl)  ![](https://img.shields.io/github/stars/intel/openfl.svg?style=social) - OpenFL is a Python framework for Federated Learning. OpenFL is designed to be a _flexible_, _extensible_ and _easily learnable_ tool for data scientists. OpenFL is developed by Intel Internet of Things Group (IOTG) and Intel Labs.\n* [PySyft](https://github.com/OpenMined/PySyft) ![](https://img.shields.io/github/stars/OpenMined/PySyft.svg?style=social) - A Python library for secure, private Deep Learning. PySyft decouples private data from model training, using Multi-Party Computation (MPC) within PyTorch.\n* [Rosetta](https://github.com/LatticeX-Foundation/Rosetta)![](https://img.shields.io/github/stars/LatticeX-Foundation/Rosetta.svg?style=social) - A privacy-preserving framework based on TensorFlow with customized backend Operations using Multi-Party Computation (MPC). Rosetta reuses the APIs of TensorFlow and allows to transfer original TensorFlow codes into a privacy-preserving manner with minimal changes.\n* [Substra](https://github.com/SubstraFoundation/substra)![](https://img.shields.io/github/stars/SubstraFoundation/substra.svg?style=social) - Substra is an open-source framework for privacy-preserving, traceable and collaborative Machine Learning.\n* [Tensorflow Privacy](https://github.com/tensorflow/privacy) ![](https://img.shields.io/github/stars/tensorflow/privacy.svg?style=social) - A Python library that includes implementations of TensorFlow optimizers for training machine learning models with differential privacy.\n* [TF Encrypted](https://github.com/tf-encrypted/tf-encrypted) ![](https://img.shields.io/github/stars/tf-encrypted/tf-encrypted.svg?style=social) - A Framework for Confidential Machine Learning on Encrypted Data in TensorFlow.\n\n\n## Model and Data Versioning\n* [Aim](https://github.com/aimhubio/aim) ![](https://img.shields.io/github/stars/aimhubio/aim?style=social) - A super-easy way to record, search and compare AI experiments.\n* [Catalyst](https://github.com/catalyst-team/catalyst) ![](https://img.shields.io/github/stars/catalyst-team/catalyst.svg?style=social) - High-level utils for PyTorch DL & RL research. It was developed with a focus on reproducibility, fast experimentation and code/ideas reusing.\n* [ClearML](https://github.com/allegroai/clearml) ![](https://img.shields.io/github/stars/allegroai/clearml.svg?style=social) - Auto-Magical Experiment Manager & Version Control for AI (previously Trains).\n* [D6tflow](https://github.com/d6t/d6tflow) ![](https://img.shields.io/github/stars/d6t/d6tflow.svg?style=social) - A python library that allows for building complex data science workflows on Python.\n* [Data Version Control (DVC)](https://github.com/iterative/dvc) ![](https://img.shields.io/github/stars/iterative/dvc.svg?style=social) - A git fork that allows for version management of models.\n* [Deepkit](https://github.com/deepkit/deepkit-ml) ![](https://img.shields.io/github/stars/deepkit/deepkit-ml.svg?style=social) - An open-source platform and cross-platform desktop application to execute, track, and debug modern machine learning experiments.\n* [Dolt](https://github.com/dolthub/dolt) ![](https://img.shields.io/github/stars/dolthub/dolt.svg?style=social) - Dolt is a SQL database that you can fork, clone, branch, merge, push and pull just like a git repository.\n* [Flor](https://github.com/ucbrise/flor) ![](https://img.shields.io/github/stars/ucbrise/flor.svg?style=social) - Easy to use logger and automatic version controller made for data scientists who write ML code.\n* [Guild AI](https://github.com/guildai/guildai) ![](https://img.shields.io/github/stars/guildai/guildai.svg?style=social) - Open source toolkit that automates and optimizes machine learning experiments.\n* [Deeplake](https://github.com/activeloopai/deeplake) ![](https://img.shields.io/github/stars/activeloopai/deeplake.svg?style=social) - Store, access & manage datasets with version-control for PyTorch/TensorFlow locally or on any cloud with scalable data pipelines.\n* [Hangar](https://github.com/tensorwerk/hangar-py) ![](https://img.shields.io/github/stars/tensorwerk/hangar-py.svg?style=social) - Version control for tensor data, git-like semantics on numerical data with high speed and efficiency.\n* [Keepsake](https://github.com/replicate/keepsake) ![](https://img.shields.io/github/stars/replicate/keepsake.svg?style=social) - Version control for machine learning.\n* [lakeFS](https://github.com/treeverse/lakeFS) ![](https://img.shields.io/github/stars/treeverse/lakefs.svg?style=social) - Repeatable, atomic and versioned data lake on top of object storage.\n* [MLflow](https://github.com/mlflow/mlflow) ![](https://img.shields.io/github/stars/mlflow/mlflow.svg?style=social) - Open source platform to manage the ML lifecycle, including experimentation, reproducibility and deployment.\n* [ModelDB](https://github.com/VertaAI/modeldb/) ![](https://img.shields.io/github/stars/mitdbg/modeldb.svg?style=social) - An open-source system to version machine learning models including their ingredients code, data, config, and environment and to track ML metadata across the model lifecycle.\n* [ModelStore](https://github.com/operatorai/modelstore) ![](https://img.shields.io/github/stars/operatorai/modelstore.svg?style=social) - An open-source Python library that allows you to version, export, and save a machine learning model to your cloud storage provider.\n* [ormb](https://github.com/kleveross/ormb) ![](https://img.shields.io/github/stars/kleveross/ormb.svg?style=social) - Docker for Your ML/DL Models Based on OCI Artifacts.\n* [Pachyderm](https://github.com/pachyderm/pachyderm) ![](https://img.shields.io/github/stars/pachyderm/pachyderm.svg?style=social) - Open source distributed processing framework build on Kubernetes focused mainly on dynamic building of production machine learning pipelines - [(Video)](https://www.youtube.com/watch?v=LamKVhe2RSM).\n* [Polyaxon](https://github.com/polyaxon/polyaxon) ![](https://img.shields.io/github/stars/polyaxon/polyaxon.svg?style=social) - A platform for reproducible and scalable machine learning and deep learning on kubernetes - [(Video)](https://www.youtube.com/watch?v=Iexwrka_hys).\n* [Quilt](https://github.com/quiltdata/quilt) ![](https://img.shields.io/github/stars/quiltdata/quilt.svg?style=social) - Versioning, reproducibility and deployment of data and models.\n* [Sacred](https://github.com/IDSIA/sacred) ![](https://img.shields.io/github/stars/IDSIA/sacred.svg?style=social) - Tool to help you configure, organize, log and reproduce machine learning experiments.\n* [Studio](https://github.com/studioml/studio) ![](https://img.shields.io/github/stars/studioml/studio.svg?style=social) - Model management framework which minimizes the overhead involved with scheduling, running, monitoring and managing artifacts of your machine learning experiments.\n* [TerminusDB](https://github.com/terminusdb/terminusdb) ![](https://img.shields.io/github/stars/terminusdb/terminusdb.svg?style=social) - A graph database management system that stores data like git.\n\n\n## Model Training Orchestration\n* [Accelerate](https://github.com/huggingface/accelerate) ![](https://img.shields.io/github/stars/huggingface/accelerate.svg?style=social) - Accelerate abstracts exactly and only the boilerplate code related to multi-GPU/TPU/mixed-precision and leaves the rest of your code unchanged.\n* [CML](https://github.com/iterative/cml) ![](https://img.shields.io/github/stars/iterative/cml.svg?style=social) - Continuous Machine Learning (CML) is an open-source library for implementing continuous integration & delivery (CI/CD) in machine learning projects.\n* [Determined](https://github.com/determined-ai/determined) ![](https://img.shields.io/github/stars/determined-ai/determined.svg?style=social) - Deep learning training platform with integrated support for distributed training, hyperparameter tuning, and model management (supports Tensorflow and Pytorch).\n* [envd](https://github.com/tensorchord/envd) ![](https://img.shields.io/github/stars/tensorchord/envd.svg?style=social) - Machine learning development environment for data science and AI/ML engineering teams.\n* [Flyte](https://flyte.org) ![](https://img.shields.io/github/stars/lyft/flyte.svg?style=social) - Lyft\u2019s Cloud Native Machine Learning and Data Processing Platform - [(Demo)](https://youtu.be/KdUJGSP1h9U?t=1451).\n* [Hopsworks](https://github.com/logicalclocks/hopsworks) ![](https://img.shields.io/github/stars/logicalclocks/hopsworks.svg?style=social) - Hopsworks is a data-intensive platform for the design and operation of machine learning pipelines that includes a Feature Store - [(Video)](https://www.youtube.com/watch?v=v1DrnY8caVU).\n* [Kubeflow](https://github.com/kubeflow/kubeflow) ![](https://img.shields.io/github/stars/kubeflow/kubeflow.svg?style=social) - A cloud native platform for machine learning based on Google\u2019s internal machine learning pipelines.\n* [MLeap](https://github.com/combust/mleap) ![](https://img.shields.io/github/stars/combust/mleap.svg?style=social) - Standardisation of pipeline and model serialization for Spark, Tensorflow and sklearn.\n* [NVIDIA TensorRT](https://github.com/NVIDIA/TensorRT) ![](https://img.shields.io/github/stars/NVIDIA/TensorRT.svg?style=social) - TensorRT is a C++ library for high performance inference on NVIDIA GPUs and deep learning accelerators.\n* [Onepanel](https://github.com/onepanelio/core) ![](https://img.shields.io/github/stars/onepanelio/core?style=social) - Production scale vision AI platform, with fully integrated components for model building, automated labeling, data processing and model training pipelines.\n* [Open Platform for AI](https://github.com/Microsoft/pai) ![](https://img.shields.io/github/stars/Microsoft/pai.svg?style=social) - Platform that provides complete AI model training and resource management capabilities.\n* [PyCaret](https://pycaret.org/) ![](https://img.shields.io/github/stars/pycaret/pycaret.svg?style=social)) - low-code library for training and deploying models (scikit-learn, XGBoost, LightGBM, spaCy)\n* [Skaffold](https://github.com/GoogleContainerTools/skaffold) ![](https://img.shields.io/github/stars/GoogleContainerTools/skaffold.svg?style=social) - Skaffold is a command line tool that facilitates continuous development for Kubernetes applications. You can iterate on your application source code locally then deploy to local or remote Kubernetes clusters.\n* [Tensorflow Extended (TFX)](https://github.com/tensorflow/tfx) ![](https://img.shields.io/github/stars/tensorflow/tfx.svg?style=social) - Production oriented configuration framework for ML based on TensorFlow, incl. monitoring and model version management.\n* [TonY](https://github.com/linkedin/TonY) ![](https://img.shields.io/github/stars/linkedin/TonY.svg?style=social) - TonY is a framework to natively run deep learning jobs on Apache Hadoop. It currently supports TensorFlow, PyTorch, MXNet and Horovod.\n* [ZenML](https://github.com/maiot-io/zenml) ![](https://img.shields.io/github/stars/maiot-io/zenml.svg?style=social) - ZenML is an extensible, open-source MLOps framework to create reproducible ML pipelines with a focus on automated metadata tracking, caching, and many integrations to other tools.\n\n\n## Model Serving and Monitoring\n* [Backprop](https://github.com/backprop-ai/backprop) ![](https://img.shields.io/github/stars/backprop-ai/backprop.svg?style=social) - Backprop makes it simple to use, finetune, and deploy state-of-the-art ML models.\n* [BentoML](https://github.com/bentoml/BentoML) ![](https://img.shields.io/github/stars/bentoml/bentoml.svg?style=social) - BentoML is an open source framework for high performance ML model serving.\n* [Cortex](https://github.com/cortexlabs/cortex) ![](https://img.shields.io/github/stars/cortexlabs/cortex.svg?style=social) - Cortex is an open source platform for deploying machine learning models\u2014trained with any framework\u2014as production web services. No DevOps required.\n* [Deepchecks](https://github.com/deepchecks/deepchecks) ![](https://img.shields.io/github/stars/deepchecks/deepchecks.svg?style=social) - Deepchecks is an open source package for comprehensively validating your machine learning models and data with minimal effort during development, deployment or in production.\n* [DeepDetect](https://github.com/jolibrain/deepdetect) ![](https://img.shields.io/github/stars/jolibrain/deepdetect.svg?style=social) - Machine Learning production server for TensorFlow, XGBoost and Cafe models written in C++ and maintained by Jolibrain.\n* [Evidently](https://github.com/evidentlyai/evidently) ![](https://img.shields.io/github/stars/evidentlyai/evidently.svg?style=social) - Evidently helps analyze machine learning models during development, validation, or production monitoring. The tool generates interactive reports from pandas DataFrame.\n* [ForestFlow](https://github.com/ForestFlow/ForestFlow)![](https://img.shields.io/github/stars/forestflow/forestflow.svg?style=social) - Cloud-native machine learning model server.\n* [Jina](https://github.com/jina-ai/jina)  ![](https://img.shields.io/github/stars/jina-ai/jina.svg?style=social) - Cloud native search framework that   supports to use deep learning/state of the art AI models for search.\n* [KFServing](https://github.com/kubeflow/kfserving) ![](https://img.shields.io/github/stars/kubeflow/kfserving.svg?style=social) - Serverless framework to deploy and monitor machine learning models in Kubernetes - [(Video)](https://www.youtube.com/watch?v=hGIvlFADMhU).\n* [m2cgen](https://github.com/BayesWitnesses/m2cgen) ![](https://img.shields.io/github/stars/BayesWitnesses/m2cgen.svg?style=social) - A lightweight library which allows to transpile trained classic machine learning models into a native code of C, Java, Go, R, PHP, Dart, Haskell, Rust and many other programming languages.\n* [MLEM](https://github.com/iterative/mlem/) ![](https://img.shields.io/github/stars/iterative/mlem.svg?style=social) - Version and deploy your ML models following GitOps principles.\n* [MLServer](https://github.com/SeldonIO/mlserver) ![](https://img.shields.io/github/stars/SeldonIO/mlserver.svg?style=social) - An inference server for your machine learning models, including support for multiple frameworks, multi-model serving and more.\n* [mltrace](https://github.com/loglabs/mltrace) ![](https://img.shields.io/github/stars/loglabs/mltrace.svg?style=social) - a lightweight, open-source Python tool to get \"bolt-on\" observability in ML pipelines.\n* [MLWatcher](https://github.com/anodot/MLWatcher) ![](https://img.shields.io/github/stars/anodot/MLWatcher.svg?style=social) - MLWatcher is a python agent that records a large variety of time-serie metrics of your running ML classification algorithm. It enables you to monitor in real time.\n* [Model Server for Apache MXNet (MMS)](https://github.com/awslabs/mxnet-model-server) ![](https://img.shields.io/github/stars/awslabs/mxnet-model-server.svg?style=social) - A model server for Apache MXNet from Amazon Web Services that is able to run MXNet models as well as Gluon models (Amazon's SageMaker runs a custom version of MMS under the hood).\n* [NannyML](https://github.com/NannyML/nannyml) ![](https://img.shields.io/github/stars/nannyml/nannyml.svg?style=social) - An open source library to estimate post-deployment model performance (without access to targets). Capable of fully capturing the impact of data drift on performance.\n* [Mosec](https://github.com/mosecorg/mosec) ![](https://img.shields.io/github/stars/mosecorg/mosec.svg?style=social) - A rust-powered and multi-stage pipelined model server which offers dynamic batching and more. Super easy to implement and deploy as micro-services.\n* [OpenScoring](https://github.com/openscoring/openscoring) ![](https://img.shields.io/github/stars/openscoring/openscoring.svg?style=social) - REST web service for the true real-time scoring (< 1 ms) of Scikit-Learn, R and Apache Spark models.\n* [Pandas Profiling](https://github.com/pandas-profiling/pandas-profiling) - Creates HTML profiling reports from pandas DataFrame objects. It extends the pandas DataFrame with df.profile_report() for quick data analysis.\n* [PredictionIO](https://github.com/apache/predictionio) ![](https://img.shields.io/github/stars/apache/predictionio.svg?style=social) - An open source Machine Learning Server built on top of a state-of-the-art open source stack for developers and data scientists to create predictive engines for any machine learning task.\n* [Redis-AI](https://github.com/RedisAI/RedisAI) ![](https://img.shields.io/github/stars/RedisAI/RedisAI.svg?style=social) - A Redis module for serving tensors and executing deep learning models. Expect changes in the API and internals.\n* [Seldon Core](https://github.com/SeldonIO/seldon-core) ![](https://img.shields.io/github/stars/SeldonIO/seldon-core.svg?style=social) - Open source platform for deploying and monitoring machine learning models in kubernetes - [(Video)](https://www.youtube.com/watch?v=pDlapGtecbY).\n* [skops](https://github.com/skops-dev/skops) ![](https://img.shields.io/github/stars/skops-dev/skops.svg?style=social) - skops is a Python library helping you share your scikit-learn based models and put them in production.\n* [Tempo](https://github.com/SeldonIO/tempo) ![](https://img.shields.io/github/stars/SeldonIO/tempo.svg?style=social) - Open source SDK that provides a unified interface to multiple MLOps projects that enable data scientists to deploy and productionise machine learning systems.\n* [Tensorflow Serving](https://github.com/tensorflow/serving) ![](https://img.shields.io/github/stars/tensorflow/serving.svg?style=social) - High-performant framework to serve Tensorflow models via grpc protocol able to handle 100k requests per second per core.\n* [TorchServe](https://github.com/pytorch/serve) ![](https://img.shields.io/github/stars/pytorch/serve.svg?style=social) - TorchServe is a flexible and easy to use tool for serving PyTorch models.\n* [Transformer-deploy](https://github.com/ELS-RD/transformer-deploy/) ![](https://img.shields.io/github/stars/ELS-RD/transformer-deploy.svg?style=social) - Transformer-deploy is an efficient, scalable and enterprise-grade CPU/GPU inference server for Hugging Face transformer models.\n* [Triton Inference Server](https://github.com/triton-inference-server/server) ![](https://img.shields.io/github/stars/triton-inference-server/server.svg?style=social) - Triton is a high performance open source serving software to deploy AI models from any framework on GPU & CPU while maximizing utilization.\n* [WhyLogs](https://github.com/whylabs/whylogs-python) ![](https://img.shields.io/github/stars/whylabs/whylogs-python.svg?style=social) - Lightweight solution for profiling and monitoring your ML data pipeline end-to-end\n\n\n## Adversarial Robustness\n* [AdvBox](https://github.com/advboxes/AdvBox) ![](https://img.shields.io/github/stars/advboxes/AdvBox.svg?style=social) - A toolbox to generate adversarial examples that fool neural networks in PaddlePaddle, PyTorch, Caffe2, MxNet, Keras, TensorFlow, and Advbox can benchmark the robustness of machine learning models.\n* [Adversarial DNN Playground](https://github.com/QData/AdversarialDNN-Playground) ![](https://img.shields.io/github/stars/QData/AdversarialDNN-Playground.svg?style=social) - think [TensorFlow Playground](https://playground.tensorflow.org/), but for Adversarial Examples! A visualization tool designed for learning and teaching - the attack library is limited in size, but it has a nice front-end to it with buttons you can press!\n* [AdverTorch](https://github.com/BorealisAI/advertorch) ![](https://img.shields.io/github/stars/BorealisAI/advertorch.svg?style=social) - library for adversarial attacks / defenses specifically for PyTorch.\n* [Alibi Detect](https://github.com/SeldonIO/alibi-detect) ![](https://img.shields.io/github/stars/SeldonIO/alibi-detect.svg?style=social) - alibi-detect is a Python package focused on outlier, adversarial and concept drift detection. The package aims to cover both online and offline detectors for tabular data, text, images and time series. The outlier detection methods should allow the user to identify global, contextual and collective outliers.\n* [Artificial Adversary](https://github.com/airbnb/artificial-adversary) ![](https://img.shields.io/github/stars/airbnb/artificial-adversary.svg?style=social) AirBnB's library to generate text that reads the same to a human but passes adversarial classifiers.\n* [CleverHans](https://github.com/tensorflow/cleverhans) ![](https://img.shields.io/github/stars/tensorflow/cleverhans.svg?style=social) - library for testing adversarial attacks / defenses maintained by some of the most important names in adversarial ML, namely Ian Goodfellow (ex-Google Brain, now Apple) and Nicolas Papernot (Google Brain). Comes with some nice tutorials!\n* [Counterfit](https://github.com/Azure/counterfit) ![](https://img.shields.io/github/stars/Azure/counterfit.svg?style=social) - Counterfit is a command-line tool and generic automation layer for assessing the security of machine learning systems.\n* [DEEPSEC](https://github.com/kleincup/DEEPSEC) ![](https://img.shields.io/github/stars/kleincup/DEEPSEC.svg?style=social) - another systematic tool for attacking and defending deep learning models.\n* [EvadeML](https://github.com/mzweilin/EvadeML-Zoo) ![](https://img.shields.io/github/stars/mzweilin/EvadeML-Zoo.svg?style=social) - benchmarking and visualization tool for adversarial ML maintained by Weilin Xu, a PhD at University of Virginia, working with David Evans. Has a tutorial on re-implementation of one of the most important adversarial defense papers - [feature squeezing](https://arxiv.org/abs/1704.01155) (same team).\n* [Foolbox](https://github.com/bethgelab/foolbox) ![](https://img.shields.io/github/stars/bethgelab/foolbox.svg?style=social) - second biggest adversarial library. Has an even longer list of attacks - but no defenses or evaluation metrics. Geared more towards computer vision. Code easier to understand / modify than ART - also better for exploring blackbox attacks on surrogate models.\n* [Adversarial Robustness Toolbox (ART))](https://github.com/Trusted-AI/adversarial-robustness-toolboxx) ![](https://img.shields.io/github/stars/Trusted-AI/adversarial-robustness-toolboxx.svg?style=social) - ART provides tools that enable developers and researchers to defend and evaluate Machine Learning models and applications against the adversarial threats of Evasion, Poisoning, Extraction, and Inference.\n* [MIA](https://github.com/spring-epfl/mia) ![](https://img.shields.io/github/stars/spring-epfl/mia.svg?style=social) - A library for running membership inference attacks (MIA) against machine learning models.\n* [Nicolas Carlini\u2019s Adversarial ML reading list](https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html) - not a library, but a curated list of the most important adversarial papers by one of the leading minds in Adversarial ML, Nicholas Carlini. If you want to discover the 10 papers that matter the most - I would start here.\n* [Robust ML](https://www.robust-ml.org/defenses/) - another robustness resource maintained by some of the leading names in adversarial ML. They specifically focus on defenses, and ones that have published code available next to papers. Practical and useful.\n* [TextFool](https://github.com/bogdan-kulynych/textfool) ![](https://img.shields.io/github/stars/bogdan-kulynych/textfool.svg?style=social) - plausible looking adversarial examples for text generation.\n* [Trickster](https://github.com/spring-epfl/trickster) ![](https://img.shields.io/github/stars/spring-epfl/trickster.svg?style=social) - Library and experiments for attacking machine learning in discrete domains using graph search.\n\n\n## Neural Architecture Search\n* [Autokeras](https://github.com/jhfjhfj1/autokeras) ![](https://img.shields.io/github/stars/jhfjhfj1/autokeras.svg?style=social) - AutoML library for Keras based on [\"Auto-Keras: Efficient Neural Architecture Search with Network Morphism\"](https://arxiv.org/abs/1806.10282).\n* [ENAS via Parameter Sharing](https://github.com/melodyguan/enas) - Efficient Neural Architecture Search via Parameter Sharing by [authors of paper](https://arxiv.org/abs/1802.03268).\n* [ENAS-PyTorch](https://github.com/carpedm20/ENAS-pytorch) ![](https://img.shields.io/github/stars/carpedm20/ENAS-pytorch.svg?style=social) - Efficient Neural Architecture Search (ENAS) in PyTorch based [on this paper](https://arxiv.org/abs/1802.03268).\n* [ENAS-Tensorflow](https://github.com/MINGUKKANG/ENAS-Tensorflow) ![](https://img.shields.io/github/stars/MINGUKKANG/ENAS-Tensorflow.svg?style=social) - Efficient Neural Architecture search via parameter sharing(ENAS) micro search Tensorflow code for windows user.\n* [Katib](https://github.com/kubeflow/katib) ![](https://img.shields.io/github/stars/kubeflow/katib.svg?style=social) - A Kubernetes-based system for Hyperparameter Tuning and Neural Architecture Search.\n* [Maggy](https://github.com/logicalclocks/maggy) ![](https://img.shields.io/github/stars/logicalclocks/maggy.svg?style=social) - Asynchronous, directed Hyperparameter search and parallel ablation studies on Apache Spark - [(Video)](https://www.youtube.com/watch?v=0Hd1iYEL03w).\n* [Neural Architecture Search with Controller RNN](https://github.com/titu1994/neural-architecture-search) ![](https://img.shields.io/github/stars/titu1994/neural-architecture-search.svg?style=social) - Basic implementation of Controller RNN from [Neural Architecture Search with Reinforcement Learning](https://arxiv.org/abs/1611.01578) and [Learning Transferable Architectures for Scalable Image Recognition](https://arxiv.org/abs/1707.07012).\n* [Neural Network Intelligence](https://github.com/Microsoft/nni) ![](https://img.shields.io/github/stars/Microsoft/nni.svg?style=social) - NNI (Neural Network Intelligence) is a toolkit to help users run automated machine learning (AutoML) experiments.\n\n\n## Data Science Notebook\n* [Apache Zeppelin](https://github.com/apache/zeppelin) ![](https://img.shields.io/github/stars/apache/zeppelin.svg?style=social) - Web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Scala and more.\n* [Binder](https://github.com/jupyterhub/binder) ![](ttps://img.shields.io/github/stars/jupyterhub/binder.svg?style=social) - Binder hosts notebooks in an executable environment (for free).\n* [H2O Flow](https://github.com/h2oai/h2o-flow) - Jupyter notebook-like interface for H2O to create, save and re-use \"flows\".\n* [Jupyter Notebooks](https://github.com/jupyter/notebook) ![](https://img.shields.io/github/stars/jupyter/notebook.svg?style=social) - Web interface python sandbox environments for reproducible development\n* [ML Workspace](https://github.com/ml-tooling/ml-workspace) ![](https://img.shields.io/github/stars/ml-tooling/ml-workspace.svg?style=social) - All-in-one web IDE for machine learning and data science. Combines Jupyter, VS Code, Tensorflow, and many other tools/libraries into one Docker image.\n* [.NET Interactive](https://github.com/dotnet/interactive) ![](https://img.shields.io/github/stars/dotnet/interactive.svg?style=social) - .NET Interactive takes the power of .NET and embeds it into your interactive experiences.\n* [Papermill](https://github.com/nteract/papermill) ![](https://img.shields.io/github/stars/nteract/papermill.svg?style=social) - Papermill is a library for parameterizing notebooks and executing them like Python scripts.\n* [Ploomber](https://github.com/ploomber/ploomber) ![](https://img.shields.io/github/stars/ploomber/ploomber.svg?style=social) - Ploomber allows you to develop workflows in Jupyter and execute them in a distributed environment without code changes. It supports Kubernetes, AWS Batch, and Airflow.\n* [Polynote](https://github.com/polynote/polynote) ![](https://img.shields.io/github/stars/stencila/stencila.svg?style=social) - Polynote is an experimental polyglot notebook environment. Currently, it supports Scala and Python (with or without Spark), SQL, and Vega.\n* [RMarkdown](https://github.com/rstudio/rmarkdown) ![](https://img.shields.io/github/stars/rstudio/rmarkdown.svg?style=social) - The rmarkdown package is a next generation implementation of R Markdown based on Pandoc.\n* [Stencila](https://github.com/stencila/stencila) ![](https://img.shields.io/github/stars/stencila/stencila.svg?style=social) - Stencila is a platform for creating, collaborating on, and sharing data driven content. Content that is transparent and reproducible.\n* [Voil\u00e0](https://github.com/voila-dashboards/voila) ![](https://img.shields.io/github/stars/voila-dashboards/voila.svg?style=social) - Voil\u00e0 turns Jupyter notebooks into standalone web applications that can e.g. be used as dashboards.\n\n\n## Industrial Strength Visualisation\n* [Altair](https://github.com/altair-viz/altair) - Altair is a declarative statistical visualization library for Python.\n* [Apache ECharts](https://github.com/apache/echarts) - Apache ECharts is a powerful, interactive charting and data visualization library for browser.\n* [Bokeh](https://github.com/bokeh/bokeh) ![](https://img.shields.io/github/stars/bokeh/bokeh.svg?style=social) - Bokeh is an interactive visualization library for Python that enables beautiful and meaningful visual presentation of data in modern web browsers.\n* [Geoplotlib](https://github.com/andrea-cuttone/geoplotlib) ![](https://img.shields.io/github/stars/andrea-cuttone/geoplotlib.svg?style=social) - geoplotlib is a python toolbox for visualizing geographical data and making maps.\n* [ggplot2](https://github.com/tidyverse/ggplot2) ![](https://img.shields.io/github/stars/tidyverse/ggplot2.svg?style=social) - An implementation of the grammar of graphics for R.\n* [gradio](https://github.com/gradio-app/gradio) ![](https://img.shields.io/github/stars/gradio-app/gradio.svg?style=social) - Quickly create and share demos of models - by only writing Python. Debug models interactively in your browser, get feedback from collaborators, and generate public links without deploying anything.\n* [matplotlib](https://github.com/matplotlib/matplotlib) ![](https://img.shields.io/github/stars/matplotlib/matplotlib.svg?style=social) - A Python 2D plotting library which produces publication-quality figures in a variety of hardcopy formats and interactive environments across platforms.\n* [Missingno](https://github.com/ResidentMario/missingno) ![](https://img.shields.io/github/stars/ResidentMario/missingno.svg?style=social) - missingno provides a small toolset of flexible and easy-to-use missing data visualizations and utilities that allows you to get a quick visual summary of the completeness (or lack thereof) of your dataset.\n* [PDPBox](https://github.com/SauceCat/PDPbox) ![](https://img.shields.io/github/stars/SauceCat/PDPbox.svg?style=social) - This repository is inspired by ICEbox. The goal is to visualize the impact of certain features towards model prediction for any supervised learning algorithm.\n* [Perspective](https://github.com/finos/perspective) ![](https://img.shields.io/github/stars/finos/perspective.svg?style=social) Streaming pivot visualization via WebAssembly.\n* [Pixiedust](https://github.com/pixiedust/pixiedust) ![](https://img.shields.io/github/stars/pixiedust/pixiedust.svg?style=social) - PixieDust is a productivity tool for Python or Scala notebooks, which lets a developer encapsulate business logic into something easy for your customers to consume.\n* [Plotly Dash](https://github.com/plotly/dash) ![](https://img.shields.io/github/stars/plotly/dash.svg?style=social) - Dash is a Python framework for building analytical web applications without the need to write javascript.\n* [Plotly.py](https://github.com/plotly/plotly.py) ![](https://img.shields.io/github/stars/plotly/plotly.py.svg?style=social) - An interactive, open source, and browser-based graphing library for Python.\n* [Plotly.NET](https://github.com/plotly/Plotly.NET) ![](https://img.shields.io/github/stars/plotly/Plotly.NET.svg?style=social) - Plotly.NET provides functions for generating and rendering plotly.js charts in .NET programming languages.\n* [PyCEbox](https://github.com/AustinRochford/PyCEbox) ![](https://img.shields.io/github/stars/AustinRochford/PyCEbox.svg?style=social) - Python Individual Conditional Expectation Plot Toolbox.\n* [pygal](https://github.com/Kozea/pygal) ![](https://img.shields.io/github/stars/Kozea/pygal.svg?style=social) - pygal is a dynamic SVG charting library written in Python.\n* [Redash](https://github.com/getredash/redash) ![](https://img.shields.io/github/stars/getredash/redash.svg?style=social) - Redash is anopen source visualisation framework that is built to allow easy access to big datasets leveraging multiple backends.\n* [seaborn](https://github.com/mwaskom/seaborn) ![](https://img.shields.io/github/stars/mwaskom/seaborn.svg?style=social) - Seaborn is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.\n* [Streamlit](https://github.com/streamlit/streamlit) ![](https://img.shields.io/github/stars/streamlit/streamlit.svg?style=social) - Streamlit lets you create apps for your machine learning projects with deceptively simple Python scripts. It supports hot-reloading, so your app updates live as you edit and save your file.\n* [Superset](https://github.com/apache/superset) ![](https://img.shields.io/github/stars/apache/superset.svg?style=social) - A modern, enterprise-ready business intelligence web application.\n* [TensorBoard](https://github.com/tensorflow/tensorboard) ![](https://img.shields.io/github/stars/tensorflow/tensorboard.svg?style=social) - A visualization toolkit for machine learning experimentation that makes it easy to host, track, and share ML experiments.\n* [yellowbrick](https://github.com/DistrictDataLabs/yellowbrick) ![](https://img.shields.io/github/stars/DistrictDataLabs/yellowbrick.svg?style=social) - yellowbrick is a matplotlib-based model evaluation plots for scikit-learn and other machine learning libraries.\n\n\n## Industrial Strength NLP\n* [AdaptNLP](https://github.com/Novetta/adaptnlp) ![](https://img.shields.io/github/stars/Novetta/adaptnlp.svg?style=social) - Built atop Zalando Research's Flair and Hugging Face's Transformers library, AdaptNLP provides Machine Learning Researchers and Scientists a modular and adaptive approach to a variety of NLP tasks with an Easy API for training, inference, and deploying NLP-based microservices.\n* [Blackstone](https://github.com/ICLRandD/Blackstone) ![](https://img.shields.io/github/stars/ICLRandD/Blackstone.svg?style=social) - Blackstone is a spaCy model and library for processing long-form, unstructured legal text. Blackstone is an experimental research project from the Incorporated Council of Law Reporting for England and Wales' research lab, ICLR&D.\n* [CTRL](https://github.com/salesforce/ctrl) ![](https://img.shields.io/github/stars/salesforce/ctrl.svg?style=social) - A Conditional Transformer Language Model for Controllable Generation released by SalesForce.\n* [Facebook's XLM](https://github.com/facebookresearch/XLM) ![](https://img.shields.io/github/stars/facebookresearch/XLM.svg?style=social) - PyTorch original implementation of Cross-lingual Language Model Pretraining which includes BERT, XLM, NMT, XNLI, PKM, etc..\n* [Flair](https://github.com/zalandoresearch/flair) ![](https://img.shields.io/github/stars/zalandoresearch/flair.svg?style=social) - Simple framework for state-of-the-art NLP developed by Zalando which builds directly on PyTorch.\n* [Github's Semantic](https://github.com/github/semantic) ![](https://img.shields.io/github/stars/github/semantic.svg?style=social) - Github's text library for parsing, analyzing, and comparing source code across many languages .\n* [GluonNLP](https://github.com/dmlc/gluon-nlp) ![](https://img.shields.io/github/stars/dmlc/gluon-nlp.svg?style=social) - GluonNLP is a toolkit that enables easy text preprocessing, datasets loading and neural models building to help you speed up your Natural Language Processing (NLP) research.\n* [Grover](https://github.com/rowanz/grover) ![](https://img.shields.io/github/stars/rowanz/grover.svg?style=social) - Grover is a model for Neural Fake News -- both generation and detection. However, it probably can also be used for other generation tasks.\n* [Kashgari](https://github.com/BrikerMan/Kashgari) ![](https://img.shields.io/github/stars/BrikerMan/Kashgari.svg?style=social) - Kashgari is a simple and powerful NLP Transfer learning framework, build a state-of-art model in 5 minutes for named entity recognition (NER), part-of-speech tagging (PoS), and text classification tasks.\n* [OpenAI GPT-2](https://github.com/openai/gpt-2) ![](https://img.shields.io/github/stars/openai/gpt-2.svg?style=social) - OpenAI's code from their paper [\"Language Models are Unsupervised Multitask Learners\"](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf).\n* [sense2vec](https://github.com/explosion/sense2vec) ![](https://img.shields.io/github/stars/explosion/sense2vec.svg?style=social) - A Pytorch library that allows for training and using sense2vec models, which are models that leverage the same approach than word2vec, but also leverage part-of-speech attributes for each token, which allows it to be \"meaning-aware\".\n* [Snorkel](https://github.com/snorkel-team/snorkel) ![](https://img.shields.io/github/stars/snorkel-team/snorkel.svg?style=social) - Snorkel is a system for quickly generating training data with weak supervision.\n* [SpaCy](https://github.com/explosion/spaCy) ![](https://img.shields.io/github/stars/explosion/spaCy.svg?style=social) - Industrial-strength natural language processing library built with python and cython by the explosion.ai team.\n* [Stable Baselines](https://github.com/DLR-RM/stable-baselines3) ![](https://img.shields.io/github/stars/DLR-RM/stable-baselines3.svg?style=social) - A fork of OpenAI Baselines, implementations of reinforcement learning algorithms.\n* [Tensorflow Lingvo](https://github.com/tensorflow/lingvo) ![](https://img.shields.io/github/stars/tensorflow/lingvo.svg?style=social) - A [framework](https://blog.tensorflow.org/2019/02/lingvo-tensorflow-framework-for-sequence-modeling.html) for building neural networks in Tensorflow, particularly sequence models.\n* [Tensorflow Text](https://github.com/tensorflow/text) ![](https://img.shields.io/github/stars/tensorflow/text.svg?style=social) - TensorFlow Text provides a collection of text related classes and ops ready to use with TensorFlow 2.0.\n* [YouTokenToMe](https://github.com/vkcom/youtokentome) ![](https://img.shields.io/github/stars/vkcom/youtokentome.svg?style=social) - YouTokenToMe is an unsupervised text tokenizer focused on computational efficiency. It currently implements fast [Byte Pair Encoding](https://arxiv.org/abs/1508.07909) (BPE).\n* [Transformers](https://github.com/huggingface/transformers) ![](https://img.shields.io/github/stars/huggingface/transformers.svg?style=social) - Huggingface's library of state-of-the-art pretrained models for Natural Language Processing (NLP).\n\n\n## Data Pipeline\n* [Apache Airflow](https://github.com/apache/airflow) ![](https://img.shields.io/github/stars/apache/airflow.svg?style=social) - Data Pipeline framework built in Python, including scheduler, DAG definition and a UI for visualisation.\n* [Apache Nifi](https://github.com/apache/nifi) ![](https://img.shields.io/github/stars/apache/nifi.svg?style=social) - Apache NiFi was made for dataflow. It supports highly configurable directed graphs of data routing, transformation, and system mediation logic.\n* [Argo Workflows](https://github.com/argoproj/argo-workflows) ![](https://img.shields.io/github/stars/argoproj/argo-workflows.svg?style=social) - Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. Argo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition).\n* [Azkaban](https://github.com/azkaban/azkaban) ![](https://img.shields.io/github/stars/azkaban/azkaban.svg?style=social) - Azkaban is a batch workflow job scheduler created at LinkedIn to run Hadoop jobs. Azkaban resolves the ordering through job dependencies and provides an easy to use web user interface to maintain and track your workflows.\n* [Basin](https://github.com/basin-etl/basin) ![](https://img.shields.io/github/stars/basin-etl/basin.svg?style=social) - Visual programming editor for building Spark and PySpark pipelines.\n* [Bonobo](https://github.com/python-bonobo/bonobo) ![](https://img.shields.io/github/stars/python-bonobo/bonobo.svg?style=social) - ETL framework for Python 3.5+ with focus on simple atomic operations working concurrently on rows of data.\n* [Chronos](https://github.com/mesos/chronos) ![](https://img.shields.io/github/stars/mesos/chronos.svg?style=social) - More of a job scheduler for Mesos than ETL pipeline.\n* [Couler](https://github.com/couler-proj/couler) ![](https://img.shields.io/github/stars/couler-proj/couler.svg?style=social) - Unified interface for constructing and managing machine learning workflows on different workflow engines, such as Argo Workflows, Tekton Pipelines, and Apache Airflow.\n* [Dagster](https://github.com/dagster-io/dagster) ![](https://img.shields.io/github/stars/dagster-io/dagster.svg?style=social) - A data orchestrator for machine learning, analytics, and ETL.\n* [DBND](https://github.com/databand-ai/dbnd) ![](https://img.shields.io/github/stars/databand-ai/dbnd.svg?style=social) - DBND is an agile pipeline framework that helps data engineering teams track and orchestrate their data processes.\n* [DBT](https://github.com/dbt-labs/dbt-core) ![](https://img.shields.io/github/stars/dbt-labs/dbt-core.svg?style=social) - ETL tool for running transformations inside data warehouses.\n* [Flyte](https://github.com/flyteorg/flyte) ![](https://img.shields.io/github/stars/lyft/flyte.svg?style=social) - Lyft\u2019s Cloud Native Machine Learning and Data Processing Platform - [(Demo)](https://youtu.be/KdUJGSP1h9U?t=1451).\n* [Genie](https://github.com/Netflix/genie) ![](https://img.shields.io/github/stars/Netflix/genie.svg?style=social) - Job orchestration engine to interface and trigger the execution of jobs from Hadoop-based systems.\n* [Gokart](https://github.com/m3dev/gokart) ![](https://img.shields.io/github/stars/m3dev/gokart.svg?style=social) - Wrapper of the data pipeline Luigi.\n* [Kedro](https://github.com/quantumblacklabs/kedro/) ![](https://img.shields.io/github/stars/quantumblacklabs/kedro.svg?style=social) - Kedro is a workflow development tool that helps you build data pipelines that are robust, scalable, deployable, reproducible and versioned. Visualization of the kedro workflows can be done by [`kedro-viz`](https://github.com/quantumblacklabs/kedro-viz).\n* [Luigi](https://github.com/spotify/luigi) ![](https://img.shields.io/github/stars/spotify/luigi.svg?style=social) - Luigi is a Python module that helps you build complex pipelines of batch jobs, handling dependency resolution, workflow management, visualisation, etc..\n* [Metaflow](https://github.com/Netflix/metaflow/) ![](https://img.shields.io/github/stars/netflix/metaflow.svg?style=social) - A framework for data scientists to easily build and manage real-life data science projects.\n* [Neuraxle](https://github.com/Neuraxio/Neuraxle) ![](https://img.shields.io/github/stars/Neuraxio/Neuraxle.svg?style=social) - A framework for building neat pipelines, providing the right abstractions to chain your data transformation and prediction steps with data streaming, as well as doing hyperparameter searches (AutoML).\n* [Oozie](https://github.com/apache/oozie) ![](https://img.shields.io/github/stars/apache/oozie.svg?style=social) - Workflow scheduler for Hadoop jobs.\n* [PipelineX](https://github.com/Minyus/pipelinex) ![](https://img.shields.io/github/stars/Minyus/pipelinex.svg?style=social) - Based on Kedro and MLflow. Full comparison is found [here](https://github.com/Minyus/Python_Packages_for_Pipeline_Workflow).\n* [Prefect Core](https://github.com/PrefectHQ/prefect) ![](https://img.shields.io/github/stars/PrefectHQ/prefect.svg?style=social) - Workflow management system that makes it easy to take your data pipelines and add semantics like retries, logging, dynamic mapping, caching, failure notifications, and more.\n* [SETL](https://github.com/SETL-Developers/setl) ![](https://img.shields.io/github/stars/SETL-Developers/setl.svg?style=social) - A simple Spark-powered ETL framework that helps you structure your ETL projects, modularize your data transformation logic and speed up your development.\n* [Snakemake](https://github.com/snakemake/snakemake) ![](https://img.shields.io/github/stars/snakemake/snakemake.svg?style=social) - Workflow management system for reproducible and scalable data analyses.\n* [Towhee](https://github.com/towhee-io/towhee) ![](https://img.shields.io/github/stars/towhee-io/towhee.svg?style=social) - General-purpose machine learning pipeline for generating embedding vectors using one or many ML models.\n\n\n## Data Labelling\n* [brat rapid annotation tool](https://github.com/nlplab/brat) ![](https://img.shields.io/github/stars/nlplab/brat.svg?style=social) - Web-based text annotation tool for Named-Entity-Recogntion task.\n* [COCO Annotator](https://github.com/jsbroks/coco-annotator) ![](https://img.shields.io/github/stars/jsbroks/coco-annotator.svg?style=social) - Web-based image segmentation tool for object detection, localization and keypoints\n* [Computer Vision Annotation Tool (CVAT)](https://github.com/opencv/cvat) ![](https://img.shields.io/github/stars/opencv/cvat.svg?style=social) - OpenCV's web-based annotation tool for both VIDEOS and images for computer algorithms.\n* [Doccano](https://github.com/chakki-works/doccano) ![](https://img.shields.io/github/stars/chakki-works/doccano.svg?style=social) - Open source text annotation tools for humans, providing functionality for sentiment analysis, named entity recognition, and machine translation.\n* [ImageTagger](https://github.com/bit-bots/imagetagger) ![](https://img.shields.io/github/stars/bit-bots/imagetagger.svg?style=social) - Image labelling tool with support for collaboration, supporting bounding box, polygon, line, point labelling, label export, etc.\n* [ImgLab](https://github.com/NaturalIntelligence/imglab) ![](https://img.shields.io/github/stars/NaturalIntelligence/imglab.svg?style=social) - Image annotation tool for bounding boxes with auto-suggestion and extensibility for plugins.\n* [Label Studio](https://github.com/heartexlabs/label-studio) ![](https://img.shields.io/github/stars/heartexlabs/label-studio.svg?style=social) - Multi-domain data labeling and annotation tool with standardized output format.\n* [Labelimg](https://github.com/tzutalin/labelImg) ![](https://img.shields.io/github/stars/tzutalin/labelImg.svg?style=social) - Open source graphical image annotation tool writen in Python using QT for graphical interface focusing primarily on bounding boxes.\n* [makesense.ai](https://github.com/SkalskiP/make-sense) ![](https://img.shields.io/github/stars/SkalskiP/make-sense.svg?style=social) - Free to use online tool for labelling photos. Prepared labels can be downloaded in one of multiple supported formats.\n* [MedTagger](https://github.com/medtagger/MedTagger) ![](https://img.shields.io/github/stars/medtagger/MedTagger.svg?style=social) - A collaborative framework for annotating medical datasets using crowdsourcing.\n* [OpenLabeling](https://github.com/Cartucho/OpenLabeling) ![](https://img.shields.io/github/stars/Cartucho/OpenLabeling.svg?style=social) - Open source tool for labelling images with support for labels, edges, as well as image resizing and zooming in.\n* [PixelAnnotationTool](https://github.com/abreheret/PixelAnnotationTool) ![](https://img.shields.io/github/stars/abreheret/PixelAnnotationTool.svg?style=social) - Image annotation tool with ability to \"colour\" on the images to select labels for segmentation. Process is semi-automated with the [watershed marked algorithm of OpenCV](docs.opencv.org/3.1.0/d7/d1b/group__imgproc__misc.html#ga3267243e4d3f95165d55a618c65ac6e1)\n* [Rubrix](https://github.com/recognai/rubrix) ![](https://img.shields.io/github/stars/recognai/rubrix.svg?style=social) - Open-source tool for tracking, exploring, and labeling data for AI projects.\n* [Semantic Segmentation Editor](https://github.com/Hitachi-Automotive-And-Industry-Lab/semantic-segmentation-editor) ![](https://img.shields.io/github/stars/Hitachi-Automotive-And-Industry-Lab/semantic-segmentation-editor.svg?style=social) - Hitachi's Open source tool for labelling camera and LIDAR data.\n* [Superintendent](https://github.com/janfreyberg/superintendent) ![](https://img.shields.io/github/stars/janfreyberg/superintendent.svg?style=social) - superintendent provides an ipywidget-based interactive labelling tool for your data.\n* [VGG Image Annotator (VIA)](http://www.robots.ox.ac.uk/~vgg/software/via/) - A simple and standalone manual annotation software for image, audio and video. VIA runs in a web browser and does not require any installation or setup.\n\n\n## Metadata Management\n* [Amundsen](https://github.com/amundsen-io/amundsen) ![](https://img.shields.io/github/stars/amundsen-io/amundsen.svg?style=social) - Amundsen is a metadata driven application for improving the productivity of data analysts, data scientists and engineers when interacting with data.\n* [ArangoML Pipeline](https://github.com/arangoml/arangopipe) ![](https://img.shields.io/github/stars/arangoml/arangopipe.svg?style=social) - ArangoML Pipeline is a common and extensible Metadata Layer for Machine Learning Pipelines which allows Data Scientists and DataOps to manage all information related to their ML pipeline in one place.\n* [Apache Atlas](https://github.com/apache/atlas) ![](https://img.shields.io/github/stars/apache/atlas.svg?style=social) - Apache Atlas framework is an extensible set of core foundational governance services \u2013 enabling enterprises to effectively and efficiently meet their compliance requirements within Hadoop and allows integration with the whole enterprise data ecosystem.\n* [DataHub](https://github.com/linkedin/datahub) ![](https://img.shields.io/github/stars/linkedin/datahub.svg?style=social) - DataHub is LinkedIn's generalized metadata search & discovery tool.\n* [Marquez](https://github.com/MarquezProject/marquez) ![](https://img.shields.io/github/stars/MarquezProject/marquez.svg?style=social) - Marquez is an open source metadata service for the collection, aggregation, and visualization of a data ecosystem's metadata.\n* [Metacat](https://github.com/Netflix/metacat) ![](https://img.shields.io/github/stars/Netflix/metacat.svg?style=social) - Metacat is a unified metadata exploration API service. Metacat focusses on solving these problems: 1) federated views of metadata systems; 2) arbitrary metadata storage about data sets; 3) metadata discovery.\n* [ML Metadata](https://github.com/google/ml-metadata) ![](https://img.shields.io/github/stars/google/ml-metadata.svg?style=social) - a library for recording and retrieving metadata associated with ML developer and data scientist workflows.\n* [Model Card Toolkit](https://github.com/tensorflow/model-card-toolkit) ![](https://img.shields.io/github/stars/tensorflow/model-card-toolkit.svg?style=social) - streamlines and automates generation of [Model Cards](https://modelcards.withgoogle.com/about).\n\n\n## Data Storage Optimisation\n* [Alluxio](https://github.com/Alluxio/alluxio) ![](https://img.shields.io/github/stars/Alluxio/alluxio.svg?style=social) - A virtual distributed storage system that bridges the gab between computation frameworks and storage systems.\n* [Apache Arrow](https://github.com/apache/arrow/) ![](https://img.shields.io/github/stars/apache/arrow.svg?style=social) - In-memory columnar representation of data compatible with Pandas, Hadoop-based systems, etc..\n* [Apache Druid](https://github.com/apache/druid) ![](https://img.shields.io/github/stars/apache/druid.svg?style=social) - A high performance real-time analytics database. Check this [article](https://towardsdatascience.com/introduction-to-druid-4bf285b92b5a) for introduction.\n* [Apache Ignite](https://github.com/apache/ignite) ![](https://img.shields.io/github/stars/apache/ignite.svg?style=social) - A memory-centric distributed database, caching, and processing platform for transactional, analytical, and streaming workloads delivering in-memory speeds at petabyte scale - [Demo](https://www.youtube.com/watch?v=Xt4PWQ__YPw).\n* [Apache Parquet](https://github.com/apache/parquet-mr/) ![](https://img.shields.io/github/stars/apache/parquet-mr.svg?style=social) - On-disk columnar representation of data compatible with Pandas, Hadoop-based systems, etc..\n* [Apache Pinot](https://github.com/apache/incubator-pinot) ![](https://img.shields.io/github/stars/apache/incubator-pinot.svg?style=social) - A realtime distributed OLAP datastore. Comparison of the open source OLAP systems for big data: ClickHouse, Druid, and Pinot is found [here](https://medium.com/@leventov/comparison-of-the-open-source-olap-systems-for-big-data-clickhouse-druid-and-pinot-8e042a5ed1c7).\n* [BayesDB](https://github.com/probcomp/bayeslite) ![](https://img.shields.io/github/stars/probcomp/bayeslite.svg?style=social) - A Bayesian database table for querying the probable implications of data as easily as SQL databases query the data itself. - [(Video)](https://www.youtube.com/watch?v=2ws84s6iD1o)\n* [ClickHouse](https://github.com/ClickHouse/ClickHouse) ![](https://img.shields.io/github/stars/ClickHouse/ClickHouse.svg?style=social) - ClickHouse is an open source column oriented database management system.\n* [Delta Lake](https://github.com/delta-io/delta) ![](https://img.shields.io/github/stars/delta-io/delta.svg?style=social) - Delta Lake is a storage layer that brings scalable, ACID transactions to Apache Spark and other big-data engines.\n* [EdgeDB](https://github.com/edgedb/edgedb) ![](https://img.shields.io/github/stars/edgedb/edgedb.svg?style=social) - NoSQL interface for Postgres that allows for object interaction to data stored.\n* [HopsFS](https://github.com/hopshadoop/hops) ![](https://img.shields.io/github/stars/hopshadoop/hops.svg?style=social) - HDFS-compatible file system with scale-out strongly consistent metadata.\n* [InfluxDB](https://github.com/influxdata/influxdb) ![](https://img.shields.io/github/stars/influxdata/influxdb.svg?style=social) Scalable datastore for metrics, events, and real-time analytics.\n* [Milvus](https://github.com/milvus-io/milvus) ![](https://img.shields.io/github/stars/milvus-io/milvus.svg?style=social) Milvus is a cloud-native, open-source vector database built to manage embedding vectors generated by machine learning models and neural networks.\n* [Qdrant](https://github.com/qdrant/qdrant) ![](https://img.shields.io/github/stars/qdrant/qdrant.svg?style=social) - An open source vector similarity search engine with extended filtering support.\n* [TimescaleDB](https://github.com/timescale/timescaledb) ![](https://img.shields.io/github/stars/timescale/timescaledb.svg?style=social) An open-source time-series SQL database optimized for fast ingest and complex queries packaged as a PostgreSQL extension - [(Video)](www.youtube.com/watch?v=zbjub8BQPyE).\n* [Weaviate](https://github.com/semi-technologies/weaviate) ![](https://img.shields.io/github/stars/semi-technologies/weaviate.svg?style=social) - A low-latency vector search engine (GraphQL, RESTful) with out-of-the-box support for different media types. Modules include Semantic Search, Q&A, Classification, Customizable Models (PyTorch/TensorFlow/Keras), and more.\n* [Zarr](https://github.com/zarr-developers/zarr-python) ![](https://img.shields.io/github/stars/zarr-developers/zarr-python.svg?style=social) - Python implementation of chunked, compressed, N-dimensional arrays designed for use in parallel computing.\n\n\n## Function as a Service\n* [Apache OpenWhisk](https://github.com/apache/incubator-openwhisk) ![](https://img.shields.io/github/stars/apache/incubator-openwhisk.svg?style=social) - Open source, distributed serverless platform that executes functions in response to events at any scale.\n* [Fission](https://github.com/fission/fission) ![](https://img.shields.io/github/stars/fission/fission.svg?style=social) - (Early Alpha) Serverless functions as a service framework on Kubernetes.\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) ![](https://img.shields.io/github/stars/Hydrospheredata/mist.svg?style=social) - Serverless proxy for Apache Spark clusters.\n* [Hydrosphere ML Lambda](https://github.com/Hydrospheredata/hydro-serving) ![](https://img.shields.io/github/stars/Hydrospheredata/hydro-serving.svg?style=social) - Open source model management cluster for deploying, serving and monitoring machine learning models and ad-hoc algorithms with a FaaS architecture.\n* [KNative Serving](https://github.com/knative/serving) ![](https://img.shields.io/github/stars/knative/serving.svg?style=social) - Kubernetes based serverless microservices with \"scale-to-zero\" functionality.\n* [Nuclio](https://github.com/nuclio/nuclio) ![](https://img.shields.io/github/stars/nuclio/nuclio.svg?style=social) - A high-performance \"serverless\" framework focused on data, I/O, and compute intensive workloads. It is well integrated with popular data science tools, such as Jupyter and Kubeflow; supports a variety of data and streaming sources; and supports execution over CPUs and GPUs.\n* [OpenFaaS](https://github.com/openfaas/faas) ![](https://img.shields.io/github/stars/openfaas/faas.svg?style=social) - Serverless functions framework with RESTful API on Kubernetes\n\n\n## Computation Load Distribution\n* [Analytics Zoo](https://github.com/intel-analytics/analytics-zoo/) ![](https://img.shields.io/github/stars/intel-analytics/analytics-zoo.svg?style=social) - A unified Data Analytics and AI platform for distributed TensorFlow, Keras and PyTorch on Apache Spark/Flink & Ray.\n* [Apache Spark MLlib](https://spark.apache.org/mllib/) - Apache Spark's scalable machine learning library in Java, Scala, Python and R.\n* [Bagua](https://github.com/BaguaSys/bagua) ![](https://img.shields.io/github/stars/BaguaSys/bagua.svg?style=social) - Bagua is a performant and flexible distributed training framework for PyTorch, providing a faster alternative to PyTorch DDP and Horovod. It supports advanced distributed training algorithms such as quantization and decentralization.\n* [Beam](https://github.com/apache/beam) ![](https://img.shields.io/github/stars/apache/beam.svg?style=social) Apache Beam is a unified programming model for Batch and Streaming.\n* [BigDL](https://github.com/intel-analytics/BigDL) ![](https://img.shields.io/github/stars/intel-analytics/BigDL.svg?style=social) - Deep learning framework on top of Spark/Hadoop to distribute data and computations across a HDFS system.\n* [Colossal-AI](https://github.com/hpcaitech/ColossalAI) ![](https://img.shields.io/github/stars/hpcaitech/ColossalAI.svg?style=social) - A unified deep learning system for big model era, which helps users to efficiently and quickly deploy large AI model training and inference.\n* [Dask](https://github.com/dask/dask) ![](https://img.shields.io/github/stars/dask/dask.svg?style=social) - Distributed parallel processing framework for Pandas and NumPy computations - [(Video)](https://www.youtube.com/watch?v=RA_2qdipVng).\n* [DEAP](https://github.com/DEAP/deap) ![](https://img.shields.io/github/stars/DEAP/deap.svg?style=social) - A novel evolutionary computation framework for rapid prototyping and testing of ideas. It seeks to make algorithms explicit and data structures transparent. It works in perfect harmony with parallelisation mechanisms such as multiprocessing and SCOOP.\n* [DeepSpeed](https://github.com/microsoft/DeepSpeed) ![](https://img.shields.io/github/stars/microsoft/deepspeed.svg?style=social) - A deep learning optimization library (lightweight PyTorch wrapper) that makes distributed training easy, efficient, and effective.\n* [Fiber](https://github.com/uber/fiber) ![](https://img.shields.io/github/stars/uber/fiber.svg?style=social) - Distributed computing library for modern computer clusters from Uber.\n* [Flashlight](https://github.com/flashlight/flashlight) ![](https://img.shields.io/github/stars/flashlight/flashlight.svg?style=social) - A fast, flexible machine learning library written entirely in C++ from the Facebook AI Research and the creators of Torch, TensorFlow, Eigen and Deep Speech.\n* [Hivemind](https://github.com/learning-at-home/hivemind) ![](https://img.shields.io/github/stars/learning-at-home/hivemind.svg?style=social) - Decentralized deep learning in PyTorch.\n* [Horovod](https://github.com/uber/horovod) ![](https://img.shields.io/github/stars/uber/horovod.svg?style=social) - Uber's distributed training framework for TensorFlow, Keras, and PyTorch.\n* [NumPyWren](https://github.com/Vaishaal/numpywren) ![](https://img.shields.io/github/stars/Vaishaal/numpywren.svg?style=social) - Scientific computing framework build on top of pywren to enable numpy-like distributed computations.\n* [PyWren](https://github.com/pywren/pywren) ![](https://img.shields.io/github/stars/pywren/pywren.svg?style=social) - Answer the question of the \"cloud button\" for python function execution. It's a framework that abstracts AWS Lambda to enable data scientists to execute any Python function - [(Video)](https://www.youtube.com/watch?v=OskQytBBdJU).\n* [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning) ![](https://img.shields.io/github/stars/PyTorchLightning/pytorch-lightning.svg?style=social) - Lightweight PyTorch research framework that allows you to easily scale your models to GPUs and TPUs and use all the latest best practices, without the engineering boilerplate - [(Video)](https://www.youtube.com/watch?v=QHww1JH7IDU&t=678s).\n* [Ray](https://github.com/ray-project/ray) ![](https://img.shields.io/github/stars/ray-project/ray.svg?style=social) - Ray is a flexible, high-performance distributed execution framework for machine learning ([VIDEO](https://www.youtube.com/watch?v=D_oz7E4v-U0)).\n* [TensorFlowOnSpark](https://github.com/yahoo/TensorFlowOnSpark) ![](https://img.shields.io/github/stars/yahoo/TensorFlowOnSpark.svg?style=social) - TensorFlowOnSpark brings TensorFlow programs to Apache Spark clusters.\n* [Vespa](https://github.com/vespa-engine/vespa) ![](https://img.shields.io/github/stars/vespa-engine/vespa.svg?style=social) Vespa is an engine for low-latency computation over large data sets.\n\n\n## Model Serialisation\n* [Java PMML API](https://github.com/jpmml) - Java libraries for consuming and producing PMML files containing models from different frameworks, including:\n    * [pyspark2pmml](https://github.com/jpmml/pyspark2pmml) ![](https://img.shields.io/github/stars/jpmml/pyspark2pmml.svg?style=social)\n    * [r2pmml](https://github.com/jpmml/r2pmml) ![](https://img.shields.io/github/stars/jpmml/r2pmml.svg?style=social)\n    * [sklearn2pmml](https://github.com/jpmml/jpmml-sklearn) ![](https://img.shields.io/github/stars/jpmml/jpmml-sklearn.svg?style=social)\n    * [sparklyr2pmml](https://github.com/jpmml/sparklyr2pmml) ![](https://img.shields.io/github/stars/jpmml/sparklyr2pmml.svg?style=social)\n* [MMdnn](https://github.com/Microsoft/MMdnn) ![](https://img.shields.io/github/stars/Microsoft/MMdnn.svg?style=social) - Cross-framework solution to convert, visualize and diagnose deep neural network models.\n* [Neural Network Exchange Format (NNEF)](https://www.khronos.org/nnef) - A standard format to store models across Torch, Caffe, TensorFlow, Theano, Chainer, Caffe2, PyTorch, and MXNet.\n* [ONNX](https://github.com/onnx/onnx) ![](https://img.shields.io/github/stars/onnx/onnx.svg?style=social) - Open Neural Network Exchange Format.\n* [PFA](https://dmg.org/pfa/) - Created by the same organisation as PMML, the Predicted Format for Analytics is an emerging standard for statistical models and data transformation engines.\n* [PMML](https://dmg.org/pmml/) - The Predictive Model Markup Language standard in XML - [(Video)](https://www.youtube.com/watch?v=_5pZm2PZ8Q8).\n\n\n## Optimized Computation\n* [CuDF](https://github.com/rapidsai/cudf) ![](https://img.shields.io/github/stars/rapidsai/cudf.svg?style=social) - Built based on the Apache Arrow columnar memory format, cuDF is a GPU DataFrame library for loading, joining, aggregating, filtering, and otherwise manipulating data.\n* [CuML](https://github.com/rapidsai/cuml) ![](https://img.shields.io/github/stars/rapidsai/cuml.svg?style=social) - cuML is a suite of libraries that implement machine learning algorithms and mathematical primitives functions that share compatible APIs with other RAPIDS projects.\n* [CuPy](https://github.com/cupy/cupy) ![](https://img.shields.io/github/stars/cupy/cupy.svg?style=social) - An implementation of NumPy-compatible multi-dimensional array on CUDA. CuPy consists of the core multi-dimensional array class, cupy.ndarray, and many functions on it.\n* [H2O-3](https://github.com/h2oai/h2o-3) ![](https://img.shields.io/github/stars/h2oai/h2o-3.svg?style=social) - Fast scalable Machine Learning platform for smarter applications: Deep Learning, Gradient Boosting & XGBoost, Random Forest, Generalized Linear Modeling (Logistic Regression, Elastic Net), K-Means, PCA, Stacked Ensembles, Automatic Machine Learning (AutoML), etc..\n* [Jax](https://github.com/google/jax) ![](https://img.shields.io/github/stars/google/jax.svg?style=social) - Composable transformations of Python+NumPy programs: differentiate, vectorize, JIT to GPU/TPU, and more.\n* [Modin](https://github.com/modin-project/modin) ![](https://img.shields.io/github/stars/modin-project/modin.svg?style=social) - Speed up your Pandas workflows by changing a single line of code.\n* [Nebullvm](https://github.com/nebuly-ai/nebullvm) ![](https://img.shields.io/github/stars/nebuly-ai/nebullvm.svg?style=social) - Easy-to-use library to boost AI inference leveraging multiple deep learning compilers.\n* [Numba](https://github.com/numba/numba) ![](https://img.shields.io/github/stars/numba/numba.svg?style=social)  - A compiler for Python array and numerical functions.\n* [NumpyGroupies](https://github.com/ml31415/numpy-groupies) ![](https://img.shields.io/github/stars/ml31415/numpy-groupies.svg?style=social) Optimised tools for group-indexing operations: aggregated sum and more\n* [OpenVINO\u2122 integration with TensorFlow](https://github.com/openvinotoolkit/openvino_tensorflow) ![](https://img.shields.io/github/stars/openvinotoolkit/openvino_tensorflow.svg?style=social) - Highly optimized Neural Network inference with Tensorflow on Intel platforms by adding a single line of code.\n* [Vaex](https://github.com/vaexio/vaex) ![](https://img.shields.io/github/stars/vaexio/vaex.svg?style=social) Vaex is a high performance Python library for lazy Out-of-Core DataFrames (similar to Pandas), to visualize and explore big tabular datasets. Vaex uses memory mapping, zero memory copy policy and lazy computations for best performance (no memory wasted).\n* [Vulkan Kompute](https://github.com/axsaucedo/vulkan-kompute/) ![](https://img.shields.io/github/stars/axsaucedo/vulkan-kompute.svg?style=social) - Blazing fast, lightweight and mobile phone-enabled Vulkan compute framework optimized for advanced GPU data processing usecases.\n* [Weld](https://github.com/weld-project/weld) ![](https://img.shields.io/github/stars/weld-project/weld.svg?style=social) High-performance runtime for data analytics applications, Here is an [interview](https://www.notamonadtutorial.com/weld-accelerating-numpy-scikit-and-pandas-as-much-as-100x-with-rust-and-llvm/) with Weld\u2019s main contributor.\n\n\n## Data Stream Processing\n* [Apache Flink](https://github.com/apache/flink) ![](https://img.shields.io/github/stars/apache/flink.svg?style=social) - Open source stream processing framework with powerful stream and batch processing capabilities.\n* [Apache Samza](https://github.com/apache/samza) ![](https://img.shields.io/github/stars/apache/samza.svg?style=social) - Distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management.\n* [Brooklin](https://github.com/linkedin/Brooklin/) ![](https://img.shields.io/github/stars/linkedin/Brooklin.svg?style=social) - Distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management.\n* [Faust](https://github.com/robinhood/faust) ![](https://img.shields.io/github/stars/robinhood/faust.svg?style=social) - Streaming library built on top of Python's Asyncio library using the async kafka client inspired by the kafka streaming library.\n* [Apache Spark](https://spark.apache.org/streaming/) ![](https://img.shields.io/github/stars/apache/spark.svg?style=social) - Micro-batch processing for streams using the apache spark framework as a backend supporting stateful exactly-once semantics.\n* [Apache Kafka](https://github.com/apache/kafka) ![](https://img.shields.io/github/stars/apache/kafka.svg?style=social) - Kafka client library for buliding applications and microservices where the input and output are stored in kafka clusters.\n\n\n## Outlier and Anomaly Detection\n* [adtk](https://github.com/arundo/adtk) ![](https://img.shields.io/github/stars/arundo/adtk.svg?style=social)  - A Python toolkit for rule-based/unsupervised anomaly detection in time series.\n* [Alibi-Detect](https://github.com/SeldonIO/alibi-detect) ![](https://img.shields.io/github/stars/seldonio/alibi-detect.svg?style=social) - Algorithms for outlier and adversarial instance detection, concept drift and metrics.\n* [dBoost](https://github.com/cpitclaudel/dBoost) ![](https://img.shields.io/github/stars/cpitclaudel/dBoost.svg?style=social) - Outlier detection in heterogeneous datasets using automatic tuple expansion. Check this [paper](https://core.ac.uk/download/pdf/78067844.pdf) for further details.\n* [Deequ](https://github.com/awslabs/deequ) ![](https://img.shields.io/github/stars/awslabs/deequ.svg?style=social) - A library built on top of Apache Spark for defining \"unit tests for data\", which measure data quality in large datasets.\n* [Deep Anomaly Detection with Outlier Exposure](https://github.com/hendrycks/outlier-exposure) ![](https://img.shields.io/github/stars/hendrycks/outlier-exposure.svg?style=social) - Outlier Exposure (OE) is a method for improving anomaly detection performance in deep learning models. [Paper](https://arxiv.org/pdf/1812.04606.pdf)\n* [PyOD](https://github.com/yzhao062/pyod) ![](https://img.shields.io/github/stars/yzhao062/pyod.svg?style=social) - A Python Toolbox for Scalable Outlier Detection (Anomaly Detection).\n* [SUOD (Scalable Unsupervised Outlier Detection)](https://github.com/yzhao062/SUOD) ![](https://img.shields.io/github/stars/yzhao062/SUOD.svg?style=social) - An Acceleration System for Large-scale Anomaly/Outlier Detection.\n* [Tensorflow Data Validation (TFDV)](https://github.com/tensorflow/data-validation) ![](https://img.shields.io/github/stars/tensorflow/data-validation.svg?style=social) - Library for exploring and validating machine learning data.\n\n\n## Feature Engineering\n* [auto-sklearn](https://github.com/automl/auto-sklearn) ![](https://img.shields.io/github/stars/automl/auto-sklearn.svg?style=social) - Framework to automate algorithm and hyperparameter tuning for sklearn.\n* [AutoGluon](https://github.com/awslabs/autogluon) ![](https://img.shields.io/github/stars/awslabs/autogluon.svg?style=social) - Automated feature, model, and hyperparameter selection for tabular, image, and text data on top of popular machine learning libraries (Scikit-Learn, LightGBM, CatBoost, PyTorch, MXNet).\n* [AutoML-GS](https://github.com/minimaxir/automl-gs) ![](https://img.shields.io/github/stars/blue-yonder/tsfresh.svg?style=social) - Automatic feature and model search with code generation in Python, on top of common data science libraries (tensorflow, sklearn, etc.).\n* [automl](https://github.com/ClimbsRocks/auto_ml) ![](https://img.shields.io/github/stars/ClimbsRocks/auto_ml?style=social)  - Automated feature engineering, feature/model selection, hyperparam. optimisation.\n* [Colombus](http://i.stanford.edu/hazy/victor/columbus/) - A scalable framework to perform exploratory feature selection implemented in R.\n* [Feature Engine](https://github.com/feature-engine/feature_engine) ![](https://img.shields.io/github/stars/feature-engine/feature_engine.svg?style=social) - Feature-engine is a Python library that contains several transformers to engineer features for use in machine learning models.\n* [Featuretools](https://github.com/alteryx/featuretools) ![](https://img.shields.io/github/stars/alteryx/featuretools.svg?style=social) - An open source framework for automated feature engineering.\n* [go-featureprocessing](https://github.com/nikolaydubina/go-featureprocessing) ![](https://img.shields.io/github/stars/nikolaydubina/go-featureprocessing.svg?style=social) - A feature pre-processing framework in Go that matches functionality of sklearn.\n* [keras-tuner](https://github.com/keras-team/keras-tuner) ![](https://img.shields.io/github/stars/keras-team/keras-tuner?style=social) - Keras Tuner is an easy-to-use, distributable hyperparameter optimization framework that solves the pain points of performing a hyperparameter search. Keras Tuner makes it easy to define a search space and leverage included algorithms to find the best hyperparameter values.\n* [mljar-supervised](https://github.com/mljar/mljar-supervised) ![](https://img.shields.io/github/stars/mljar/mljar-supervised.svg?style=social) - An Automated Machine Learning (AutoML) python package for tabular data. It can handle: Binary Classification, MultiClass Classification and Regression. It provides feature engineering, explanations and markdown reports.\n* [sklearn-deap](https://github.com/rsteca/sklearn-deap) ![](https://img.shields.io/github/stars/rsteca/sklearn-deap.svg?style=social) Use evolutionary algorithms instead of gridsearch in scikit-learn.\n* [TPOT](https://github.com/epistasislab/tpot) ![](https://img.shields.io/github/stars/epistasislab/tpot.svg?style=social) - Automation of sklearn pipeline creation (including feature selection, pre-processor, etc.).\n* [tsfresh](https://github.com/blue-yonder/tsfresh) ![](https://img.shields.io/github/stars/blue-yonder/tsfresh.svg?style=social) - Automatic extraction of relevant features from time series.\n* [Upgini](https://github.com/upgini/upgini) ![](https://img.shields.io/github/stars/upgini/upgini.svg?style=social) - Free automated data & feature enrichment library for machine learning: automatically searches through thousands of ready-to-use features from public and community shared data sources and enriches your training dataset with only the accuracy improving features.\n\n\n## Feature Store\n* [Butterfree](https://github.com/quintoandar/butterfree) ![](https://img.shields.io/github/stars/quintoandar/butterfree.svg?style=social) - A tool for building feature stores which allows you to transform your raw data into beautiful features.\n* [Feature Store for Machine Learning (FEAST)](https://github.com/feast-dev/feast)  ![](https://img.shields.io/github/stars/feast-dev/feast.svg?style=social) - Feast (Feature Store) is a tool for managing and serving machine learning features. Feast is the bridge between models and data.\n* [Featureform](https://github.com/featureform/featureform) ![](https://img.shields.io/github/stars/featureform/featureform.svg?style=social) - A virtual featurestore. Plug-&-play with your existing infra. Data Scientist approved. Discovery, Governance, Lineage, & Collaboration just a pip install away. Supports pandas, Python, spark, SQL + integrations with major cloud vendors. \n* [Hopsworks Feature Store](https://github.com/logicalclocks/hopsworks) ![](https://img.shields.io/github/stars/logicalclocks/hopsworks.svg?style=social) - Offline/Online Feature Store for ML [(Video)](https://www.youtube.com/watch?v=N1BjPk1smdg).\n* [Ivory](https://github.com/antony-a1/ivory)  ![](https://img.shields.io/github/stars/antony-a1/ivory.svg?style=social) - ivory defines a specification for how to store feature data and provides a set of tools for querying it. It does not provide any tooling for producing feature data in the first place. All ivory commands run as MapReduce jobs so it assumed that feature data is maintained on HDFS.\n* [Veri](https://github.com/bgokden/veri) ![](https://img.shields.io/github/stars/bgokden/veri.svg?style=social) - Veri is a Feature Label Store. Feature Label store allows storing features as keys and labels as values. Querying values is only possible with knn using features. Veri also supports creating sub sample spaces of data by default.\n\n\n## Commercial Platform\n* [Amazon SageMaker](https://aws.amazon.com/sagemaker/) - End-to-end machine learning development and deployment interface where you are able to build notebooks that use EC2 instances as backend, and then can host models exposed on an API.\n* [Apheris](https://www.apheris.com/) - A platform for federated and privacy-preserving data science that lets you securely collaborate on AI with partners without sharing any data.\n* [Arize AI](https://arize.com/) - ML observability and automated model monitoring to help ML practitioners understand how their models perform in production, troubleshoot issues, and improve model performance. ML teams can upload offline (training or validation) baselines into an evaluation/inference store alongside online production data for model validation, drift detection, data quality checks, and model performance management.\n* [BigML](https://bigml.com/) - A consumable, programmable, and scalable Machine Learning platform that makes it easy to solve and automate classification, regression, time series, etc..\n* [Censius](https://censius.ai) - Censius is an AI Observability Platform that assists enterprises in continuously monitoring, analyzing, and explaining their production models. It combines monitoring, accountability, and explainability into one Observability Platform.\n* [Cnvrg.io](https://cnvrg.io) - An end-to-end platform to manage, build and automate machine learning\n* [Comet](http://comet.ml) - Machine learning experiment management. Free for open source and students - [(Video)](https://www.youtube.com/watch?v=xaybRkapeNE).\n* [D2iQ Kaptain](https://d2iq.com/products/kaptain) - An end-to-end machine learning platform built for security, scale, and speed, that allows enterprises to develop and deploy machine learning models that runs in the cloud, on premises (incl. air-gapped), in hybrid environments, or on the edge; based on Kubeflow and open-source [Kubernetes Universal Declarative Operators](https://kudo.dev/) (KUDO).\n* [DAGsHub](https://dagshub.com/) - Community platform for Open Source ML \u2013 Manage experiments, data & models and create collaborative ML projects easily.\n* [Databricks](https://www.databricks.com/) - An integrated end-to-end machine learning environment incorporating managed services for experiment tracking, model training, feature development and management, and feature and model serving.\n* [Dataiku](https://www.dataiku.com/) - Collaborative data science platform powering both self-service analytics and the operationalization of machine learning models in production.\n* [DataRobot](https://www.datarobot.com/) - Automated machine learning platform which enables users to build and deploy machine learning models.\n* [Datatron](https://datatron.com/) - Machine Learning Model Governance Platform for all your AI models in production for large Enterprises.\n* [Deep Cognition Deep Learning Studio](https://deepcognition.ai/) - E2E platform for deep learning.\n* [deepsense Safety](https://safety.deepsense.ai/) - AI-driven solution to increase worksite safety via safety procedure check, thread detection and hazardous zones monitoring.\n* [deepsense Quality](https://quality.deepsense.ai/) - Automating laborious quality control tasks.\n* [Diffgram](https://diffgram.com/) - Training Data First platform. Database & Training Data Pipelines for Supervised AI. Integrated with GCP, AWS, Azure and top Annotation Supervision UIs (or use built-in Diffgram UI, or build your own). Plus a growing list of integrated service providers! For Computer Vision, NLP, and Supervised Deep Learning / Machine Learning.\n* [Domino](https://www.dominodatalab.com/) - An enterprise MLOps platform that supports data scientist collaboration with their preferred tools, languages, and infrastructure, with IT central resource management, governance, and security, without vendor lock-in.\n* [Google Cloud Machine Learning Engine](https://cloud.google.com/ml-engine/) - Managed service that enables developers and data scientists to build and bring machine learning models to production.\n* [Graphsignal](https://graphsignal.com/) - Machine learning profiler that helps make model training and inference faster and more efficient.\n* [H2O Driverless AI](https://www.h2o.ai/products/h2o-driverless-ai/) - Automates key machine learning tasks, delivering automatic feature engineering, model validation, model tuning, model selection and deployment, machine learning interpretability, bring your own recipe, time-series and automatic pipeline generation for model scoring - [(Video)](https://www.youtube.com/watch?v=ZqCoFp3-rGc).\n* [IBM Watson Studio](https://www.ibm.com/cloud/watson-studio) - Build and scale trusted AI on any cloud. Automate the AI lifecycle for ModelOps.\n* [Iguazio Data Science Platform](https://www.iguazio.com/) - Bring your Data Science to life by automating MLOps with end-to-end machine learning pipelines, transforming AI projects into real-world business outcomes, and supporting real-time performance at enterprise scale.\n* [Iterative Studio](https://studio.iterative.ai/) - Seamless data and model management, experiment tracking, visualization and automation, with Git as the single source of truth.\n* [Katonic.ai](https://katonic.ai/) - Automate your cycle of Intelligence with Katonic MLOps Platform.\n* [Labelbox](https://labelbox.com/) - Image labelling service with support for semantic segmentation (brush & superpixels), bounding boxes and nested classifications.\n* [Microsoft Azure Machine Learning service](https://azure.microsoft.com/en-us/services/machine-learning-service/) - Build, train, and deploy models from the cloud to the edge.\n* [ModelOp](https://www.modelop.com/) - An enterprise MLOps platform that automates the governance, management and monitoring of deployed AI, ML models across platforms and teams, resulting in reliable, compliant and scalable AI initiatives.\n* [MLJAR](https://mljar.com/) - Platform for rapid prototyping, developing and deploying machine learning models.\n* [Neptune.ai](https://github.com/neptune-ai/neptune-client) ![](https://img.shields.io/github/stars/neptune-ai/neptune-client.svg?style=social) - Neptune is a lightweight solution designed for: 1) experiment tracking; 2) model registry; 3) ML runs live monitoring.  \n* [Nimblebox](https://nimblebox.ai) - A full-stack MLOps platform designed to help data scientists and machine learning practitioners around the world discover, create, and launch multi-cloud apps from their web browser.\n* [Prodigy](https://prodi.gy/) - Active learning-based data annotation. Allows to train a model and pick most 'uncertain' samples for labeling from an unlabeled pool.\n* [Robust Intelligence](https://www.robustintelligence.com/) - Robust Intelligence is an end-to-end ML integrity solution that proactively eliminates failure at every stage of the model lifecycle. From pre-deployment vulnerability detection and validation to post-deployment monitoring and protection, Robust Intelligence gives teams the confidence to scale models in production across a variety of use cases and modalities.\n* [Scribble Enrich](https://www.scribbledata.io/product) - Customizable, auditable, privacy-aware feature store. It is designed to help mid-sized data teams gain trust in the data that they use for training and analysis, and support emerging needs such drift computation and bias assessment.\n* [SigOpt](https://sigopt.com/) - SigOpt is a model development platform that makes it easy to track runs, visualize training, and scale hyperparameter optimization for any type of model built with any library on any infrastructure.\n* [Skymind](https://skymind.global/) - Software distribution designed to help enterprise IT teams manage, deploy, and retrain machine learning models at scale.\n* [Skytree](http://skytree.net) - End to end machine learning platform - [(Video)](https://www.youtube.com/watch?v=XuCwpnU-F1k).\n* [Spell](https://spell.run) - Flexible end-to-end MLOps / Machine Learning Platform - [(Video)](https://www.youtube.com/watch?v=J7xo-STHx1k).\n* [SuperAnnotate](https://www.superannotate.com/) - A complete set of solutions for image and video annotation and an annotation service with integrated tooling, on-demand narrow expertise in various fields, and a custom neural network, automation, and training models powered by AI.\n* [Superb AI](https://superb-ai.com) - ML DataOps platform providing various tools to build, label, manage and iterate on training data.\n* [Syndicai](https://syndicai.co) - Easy-to-use cloud agnostic platform that deploys, manages, and scales any trained AI model in minutes with no configuration & infrastructure setup.\n* [Talend Studio](https://www.talend.com/) - Data integration platform that provides various software and services for data integration, data management, enterprise application integration, data quality, cloud storage and Big Data.\n* [Valohai](https://valohai.com/) - Machine orchestration, version control and pipeline management for deep learning.\n* [Vertex AI](https://cloud.google.com/vertex-ai) - Vertex AI Workbench is the single environment for data scientists to complete all of their ML work, from experimentation, to deployment, to managing and monitoring models. It is a Jupyter-based fully managed, scalable, enterprise-ready compute infrastructure with security controls and user management capabilities.\n* [Weights & Biases](https://github.com/wandb/wandb) ![](https://img.shields.io/github/stars/wandb/wandb.svg?style=social) - Machine learning experiment tracking, dataset versioning, hyperparameter search, visualization, and collaboration.\n",
	"data-mining data-science logistic-regression machine-learning machine-learning-algorithms neural-network python scikit-learn": "# Python Machine Learning book code repository\n\n\n[![Google Group](https://img.shields.io/badge/-Google%20Group-lightgrey.svg)](https://groups.google.com/forum/#!forum/python-machine-learning-reader-discussion-board)\n\n---\n\n#### IMPORTANT NOTE (09/21/2017):\n\nThis GitHub repository contains the code examples of the **1st Edition** of Python Machine Learning book. If you are looking for the code examples of the **2nd Edition**, please refer to [this](https://github.com/rasbt/python-machine-learning-book-2nd-edition#whats-new-in-the-second-edition-from-the-first-edition) repository instead. \n\n---\n\nWhat you can expect are 400 pages rich in useful material just about everything you need to know to get started with machine learning ... from theory to the actual code that you can directly put into action! This is not yet just another \"this is how scikit-learn works\" book. I aim to explain all the underlying concepts, tell you everything you need to know in terms of best practices and caveats, and\nwe will put those concepts into action mainly using NumPy, scikit-learn, and Theano.\n\nYou are not sure if this book is for you? Please checkout the excerpts from the [Foreword](./docs/foreword_ro.pdf) and [Preface](./docs/preface_sr.pdf), or take a look at the [FAQ](#faq) section for further information.\n\n\n\n---\n\n[![](./images/pymle_cover_double_small.jpg)](https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130/ref=sr_1_1?ie=UTF8&qid=1470882464&sr=8-1&keywords=python+machine+learning)\n\n1st edition, published September 23rd 2015<br>\nPaperback: 454 pages<br>\nPublisher: Packt Publishing<br>  \nLanguage: English<br>\nISBN-10: 1783555130<br>  \nISBN-13: 978-1783555130<br>\nKindle ASIN: B00YSILNL0<br>\n\n<br>\n\n[![](./images/CRBadgeNotableBook.jpg)](http://www.computingreviews.com/recommend/bestof/notableitems.cfm?bestYear=2016)\n\n<br>\n\nGerman ISBN-13: 978-3958454224<br>\nJapanese ISBN-13: 978-4844380603<br>\nItalian ISBN-13: 978-8850333974<br>\nChinese (traditional) ISBN-13: 978-9864341405<br>\nChinese (mainland) ISBN-13: 978-7111558804<br>\nKorean ISBN-13: 979-1187497035<br>\nRussian ISBN-13: 978-5970604090<br>\n\n\n\n## Table of Contents and Code Notebooks\n\n\nSimply click on the `ipynb`/`nbviewer` links next to the chapter headlines to view the code examples (currently, the internal document links are only supported by the NbViewer version).\n**Please note that these are just the code examples accompanying the book, which I uploaded for your convenience; be aware that these notebooks may not be useful without the formulae and descriptive text.**   \n\n\n- Excerpts from the [Foreword](./docs/foreword_ro.pdf) and [Preface](./docs/preface_sr.pdf)\n- [Instructions for setting up Python and the Jupiter Notebook](./code/ch01/README.md)  \n\n<br>\n\n1. Machine Learning - Giving Computers the Ability to Learn from Data [[dir](./code/ch01)] [[ipynb](./code/ch01/ch01.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch01/ch01.ipynb)]\n2. Training Machine Learning Algorithms for Classification [[dir](./code/ch02)] [[ipynb](./code/ch02/ch02.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb)]\n3. A Tour of Machine Learning Classifiers Using Scikit-Learn [[dir](./code/ch03)] [[ipynb](./code/ch03/ch03.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch03/ch03.ipynb)]\n4. Building Good Training Sets \u2013 Data Pre-Processing [[dir](./code/ch04)] [[ipynb](./code/ch04/ch04.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch04/ch04.ipynb)]\n5. Compressing Data via Dimensionality Reduction [[dir](./code/ch05)] [[ipynb](./code/ch05/ch05.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch05/ch05.ipynb)]\n6. Learning Best Practices for Model Evaluation and Hyperparameter Optimization [[dir](./code/ch06)] [[ipynb](./code/ch06/ch06.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch06/ch06.ipynb)]\n7. Combining Different Models for Ensemble Learning [[dir](./code/ch07)] [[ipynb](./code/ch07/ch07.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch07/ch07.ipynb)]\n8. Applying Machine Learning to Sentiment Analysis [[dir](./code/ch08)] [[ipynb](./code/ch08/ch08.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch08/ch08.ipynb)]\n9. Embedding a Machine Learning Model into a Web Application [[dir](./code/ch09)] [[ipynb](./code/ch09/ch09.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch09/ch09.ipynb)]\n10. Predicting Continuous Target Variables with Regression Analysis [[dir](./code/ch10)] [[ipynb](./code/ch10/ch10.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch10/ch10.ipynb)]\n11. Working with Unlabeled Data \u2013 Clustering Analysis [[dir](./code/ch11)] [[ipynb](./code/ch11/ch11.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch11/ch11.ipynb)]\n12. Training Artificial Neural Networks for Image Recognition [[dir](./code/ch12)] [[ipynb](./code/ch12/ch12.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb)]\n13. Parallelizing Neural Network Training via Theano [[dir](./code/ch13)] [[ipynb](./code/ch13/ch13.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/ch13/ch13.ipynb)]\n\n<br>\n\n#### Equation Reference\n\n<a href=\"https://github.com/rasbt/python-machine-learning-book/tree/master/docs/equations\"><img src=\"images/equation-ref-logo.png\" width=\"200\" height=\"200\" /></a>\n\n[[PDF](./docs/equations/pymle-equations.pdf)] [[TEX](./docs/equations/pymle-equations.tex)]\n\n#### Slides for Teaching\n\nA big thanks to [Dmitriy Dligach](dmitriydligach) for sharing his slides from his machine learning course that is currently offered at [Loyola University Chicago](http://www.luc.edu/cs/). \n\n- [https://github.com/dmitriydligach/PyMLSlides](https://github.com/dmitriydligach/PyMLSlides)\n- \n\n\n\n#### Additional Math and NumPy Resources\n\nSome readers were asking about Math and NumPy primers, since they were not included due to length limitations. However, I recently put together such resources for another book, but I made these *chapters* freely available online in hope that they also serve as helpful background material for this book:\n\n\n- Algebra Basics [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_b_algebra.pdf)] [[EPUB](https://sebastianraschka.com/pdf/books/dlb/appendix_b_algebra.epub)]\n\n- A Calculus and Differentiation Primer [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf)] [[EPUB](https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.epub)]\n\n- Introduction to NumPy [[PDF](https://sebastianraschka.com/pdf/books/dlb/appendix_f_numpy-intro.pdf)] [[EPUB](https://sebastianraschka.com/pdf/books/dlb/appendix_f_numpy-intro.epub)] [[Code Notebook](https://github.com/rasbt/deep-learning-book/blob/master/code/appendix_f_numpy-intro/appendix_f_numpy-intro.ipynb)]\n\n\n\n---\n\n#### Citing this Book\n\nYou are very welcome to re-use the code snippets or other contents from this book\nin scientific publications and other works;\nin this case, I would appreciate citations to the original source:\n\n**BibTeX**:\n\n```\n@Book{raschka2015python,\n author = {Raschka, Sebastian},\n title = {Python Machine Learning},\n publisher = {Packt Publishing},\n year = {2015},\n address = {Birmingham, UK},\n isbn = {1783555130}\n }\n```\n\n\n**MLA**:\n\n\nRaschka, Sebastian. *Python machine learning*. Birmingham, UK: Packt Publishing, 2015. Print.\n\n---\n\n### [Feedback & Reviews](./docs/feedback.md)\n\n#### [Short review snippets](./docs/feedback.md)\n\n[![](./images/pymle_amzn.png)](https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130/ref=sr_1_1?ie=UTF8&qid=1472342570&sr=8-1&keywords=sebastian+raschka)\n\n---\n> *Sebastian Raschka\u2019s new book, Python Machine Learning, has just been released. I got a chance to read a review copy and it\u2019s just as I expected - really great! It\u2019s well organized, super easy to follow, and it not only offers a good foundation for smart, non-experts, practitioners will get some ideas and learn new tricks here as well.*  \n\u2013 Lon Riesberg at [Data Elixir](http://dataelixir.com/issues/55#start)\n\n> *Superb job! Thus far, for me it seems to have hit the right balance of theory and practice\u2026math and code!*   \n\u2013 [Brian Thomas](http://sebastianraschka.com/blog/2015/writing-pymle.html#comment-2295668894)\n\n> *I've read (virtually) every Machine Learning title based around Scikit-learn and this is hands-down the best one out there.*    \n\u2013 [Jason Wolosonovich](https://www.linkedin.com/pulse/python-machine-learning-sebastian-raschka-review-jason-wolosonovich?trk=prof-post)\n\n> *The best book I've seen to come out of PACKT Publishing. This is a very well written introduction to machine learning with Python. As others have noted, a perfect mixture of theory and application.*    \n\u2013 [Josh D.](https://www.amazon.com/gp/customer-reviews/R27WB1GWTNGIR2/ref=cm_cr_getr_d_rvw_ttl?ie=UTF8&ASIN=1783555130)\n\n> *A book with a blend of qualities that is hard to come by: combines the needed mathematics to control the theory with the applied coding in Python. Also great to see it doesn't waste paper in giving a primer on Python as many other books do just to appeal to the greater audience. You can tell it's been written by knowledgeable writers and not just DIY geeks.*    \n\u2013 [Amazon Customer](https://www.amazon.com/gp/customer-reviews/RZWY4TF66Z6V0/ref=cm_cr_getr_d_rvw_ttl?ie=UTF8&ASIN=1783555130)\n\n> *Sebastian Raschka created an amazing machine learning tutorial which combines theory with practice. The book explains machine learning from a theoretical perspective and has tons of coded examples to show how you would actually use the machine learning technique. It can be read by a beginner or advanced programmer.*\n- William P. Ross, [7 Must Read Python Books](http://williampross.com/7-must-read-python-books/)\n\n#### Longer reviews\n\nIf you need help to decide whether this book is for you, check out some of the \"longer\" reviews linked below. (If you wrote a review, please let me know, and I'd be happy to add it to the list).\n\n- [Python Machine Learning Review](http://www.bcs.org/content/conWebDoc/55586) by Patrick Hill at the Chartered Institute for IT\n- [Book Review: Python Machine Learning by Sebastian Raschka](http://whatpixel.com/python-machine-learning-book-review/) by Alex Turner at WhatPixel\n\n---\n\n## Links\n\n- ebook and paperback at [Amazon.com](http://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130/ref=sr_1_2?ie=UTF8&qid=1437754343&sr=8-2&keywords=python+machine+learning+essentials), [Amazon.co.uk](http://www.amazon.co.uk/Python-Machine-Learning-Sebastian-Raschka/dp/1783555130), [Amazon.de](http://www.amazon.de/s/ref=nb_sb_noss_2?__mk_de_DE=\u00c5M\u00c5\u017d\u00d5\u00d1&url=search-alias%3Daps&field-keywords=python+machine+learning)\n- [ebook and paperback](https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning) from Packt (the publisher)\n- at other book stores: [Google Books](https://books.google.com/books?id=GOVOCwAAQBAJ&source=gbs_slider_cls_metadata_7_mylibrary), [O'Reilly](http://shop.oreilly.com/product/9781783555130.do), [Safari](https://www.safaribooksonline.com/library/view/python-machine-learning/9781783555130/), [Barnes & Noble](http://www.barnesandnoble.com/w/python-machine-learning-essentials-sebastian-raschka/1121999969?ean=9781783555130), [Apple iBooks](https://itunes.apple.com/us/book/python-machine-learning/id1028207310?mt=11), ...\n- social platforms: [Goodreads](https://www.goodreads.com/book/show/25545994-python-machine-learning)\n\n#### Translations\n\n- [Italian translation](https://www.amazon.it/learning-Costruire-algoritmi-generare-conoscenza/dp/8850333978/) via \"Apogeo\"\n- [German translation](https://www.amazon.de/Machine-Learning-Python-mitp-Professional/dp/3958454224/) via \"mitp Verlag\"\n- [Japanese translation](http://www.amazon.co.jp/gp/product/4844380605/) via \"Impress Top Gear\"\n- [Chinese translation (traditional Chinese)](https://taiwan.kinokuniya.com/bw/9789864341405)\n- [Chinese translation (simple Chinese)](https://book.douban.com/subject/27000110/)\n- [Korean translation](http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&ejkGb=KOR&barcode=9791187497035) via \"Kyobo\"\n- [Polish translation](https://www.amazon.de/Python-Uczenie-maszynowe-Sebastian-Raschka/dp/8328336138/ref=sr_1_11?ie=UTF8&qid=1513601461&sr=8-11&keywords=sebastian+raschka) via \"Helion\"\n\n---\n\n### [Literature References & Further Reading Resources](./docs/references.md)\n\n### [Errata](./docs/errata.md)\n\n\n---\n\n### Bonus Notebooks (not in the book)\n\n- Logistic Regression Implementation [[dir](./code/bonus)] [[ipynb](./code/bonus/logistic_regression.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/logistic_regression.ipynb)]\n- A Basic Pipeline and Grid Search Setup [[dir](./code/bonus)] [[ipynb](./code/bonus/svm_iris_pipeline_and_gridsearch.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/svm_iris_pipeline_and_gridsearch.ipynb)]\n- An Extended Nested Cross-Validation Example [[dir](./code/bonus)] [[ipynb](./code/bonus/nested_cross_validation.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/nested_cross_validation.ipynb)]\n- A Simple Barebones Flask Webapp Template [[view directory](./code/bonus/flask_webapp_ex01)][[download as zip-file](https://github.com/rasbt/python-machine-learning-book/raw/master/code/bonus/flask_webapp_ex01/flask_webapp_ex01.zip)]\n- Reading handwritten digits from MNIST into NumPy arrays [[GitHub ipynb](./code/bonus/reading_mnist.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/reading_mnist.ipynb)]\n- Scikit-learn Model Persistence using JSON [[GitHub ipynb](./code/bonus/scikit-model-to-json.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/scikit-model-to-json.ipynb)]\n- Multinomial logistic regression / softmax regression [[GitHub ipynb](./code/bonus/softmax-regression.ipynb)] [[nbviewer](http://nbviewer.ipython.org/github/rasbt/python-machine-learning-book/blob/master/code/bonus/softmax-regression.ipynb)]\n\n<hr>\n\n**\"Related Content\" (not in the book)**\n\n- [Model evaluation, model selection, and algorithm selection in machine learning - Part I](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html)\n- [Model evaluation, model selection, and algorithm selection in machine learning - Part II](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html)\n- [Model evaluation, model selection, and algorithm selection in machine learning - Part III](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html)\n\n---\n\n#### SciPy 2016\n\nWe had such a great time at [SciPy 2016](http://scipy2016.scipy.org/ehome/index.php?eventid=146062&tabid=332930&) in Austin! It was a real pleasure to meet and chat with so many readers of my book. Thanks so much for all the nice words and feedback! And in case you missed it, Andreas Mueller and I gave an **Introduction to Machine Learning with Scikit-learn**; if you are interested, the video recordings of [Part I](https://www.youtube.com/watch?v=OB1reY6IX-o&index=91&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6) and [Part II](https://www.youtube.com/watch?v=Cte8FYCpylk&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6&index=90) are now online!\n\n[![](images/scipy2016.jpg)](https://www.youtube.com/watch?v=OB1reY6IX-o&index=91&list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6)\n\n#### PyData Chicago 2016\n\nI attempted the rather challenging task of introducing scikit-learn & machine learning in *just* 90 minutes at PyData Chicago 2016. The slides and tutorial material are available at \"[Learning scikit-learn -- An Introduction to Machine Learning in Python](https://github.com/rasbt/pydata-chicago2016-ml-tutorial).\"\n\n\n---\n\n**Note**\n\nI have set up a separate library, [`mlxtend`](http://rasbt.github.io/mlxtend/), containing additional implementations of machine learning (and general \"data science\") algorithms. I also added implementations from this book (for example, the decision region plot, the artificial neural network, and sequential feature selection algorithms) with additional functionality.\n\n[![](./images/mlxtend_logo.png)](http://rasbt.github.io/mlxtend/)\n\n\n<br>\n\n<hr>\n\n### Translations\n\n[![](./images/pymle-cover_it.jpg)](https://www.amazon.it/learning-Costruire-algoritmi-generare-conoscenza/dp/8850333978/)\n[![](./images/pymle-cover_de.jpg)](https://www.amazon.de/Machine-Learning-Python-mitp-Professional/dp/3958454224/)\n[![](./images/pymle-cover_jp.jpg)](http://www.amazon.co.jp/gp/product/4844380605/)\n[![](./images/pymle-cover_cn.jpg)](https://taiwan.kinokuniya.com/bw/9789864341405)\n[![](./images/pymle-cover_cn_mainland.jpg)](https://book.douban.com/subject/27000110/)\n[![](./images/pymle-cover_kr.jpg)](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9791187497035&orderClick=LEA&Kc=)\n[![](./images/pymle-cover_ru.jpg)](http://www.ozon.ru/context/detail/id/140152222/)\n[![](./images/pymle-cover_pl.jpg)](https://www.amazon.de/Python-Uczenie-maszynowe-Sebastian-Raschka/dp/8328336138/ref=sr_1_11?ie=UTF8&qid=1513601461&sr=8-11&keywords=sebastian+raschka)\n\n<hr>\n\n---\n\n***Dear readers***,  \nfirst of all, I want to thank all of you for the great support! I am really happy about all the great feedback you sent me so far, and I am glad that the book has been so useful to a broad audience.\n\nOver the last couple of months, I received hundreds of emails, and I tried to answer as many as possible in the available time I have. To make them useful to other readers as well, I collected many of my answers in the FAQ section (below).\n\nIn addition, some of you asked me about a platform for readers to discuss the contents of the book. I hope that this would provide an opportunity for you to discuss and share your knowledge with other readers:\n\n#### [Google Groups Discussion Board](https://groups.google.com/forum/#!forum/python-machine-learning-reader-discussion-board)\n\n(And I will try my best to answer questions myself if time allows! :))\n\n> The only thing to do with good advice is to pass it on. It is never of any use to oneself.  \n\u2014 Oscar Wilde\n\n---\n\n## Examples and Applications by Readers\n\nOnce again, I have to say (big!) THANKS for all the nice feedback about the book. I've received many emails from readers, who\nput the concepts and examples from this book out into the real world and make good use of them in their projects. In this section, I am\nstarting to gather some of these great applications, and I'd be more than happy to add your project to this list -- just shoot me a quick mail!\n\n- [40 scripts on Optical Character Recognition](https://github.com/rrlyman/PythonMachineLearingExamples) by [Richard Lyman](https://github.com/rrlyman)\n- [Code experiments](https://github.com/jeremyn/python-machine-learning-book) by [Jeremy Nation](https://github.com/jeremyn)\n- [What I Learned Implementing a Classifier from Scratch in Python](http://www.jeannicholashould.com) by [Jean-Nicholas Hould](http://www.jeannicholashould.com)\n\n## FAQ\n\n### General Questions\n\n- [What are machine learning and data science?](./faq/datascience-ml.md)\n- [Why do you and other people sometimes implement machine learning algorithms from scratch?](./faq/implementing-from-scratch.md)\n- [What learning path/discipline in data science I should focus on?](./faq/data-science-career.md)\n- [At what point should one start contributing to open source?](./faq/open-source.md)\n- [How important do you think having a mentor is to the learning process?](./faq/mentor.md)\n- [Where are the best online communities centered around data science/machine learning or python?](./faq/ml-python-communities.md)\n- [How would you explain machine learning to a software engineer?](./faq/ml-to-a-programmer.md)\n- [How would your curriculum for a machine learning beginner look like?](./faq/ml-curriculum.md)\n- [What is the Definition of Data Science?](./faq/definition_data-science.md)\n- [How do Data Scientists perform model selection? Is it different from Kaggle?](./faq/model-selection-in-datascience.md)\n\n### Questions about the Machine Learning Field\n\n- [How are Artificial Intelligence and Machine Learning related?](./faq/ai-and-ml.md)\n- [What are some real-world examples of applications of machine learning in the field?](./faq/ml-examples.md)\n- [What are the different fields of study in data mining?](./faq/datamining-overview.md)\n- [What are differences in research nature between the two fields: machine learning & data mining?](./faq/datamining-vs-ml.md)\n- [How do I know if the problem is solvable through machine learning?](./faq/ml-solvable.md)\n- [What are the origins of machine learning?](./faq/ml-origins.md)\n- [How was classification, as a learning machine, developed?](./faq/classifier-history.md)\n- [Which machine learning algorithms can be considered as among the best?](./faq/best-ml-algo.md)\n- [What are the broad categories of classifiers?](./faq/classifier-categories.md)\n- [What is the difference between a classifier and a model?](./faq/difference_classifier_model.md)\n- [What is the difference between a parametric learning algorithm and a nonparametric learning algorithm?](./faq/parametric_vs_nonparametric.md)\n- [What is the difference between a cost function and a loss function in machine learning?](./faq/cost-vs-loss.md)\n\n### Questions about ML Concepts and Statistics\n\n##### Cost Functions and Optimization\n\n- [Fitting a model via closed-form equations vs. Gradient Descent vs Stochastic Gradient Descent vs Mini-Batch Learning -- what is the difference?](./faq/closed-form-vs-gd.md)\n- [How do you derive the Gradient Descent rule for Linear Regression and Adaline?](./faq/linear-gradient-derivative.md)\n\n##### Regression Analysis\n\n- [What is the difference between Pearson R and Simple Linear Regression?](./faq/pearson-r-vs-linear-regr.md)\n\n##### Tree models\n\n- [How does the random forest model work? How is it different from bagging and boosting in ensemble models?](./faq/bagging-boosting-rf.md)\n- [What are the disadvantages of using classic decision tree algorithm for a large dataset?](./faq/decision-tree-disadvantages.md)\n- [Why are implementations of decision tree algorithms usually binary, and what are the advantages of the different impurity metrics?](./faq/decision-tree-binary.md)\n- [Why are we growing decision trees via entropy instead of the classification error?](./faq/decisiontree-error-vs-entropy.md)\n- [When can a random forest perform terribly?](./faq/random-forest-perform-terribly.md)\n\n##### Model evaluation\n\n- [What is overfitting?](./faq/overfitting.md)\n- [How can I avoid overfitting?](./faq/avoid-overfitting.md)\n- [Is it always better to have the largest possible number of folds when performing cross validation?](./faq/number-of-kfolds.md)\n- [When training an SVM classifier, is it better to have a large or small number of support vectors?](./faq/num-support-vectors.md)\n- [How do I evaluate a model?](./faq/evaluate-a-model.md)\n- [What is the best validation metric for multi-class classification?](./faq/multiclass-metric.md)\n- [What factors should I consider when choosing a predictive model technique?](./faq/choosing-technique.md)\n- [What are the best toy datasets to help visualize and understand classifier behavior?](./faq/clf-behavior-data.md)\n- [How do I select SVM kernels?](./faq/select_svm_kernels.md)\n- [Interlude: Comparing and Computing Performance Metrics in Cross-Validation -- Imbalanced Class Problems and 3 Different Ways to Compute the F1 Score](./faq/computing-the-f1-score.md)\n\n##### Logistic Regression\n\n- [What is Softmax regression and how is it related to Logistic regression?](./faq/softmax_regression.md)\n- [Why is logistic regression considered a linear model?](./faq/logistic_regression_linear.md)\n- [What is the probabilistic interpretation of regularized logistic regression?](./faq/probablistic-logistic-regression.md)\n- [Does regularization in logistic regression always results in better fit and better generalization?](./faq/regularized-logistic-regression-performance.md)\n- [What is the major difference between naive Bayes and logistic regression?](./faq/naive-bayes-vs-logistic-regression.md)\n- [What exactly is the \"softmax and the multinomial logistic loss\" in the context of machine learning?](./faq/softmax.md)\n- [What is the relation between Loigistic Regression and Neural Networks and when to use which?](./faq/logisticregr-neuralnet.md)\n- [Logistic Regression: Why sigmoid function?](./faq/logistic-why-sigmoid.md)\n- [Is there an analytical solution to Logistic Regression similar to the Normal Equation for Linear Regression?](./faq/logistic-analytical.md)\n\n\n##### Neural Networks and Deep Learning\n\n- [What is the difference between deep learning and usual machine learning?](./faq/difference-deep-and-normal-learning.md)\n- [Can you give a visual explanation for the back propagation algorithm for neural networks?](./faq/visual-backpropagation.md)\n- [Why did it take so long for deep networks to be invented?](./faq/inventing-deeplearning.md)\n- [What are some good books/papers for learning deep learning?](./faq/deep-learning-resources.md)\n- [Why are there so many deep learning libraries?](./faq/many-deeplearning-libs.md)\n- [Why do some people hate neural networks/deep learning?](./faq/deeplearning-criticism.md)\n- [How can I know if Deep Learning works better for a specific problem than SVM or random forest?](./faq/deeplearn-vs-svm-randomforest.md)\n- [What is wrong when my neural network's error increases?](./faq/neuralnet-error.md)\n- [How do I debug an artificial neural network algorithm?](./faq/nnet-debugging-checklist.md)\n- [What is the difference between a Perceptron, Adaline, and neural network model?](./faq/diff-perceptron-adaline-neuralnet.md)\n- [What is the basic idea behind the dropout technique?](./faq/dropout.md)\n\n\n##### Other Algorithms for Supervised Learning\n\n- [Why is Nearest Neighbor a Lazy Algorithm?](./faq/lazy-knn.md)\n\n##### Unsupervised Learning\n\n- [What are some of the issues with clustering?](./faq/issues-with-clustering.md)\n\n##### Semi-Supervised Learning\n\n- [What are the advantages of semi-supervised learning over supervised and unsupervised learning?](./faq/semi-vs-supervised.md)\n\n##### Ensemble Methods\n\n- [Is Combining Classifiers with Stacking Better than Selecting the Best One?](./faq/logistic-boosting.md)\n\n##### Preprocessing, Feature Selection and Extraction\n\n- [Why do we need to re-use training parameters to transform test data?](./faq/scale-training-test.md)\n- [What are the different dimensionality reduction methods in machine learning?](./faq/dimensionality-reduction.md)\n- [What is the difference between LDA and PCA for dimensionality reduction?](./faq/lda-vs-pca.md)\n- [When should I apply data normalization/standardization?](./faq/when-to-standardize.md)\n- [Does mean centering or feature scaling affect a Principal Component Analysis?](./faq/pca-scaling.md)\n- [How do you attack a machine learning problem with a large number of features?](./faq/large-num-features.md)\n- [What are some common approaches for dealing with missing data?](./faq/missing-data.md)\n- [What is the difference between filter, wrapper, and embedded methods for feature selection?](./faq/feature_sele_categories.md)\n- [Should data preparation/pre-processing step be considered one part of feature engineering? Why or why not?](./faq/dataprep-vs-dataengin.md)\n- [Is a bag of words feature representation for text classification considered as a sparse matrix?](./faq/bag-of-words-sparsity.md)\n\n##### Naive Bayes\n\n- [Why is the Naive Bayes Classifier naive?](./faq/naive-naive-bayes.md)\n- [What is the decision boundary for Naive Bayes?](./faq/naive-bayes-boundary.md)\n- [Can I use Naive Bayes classifiers for mixed variable types?](./faq/naive-bayes-vartypes.md)\n- [Is it possible to mix different variable types in Naive Bayes, for example, binary and continues features?](./naive-bayes-vartypes.md)\n\n##### Other\n\n- [What is Euclidean distance in terms of machine learning?](./faq/euclidean-distance.md)\n- [When should one use median, as opposed to the mean or average?](./faq/median-vs-mean.md)\n\n##### Programming Languages and Libraries for Data Science and Machine Learning\n\n- [Is R used extensively today in data science?](./faq/r-in-datascience.md)\n- [What is the main difference between TensorFlow and scikit-learn?](./faq/tensorflow-vs-scikitlearn.md)\n\n<br>\n\n\n\n\n\n### Questions about the Book\n\n- [Can I use paragraphs and images from the book in presentations or my blog?](./faq/copyright.md)\n- [How is this different from other machine learning books?](./faq/different.md)\n- [Which version of Python was used in the code examples?](./faq/py2py3.md)\n- [Which technologies and libraries are being used?](./faq/technologies.md)\n- [Which book version/format would you recommend?](./faq/version.md)\n- [Why did you choose Python for machine learning?](./faq/why-python.md)\n- [Why do you use so many leading and trailing underscores in the code examples?](./faq/underscore-convention.md)\n- [What is the purpose of the `return self` idioms in your code examples?](./faq/return_self_idiom.md)\n- [Are there any prerequisites and recommended pre-readings?](./faq/prerequisites.md)\n- [How can I apply SVM to categorical data?](./faq/svm_for_categorical.md)\n\n\n## Contact\n\nI am happy to answer questions! Just write me an [email](mailto:mail@sebastianraschka.com)\nor consider asking the question on the [Google Groups Email List](https://groups.google.com/forum/#!forum/python-machine-learning-book).\n\nIf you are interested in keeping in touch, I have quite a lively twitter stream ([@rasbt](https://twitter.com/rasbt)) all about data science and machine learning. I also maintain a [blog](http://sebastianraschka.com/articles.html) where I post all of the things I am particularly excited about.\n",
	"data-mining data-science forecasting machine-learning scikit-learn time-series time-series-analysis time-series-classification time-series-regression": "<a href=\"https://sktime.org\"><img src=\"https://github.com/sktime/sktime/blob/main/docs/source/images/sktime-logo.jpg?raw=true)\" width=\"175\" align=\"right\" /></a>\n\n# Welcome to sktime\n\n> A unified interface for machine learning with time series\n\n:rocket: **Version 0.14.0 out now!** [Check out the release notes here](https://www.sktime.org/en/latest/changelog.html).\n\nsktime is a library for time series analysis in Python. It provides a unified interface for multiple time series learning tasks. Currently, this includes time series classification, regression, clustering, annotation and forecasting. It comes with [time series algorithms](https://www.sktime.org/en/stable/estimator_overview.html) and [scikit-learn] compatible tools to build, tune and validate time series models.\n\n[scikit-learn]: https://scikit-learn.org/stable/\n\n| Overview | |\n|---|---|\n| **CI/CD** | [![github-actions](https://img.shields.io/github/workflow/status/sktime/sktime/build-and-test?logo=github)](https://github.com/sktime/sktime/actions?query=workflow%3Abuild-and-test) [![!codecov](https://img.shields.io/codecov/c/github/sktime/sktime?label=codecov&logo=codecov)](https://codecov.io/gh/sktime/sktime) [![readthedocs](https://img.shields.io/readthedocs/sktime?logo=readthedocs)](https://www.sktime.org/en/latest/?badge=latest) [![platform](https://img.shields.io/conda/pn/conda-forge/sktime)](https://github.com/sktime/sktime) |\n| **Code** |  [![!pypi](https://img.shields.io/pypi/v/sktime?color=orange)](https://pypi.org/project/sktime/) [![!conda](https://img.shields.io/conda/vn/conda-forge/sktime)](https://anaconda.org/conda-forge/sktime) [![!python-versions](https://img.shields.io/pypi/pyversions/sktime)](https://www.python.org/) [![!black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sktime/sktime/main?filepath=examples) |\n| **Downloads**| [![Downloads](https://static.pepy.tech/personalized-badge/sktime?period=week&units=international_system&left_color=grey&right_color=blue&left_text=weekly%20(pypi))](https://pepy.tech/project/sktime) [![Downloads](https://static.pepy.tech/personalized-badge/sktime?period=month&units=international_system&left_color=grey&right_color=blue&left_text=monthly%20(pypi))](https://pepy.tech/project/sktime) [![Downloads](https://static.pepy.tech/personalized-badge/sktime?period=total&units=international_system&left_color=grey&right_color=blue&left_text=cumulative%20(pypi))](https://pepy.tech/project/sktime) |\n| **Community** | [![!slack](https://img.shields.io/static/v1?logo=slack&label=slack&message=chat&color=lightgreen)](https://join.slack.com/t/sktime-group/shared_invite/zt-1cghagwee-sqLJ~eHWGYgzWbqUX937ig) [![!discord](https://img.shields.io/static/v1?logo=discord&label=discord&message=chat&color=lightgreen)](https://discord.com/invite/gqSab2K) [![!slack](https://img.shields.io/static/v1?logo=linkedin&label=LinkedIn&message=news&color=lightblue)](https://www.linkedin.com/company/sktime/) [![!twitter](https://img.shields.io/static/v1?logo=twitter&label=Twitter&message=news&color=lightblue)](https://twitter.com/sktime_toolbox) [![!youtube](https://img.shields.io/static/v1?logo=youtube&label=YouTube&message=tutorials&color=red)](https://www.youtube.com/playlist?list=PLKs3UgGjlWHqNzu0LEOeLKvnjvvest2d0) |\n| **Citation** | [![!zenodo](https://zenodo.org/badge/DOI/10.5281/zenodo.3749000.svg)](https://doi.org/10.5281/zenodo.3749000) |\n\n## :books: Documentation\n\n| Documentation              |                                                                |\n| -------------------------- | -------------------------------------------------------------- |\n| :star: **[Tutorials]**        | New to sktime? Here's everything you need to know!              |\n| :clipboard: **[Binder Notebooks]** | Example notebooks to play with in your browser.              |\n| :woman_technologist: **[User Guides]**      | How to use sktime and its features.                             |\n| :scissors: **[Extension Templates]** | How to build your own estimator using sktime's API.            |\n| :control_knobs: **[API Reference]**      | The detailed reference for sktime's API.                        |\n| :tv: **[Video Tutorial]**            | Our video tutorial from 2021 PyData Global.      |\n| :hammer_and_wrench: **[Changelog]**          | Changes and version history.                                   |\n| :deciduous_tree: **[Roadmap]**          | sktime's software and community development plan.                                   |\n| :pencil: **[Related Software]**          | A list of related software. |\n\n[tutorials]: https://www.sktime.org/en/latest/tutorials.html\n[binder notebooks]: https://mybinder.org/v2/gh/sktime/sktime/main?filepath=examples\n[user guides]: https://www.sktime.org/en/latest/user_guide.html\n[video tutorial]: https://github.com/sktime/sktime-tutorial-pydata-global-2021\n[api reference]: https://www.sktime.org/en/latest/api_reference.html\n[changelog]: https://www.sktime.org/en/latest/changelog.html\n[roadmap]: https://www.sktime.org/en/latest/roadmap.html\n[related software]: https://www.sktime.org/en/latest/related_software.html\n\n## :speech_balloon: Where to ask questions\n\nQuestions and feedback are extremely welcome! Please understand that we won't be able to provide individual support via email. We also believe that help is much more valuable if it's shared publicly, so that more people can benefit from it.\n\n| Type                            | Platforms                               |\n| ------------------------------- | --------------------------------------- |\n| :bug: **Bug Reports**              | [GitHub Issue Tracker]                  |\n| :sparkles: **Feature Requests & Ideas** | [GitHub Issue Tracker]                       |\n| :woman_technologist: **Usage Questions**          | [GitHub Discussions] \u00b7 [Stack Overflow] |\n| :speech_balloon: **General Discussion**        | [GitHub Discussions] |\n| :factory: **Contribution & Development** | [Slack], contributors channel \u00b7 [Discord] |\n| :globe_with_meridians: **Community collaboration session** | [Discord] - Fridays 1pm UTC, dev/meet-ups channel |\n\n[github issue tracker]: https://github.com/sktime/sktime/issues\n[github discussions]: https://github.com/sktime/sktime/discussions\n[stack overflow]: https://stackoverflow.com/questions/tagged/sktime\n[discord]: https://discord.com/invite/gqSab2K\n[slack]: https://join.slack.com/t/sktime-group/shared_invite/zt-1cghagwee-sqLJ~eHWGYgzWbqUX937ig\n\n## :dizzy: Features\nOur aim is to make the time series analysis ecosystem more interoperable and usable as a whole. sktime provides a __unified interface for distinct but related time series learning tasks__. It features [__dedicated time series algorithms__](https://www.sktime.org/en/stable/estimator_overview.html) and __tools for composite model building__ including pipelining, ensembling, tuning and reduction that enables users to apply an algorithm for one task to another.\n\nsktime also provides **interfaces to related libraries**, for example [scikit-learn], [statsmodels], [tsfresh], [PyOD] and [fbprophet], among others.\n\nFor **deep learning**, see our companion package: [sktime-dl](https://github.com/sktime/sktime-dl).\n\n[statsmodels]: https://www.statsmodels.org/stable/index.html\n[tsfresh]: https://tsfresh.readthedocs.io/en/latest/\n[pyod]: https://pyod.readthedocs.io/en/latest/\n[fbprophet]: https://facebook.github.io/prophet/\n\n| Module | Status | Links |\n|---|---|---|\n| **[Forecasting]** | stable | [Tutorial](https://www.sktime.org/en/latest/examples/01_forecasting.html) \u00b7 [API Reference](https://www.sktime.org/en/latest/api_reference.html#sktime-forecasting-time-series-forecasting) \u00b7 [Extension Template](https://github.com/sktime/sktime/blob/main/extension_templates/forecasting.py)  |\n| **[Time Series Classification]** | stable | [Tutorial](https://github.com/sktime/sktime/blob/main/examples/02_classification.ipynb) \u00b7 [API Reference](https://www.sktime.org/en/latest/api_reference.html#sktime-classification-time-series-classification) \u00b7 [Extension Template](https://github.com/sktime/sktime/blob/main/extension_templates/classification.py) |\n| **[Time Series Regression]** | stable | [API Reference](https://www.sktime.org/en/latest/api_reference.html#sktime-classification-time-series-regression) |\n| **[Transformations]** | stable | [API Reference](https://www.sktime.org/en/latest/api_reference.html#sktime-transformations-time-series-transformers) \u00b7 [Extension Template](https://github.com/sktime/sktime/blob/main/extension_templates/transformer.py)  |\n| **[Time Series Clustering]** | maturing | [Extension Template](https://github.com/sktime/sktime/blob/main/extension_templates/clustering.py) |\n| **[Time Series Distances/Kernels]** | experimental | [Extension Template](https://github.com/sktime/sktime/blob/main/extension_templates/dist_kern_panel.py) |\n| **[Annotation]** | experimental | [Extension Template](https://github.com/sktime/sktime/blob/main/extension_templates/annotation.py) |\n\n[forecasting]: https://github.com/sktime/sktime/tree/main/sktime/forecasting\n[time series classification]: https://github.com/sktime/sktime/tree/main/sktime/classification\n[time series regression]: https://github.com/sktime/sktime/tree/main/sktime/regression\n[time series clustering]: https://github.com/sktime/sktime/tree/main/sktime/clustering\n[annotation]: https://github.com/sktime/sktime/tree/main/sktime/annotation\n[time series distances/kernels]: https://github.com/sktime/sktime/tree/main/sktime/dists_kernels\n[transformations]: https://github.com/sktime/sktime/tree/main/sktime/transformations\n\n\n## :hourglass_flowing_sand: Install sktime\nFor trouble shooting and detailed installation instructions, see the [documentation](https://www.sktime.org/en/latest/installation.html).\n\n- **Operating system**: macOS X \u00b7 Linux \u00b7 Windows 8.1 or higher\n- **Python version**: Python 3.7, 3.8, 3.9, and 3.10 (only 64 bit)\n- **Package managers**: [pip] \u00b7 [conda] (via `conda-forge`)\n\n[pip]: https://pip.pypa.io/en/stable/\n[conda]: https://docs.conda.io/en/latest/\n\n### pip\nUsing pip, sktime releases are available as source packages and binary wheels. You can see all available wheels [here](https://pypi.org/simple/sktime/).\n\n```bash\npip install sktime\n```\n\nor, with maximum dependencies,\n\n```bash\npip install sktime[all_extras]\n```\n\n### conda\nYou can also install sktime from `conda` via the `conda-forge` channel. For the feedstock including the build recipe and configuration, check out [this repository](https://github.com/conda-forge/sktime-feedstock).\n\n```bash\nconda install -c conda-forge sktime\n```\n\nor, with maximum dependencies,\n\n```bash\nconda install -c conda-forge sktime-all-extras\n```\n\n## :zap: Quickstart\n\n### Forecasting\n\n```python\nfrom sktime.datasets import load_airline\nfrom sktime.forecasting.base import ForecastingHorizon\nfrom sktime.forecasting.model_selection import temporal_train_test_split\nfrom sktime.forecasting.theta import ThetaForecaster\nfrom sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n\ny = load_airline()\ny_train, y_test = temporal_train_test_split(y)\nfh = ForecastingHorizon(y_test.index, is_relative=False)\nforecaster = ThetaForecaster(sp=12)  # monthly seasonal periodicity\nforecaster.fit(y_train)\ny_pred = forecaster.predict(fh)\nmean_absolute_percentage_error(y_test, y_pred)\n>>> 0.08661467738190656\n```\n\n### Time Series Classification\n\n```python\nfrom sktime.classification.interval_based import TimeSeriesForestClassifier\nfrom sktime.datasets import load_arrow_head\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX, y = load_arrow_head()\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nclassifier = TimeSeriesForestClassifier()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\naccuracy_score(y_test, y_pred)\n>>> 0.8679245283018868\n```\n\n## :wave: How to get involved\n\nThere are many ways to join the sktime community. We follow the [all-contributors](https://github.com/all-contributors/all-contributors) specification: all kinds of contributions are welcome - not just code.\n\n| Documentation              |                                                                |\n| -------------------------- | --------------------------------------------------------------        |\n| :gift_heart: **[Contribute]**        | How to contribute to sktime.          |\n| :school_satchel:  **[Mentoring]** | New to open source? Apply to our mentoring program! |\n| :date: **[Meetings]** | Join our discussions, tutorials, workshops and sprints! |\n| :woman_mechanic:  **[Developer Guides]**      | How to further develop sktime's code base.                             |\n| :construction: **[Enhancement Proposals]** | Design a new feature for sktime. |\n| :medal_sports: **[Contributors]** | A list of all contributors. |\n| :raising_hand: **[Roles]** | An overview of our core community roles. |\n| :money_with_wings: **[Donate]** | Fund sktime maintenance and development. |\n| :classical_building: **[Governance]** | How and by whom decisions are made in sktime's community.   |\n\n[contribute]: https://www.sktime.org/en/latest/get_involved/contributing.html\n[donate]: https://opencollective.com/sktime\n[extension templates]: https://github.com/sktime/sktime/tree/main/extension_templates\n[developer guides]: https://www.sktime.org/en/latest/developer_guide.html\n[contributors]: https://github.com/sktime/sktime/blob/main/CONTRIBUTORS.md\n[governance]: https://www.sktime.org/en/latest/governance.html\n[mentoring]: https://github.com/sktime/mentoring\n[meetings]: https://calendar.google.com/calendar/u/0/embed?src=sktime.toolbox@gmail.com&ctz=UTC\n[enhancement proposals]: https://github.com/sktime/enhancement-proposals\n[roles]: https://www.sktime.org/en/latest/about/team.html\n\n## :bulb: Project vision\n\n* **by the community, for the community** -- developed by a friendly and collaborative community.\n* the **right tool for the right task** -- helping users to diagnose their learning problem and suitable scientific model types.\n* **embedded in state-of-art ecosystems** and **provider of interoperable interfaces** -- interoperable with [scikit-learn], [statsmodels], [tsfresh], and other community favourites.\n* **rich model composition and reduction functionality** -- build tuning and feature extraction pipelines, solve forecasting tasks with [scikit-learn] regressors.\n* **clean, descriptive specification syntax** -- based on modern object-oriented design principles for data science.\n* **fair model assessment and benchmarking** -- build your models, inspect your models, check your models, avoid pitfalls.\n* **easily extensible** -- easy extension templates to add your own algorithms compatible with sktime's API.\n",
	"awesome-list cyber-security data-mining machine-learning": "# Awesome Machine Learning for Cyber Security [![Awesom](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\n[<img src=\"https://github.com/jivoi/awesome-ml-for-cybersecurity/raw/master/cyber-ml-logo.png\" align=\"right\" width=\"100\">](https://github.com/jivoi/awesome-ml-for-cybersecurity)\n\nA curated list of amazingly awesome tools and resources related to the use of machine learning for cyber security.\n\n## Table of Contents\n\n - [Datasets](#-datasets)\n - [Papers](#-papers)\n - [Books](#-books)\n - [Talks](#-talks)\n - [Tutorials](#-tutorials)\n - [Courses](#-courses)\n - [Miscellaneous](#-miscellaneous)\n\n## [\u2191](#table-of-contents) Contributing\n\nPlease read [CONTRIBUTING](./CONTRIBUTING.md) if you wish to add tools or resources.\n\n## [\u2191](#table-of-contents) Datasets\n\n* [HIKARI-2021 Datasets](https://zenodo.org/record/5199540)\n* [Samples of Security Related Data](http://www.secrepo.com/)\n* [DARPA Intrusion Detection Data Sets](https://www.ll.mit.edu/r-d/datasets) [ [1998](https://www.ll.mit.edu/r-d/datasets/1998-darpa-intrusion-detection-evaluation-dataset) / [1999](https://www.ll.mit.edu/r-d/datasets/1999-darpa-intrusion-detection-evaluation-dataset) ]\n* [Stratosphere IPS Data Sets](https://stratosphereips.org/category/dataset.html)\n* [Open Data Sets](http://csr.lanl.gov/data/)\n* [Data Capture from National Security Agency](http://www.westpoint.edu/crc/SitePages/DataSets.aspx)\n* [The ADFA Intrusion Detection Data Sets](https://www.unsw.adfa.edu.au/australian-centre-for-cyber-security/cybersecurity/ADFA-IDS-Datasets/)\n* [NSL-KDD Data Sets](https://github.com/defcom17/NSL_KDD)\n* [Malicious URLs Data Sets](http://sysnet.ucsd.edu/projects/url/)\n* [Multi-Source Cyber-Security Events](http://csr.lanl.gov/data/cyber1/)\n* [KDD Cup 1999 Data](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)\n* [Web Attack Payloads](https://github.com/foospidy/payloads)\n* [WAF Malicious Queries Data Sets](https://github.com/faizann24/Fwaf-Machine-Learning-driven-Web-Application-Firewall)\n* [Malware Training Data Sets](https://github.com/marcoramilli/MalwareTrainingSets)\n* [Aktaion Data Sets](https://github.com/jzadeh/Aktaion/tree/master/data)\n* [CRIME Database from DeepEnd Research](https://www.dropbox.com/sh/7fo4efxhpenexqp/AADHnRKtL6qdzCdRlPmJpS8Aa/CRIME?dl=0)\n* [Publicly available PCAP files](http://www.netresec.com/?page=PcapFiles)\n* [2007 TREC Public Spam Corpus](https://plg.uwaterloo.ca/~gvcormac/treccorpus07/)\n* [Drebin Android Malware Dataset](https://www.sec.cs.tu-bs.de/~danarp/drebin/)\n* [PhishingCorpus Datset](https://monkey.org/~jose/phishing/)\n* [EMBER](https://github.com/endgameinc/ember)\n* [Vizsec Research](https://vizsec.org/data/)\n* [SHERLOCK](http://bigdata.ise.bgu.ac.il/sherlock/index.html#/)\n* [Probing / Port Scan - Dataset ](https://github.com/gubertoli/ProbingDataset)\n* [Aegean Wireless Intrusion Dataset (AWID)](http://icsdweb.aegean.gr/awid/)\n* [BODMAS PE Malware Dataset](https://whyisyoung.github.io/BODMAS/)\n\n## [\u2191](#table-of-contents) Papers\n\n* [Generating Network Intrusion Detection Dataset Based on Real and Encrypted Synthetic Attack Traffic](https://www.mdpi.com/2076-3417/11/17/7868/htm)\n* [Fast, Lean, and Accurate: Modeling Password Guessability Using Neural Networks](https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/melicher)\n* [Outside the Closed World: On Using Machine Learning for Network Intrusion Detection](http://ieeexplore.ieee.org/document/5504793/?reload=true)\n* [Anomalous Payload-Based Network Intrusion Detection](https://link.springer.com/chapter/10.1007/978-3-540-30143-1_11)\n* [Malicious PDF detection using metadata and structural features](http://dl.acm.org/citation.cfm?id=2420987)\n* [Adversarial support vector machine learning](https://dl.acm.org/citation.cfm?id=2339697)\n* [Exploiting machine learning to subvert your spam filter](https://dl.acm.org/citation.cfm?id=1387709.1387716)\n* [CAMP \u2013 Content Agnostic Malware Protection](http://www.covert.io/research-papers/security/CAMP%20-%20Content%20Agnostic%20Malware%20Protection.pdf)\n* [Notos \u2013 Building a Dynamic Reputation System for DNS](http://www.covert.io/research-papers/security/Notos%20-%20Building%20a%20dynamic%20reputation%20system%20for%20dns.pdf)\n* [Kopis \u2013 Detecting malware domains at the upper dns hierarchy](http://www.covert.io/research-papers/security/Kopis%20-%20Detecting%20malware%20domains%20at%20the%20upper%20dns%20hierarchy.pdf)\n* [Pleiades \u2013 From Throw-away Traffic To Bots \u2013 Detecting The Rise Of DGA-based Malware](http://www.covert.io/research-papers/security/From%20throw-away%20traffic%20to%20bots%20-%20detecting%20the%20rise%20of%20dga-based%20malware.pdf)\n* [EXPOSURE \u2013 Finding Malicious Domains Using Passive DNS Analysis](http://www.covert.io/research-papers/security/Exposure%20-%20Finding%20malicious%20domains%20using%20passive%20dns%20analysis.pdf)\n* [Polonium \u2013 Tera-Scale Graph Mining for Malware Detection](http://www.covert.io/research-papers/security/Polonium%20-%20Tera-Scale%20Graph%20Mining%20for%20Malware%20Detection.pdf)\n* [Nazca \u2013 Detecting Malware Distribution in Large-Scale Networks](http://www.covert.io/research-papers/security/Nazca%20-%20%20Detecting%20Malware%20Distribution%20in%20Large-Scale%20Networks.pdf)\n* [PAYL \u2013 Anomalous Payload-based Network Intrusion Detection](http://www.covert.io/research-papers/security/PAYL%20-%20Anomalous%20Payload-based%20Network%20Intrusion%20Detection.pdf)\n* [Anagram \u2013 A Content Anomaly Detector Resistant to Mimicry Attacks](http://www.covert.io/research-papers/security/Anagram%20-%20A%20Content%20Anomaly%20Detector%20Resistant%20to%20Mimicry%20Attack.pdf)\n* [Applications of Machine Learning in Cyber Security](https://www.researchgate.net/publication/283083699_Applications_of_Machine_Learning_in_Cyber_Security)\n* [Data Mining \u0434\u043b\u044f \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u0441\u0438\u0441\u0442\u0435\u043c \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u0441\u0435\u0442\u0435\u0432\u044b\u0445 \u0430\u0442\u0430\u043a (RUS)](http://vak.ed.gov.ru/az/server/php/filer.php?table=att_case&fld=autoref&key%5B%5D=100003407)\n* [\u0412\u044b\u0431\u043e\u0440 \u0442\u0435\u0445\u043d\u043e\u043b\u043e\u0433\u0438\u0439 Data Mining \u0434\u043b\u044f \u0441\u0438\u0441\u0442\u0435\u043c \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u0432\u0442\u043e\u0440\u0436\u0435\u043d\u0438\u0439 \u0432 \u043a\u043e\u0440\u043f\u043e\u0440\u0430\u0442\u0438\u0432\u043d\u0443\u044e \u0441\u0435\u0442\u044c (RUS)](http://engjournal.ru/articles/987/987.pdf)\n* [\u041d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0435\u0432\u043e\u0439 \u043f\u043e\u0434\u0445\u043e\u0434 \u043a \u0438\u0435\u0440\u0430\u0440\u0445\u0438\u0447\u0435\u0441\u043a\u043e\u043c\u0443 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u044e \u043a\u043e\u043c\u043f\u044c\u044e\u0442\u0435\u0440\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u0432 \u0437\u0430\u0434\u0430\u0447\u0430\u0445 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0431\u0435\u0437\u043e\u043f\u0430\u0441\u043d\u043e\u0441\u0442\u0438 (RUS)](http://engjournal.ru/articles/534/534.pdf)\n* [\u041c\u0435\u0442\u043e\u0434\u044b \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0443\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u0435 \u0432\u0442\u043e\u0440\u0436\u0435\u043d\u0438\u0439 (RUS)](http://vestnik.sibsutis.ru/uploads/1459329553_3576.pdf)\n* [Dimension Reduction in Network Attacks Detection Systems](http://elib.bsu.by/bitstream/123456789/120105/1/v17no3p284.pdf)\n* [Rise of the machines: Machine Learning & its cyber security applications](https://www.nccgroup.trust/globalassets/our-research/uk/whitepapers/2017/rise-of-the-machines-preliminaries-wp-new-template-final_web.pdf)\n* [Machine Learning in Cyber Security: Age of the Centaurs](https://go.recordedfuture.com/hubfs/white-papers/machine-learning.pdf)\n* [Automatically Evading Classifiers A Case Study on PDF Malware Classifiers](https://www.cs.virginia.edu/~evans/pubs/ndss2016/)\n* [Weaponizing Data Science for Social Engineering\u200a\u2014\u200aAutomated E2E Spear Phishing on Twitter](https://www.blackhat.com/docs/us-16/materials/us-16-Seymour-Tully-Weaponizing-Data-Science-For-Social-Engineering-Automated-E2E-Spear-Phishing-On-Twitter.pdf)\n* [Machine Learning: A Threat-Hunting Reality Check](https://s3-eu-central-1.amazonaws.com/evermade-fsecure-assets/wp-content/uploads/2019/09/17153425/countercept-whitepaper-machine-learning.pdf)\n* [Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection](https://arxiv.org/abs/1708.06525)\n* [Practical Secure Aggregation for Privacy-Preserving Machine Learning](https://eprint.iacr.org/2017/281.pdf)\n* [DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning](https://acmccs.github.io/papers/p1285-duA.pdf)\n* [eXpose: A Character-Level Convolutional Neural Network with Embeddings For Detecting Malicious URLs, File Paths and Registry Keys](https://arxiv.org/pdf/1702.08568.pdf)\n* [Big Data Technologies for Security Event Correlation Based on Event Type Accounting (RUS)](http://cyberrus.com/wp-content/uploads/2018/02/2-16-524-17_1.-Kotenko.pdf)\n* [Investigation of The Use of Neural Networks for Detecting Low-Intensive Dd\u043es-Atak of Applied Level (RUS)](http://cyberrus.com/wp-content/uploads/2018/02/23-29-524-17_3.-Tarasov.pdf)\n* [Detecting Malicious PowerShell Commands using Deep Neural Networks](https://arxiv.org/pdf/1804.04177.pdf)\n* [Machine Learning DDoS Detection for Consumer Internet of Things Devices](https://arxiv.org/pdf/1804.04159.pdf)\n* [Anomaly Detection in Computer System\nby Intellectual Analysis of System Journals (RUS)](http://cyberrus.com/wp-content/uploads/2018/06/33-43-226-18_4.-Sheluhin.pdf)\n* [EMBER: An Open Dataset for Training Static PE Malware Machine Learning Models](https://arxiv.org/pdf/1804.04637.pdf)\n* [A state-of-the-art survey of malware detection approaches using data mining techniques.](https://link.springer.com/article/10.1186/s13673-018-0125-x)\n* [Investigation of malicious portable executable file detection on network using supervised learning techniques.](https://www.researchgate.net/publication/318665164_Investigation_of_malicious_portable_executable_file_detection_on_the_network_using_supervised_learning_techniques)\n* [Machine Learning in Cybersecurity: A Guide](https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=633583)\n* [Outside the Closed World: On Using Machine Learning For Network Intrusion Detection](https://personal.utdallas.edu/~muratk/courses/dmsec_files/oakland10-ml.pdf)\n* [Machine Learning Based Network Vulnerability Analysis of Industrial Internet of Things](https://arxiv.org/abs/1911.05771)\n* [Hopper: Modeling and Detecting Lateral Movement](https://arxiv.org/pdf/2105.13442.pdf1)\n* [Finding Effective Security Strategies through Reinforcement Learning and Self-Play](https://arxiv.org/abs/2009.08120)\n* [Intrusion Prevention through Optimal Stopping](https://arxiv.org/abs/2111.00289)\n\n## [\u2191](#table-of-contents) Books\n\n* [Data Mining and Machine Learning in Cybersecurity](https://www.amazon.com/Data-Mining-Machine-Learning-Cybersecurity/dp/1439839425)\n* [Machine Learning and Data Mining for Computer Security](https://www.amazon.com/Machine-Learning-Mining-Computer-Security/dp/184628029X)\n* [Network Anomaly Detection: A Machine Learning Perspective](https://www.amazon.com/Network-Anomaly-Detection-Learning-Perspective/dp/1466582081)\n* [Machine Learning and Security: Protecting Systems with Data and Algorithms](https://www.amazon.com/Machine-Learning-Security-Protecting-Algorithms/dp/1491979909)\n* [Introduction To Artificial Intelligence For Security Professionals](https://github.com/cylance/IntroductionToMachineLearningForSecurityPros/blob/master/IntroductionToArtificialIntelligenceForSecurityProfessionals_Cylance.pdf)\n* [Mastering Machine Learning for Penetration Testing](https://www.packtpub.com/networking-and-servers/mastering-machine-learning-penetration-testing)\n* [Malware Data Science: Attack Detection and Attribution](https://nostarch.com/malwaredatascience)\n\n## [\u2191](#table-of-contents) Talks\n\n* [Using Machine Learning to Support Information Security](https://www.youtube.com/watch?v=tukidI5vuBs)\n* [Defending Networks with Incomplete Information](https://www.youtube.com/watch?v=36IT9VgGr0g)\n* [Applying Machine Learning to Network Security Monitoring](https://www.youtube.com/watch?v=vy-jpFpm1AU)\n* [Measuring the IQ of your Threat Intelligence Feeds](https://www.youtube.com/watch?v=yG6QlHOAWiE)\n* [Data-Driven Threat Intelligence: Metrics On Indicator Dissemination And Sharing](https://www.youtube.com/watch?v=6JMEKnes-w0)\n* [Applied Machine Learning for Data Exfil and Other Fun Topics](https://www.youtube.com/watch?v=dGwH7m4N8DE)\n* [Secure Because Math: A Deep-Dive on ML-Based Monitoring](https://www.youtube.com/watch?v=TYVCVzEJhhQ)\n* [Machine Duping 101: Pwning Deep Learning Systems](https://www.youtube.com/watch?v=JAGDpJFFM2A)\n* [Delta Zero, KingPhish3r \u2013 Weaponizing Data Science for Social Engineering](https://www.youtube.com/watch?v=l7U0pDcsKLg)\n* [Defeating Machine Learning What Your Security Vendor Is Not Telling You](https://www.youtube.com/watch?v=oiuS1DyFNd8)\n* [CrowdSource: Crowd Trained Machine Learning Model for Malware Capability Det](https://www.youtube.com/watch?v=u6a7afsD39A)\n* [Defeating Machine Learning: Systemic Deficiencies for Detecting Malware](https://www.youtube.com/watch?v=sPtbDUJjhbk)\n* [Packet Capture Village \u2013 Theodora Titonis \u2013 How Machine Learning Finds Malware](https://www.youtube.com/watch?v=2cQRSPFSY-s)\n* [Build an Antivirus in 5 Min \u2013 Fresh Machine Learning #7. A fun video to watch](https://www.youtube.com/watch?v=iLNHVwSu9EA&t=245s)\n* [Hunting for Malware with Machine Learning](https://www.youtube.com/watch?v=zT-4zdtvR30)\n* [Machine Learning for Threat Detection](https://www.youtube.com/watch?v=qVwktOa-F34)\n* [Machine Learning and the Cloud: Disrupting Threat Detection and Prevention](https://www.youtube.com/watch?v=fRklX97iGIw)\n* [Fraud detection using machine learning & deep learning](https://www.youtube.com/watch?v=gHtN4jU69W0)\n* [The Applications Of Deep Learning On Traffic Identification](https://www.youtube.com/watch?v=yZ-Y1WCM0lc)\n* [Defending Networks With Incomplete Information: A Machine Learning Approach](https://www.youtube.com/watch?v=_0CRSF6yPB4)\n* [Machine Learning & Data Science](https://vimeo.com/112702666)\n* [Advances in Cloud-Scale Machine Learning for Cyber-Defense](https://www.youtube.com/watch?v=skSIIvvZFIk)\n* [Applied Machine Learning: Defeating Modern Malicious Documents](https://www.youtube.com/watch?v=ZAuCEgA3itI)\n* [Automated Prevention of Ransomware with Machine Learning and GPOs](https://www.rsaconference.com/writable/presentations/file_upload/spo2-t11_automated-prevention-of-ransomware-with-machine-learning-and-gpos.pdf)\n* [Learning to Detect Malware by Mining the Security Literature](https://www.usenix.org/conference/enigma2017/conference-program/presentation/dumitras)\n* [Clarence Chio and Anto Joseph - Practical Machine Learning in Infosecurity](https://conference.hitb.org/hitbsecconf2017ams/materials/D1T3%20-%20Clarence%20Chio%20and%20Anto%20Joseph%20-%20Practical%20Machine%20Learning%20in%20Infosecurity.pdf)\n* [Advances in Cloud-Scale Machine Learning for Cyberdefense](https://www.youtube.com/watch?v=6Slj2FV9CLA)\n* [Machine Learning-Based Techniques For Network Intrusion Detection](https://www.youtube.com/watch?v=-EUJgpiJ8Jo)\n* [Practical Machine Learning in Infosec](https://www.youtube.com/watch?v=YF2dm6GZf2U)\n* [AI and Security](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/AI_and_Security_Dawn_Song.pdf)\n* [AI in InfoSec](https://vimeo.com/230502013)\n* [Beyond the Blacklists: Detecting Malicious URL Through Machine Learning](https://www.youtube.com/watch?v=Kd3svc9HZ0Y)\n* [Machine Learning Fueled Cyber Threat Hunting](https://www.youtube.com/watch?v=c-c-IQ5pFXw)\n* [Weaponizing Machine Learning: Humanity Was Overrated](https://www.youtube.com/watch?v=QbX7BhjOOvY)\n* [Machine Learning, Offense, and the future of Automation](https://www.youtube.com/watch?v=BWFdxAG_TGk)\n* [Bringing Red vs. Blue to Machine Learning](https://www.youtube.com/watch?v=e5O0Oxt5dYI)\n* [Explaining Machine Learning with Azure and the Titanic Dataset](https://www.youtube.com/watch?v=x1DfjUEYm0k)\n* [Using Machines to exploit Machines](https://www.youtube.com/watch?v=VuLvzL-WbBQ)\n* [Analyze active directory event logs using visualize and ML](https://www.youtube.com/watch?v=ISbbzaCGBns)\n* [Hardening Machine Learning Defenses Against Adversarial Attacks](https://www.youtube.com/watch?v=CAwua_lugV8)\n* [Deep Neural Networks for Hackers: Methods, Applications, and Open Source Tools](https://www.youtube.com/watch?v=fKJ8sTi6H88)\n* [ML in the daily work of a threat hunter](https://www.youtube.com/watch?v=vWMRVhDCpao)\n* [The Real Deal About AI: ML for CyberSecurity - Josh Fu](https://www.youtube.com/watch?v=RzakalH1eL8)\n* [Automated Detection of Software Vulnerabilities Using Deep-Learning](https://www.youtube.com/watch?v=tpzT8ppx5-s)\n* [Building and Breaking a Machine Learning System - Johann Rehberger](https://www.youtube.com/watch?v=-SV80sIBhqY)\n* [Vulnerabilities of Machine Learning Infrastructure - Sergey Gordeychik](https://www.youtube.com/watch?v=5bWyY3kocdE)\n\n## [\u2191](#table-of-contents) Tutorials\n\n* [Machine Learning based Password Strength Classification](http://web.archive.org/web/20170606022743/http://fsecurify.com/machine-learning-based-password-strength-checking/)\n* [Using Machine Learning to Detect Malicious URLs](http://web.archive.org/web/20170514093208/http://fsecurify.com/using-machine-learning-detect-malicious-urls/)\n* [Using deep learning to break a Captcha system](https://deepmlblog.wordpress.com/2016/01/03/how-to-break-a-captcha-system/)\n* [Data mining for network security and intrusion detection](https://www.r-bloggers.com/data-mining-for-network-security-and-intrusion-detection/)\n* [Applying Machine Learning to Improve Your Intrusion Detection System](https://securityintelligence.com/applying-machine-learning-to-improve-your-intrusion-detection-system/)\n* [Analyzing BotNets with Suricata & Machine Learning](http://blogs.splunk.com/2017/01/30/analyzing-botnets-with-suricata-machine-learning/)\n* [fWaf \u2013 Machine learning driven Web Application Firewall](http://web.archive.org/web/20170706222016/http://fsecurify.com/fwaf-machine-learning-driven-web-application-firewall/)\n* [Deep Session Learning for Cyber Security](https://blog.cyberreboot.org/deep-session-learning-for-cyber-security-e7c0f6804b81#.eo2m4alid)\n* [DMachine Learning for Malware Detection](http://resources.infosecinstitute.com/machine-learning-malware-detection/)\n* [ShadowBrokers Leak: A Machine Learning Approach](https://marcoramilli.blogspot.ru/2017/04/shadowbrokers-leak-machine-learning.html)\n* [Practical Machine Learning in Infosec - Virtualbox Image and Stuff](https://docs.google.com/document/d/1v4plS1EhLBfjaz-9GHBqspTH7vnrJfqLrLjeP9k9i9A/edit)\n* [A Machine-Learning Toolkit for Large-scale eCrime Forensics](http://blog.trendmicro.com/trendlabs-security-intelligence/defplorex-machine-learning-toolkit-large-scale-ecrime-forensics/)\n* [WebShells Detection by Machine Learning](https://github.com/lcatro/WebShell-Detect-By-Machine-Learning)\n* [Building Machine Learning Models for the SOC](https://www.fireeye.com/blog/threat-research/2018/06/build-machine-learning-models-for-the-soc.html)\n* [Detecting Web Attacks With Recurrent Neural Networks](https://aivillage.org/posts/detecting-web-attacks-rnn/)\n* [Machine Learning for Red Teams, Part 1](https://silentbreaksecurity.com/machine-learning-for-red-teams-part-1/)\n* [Detecting Reverse Shell with Machine Learning](https://www.cyberbit.com/blog/endpoint-security/detecting-reverse-shell-with-machine-learning/)\n* [Obfuscated Command Line Detection Using Machine Learning](https://www.fireeye.com/blog/threat-research/2018/11/obfuscated-command-line-detection-using-machine-learning.html)\n* [\u041e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u0435 \u0432\u0435\u0431-\u0430\u0442\u0430\u043a \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0440\u0435\u043a\u0443\u0440\u0440\u0435\u043d\u0442\u043d\u044b\u0445 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u0435\u0439 (RUS)](https://habr.com/ru/company/pt/blog/439202/)\n* [Clear and Creepy Danger of Machine Learning: Hacking Passwords](https://towardsdatascience.com/clear-and-creepy-danger-of-machine-learning-hacking-passwords-a01a7d6076d5)\n* [Discovering anomalous patterns based on parent-child process relationships](https://www.elastic.co/cn/blog/discovering-anomalous-patterns-based-on-parent-child-process-relationships)\n* [Machine Learning for Detecting Phishing Websites](https://faizanahmad.tech/blog/2020/02/phishytics-machine-learning-for-phishing-websites-detection/)\n* [Password Hunting with ML in Active Directory](https://blog.hunniccyber.com/password-hunting-with-ml-in-active-directory/)\n* [\u041a\u0430\u043a \u0441\u0430\u043c\u043e\u043c\u0443 \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0441\u0438\u0441\u0442\u0435\u043c\u0443 \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u043a\u043e\u043c\u043f\u044c\u044e\u0442\u0435\u0440\u043d\u044b\u0445 \u0430\u0442\u0430\u043a \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f (RUS)](https://habr.com/ru/post/538296/)\n\n## [\u2191](#table-of-contents) Courses\n\n* [Data Mining for Cyber Security by Stanford](http://web.stanford.edu/class/cs259d/)\n* [Data Science and Machine Learning for Infosec](http://www.pentesteracademy.com/course?id=30)\n* [Cybersecurity Data Science on Udemy](https://www.udemy.com/cybersecurity-data-science)\n* [Machine Learning for Red Team Hackers on Udemy](https://www.udemy.com/course/machine-learning-for-red-team-hackers/)\n* [Machine Learning for Security](https://security.kiwi/docs/introduction/)\n\n## [\u2191](#table-of-contents) Miscellaneous\n\n* [System predicts 85 percent of cyber-attacks using input from human experts](http://news.mit.edu/2016/ai-system-predicts-85-percent-cyber-attacks-using-input-human-experts-0418)\n* [A list of open source projects in cyber security using machine learning](http://www.mlsecproject.org/#open-source-projects)\n* [Source code about machine learning and security](https://github.com/13o-bbr-bbq/machine_learning_security)\n* [Source code for Mastering Machine Learning for Penetration Testing](https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing)\n* [Convolutional neural network for analyzing pentest screenshots](https://github.com/BishopFox/eyeballer)\n* [Big Data and Data Science for Security and Fraud Detection](http://www.kdnuggets.com/2015/12/big-data-science-security-fraud-detection.html)\n* [StringSifter - a machine learning tool that ranks strings based on their relevance for malware analysis](https://github.com/fireeye/stringsifter)\n\n## License\n\n![cc license](http://i.creativecommons.org/l/by-sa/4.0/88x31.png)\n\nThis work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International](http://creativecommons.org/licenses/by-sa/4.0/) license.\n",
	"algorithm artificial-intelligence caffe cv data-analysis data-mining data-science deep-learning keras machine-learning mathematics matplotlib nlp numpy pandas python pytorch seaborn tensorflow tensorflow2": "<div align=\"center\">\r\n<a href=\"https://github.com/tangyudi/Ai-learn\"><img src=\"https://github.com/tangyudi/Ai-learn/blob/master/imgs/logo2.png\" width=\"400\"/></a>\r\n<br >\r\n<a class=\"ai-header-badge\" target=\"_blank\" href=\"https://github.com/tangyudi/Ai-learn\">\r\n<img class=\"ai-header-badge-img\" src=\"https://img.shields.io/github/stars/tangyudi/Ai-learn.svg?style=social&label=Star\">\r\n</a>\r\n\r\n<a class=\"ai-header-badge\" target=\"_blank\" href=\"https://github.com/tangyudi/Ai-learn/blob/master/imgs/logo8.png\">\r\n<img src=\"https://img.shields.io/badge/style--5eba00.svg?label=WeChat&logo=wechat&style=social\">\r\n</a>\r\n\r\n<sub>Created by\r\n<a href=\"https://github.com/tangyudi\" target=\"_blank\">\u5510\u5b87\u8fea</a> \r\n</sub>\r\n</div>\r\n\r\n# \u4eba\u5de5\u667a\u80fd\u5b9e\u6218\u5c31\u4e1a(\u9762\u8bd5)\u5b66\u4e60\u8def\u7ebf\u56fe\r\n\r\n- [x] \u8fd9\u4e2a\u9879\u76ee\u662f\u5e72\u4ec0\u4e48\u7684\uff1f\r\n\r\n**\u8d44\u6599\u5b58\u5728\u592a\u591a\u6570\u636e\u96c6\uff0c\u767e\u5ea6\u7f51\u76d8\u88ab\u4e3e\u62a5\u540e\u5df2\u7ecf\u65e0\u6cd5\u5206\u4eab\u94fe\u63a5\uff0c\u540e\u7eed\u5c06\u63d0\u4f9b\u8c37\u6b4c\u7f51\u76d8**\r\n\r\n**\u9886\u53d6\u8d44\u6599\u8bf7\u76f4\u63a5\u52a0\u5fae\u4fe1\uff1aGp00006666** \uff08\u9a8c\u8bc1\u4fe1\u606f\u5907\u6ce8GITHUB\u5373\u53ef\uff09\r\n\r\n\u6574\u7406\u8fd9\u4e2a\u9879\u76ee\u7684\u521d\u8877\u662f\u65b9\u4fbf\u540c\u5b66\u4eec\u5feb\u901f\u5f00\u542f\u4eba\u5de5\u667a\u80fd\u81ea\u5b66\u8ba1\u5212\uff0c\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u5c11\u8d70\u5f2f\u8def\u7528\u6700\u5feb\u7684\u6548\u7387\u5165\u95e8Ai\u5e76\u5f00\u59cb\u5b9e\u6218\u9879\u76ee\uff0c\r\n\u63d0\u4f9b\u4e86\u8fd1**200\u4e2aAi\u5b9e\u6218\u6848\u4f8b\u548c\u9879\u76ee**\uff0c\u8fd9\u4e9b\u5e76\u4e0d\u662f\u7f51\u4e0a\u641c\u96c6\u6765\u7684\uff0c\u800c\u662f\u6211\u8fd9\u4e94\u5e74\u7ebf\u4e0a\u7ebf\u4e0b\u6559\u5b66\u6240\u5f00\u53d1\u548c\u79ef\u7d2f\u7684\u6848\u4f8b\u3002\u53ef\u4ee5\u8bf4\u90fd\u662f\r\n\u53cd\u590d\u8fed\u4ee3\u66f4\u65b0\u51fa\u6765\u7684\uff0c\u9002\u5408\u540c\u5b66\u4eec\u6765\u8fdb\u884c\u5faa\u5e8f\u6e10\u8fdb\u7684\u5b66\u4e60\u4e0e\u7ec3\u624b\u3002**\u6765\u7684\u540c\u5b66\u8bb0\u5f97\u70b9\u4e2astar\u6536\u85cf\u4e0b\uff01**\r\n\r\n- [x] \u914d\u5957\u6559\u6750\u5982\u4f55\u83b7\u53d6\uff1f\r\n\r\n19\u5e74\u5e95\u6211\u51fa\u7248\u4e86\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b\u7684\u914d\u5957\u6559\u6750\u300a\u8ddf\u7740\u8fea\u54e5\u5b66Python\u6570\u636e\u5206\u6790\u4e0e\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u300b\uff0c\r\n\u98ce\u683c\u4f9d\u65e7\u662f\u901a\u4fd7\u6613\u61c2\uff0c\u5386\u65f6\u4e24\u5e74\u53cd\u590d\u4fee\u6539\u8ba2\u6b63\u5341\u4f59\u6b21\u7ec8\u4e8e\u548c\u5927\u5bb6\u89c1\u9762\u4e86\u3002\r\n\u4e3a\u4e86\u65b9\u4fbf\u66f4\u591a\u540c\u5b66\u4eec\u80fd\u5feb\u901f\u5f00\u59cb\u5b66\u4e60\u8ba1\u5212\uff0c\u6211\u51b3\u5b9a\u5c06\u672c\u4e66\u7684**\u7535\u5b50\u7248\u514d\u8d39\u9001\u7ed9\u5927\u5bb6**\u3002\u5e0c\u671b\u5b83\u80fd\u7ed9\u5927\u5bb6\u5e26\u6765\u5b66\u4e60\u7684\u6536\u83b7\uff01\r\n\u5728\u672c\u9879\u76ee\u4e3b\u9875\u5373\u53ef\u4e0b\u8f7dPDF\u7248\u672c\uff0c[\u6559\u6750\u5982\u679c\u559c\u6b22\u4e5f\u53ef\u4ece\u4eac\u4e1c\u8d2d\u4e70\u3002](https://item.jd.com/12684940.html)\r\n\r\n**\u300a\u8ddf\u7740\u8fea\u54e5\u5b66Python\u6570\u636e\u5206\u6790\u4e0e\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u300bPDF\u539f\u7248\u4e0b\u8f7d** \uff1a\r\n\r\n(\u7f51\u76d8\u94fe\u63a5: https://pan.baidu.com/s/19wzJeyPmwTBDp9ASEWBvFQ \u63d0\u53d6\u7801: tece )\r\n\r\n- [x] \u6309\u7167\u4ec0\u4e48\u987a\u5e8f\u5f00\u59cb\u5b66\u4e60\uff1f\r\n\r\n\u4e0b\u9762\u76ee\u5f55\u4e5f\u5c31\u662f\u5b66\u4e60\u8def\u7ebf\u8def\u4e86\uff0c\u521d\u5b66\u8005\u5efa\u8bae\u6309\u7167\u76ee\u5f55\u4e2d\u7ed9\u51fa\u7684\u987a\u5e8f\u6765\u8fdb\u884c\u5b66\u4e60\uff0c\u5df2\u7ecf\u5165\u95e8\u7684\u540c\u5b66\u5c31\u53ef\u4ee5\u6309\u7167\u81ea\u5df1\u7684\u559c\u597d\u6765\u9009\u62e9\u4e86\u3002\r\n\r\n- [x] \u63d0\u4f9b\u6848\u4f8b\u5982\u4f55\u83b7\u53d6\uff1f\r\n\r\n\u6848\u4f8b\u4e2d\u6d89\u53ca\u7684\u6570\u636e\u90fd\u662f\u771f\u5b9e\u6570\u636e\u96c6\uff0c\u6709\u4e9b\u4f1a\u6bd4\u8f83\u5e9e\u5927\uff0c\u76f4\u63a5\u4e0a\u4f20github\u5927\u5bb6\u4e0b\u8f7d\u8d77\u6765\u4f1a\u975e\u5e38\u6162\uff0c\u6211\u4f1a\u9010\u6e10\u4e0a\u4f20\u5404\u4e2a\u6a21\u5757\r\n\u7684\u7f51\u76d8\u94fe\u63a5\uff0c\u91cc\u9762\u5305\u62ec\u4e86\u6570\u636e\uff0c\u4ee3\u7801\uff0cPPT\u7b49\u5b66\u4e60\u8d44\u6e90\u3002\u5982\u9700\u914d\u5957\u89c6\u9891\u8bb2\u89e3\u8bf7\u6dfb\u52a0**\u5fae\u4fe1\uff1adigexiaozhushou\uff08\u8fea\u54e5\u5c0f\u52a9\u624b\u62fc\u97f3\uff09**\r\n\r\n- [x] \u5408\u4f5c\u4e0e\u4ea4\u6d41\r\n\r\n\u6709\u5404\u65b9\u9762\u5408\u4f5c\u4ea4\u6d41\u4ee5\u53ca\u9879\u76ee\u95ee\u9898\u90fd\u53ef\u4ee5\u76f4\u63a5\u6dfb\u52a0**\u5fae\u4fe1:digexiaozhushou\uff08\u8fea\u54e5\u5c0f\u52a9\u624b\u62fc\u97f3\uff09**\r\n\r\n# \u76ee\u5f55  \r\n- [\u5fc5\u5907\u57fa\u7840\u6280\u80fd](#\u5fc5\u5907\u57fa\u7840\u6280\u80fd)\r\n  - [\u5fc5\u5907Python\u57fa\u7840](#\u5fc5\u5907Python\u57fa\u7840) \r\n  - [\u5fc5\u5907\u6570\u5b66\u57fa\u7840](#\u5fc5\u5907\u6570\u5b66\u57fa\u7840)   \r\n  - [\u5fc5\u5907Python\u5de5\u5177\u5305](#\u5fc5\u5907Python\u5de5\u5177\u5305) \r\n- [\u673a\u5668\u5b66\u4e60](#\u673a\u5668\u5b66\u4e60)\r\n  - [\u673a\u5668\u5b66\u4e60\u7b97\u6cd5](#\u673a\u5668\u5b66\u4e60\u7b97\u6cd5) \r\n  - [\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5b9e\u9a8c\u5206\u6790](#\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5b9e\u9a8c\u5206\u6790) \r\n  - [\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4ee3\u7801\u590d\u73b0](#\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4ee3\u7801\u590d\u73b0) \r\n  - [\u673a\u5668\u5b66\u4e60\u7ecf\u5178\u6848\u4f8b\u5b9e\u6218](#\u673a\u5668\u5b66\u4e60\u7ecf\u5178\u6848\u4f8b\u5b9e\u6218)\r\n  - [\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u96c6\u9526](#\u673a\u5668\u5b66\u4e60\u5b9e\u6218\u96c6\u9526)   \r\n- [\u6570\u636e\u5206\u6790\u4e0e\u6316\u6398](#\u6570\u636e\u5206\u6790\u4e0e\u6316\u6398) \r\n  - [\u6570\u636e\u6316\u6398\u5b9e\u6218](#\u6570\u636e\u6316\u6398\u5b9e\u6218) \r\n  - [\u6570\u636e\u6316\u6398\u7ade\u8d5b\u4f18\u80dc\u89e3\u51b3\u65b9\u6848](#\u6570\u636e\u6316\u6398\u7ade\u8d5b\u4f18\u80dc\u89e3\u51b3\u65b9\u6848) \r\n  - [\u6570\u636e\u5206\u6790\u5b9e\u6218](#\u6570\u636e\u5206\u6790\u5b9e\u6218) \r\n- [\u6df1\u5ea6\u5b66\u4e60](#\u6df1\u5ea6\u5b66\u4e60) \r\n  - [\u6df1\u5ea6\u5b66\u4e60\u5fc5\u5907\u7b97\u6cd5](#\u6df1\u5ea6\u5b66\u4e60\u5fc5\u5907\u7b97\u6cd5) \r\n  - [\u6df1\u5ea6\u5b66\u4e60\u5fc5\u5907\u5de5\u5177](#\u673a\u5668\u5b66\u4e60\u7b97\u6cd5) \r\n- [\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6](#\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6)\r\n  - [\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Tensorflow2](#\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Tensorflow2) \r\n  - [\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Pytorch](#\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Pytorch) \r\n  - [\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Keras](#\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Keras) \r\n  - [\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Caffe](#\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Caffe)\r\n- [\u8ba1\u7b97\u673a\u89c6\u89c9](#\u8ba1\u7b97\u673a\u89c6\u89c9)\r\n  - [Opencv\u56fe\u50cf\u5904\u7406\u5b9e\u6218](#Opencv\u56fe\u50cf\u5904\u7406\u5b9e\u6218) \r\n  - [\u8ba1\u7b97\u673a\u89c6\u89c9\u5b9e\u6218\u9879\u76ee\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff09](#\u8ba1\u7b97\u673a\u89c6\u89c9\u5b9e\u6218\u9879\u76ee\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff09) \r\n- [\u81ea\u7136\u8bed\u8a00\u5904\u7406](#\u81ea\u7136\u8bed\u8a00\u5904\u7406)\r\n  - [\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5b9e\u6218\u9879\u76ee\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff09](#\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5b9e\u6218\u9879\u76ee\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff09) \r\n  \r\n# \u5fc5\u5907\u57fa\u7840\u6280\u80fd\r\n\r\n\u8981\u5b66\u4eba\u5de5\u667a\u80fd\uff08\u6570\u636e\u79d1\u5b66\uff09\u8fd9\u884c\u8fd8\u662f\u9700\u8981\u4e00\u4e9b\u57fa\u672c\u529f\u7684\uff0c\u6700\u57fa\u7840\u4e5f\u662f\u6700\u6838\u5fc3\u7684\u5c31\u662f**Python**\u548c**\u6570\u5b66**\u4e86\uff01\u8fd9\u4e24\u5144\u5f1f\u5165\u95e8\u8d77\u6765\r\n\u5e76\u4e0d\u96be\uff0c\u5148\u638c\u63e1\u57fa\u7840\u7684\u8fb9\u7528\u8fb9\u5b66\u4e5f\u662f\u53ef\u4ee5\u7684\uff01\r\n\r\n## \u5fc5\u5907Python\u57fa\u7840\r\n\r\n\u5982\u679c\u5bf9Python\u4e0d\u719f\u6089\u7684\u540c\u5b66\u4eec\uff0c\u5efa\u8bae\u5148\u770b\u4e00\u4e0b\u6211\u7684Python\u5165\u95e8\u89c6\u9891\u8bfe\u7a0b\uff0c\u53ef\u4ee5\u5feb\u901f\u5165\u95e8\uff01[\u4f20\u9001\u95e8](https://www.bilibili.com/video/av22404277?from=search&seid=12821472533341778879)\r\n\r\n- [x] \u4e3a\u4ec0\u4e48\u662fPython\uff1f\r\n\r\n\u6700\u76f4\u63a5\u7684\u89e3\u91ca\u5c31\u662f\u5927\u5bb6\u90fd\u7528\u5b83\uff01\u4ee5\u524d\u662f\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\uff0c\u540e\u6765\u5927\u5bb6\u66f4\u559c\u6b22\u9762\u5411\u590d\u5236\u7c98\u8d34\u7f16\u7a0b\uff0c\u73b0\u5728\u61d2\u5230\u9762\u5411github\u7f16\u7a0b\uff0c\u786e\u5b9e\u5982\u6b64\uff0c\u8be5\u5077\u61d2\u5c31\u5f97\u5077\u61d2\uff0cPython\u5c31\u662f\u8fd9\u4e2a\u4f5c\u7528\uff01\r\n\u540e\u7eed\u6240\u6709\u7684\u5b9e\u6218\u5185\u5bb9\u90fd\u662f\u57fa\u4e8ePython\uff0c\u6240\u4ee5\u6ca1\u5f97\u9009\u5566\uff01\r\n\r\n- [x] \u9700\u8981\u5b89\u88c5\u4ec0\u4e48\uff1f\r\n\r\n**Anaconda**\u5c31\u591f\u4e86\uff01Anaconda\u5c31\u591f\u4e86\uff01Anaconda\u5c31\u591f\u4e86\uff01\u597d\u4e86\uff0c\u8bf4\u4e86\u4e09\u904d\u4e86\uff0c\u5177\u4f53\u89e3\u91ca\u5927\u5bb6\u53c2\u8003\u4e0a\u9762\u4f20\u9001\u95e8\u8bfe\u7a0b\u5c31\u597d\r\n\r\n- [x] \u7528\u4ec0\u4e48\u7f16\u7a0b\u5de5\u5177\u5f00\u59cb\uff1f\r\n\u867d\u7136\u5927\u5bb6\u90fd\u6709\u8d81\u624b\u7684\u5175\u5668\uff0c\u4f46\u662f\u6211\u7ed9\u5927\u5bb6\u51c6\u5907\u7684\u7edd\u5927\u591a\u6570\u8bfe\u4ef6\u90fd\u662f\u57fa\u4e8e**jupyter notebook**\u7684\uff0c\u6240\u4ee5\u8fd9\u4e2a\u80af\u5b9a\u662f\u5fc5\u5907\u7684\uff01\r\n\r\n## \u5fc5\u5907Python\u5de5\u5177\u5305\r\n\r\n- [x] \u4ec0\u4e48\u662f\u5de5\u5177\u5305\uff1f\r\n\r\n\u5de5\u5177\u5305\u5c31\u662f\u4eba\u5bb6\u628a\u529f\u80fd\u90fd\u5199\u597d\u4e86\uff0c\u54b1\u4eec\u76f4\u63a5\u8c03\u7528\u5c31\u5b8c\u4e8b\u5566\uff01\u6570\u636e\u5904\u7406\uff0c\u5206\u6790\uff0c\u5efa\u6a21\u7b49\u90fd\u6709\u5bf9\u5e94\u7684\u5de5\u5177\u5305\u3002\u5bf9\u4e8e\u5b66\u4e60\u6765\u8bf4\r\n\u5e76\u4e0d\u7528\u628a\u8fd9\u4e9b\u5de5\u5177\u5305\u80cc\u4e0b\u6765\uff0c\u5148\u719f\u6089\u8d77\u6765\uff0c\u540e\u7eed\u80af\u5b9a\u8fd8\u662f\u8981\u73b0\u7528\u73b0\u67e5\u7684\u3002\r\n\r\n- [x] \u54ea\u4e9b\u5de5\u5177\u5305\u662f\u521d\u5b66\u8005\u5fc5\u5907\u7684\u5462\uff1f\r\n\r\n|\u5de5\u5177\u5305\u540d\u79f0|\u529f\u80fd\u6982\u8ff0|\r\n| --------   | :----:  |\r\n| Numpy       |\u77e9\u9635\u8ba1\u7b97\u5fc5\u5907\uff01\u5b83\u662f\u540e\u7eed\u4e00\u5207\u8ba1\u7b97\u7684\u6838\u5fc3\uff0c\u6570\u636e\u79d1\u5b66\u9886\u57df\u6838\u5fc3\u5de5\u5177\u5305| \r\n| Pandas       |\u6570\u636e\u5904\u7406\u5fc5\u5907\uff01\u8bfb\u6570\u636e\uff0c\u5904\u7406\u6570\u636e\uff0c\u5206\u6790\u6570\u636e\uff0c\u975e\u4ed6\u4e0d\u53ef!|\r\n| Matplotlib    |\u53ef\u89c6\u5316\u5fc5\u5907\uff01\u529f\u80fd\u5341\u5206\u5f3a\u5927\uff0c\u6ca1\u6709\u753b\u4e0d\u51fa\u6765\u7684\u56fe\uff0c\u5206\u6790\u5c55\u793a\u5c31\u9760\u5b83\u4e86\uff01| \r\n| Seaborn      |\u66f4\u7b80\u5355\u7684\u53ef\u89c6\u5316\u795e\u5668\uff01\u4e00\u884c\u4ee3\u7801\u7ed9\u4f60\u641e\u5b9a\u4e00\u4e2a\u53ef\u89c6\u5316\u5c55\u793a\u7ed3\u679c| \r\n\r\n## \u5fc5\u5907\u6570\u5b66\u57fa\u7840\r\n\r\n- [x] \u6570\u5b66\u91cd\u8981\u5417\uff1f\u975e\u5b66\u4e0d\u53ef\u5417\uff1f \r\n\r\n\r\n\u6570\u5b66\u6709\u591a\u91cd\u8981\u540c\u5b66\u4eec\u80af\u5b9a\u90fd\u5341\u5206\u6e05\u695a\uff0c\u5c24\u5176\u662f\u5728\u4eba\u5de5\u667a\u80fd\uff08\u6570\u636e\u79d1\u5b66\uff09\u9886\u57df\uff0c\u4e0d\u61c2\u6570\u5b66\u60f3\u5fc5\u5bf8\u6b65\u96be\u884c\uff0c\u5f88\u591a\u540c\u5b66\u90fd\u95ee\u8fc7\u6211\u4e00\u4e2a\u95ee\u9898\uff0c\u5de5\u4f5c\u4e2d\u771f\u80fd\u7528\u4e0a\u8fd9\u4e48\u591a\u6570\u5b66\u5417\uff1f\r\n\u6211\u8ddf\u5927\u5bb6\u6765\u89e3\u91ca\u4e00\u4e0b\uff0c\u4eba\u5de5\u667a\u80fd\u8fd9\u884c\u53d1\u5c55\u76f8\u5f53\u8fc5\u901f\uff0c\u5728\u5b9e\u9645\u5de5\u4f5c\u4e2d\u80af\u5b9a\u8981\u8fb9\u5e72\u8fb9\u5b66\uff0c\u5b66\u4ec0\u4e48\u5462\uff1f\u60f3\u5fc5\u5c31\u662f\u5f53\u4e0b\u7684\u4e00\u4e9b\u4f18\u79c0\u8bba\u6587\u4e86\uff0c\u5982\u679c\u8fde\u57fa\u672c\u7684\u6570\u5b66\u516c\u5f0f\u90fd\u770b\u4e0d\u61c2\uff0c\r\n\u90a3\u5c31\u4e0d\u7528\u518d\u53bb\u8c08\u4ec0\u4e48\u9ad8\u7aef\u6280\u672f\u4e86\u3002\u505a\u8fd9\u884c\u7684\u540c\u5b66\u4eec\u80af\u5b9a\u90fd\u4f1a\u6709\u8fd9\u6837\u4e00\u4e2a\u60f3\u6cd5\uff0c\u6240\u8c13\u7684\u4eba\u5de5\u667a\u80fd\u5c31\u662f\u5bf9\u6570\u636e\u505a\u5404\u79cd\u5404\u6837\u7684\u6570\u5b66\u8ba1\u7b97\u7f62\u4e86\uff01\r\n\r\n- [x] \u5982\u4f55\u5b66\u6570\u5b66\uff1f\u8981\u5b9a\u4e00\u4e2a\u957f\u671f\u8ba1\u5212\u5417\uff1f\r\n\r\n\u5bf9\u4e8e\u6570\u5b66\u6211\u89c9\u5f97\u5e76\u4e0d\u9700\u8981\u4ece\u5934\u5f00\u59cb\u82b1\u5927\u91cf\u65f6\u95f4\u4e00\u6b65\u4e00\u4e2a\u811a\u5370\u53bb\u5b66\u4e60\uff0c\u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff0c\u6211\u548c\u6211\u8eab\u8fb9\u7684\u540c\u4e8b\uff0c\u670b\u53cb\u90fd\u662f\u5e72\u8fd9\u884c\u86ee\u4e45\u7684\u4e86\uff0c\u6570\u5b66\u4e0d\u77e5\u9053\u64b8\u4e86\u591a\u5c11\u904d\u4e86\uff0c\u8003\u7814\u65f6\u5019\u4e5f\u66fe\u5237\u9898\u65e0\u6570\uff0c\r\n\u4f46\u4e5f\u4f1a\u9047\u5230\u8fd9\u6837\u7684\u95ee\u9898\uff0c\u5f88\u591a\u77e5\u8bc6\u70b9\u5982\u679c\u4e00\u6bb5\u65f6\u95f4\u6ca1\u770b\u5f88\u5feb\u8fd8\u662f\u4f1a\u5fd8\u8bb0\u3002\u6211\u6700\u5e38\u505a\u7684\u4e00\u4ef6\u4e8b\u5c31\u662f\u7528\u5230\u4ec0\u4e48\u67e5\u4ec0\u4e48\uff0c\u67e5\u627e\u7684\u8fc7\u7a0b\u5176\u5b9e\u4e5f\u662f\u5b66\u4e60\u8fdb\u6b65\u8fc7\u7a0b\u3002\u5efa\u8bae\u5927\u5bb6\u53ef\u4ee5\u5feb\u901f\u8fc7\u4e00\u904d\r\n\u5e38\u7528\u7684\u77e5\u8bc6\u70b9\uff08\u9ad8\u6570\uff0c\u7ebf\u6027\uff0c\u6982\u7387\u8bba\u4e2d\u7684\u57fa\u7840\uff09\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u5343\u4e07\u522b\u53bb\u770b\u5404\u79cd\u89e3\u9898\u8fc7\u7a0b\uff0c\u4e5f\u4e0d\u7528\u7ba1\u5177\u4f53\u6c42\u89e3\u7684\u65b9\u6cd5\uff0c\u8bf4\u767d\u4e86\u5c31\u662f\u53ea\u8981\u7406\u89e3\u4e00\u4e2a\u516c\u5f0f\u662f\u505a\u4ec0\u4e48\u7684\uff0c\u6709\u4ec0\u4e48\u7528\r\n\u5c31\u8db3\u591f\u4e86\uff0c\u7c7b\u4f3c\u6559\u6750\u4e2d\u7684\u4e60\u9898\uff0c\u7ec3\u4e60\u518c\u4e0a\u7684\u6c42\u89e3\u8fd9\u4e9b\u7edf\u7edf\u4e0d\u9700\u8981\uff0c\u4ee5\u540e\u4e5f\u6839\u672c\u4e0d\u4f1a\u7528\u7b14\u53bb\u7b97\u8fd9\u4e9b\u9ebb\u70e6\u4e8b\uff0c\u628a\u8fd9\u4e2a\u65f6\u95f4\u7701\u4e0b\u6765\u53bb\u5b66\u4e60\u7b97\u6cd5\u66f4\u5212\u5f97\u6765\uff01\r\n\r\n- [x] \u4e0b\u9762\u662f\u8bfe\u7a0b\u4e2d\u6240\u8bbe\u8ba1\u7684\u77e5\u8bc6\u70b9\uff0c\u4e5f\u662f\u5fc5\u5907\u57fa\u7840\r\n\r\n|\u77e5\u8bc6\u70b9   |  \u5185\u5bb9  |  \u4f5c\u7528  |\r\n| --------   | -----:  | :----:  |\r\n| \u9ad8\u7b49\u6570\u5b66        | \u9ad8\u7b49\u6570\u5b66\u57fa\u7840\uff0c\u5fae\u79ef\u5206\uff0c\u6cf0\u52d2\u516c\u5f0f\u4e0e\u62c9\u683c\u6717\u65e5\uff0c |  \u673a\u5668\u5b66\u4e60\u516c\u5f0f\u63a8\u5bfc\u5fc5\u5907|\r\n| \u7ebf\u6027\u4ee3\u6570        |\u7ebf\u6027\u4ee3\u6570\u57fa\u7840\uff0c\u7279\u5f81\u503c\u4e0e\u77e9\u9635\u5206\u89e3\uff0c| \u7b97\u6cd5\u6c42\u89e3\u5fc5\u5907|\r\n| \u6982\u7387\u8bba          |\u6982\u7387\u8bba\u57fa\u7840\uff0c\u968f\u673a\u53d8\u91cf\u4e0e\u6982\u7387\u4f30\u8ba1\uff0c\u5e38\u7528\u5206\u5e03|  \u673a\u5668\u5b66\u4e60\u7ecf\u5e38\u63d0\u8fd9\u4e9b\u8bcd|\r\n| \u7edf\u8ba1\u5206\u6790         |\u56de\u5f52\u5206\u6790\uff0c\u5047\u8bbe\u68c0\u9a8c\uff0c\u76f8\u5173\u5206\u6790\uff0c\u65b9\u5dee\u5206\u6790|  \u6570\u636e\u5206\u6790\u5fc5\u5907  |\r\n\r\n# \u673a\u5668\u5b66\u4e60\r\n\r\n\u4eba\u5de5\u667a\u80fd\u9886\u57df\u6700\u6838\u5fc3\u7684\u5c31\u662f\u673a\u5668\u5b66\u4e60\u4e86\uff0c\u65e0\u8bba\u5927\u5bb6\u540e\u7eed\u60f3\u4ece\u4e8b\u54ea\u4e2a\u65b9\u5411\uff0c\u80af\u5b9a\u90fd\u662f\u5148\u4ece\u673a\u5668\u5b66\u4e60\u5f00\u59cb\uff01\u4e3b\u8981\u5c31\u4e24\u4ef6\u4e8b\uff0c\r\n\u7b2c\u4e00\u5c31\u662f\u638c\u63e1\u7ecf\u5178\u7b97\u6cd5\u539f\u7406\uff0c\u7b2c\u4e8c\u5c31\u662f\u719f\u7ec3\u5e94\u7528Python\u5de5\u5177\u5305\u8fdb\u884c\u5efa\u6a21\u5b9e\u6218\uff01\r\n\r\n## \u673a\u5668\u5b66\u4e60\u7b97\u6cd5\r\n\r\n- [x] \u7b97\u6cd5\u8981\u5b66\u4ec0\u4e48\uff1f\r\n\u7406\u89e3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u662f\u5982\u4f55\u5bf9\u6570\u636e\u8fdb\u884c\u64cd\u4f5c\u4ece\u800c\u5b8c\u6210\u5efa\u6a21\u6c42\u89e3\u8fc7\u7a0b\uff0c\u8bf4\u767d\u4e86\u5c31\u662f\u719f\u6089\u4e0b\u6570\u5b66\u5728\u7b97\u6cd5\u4e2d\u662f\u5982\u4f55\u5e94\u7528\u7684\u3002\u91cd\u5728\u7406\u89e3\u5373\u53ef\uff01\u4e0d\u8981\u5bf9\u4e00\u4e2a\u95ee\u9898\u94bb\u7684\u6ca1\u5b8c\u6ca1\u4e86\uff0c\u8fd9\u6837\u592a\r\n\u6d6a\u8d39\u65f6\u95f4\u4e86\uff0c\u6ca1\u51c6\u540e\u7eed\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4e00\u4e0b\u5b50\u5c31\u8fce\u5203\u800c\u89e3\u4e86\u3002\u6211\u89c9\u5f97\u5bf9\u7b97\u6cd5\u7684\u5b66\u4e60\u80af\u5b9a\u4e0d\u6b62\u4e00\u904d\uff0c\u5c24\u5176\u662f\u51c6\u5907\u9762\u8bd5\u5c31\u4e1a\u7684\u540c\u5b66\u4eec\uff0c\u4e8c\u5237\uff0c\u4e09\u5237\u90fd\u662f\u5f88\u6b63\u5e38\u7684\u73b0\u8c61\uff08\u66fe\u7ecf\u6709\u540c\u5b66\r\n\u8ddf\u6211\u8bf4\u9762\u8bd5\u524d\u4e00\u5171\u5237\u4e866\u904d\u8bfe\u7a0b\uff09\r\n\r\n- [x] \u6709\u4e86\u6df1\u5ea6\u5b66\u4e60\u8fd8\u9700\u8981\u673a\u5668\u5b66\u4e60\u5417\uff1f\r\n\r\n\u6df1\u5ea6\u5b66\u4e60\u53ef\u4ee5\u8bf4\u662f\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u4e00\u79cd\uff0c\u5e76\u4e0d\u662f\u6709\u4e86\u795e\u7ecf\u7f51\u7edc\u5176\u4ed6\u7ecf\u5178\u7b97\u6cd5\u5c31\u4e0d\u9700\u8981\u4e86\uff0c\u9700\u8981\u6839\u636e\u4e0d\u540c\u7684\u4efb\u52a1\u548c\u6570\u636e\u6765\u9009\u62e9\u6700\u5408\u9002\u7684\u7b97\u6cd5\uff0c\u5b66\u4e60\u8def\u5f84\u80af\u5b9a\u662f\u5148\u4ece\u673a\u5668\u5b66\u4e60\u5f00\u59cb\uff0c\r\n\u5176\u5b9e\u638c\u63e1\u4e86\u8fd9\u4e9b\u7ecf\u5178\u7b97\u6cd5\u4e4b\u540e\u518d\u770b\u795e\u7ecf\u7f51\u7edc\u771f\u7684\u5f88\u7b80\u5355\uff01\r\n\r\n- [x] \u4e0b\u9762\u662f\u8bfe\u7a0b\u4e2d\u4f1a\u8bb2\u89e3\u7684\u7b97\u6cd5\uff0c\u4e5f\u662f\u5927\u5bb6\u5fc5\u987b\u638c\u63e1\u7684\uff01\u8fd9\u91cc\u6ca1\u6709\u5217\u51fa\u6240\u6709\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u56e0\u4e3a\u6709\u5f88\u591a\u73b0\u5728\u5df2\u7ecf\u4e0d\u5b9e\u7528\u4e86\u3002\r\n\r\n|\u77e5\u8bc6\u70b9   |  \u5185\u5bb9  |  \u6982\u8ff0  |\r\n| --------   | -----:  | :----:  |\r\n| \u5206\u7c7b\u7b97\u6cd5        | \u903b\u8f91\u56de\u5f52\uff0c\u51b3\u7b56\u6811\uff0c\u652f\u6301\u5411\u91cf\u673a\uff0c\u96c6\u6210\u7b97\u6cd5\uff0c\u8d1d\u53f6\u65af\u7b97\u6cd5|  \u51c6\u5907\u9762\u8bd5\u7684\u540c\u5b66\u4eec\u5fc5\u987b\u638c\u63e1|\r\n| \u56de\u5f52\u7b97\u6cd5        |\u7ebf\u6027\u56de\u5f52\uff0c\u51b3\u7b56\u6811\uff0c\u96c6\u6210\u7b97\u6cd5| \u6709\u4e9b\u7b97\u6cd5\u65e2\u80fd\u505a\u5206\u7c7b\u4e5f\u80fd\u505a\u56de\u5f52|\r\n| \u805a\u7c7b\u7b97\u6cd5     |k-means\uff0cdbscan\u7b49| \u65e0\u76d1\u7763\u662f\u5b9e\u5728\u6ca1\u6807\u7b7e\u7684\u65f6\u5019\u624d\u8003\u8651\u7684|\r\n| \u964d\u7ef4\u7b97\u6cd5         |\u4e3b\u6210\u5206\u5206\u6790\uff0c\u7ebf\u6027\u5224\u522b\u5206\u6790\u7b49|  \u91cd\u5728\u7406\u89e3\u964d\u7ef4\u7684\u601d\u60f3  |\r\n| \u8fdb\u9636\u7b97\u6cd5         |GBDT\u63d0\u5347\u7b97\u6cd5\uff0clightgbm\uff0c\uff0cEM\u7b97\u6cd5\uff0c\u9690\u9a6c\u5c14\u79d1\u592b\u6a21\u578b| \u8fdb\u9636\u7b97\u6cd5\u6709\u65f6\u95f4\u7cbe\u529b\u7684\u540c\u5b66\u4eec\u53ef\u4ee5\u6311\u6218|\r\n\r\n## \u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5b9e\u9a8c\u5206\u6790\r\n\r\n\u901a\u8fc7\u5bf9\u6bd4\u5b9e\u9a8c\u5206\u6790\u7ecf\u5178\u7b97\u6cd5\u5efa\u6a21\u65b9\u6cd5\u53ca\u5176\u53c2\u6570\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u5b9e\u9a8c\u4e0e\u53ef\u89c6\u5316\u5c55\u793a\u7406\u89e3\u7b97\u6cd5\u4e2d\u7684\u53c2\u6570\u4e0e\u5e94\u7528\u5b9e\u4f8b\u3002\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   | :----:  |\r\n| \u7ebf\u6027\u56de\u5f52\u5b9e\u9a8c\u5206\u6790       |\u638c\u63e1\u4e00\u5143\u4e0e\u591a\u5143\u7ebf\u6027\u56de\u5f52\uff0c\u975e\u7ebf\u6027\u56de\u5f52\u65b9\u6cd5\uff0c\u6b63\u5219\u5316\u60e9\u7f5a\u7684\u4f5c\u7528| \r\n| \u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5        |\u5e38\u7528\u5206\u7c7b\u4e0e\u56de\u5f52\u7b97\u6cd5\u8bc4\u4f30\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u6570\u636e\u96c6\u5207\u5206\u5b9e\u4f8b|\r\n| \u903b\u8f91\u56de\u5f52\u5b9e\u9a8c\u5206\u6790    |\u7ecf\u5178\u5206\u7c7b\u6a21\u578b\u6784\u9020\u65b9\u6cd5\uff0c\u51b3\u7b56\u6811\u8fb9\u754c\u7ed8\u5236\u65b9\u6cd5| \r\n| \u805a\u7c7b\u7b97\u6cd5\u5b9e\u9a8c\u5206\u6790       |\u65e0\u76d1\u7763\u5efa\u6a21\u5b9e\u4f8b\uff0c\u805a\u7c7b\u7b97\u6cd5\u8bc4\u4f30\u65b9\u6cd5\uff0c\u65e0\u76d1\u7763\u7684\u4f5c\u7528\u4e0e\u5e94\u7528\u5b9e\u4f8b| \r\n| \u51b3\u7b56\u6811\u5b9e\u9a8c\u5206\u6790      |\u6811\u6a21\u578b\u53ef\u89c6\u5316\u5b9e\u4f8b\u4e0e\u6784\u9020\u65b9\u6cd5\uff0c\u6811\u6a21\u578b\u7684\u5206\u7c7b\u4e0e\u56de\u5f52\u5e94\u7528| \r\n| \u96c6\u6210\u7b97\u6cd5\u5b9e\u9a8c\u5206\u6790       |\u96c6\u6210\u65b9\u6cd5\u5e94\u7528\u5b9e\u4f8b\u4e0e\u6548\u679c\u5206\u6790\uff0c\u5e38\u89c1\u96c6\u6210\u7b56\u7565\u5bf9\u6bd4|\r\n| \u652f\u6301\u5411\u91cf\u673a\u5b9e\u9a8c\u5206\u6790   |SVM\u6d89\u53ca\u53c2\u6570\u4e0e\u5efa\u6a21\u5bf9\u6bd4\u5b9e\u9a8c| \r\n| \u5173\u8054\u89c4\u5219\u5b9e\u6218\u5206\u6790      |\u5173\u8054\u89c4\u5219\u5fc5\u5907\u77e5\u8bc6\u70b9\u4e0e\u5efa\u6a21\u5206\u6790\u5b9e\u4f8b|\r\n\r\n## \u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4ee3\u7801\u590d\u73b0\r\n\r\n\u4e3a\u4e86\u66f4\u597d\u7406\u89e3\u7b97\u6cd5\u7684\u673a\u5236\u4ece\u96f6\u5f00\u59cb\u590d\u73b0\u7ecf\u5178\u7b97\u6cd5\uff0c\u575a\u6301\u4e0d\u6389\u5305\u539f\u5219\uff0c\u4e00\u6b65\u6b65\u5b8c\u6210\u7b97\u6cd5\u6240\u9700\u6240\u6709\u6a21\u5757\u3002\r\n\r\n- [x] \u4e3a\u4ec0\u4e48\u8981\u81ea\u5df1\u590d\u73b0\u4ee3\u7801\uff1f\u6709\u4f55\u4ef7\u503c\u5462\uff1f\r\n\r\n\u4e3b\u8981\u76ee\u7684\u662f\u66f4\u597d\u7684\u638c\u63e1\u7b97\u6cd5\u7684\u5de5\u4f5c\u539f\u7406\uff0c\u91cd\u5728\u7ec3\u4e60\uff01\u6709\u65f6\u95f4\u7684\u540c\u5b66\u4eec\u53ef\u4ee5\u81ea\u5df1\u590d\u73b0\u4e00\u904d\uff0c\u65f6\u95f4\u7d27\u7684\u540c\u5b66\u5c31\u4e0d\u5fc5\u4eb2\u529b\u4eb2\u4e3a\u4e86\u3002\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   | :----:  |\r\n| \u7ebf\u6027\u56de\u5f52\u4ee3\u7801\u5b9e\u73b0       |\u5206\u6a21\u5757\u6784\u5efa\u7b97\u6cd5\u5e38\u7528\u51fd\u6570| \r\n| \u903b\u8f91\u56de\u5f52\u4ee3\u7801\u5b9e\u73b0       |\u5b9e\u4f8b\u89e3\u8bfb\u903b\u8f91\u56de\u5f52\u5b9e\u73b0\u65b9\u6cd5|\r\n| Kmeans\u4ee3\u7801\u5b9e\u73b0    |\u975e\u5e38\u7b80\u5355\u6613\u61c2\u7684\u65e0\u76d1\u7763\u7b97\u6cd5| \r\n| \u51b3\u7b56\u6811\u4ee3\u7801\u5b9e\u73b0      |\u6811\u6a21\u578b\u5176\u5b9e\u5c31\u662f\u9012\u5f52\u5b9e\u73b0| \r\n| \u795e\u7ecf\u7f51\u7edc\u4ee3\u7801\u5b9e\u73b0      |\u4ee3\u7801\u91cf\u7565\u5927\uff0c\u5efa\u8baedebug\u6a21\u5f0f\u5b66\u4e60| \r\n| \u8d1d\u53f6\u65af\u4ee3\u7801\u5b9e\u73b0      |\u8d1d\u53f6\u65af\u5728\u6587\u672c\u4efb\u52a1\u4e2d\u8fd8\u662f\u6bd4\u8f83\u597d\u89e3\u91ca|\r\n| \u5173\u8054\u89c4\u5219\u4ee3\u7801\u5b9e\u73b0   |\u5e38\u7528\u7684\u6570\u636e\u5206\u6790\u7b97\u6cd5| \r\n| \u6253\u9020\u97f3\u4e50\u63a8\u8350\u7cfb\u7edf    |\u4ece\u96f6\u5f00\u59cb\u6784\u9020\u63a8\u8350\u7cfb\u7edf\u6a21\u578b|\r\n\r\n\r\n\r\n## \u673a\u5668\u5b66\u4e60\u7ecf\u5178\u6848\u4f8b\u5b9e\u6218\r\n\r\n- [x] \u5b9e\u6218\u9700\u8981\u638c\u63e1\u54ea\u4e9b\u6280\u80fd\uff1f\r\n\r\n\u5728\u5b9e\u6218\u4e2d\u53ef\u80fd\u628a\u6570\u5b66\u77e5\u8bc6\u70b9\u90fd\u5f31\u5316\u4e86\uff0c\u56e0\u4e3a\u66f4\u591a\u65f6\u5019\u6211\u4eec\u90fd\u662f\u4f7f\u7528\u73b0\u6210\u7684\u5de5\u5177\u5305\u6765\u5b8c\u6210\u4efb\u52a1\uff08\u8c03\u5305\u4fa0\uff09\u3002\u8fd9\u91cc\u9700\u8981\u5927\u5bb6\u638c\u63e1\u7684\u8282\u80fd\u529f\u80fd\u6bd4\u8f83\u591a\uff0c\r\n\u9996\u5148\u5c31\u662f\u719f\u7ec3\u4f7f\u7528\u8fd9\u4e9b\u5e38\u7528\u5de5\u5177\u5305\u4e86\uff0c\u6570\u636e\u9884\u5904\u7406\uff0c\u7279\u5f81\u5de5\u7a0b\uff0c\u8c03\u53c2\uff0c\u9a8c\u8bc1\u8fd9\u4e9b\u90fd\u662f\u975e\u5e38\u6838\u5fc3\u7684\u6b65\u9aa4\u3002\u6982\u62ec\u6765\u8bf4\u5c31\u662f\u8981\u5b8c\u6210\u4e0d\u540c\u7684\u4efb\u52a1\u6240\u9700\u6d41\u7a0b\u548c\u5957\u8def\u90fd\u662f\u7c7b\u4f3c\u7684\uff0c\r\n\u4f46\u662f\u4f7f\u7528\u7684\u65b9\u6cd5\u548c\u7b97\u6cd5\u5374\u53ef\u80fd\u4e0d\u540c\uff0c\u8fd9\u5c31\u9700\u8981\u5927\u5bb6\u4e0d\u65ad\u79ef\u7d2f\u6765\u4e30\u5bcc\u5b9e\u6218\u7ecf\u9a8c\u4e86\u3002\u7ed9\u540c\u5b66\u4eec\u63d0\u4f9b\u7684\u8fd9\u4e9b\u6848\u4f8b\u5927\u5bb6\u90fd\u53ef\u4ee5\u5f53\u4f5c\u662f\u81ea\u5df1\u7684\u5b9e\u6218\u6a21\u677f\uff01\r\n\r\n- [x] \u8fd9\u4e9b\u6848\u4f8b\u80fd\u8ba9\u6211\u6536\u83b7\u4ec0\u4e48\uff1f\r\n\r\n\u6700\u91cd\u8981\u7684\u5c31\u662f\u5b66\u4f1a\u9488\u5bf9\u4e0d\u540c\u6570\u636e\uff08\u6570\u503c\uff0c\u6587\u672c\uff0c\u56fe\u50cf\uff09\u5982\u4f55\u8fdb\u884c\u9884\u5904\u7406\u4e0e\u5206\u6790\uff0c\u719f\u7ec3\u5e94\u7528\u5de5\u5177\u5305\u4e2d\u5404\u5927\u6838\u5fc3\u51fd\u6570\u8fdb\u884c\u8c03\u53c2\u4e0e\u9884\u5904\u7406\uff0c\u9488\u5bf9\u4e0d\u540c\u4efb\u52a1\u63d0\u51fa\u591a\u79cd\u89e3\u51b3\r\n\u65b9\u6848\u5e76\u8fdb\u884c\u5b9e\u9a8c\u5206\u6790\u3002\u603b\u7ed3\u8d77\u6765\u5c31\u662f\u591a\u505a\u5b9e\u9a8c\uff0c\u591a\u52a8\u624b\uff0c\u4ee3\u7801\u5199\u7684\u591a\u4e86\u81ea\u7136\u5c31\u719f\u7ec3\u4e86\uff01\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| K\u8fd1\u90bb\u7b97\u6cd5\u5b9e\u6218       |\u673a\u5668\u5b66\u4e60\u5165\u95e8\u6848\u4f8b\uff0c\u638c\u63e1\u5de5\u5177\u5305\u5e94\u7528\u4e8e\u5efa\u6a21\u65b9\u6cd5| \r\n| \u4ea4\u6613\u6570\u636e\u5f02\u5e38\u68c0\u6d4b      |\u5341\u5206\u91cd\u8981\uff0c\u6570\u636e\u5904\u7406\u548c\u5efa\u6a21\u7b56\u7565\u7684\u8be6\u7ec6\u5206\u6790\u5bf9\u6bd4|\r\n| \u96c6\u6210\u7b97\u6cd5\u5efa\u6a21\u5b9e\u6218    |\u96c6\u6210\u4e0d\u7528\u6211\u591a\u8bf4\u4e86\uff0c\u5fc5\u5907\u6838\u5fc3\u7b56\u7565| \r\n| \u57fa\u4e8e\u968f\u673a\u68ee\u6797\u7684\u6c14\u6e29\u9884\u6d4b      |\u968f\u673a\u68ee\u6797\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u6700\u5e38\u7528\u7684\u7b97\u6cd5\uff0c\u8be6\u7ec6\u5206\u6790\u5bf9\u6bd4| \r\n| \u65b0\u95fb\u5206\u7c7b\u5b9e\u6218      |\u6587\u672c\u6570\u636e\u5206\u6790\u5904\u7406\uff0c\u57fa\u4e8e\u8d1d\u53f6\u65af\u7b97\u6cd5\u5c55\u5f00\u5efa\u6a21\u5b9e\u6218| \r\n| \u805a\u7c7b\u5b9e\u8df5\u5206\u6790       |\u65e0\u76d1\u7763\u5e94\u7528\u5b9e\u4f8b|\r\n| \u65f6\u95f4\u5e8f\u5217\u5206\u6790   |\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5236\u4f5c\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5e8f\u5217\u6570\u636e\u8fdb\u884c\u5efa\u6a21| \r\n| \u7528\u6237\u6d41\u5931\u9884\u8b66      |\u6211\u7ecf\u5e38\u8bf4\u68a6\u5e7b\u897f\u6e38\u7684\u7528\u6237\u6d41\u5931\uff0c\u8fd9\u4e2a\u53ea\u662f\u4e2aDEMO|\r\n| \u4f7f\u7528lightgbm\u8fdb\u884c\u996d\u5e97\u6d41\u91cf\u9884\u6d4b       |\u53c8\u662f\u4e00\u4e2a\u5927\u6740\u5668\uff0c\u6bd4xgboost\u8fd8\u864e|\r\n| \u4eba\u53e3\u666e\u67e5\u6570\u636e\u96c6\u9879\u76ee\u5b9e\u6218-\u6536\u5165\u9884\u6d4b   |\u6838\u5fc3\u6a21\u677f\uff0c\u6570\u636e\u5206\u6790\uff0c\u53ef\u89c6\u5316\u5565\u7684\u8be5\u6709\u7684\u90fd\u6709| \r\n| \u8d1d\u53f6\u65af\u4f18\u5316\u5b9e\u6218      |\u96be\u5ea6\u8f83\u5927\uff0c\u8d1d\u53f6\u65af\u4f18\u5316\u5de5\u5177\u5305\u4f7f\u7528\u5b9e\u4f8b|\r\n| \u6587\u672c\u7279\u5f81\u65b9\u6cd5\u5bf9\u6bd4   |\u6587\u672c\u6570\u636e\u5e38\u7528\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u5bf9\u6bd4| \r\n| \u5236\u4f5c\u81ea\u5df1\u5e38\u7528\u5de5\u5177\u5305     |\u81ea\u5df1\u505a\u4e2a\u5305\u73a9\u73a9|\r\n\r\n## \u673a\u5668\u5b66\u4e60\u5b9e\u6218\u96c6\u9526\r\n\r\n- [x] \u8fd9\u91cc\u8fd8\u7ed9\u5927\u5bb6\u51c6\u5907\u4e86\u4e30\u5bcc\u7684\u5b9e\u6218\u9879\u76ee\uff0c\u975e\u5e38\u9002\u5408\u5927\u5bb6\u6765\u7ec3\u624b\uff01\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| Python\u5b9e\u6218\u5173\u8054\u89c4\u5219       |\u7528\u5de5\u5177\u5305\u6765\u505a\u5173\u8054\u89c4\u5219\u5b9e\u5728\u592a\u8f7b\u677e\u4e86| \r\n| \u7231\u5f7c\u8fce\u6570\u636e\u96c6\u5206\u6790\u4e0e\u5efa\u6a21     |\u623f\u4ef7\u6570\u636e\u96c6\u5206\u6790\u4e0e\u5efa\u6a21\u5b9e\u4f8b|\r\n| \u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u9152\u5e97\u63a8\u8350\u7cfb\u7edf    |\u6765\u6784\u5efa\u4e00\u4e2a\u63a8\u8350\u7cfb\u7edf\u5b8c\u6210\u9152\u5e97\u63a8\u8350| \r\n| \u5546\u54c1\u9500\u552e\u989d\u56de\u5f52\u5206\u6790      |\u9500\u552e\u989d\u9884\u6d4b\uff0c\u5f88\u5e38\u89c4\u7684\u4efb\u52a1\uff0c\u5e38\u89c4\u5957\u8def\u641e\u5b9a| \r\n| \u7edd\u5730\u6c42\u751f\u6570\u636e\u96c6\u63a2\u7d22\u5206\u6790\u4e0e\u5efa\u6a21      |\u7edd\u5730\u6c42\u751f\u6570\u636e\u96c6\uff0c\u6765\u770b\u770b\u4f60\u7a76\u7adf\u88ab\u4ec0\u4e48\u4eba\u5e72\u6389\u4e86| \r\n| \u6a21\u578b\u89e3\u91ca\u65b9\u6cd5\u5b9e\u6218       |\u5efa\u6a21\u540e\u5982\u4f55\u6765\u89e3\u91ca\u6a21\u578b\u5462\uff0c\u8fd9\u51e0\u4e2a\u5de5\u5177\u5305\u5e2e\u4f60\u641e\u5b9a|\r\n| \u81ea\u7136\u8bed\u8a00\u5904\u7406\u5fc5\u5907\u5de5\u5177\u5305\u5b9e\u6218  |NLP\u5e38\u7528\u5de5\u5177\u5305\u89e3\u8bfb\uff0c\u5b9e\u4f8b\u6f14\u793a| \r\n| \u94f6\u884c\u5ba2\u6237\u8fd8\u6b3e\u53ef\u80fd\u6027\u9884\u6d4b      |\u94f6\u884c\u5ba2\u6237\u6570\u636e\u6765\u9884\u6d4b\u8fd8\u6b3e\u7684\u53ef\u80fd\u6027|\r\n| \u56fe\u50cf\u7279\u5f81\u805a\u7c7b\u5206\u6790\u5b9e\u8df5       |\u56fe\u50cf\u6570\u636e\u5982\u4f55\u8fdb\u884c\u805a\u7c7b\u5462\uff1f|\r\n| \u4eba\u53e3\u666e\u67e5\u6570\u636e\u96c6\u9879\u76ee\u5b9e\u6218-\u6536\u5165\u9884\u6d4b   |\u6838\u5fc3\u6a21\u677f\uff0c\u6570\u636e\u5206\u6790\uff0c\u53ef\u89c6\u5316\u5565\u7684\u8be5\u6709\u7684\u90fd\u6709| \r\n\r\n# \u6570\u636e\u5206\u6790\u4e0e\u6316\u6398\r\n\r\n\u6570\u636e\u5206\u6790\u8fd9\u4e2a\u8bcd\u5927\u5bb6\u5929\u5929\u90fd\u5728\u542c\uff0c\u8981\u5e72\u4ec0\u4e48\u5462\uff1f\u65e0\u975e\u5c31\u662f\u4ece\u6570\u636e\u4e2d\u83b7\u53d6\u6709\u4ef7\u503c\u7684\u4fe1\u606f\uff0c\u8fd9\u5176\u4e2d\u65b9\u6cd5\u4e0e\u5957\u8def\u8fd8\u662f\u975e\u5e38\u591a\u7684\u3002\r\n\u8fd9\u4e2a\u65b9\u5411\u4e0d\u9700\u8981\u4ec0\u4e48\u7406\u8bba\u79ef\u7d2f\uff0c\u76f4\u63a5\u4e0a\u6570\u636e\uff0c\u5e72\u5c31\u5f97\u4e86\uff01\u6848\u4f8b\u7684\u79ef\u7d2f\u5c31\u662f\u5b66\u4e60\u8fc7\u7a0b\uff01\r\n\r\n## \u6570\u636e\u6316\u6398\u5b9e\u6218\r\n\r\n- [x] \u6570\u636e\u6316\u6398\u662f\u4ec0\u4e48\uff1f\u548c\u673a\u5668\u5b66\u4e60\u6709\u4ec0\u4e48\u533a\u522b\uff1f\r\n\r\n\u7b80\u5355\u6765\u8bf4\u6570\u636e\u6316\u6398\u5c31\u662f\u5bf9\u6d77\u91cf\u6570\u636e\u5e94\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u6765\u5f97\u5230\u60f3\u8981\u7684\u7ed3\u679c\u3002\u5728\u6570\u636e\u6316\u6398\u4e2d\u91cd\u70b9\u5e76\u4e0d\u662f\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u9009\u62e9\uff0c\u800c\u662f\u600e\u4e48\u6837\u5bf9\u6570\u636e\u8fdb\u884c\u5904\u7406\u624d\u80fd\u5f97\u5230\u66f4\u597d\u7684\r\n\u9884\u6d4b\u7ed3\u679c\uff0c\u5728\u8fd9\u91cc\u7279\u5f81\u5de5\u7a0b\u4e0e\u9884\u5904\u7406\u5c06\u6210\u4e3a\u6838\u5fc3\u89e3\u51b3\u65b9\u6848\u3002\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| \u6cf0\u5766\u5c3c\u514b\u53f7\u83b7\u6551\u9884\u6d4b       |\u7ecf\u5178\u7684kaggle\u7ade\u8d5b\u6848\u4f8b\uff0c\u5165\u95e8\u6570\u636e\u6316\u6398\u7684\u7b2c\u4e00\u4e2a\u5b9e\u6218\u9879\u76ee| \r\n| \u6570\u636e\u7279\u5f81\u6784\u5efa       |\u7279\u5f81\u5de5\u7a0b\u662f\u6570\u636e\u6316\u6398\u7684\u6838\u5fc3\uff0c\u57fa\u4e8esklearn\u8bb2\u89e3\u591a\u79cd\u7279\u5f81\u6784\u5efa\u65b9\u6cd5|\r\n| \u7528\u6237\u753b\u50cf\u5b9e\u6218    |\u7528\u6237\u753b\u50cf\u60f3\u5fc5\u5927\u5bb6\u90fd\u542c\u8fc7\u4e86\uff0c\u5982\u4f55\u5e94\u7528\u6570\u636e\u6765\u5b8c\u6210\u753b\u50cf\u5462\uff1f| \r\n| \u96c6\u6210\u7b56\u7565\u5b9e\u4f8b       |\u6570\u636e\u6316\u6398\u4e2d\u9009\u62e9\u901a\u5e38\u90fd\u9009\u62e9\u96c6\u6210\u7b56\u7565\u6765\u66f4\u597d\u7684\u63d0\u5347\u6548\u679c| \r\n| Xgboost\u5b9e\u6218    |\u96c6\u6210\u4e2d\u7684\u5178\u578b\u4ee3\u8868\uff0c\u7ade\u8d5b\u7684\u5927\u6740\u5668| \r\n| \u4eac\u4e1c\u8d2d\u4e70\u610f\u5411\u9884\u6d4b       |\u7ecf\u5178\u9884\u6d4b\u95ee\u9898\uff0c\u57fa\u4e8e\u7528\u6237\u5386\u53f2\u884c\u4e3a\u6570\u636e\u5b8c\u6210\u9884\u6d4b\u4efb\u52a1|\r\n| kaggle\u6570\u636e\u79d1\u5b66\u8c03\u67e5   |\u53ef\u89c6\u5316\u5c55\u793akaggle\u7ade\u8d5b\u4e2d\u53c2\u8d5b\u4eba\u5458\u60c5\u51b5| \r\n| \u623f\u4ef7\u9884\u6d4b     |\u6570\u636e\u6316\u6398\u5165\u95e8\u7ea7\u522b\u6848\u4f8b\uff0c\u5feb\u901f\u638c\u63e1\u5e38\u89c4\u5957\u8def|\r\n| \u7535\u529b\u654f\u611f\u7528\u6237\u5206\u6790   |\u7ade\u8d5b\u5b9e\u4f8b\uff0c\u4e3b\u8981\u8bb2\u89e3\u7279\u5f81\u5de5\u7a0b\u7684\u4f5c\u7528| \r\n| fbprophet\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b     |\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u975e\u5e38\u5b9e\u7528\u7684\u7b97\u6cd5\uff0c\u7528\u8d77\u6765\u975e\u5e38\u7b80\u5355|\r\n\r\n## \u6570\u636e\u6316\u6398\u7ade\u8d5b\u4f18\u80dc\u89e3\u51b3\u65b9\u6848\r\n\r\n- [x] \u6211\u53c8\u4e0d\u53c2\u52a0\u7ade\u8d5b\uff0c\u4e3a\u4ec0\u4e48\u8981\u770b\u4eba\u5bb6\u7684\u89e3\u51b3\u65b9\u6848\u5462\uff1f\r\n\r\n\u7ed9\u5927\u5bb6\u9009\u62e9\u4e86\u5929\u6c60\uff0ckaggle\uff0c\u878d\u673a\u7b49\u5927\u578b\u7ade\u8d5b\u6848\u4f8b\uff0c\u5e76\u4e14\u63d0\u4f9b\u7684\u4ee3\u7801\u548c\u65b9\u6848\u5747\u4e3a\u7ade\u8d5b\u65f6\u4f18\u80dc\u8005\u7684\u89e3\u51b3\u601d\u8def\u3002\u5c31\u597d\u6bd4\u8981\u5b66\u4e0b\u68cb\u5c31\u5f97\u8ddf\u4e0b\u7684\u6700\u597d\u7684\u73a9\u81ea\u5df1\u624d\u4f1a\u63d0\u5347\uff0c\r\n\u6848\u4f8b\u4e2d\u5747\u4f1a\u8bb2\u89e3\u4f18\u80dc\u8005\u7684\u601d\u8def\u548c\u6574\u4f53\u89e3\u51b3\u65b9\u6848\u5e76\u63d0\u4f9b\u4ee3\u7801\u5b9e\u73b0\u3002\u975e\u5e38\u6709\u52a9\u4e8e\u5927\u5bb6\u63d0\u5347\uff01\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| \u5feb\u624b\u77ed\u89c6\u9891\u7528\u6237\u6d3b\u8dc3\u5ea6\u5206\u6790       |\u57fa\u4e8e\u7528\u6237\u7684\u884c\u4e3a\u6570\u636e\u6765\u9884\u6d4b\u63a5\u4e0b\u6765\u7684\u6d3b\u8dc3\u7a0b\u5ea6| \r\n| \u5de5\u4e1a\u5316\u5de5\u751f\u4ea7\u9884\u6d4b       |\u5bf9\u5316\u5de5\u6570\u636e\u8fdb\u884c\u5206\u6790\uff0c\u5efa\u6a21\u9884\u6d4b\u751f\u4ea7\u6548\u7387|\r\n| \u667a\u6167\u57ce\u5e02-\u9053\u8def\u901a\u884c\u65f6\u95f4\u9884\u6d4b    |\u5f88\u63a5\u5730\u6c14\u7684\u7ade\u8d5b\uff0c\u57fa\u4e8e\u9053\u8def\u6570\u636e\u9884\u6d4b\u901a\u884c\u65f6\u95f4| \r\n| \u7279\u5f81\u5de5\u7a0b\u5efa\u6a21\u53ef\u89e3\u91ca\u5de5\u5177\u5305      |\u6570\u636e\u6316\u6398\u4e2d\u5f88\u96be\u7684\u4e00\u70b9\u5c31\u662f\u8fdb\u884c\u7279\u5f81\u89e3\u91ca\uff0c\u8fd9\u4e9b\u5de5\u5177\u5305\u975e\u5e38\u5b9e\u7528| \r\n| \u533b\u5b66\u7cd6\u5c3f\u75c5\u6570\u636e\u547d\u540d\u5b9e\u4f53\u8bc6\u522b    |\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7b97\u6cd5\u8bb2\u89e3\u4e0e\u5e94\u7528\u5b9e\u4f8b\u5206\u6790| \r\n| \u8d37\u6b3e\u5e73\u53f0\u98ce\u63a7\u6a21\u578b-\u7279\u5f81\u5de5\u7a0b       |\u7528\u56fe\u6a21\u578b\u6765\u6784\u5efa\u7279\u5f81\u5de5\u7a0b\uff0c\u8fd9\u5957\u601d\u8def\u5e94\u7528\u5f88\u5e7f|\r\n| \u65b0\u95fb\u5173\u952e\u8bcd\u62bd\u53d6\u6a21\u578b  |\u5173\u952e\u8bcd\u62bd\u53d6\u53ef\u4ee5\u8bf4\u662fNLP\u5fc5\u5907\u6280\u80fd\u4e86| \r\n| \u673a\u5668\u5b66\u4e60\u9879\u76ee\u5b9e\u6218\u6a21\u677f    |\u6a21\u677f\u6765\u4e86\uff0c\u4ee5\u540e\u6709\u4efb\u52a1\u53ef\u4ee5\u5957\u7528\u4e86\uff0c\u65b9\u6cd5\u90fd\u5dee\u4e0d\u591a|\r\n| \u7535\u529b\u654f\u611f\u7528\u6237\u5206\u6790   |\u7ade\u8d5b\u5b9e\u4f8b\uff0c\u4e3b\u8981\u8bb2\u89e3\u7279\u5f81\u5de5\u7a0b\u7684\u4f5c\u7528| \r\n\r\n\r\n## \u6570\u636e\u5206\u6790\u5b9e\u6218\r\n\r\n- [x] \u6570\u636e\u5206\u6790\u7684\u91cd\u70b9\u53c8\u662f\u4ec0\u4e48\u5462\uff1f\r\n\r\n\u6570\u636e\u6316\u6398\u4e3b\u8981\u662f\u5efa\u6a21\u6765\u8fdb\u884c\u9884\u6d4b\uff0c\u6570\u636e\u5206\u6790\u5219\u91cd\u5728\u53ef\u89c6\u5316\u5c55\u793a\uff0c\u5206\u6790\u5176\u4e2d\u5404\u9879\u6307\u6807\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u7b49\u3002\u7ed9\u5927\u5bb6\u9009\u62e9\u4e86\u4e00\u4e9b\u7ecf\u5178\u5206\u6790\u6848\u4f8b\uff0c\u5f88\u591a\u90fd\u53ef\u4ee5\u76f4\u63a5\u5f53\u4f5c\u6a21\u677f\u6765\u4f7f\u7528\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| \u6563\u70b9\u56fe\u7ed8\u5236\u6280\u5de7       |\u90fd\u8bf4\u4e86\u53ef\u89c6\u5316\u662f\u91cd\u70b9\uff0c\u753b\u56fe\u80af\u5b9a\u5fc5\u987b\u7684\u4e86| \r\n| \u7ebd\u7ea6\u51fa\u79df\u8f66\u8fd0\u884c\u60c5\u51b5\u5206\u6790\u5efa\u6a21       |\u7528\u4e86\u597d\u591a\u5de5\u5177\u5305\uff0c\u53ef\u4ee5\u719f\u6089\u4e0b\u5bf9\u5730\u7406\u6570\u636e\u5982\u4f55\u8fdb\u884c\u5206\u6790\u4e0e\u5c55\u793a|\r\n| \u57fa\u4e8e\u7edf\u8ba1\u5206\u6790\u7684\u7535\u5f71\u63a8\u8350\u4efb\u52a1    |\u7edf\u8ba1\u5206\u6790\u5e38\u7528\u65b9\u6cd5\uff0c\u8fd8\u80fd\u505a\u63a8\u8350| \r\n| \u6570\u636e\u5206\u6790\u4e0e\u673a\u5668\u5b66\u4e60\u6a21\u677f      |\u8fd9\u4e2a\u6a21\u677f\u771f\u7684\u975e\u5e38\u5168\u9762\u4e86\uff0c\u5206\u6790\uff0c\u5c55\u793a\uff0c\u5efa\u6a21\uff0c\u8bc4\u4f30\uff0c\u7b80\u76f4\u4e00\u5957\u9f99\u4e86| \r\n| \u6570\u636e\u964d\u7ef4    |\u51e0\u79cd\u5e38\u7528\u7684\u964d\u7ef4\u7b97\u6cd5\u5bf9\u6bd4\u5206\u6790\u4e0e\u5c55\u793a| \r\n| \u5546\u54c1\u53ef\u89c6\u5316\u5c55\u793a\u4e0e\u6587\u672c\u5904\u7406       |\u6587\u672c\u6570\u636e\u9884\u5904\u7406\u4e0e\u53ef\u89c6\u5316\u5c55\u793a|\r\n| \u591a\u53d8\u91cf\u5206\u6790  |\u591a\u53d8\u91cf\u5206\u6790\u4e5f\u662f\u6570\u636e\u5206\u6790\u4e2d\u5e38\u89c1\u7684\u65b9\u6cd5| \r\n| \u5546\u54c1\u8ba2\u5355\u6570\u636e\u96c6\u5206\u6790    |\u8ba2\u5355\u6570\u636e\u96c6\u5206\u6790|\r\n| KIVA\u8d37\u6b3e\u6570\u636e\u5206\u6790   |\u8d37\u6b3e\u6570\u636e\u96c6\u5206\u6790| \r\n\r\n# \u6df1\u5ea6\u5b66\u4e60\r\n- [x] \u7ec8\u4e8e\u8bf4\u5230\u6df1\u5ea6\u5b66\u4e60\u4e86\uff0c\u90fd\u9700\u8981\u5b66\u4ec0\u4e48\u5462\uff1f\r\n\r\n\u6df1\u5ea6\u5b66\u4e60\u53ef\u4ee5\u8bf4\u662f\u5f53\u4e0b\u6700\u597d\u7528\u7684\u7b97\u6cd5\u4e86\uff0c\u5404\u4e2a\u9886\u57df\u90fd\u80fd\u5403\u5f97\u5f00\u3002\u5176\u5b9e\u6700\u6838\u5fc3\u7684\u8fd8\u662f\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\uff0c\u56e0\u4e3a\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5\u66f4\u9002\u7528\u4e8e\u56fe\u50cf\u548c\u6587\u672c\u6570\u636e\u3002\r\n\u4e3b\u8981\u9700\u8981\u638c\u63e1\u7684\u5c31\u662f\u7b97\u6cd5\u548c\u6846\u67b6\u4e86\uff0c\u7b97\u6cd5\u5c31\u662fCNN,RNN\u8fd9\u4e9b\u7ecf\u5178\u7f51\u7edc\u6a21\u578b\uff0c\u6846\u67b6\u5c31\u662f\u5b9e\u6218\u7684\u5de5\u5177\u4e86\u4f8b\u5982tenorflow,Pytorch\u7b49\uff0c\u540e\u9762\u8fd8\u4f1a\u8be6\u7ec6\u8bf4\u3002\r\n\r\n- [x] \u6df1\u5ea6\u5b66\u4e60\u542c\u8d77\u6765\u6bd4\u8f83\u9ad8\u5927\u4e0a\uff0c\u662f\u4e0d\u662f\u6bd4\u673a\u5668\u5b66\u4e60\u96be\u5f88\u591a\uff1f\r\n\r\n\u597d\u50cf\u73b0\u5728\u597d\u591a\u5c0f\u4f19\u4f34\u4e00\u62ff\u5230\u4efb\u52a1\uff0c\u7b2c\u4e00\u4e2a\u60f3\u6cd5\u90fd\u662f\u76f4\u63a5\u7528\u6df1\u5ea6\u5b66\u4e60\u505a\u3002\u5982\u679c\u6df1\u5ea6\u5b66\u4e60\u96be\u5ea6\u5927\uff0c\u505a\u8d77\u6765\u9ebb\u70e6\uff0c\u90a3\u8fd8\u80fd\u6709\u8fd9\u4e48\u9ad8\u7684\u70ed\u5ea6\u5417\uff1f\u5176\u5b9e\u6070\u6070\u76f8\u53cd\uff0c\u6211\u89c9\u5f97\u6df1\u5ea6\u5b66\u4e60\r\n\u771f\u7684\u6bd4\u673a\u5668\u5b66\u4e60\u7b80\u5355\u5f88\u591a\uff0c\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u9700\u8981\u6211\u4eec\u5bf9\u4e0d\u540c\u7684\u6570\u636e\u9009\u62e9\u4e0d\u540c\u7684\u9884\u5904\u7406\u65b9\u6cd5\u548c\u7279\u5f81\u5de5\u7a0b\u6784\u5efa\u65b9\u6cd5\u3002\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5957\u8def\u76f8\u5bf9\u6765\u8bf4\u66f4\u56fa\u5b9a\u4e00\u4e9b\uff0c\u800c\u4e14\u6709\u8fd9\u4e9b\u5f00\u6e90\u6846\u67b6\r\n\u548c\u5404\u5927\u7ecf\u5178\u7f51\u7edc\u67b6\u6784\uff0c\u6211\u4eec\u901a\u5e38\u9700\u8981\u505a\u7684\u5c31\u662f\u5957\u7528\u5c31\u53ef\u4ee5\u4e86\u3002\u6574\u4f53\u96be\u5ea6\u8981\u6bd4\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u66f4\u5bb9\u6613\u4e00\u4e9b\uff08\u53ea\u662f\u76f8\u5bf9\u6765\u8bf4\uff01\uff09\u3002\r\n\r\n## \u6df1\u5ea6\u5b66\u4e60\u5fc5\u5907\u7b97\u6cd5\r\n\r\n- [x] \u6df1\u5ea6\u5b66\u4e60\u90fd\u9700\u8981\u5b66\u54ea\u4e9b\u7b97\u6cd5\u5462\uff1f\r\n\r\n|\u7b97\u6cd5\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| \u795e\u7ecf\u7f51\u7edc       |\u795e\u7ecf\u7f51\u7edc\u662f\u6700\u57fa\u7840\u7684\uff0c\u76f8\u5f53\u4e8e\u4e3a\u540e\u9762\u7f51\u7edc\u7684\u5b66\u4e60\u6253\u4e0b\u57fa\u7840| \r\n| \u5377\u79ef\u795e\u7ecf\u7f51\u7edc       |\u8fd9\u4e2a\u5927\u5bb6\u542c\u8d77\u6765\u5f88\u719f\u6089\u5427\uff0c\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5927\u54e5\u5927\uff01\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u6838\u5fc3\u7f51\u7edc|\r\n| \u9012\u5f52\u795e\u7ecf\u7f51\u7edc    |\u5317\u4e54\u5cf0\uff0c\u5357\u6155\u5bb9\uff0c\u5b83\u5c31\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u5927\u54e5\u5927\u4e86\uff01| \r\n| \u5bf9\u6297\u751f\u6210\u7f51\u7edc   |\u73b0\u5728\u6bd4\u8f83\u706b\u7684\u6a21\u578b\uff0c\u73a9\u8d77\u6765\u5f88\u6709\u8da3\uff0c\u53ef\u4ee5\u8fdb\u884c\u5404\u79cd\u56fe\u50cf\u878d\u5408| \r\n| \u5e8f\u5217\u7f51\u7edc\u6a21\u578b   |NLP\u4e2d\u5e38\u7528\u67b6\u6784\uff0c\u673a\u5668\u5b66\u4e60\u7ffb\u8bd1\u6a21\u578b\uff0c\u5e94\u7528\u70b9\u6bd4\u8f83\u591a| \r\n| \u5404\u5927\u7ecf\u5178\u7f51\u7edc\u67b6\u6784    |\u521a\u624d\u8bf4\u7684CNN\u548cRNN\u90fd\u662f\u6bd4\u8f83\u57fa\u7840\u7684\u7f51\u7edc\u6a21\u578b\uff0c\u5728\u5176\u57fa\u7840\u4e0a\u8fd8\u6709\u5f88\u591a\u62d3\u5c55\u9700\u8981\u5927\u5bb6\u638c\u63e1| \r\n\r\n## \u6df1\u5ea6\u5b66\u4e60\u5fc5\u5907\u5de5\u5177\r\n- [x] \u4ec0\u4e48\u662f\u6846\u67b6\uff1f\u80fd\u5e2e\u6211\u4eec\u505a\u4ec0\u4e48\u5462\uff1f\r\n\r\n\u6846\u67b6\u597d\u6bd4\u8bf4\u4f60\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7f51\u7edc\u6a21\u578b\uff0c\u4f46\u662f\u5982\u679c\u628a\u5176\u4e2d\u5177\u4f53\u7684\u8ba1\u7b97\u8fc7\u7a0b\u5168\u90e8\u81ea\u5df1\u5b8c\u6210\u5c31\u592a\u9ebb\u70e6\u4e86\u3002\u6846\u67b6\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8ba1\u7b97\u65b9\u6cd5\u5e76\u4e14\u4e0d\u9700\u8981\u54b1\u4eec\u6765\u5b8c\u6210\uff0c\u4e00\u5957\u5168\u81ea\u52a8\u7684\u8ba1\u7b97\u3002\r\n\u76f8\u5f53\u4e8e\u6211\u4eec\u53ea\u9700\u8981\u8bbe\u8ba1\u597d\u7ed3\u6784\uff0c\u5177\u4f53\u7684\u65bd\u5de5\u5c31\u4ea4\u7ed9\u5b83\u4e86\u3002\u8981\u73a9\u6df1\u5ea6\u5b66\u4e60\u5fc5\u5907\u7684\u5c31\u662f\u6846\u67b6\u4e86\u3002\r\n\r\n- [x] \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u54ea\u5bb6\u5f3a\uff1f\r\n\r\ntensorflow,Pytorch,keras,caffe\u7b49\uff0c\u6709\u8fd9\u4e48\u591a\u6846\u67b6\uff0c\u6211\u8be5\u9009\u54ea\u4e00\u4e2a\u5462\uff1f\u662f\u4e0d\u662f\u4e0d\u540c\u6846\u67b6\u5dee\u5f02\u5f88\u5927\u5462\uff1f\r\n\u73b0\u5728\u6700\u4e3b\u6d41\u7684\u5c31\u662ftensorflow\u548cPyTorch\u4e86\uff0c\u76f8\u5f53\u4e8e\u80af\u5fb7\u57fa\u548c\u9ea6\u5f53\u52b3\u5427\u3002\u90fd\u5f88\u5f3a\uff0c\u81f3\u4e8e\u5177\u4f53\u9009\u62e9\u54ea\u4e00\u4e2a\u8fd8\u662f\u53c2\u8003\u5927\u5bb6\u5404\u81ea\u7684\u9879\u76ee\u7ec4\u548c\u4efb\u52a1\u9700\u6c42\u5427\u3002\u5982\u679c\u975e\u8981\u6211\u63a8\u8350\u4e00\u4e2a\r\n\u6211\u4f1a\u7ed9\u5927\u5bb6\u63a8\u8350PyTorch\uff0c\u56e0\u4e3a\u66f4\u7b80\u6d01\u901a\u4fd7\u3002\u8fd9\u4e9b\u6846\u67b6\u6211\u5168\u90fd\u7528\u8fc7\uff0c\u6700\u4e3b\u8981\u7684\u539f\u56e0\u5c31\u662f\u5de5\u4f5c\u4e2d\u7ecf\u5e38\u9700\u8981\u53c2\u8003\u8bba\u6587\u548c\u5f00\u6e90\u9879\u76ee\uff0c\u4e00\u822c\u522b\u4eba\u8bba\u6587\u4e2d\u6e90\u7801\u7528\u4ec0\u4e48\u6846\u67b6\u6211\u4e5f\u5c31\u63a5\u7740\u8fdb\u884c\r\n\u4e8c\u6b21\u5f00\u53d1\u4e86\uff0c\u6240\u4ee5\u8fd9\u4e9b\u6846\u67b6\u65e9\u665a\u5927\u5bb6\u90fd\u4f1a\u7528\u4e00\u904d\u7684\uff01\r\n\r\n- [x] \u6846\u67b6\u8be5\u600e\u4e48\u5b66\u5462\uff1f\r\n\r\n\u6846\u67b6\u6ca1\u6709\u4ec0\u4e48\u7406\u8bba\u53ef\u8c08\uff0c\u4e5f\u4e0d\u7528\u770b\u5404\u79cd\u957f\u7bc7\u5927\u8bba\uff0c\u76f4\u63a5\u7528\u5c31\u5f97\u4e86\uff01\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u5de5\u5177\u5305\uff0c\u8fb9\u7528\u8fb9\u5b66\uff0c\u6848\u4f8b\u5f53\u6a21\u677f\u6765\u603b\u7ed3\u5c31\u53ef\u4ee5\u4e86\uff01\r\n\r\n- [x] \u9488\u5bf9\u4e0d\u540c\u6846\u67b6\uff0c\u5206\u522b\u7ed9\u5927\u5bb6\u51c6\u5907\u4e86\u4e30\u5bcc\u7684\u5b9e\u6218\u9879\u76ee\u548c\u5b66\u4e60\u5185\u5bb9\u3002\r\n\r\n|\u6846\u67b6\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| Caffe\u6846\u67b6       |\u8fdc\u53e4\u65f6\u4ee3\u7684\u795e\u7ea7\u6846\u67b6\uff0c\u73b0\u5728\u6709\u70b9\u8dcc\u843d\u795e\u575b\u4e86\uff0c\u6211\u5b66\u4e60\u7684\u7b2c\u4e00\u4e2a\u6846\u67b6| \r\n| Tensorflow2\u7248\u672c       |2\u7248\u672c\u505a\u4e86\u5f88\u591a\u6539\u8fdb\uff0c\u7ec8\u4e8e\u66f4\u4eba\u6027\u5316\u4e86\uff0c\u7528\u8d77\u6765\u6bd41\u7248\u672c\u8212\u670d\u591a\u4e86|\r\n| Keras   |\u4e00\u53e5\u8bdd\u6982\u8ff0\u5c31\u662f\u7b80\u5355\uff01\u7b80\u5355\uff01\u7b80\u5355\uff01\u90fd\u4e0d\u7528\u5b66\uff0c\u770b\u4ee3\u7801\u975e\u5e38\u5bb9\u6613\u7406\u89e3| \r\n| PyTorch   |\u73b0\u9636\u6bb5\u6700\u706b\u7684\u6846\u67b6\uff0c\u6211\u4f30\u8ba1\u4e5f\u662f\u4eca\u5e74\uff082020\uff09\u6700\u6d41\u884c\u7684\u6846\u67b6\u4e86\uff0c\u63a8\u8350\uff01| \r\n\r\n# \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\r\n\u9488\u5bf9\u5404\u5927\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5747\u7ed9\u5927\u5bb6\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u5b9e\u6218\u6848\u4f8b\uff0c\u7528\u54ea\u4e2a\u5c31\u770b\u5927\u5bb6\u7684\u559c\u597d\u4e86\uff01\r\n\r\n## \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Tensorflow2\r\n- [x] \u8bf7\u7ed9\u6211\u4e00\u4e2a\u5b66tensorflow2\u7684\u7406\u7531!\r\n\r\n\u8c37\u6b4c\u51fa\u54c1\u6211\u5c31\u4e0d\u7528\u591a\u89e3\u91ca\u4e86\uff0c\u4eba\u5bb6\u8c37\u6b4c\u90a3\u4e48\u591a\u5f00\u6e90\u9879\u76ee\u80af\u5b9a\u90fd\u662f\u57fa\u4e8eTF\u6846\u67b6\u7684\uff0c\u8981\u5b66\u4e60\u6216\u8005\u53c2\u8003\u4eba\u5bb6\u5f00\u6e90\u9879\u76ee\u548c\u8bba\u6587\u80af\u5b9a\u8981\u5b66TF\u7684\uff0c\u5de5\u4e1a\u754c\u5e94\u7528\u4e5f\u975e\u5e38\u5e7f\u6cdb\u3002\u8fd9\u6ce2\u80af\u5b9a\u4e0d\u4e8f\uff01\r\n\r\n- [x] \u7ed9\u5927\u5bb6\u51c6\u5907\u7684\u6848\u4f8b\u5185\u5bb9\uff0c\u501f\u7528\u7a0b\u54ac\u91d1\u7684\u914d\u97f3\uff1a\u4e00\u4e2a\u5b57\uff0c\u5e72!\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| tensorflow\u5b89\u88c5\u4e0e\u7b80\u4ecb       |2\u7248\u672c\u7684\u4ecb\u7ecd\u4e8e\u5b89\u88c5\u65b9\u6cd5\uff0c\u7b80\u5355\u8fc7\u4e00\u4e0b\u5c31\u597d| \r\n| \u795e\u7ecf\u7f51\u7edc\u539f\u7406\u89e3\u8bfb\u4e0e\u6574\u4f53\u67b6\u6784       |\u590d\u4e60\u4e0b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784|\r\n| \u642d\u5efa\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u5206\u7c7b\u4e0e\u56de\u5f52\u4efb\u52a1    |\u7528TF\u5b8c\u6210\u57fa\u672c\u7684\u5206\u7c7b\u4e8e\u56de\u5f52\u4efb\u52a1\uff0c\u638c\u63e1\u5176\u5e94\u7528\u65b9\u6cd5| \r\n| \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u539f\u7406\u4e0e\u53c2\u6570\u89e3\u8bfb     |CNN\u7684\u67b6\u6784\u4e8e\u5176\u4e2d\u6bcf\u4e00\u4e2a\u53c2\u6570\u8be6\u89e3| \r\n| \u732b\u72d7\u8bc6\u522b\u5b9e\u6218    |\u7ecf\u5178\u7684\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\uff0c\u8fd9\u91cc\u8981\u8bb2\u5f88\u591a\u5185\u5bb9\uff0c\u975e\u5e38\u91cd\u8981| \r\n| \u56fe\u50cf\u6570\u636e\u589e\u5f3a\u5b9e\u4f8b       |\u6570\u636e\u589e\u5f3a\u53ef\u4ee5\u8bf4\u4e86\u73b0\u5728\u5fc5\u5907\u6280\u80fd\u4e86|\r\n| \u8bad\u7ec3\u7b56\u7565-\u8fc1\u79fb\u5b66\u4e60\u5b9e\u6218  |\u8fc1\u79fb\u5b66\u4e60\u5e26\u6765\u7684\u6548\u679c\u8fd8\u662f\u76f8\u5f53\u53ef\u4ee5\u7684| \r\n| \u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u4e0e\u8bcd\u5411\u91cf\u539f\u7406\u89e3\u8bfb    |RNN\u6a21\u578b\u89e3\u8bfb|\r\n| \u57fa\u4e8eTensorFlow\u5b9e\u73b0word2vec   |\u8bcd\u5411\u91cf\u6a21\u578b\u89e3\u8bfb\uff0c\u5e76\u57fa\u4e8eTF\u6765\u5b9e\u73b0| \r\n| \u57fa\u4e8eRNN\u6a21\u578b\u8fdb\u884c\u6587\u672c\u5206\u7c7b\u4efb\u52a1  |\u57fa\u4e8eTF\u5b8c\u6210\u6587\u672c\u5206\u7c7b\u4efb\u52a1| \r\n| tfrecord\u5236\u4f5c\u6570\u636e\u6e90    |\u6570\u636e\u6e90\u5236\u4f5c\u5b9e\u4f8b|\r\n| \u5c06CNN\u7f51\u7edc\u5e94\u7528\u4e8e\u6587\u672c\u5206\u7c7b\u5b9e\u6218   |CNN\u4e5f\u80fd\u73a9\u6587\u672c\u5206\u7c7b| \r\n| \u65f6\u95f4\u5e8f\u5217\u9884\u6d4b    |\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5904\u7406\u4e0e\u5efa\u6a21\u5b9e\u4f8b|\r\n| \u5bf9\u6297\u751f\u6210\u7f51\u7edc\u5b9e\u6218   |GAN\u6765\u5566\uff0c\u8fd9\u4e2a\u53ef\u597d\u73a9\u4e86| \r\n| \u57fa\u4e8eCycleGan\u5f00\u6e90\u9879\u76ee\u5b9e\u6218\u56fe\u50cf\u878d\u5408  |\u6211\u6700\u559c\u6b22\u73a9\u7684GAN\uff0c\u6548\u679c\u76f8\u5f53\u9017\u4e86\uff01| \r\n| \u7ecf\u5178\u7f51\u7edc\u67b6\u6784Resnet\u5b9e\u6218    |\u5fc5\u987b\u61c2\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u5b66\u5c31\u5f97\u4e86\uff01|\r\n\r\n## \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Pytorch\r\n\r\n- [x] \u542c\u8bf4\u5b83\u5f88\u706b\uff0c\u4e3a\u5565\u5462\uff1f\r\n\r\n19\u5e74\u5e95Pytorch\u6846\u67b6\u4f7f\u7528\u4eba\u6570\u5df2\u7ecf\u8d85\u8d8atensorflow\u6210\u4e3a\u5f53\u4e0b\u6700\u706b\u7684\u6846\u67b6\uff0c\u539f\u56e0\u5176\u5b9e\u5f88\u7b80\u5355\uff0c\u5927\u5bb6\u90fd\u559c\u6b22\u7528\u66f4\u7b80\u5355\u6613\u61c2\u7684\u6846\u67b6\u3002\u6574\u4f53\u7684\u611f\u89c9\u786e\u5b9e\u6bd4tensorflow\u597d\u4e0a\u624b\u800c\u4e14\r\n\u8c03\u8bd5\u8d77\u6765\u5341\u5206\u65b9\u4fbf\uff0c\u4e5f\u662f\u5efa\u8bae\u521d\u5b66\u7684\u540c\u5b66\u4eec\u4f18\u5148\u9009\u62e9Pytorch\u6846\u67b6\u3002\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| PyTorch\u6846\u67b6\u57fa\u672c\u5904\u7406\u64cd\u4f5c       |PyTorch\u7b80\u5355\u719f\u6089\u4e00\u4e0b\u5c31\u597d\uff0c\u4e0a\u624b\u975e\u5e38\u7b80\u5355| \r\n| \u795e\u7ecf\u7f51\u7edc\u5b9e\u6218\u5206\u7c7b\u4e0e\u56de\u5f52\u4efb\u52a1      |\u7528PyTorch\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u786e\u5b9e\u6bd4TF\u7528\u7684\u987a\u624b|\r\n| \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u539f\u7406\u4e0e\u53c2\u6570\u89e3\u8bfb    |CNN\u6a21\u578b\u67b6\u6784\u4e0e\u53c2\u6570\u4e66\u89e3\u8bfb| \r\n| \u56fe\u50cf\u8bc6\u522b\u6838\u5fc3\u6a21\u5757\u5b9e\u6218\u89e3\u8bfb    |\u975e\u5e38\u91cd\u8981\uff0cPyTorch\u4e2d\u7684\u56fe\u50cf\u5904\u7406\u6838\u5fc3\u6a21\u5757| \r\n| \u8fc1\u79fb\u5b66\u4e60\u7684\u4f5c\u7528\u4e0e\u5e94\u7528\u5b9e\u4f8b  |PyTorch\u4e2d\u52a0\u8f7d\u6a21\u578b\u6765\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60| \r\n| \u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u4e0e\u8bcd\u5411\u91cf\u539f\u7406\u89e3\u8bfb       |RNN\u6a21\u578b\u67b6\u6784\u89e3\u8bfb|\r\n| \u65b0\u95fb\u6570\u636e\u96c6\u6587\u672c\u5206\u7c7b\u5b9e\u6218 |\u57fa\u4e8ePyTorch\u6765\u6784\u5efa\u6587\u672c\u5206\u7c7b\u6a21\u578b| \r\n| \u5bf9\u6297\u751f\u6210\u7f51\u7edc\u67b6\u6784\u539f\u7406\u4e0e\u5b9e\u6218\u89e3\u6790    |GAN\u6a21\u578b\u901a\u4fd7\u89e3\u8bfb|\r\n| \u57fa\u4e8eCycleGan\u5f00\u6e90\u9879\u76ee\u5b9e\u6218\u56fe\u50cf\u878d\u5408   |PyTorch\u7248\u672c\u7684CYCLEGAN\uff0c\u8fd9\u4e2a\u5f00\u6e90\u9879\u76ee\u5199\u7684\u76f8\u5f53\u68d2| \r\n| OCR\u6587\u5b57\u8bc6\u522b\u539f\u7406  |OCR\u5176\u5b9e\u539f\u7406\u5f88\u7b80\u5355\uff0c\u9700\u8981\u591a\u4e2a\u6a21\u578b\u534f\u52a9\u5b8c\u6210| \r\n| OCR\u6587\u5b57\u8bc6\u522b\u9879\u76ee\u5b9e\u6218    |\u6784\u5efaOCR\u7f51\u7edc\u6a21\u578b|\r\n| \u57fa\u4e8e3D\u5377\u79ef\u7684\u89c6\u9891\u5206\u6790\u4e0e\u52a8\u4f5c\u8bc6\u522b   |\u75283D\u5377\u79ef\u6765\u5904\u7406\u89c6\u9891\u6570\u636e\u5e76\u5b8c\u6210\u884c\u4e3a\u8bc6\u522b| \r\n| \u57fa\u4e8ePyTorch\u5b9e\u6218BERT\u6a21\u578b    |BERT\u8fd9\u4e2a\u67b6\u6784\u592a\u706b\u4e86\uff0c\u5fc5\u5907\u6a21\u578b\u4e4b\u4e00|\r\n| PyTorch\u6846\u67b6\u5b9e\u6218\u6a21\u677f\u89e3\u8bfb   |\u63d0\u4f9b\u4e00\u4e2a\u6a21\u677f\uff0c\u4ee5\u540e\u6709\u4efb\u52a1\u53ef\u4ee5\u57fa\u4e8e\u6a21\u677f\u6765\u8fdb\u884c\u6539\u8fdb| \r\n\r\n## \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Keras\r\n\r\n- [x] Keras\u90fd\u8bf4\u7b80\u5355\uff0c\u6709\u591a\u7b80\u5355\u5462\uff1f\r\n\r\n\u6574\u4f53\u611f\u89c9\u5c31\u662f\u5565\u90fd\u4e0d\u7528\u5b66\uff0c\u4ece\u6848\u4f8b\u5f00\u59cb\u76f4\u63a5\u7528\u5c31\u597d\u4e86\uff0cTF2\u7248\u672c\u5176\u5b9e\u8ddfkeras\u5f88\u50cf\u3002\u9002\u5408\u505a\u5b9e\u9a8c\u5199\u8bba\u6587\uff0c\u7b80\u5355\u5feb\u901f\uff01\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| \u5b89\u88c5\u4e0e\u7b80\u4ecb      |keras\u5b89\u88c5\u4e0e\u4e0a\u624b\u5f88\u5bb9\u6613\uff0c\u57fa\u4e8etf\u6765\u8fdb\u884c| \r\n| \u642d\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b      |\u642d\u5efa\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6765\u8bd5\u8bd5\u6c34|\r\n| \u518d\u6218\u5377\u79ef\u795e\u7ecf\u7f51\u7edc    |CNN\u6a21\u578b\u6784\u5efa\u8d77\u6765\u4e5f\u975e\u5e38\u5bb9\u6613| \r\n| LSTM\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1    |LSTM\u6a21\u578b\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1| \r\n| \u6587\u672c\u5206\u7c7b\u5b9e\u6218  |\u6587\u672c\u5206\u7c7b\u5b9e\u4f8b| \r\n| \u591a\u6807\u7b7e\u4e0e\u591a\u8f93\u51fa       |\u591a\u6807\u7b7e\u4efb\u52a1\u5f88\u5e38\u89c1\uff0c\u5f88\u6709\u5b66\u4e60\u4ef7\u503c|\r\n| \u65b0\u95fb\u6570\u636e\u96c6\u6587\u672c\u5206\u7c7b\u5b9e\u6218 |\u57fa\u4e8ekeras\u7684\u6587\u672c\u5206\u7c7b\u4efb\u52a1| \r\n| \u6570\u636e\u589e\u5f3a    |\u6570\u636e\u589e\u5f3a\u5b9e\u4f8b\u89e3\u8bfb|\r\n| \u5bf9\u6297\u751f\u6210\u7f51\u7edc   |GAN\u67b6\u6784\uff0c\u7528keras\u6765\u505a\u66f4\u7b80\u5355| \r\n| \u8fc1\u79fb\u5b66\u4e60\u4e0eResnet\u6b8b\u5dee\u7f51\u7edc  |resnet\u6a21\u578b\u5927\u5bb6\u4e00\u5b9a\u81ea\u5df1\u52a8\u624b\u73a9\u4e00\u904d| \r\n| \u5730\u5740\u90ae\u7f16\u591a\u5e8f\u5217\u4efb\u52a1   |\u6587\u672c\u6a21\u578b\u5b9e\u4f8b|\r\n| seq2seq\u7f51\u7edc\u5b9e\u6218   |\u5e8f\u5217\u7f51\u7edc\u6a21\u578b\u5e94\u7528\u8fd8\u662f\u6bd4\u8f83\u5e7f\u7684| \r\n| \u5b9e\u6218\u6a21\u677f\u603b\u7ed3    |\u7ed9\u5927\u5bb6\u63d0\u4f9b\u7684keras\u6a21\u677f\uff0c\u518d\u6709\u4efb\u52a1\u76f4\u63a5\u5199\u5c31\u597d|\r\n\r\n## \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6-Caffe\r\n\r\n- [x] Caffe\u6846\u67b6\u73b0\u9636\u6bb5\u8fd8\u6709\u5fc5\u8981\u5b66\u4e60\u5417\uff1f\r\n\r\n\u6211\u89c9\u5f97\u73b0\u9636\u6bb5\u5df2\u7ecf\u6709tensorflow\u548cpytorch\u4e86\uff0c\u6682\u65f6\u8f6e\u4e0d\u5230caffe\u767b\u573a\u4e86\uff0c\u521d\u5b66\u7684\u540c\u5b66\u4eec\u5c31\u4e0d\u63a8\u8350\u4e86\u3002\u53ef\u80fd\u6709\u4e9b\u8bba\u6587\u548c\u4efb\u52a1\u8fd8\u662f\u9700\u8981caffe\u6846\u67b6\uff0c\u9700\u8981\u7684\u540c\u5b66\u4eec\u81ea\u53d6\u5c31\u597d\u5566\uff01\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| Caffe\u914d\u7f6e\u6587\u4ef6\u89e3\u8bfb      |Caffe\u6846\u67b6\u5e38\u7528\u914d\u7f6e\u6587\u4ef6\u89e3\u8bfb| \r\n| \u591a\u79cd\u6570\u636e\u96c6\u6784\u5efa\u65b9\u6cd5    |\u6570\u636e\u96c6\u6784\u5efa\u65b9\u6cd5\uff0c\u8fd9\u4e2a\u5f88\u91cd\u8981|\r\n| Caffe\u5e38\u7528\u5de5\u5177\u89e3\u8bfb  |\u91cc\u9762\u5185\u7f6e\u4e86\u5f88\u591a\u5c0f\u5de5\u5177\uff0c\u53ef\u4ee5\u5feb\u901f\u5b8c\u6210\u4efb\u52a1| \r\n| \u4eba\u8138\u68c0\u6d4b\u5b9e\u6218    |\u57fa\u4e8eCaffe\u6846\u67b6\u6784\u5efa\u4eba\u8138\u68c0\u6d4b\u6a21\u578b| \r\n| \u4eba\u8138\u5173\u952e\u70b9\u5b9a\u4f4d\u5b9e\u6218  |\u57fa\u4e8eCaffe\u6846\u67b6\u5b8c\u6210\u4eba\u8138\u5173\u952e\u70b9\u8bc6\u522b\u6a21\u578b| \r\n\r\n## \u8ba1\u7b97\u673a\u89c6\u89c9\r\n\r\n- [x] \u8ba1\u7b97\u673a\u89c6\u89c9\u53d1\u5c55\u8fd9\u4e48\u706b\uff0c\u5c31\u4e1a\u9762\u8bd5\u90fd\u9700\u8981\u54ea\u4e9b\u6838\u5fc3\u6280\u80fd\u5462\uff1f\r\n\r\n\u8ba1\u7b97\u673a\u89c6\u89c9\u8fd9\u4e2a\u884c\u4e1a\u6211\u5c31\u4e0d\u7528\u591a\u8bf4\u5566\uff0c\u5f53\u4e0b\u6700\u5403\u9999\u7684\u4e86\u3002\u90a3\u90fd\u9700\u8981\u5b66\u4ec0\u4e48\u5462\uff1f\u6700\u6838\u5fc3\u7684\u5176\u5b9e\u5c31\u4e24\u90e8\u5206\uff0c\u4e00\u4e2a\u662f\u56fe\u50cf\u5904\u7406\uff0c\u53e6\u4e00\u4e2a\u662f\u56fe\u50cf\u5efa\u6a21\u3002\u6240\u8c13\u7684\u56fe\u50cf\u5904\u7406\u5c31\u662fOpencv\r\n\u90a3\u4e00\u5957\u5566\uff0c\u8fd9\u4e2a\u5de5\u5177\u5305\u7b80\u76f4\u65e0\u654c\u4e86\uff0c\u4f46\u51e1\u4f60\u8981\u7528\u7684\u8fd9\u91cc\u5168\u80fd\u627e\u5230\u3002\u56fe\u50cf\u5efa\u6a21\u4e3b\u8981\u5c31\u662f\u7528\u6df1\u5ea6\u5b66\u4e60\u6765\u5b8c\u6210\u68c0\u6d4b\uff0c\u8bc6\u522b\u7b49\u4efb\u52a1\u3002\u73b0\u9636\u6bb5\u7684\u5b66\u4e60\u6211\u89c9\u5f97\u5173\u4e8e\u4f20\u7edf\u56fe\u50cf\u5904\u7406\u7b97\u6cd5\u53ef\u4ee5\r\n\u90fd\u4e0d\u7528\u53bb\u770b\u5566\uff0c\u7b80\u5355\u719f\u6089\u4e00\u4e0b\u5c31\u597d\uff0c\u4e3b\u6d41\u7684\u65b9\u5411\u8fd8\u662f\u7528\u6df1\u5ea6\u5b66\u4e60\u6765\u505a\uff0c\u8fd9\u5c31\u9700\u8981\u5927\u5bb6\u591a\u591a\u6700\u65b0\u7684\u9605\u8bfb\u8bba\u6587\u4e86\u3002\r\n\r\n## Opencv\u56fe\u50cf\u5904\u7406\u5b9e\u6218\r\n\r\n- [x] \u5173\u4e8eopencv\u6211\u8be5\u600e\u4e48\u5b66\u5462\uff1f\r\n\r\n\u5efa\u8bae\u5927\u5bb6\u9009\u62e9Python\u7248\u672c\u6765\u8fdb\u884c\u5b66\u4e60\u548c\u4f7f\u7528\uff0c\u8ddf\u5176\u4ed6\u5de5\u5177\u5305\u4e00\u6837\uff0c\u8c03\u5c31\u5b8c\u4e8b\u4e86\uff01\u9047\u5230\u4e0d\u719f\u6089\u7684\u591a\u67e5API\uff0c\u8fb9\u7528\u8fb9\u5b66\u662f\u6700\u5feb\u7684\u9014\u5f84\u3002Opencv\u4e2d\u57fa\u672c\u6240\u6709\u51fd\u6570\u90fd\u6d89\u53ca\u975e\u5e38\u591a\u7684\r\n\u6570\u5b66\u516c\u5f0f\uff0c\u8fd9\u4e9b\u5927\u5bb6\u90fd\u53ef\u4ee5\u5148\u653e\u4e00\u653e\uff0c\u5982\u679c\u628a\u6bcf\u4e2a\u7b97\u6cd5\u6bcf\u4e2a\u516c\u5f0f\u90fd\u5b66\u4e00\u904d\u90a3\u5f97\u7334\u5e74\u9a6c\u6708\u4e86\uff0c\u4ee5\u540e\u7528\u5230\u4e86\u518d\u8bf4\u5b8c\u5168\u6765\u5f97\u53ca\u3002\r\n\r\n- [x] \u8fd9\u4e9b\u6848\u4f8b\u6211\u9700\u8981\u81ea\u5df1\u52a8\u624b\u5199\u4e00\u904d\u5417\uff1f\r\n\r\n\u7ed9\u5927\u5bb6\u51c6\u5907\u4e86\u975e\u5e38\u591a\u7684\u5b66\u4e60\u8d44\u6e90\u548c\u6848\u4f8b\uff0c\u524d\u671f\u53ea\u9700\u8981\u719f\u6089\u5373\u53ef\uff0c\u5de5\u5177\u5305\u5c31\u662f\u7528\u7684\uff0c\u9762\u5411\u590d\u5236\u7c98\u8d34\u7f16\u7a0b\u4e5f\u662f\u4e00\u9879\u6280\u80fd\uff01\r\n\r\n|\u6848\u4f8b\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| Opencv\u7b80\u4ecb\u4e0e\u73af\u5883\u914d\u7f6e      |\u73af\u5883\u5b89\u88c5\u4e0e\u914d\u7f6e| \r\n| \u56fe\u50cf\u57fa\u672c\u64cd\u4f5c      |\u7528opencv\u5b8c\u6210\u57fa\u672c\u7684\u56fe\u50cf\u5904\u7406\u64cd\u4f5c\uff0c\u7ec3\u624b!|\r\n| \u9608\u503c\u4e0e\u5e73\u6ed1\u5904\u7406    |\u6700\u5e38\u7528\u7684\u5904\u7406\u64cd\u4f5c\uff0c\u51e0\u884c\u4ee3\u7801\u5c31\u80fd\u641e\u5b9a| \r\n| \u56fe\u50cf\u5f62\u6001\u5b66\u64cd\u4f5c    |\u8fd9\u51e0\u4e2a\u5f62\u6001\u5b66\u64cd\u4f5c\u719f\u6089\u4e0b\u5373\u53ef| \r\n| \u56fe\u50cf\u68af\u5ea6\u8ba1\u7b97  |\u56fe\u50cf\u68af\u5ea6\u8ba1\u7b97\u5b9e\u4f8b| \r\n| \u8fb9\u7f18\u68c0\u6d4b       |\u8fb9\u7f18\u68c0\u6d4b\u7684\u5e94\u7528\u9762\u975e\u5e38\u5e7f|\r\n| \u56fe\u50cf\u91d1\u5b57\u5854\u4e0e\u8f6e\u5ed3\u68c0\u6d4b |\u8f6e\u5ed3\u68c0\u6d4b\u5b9e\u4f8b\uff0c\u6548\u679c\u8fd8\u662f\u4e0d\u9519\u7684| \r\n| \u76f4\u65b9\u56fe\u4e0e\u5085\u91cc\u53f6\u53d8\u6362    |\u719f\u6089\u4e0b\u5373\u53ef|\r\n| \u9879\u76ee\u5b9e\u6218-\u4fe1\u7528\u5361\u6570\u5b57\u8bc6\u522b   |\u52a8\u624b\u505a\u4e00\u4e2a\u5b9e\u6218\u9879\u76ee\uff0c\u5bf9\u4fe1\u7528\u5361\u6570\u5b57\u8fdb\u884c\u68c0\u6d4b\u4e0e\u8bc6\u522b| \r\n| \u9879\u76ee\u5b9e\u6218-\u6587\u6863\u626b\u63cfOCR\u8bc6\u522b  |\u626b\u63cf\u6587\u6863\u6570\u636e\uff0c\u8fdb\u884cocr\u8bc6\u522b| \r\n| \u56fe\u50cf\u7279\u5f81-harris   |\u5e38\u7528\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff0c\u7b97\u6cd5\u7b80\u5355\u719f\u6089\u5c31\u53ef\u4ee5|\r\n| \u56fe\u50cf\u7279\u5f81-sift   |\u6700\u8001\u724c\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u4e86\uff0c\u6570\u5b66\u8fd8\u662f\u86ee\u591a\u7684| \r\n| \u6848\u4f8b\u5b9e\u6218-\u5168\u666f\u56fe\u50cf\u62fc\u63a5   |\u5168\u666f\u6444\u50cf\u5927\u5bb6\u80af\u5b9a\u90fd\u73a9\u8fc7\uff0c\u600e\u4e48\u5b9e\u73b0\u7684\u5462\uff1f|\r\n| \u9879\u76ee\u5b9e\u6218-\u505c\u8f66\u573a\u8f66\u4f4d\u8bc6\u522b     |\u91cd\u578b\u9879\u76ee\uff0c\u4ece\u96f6\u5f00\u59cb\u6784\u5efa\u505c\u8f66\u573a\u8f66\u4f4d\u8bc6\u522b\u6a21\u578b| \r\n| \u9879\u76ee\u5b9e\u6218-\u7b54\u9898\u5361\u8bc6\u522b\u5224\u5377     |\u54b1\u4eec\u4e5f\u6574\u4e00\u4e2a\u81ea\u52a8\u9605\u5377\u7684\u73a9\u73a9|\r\n| \u80cc\u666f\u5efa\u6a21  |\u5e38\u89c4\u5904\u7406\u65b9\u6cd5| \r\n| \u5149\u6d41\u4f30\u8ba1    |\u7b80\u5355\u719f\u6089\u5373\u53ef| \r\n| Opencv\u7684DNN\u6a21\u5757  |\u52a0\u8f7d\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u8bc6\u522b| \r\n| \u9879\u76ee\u5b9e\u6218-\u76ee\u6807\u8ffd\u8e2a       |\u8ffd\u8e2a\u7684\u6548\u679c\u8fd8\u662f\u86ee\u6709\u610f\u601d\u7684|\r\n| \u5377\u79ef\u539f\u7406\u4e0e\u64cd\u4f5c |\u5377\u79ef\u5230\u54ea\u90fd\u662f\u6838\u5fc3| \r\n| \u9879\u76ee\u5b9e\u6218-\u75b2\u52b3\u68c0\u6d4b |\u57fa\u4e8e\u6444\u50cf\u5934\u68c0\u6d4b\u75b2\u52b3|\r\n\r\n## \u8ba1\u7b97\u673a\u89c6\u89c9\u5b9e\u6218\u9879\u76ee\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff09\r\n\r\n- [x] \u8fd9\u4e9b\u9879\u76ee\u6211\u90fd\u9700\u8981\u638c\u63e1\u5417\uff1f\r\n\r\n\u5bf9\u4e8e\u51c6\u5907\u9762\u8bd5\u5c31\u4e1a\u7684\u540c\u5b66\u4eec\u5efa\u8bae\u90fd\u8fc7\u4e00\u904d\uff0c\u91cc\u9762\u7684\u601d\u60f3\u90fd\u662f\u86ee\u597d\u7684\uff0c\u5927\u90e8\u5206\u90fd\u662f\u57fa\u4e8e\u8bba\u6587\u6765\u8fdb\u884c\u590d\u73b0\uff0c\u6709\u65f6\u95f4\u7684\u540c\u5b66\u6700\u597d\r\n\u5148\u9605\u8bfb\u4e00\u904d\u8bba\u6587\u518d\u5f00\u59cb\u7814\u7a76\u4ee3\u7801\uff0c\u91cc\u9762\u7684\u4ee3\u7801\u91cf\u90fd\u4f1a\u76f8\u5bf9\u8f83\u5927\uff0c\u5efa\u8bae\u4ecedebug\u6a21\u5f0f\u5165\u624b\uff0c\u4e00\u884c\u4ee3\u7801\u4e00\u884c\u4ee3\u7801\u6765\u770b\uff0c\u6211\u5728\r\n\u8bb2\u89e3\u8fc7\u7a0b\u4e2d\u4e5f\u4f1a\u8fdb\u5165debug\u6a21\u5f0f\u7ed9\u5927\u5bb6\u9010\u884c\u8fdb\u884c\u8bb2\u89e3\u3002\r\n\r\n- [x] \u6709\u6ca1\u6709\u54ea\u4e2a\u662f\u9700\u8981\u91cd\u70b9\u5b66\u4e60\u7684\uff1f\u6700\u597d\u80fd\u5199\u5728\u7b80\u5386\u91cc\u9762\u5462\uff1f\r\n\r\n\u91cd\u70b9\u63a8\u8350Mask-rcnn\u5b9e\u6218\u9879\u76ee\uff0c\u53ef\u4ee5\u8bf4\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u901a\u7528\u9879\u76ee\uff0c\u68c0\u6d4b\uff0c\u8bc6\u522b\uff0c\u5206\u5272\u4e00\u6b65\u5168\u5230\u4f4d\u4e86\uff01\u5e94\u7528\u573a\u666f\u975e\u5e38\r\n\u5e7f\uff0c\u4e5f\u9002\u5408\u8fdb\u884c\u4e8c\u6b21\u5f00\u53d1\u548c\u6539\u8fdb\uff0c\u5982\u679c\u8981\u5199\u5728\u7b80\u5386\u91cc\u80af\u5b9a\u975e\u5b83\u83ab\u5c5e\u4e86\uff0c\u7b97\u6cd5\u539f\u7406\u548c\u6e90\u7801\u90fd\u9700\u8981\u5927\u5bb6\u719f\u6089\uff0c\u5728\u8bfe\u7a0b\u4e2d\r\n\u6211\u4f1a\u91cd\u70b9\u8bb2\u89e3\u8be5\u9879\u76ee\uff0c\u5e76\u5e94\u7528\u5230\u81ea\u5df1\u7684\u6570\u636e\u4efb\u52a1\u4e2d\uff01\r\n\r\n|\u9879\u76ee\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| \u56fe\u50cf\u98ce\u683c\u8f6c\u6362\uff08style-transfer\uff09      |\u4e3b\u8981\u6765\u5b66\u4e60\u5176\u601d\u60f3\uff0c\u6548\u679c\u8fd8\u662f\u5f88\u6709\u610f\u601d\u7684| \r\n| \u56fe\u50cf\u7f3a\u5931\u81ea\u52a8\u8865\u5168      |GAN\u7f51\u7edc\u5e94\u7528\u573a\u666f\u975e\u5e38\u591a\uff0c\u56fe\u50cf\u4e5f\u80fd\u81ea\u5df1\u4fee\u590d|\r\n| \u8d85\u5206\u8fa8\u7387\u91cd\u6784    |\u8fd1\u51e0\u5e74\u7814\u7a76\u7684\u91cd\u70b9\u9886\u57df\u4e4b\u4e00\uff0c\u8fd9\u7bc7\u8bba\u6587\u7684\u6548\u679c\u5df2\u7ecf\u975e\u5e38\u4e0d\u9519\u4e86| \r\n| \u7269\u4f53\u68c0\u6d4b\u6846\u67b6-MaskRcnn\u9879\u76ee    |\u8fd9\u4e2a\u5c31\u662f\u6211\u91cd\u70b9\u5f3a\u8c03\u7684\u5f00\u6e90\u9879\u76ee\uff0c\u5fc5\u770b\uff01\u5fc5\u770b\uff01\u5fc5\u770b\uff01| \r\n| MaskRcnn\u7f51\u7edc\u6846\u67b6\u6e90\u7801\u8be6\u89e3  |\u6e90\u7801\u975e\u5e38\u91cd\u8981\uff0c\u6bcf\u4e00\u884c\u90fd\u9700\u8981\u61c2\uff01| \r\n| \u57fa\u4e8eMASK-RCNN\u6846\u67b6\u8bad\u7ec3\u81ea\u5df1\u7684\u6570\u636e       |\u5982\u4f55\u6807\u6ce8\u56fe\u50cf\u6570\u636e\u5e76\u8fdb\u884c\u8bad\u7ec3\u5462\uff1f\u8fd9\u91cc\u7ed9\u4f60\u7b54\u6848|\r\n| \u4eba\u4f53\u59ff\u6001\u8bc6\u522bdemo |MaskRcnn\u5e94\u7528\u573a\u666f\u975e\u5e38\u591a| \r\n| \u7269\u4f53\u68c0\u6d4bFasterRcnn\u7cfb\u5217    |\u7269\u4f53\u68c0\u6d4b\u7684\u7ecf\u5178\u4e4b\u4f5c\uff0c\u53ef\u4ee5\u5f53\u4f5c\u5b66\u4e60\u8d44\u6e90|\r\n| \u57fa\u4e8eCycleGan\u5f00\u6e90\u9879\u76ee\u5b9e\u6218\u56fe\u50cf\u878d\u5408   |PyTorch\u7248\u672c\u7684CYCLEGAN\uff0c\u8fd9\u4e2a\u5f00\u6e90\u9879\u76ee\u5199\u7684\u76f8\u5f53\u68d2| \r\n| OCR\u6587\u5b57\u8bc6\u522b\u539f\u7406  |OCR\u5176\u5b9e\u539f\u7406\u5f88\u7b80\u5355\uff0c\u9700\u8981\u591a\u4e2a\u6a21\u578b\u534f\u52a9\u5b8c\u6210| \r\n| OCR\u6587\u5b57\u8bc6\u522b\u9879\u76ee\u5b9e\u6218    |\u6784\u5efaOCR\u7f51\u7edc\u6a21\u578b|\r\n| \u57fa\u4e8e3D\u5377\u79ef\u7684\u89c6\u9891\u5206\u6790\u4e0e\u52a8\u4f5c\u8bc6\u522b   |\u75283D\u5377\u79ef\u6765\u5904\u7406\u89c6\u9891\u6570\u636e\u5e76\u5b8c\u6210\u884c\u4e3a\u8bc6\u522b| \r\n\r\n\r\n## \u81ea\u7136\u8bed\u8a00\u5904\u7406\r\n\r\n- [x] NLP\u5b66\u4e60\u96be\u5ea6\u5927\u4e0d\u5927\uff1f\u5c31\u4e1a\u65b9\u5411\u600e\u4e48\u6837\u5462\uff1f\r\n\r\n\u96be\u5ea6\u53ef\u4ee5\u8bf4\u8fd8\u662f\u86ee\u5927\u7684\uff0c\u5bf9\u4e8e\u56fe\u50cf\u6765\u8bf4\uff0c\u6570\u636e\u90fd\u662f\u56fa\u5b9a\u7684\uff0c\u62cd\u4e86\u4ec0\u4e48\u5c31\u662f\u4ec0\u4e48\uff01\u4f46\u662f\u6587\u672c\u6570\u636e\u5c31\u6ca1\u90a3\u4e48\u56fa\u5b9a\u4e86\uff0c\u4eba\u7c7b\r\n\u6709\u65f6\u5019\u7406\u89e3\u8d77\u6765\u90fd\u4e0d\u5bb9\u6613\uff0c\u66f4\u4f55\u51b5\u8ba1\u7b97\u673a\u4e86\u3002\u9ad8\u6311\u6218\u4e5f\u662f\u9ad8\u6536\u76ca\uff0cNLP\u53d1\u5c55\u524d\u666f\u8fd8\u662f\u975e\u5e38\u4e0d\u9519\u7684\uff0c\u81f3\u4e8e\u5177\u4f53\u9009\u62e9\u54ea\u4e2a\u65b9\u5411\r\n\u5176\u5b9e\u8fd8\u662f\u770b\u5927\u5bb6\u7684\u559c\u597d\u4e86\uff01\r\n\r\n## \u81ea\u7136\u8bed\u8a00\u5904\u7406\u5b9e\u6218\u9879\u76ee\uff08\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff09\r\n\r\n- [x] \u8fd9\u4e48\u591a\u9879\u76ee\uff0c\u6709\u6ca1\u6709\u54ea\u4e2a\u662f\u9700\u8981\u91cd\u70b9\u5b66\u4e60\u7684\uff1f\u6700\u597d\u80fd\u5199\u5728\u7b80\u5386\u91cc\u9762\u5462\uff1f\r\n\r\n18\u5e74\u7684\u65f6\u5019\u8c37\u6b4c\u4e00\u7bc7\u8bba\u6587\u6a2a\u7a7a\u51fa\u4e16\uff0cBERT\uff01\u76f8\u5f53\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u901a\u7528\u89e3\u51b3\u6846\u67b6\u4e86\uff0c\u57fa\u672c\u6240\u6709\u4efb\u52a1\u90fd\u80fd\u505a\uff01\r\n\u8fd9\u4e2a\u9700\u8981\u5927\u5bb6\u91cd\u70b9\u6765\u5b66\u4e60\uff0c\u5e76\u4e14\u53ef\u4ee5\u5f53\u4f5c\u9879\u76ee\u5199\u5728\u7b80\u5386\u91cc\uff0c\u53ef\u4ee5\u8bf4\u662f\u5f53\u4e0bNLP\u5fc5\u5907\u6280\u80fd\u4e4b\u4e00\u5566\uff01\r\n\r\n|\u9879\u76ee\u540d\u79f0|\u5185\u5bb9\u6982\u8ff0|\r\n| --------   |:----:  |\r\n| \u8bed\u8a00\u6a21\u578b      |\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5927\u5bb6\u719f\u6089\u4e0b\uff0c\u540e\u7eed\u8bcd\u5411\u91cf\u7684\u57fa\u7840| \r\n| \u4f7f\u7528Gemsim\u6784\u5efa\u8bcd\u5411\u91cf      |Gensim\u8fd9\u4e2a\u5305\u5b9e\u5728\u597d\u7528\uff01|\r\n| \u57fa\u4e8eword2vec\u7684\u5206\u7c7b\u4efb\u52a1   |\u5148\u7528\u8fd9\u4e2a\u4f8b\u5b50\u6765\u7406\u89e3\u4e0a\u5982\u4f55\u4f7f\u7528\u8bcd\u5411\u91cf| \r\n| NLP-\u6587\u672c\u7279\u5f81\u65b9\u6cd5\u5bf9\u6bd4    |\u6587\u672c\u7279\u5f81\u6784\u9020\u65b9\u6cd5\u8fd9\u4e48\u591a\uff0c\u54ea\u4e00\u4e2a\u66f4\u597d\u7528\u5462\uff1f| \r\n| LSTM\u60c5\u611f\u5206\u6790  |\u7528\u8fd9\u4e2a\u9879\u76ee\u6765\u7406\u89e3RNN\u6a21\u578b\u6240\u9700\u7684\u8f93\u5165\u957f\u4ec0\u4e48\u6837\u5b50| \r\n| NLP-\u76f8\u4f3c\u5ea6\u6a21\u578b       |\u6587\u672c\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65b9\u6cd5|\r\n| \u5bf9\u8bdd\u673a\u5668\u4eba |\u57fa\u4e8etensorlfow\u6846\u67b6\u6784\u5efa\u4e00\u4e2a\u804a\u5929\u673a\u5668\u4eba| \r\n| \u52a8\u624b\u6253\u9020\u81ea\u5df1\u7684\u8f93\u5165\u6cd5    |\u80fd\u4e0d\u80fd\u6784\u5efa\u4e00\u6b3e\u81ea\u5df1\u7684\u8f93\u5165\u6cd5\u5462\uff1f\u5e2e\u4f60\u641e\u5b9a\uff01|\r\n| \u673a\u5668\u4eba\u5199\u5510\u8bd7   |\u770b\u770b\u6a21\u578b\u5199\u51fa\u7684\u5510\u8bd7\u548b\u6837\uff01| \r\n| NMT\u673a\u5668\u7ffb\u8bd1\u6846  |\u5f00\u6e90\u9879\u76ee\uff0c\u53ef\u4ee5\u8fdb\u884c\u4e8c\u6b21\u5f00\u53d1| \r\n| \u5730\u5740\u90ae\u7f16\u591a\u5e8f\u5217\u4efb\u52a1    |\u7ecf\u5178\u6587\u672c\u5206\u7c7b\u4efb\u52a1|\r\n| \u81ea\u7136\u8bed\u8a00\u5904\u7406\u901a\u7528\u6846\u67b6BERT\u539f\u7406   |\u8fd9\u4e2a\u5c31\u662f\u4e0a\u9762\u8bf4\u7684BERT\u4e86\uff0c\u91cd\u70b9\uff01\u91cd\u70b9\uff01\u91cd\u70b9\uff01| \r\n| \u8c37\u6b4c\u5f00\u6e90\u9879\u76eeBERT\u6e90\u7801\u89e3\u8bfb      |\u6e90\u7801\u975e\u5e38\u91cd\u8981\uff0c\u6bcf\u4e00\u884c\u90fd\u9700\u8981\u7406\u89e3| \r\n| \u57fa\u4e8eBERT\u7684\u4e2d\u6587\u60c5\u611f\u5206\u6790      |\u57fa\u4e8e\u5f00\u6e90\u9879\u76ee\u8fdb\u884c\u6a21\u578b\u5f00\u53d1|\r\n| \u57fa\u4e8eBERT\u7684\u4e2d\u6587\u547d\u540d\u5b9e\u4f53\u8bc6\u522b   |\u57fa\u4e8e\u5f00\u6e90\u9879\u76ee\u8fdb\u884c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b| \r\n\r\n# \u6700\u540e\u5520\u53e8\u51e0\u53e5\r\n\r\n\u901a\u8fc7\u8fd9\u51e0\u5e74\u7684\u7ebf\u4e0a\u8bfe\u7a0b\u8fd8\u6709\u7ebf\u4e0b\u7684\u4f01\u4e1a\u57f9\u8bad\u7ed3\u8bc6\u4e86\u5f88\u591a\u5c0f\u4f19\u4f34\uff0c\u673a\u6784\u548c\u540c\u5b66\u4eec\u7684\u4fe1\u4efb\u662f\u6211\u7ee7\u7eed\u66f4\u65b0\u8bfe\u7a0b\u6700\u5927\u7684\u52a8\u529b\r\n\u3002\u5927\u5bb6\u8ba4\u8bc6\u6211\u57fa\u672c\u90fd\u662f\u901a\u8fc7\u89c6\u9891\u8bfe\u7a0b\uff0c\u5f88\u5f00\u5fc3\u80fd\u7ed9\u5927\u5bb6\u5e26\u6765\u6536\u83b7\uff0c\u8bb0\u5f97\u6700\u5174\u594b\u7684\u5c31\u662f\u8ddf\u5bb6\u4eba\u5206\u4eab\u53c8\u6709\u5c0f\u4f19\u4f34\u6536\u83b7\r\noffer\u4e86\u3002\u611f\u8c22\u8fd9\u4e48\u591a\u5c0f\u4f19\u4f34\u7684\u652f\u6301\uff0c\u52a0\u6cb9\uff0c\u4f60\u4eec\u90fd\u662f\u6700\u68d2\u7684\uff01\r\n \r\n<div align=\"center\">\r\n<a href=\"https://github.com/tangyudi/Ai-learn\"><img src=\"https://github.com/tangyudi/Ai-learn/blob/master/imgs/logo5.png\" width=\"600\"/></a>\r\n<br >\r\n</sub>\r\n</div>\r\n",
	"cdp chrome cli crawler crawling data-mining dsl go golang hacktoberfest hacktoberfest2021 library query-language scraper scraping scraping-websites tool": "# Ferret\n<p align=\"center\">\n\t<a href=\"https://goreportcard.com/report/github.com/MontFerret/ferret\">\n\t\t<img alt=\"Go Report Status\" src=\"https://goreportcard.com/badge/github.com/MontFerret/ferret\">\n\t</a>\n\t<a href=\"https://github.com/MontFerret/ferret/actions\">\n\t\t<img alt=\"Build Status\" src=\"https://github.com/MontFerret/ferret/workflows/build/badge.svg\">\n\t</a>\n\t<a href=\"https://codecov.io/gh/MontFerret/ferret\">\n\t\t<img src=\"https://codecov.io/gh/MontFerret/ferret/branch/master/graph/badge.svg\" />\n\t</a>\n\t<a href=\"https://discord.gg/kzet32U\">\n\t\t<img alt=\"Discord Chat\" src=\"https://img.shields.io/discord/501533080880676864.svg\">\n\t</a>\n\t<a href=\"https://t.me/montferret_chat\">\n\t\t<img alt=\"Discord Chat\" src=\"https://raw.githubusercontent.com/Patrolavia/telegram-badge/master/chat.svg\">\n\t</a>\n\t<a href=\"https://github.com/MontFerret/ferret/releases\">\n\t\t<img alt=\"Ferret release\" src=\"https://img.shields.io/github/release/MontFerret/ferret.svg\">\n\t</a>\n\t<a href=\"https://opensource.org/licenses/Apache-2.0\">\n\t\t<img alt=\"Apache-2.0 License\" src=\"http://img.shields.io/badge/license-Apache-brightgreen.svg\">\n\t</a>\n</p>\n\n![ferret](https://raw.githubusercontent.com/MontFerret/ferret/master/assets/intro.jpg)\n\n<p align=\"center\">\n\t<a href=\"https://www.montferret.dev/try\" style=\"margin: 0 15px\">\n\t\t<span>Try it!</span>\n\t</a>\n\t<a href=\"https://www.montferret.dev/docs/introduction\" style=\"margin: 0 15px\">\n\t\t<span>Docs</span>\n\t</a>\n\t<a href=\"https://github.com/MontFerret/cli\" style=\"margin: 0 15px\">\n\t\t<span>CLI</span>\n\t</a>\n\t<a href=\"https://github.com/MontFerret/lab\" style=\"margin: 0 15px\">\n\t\t<span>Test runner</span>\n\t</a>\n\t<a href=\"https://github.com/MontFerret/worker\" style=\"margin: 0 15px\">\n\t\t<span>Web worker</span>\n\t</a>\n</p>\n\n## What is it?\n```ferret``` is a web scraping system. It aims to simplify data extraction from the web for UI testing, machine learning, analytics and more.    \n```ferret``` allows users to focus on the data. It abstracts away the technical details and complexity of underlying technologies using its own declarative language. \nIt is extremely portable, extensible, and fast.\n\n[Read the introductory blog post about Ferret here!](https://medium.com/@ziflex/say-hello-to-ferret-a-modern-web-scraping-tool-5c9cc85ba183)\n\n### Features\n\n* Declarative language\n* Support of both static and dynamic web pages\n* Embeddable\n* Extensible\n\nDocumentation is available [at our website](https://www.montferret.dev/docs/introduction/).\n\n### Different languages\n\n* Ferret for python. [Pyfer](https://github.com/MontFerret/pyfer)\n",
	"association-rules data-mining data-science machine-learning python supervised-learning unsupervised-learning": "[![DOI](https://joss.theoj.org/papers/10.21105/joss.00638/status.svg)](https://doi.org/10.21105/joss.00638)\n[![PyPI version](https://badge.fury.io/py/mlxtend.svg)](http://badge.fury.io/py/mlxtend)\n[![Anaconda-Server Badge](https://anaconda.org/conda-forge/mlxtend/badges/version.svg)](https://anaconda.org/conda-forge/mlxtend)\n[![Build status](https://ci.appveyor.com/api/projects/status/7vx20e0h5dxcyla2/branch/master?svg=true)](https://ci.appveyor.com/project/rasbt/mlxtend/branch/master)\n[![codecov](https://codecov.io/gh/rasbt/mlxtend/branch/master/graph/badge.svg)](https://codecov.io/gh/rasbt/mlxtend)\n![Python 3](https://img.shields.io/badge/python-3-blue.svg)\n![License](https://img.shields.io/badge/license-BSD-blue.svg)\n[![Discuss](https://img.shields.io/badge/discuss-github-blue.svg)](https://github.com/rasbt/mlxtend/discussions)\n\n![](./docs/sources/img/logo.png)\n\n**Mlxtend (machine learning extensions) is a Python library of useful tools for the day-to-day data science tasks.**\n\n<br>\n\nSebastian Raschka 2014-2022\n\n<br>\n\n## Links\n\n- **Documentation:** [http://rasbt.github.io/mlxtend](http://rasbt.github.io/mlxtend)\n- PyPI: [https://pypi.python.org/pypi/mlxtend](https://pypi.python.org/pypi/mlxtend)\n- Changelog: [http://rasbt.github.io/mlxtend/CHANGELOG](http://rasbt.github.io/mlxtend/CHANGELOG)\n- Contributing: [http://rasbt.github.io/mlxtend/CONTRIBUTING](http://rasbt.github.io/mlxtend/CONTRIBUTING)\n- Questions? Check out the [GitHub Discussions board](https://github.com/rasbt/mlxtend/discussions)\n\n<br>\n<br>\n\n## Installing mlxtend\n\n#### PyPI\n\nTo install mlxtend, just execute  \n\n```bash\npip install mlxtend  \n```\n\nAlternatively, you could download the package manually from the Python Package Index [https://pypi.python.org/pypi/mlxtend](https://pypi.python.org/pypi/mlxtend), unzip it, navigate into the package, and use the command:\n\n```bash\npython setup.py install\n```\n\n#### Conda\nIf you use conda, to install mlxtend just execute\n\n```bash\nconda install -c conda-forge mlxtend \n```\n\n#### Dev Version\n\nThe mlxtend version on PyPI may always be one step behind; you can install the latest development version from the GitHub repository by executing\n\n```bash\npip install git+git://github.com/rasbt/mlxtend.git#egg=mlxtend\n```\n\nOr, you can fork the GitHub repository from https://github.com/rasbt/mlxtend and install mlxtend from your local drive via\n\n```bash\npython setup.py install\n```\n\n<br>\n<br>\n\n## Examples\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport itertools\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom mlxtend.classifier import EnsembleVoteClassifier\nfrom mlxtend.data import iris_data\nfrom mlxtend.plotting import plot_decision_regions\n\n# Initializing Classifiers\nclf1 = LogisticRegression(random_state=0)\nclf2 = RandomForestClassifier(random_state=0)\nclf3 = SVC(random_state=0, probability=True)\neclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[2, 1, 1], voting='soft')\n\n# Loading some example data\nX, y = iris_data()\nX = X[:,[0, 2]]\n\n# Plotting Decision Regions\ngs = gridspec.GridSpec(2, 2)\nfig = plt.figure(figsize=(10, 8))\n\nfor clf, lab, grd in zip([clf1, clf2, clf3, eclf],\n                         ['Logistic Regression', 'Random Forest', 'RBF kernel SVM', 'Ensemble'],\n                         itertools.product([0, 1], repeat=2)):\n    clf.fit(X, y)\n    ax = plt.subplot(gs[grd[0], grd[1]])\n    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n    plt.title(lab)\nplt.show()\n```\n\n![](./docs/sources/img/ensemble_decision_regions_2d.png)\n\n---\n\nIf you use mlxtend as part of your workflow in a scientific publication, please consider citing the mlxtend repository with the following DOI:\n\n\n```\n@article{raschkas_2018_mlxtend,\n  author       = {Sebastian Raschka},\n  title        = {MLxtend: Providing machine learning and data science \n                  utilities and extensions to Python\u2019s  \n                  scientific computing stack},\n  journal      = {The Journal of Open Source Software},\n  volume       = {3},\n  number       = {24},\n  month        = apr,\n  year         = 2018,\n  publisher    = {The Open Journal},\n  doi          = {10.21105/joss.00638},\n  url          = {http://joss.theoj.org/papers/10.21105/joss.00638}\n}\n```\n\n- Raschka, Sebastian (2018) MLxtend: Providing machine learning and data science utilities and extensions to Python's scientific computing stack.\nJ Open Source Softw 3(24).\n\n---\n\n## License\n\n- This project is released under a permissive new BSD open source license ([LICENSE-BSD3.txt](https://github.com/rasbt/mlxtend/blob/master/LICENSE-BSD3.txt)) and commercially usable. There is no warranty; not even for merchantability or fitness for a particular purpose.\n- In addition, you may use, copy, modify and redistribute all artistic creative works (figures and images) included in this distribution under the directory\naccording to the terms and conditions of the Creative Commons Attribution 4.0 International License.  See the file [LICENSE-CC-BY.txt](https://github.com/rasbt/mlxtend/blob/master/LICENSE-CC-BY.txt) for details. (Computer-generated graphics such as the plots produced by matplotlib fall under the BSD license mentioned above).\n\n## Contact\n\nThe best way to ask questions is via the [GitHub Discussions channel](https://github.com/rasbt/mlxtend/discussions). In case you encounter usage bugs, please don't hesitate to use the [GitHub's issue tracker](https://github.com/rasbt/mlxtend/issues) directly. \n",
	"classification clustering data-mining data-science data-visualization decision-trees machine-learning numpy orange orange3 pandas plotting python random-forest regression scikit-learn scipy visual-programming visualization": "<p align=\"center\">\n    <a href=\"https://orange.biolab.si/download\">\n    <img src=\"https://raw.githubusercontent.com/irgolic/orange3/README-shields/distribute/orange-title.png\" alt=\"Orange Data Mining\" height=\"200\">\n    </a>\n</p>\n<p align=\"center\">\n    <a href=\"https://orange.biolab.si/download\" alt=\"Latest release\">\n        <img src=\"https://img.shields.io/github/v/release/biolab/orange3?label=download\" />\n    </a>\n    <a href=\"https://orange3.readthedocs.io/en/latest/?badge=latest\" alt=\"Documentation\">\n        <img src=\"https://readthedocs.org/projects/orange3/badge/?version=latest\">\n    </a>\n    <a href=\"https://discord.gg/FWrfeXV\" alt=\"Discord\">\n        <img src=\"https://img.shields.io/discord/633376992607076354?logo=discord&color=7389D8&logoColor=white&label=Discord\">                                                                                                                                                                                                                                                  </a>\n</p>\n\n# Orange Data Mining\n[Orange] is a data mining and visualization toolbox for novice and expert alike. To explore data with Orange, one requires __no programming or in-depth mathematical knowledge__. We believe that workflow-based data science tools democratize data science by hiding complex underlying mechanics and exposing intuitive concepts. Anyone who owns data, or is motivated to peek into data, should have the means to do so.\n\n<p align=\"center\">\n    <a href=\"https://orange.biolab.si/download\">\n    <img src=\"https://raw.githubusercontent.com/irgolic/orange3/README-shields/distribute/orange-example-tall.png\" alt=\"Example Workflow\">\n    </a>\n</p>\n\n[Orange]: https://orange.biolab.si/\n\n\n## Installing\n\n### Easy installation\n\nFor easy installation, [Download](https://orange.biolab.si/download) the latest released Orange version from our website. To install an add-on, head to `Options -> Add-ons...` in the menu bar.\n\n### Installing with Conda\n\nFirst, install [Miniconda](https://docs.conda.io/en/latest/miniconda.html) for your OS. \n\nThen, create a new conda environment, and install orange3:\n\n```Shell\n# Add conda-forge to your channels for access to the latest release\nconda config --add channels conda-forge\n\n# Perhaps enforce strict conda-forge priority\nconda config --set channel_priority strict\n\n# Create and activate an environment for Orange\nconda create python=3 --yes --name orange3\nconda activate orange3\n\n# Install Orange\nconda install orange3\n```\n\nFor installation of an add-on, use:\n```Shell\nconda install orange3-<addon name>\n```\n[See specific add-on repositories for details.](https://github.com/biolab/)\n\n\n### Installing with pip\n\nWe recommend using our [standalone installer](https://orange.biolab.si/download) or conda, but Orange is also installable with pip. You will need a C/C++ compiler (on Windows we suggest using Microsoft Visual Studio Build Tools).\n\n\n### Installing with winget (Windows only)\n\nTo install Orange with [winget](https://docs.microsoft.com/en-us/windows/package-manager/winget/), run:\n\n```Shell\nwinget install --id  UniversityofLjubljana.Orange \n```\n\n## Running\n\nEnsure you've activated the correct virtual environment. If following the above conda instructions:\n\n```Shell\nconda activate orange3\n``` \n\nRun `orange-canvas` or `python3 -m Orange.canvas`. Add `--help` for a list of program options.\n\nStarting up for the first time may take a while.\n\n\n## Developing\n\n[![GitHub Actions](https://img.shields.io/endpoint.svg?url=https%3A%2F%2Factions-badge.atrox.dev%2Fbiolab%2Forange3%2Fbadge&label=build)](https://actions-badge.atrox.dev/biolab/orange3/goto) [![codecov](https://img.shields.io/codecov/c/github/biolab/orange3)](https://codecov.io/gh/biolab/orange3) [![Contributor count](https://img.shields.io/github/contributors-anon/biolab/orange3)](https://github.com/biolab/orange3/graphs/contributors) [![Latest GitHub commit](https://img.shields.io/github/last-commit/biolab/orange3)](https://github.com/biolab/orange3/commits/master)\n\nWant to write a widget? [Use the Orange3 example add-on template.](https://github.com/biolab/orange3-example-addon)\n\nWant to get involved? Join us on [Discord](https://discord.gg/FWrfeXV), introduce yourself in #general! \n\nTake a look at our [contributing guide](https://github.com/irgolic/orange3/blob/README-shields/CONTRIBUTING.md) and [style guidelines](https://github.com/biolab/orange-widget-base/wiki/Widget-UI).\n\nCheck out our widget development [docs](https://orange-widget-base.readthedocs.io/en/latest/?badge=latest) for a comprehensive guide on writing Orange widgets.\n\n### The Orange ecosystem\n\nThe development of core Orange is primarily split into three repositories:\n\n[biolab/orange-canvas-core](https://www.github.com/biolab/orange-canvas-core) implements the canvas,  \n[biolab/orange-widget-base](https://www.github.com/biolab/orange-widget-base) is a handy widget GUI library,  \n[biolab/orange3](https://www.github.com/biolab/orange3) brings it all together and implements the base data mining toolbox.\t\n\nAdditionally, add-ons implement additional widgets for more specific use cases. [Anyone can write an add-on.](https://github.com/biolab/orange3-example-addon) Some of our first-party add-ons:\n\n- [biolab/orange3-text](https://www.github.com/biolab/orange3-text)\n- [biolab/orange3-bioinformatics](https://www.github.com/biolab/orange3-bioinformatics)\n- [biolab/orange3-timeseries](https://www.github.com/biolab/orange3-timeseries)    \n- [biolab/orange3-single-cell](https://www.github.com/biolab/orange3-single-cell)    \n- [biolab/orange3-imageanalytics](https://www.github.com/biolab/orange3-imageanalytics)    \n- [biolab/orange3-educational](https://www.github.com/biolab/orange3-educational)    \n- [biolab/orange3-geo](https://www.github.com/biolab/orange3-geo)    \n- [biolab/orange3-associate](https://www.github.com/biolab/orange3-associate)    \n- [biolab/orange3-network](https://www.github.com/biolab/orange3-network)\n- [biolab/orange3-explain](https://www.github.com/biolab/orange3-explain)\n\n### Setting up for core Orange development\n\nFirst, fork the repository by pressing the fork button in the top-right corner of this page.\n\nSet your GitHub username,\n\n```Shell\nexport MY_GITHUB_USERNAME=replaceme\n```\n\ncreate a conda environment, clone your fork, and install it:\n\n```Shell\nconda create python=3 --yes --name orange3\nconda activate orange3\n\ngit clone ssh://git@github.com/$MY_GITHUB_USERNAME/orange3\n\npip install -e orange3\n```\n\nNow you're ready to work with git. See GitHub's guides on [pull requests](https://docs.github.com/en/free-pro-team@latest/github/collaborating-with-issues-and-pull-requests/proposing-changes-to-your-work-with-pull-requests), [forks](https://docs.github.com/en/free-pro-team@latest/github/collaborating-with-issues-and-pull-requests/working-with-forks) if you're unfamiliar. If you're having trouble, get in touch on [Discord](https://discord.gg/FWrfeXV).\n\n#### Running\n\nRun Orange with `python -m Orange.canvas` (after activating the conda environment).\n\n`python -m Orange.canvas -l 2 --no-splash --no-welcome` will skip the splash screen and welcome window, and output more debug info. Use `-l 4` for more.\n\nAdd `--clear-widget-settings` to clear the widget settings before start.\n\nTo explore the dark side of the Orange, try `--style=fusion:breeze-dark`\n\nArgument `--help` lists all available options.\n\nTo run tests, use `unittest Orange.tests Orange.widgets.tests`\n\n\n### Setting up for development of all components\n\nShould you wish to contribute Orange's base components (the widget base and the canvas), you must also clone these two repositories from Github instead of installing them as dependencies of Orange3.\n\nFirst, fork all the repositories to which you want to contribute. \n\nSet your GitHub username,\n\n```Shell\nexport MY_GITHUB_USERNAME=replaceme\n```\n\ncreate a conda environment, clone your forks, and install them:\n\n```Shell\nconda create python=3 --yes --name orange3\nconda activate orange3\n\ngit clone ssh://git@github.com/$MY_GITHUB_USERNAME/orange-widget-base\npip install -e orange-widget-base\n\ngit clone ssh://git@github.com/$MY_GITHUB_USERNAME/orange-canvas-core\npip install -e orange-canvas-core\n\ngit clone ssh://git@github.com/$MY_GITHUB_USERNAME/orange3\npip install -e orange3\n\n# Repeat for any add-on repositories\n```\n\nIt's crucial to install `orange-base-widget` and `orange-canvas-core` before `orange3` to ensure that `orange3` will use your local versions.\n",
	"artificial-intelligence awesome awesome-list bayes data-analysis data-mining data-science data-visualization datascience deep-learning deeplearning machine-learning python statistics": "# Awesome Data Science with Python\n\n> A curated list of awesome resources for practicing data science using Python, including not only libraries, but also links to tutorials, code snippets, blog posts and talks.  \n\n#### Core\n[pandas](https://pandas.pydata.org/) - Data structures built on top of [numpy](https://www.numpy.org/).  \n[scikit-learn](https://scikit-learn.org/stable/) - Core ML library.  \n[matplotlib](https://matplotlib.org/) - Plotting library.  \n[seaborn](https://seaborn.pydata.org/) - Data visualization library based on matplotlib.  \n[datatile](https://github.com/polyaxon/datatile) - Basic statistics using `DataFrameSummary(df).summary()`.  \n[pandas_profiling](https://github.com/pandas-profiling/pandas-profiling) - Descriptive statistics using `ProfileReport`.  \n[sklearn_pandas](https://github.com/scikit-learn-contrib/sklearn-pandas) - Helpful `DataFrameMapper` class.  \n[missingno](https://github.com/ResidentMario/missingno) - Missing data visualization.  \n[rainbow-csv](https://marketplace.visualstudio.com/items?itemName=mechatroner.rainbow-csv) - Plugin to display .csv files with nice colors.  \n\n#### Environment and Jupyter\n[General Jupyter Tricks](https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/)  \nFixing environment: [link](https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/)  \nPython debugger (pdb) - [blog post](https://www.blog.pythonlibrary.org/2018/10/17/jupyter-notebook-debugging/), [video](https://www.youtube.com/watch?v=Z0ssNAbe81M&t=1h44m15s), [cheatsheet](https://nblock.org/2011/11/15/pdb-cheatsheet/)  \n[cookiecutter-data-science](https://github.com/drivendata/cookiecutter-data-science) - Project template for data science projects.  \n[nteract](https://nteract.io/) - Open Jupyter Notebooks with doubleclick.  \n[papermill](https://github.com/nteract/papermill) - Parameterize and execute Jupyter notebooks, [tutorial](https://pbpython.com/papermil-rclone-report-1.html).  \n[nbdime](https://github.com/jupyter/nbdime) - Diff two notebook files, Alternative GitHub App: [ReviewNB](https://www.reviewnb.com/).  \n[RISE](https://github.com/damianavila/RISE) - Turn Jupyter notebooks into presentations.  \n[qgrid](https://github.com/quantopian/qgrid) - Pandas `DataFrame` sorting.  \n[pivottablejs](https://github.com/nicolaskruchten/jupyter_pivottablejs) - Drag n drop Pivot Tables and Charts for jupyter notebooks.  \n[itables](https://github.com/mwouts/itables) - Interactive tables in Jupyter.  \n[jupyter-datatables](https://github.com/CermakM/jupyter-datatables) - Interactive tables in Jupyter.  \n[debugger](https://blog.jupyter.org/a-visual-debugger-for-jupyter-914e61716559) - Visual debugger for Jupyter.  \n[nbcommands](https://github.com/vinayak-mehta/nbcommands) - View and search notebooks from terminal.  \n[handcalcs](https://github.com/connorferster/handcalcs) - More convenient way of writing mathematical equations in Jupyter.  \n[notebooker](https://github.com/man-group/notebooker) - Productionize and schedule Jupyter Notebooks.  \n[bamboolib](https://github.com/tkrabel/bamboolib) - Intuitive GUI for tables.  \n[voila](https://github.com/QuantStack/voila) - Turn Jupyter notebooks into standalone web applications.  \n[voila-gridstack](https://github.com/voila-dashboards/voila-gridstack) - Voila grid layout.  \n\n#### Pandas Tricks, Alternatives and Additions\n[Pandas Tricks](https://towardsdatascience.com/5-lesser-known-pandas-tricks-e8ab1dd21431)  \n[Using df.pipe() (video)](https://www.youtube.com/watch?v=yXGCKqo5cEY)  \n[pandasvault](https://github.com/firmai/pandasvault) - Large collection of pandas tricks.  \n[modin](https://github.com/modin-project/modin) - Parallelization library for faster pandas `DataFrame`.  \n[vaex](https://github.com/vaexio/vaex) - Out-of-Core DataFrames.  \n[pandarallel](https://github.com/nalepae/pandarallel) - Parallelize pandas operations.  \n[xarray](https://github.com/pydata/xarray/) - Extends pandas to n-dimensional arrays.  \n[swifter](https://github.com/jmcarpenter2/swifter) - Apply any function to a pandas dataframe faster.   \n[pandas_flavor](https://github.com/Zsailer/pandas_flavor) - Write custom accessors like `.str` and `.dt`.   \n[pandas-log](https://github.com/eyaltrabelsi/pandas-log) - Find business logic issues and performance issues in pandas.  \n[pandapy](https://github.com/firmai/pandapy) - Additional features for pandas.  \n[lux](https://github.com/lux-org/lux) - Dataframe visualization within Jupyter.  \n[dtale](https://github.com/man-group/dtale) - View and analyze Pandas data structures, integrating with Jupyter.  \n[polars](https://github.com/pola-rs/polars) - Multi-threaded alternative to pandas.  \n[duckdb](https://github.com/duckdb/duckdb) - Efficiently run SQL queries on pandas DataFrame.  \n\n#### Scikit-Learn Alternatives\n[scikit-learn-intelex](https://github.com/intel/scikit-learn-intelex) - Intel extension for scikit-learn for speed.  \n\n#### Helpful\n[drawdata](https://github.com/koaning/drawdata) - Quickly draw some points and export them as csv, [website](https://drawdata.xyz/).  \n[tqdm](https://github.com/tqdm/tqdm) - Progress bars for for-loops. Also supports [pandas apply()](https://stackoverflow.com/a/34365537/1820480).  \n[icecream](https://github.com/gruns/icecream) - Simple debugging output.  \n[loguru](https://github.com/Delgan/loguru) - Python logging.  \n[pyprojroot](https://github.com/chendaniely/pyprojroot) - Helpful `here()` command from R.  \n[intake](https://github.com/intake/intake) - Loading datasets made easier, [talk](https://www.youtube.com/watch?v=s7Ww5-vD2Os&t=33m40s).   \n\n#### Extraction\n[textract](https://github.com/deanmalmgren/textract) - Extract text from any document.  \n[camelot](https://github.com/socialcopsdev/camelot) - Extract text from PDF.  \n\n#### Big Data\n[spark](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#work-with-dataframes) - `DataFrame` for big data, [cheatsheet](https://gist.github.com/crawles/b47e23da8218af0b9bd9d47f5242d189), [tutorial](https://github.com/ericxiao251/spark-syntax).  \n[sparkit-learn](https://github.com/lensacom/sparkit-learn), [spark-deep-learning](https://github.com/databricks/spark-deep-learning) - ML frameworks for spark.  \n[koalas](https://github.com/databricks/koalas) - Pandas API on Apache Spark.  \n[dask](https://github.com/dask/dask), [dask-ml](http://ml.dask.org/) - Pandas `DataFrame` for big data and machine learning library, [resources](https://matthewrocklin.com/blog//work/2018/07/17/dask-dev), [talk1](https://www.youtube.com/watch?v=ccfsbuqsjgI), [talk2](https://www.youtube.com/watch?v=RA_2qdipVng), [notebooks](https://github.com/dask/dask-ec2/tree/master/notebooks), [videos](https://www.youtube.com/user/mdrocklin).  \n[dask-gateway](https://github.com/jcrist/dask-gateway) - Managing dask clusters.  \n[turicreate](https://github.com/apple/turicreate) - Helpful `SFrame` class for out-of-memory dataframes.  \n[h2o](https://github.com/h2oai/h2o-3) - Helpful `H2OFrame` class for out-of-memory dataframes.  \n[datatable](https://github.com/h2oai/datatable) - Data Table for big data support.  \n[cuDF](https://github.com/rapidsai/cudf) - GPU DataFrame Library, [Intro](https://www.youtube.com/watch?v=6XzS5XcpicM&t=2m50s).  \n[ray](https://github.com/ray-project/ray/) - Flexible, high-performance distributed execution framework.  \n[mars](https://github.com/mars-project/mars) - Tensor-based unified framework for large-scale data computation.  \n[bottleneck](https://github.com/kwgoodman/bottleneck) - Fast NumPy array functions written in C.   \n[bolz](https://github.com/Blosc/bcolz) - A columnar data container that can be compressed.  \n[cupy](https://github.com/cupy/cupy) - NumPy-like API accelerated with CUDA.  \n[petastorm](https://github.com/uber/petastorm) - Data access library for parquet files by Uber.  \n[zarr](https://github.com/zarr-developers/zarr-python) - Distributed numpy arrays.  \n[NVTabular](https://github.com/NVIDIA/NVTabular) - Feature engineering and preprocessing library for tabular data by nvidia.  \n[tensorstore](https://github.com/google/tensorstore) - Reading and writing large multi-dimensional arrays (Google).  \n\n#### Distributed Systems\n[nextflow](https://github.com/goodwright/nextflow.py) - Run scripts and workflow graphs in Docker image using Google Life Sciences, AWS Batch, [Website](https://github.com/nextflow-io/nextflow).  \n[dsub](https://github.com/DataBiosphere/dsub) - Run batch computing tasks in Docker image in the Google Cloud.  \n\n#### Command line tools, CSV\n[ni](https://github.com/spencertipping/ni) - Command line tool for big data.  \n[xsv](https://github.com/BurntSushi/xsv) - Command line tool for indexing, slicing, analyzing, splitting and joining CSV files.  \n[csvkit](https://csvkit.readthedocs.io/en/1.0.3/) - Another command line tool for CSV files.  \n[csvsort](https://pypi.org/project/csvsort/) - Sort large csv files.  \n[tsv-utils](https://github.com/eBay/tsv-utils) - Tools for working with CSV files by ebay.  \n[cheat](https://github.com/cheat/cheat) - Make cheatsheets for command line commands.  \n\n#### Classical Statistics\n\n##### Correlation\n[phik](https://github.com/kaveio/phik) - Correlation between categorical, ordinal and interval variables.  \n\n##### Packages\n[statsmodels](https://www.statsmodels.org/stable/index.html) - Statistical tests.  \n[linearmodels](https://github.com/bashtage/linearmodels) - Instrumental variable and panel data models.  \n[pingouin](https://github.com/raphaelvallat/pingouin) - Statistical tests. [Pairwise correlation between columns of pandas DataFrame](https://pingouin-stats.org/generated/pingouin.pairwise_corr.html)   \n[scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html#statistical-tests) - Statistical tests.  \n[scikit-posthocs](https://github.com/maximtrp/scikit-posthocs) - Statistical post-hoc tests for pairwise multiple comparisons.   \nBland-Altman Plot [1](https://pingouin-stats.org/generated/pingouin.plot_blandaltman.html), [2](http://www.statsmodels.org/dev/generated/statsmodels.graphics.agreement.mean_diff_plot.html) - Plot for agreement between two methods of measurement.  \n[ANOVA](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html), Tutorials: [One-way](https://pythonfordatascience.org/anova-python/), [Two-way](https://pythonfordatascience.org/anova-2-way-n-way/), [Type 1,2,3 explained](https://mcfromnz.wordpress.com/2011/03/02/anova-type-iiiiii-ss-explained/).  \n\n##### Statistical Tests\n[test_proportions_2indep](https://www.statsmodels.org/dev/generated/statsmodels.stats.proportion.test_proportions_2indep.html) - Proportion test.  \n[G-Test](https://en.wikipedia.org/wiki/G-test) - Alternative to chi-square test, [power_divergence](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.power_divergence.html).  \n\n##### Comparing Two Populations\n[torch-two-sample](https://github.com/josipd/torch-two-sample) - Friedman-Rafsky Test: Compare two population based on a multivariate generalization of the Runstest. [Explanation](https://www.real-statistics.com/multivariate-statistics/multivariate-normal-distribution/friedman-rafsky-test/), [Application](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5014134/)  \n\n##### Interim Analyses / Sequential Analysis / Stopping\n[Squential Analysis](https://en.wikipedia.org/wiki/Sequential_analysis) - Wikipedia.  \n[Treatment Effects Monitoring](https://online.stat.psu.edu/stat509/node/75/) - Design and Analysis of Clinical Trials PennState.  \n[sequential](https://cran.r-project.org/web/packages/Sequential/Sequential.pdf) - Exact Sequential Analysis for Poisson and Binomial Data (R package).  \n[confseq](https://github.com/gostevehoward/confseq) - Uniform boundaries, confidence sequences, and always-valid p-values.  \n\n##### Visualizations\n[Great Overview over Visualizations](https://textvis.lnu.se/)  \n[Dependent Propabilities](https://static.laszlokorte.de/stochastic/)  \n[Null Hypothesis Significance Testing (NHST) and Sample Size Calculation](https://rpsychologist.com/d3/NHST/)  \n[Correlation](https://rpsychologist.com/d3/correlation/)  \n[Cohen's d](https://rpsychologist.com/d3/cohend/)  \n[Confidence Interval](https://rpsychologist.com/d3/CI/)  \n[Equivalence, non-inferiority and superiority testing](https://rpsychologist.com/d3/equivalence/)  \n[Bayesian two-sample t test](https://rpsychologist.com/d3/bayes/)  \n[Distribution of p-values when comparing two groups](https://rpsychologist.com/d3/pdist/)  \n[Understanding the t-distribution and its normal approximation](https://rpsychologist.com/d3/tdist/)  \n\n##### Talks\n[Inverse Propensity Weighting](https://www.youtube.com/watch?v=SUq0shKLPPs)  \n[Dealing with Selection Bias By Propensity Based Feature Selection](https://www.youtube.com/watch?reload=9&v=3ZWCKr0vDtc)  \n\n##### Texts\n[Modes, Medians and Means: A Unifying Perspective](https://www.johnmyleswhite.com/notebook/2013/03/22/modes-medians-and-means-an-unifying-perspective/)   \n[Using Norms to Understand Linear Regression](https://www.johnmyleswhite.com/notebook/2013/03/22/using-norms-to-understand-linear-regression/)   \n[Verifying the Assumptions of Linear Models](https://github.com/erykml/medium_articles/blob/master/Statistics/linear_regression_assumptions.ipynb)  \n[Mediation and Moderation Intro](https://ademos.people.uic.edu/Chapter14.html)  \n[Montgomery et al. - How conditioning on post-treatment variables can ruin your experiment and what to do about it](https://cpb-us-e1.wpmucdn.com/sites.dartmouth.edu/dist/5/2293/files/2021/03/post-treatment-bias.pdf)  \n[Greenland - Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4877414/)  \n[Blume - Second-generation p-values: Improved rigor, reproducibility, & transparency in statistical analyses](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0188299)  \n[Lindel\u00f8v - Common statistical tests are linear models](https://lindeloev.github.io/tests-as-linear/)    \n[Chatruc - The Central Limit Theorem and its misuse](https://lambdaclass.com/data_etudes/central_limit_theorem_misuse/)  \n[Al-Saleh - Properties of the Standard Deviation that are Rarely Mentioned in Classrooms](http://www.stat.tugraz.at/AJS/ausg093/093Al-Saleh.pdf)   \n[Wainer - The Most Dangerous Equation](http://www-stat.wharton.upenn.edu/~hwainer/Readings/Most%20Dangerous%20eqn.pdf)   \n[Gigerenzer - The Bias Bias in Behavioral Economics](https://www.nowpublishers.com/article/Details/RBE-0092)  \n[Cook - Estimating the chances of something that hasn\u2019t happened yet](https://www.johndcook.com/blog/2010/03/30/statistical-rule-of-three/)  \n\n#### Epidemiology\n[R Epidemics Consortium](https://www.repidemicsconsortium.org/projects/) - Large tool suite for working with epidemiological data (R packages). [Github](https://github.com/reconhub)   \n[incidence2](https://github.com/reconhub/incidence2) - Computation, handling, visualisation and simple modelling of incidence (R package).  \n[EpiEstim](https://github.com/mrc-ide/EpiEstim) - Estimate time varying instantaneous reproduction number R during epidemics (R package) [paper](https://academic.oup.com/aje/article/178/9/1505/89262).  \n[researchpy](https://github.com/researchpy/researchpy) - Helpful `summary_cont()` function for summary statistics (Table 1).  \n[zEpid](https://github.com/pzivich/zEpid) - Epidemiology analysis package, [Tutorial](https://github.com/pzivich/Python-for-Epidemiologists).  \n[tipr](https://github.com/LucyMcGowan/tipr) - Sensitivity analyses for unmeasured confounders (R package).  \n\n#### Exploration and Cleaning\n[Checklist](https://github.com/r0f1/ml_checklist).  \n[pandasgui](https://github.com/adamerose/pandasgui) - GUI for viewing, plotting and analyzing Pandas DataFrames.  \n[janitor](https://pyjanitor.readthedocs.io/) - Clean messy column names.  \n[pandera](https://github.com/unionai-oss/pandera) - Data / Schema validation.  \n[impyute](https://github.com/eltonlaw/impyute) - Imputations.  \n[fancyimpute](https://github.com/iskandr/fancyimpute) - Matrix completion and imputation algorithms.  \n[imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) - Resampling for imbalanced datasets.  \n[tspreprocess](https://github.com/MaxBenChrist/tspreprocess) - Time series preprocessing: Denoising, Compression, Resampling.  \n[Kaggler](https://github.com/jeongyoonlee/Kaggler) - Utility functions (`OneHotEncoder(min_obs=100)`)  \n[pyupset](https://github.com/ImSoErgodic/py-upset) - Visualizing intersecting sets.  \n[pyemd](https://github.com/wmayner/pyemd) - Earth Mover's Distance / Wasserstein distance, similarity between histograms. [OpenCV implementation](https://docs.opencv.org/3.4/d6/dc7/group__imgproc__hist.html), [POT implementation](https://pythonot.github.io/auto_examples/plot_OT_2D_samples.html)   \n[littleballoffur](https://github.com/benedekrozemberczki/littleballoffur) - Sampling from graphs.  \n\n#### Noisy Labels\n[cleanlab](https://github.com/cleanlab/cleanlab) - Machine learning with noisy labels, finding mislabeled data, and uncertainty quantification. Also see awesome list below.  \n[doubtlab](https://github.com/koaning/doubtlab) - Find bad or noisy labels.\n\n#### Train / Test Split\n[iterative-stratification](https://github.com/trent-b/iterative-stratification) - Stratification of multilabel data.  \n\n#### Feature Engineering\n[Talk](https://www.youtube.com/watch?v=68ABAU_V8qI)  \n[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) - Pipeline, [examples](https://github.com/jem1031/pandas-pipelines-custom-transformers).  \n[pdpipe](https://github.com/shaypal5/pdpipe) - Pipelines for DataFrames.  \n[scikit-lego](https://github.com/koaning/scikit-lego) - Custom transformers for pipelines.  \n[skoot](https://github.com/tgsmith61591/skoot) - Pipeline helper functions.  \n[categorical-encoding](https://github.com/scikit-learn-contrib/categorical-encoding) - Categorical encoding of variables, [vtreat (R package)](https://cran.r-project.org/web/packages/vtreat/vignettes/vtreat.html).  \n[dirty_cat](https://github.com/dirty-cat/dirty_cat) - Encoding dirty categorical variables.  \n[patsy](https://github.com/pydata/patsy/) - R-like syntax for statistical models.  \n[mlxtend](https://rasbt.github.io/mlxtend/user_guide/feature_extraction/LinearDiscriminantAnalysis/) - LDA.  \n[featuretools](https://github.com/Featuretools/featuretools) - Automated feature engineering, [example](https://github.com/WillKoehrsen/automated-feature-engineering/blob/master/walk_through/Automated_Feature_Engineering.ipynb).  \n[tsfresh](https://github.com/blue-yonder/tsfresh) - Time series feature engineering.  \n[pypeln](https://github.com/cgarciae/pypeln) - Concurrent data pipelines.  \n[feature_engine](https://github.com/solegalli/feature_engine) - Encoders, transformers, etc.  \n[NVTabular](https://github.com/NVIDIA/NVTabular) - Feature engineering and preprocessing library for tabular data by nvidia.  \n\n#### Computer Vision\n[Intro to Computer Vision](https://www.youtube.com/playlist?list=PLjMXczUzEYcHvw5YYSU92WrY8IwhTuq7p)  \n\n#### Image Cleanup\n[Fiji](https://fiji.sc/) - General purpose tool. Image viewer and image processing package.  \n[napari](https://github.com/napari/napari) - Multi-dimensional image viewer.  \n[fiftyone](https://github.com/voxel51/fiftyone) - Viewer and tool for building high-quality datasets and computer vision models.  \n[DivNoising](https://github.com/juglab/DivNoising) - Unsupervised denoising method.  \n[aydin](https://github.com/royerlab/aydin) - Image denoising.  \n[unprocessing](https://github.com/timothybrooks/unprocessing) - Image denoising by reverting the image processing pipeline.  \n\n#### Microscopy / Segmentation\n\n##### Datasets\n[jump-cellpainting](https://github.com/jump-cellpainting/datasets) - Cellpainting dataset.  \n[MedMNIST](https://github.com/MedMNIST/MedMNIST) - Datasets for 2D and 3D Biomedical Image Classification.  \n[CytoImageNet](https://github.com/stan-hua/CytoImageNet) - Huge diverse dataset like ImageNet but for cell images.  \n[cellpose dataset](https://www.cellpose.org/dataset) - Cell images.  \n[Haghighi](https://github.com/carpenterlab/2021_Haghighi_NatureMethods) - Gene Expression and Morphology Profiles.  \n[broadinstitute/lincs-profiling-complementarity](https://github.com/broadinstitute/lincs-profiling-complementarity) - Cellpainting vs. L1000 assay.  \n\n#### Packages\n[Awesome Cytodata](https://github.com/cytodata/awesome-cytodata)  \n[BD Spectrum Viewer](https://www.bdbiosciences.com/en-us/resources/bd-spectrum-viewer) - Calculate spectral overlap, bleed through for fluorescence microscopy dyes.  \n[Tree of Microscopy](https://biomag-lab.github.io/microscopy-tree/) - Review of cell segmentation algorithms, [Paper](https://www.sciencedirect.com/science/article/abs/pii/S0962892421002518).  \n[cellpose](https://github.com/mouseland/cellpose) - Cell segmentation. [Paper](https://www.biorxiv.org/content/10.1101/2020.02.02.931238v1), [Dataset](https://www.cellpose.org/dataset).  \n[skimage](https://scikit-image.org/docs/dev/api/skimage.exposure.html#skimage.exposure.equalize_adapthist) - Illumination correction (CLAHE).  \n[cidre](https://github.com/smithk/cidre) - Illumination correction method for optical microscopy.  \n[BaSiCPy](https://github.com/peng-lab/BaSiCPy) - Background and Shading Correction of Optical Microscopy Images, [BaSiC](https://github.com/marrlab/BaSiC).  \n[ashlar](https://github.com/labsyspharm/ashlar) - Whole-slide microscopy image stitching and registration.  \n[CSBDeep](https://github.com/CSBDeep/CSBDeep) - Image denoising, restoration and object detection, [Project page](https://csbdeep.bioimagecomputing.com/tools/).  \n[mcmicro](https://github.com/labsyspharm/mcmicro) - Multiple-choice microscopy pipeline, [Paper](https://www.nature.com/articles/s41592-021-01308-y).  \n[UnMicst](https://github.com/HMS-IDAC/UnMicst) - Identifying Cells and Segmenting Tissue.  \n[stardist](https://github.com/stardist/stardist) - Object Detection with Star-convex Shapes.  \n[nnUnet](https://github.com/MIC-DKFZ/nnUNet) - 3D biomedical image segmentation.  \n[atomai](https://github.com/pycroscopy/atomai) - Deep and Machine Learning for Microscopy.  \n[allencell](https://www.allencell.org/segmenter.html) - Tools for the 3D segmentation of intracellular structures.  \n\n#### Domain Adaptation / Batch-Effect Correction \n[Tran - A benchmark of batch-effect correction methods for single-cell RNA sequencing data](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1850-9), [Code](https://github.com/JinmiaoChenLab/Batch-effect-removal-benchmarking).  \n[R Tutorial on correcting batch effects](https://broadinstitute.github.io/2019_scWorkshop/correcting-batch-effects.html).  \n[harmonypy](https://github.com/slowkow/harmonypy) - Fuzzy k-means and locally linear adjustments.  \n[pyliger](https://github.com/welch-lab/pyliger) - Batch-effect correction, [Example](https://github.com/welch-lab/pyliger/blob/master/pyliger/factorization/_iNMF_ANLS.py#L65), [R package](https://github.com/welch-lab/liger).  \n[nimfa](https://github.com/mims-harvard/nimfa) - Nonnegative matrix factorization.  \n[scgen](https://github.com/theislab/scgen) - Batch removal. [Doc](https://scgen.readthedocs.io/en/stable/).  \n[CORAL](https://github.com/google-research/google-research/tree/30e54523f08d963ced3fbb37c00e9225579d2e1d/correct_batch_effects_wdn) - Correcting for Batch Effects Using Wasserstein Distance, [Code](https://github.com/google-research/google-research/blob/30e54523f08d963ced3fbb37c00e9225579d2e1d/correct_batch_effects_wdn/transform.py#L152), [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7050548/).   \n[adapt](https://github.com/adapt-python/adapt) - Aweseome Domain Adaptation Python Toolbox.  \n[pytorch-adapt](https://github.com/KevinMusgrave/pytorch-adapt) - Various neural network models for domain adaptation.  \n\n#### Feature Engineering Images\n[skimage](https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.regionprops) - Regionprops: area, eccentricity, extent.  \n[mahotas](https://github.com/luispedro/mahotas) - Zernike, Haralick, LBP, and TAS features.  \n[pyradiomics](https://github.com/AIM-Harvard/pyradiomics) - Radiomics features from medical imaging.  \n[pyefd](https://github.com/hbldh/pyefd) - Elliptical feature descriptor, approximating a contour with a Fourier series.  \n\n#### Feature Selection\n[Overview Paper](https://www.sciencedirect.com/science/article/pii/S016794731930194X), [Talk](https://www.youtube.com/watch?v=JsArBz46_3s), [Repo](https://github.com/Yimeng-Zhang/feature-engineering-and-feature-selection)    \nBlog post series - [1](http://blog.datadive.net/selecting-good-features-part-i-univariate-selection/), [2](http://blog.datadive.net/selecting-good-features-part-ii-linear-models-and-regularization/), [3](http://blog.datadive.net/selecting-good-features-part-iii-random-forests/), [4](http://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/)  \nTutorials - [1](https://www.kaggle.com/residentmario/automated-feature-selection-with-sklearn), [2](https://machinelearningmastery.com/feature-selection-machine-learning-python/)  \n[sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) - Feature selection.  \n[eli5](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html#feature-selection) - Feature selection using permutation importance.  \n[scikit-feature](https://github.com/jundongl/scikit-feature) - Feature selection algorithms.  \n[stability-selection](https://github.com/scikit-learn-contrib/stability-selection) - Stability selection.  \n[scikit-rebate](https://github.com/EpistasisLab/scikit-rebate) - Relief-based feature selection algorithms.  \n[scikit-genetic](https://github.com/manuel-calzolari/sklearn-genetic) - Genetic feature selection.  \n[boruta_py](https://github.com/scikit-learn-contrib/boruta_py) - Feature selection, [explaination](https://stats.stackexchange.com/questions/264360/boruta-all-relevant-feature-selection-vs-random-forest-variables-of-importanc/264467), [example](https://www.kaggle.com/tilii7/boruta-feature-elimination).  \n[Boruta-Shap](https://github.com/Ekeany/Boruta-Shap) - Boruta feature selection algorithm + shapley values.  \n[linselect](https://github.com/efavdb/linselect) - Feature selection package.  \n[mlxtend](https://rasbt.github.io/mlxtend/user_guide/feature_selection/ExhaustiveFeatureSelector/) - Exhaustive feature selection.     \n[BoostARoota](https://github.com/chasedehan/BoostARoota) - Xgboost feature selection algorithm.  \n[INVASE](https://github.com/jsyoon0823/INVASE) - Instance-wise Variable Selection using Neural Networks.  \n[SubTab](https://github.com/AstraZeneca/SubTab) - Subsetting Features of Tabular Data for Self-Supervised Representation Learning, AstraZeneca.  \n[mrmr](https://github.com/smazzanti/mrmr) - Maximum Relevance and Minimum Redundancy Feature Selection, [Website](http://home.penglab.com/proj/mRMR/).  \n[arfs](https://github.com/ThomasBury/arfs) - All Relevant Feature Selection.  \n[VSURF](https://github.com/robingenuer/VSURF) - Variable Selection Using Random Forests (R package) [doc](https://www.rdocumentation.org/packages/VSURF/versions/1.1.0/topics/VSURF).  \n[FeatureSelectionGA](https://github.com/kaushalshetty/FeatureSelectionGA) - Feature Selection using Genetic Algorithm.  \n\n#### Subset Selection\n[apricot](https://github.com/jmschrei/apricot) - Selecting subsets of data sets to train machine learning models quickly.  \n[ducks](https://github.com/manimino/ducks) - Index data for fast lookup by any combination of fields.  \n\n#### Dimensionality Reduction / Representation Learning\n\n##### Selection\nCheck also the Clustering section and self-supervised learning section for ideas!  \n[Review](https://members.loria.fr/moberger/Enseignement/AVR/Exposes/TR_Dimensiereductie.pdf)  \n  \nPCA - [link](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)    \nAutoencoder - [link](https://blog.keras.io/building-autoencoders-in-keras.html)  \nIsomaps - [link](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.Isomap.html#sklearn.manifold.Isomap)    \nLLE - [link](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.LocallyLinearEmbedding.html)  \nForce-directed graph drawing - [link](https://scanpy.readthedocs.io/en/stable/api/scanpy.tl.draw_graph.html#scanpy.tl.draw_graph)    \nMDS - [link](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html)  \nDiffusion Maps - [link](https://scanpy.readthedocs.io/en/stable/api/scanpy.tl.diffmap.html)  \nt-SNE - [link](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE)    \nNeRV - [link](https://github.com/ziyuang/pynerv), [paper](https://www.jmlr.org/papers/volume11/venna10a/venna10a.pdf)  \nMDR - [link](https://github.com/EpistasisLab/scikit-mdr)  \nUMAP - [link](https://github.com/lmcinnes/umap)  \nRandom Projection - [link](https://scikit-learn.org/stable/modules/random_projection.html)  \nIvis - [link](https://github.com/beringresearch/ivis)   \nSimCLR - [link](https://github.com/lightly-ai/lightly)  \n\n##### Neural-network based\n[esvit](https://github.com/microsoft/esvit) - Vision Transformers for Representation Learning (Microsoft).  \n[MCML](https://github.com/pachterlab/MCML) - Semi-supervised dimensionality reduction of Multi-Class, Multi-Label data (sequencing data) [paper](https://www.biorxiv.org/content/10.1101/2021.08.25.457696v1).  \n\n##### Packages\n[Dangers of PCA (paper)](https://www.nature.com/articles/s41598-022-14395-4).  \n[Talk](https://www.youtube.com/watch?v=9iol3Lk6kyU), [tsne intro](https://distill.pub/2016/misread-tsne/). \n[sklearn.manifold](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold) and [sklearn.decomposition](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition) - PCA, t-SNE, MDS, Isomaps and others.  \nAdditional plots for PCA - Factor Loadings, Cumulative Variance Explained, [Correlation Circle Plot](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_pca_correlation_graph/), [Tweet](https://twitter.com/rasbt/status/1555999903398219777/photo/1)  \n[sklearn.random_projection](https://scikit-learn.org/stable/modules/random_projection.html) - Johnson-Lindenstrauss lemma, Gaussian random projection, Sparse random projection.  \n[sklearn.cross_decomposition](https://scikit-learn.org/stable/modules/cross_decomposition.html#cross-decomposition) - Partial least squares, supervised estimators for dimensionality reduction and regression.  \n[prince](https://github.com/MaxHalford/prince) - Dimensionality reduction, factor analysis (PCA, MCA, CA, FAMD).  \nFaster t-SNE implementations: [lvdmaaten](https://lvdmaaten.github.io/tsne/), [MulticoreTSNE](https://github.com/DmitryUlyanov/Multicore-TSNE), [FIt-SNE](https://github.com/KlugerLab/FIt-SNE)\n[umap](https://github.com/lmcinnes/umap) - Uniform Manifold Approximation and Projection, [talk](https://www.youtube.com/watch?v=nq6iPZVUxZU), [explorer](https://github.com/GrantCuster/umap-explorer), [explanation](https://pair-code.github.io/understanding-umap/), [parallel version](https://docs.rapids.ai/api/cuml/stable/api.html).  \n[humap](https://github.com/wilsonjr/humap) - Hierarchical UMAP.  \n[sleepwalk](https://github.com/anders-biostat/sleepwalk/) - Explore embeddings, interactive visualization (R package).  \n[somoclu](https://github.com/peterwittek/somoclu) - Self-organizing map.  \n[scikit-tda](https://github.com/scikit-tda/scikit-tda) - Topological Data Analysis, [paper](https://www.nature.com/articles/srep01236), [talk](https://www.youtube.com/watch?v=F2t_ytTLrQ4), [talk](https://www.youtube.com/watch?v=AWoeBzJd7uQ), [paper](https://www.uncg.edu/mat/faculty/cdsmyth/topological-approaches-skin.pdf).  \n[giotto-tda](https://github.com/giotto-ai/giotto-tda) - Topological Data Analysis.  \n[ivis](https://github.com/beringresearch/ivis) - Dimensionality reduction using Siamese Networks.  \n[trimap](https://github.com/eamid/trimap) - Dimensionality reduction using triplets.  \n[scanpy](https://github.com/theislab/scanpy) - [Force-directed graph drawing](https://scanpy.readthedocs.io/en/stable/api/scanpy.tl.draw_graph.html#scanpy.tl.draw_graph), [Diffusion Maps](https://scanpy.readthedocs.io/en/stable/api/scanpy.tl.diffmap.html).  \n[direpack](https://github.com/SvenSerneels/direpack) - Projection pursuit, Sufficient dimension reduction, Robust M-estimators.  \n[DBS](https://cran.r-project.org/web/packages/DatabionicSwarm/vignettes/DatabionicSwarm.html) - DatabionicSwarm (R package).  \n[contrastive](https://github.com/abidlabs/contrastive) - Contrastive PCA.  \n[scPCA](https://github.com/PhilBoileau/scPCA) - Sparse contrastive PCA (R package).  \n[tmap](https://github.com/reymond-group/tmap) - Visualization library for large, high-dimensional data sets.  \n[lollipop](https://github.com/neurodata/lollipop) - Linear Optimal Low Rank Projection.  \n[linearsdr](https://github.com/HarrisQ/linearsdr) - Linear Sufficient Dimension Reduction (R package).  \n[PHATE](https://github.com/KrishnaswamyLab/PHATE) - Tool for visualizing high dimensional data.  \n\n#### Training-related\n[iterative-stratification](https://github.com/trent-b/iterative-stratification) - Cross validators with stratification for multilabel data.   \n[livelossplot](https://github.com/stared/livelossplot) - Live training loss plot in Jupyter Notebook.   \n\n#### Visualization\n[All charts](https://datavizproject.com/), [Austrian monuments](https://github.com/njanakiev/austrian-monuments-visualization).  \n[Better heatmaps and correlation plots](https://towardsdatascience.com/better-heatmaps-and-correlation-matrix-plots-in-python-41445d0f2bec).  \n[Example notebooks for interactive visualizations](https://github.com/nicolaskruchten/pydata_global_2021/tree/main)(Plotly,Seaborn, Holoviz, Altair)  \n[cufflinks](https://github.com/santosjorge/cufflinks) - Dynamic visualization library, wrapper for [plotly](https://plot.ly/), [medium](https://towardsdatascience.com/the-next-level-of-data-visualization-in-python-dd6e99039d5e), [example](https://github.com/WillKoehrsen/Data-Analysis/blob/master/plotly/Plotly%20Whirlwind%20Introduction.ipynb).  \n[physt](https://github.com/janpipek/physt) - Better histograms, [talk](https://www.youtube.com/watch?v=ZG-wH3-Up9Y), [notebook](https://nbviewer.jupyter.org/github/janpipek/pydata2018-berlin/blob/master/notebooks/talk.ipynb).  \n[fast-histogram](https://github.com/astrofrog/fast-histogram) - Fast histograms.  \n[matplotlib_venn](https://github.com/konstantint/matplotlib-venn) - Venn diagrams, [alternative](https://github.com/penrose/penrose).  \n[joypy](https://github.com/sbebo/joypy) - Draw stacked density plots (=ridge plots), [Ridge plots in seaborn](https://seaborn.pydata.org/examples/kde_ridgeplot.html).  \n[mosaic plots](https://www.statsmodels.org/dev/generated/statsmodels.graphics.mosaicplot.mosaic.html) - Categorical variable visualization, [example](https://sukhbinder.wordpress.com/2018/09/18/mosaic-plot-in-python/).  \n[scikit-plot](https://github.com/reiinakano/scikit-plot) - ROC curves and other visualizations for ML models.  \n[yellowbrick](https://github.com/DistrictDataLabs/yellowbrick) - Visualizations for ML models (similar to scikit-plot).  \n[bokeh](https://bokeh.pydata.org/en/latest/) - Interactive visualization library, [Examples](https://bokeh.pydata.org/en/latest/docs/user_guide/server.html), [Examples](https://github.com/WillKoehrsen/Bokeh-Python-Visualization).  \n[lets-plot](https://github.com/JetBrains/lets-plot) - Plotting library.  \n[animatplot](https://github.com/t-makaro/animatplot) - Animate plots build on matplotlib.  \n[plotnine](https://github.com/has2k1/plotnine) - ggplot for Python.  \n[altair](https://altair-viz.github.io/) - Declarative statistical visualization library.  \n[bqplot](https://github.com/bloomberg/bqplot) - Plotting library for IPython/Jupyter Notebooks.  \n[hvplot](https://github.com/pyviz/hvplot) - High-level plotting library built on top of [holoviews](http://holoviews.org/).  \n[dtreeviz](https://github.com/parrt/dtreeviz) - Decision tree visualization and model interpretation.  \n[chartify](https://github.com/spotify/chartify/) - Generate charts.  \n[VivaGraphJS](https://github.com/anvaka/VivaGraphJS) - Graph visualization (JS package).  \n[pm](https://github.com/anvaka/pm) - Navigatable 3D graph visualization (JS package), [example](https://w2v-vis-dot-hcg-team-di.appspot.com/#/galaxy/word2vec?cx=5698&cy=-5135&cz=5923&lx=0.1127&ly=0.3238&lz=-0.1680&lw=0.9242&ml=150&s=1.75&l=1&v=hc).  \n[python-ternary](https://github.com/marcharper/python-ternary) - Triangle plots.  \n[falcon](https://github.com/uwdata/falcon) - Interactive visualizations for big data.  \n[hiplot](https://github.com/facebookresearch/hiplot) - High dimensional Interactive Plotting.  \n[visdom](https://github.com/fossasia/visdom) - Live Visualizations.  \n[mpl-scatter-density](https://github.com/astrofrog/mpl-scatter-density) - Scatter density plots. Alternative to 2d-histograms.   \n[ComplexHeatmap](https://github.com/jokergoo/ComplexHeatmap) - Complex heatmaps for multidimensional genomic data (R package).  \n[largeVis](https://github.com/elbamos/largeVis) - Visualize embeddings (t-SNE etc.) (R package).  \n[proplot](https://github.com/proplot-dev/proplot) - Matplotlib wrapper.  \n[morpheus](https://software.broadinstitute.org/morpheus/) - Broad Institute tool matrix visualization and analysis software. [Source](https://github.com/cmap/morpheus.js), Tutorial: [1](https://www.youtube.com/watch?v=0nkYDeekhtQ), [2](https://www.youtube.com/watch?v=r9mN6MsxUb0), [Code](https://github.com/broadinstitute/BBBC021_Morpheus_Exercise).  \n\n#### Colors\n[palettable](https://github.com/jiffyclub/palettable) - Color palettes from [colorbrewer2](https://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3).  \n[colorcet](https://github.com/holoviz/colorcet) - Collection of perceptually uniform colormaps.  \n[Named Colors Wheel](https://arantius.github.io/web-color-wheel/) - Color wheel for all named HTML colors.  \n\n#### Dashboards\n[superset](https://github.com/apache/superset) - Dashboarding solution by Apache.  \n[streamlit](https://github.com/streamlit/streamlit) - Dashboarding solution. [Resources](https://github.com/marcskovmadsen/awesome-streamlit), [Gallery](https://awesome-streamlit.org/) [Components](https://www.streamlit.io/components), [bokeh-events](https://github.com/ash2shukla/streamlit-bokeh-events).  \n[mercury](https://github.com/mljar/mercury) - Convert Python notebook to web app, [Example](https://github.com/pplonski/dashboard-python-jupyter-notebook).  \n[dash](https://dash.plot.ly/gallery) - Dashboarding solution by plot.ly. [Resources](https://github.com/ucg8j/awesome-dash).  \n[visdom](https://github.com/facebookresearch/visdom) - Dashboarding library by facebook.  \n[panel](https://panel.pyviz.org/index.html) - Dashboarding solution.  \n[altair example](https://github.com/xhochy/altair-vue-vega-example) - [Video](https://www.youtube.com/watch?v=4L568emKOvs).  \n[voila](https://github.com/QuantStack/voila) - Turn Jupyter notebooks into standalone web applications.  \n[voila-gridstack](https://github.com/voila-dashboards/voila-gridstack) - Voila grid layout.  \n\n#### UI\n[gradio](https://github.com/gradio-app/gradio) - Create UIs for your machine learning model.  \n\n#### Survey Tools\n[samplics](https://github.com/samplics-org/samplics) - Sampling techniques for complex survey designs.  \n\n#### Geographical Tools\n[folium](https://github.com/python-visualization/folium) - Plot geographical maps using the Leaflet.js library, [jupyter plugin](https://github.com/jupyter-widgets/ipyleaflet).  \n[gmaps](https://github.com/pbugnion/gmaps) - Google Maps for Jupyter notebooks.  \n[stadiamaps](https://stadiamaps.com/) - Plot geographical maps.  \n[datashader](https://github.com/bokeh/datashader) - Draw millions of points on a map.  \n[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html) - BallTree, [Example](https://tech.minodes.com/experiments-with-in-memory-spatial-radius-queries-in-python-e40c9e66cf63).  \n[pynndescent](https://github.com/lmcinnes/pynndescent) - Nearest neighbor descent for approximate nearest neighbors.  \n[geocoder](https://github.com/DenisCarriere/geocoder) - Geocoding of addresses, IP addresses.  \nConversion of different geo formats: [talk](https://www.youtube.com/watch?v=eHRggqAvczE), [repo](https://github.com/dillongardner/PyDataSpatialAnalysis)  \n[geopandas](https://github.com/geopandas/geopandas) - Tools for geographic data  \nLow Level Geospatial Tools (GEOS, GDAL/OGR, PROJ.4)  \nVector Data (Shapely, Fiona, Pyproj)  \nRaster Data (Rasterio)  \nPlotting (Descartes, Catropy)  \nPredict economic indicators from Open Street Map [ipynb](https://github.com/njanakiev/osm-predict-economic-measurements/blob/master/osm-predict-economic-indicators.ipynb).  \n[PySal](https://github.com/pysal/pysal) - Python Spatial Analysis Library.  \n[geography](https://github.com/ushahidi/geograpy) - Extract countries, regions and cities from a URL or text.  \n[cartogram](https://go-cart.io/cartogram) - Distorted maps based on population.  \n\n#### Recommender Systems\nExamples: [1](https://lazyprogrammer.me/tutorial-on-collaborative-filtering-and-matrix-factorization-in-python/), [2](https://medium.com/@james_aka_yale/the-4-recommendation-engines-that-can-predict-your-movie-tastes-bbec857b8223), [2-ipynb](https://github.com/khanhnamle1994/movielens/blob/master/Content_Based_and_Collaborative_Filtering_Models.ipynb), [3](https://www.kaggle.com/morrisb/how-to-recommend-anything-deep-recommender).  \n[surprise](https://github.com/NicolasHug/Surprise) - Recommender, [talk](https://www.youtube.com/watch?v=d7iIb_XVkZs).  \n[turicreate](https://github.com/apple/turicreate) - Recommender.  \n[implicit](https://github.com/benfred/implicit) - Fast Collaborative Filtering for Implicit Feedback Datasets.  \n[spotlight](https://github.com/maciejkula/spotlight) - Deep recommender models using PyTorch.  \n[lightfm](https://github.com/lyst/lightfm) - Recommendation algorithms for both implicit and explicit feedback.  \n[funk-svd](https://github.com/gbolmier/funk-svd) - Fast SVD.  \n[pywFM](https://github.com/jfloff/pywFM) - Factorization.  \n\n#### Decision Tree Models\n[Intro to Decision Trees and Random Forests](https://victorzhou.com/blog/intro-to-random-forests/), Intro to Gradient Boosting [1](https://explained.ai/gradient-boosting/), [2](https://www.gormanalysis.com/blog/gradient-boosting-explained/), [Decision Tree Visualization](https://explained.ai/decision-tree-viz/index.html)    \n[lightgbm](https://github.com/Microsoft/LightGBM) - Gradient boosting (GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, [doc](https://sites.google.com/view/lauraepp/parameters).  \n[xgboost](https://github.com/dmlc/xgboost) - Gradient boosting (GBDT, GBRT or GBM) library, [doc](https://sites.google.com/view/lauraepp/parameters), Methods for CIs: [link1](https://stats.stackexchange.com/questions/255783/confidence-interval-for-xgb-forecast), [link2](https://towardsdatascience.com/regression-prediction-intervals-with-xgboost-428e0a018b).  \n[catboost](https://github.com/catboost/catboost) - Gradient boosting.  \n[h2o](https://github.com/h2oai/h2o-3) -  Gradient boosting and general machine learning framework.  \n[snapml](https://www.zurich.ibm.com/snapml/) - Gradient boosting and general machine learning framework by IBM, for CPU and GPU. [PyPI](https://pypi.org/project/snapml/)    \n[pycaret](https://github.com/pycaret/pycaret) - Wrapper for xgboost, lightgbm, catboost etc.  \n[thundergbm](https://github.com/Xtra-Computing/thundergbm) - GBDTs and Random Forest.  \n[h2o](https://github.com/h2oai/h2o-3) - Gradient boosting.  \n[forestci](https://github.com/scikit-learn-contrib/forest-confidence-interval) - Confidence intervals for random forests.  \n[scikit-garden](https://github.com/scikit-garden/scikit-garden) - Quantile Regression.  \n[grf](https://github.com/grf-labs/grf) - Generalized random forest.  \n[dtreeviz](https://github.com/parrt/dtreeviz) - Decision tree visualization and model interpretation.  \n[Nuance](https://github.com/SauceCat/Nuance) - Decision tree visualization.  \n[rfpimp](https://github.com/parrt/random-forest-importances) - Feature Importance for RandomForests using Permuation Importance.  \nWhy the default feature importance for random forests is wrong: [link](http://explained.ai/rf-importance/index.html)  \n[treeinterpreter](https://github.com/andosa/treeinterpreter) - Interpreting scikit-learn's decision tree and random forest predictions.  \n[bartpy](https://github.com/JakeColtman/bartpy) - Bayesian Additive Regression Trees.  \n[infiniteboost](https://github.com/arogozhnikov/infiniteboost) - Combination of RFs and GBDTs.  \n[merf](https://github.com/manifoldai/merf) - Mixed Effects Random Forest for Clustering, [video](https://www.youtube.com/watch?v=gWj4ZwB7f3o)  \n[rrcf](https://github.com/kLabUM/rrcf) - Robust Random Cut Forest algorithm for anomaly detection on streams.  \n[groot](https://github.com/tudelft-cda-lab/GROOT) - Robust decision trees.  \n[linear-tree](https://github.com/cerlymarco/linear-tree) - Trees with linear models at the leaves.  \n\n#### Natural Language Processing (NLP) / Text Processing\n[talk](https://www.youtube.com/watch?v=6zm9NC9uRkk)-[nb](https://nbviewer.jupyter.org/github/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb), [nb2](https://ahmedbesbes.com/how-to-mine-newsfeed-data-and-extract-interactive-insights-in-python.html), [talk](https://www.youtube.com/watch?time_continue=2&v=sI7VpFNiy_I).  \n[Text classification Intro](https://mlwhiz.com/blog/2018/12/17/text_classification/), [Preprocessing blog post](https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/).  \n[gensim](https://radimrehurek.com/gensim/) - NLP, doc2vec, word2vec, text processing, topic modelling (LSA, LDA), [Example](https://markroxor.github.io/gensim/static/notebooks/gensim_news_classification.html), [Coherence Model](https://radimrehurek.com/gensim/models/coherencemodel.html) for evaluation.  \nEmbeddings - [GloVe](https://nlp.stanford.edu/projects/glove/) ([[1](https://www.kaggle.com/jhoward/improved-lstm-baseline-glove-dropout)], [[2](https://www.kaggle.com/sbongo/do-pretrained-embeddings-give-you-the-extra-edge)]), [StarSpace](https://github.com/facebookresearch/StarSpace), [wikipedia2vec](https://wikipedia2vec.github.io/wikipedia2vec/pretrained/), [visualization](https://projector.tensorflow.org/).  \n[magnitude](https://github.com/plasticityai/magnitude) - Vector embedding utility package.  \n[pyldavis](https://github.com/bmabey/pyLDAvis) - Visualization for topic modelling.  \n[spaCy](https://spacy.io/) - NLP.  \n[NTLK](https://www.nltk.org/) - NLP, helpful `KMeansClusterer` with `cosine_distance`.  \n[pytext](https://github.com/facebookresearch/PyText) - NLP from Facebook.  \n[fastText](https://github.com/facebookresearch/fastText) - Efficient text classification and representation learning.  \n[annoy](https://github.com/spotify/annoy) - Approximate nearest neighbor search.  \n[faiss](https://github.com/facebookresearch/faiss) - Approximate nearest neighbor search.  \n[pysparnn](https://github.com/facebookresearch/pysparnn) - Approximate nearest neighbor search.  \n[infomap](https://github.com/mapequation/infomap) - Cluster (word-)vectors to find topics, [example](https://github.com/mapequation/infomap/blob/master/examples/python/infomap-examples.ipynb).  \n[datasketch](https://github.com/ekzhu/datasketch) - Probabilistic data structures for large data (MinHash, HyperLogLog).  \n[flair](https://github.com/zalandoresearch/flair) - NLP Framework by Zalando.  \n[stanfordnlp](https://github.com/stanfordnlp/stanfordnlp) - NLP Library.  \n[Chatistics](https://github.com/MasterScrat/Chatistics) - Turn Messenger, Hangouts, WhatsApp and Telegram chat logs into DataFrames.  \n[textvec](https://github.com/textvec/textvec) - Supervised text vectorization tool.  \n[textdistance](https://github.com/life4/textdistance) - Collection for comparing distances between two or more sequences.  \n\n##### Papers\n[Search Engine Correlation](https://arxiv.org/pdf/1107.2691.pdf)  \n\n#### Biology / Bioinformatics\n\n##### Biostatistics / Robust statistics\n[MinCovDet](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.MinCovDet.html) - Robust estimator of covariance, RMPV, [Paper](https://wires.onlinelibrary.wiley.com/doi/full/10.1002/wics.1421), [App1](https://journals.sagepub.com/doi/10.1177/1087057112469257?url_ver=Z39.88-2003&rfr_id=ori%3Arid%3Acrossref.org&rfr_dat=cr_pub++0pubmed&), [App2](https://www.cell.com/cell-reports/pdf/S2211-1247(21)00694-X.pdf).  \n[winsorize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mstats.winsorize.html#scipy.stats.mstats.winsorize) - Simple adjustment of outliers.  \n[moderated z-score](https://clue.io/connectopedia/replicate_collapse) - Weighted average of z-scores based on Spearman correlation.  \n\n##### Sequencing\n[Single cell tutorial](https://github.com/theislab/single-cell-tutorial).  \n[cellxgene](https://github.com/chanzuckerberg/cellxgene) - Interactive explorer for single-cell transcriptomics data.  \n[scanpy](https://github.com/theislab/scanpy) - Analyze single-cell gene expression data, [tutorial](https://github.com/theislab/single-cell-tutorial).  \n[besca](https://github.com/bedapub/besca) - Beyond single-cell analysis.  \n[janggu](https://github.com/BIMSBbioinfo/janggu) - Deep Learning for Genomics.  \n[gdsctools](https://github.com/CancerRxGene/gdsctools) - Drug responses in the context of the Genomics of Drug Sensitivity in Cancer project, ANOVA, IC50, MoBEM, [doc](https://gdsctools.readthedocs.io/en/master/).  \n\n##### Image-related\nSee also Microscopy Section above.  \n[Overview over cell segmentation algorithms](https://biomag-lab.github.io/microscopy-tree/)  \n[python_for_microscopists](https://github.com/bnsreenu/python_for_microscopists) - Notebooks and associated [youtube channel](https://www.youtube.com/channel/UC34rW-HtPJulxr5wp2Xa04w/videos) for a variety of image processing tasks.  \n[mahotas](http://luispedro.org/software/mahotas/) - Image processing (Bioinformatics), [example](https://github.com/luispedro/python-image-tutorial/blob/master/Segmenting%20cell%20images%20(fluorescent%20microscopy).ipynb).   \n[imagepy](https://github.com/Image-Py/imagepy) - Software package for bioimage analysis.  \n[scimap](https://github.com/labsyspharm/scimap) - Spatial Single-Cell Analysis Toolkit.  \n[CellProfiler](https://github.com/CellProfiler/CellProfiler) - Biological image analysis.   \n[imglyb](https://github.com/imglib/imglyb) - Viewer for large images, [talk](https://www.youtube.com/watch?v=Ddo5z5qGMb8), [slides](https://github.com/hanslovsky/scipy-2019/blob/master/scipy-2019-imglyb.pdf).  \n[microscopium](https://github.com/microscopium/microscopium) - Unsupervised clustering of images + viewer, [talk](https://www.youtube.com/watch?v=ytEQl9xs8FQ).  \n[cytokit](https://github.com/hammerlab/cytokit) - Analyzing properties of cells in fluorescent microscopy datasets.  \n[ZeroCostDL4Mic](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki) - Deep-Learning in Microscopy.  \n\n##### Drug discovery\n[TDC](https://github.com/mims-harvard/TDC/tree/main) - Drug Discovery and Development.  \n[DeepPurpose](https://github.com/kexinhuang12345/DeepPurpose) - Deep Learning Based Molecular Modeling and Prediction Toolkit.  \n\n##### Courses\n[mit6874](https://mit6874.github.io/) - Computational Systems Biology: Deep Learning in the Life Sciences.  \n\n#### Image Processing\n[Talk](https://www.youtube.com/watch?v=Y5GJmnIhvFk)  \n[cv2](https://github.com/skvark/opencv-python) - OpenCV, classical algorithms: [Gaussian Filter](https://docs.opencv.org/3.1.0/d4/d13/tutorial_py_filtering.html), [Morphological Transformations](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html).  \n[scikit-image](https://github.com/scikit-image/scikit-image) - Image processing.  \n\n#### Neural Networks\n[Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/) - Stanford CS class.  \n[ConvNet Shape Calculator](https://madebyollin.github.io/convnet-calculator/) - Calculate output dimensions of Conv2D layer.  \n[Great Gradient Descent Article](https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9).  \n[Intro to semi-supervised learning](https://lilianweng.github.io/lil-log/2021/12/05/semi-supervised-learning.html).  \n\n##### Tutorials & Viewer\nfast.ai course - [Lessons 1-7](https://course.fast.ai/videos/?lesson=1), [Lessons 8-14](http://course18.fast.ai/lessons/lessons2.html)  \n[Tensorflow without a PhD](https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd) - Neural Network course by Google.  \nFeature Visualization: [Blog](https://distill.pub/2017/feature-visualization/), [PPT](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf)  \n[Tensorflow Playground](https://playground.tensorflow.org/)  \n[Visualization of optimization algorithms](https://vis.ensmallen.org/), [Another visualization](https://github.com/jettify/pytorch-optimizer)    \n[cutouts-explorer](https://github.com/mgckind/cutouts-explorer) - Image Viewer.  \n\n##### Image Related\n[imgaug](https://github.com/aleju/imgaug) - More sophisticated image preprocessing.  \n[Augmentor](https://github.com/mdbloice/Augmentor) - Image augmentation library.  \n[keras preprocessing](https://keras.io/preprocessing/image/) - Preprocess images.  \n[albumentations](https://github.com/albu/albumentations) - Wrapper around imgaug and other libraries.  \n[augmix](https://github.com/google-research/augmix) - Image augmentation from Google.  \n[kornia](https://github.com/kornia/kornia) - Image augmentation, feature extraction and loss functions.  \n[augly](https://github.com/facebookresearch/AugLy) - Image, audio, text, video augmentation from Facebook.  \n\n##### Lossfunction Related\n[SegLoss](https://github.com/JunMa11/SegLoss) - List of loss functions for medical image segmentation.  \n\n##### Activation Functions\n[rational_activations](https://github.com/ml-research/rational_activations) - Rational activation functions.  \n\n##### Text Related\n[ktext](https://github.com/hamelsmu/ktext) - Utilities for pre-processing text for deep learning in Keras.   \n[textgenrnn](https://github.com/minimaxir/textgenrnn) - Ready-to-use LSTM for text generation.  \n[ctrl](https://github.com/salesforce/ctrl) - Text generation.  \n\n##### Neural network and deep learning frameworks\n[OpenMMLab](https://github.com/open-mmlab) - Framework for segmentation, classification and lots of other computer vision tasks.  \n[caffe](https://github.com/BVLC/caffe) - Deep learning framework, [pretrained models](https://github.com/BVLC/caffe/wiki/Model-Zoo).  \n[mxnet](https://github.com/apache/incubator-mxnet) - Deep learning framework, [book](https://d2l.ai/index.html).  \n\n##### Libs General\n[keras](https://keras.io/) - Neural Networks on top of [tensorflow](https://www.tensorflow.org/), [examples](https://gist.github.com/candlewill/552fa102352ccce42fd829ae26277d24).  \n[keras-contrib](https://github.com/keras-team/keras-contrib) - Keras community contributions.  \n[keras-tuner](https://github.com/keras-team/keras-tuner) - Hyperparameter tuning for Keras.  \n[hyperas](https://github.com/maxpumperla/hyperas) - Keras + Hyperopt: Convenient hyperparameter optimization wrapper.  \n[elephas](https://github.com/maxpumperla/elephas) - Distributed Deep learning with Keras & Spark.  \n[tflearn](https://github.com/tflearn/tflearn) - Neural Networks on top of tensorflow.  \n[tensorlayer](https://github.com/tensorlayer/tensorlayer) - Neural Networks on top of tensorflow, [tricks](https://github.com/wagamamaz/tensorlayer-tricks).  \n[tensorforce](https://github.com/reinforceio/tensorforce) - Tensorflow for applied reinforcement learning.  \n[autokeras](https://github.com/jhfjhfj1/autokeras) - AutoML for deep learning.  \n[PlotNeuralNet](https://github.com/HarisIqbal88/PlotNeuralNet) - Plot neural networks.  \n[lucid](https://github.com/tensorflow/lucid) - Neural network interpretability, [Activation Maps](https://openai.com/blog/introducing-activation-atlases/).  \n[tcav](https://github.com/tensorflow/tcav) - Interpretability method.  \n[AdaBound](https://github.com/Luolc/AdaBound) - Optimizer that trains as fast as Adam and as good as SGD, [alt](https://github.com/titu1994/keras-adabound).  \n[foolbox](https://github.com/bethgelab/foolbox) - Adversarial examples that fool neural networks.  \n[hiddenlayer](https://github.com/waleedka/hiddenlayer) - Training metrics.  \n[imgclsmob](https://github.com/osmr/imgclsmob) - Pretrained models.  \n[netron](https://github.com/lutzroeder/netron) - Visualizer for deep learning and machine learning models.  \n[ffcv](https://github.com/libffcv/ffcv) - Fast dataloder.  \n\n##### Libs Pytorch\n[Good Pytorch Introduction](https://cs230.stanford.edu/blog/pytorch/)    \n[skorch](https://github.com/dnouri/skorch) - Scikit-learn compatible neural network library that wraps pytorch, [talk](https://www.youtube.com/watch?v=0J7FaLk0bmQ), [slides](https://github.com/thomasjpfan/skorch_talk).  \n[fastai](https://github.com/fastai/fastai) - Neural Networks in pytorch.  \n[timm](https://github.com/rwightman/pytorch-image-models) - Pytorch image models.  \n[ignite](https://github.com/pytorch/ignite) - Highlevel library for pytorch.  \n[torchcv](https://github.com/donnyyou/torchcv) - Deep Learning in Computer Vision.  \n[pytorch-optimizer](https://github.com/jettify/pytorch-optimizer) - Collection of optimizers for pytorch.  \n[pytorch-lightning](https://github.com/PyTorchLightning/PyTorch-lightning) - Wrapper around PyTorch.  \n[lightly](https://github.com/lightly-ai/lightly) - MoCo, SimCLR, SimSiam, Barlow Twins, BYOL, NNCLR.  \n[MONAI](https://github.com/project-monai/monai) - Deep learning in healthcare imaging.  \n[kornia](https://github.com/kornia/kornia) - Image transformations, epipolar geometry, depth estimation.  \n[torchinfo](https://github.com/TylerYep/torchinfo) - Nice model summary.  \n[lovely-tensors](https://github.com/xl0/lovely-tensors/) - Inspect tensors, mean, std, inf values.  \n\n##### Distributed Libs\n[flexflow](https://github.com/flexflow/FlexFlow) - Distributed TensorFlow Keras and PyTorch.  \n[horovod](https://github.com/horovod/horovod) - Distributed training framework for TensorFlow, Keras, PyTorch, and Apache MXNet.  \n\n##### Architecture Visualization\n[Awesome List](https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network).  \n[netron](https://github.com/lutzroeder/netron) - Viewer for neural networks.  \n[visualkeras](https://github.com/paulgavrikov/visualkeras) - Visualize Keras networks.  \n\n##### Object detection / Instance Segmentation\n[Good Yolo Explanation](https://jonathan-hui.medium.com/real-time-object-detection-with-yolo-yolov2-28b1b93e2088)  \n[segmentation_models](https://github.com/qubvel/segmentation_models) - Segmentation models with pretrained backbones: Unet, FPN, Linknet, PSPNet.  \n[yolact](https://github.com/dbolya/yolact) - Fully convolutional model for real-time instance segmentation.  \n[EfficientDet Pytorch](https://github.com/toandaominh1997/EfficientDet.Pytorch), [EfficientDet Keras](https://github.com/xuannianz/EfficientDet) - Scalable and Efficient Object Detection.  \n[detectron2](https://github.com/facebookresearch/detectron2) - Object Detection (Mask R-CNN) by Facebook.  \n[simpledet](https://github.com/TuSimple/simpledet) - Object Detection and Instance Recognition.  \n[CenterNet](https://github.com/xingyizhou/CenterNet) - Object detection.  \n[FCOS](https://github.com/tianzhi0549/FCOS) - Fully Convolutional One-Stage Object Detection.  \n[norfair](https://github.com/tryolabs/norfair) - Real-time 2D object tracking.  \n[Detic](https://github.com/facebookresearch/Detic) -  Detector with image classes that can use image-level labels (facebookresearch).  \n[EasyCV](https://github.com/alibaba/EasyCV) - Image segmentation, classification, metric-learning, object detection, pose estimation.  \n\n##### Image Annotation\n[cvat](https://github.com/openvinotoolkit/cvat) - Image annotation tool.  \n[pigeon](https://github.com/agermanidis/pigeon) - Create annotations from within a Jupyter notebook.  \n\n##### Image Classification\n[nfnets](https://github.com/ypeleg/nfnets-keras) - Neural network.   \n[efficientnet](https://github.com/lukemelas/EfficientNet-PyTorch) - Neural network.   \n[pycls](https://github.com/facebookresearch/pycls) - Pytorch image classification networks: ResNet, ResNeXt, EfficientNet, and RegNet (by Facebook).  \n\n##### Applications and Snippets\n[SPADE](https://github.com/nvlabs/spade) - Semantic Image Synthesis.  \n[Entity Embeddings of Categorical Variables](https://arxiv.org/abs/1604.06737), [code](https://github.com/entron/entity-embedding-rossmann), [kaggle](https://www.kaggle.com/aquatic/entity-embedding-neural-net/code)  \n[Image Super-Resolution](https://github.com/idealo/image-super-resolution) - Super-scaling using a Residual Dense Network.  \nCell Segmentation - [Talk](https://www.youtube.com/watch?v=dVFZpodqJiI), Blog Posts: [1](https://www.thomasjpfan.com/2018/07/nuclei-image-segmentation-tutorial/), [2](https://www.thomasjpfan.com/2017/08/hassle-free-unets/)  \n[deeplearning-models](https://github.com/rasbt/deeplearning-models) - Deep learning models.  \n\n##### Variational Autoencoders (VAEs)\n[Variational Autoencoder Explanation Video](https://www.youtube.com/watch?v=9zKuYvjFFS8)  \n[disentanglement_lib](https://github.com/google-research/disentanglement_lib) - BetaVAE, FactorVAE, BetaTCVAE, DIP-VAE.  \n[ladder-vae-pytorch](https://github.com/addtt/ladder-vae-pytorch) - Ladder Variational Autoencoders (LVAE).  \n[benchmark_VAE](https://github.com/clementchadebec/benchmark_VAE) - Unifying Generative Autoencoder implementations.  \n\n##### Generative Adversarial Networks (GANs)\n[Awesome GAN Applications](https://github.com/nashory/gans-awesome-applications)  \n[The GAN Zoo](https://github.com/hindupuravinash/the-gan-zoo) - List of Generative Adversarial Networks.  \n[CycleGAN and Pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) - Various image-to-image tasks.  \n[Tensorflow GAN implementations](https://github.com/hwalsuklee/tensorflow-generative-model-collections)  \n[Pytorch GAN implementations](https://github.com/znxlwm/pytorch-generative-model-collections)  \n[Pytorch GAN implementations](https://github.com/eriklindernoren/PyTorch-GAN#adversarial-autoencoder)  \n[StudioGAN](https://github.com/POSTECH-CVLab/PyTorch-StudioGAN) - Pytorch GAN implementations.  \n\n##### Transformers\n[SegFormer](https://github.com/NVlabs/SegFormer) - Simple and Efficient Design for Semantic Segmentation with Transformers.  \n[esvit](https://github.com/microsoft/esvit) - Efficient self-supervised Vision Transformers.  \n[nystromformer](https://github.com/Rishit-dagli/Nystromformer) - More efficient transformer because of approximate self-attention.  \n\n##### Deep learning on structured data\n[Great overview for deep learning for tabular data](https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html)  \n\n##### Graph-Based Neural Networks\n[How to do Deep Learning on Graphs with Graph Convolutional Networks](https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780)  \n[Introduction To Graph Convolutional Networks](http://tkipf.github.io/graph-convolutional-networks/)  \n[An attempt at demystifying graph deep learning](https://ericmjl.github.io/essays-on-data-science/machine-learning/graph-nets/)  \n[ogb](https://ogb.stanford.edu/) - Open Graph Benchmark, Benchmark datasets.  \n[networkx](https://github.com/networkx/networkx) - Graph library.  \n[cugraph](https://github.com/rapidsai/cugraph) - RAPIDS, Graph library on the GPU.  \n[pytorch-geometric](https://github.com/rusty1s/pytorch_geometric) - Various methods for deep learning on graphs.  \n[dgl](https://github.com/dmlc/dgl) - Deep Graph Library.  \n[graph_nets](https://github.com/deepmind/graph_nets) - Build graph networks in Tensorflow, by deepmind.  \n\n#### Model conversion\n[hummingbird](https://github.com/microsoft/hummingbird) - Compile trained ML models into tensor computations (by Microsoft).  \n\n#### GPU\n[cuML](https://github.com/rapidsai/cuml) - RAPIDS, Run traditional tabular ML tasks on GPUs, [Intro](https://www.youtube.com/watch?v=6XzS5XcpicM&t=2m50s).  \n[thundergbm](https://github.com/Xtra-Computing/thundergbm) - GBDTs and Random Forest.  \n[thundersvm](https://github.com/Xtra-Computing/thundersvm) - Support Vector Machines.  \nLegate Numpy - Distributed Numpy array multiple using GPUs by Nvidia (not released yet) [video](https://www.youtube.com/watch?v=Jxxs_moibog).  \n\n#### Regression\nUnderstanding SVM Regression: [slides](https://cs.adelaide.edu.au/~chhshen/teaching/ML_SVR.pdf), [forum](https://www.quora.com/How-does-support-vector-regression-work), [paper](http://alex.smola.org/papers/2003/SmoSch03b.pdf)  \n\n[pyearth](https://github.com/scikit-learn-contrib/py-earth) - Multivariate Adaptive Regression Splines (MARS), [tutorial](https://uc-r.github.io/mars).  \n[pygam](https://github.com/dswah/pyGAM) - Generalized Additive Models (GAMs), [Explanation](https://multithreaded.stitchfix.com/blog/2015/07/30/gam/).  \n[GLRM](https://github.com/madeleineudell/LowRankModels.jl) - Generalized Low Rank Models.  \n[tweedie](https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tweedie-regression-objective-reg-tweedie) - Specialized distribution for zero inflated targets, [Talk](https://www.youtube.com/watch?v=-o0lpHBq85I).  \n[MAPIE](https://github.com/scikit-learn-contrib/MAPIE) - Estimating prediction intervals.  \n[Regressio](https://github.com/brendanartley/Regressio) - Regression and Spline models.  \n\n#### Polynomials\n[orthopy](https://github.com/nschloe/orthopy) - Orthogonal polynomials in all shapes and sizes.  \n\n#### Classification\n[Talk](https://www.youtube.com/watch?v=DkLPYccEJ8Y), [Notebook](https://github.com/ianozsvald/data_science_delivered/blob/master/ml_creating_correct_capable_classifiers.ipynb)  \n[Blog post: Probability Scoring](https://machinelearningmastery.com/how-to-score-probability-predictions-in-python/)  \n[All classification metrics](http://rali.iro.umontreal.ca/rali/sites/default/files/publis/SokolovaLapalme-JIPM09.pdf)  \n[DESlib](https://github.com/scikit-learn-contrib/DESlib) - Dynamic classifier and ensemble selection.  \n[human-learn](https://github.com/koaning/human-learn) - Create and tune classifier based on your rule set.  \n\n#### Metric Learning\n[Contrastive Representation Learning](https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html)  \n  \n[metric-learn](https://github.com/scikit-learn-contrib/metric-learn) - Supervised and weakly-supervised metric learning algorithms.  \n[pytorch-metric-learning](https://github.com/KevinMusgrave/pytorch-metric-learning) - Pytorch metric learning.  \n[deep_metric_learning](https://github.com/ronekko/deep_metric_learning) - Methods for deep metric learning.  \n[ivis](https://bering-ivis.readthedocs.io/en/latest/supervised.html) - Metric learning using siamese neural networks.  \n[tensorflow similarity](https://github.com/tensorflow/similarity) - Metric learning.  \n\n#### Distance Functions\n[scipy.spatial](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html) - All kinds of distance metrics.  \n[pyemd](https://github.com/wmayner/pyemd) - Earth Mover's Distance / Wasserstein distance, similarity between histograms. [OpenCV implementation](https://docs.opencv.org/3.4/d6/dc7/group__imgproc__hist.html), [POT implementation](https://pythonot.github.io/auto_examples/plot_OT_2D_samples.html)   \n[dcor](https://github.com/vnmabus/dcor)  - Distance correlation and related Energy statistics.  \n[GeomLoss](https://www.kernel-operations.io/geomloss/) - Kernel norms, Hausdorff divergences, Debiased Sinkhorn divergences (=approximation of Wasserstein distance).  \n\n#### Self-supervised Learning\n[lightly](https://github.com/lightly-ai/lightly) - MoCo, SimCLR, SimSiam, Barlow Twins, BYOL, NNCLR.  \n[vissl](https://github.com/facebookresearch/vissl) - Self-Supervised Learning with PyTorch: RotNet, Jigsaw, NPID, ClusterFit, PIRL, SimCLR, MoCo, DeepCluster, SwAV.  \n\n#### Clustering\n[Overview of clustering algorithms applied image data (= Deep Clustering)](https://deepnotes.io/deep-clustering).  \n[Clustering with Deep Learning: Taxonomy and New Methods](https://arxiv.org/pdf/1801.07648.pdf).  \n[Hierarchical Cluster Analysis (R Tutorial)](https://uc-r.github.io/hc_clustering) - Dendrogram, Tanglegram  \n[hdbscan](https://github.com/scikit-learn-contrib/hdbscan) - Clustering algorithm, [talk](https://www.youtube.com/watch?v=dGsxd67IFiU), [blog](https://towardsdatascience.com/understanding-hdbscan-and-density-based-clustering-121dbee1320e).  \n[pyclustering](https://github.com/annoviko/pyclustering) - All sorts of clustering algorithms.  \n[FCPS](https://github.com/Mthrun/FCPS) -  Fundamental Clustering Problems Suite (R package).  \n[GaussianMixture](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html) - Generalized k-means clustering using a mixture of Gaussian distributions, [video](https://www.youtube.com/watch?v=aICqoAG5BXQ).  \n[nmslib](https://github.com/nmslib/nmslib) - Similarity search library and toolkit for evaluation of k-NN methods.  \n[buckshotpp](https://github.com/zjohn77/buckshotpp) - Outlier-resistant and scalable clustering algorithm.  \n[merf](https://github.com/manifoldai/merf) - Mixed Effects Random Forest for Clustering, [video](https://www.youtube.com/watch?v=gWj4ZwB7f3o)  \n[tree-SNE](https://github.com/isaacrob/treesne) - Hierarchical clustering algorithm based on t-SNE.  \n[MiniSom](https://github.com/JustGlowing/minisom) - Pure Python implementation of the Self Organizing Maps.  \n[distribution_clustering](https://github.com/EricElmoznino/distribution_clustering), [paper](https://arxiv.org/abs/1804.02624), [related paper](https://arxiv.org/abs/2003.07770), [alt](https://github.com/r0f1/distribution_clustering).  \n[phenograph](https://github.com/dpeerlab/phenograph) - Clustering by community detection.  \n[FastPG](https://github.com/sararselitsky/FastPG) - Clustering of single cell data (RNA). Improvement of phenograph, [Paper](https://www.researchgate.net/publication/342339899_FastPG_Fast_clustering_of_millions_of_single_cells).  \n[HypHC](https://github.com/HazyResearch/HypHC) - Hyperbolic Hierarchical Clustering.  \n[BanditPAM](https://github.com/ThrunGroup/BanditPAM) - Improved k-Medoids Clustering.  \n[dendextend](https://github.com/talgalili/dendextend) - Comparing dendrograms (R package).  \n[DeepDPM](https://github.com/BGU-CS-VIL/DeepDPM) - Deep Clustering With An Unknown Number of Clusters.  \n\n##### Clustering Evalutation\n[Wagner, Wagner - Comparing Clusterings - An Overview](https://publikationen.bibliothek.kit.edu/1000011477/812079)\n* [Adjusted Rand Index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html)\n* [Normalized Mutual Information](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html)\n* [Adjusted Mutual Information](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html)\n* [Fowlkes-Mallows Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fowlkes_mallows_score.html)\n* [Silhouette Coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)\n* [Variation of Information](https://gist.github.com/jwcarr/626cbc80e0006b526688), [Julia](https://clusteringjl.readthedocs.io/en/latest/varinfo.html)\n* [Pair Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cluster.pair_confusion_matrix.html)\n* [Consensus Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.consensus_score.html) - The similarity of two sets of biclusters.\n\n[Assessing the quality of a clustering (video)](https://www.youtube.com/watch?v=Mf6MqIS2ql4)   \n[fpc](https://cran.r-project.org/web/packages/fpc/index.html) - Various methods for clustering and cluster validation (R package).  \n* Minimum distance between any two clusters\n* Distance between centroids\n* p-separation index: Like minimum distance. Look at the average distance to nearest point in different cluster for p=10% \"border\" points in any cluster. Measuring density, measuring mountains vs valleys\n* Estimate density by weighted count of close points \n\nOther measures:\n* Within-cluster average distance\n* Mean of within-cluster average distance over nearest-cluster average distance (silhouette score)\n* Within-cluster similarity measure to normal/uniform\n* Within-cluster (squared) distance to centroid (this is the k-Means loss function)\n* Correlation coefficient between distance we originally had to the distance the are induced by the clustering (Huberts Gamma)\n* Entropy of cluster sizes\n* Average largest within-cluster gap\n* Variation of clusterings on bootstrapped data\n\n#### Multi-label classification\n[scikit-multilearn](https://github.com/scikit-multilearn/scikit-multilearn) - Multi-label classification, [talk](https://www.youtube.com/watch?v=m-tAASQA7XQ&t=18m57s).  \n\n#### Signal Processing and Filtering\n[Stanford Lecture Series on Fourier Transformation](https://see.stanford.edu/Course/EE261), [Youtube](https://www.youtube.com/watch?v=gZNm7L96pfY&list=PLB24BC7956EE040CD&index=1), [Lecture Notes](https://see.stanford.edu/materials/lsoftaee261/book-fall-07.pdf).  \n[Visual fourier explanation](https://dsego.github.io/demystifying-fourier/).  \n[The Scientist & Engineer's Guide to Digital Signal Processing (1999)](https://www.analog.com/en/education/education-library/scientist_engineers_guide.html).  \n[Kalman Filter article](https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures).  \n[Kalman Filter book](https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python) - Focuses on intuition using Jupyter Notebooks. Includes Baysian and various Kalman filters.  \n[Interactive Tool](https://fiiir.com/) for FIR and IIR filters, [Examples](https://plot.ly/python/fft-filters/).  \n[filterpy](https://github.com/rlabbe/filterpy) - Kalman filtering and optimal estimation library.  \n\n#### Geometry\n[geomstats](https://github.com/geomstats/geomstats) - Computations and statistics on manifolds with geometric structures.  \n\n#### Time Series\n[statsmodels](https://www.statsmodels.org/dev/tsa.html) - Time series analysis, [seasonal decompose](https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.seasonal_decompose.html) [example](https://gist.github.com/balzer82/5cec6ad7adc1b550e7ee), [SARIMA](https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html), [granger causality](http://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.grangercausalitytests.html).  \n[kats](https://github.com/facebookresearch/kats) - Time series prediction library by Facebook.  \n[prophet](https://github.com/facebook/prophet) - Time series prediction library by Facebook.  \n[neural_prophet](https://github.com/ourownstory/neural_prophet) - Time series prediction built on Pytorch.  \n[pyramid](https://github.com/tgsmith61591/pyramid), [pmdarima](https://github.com/tgsmith61591/pmdarima) - Wrapper for (Auto-) ARIMA.  \n[modeltime](https://cran.r-project.org/web/packages/modeltime/index.html) - Time series forecasting framework (R package).  \n[pyflux](https://github.com/RJT1990/pyflux) - Time series prediction algorithms (ARIMA, GARCH, GAS, Bayesian).  \n[atspy](https://github.com/firmai/atspy) - Automated Time Series Models.  \n[pm-prophet](https://github.com/luke14free/pm-prophet) - Time series prediction and decomposition library.  \n[htsprophet](https://github.com/CollinRooney12/htsprophet) - Hierarchical Time Series Forecasting using Prophet.  \n[nupic](https://github.com/numenta/nupic) - Hierarchical Temporal Memory (HTM) for Time Series Prediction and Anomaly Detection.  \n[tensorflow](https://github.com/tensorflow/tensorflow/) - LSTM and others, examples: [link](\nhttps://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n), [link](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/timeseries), [link](https://github.com/hzy46/TensorFlow-Time-Series-Examples), [Explain LSTM](https://github.com/slundberg/shap/blob/master/notebooks/deep_explainer/Keras%20LSTM%20for%20IMDB%20Sentiment%20Classification.ipynb), seq2seq: [1](https://machinelearningmastery.com/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/), [2](https://github.com/guillaume-chevalier/seq2seq-signal-prediction), [3](https://github.com/JEddy92/TimeSeries_Seq2Seq/blob/master/notebooks/TS_Seq2Seq_Intro.ipynb), [4](https://github.com/LukeTonin/keras-seq-2-seq-signal-prediction)  \n[tspreprocess](https://github.com/MaxBenChrist/tspreprocess) - Preprocessing: Denoising, Compression, Resampling.  \n[tsfresh](https://github.com/blue-yonder/tsfresh) - Time series feature engineering.  \n[tsfel](https://github.com/fraunhoferportugal/tsfel) - Time series feature extraction.  \n[thunder](https://github.com/thunder-project/thunder) - Data structures and algorithms for loading, processing, and analyzing time series data.  \n[gatspy](https://www.astroml.org/gatspy/) - General tools for Astronomical Time Series, [talk](https://www.youtube.com/watch?v=E4NMZyfao2c).  \n[gendis](https://github.com/IBCNServices/GENDIS) - shapelets, [example](https://github.com/IBCNServices/GENDIS/blob/master/gendis/example.ipynb).  \n[tslearn](https://github.com/rtavenar/tslearn) - Time series clustering and classification, `TimeSeriesKMeans`, `TimeSeriesKMeans`.  \n[pastas](https://pastas.readthedocs.io/en/latest/examples.html) - Simulation of time series.  \n[fastdtw](https://github.com/slaypni/fastdtw) - Dynamic Time Warp Distance.  \n[fable](https://www.rdocumentation.org/packages/fable/versions/0.0.0.9000) - Time Series Forecasting (R package).  \n[pydlm](https://github.com/wwrechard/pydlm) - Bayesian time series modeling ([R package](https://cran.r-project.org/web/packages/bsts/index.html), [Blog post](http://www.unofficialgoogledatascience.com/2017/07/fitting-bayesian-structural-time-series.html))  \n[PyAF](https://github.com/antoinecarme/pyaf) - Automatic Time Series Forecasting.  \n[luminol](https://github.com/linkedin/luminol) - Anomaly Detection and Correlation library from Linkedin.  \n[matrixprofile-ts](https://github.com/target/matrixprofile-ts) - Detecting patterns and anomalies, [website](https://www.cs.ucr.edu/~eamonn/MatrixProfile.html), [ppt](https://www.cs.ucr.edu/~eamonn/Matrix_Profile_Tutorial_Part1.pdf), [alternative](https://github.com/matrix-profile-foundation/mass-ts).  \n[stumpy](https://github.com/TDAmeritrade/stumpy) - Another matrix profile library.  \n[obspy](https://github.com/obspy/obspy) - Seismology package. Useful `classic_sta_lta` function.  \n[RobustSTL](https://github.com/LeeDoYup/RobustSTL) - Robust Seasonal-Trend Decomposition.  \n[seglearn](https://github.com/dmbee/seglearn) - Time Series library.  \n[pyts](https://github.com/johannfaouzi/pyts) - Time series transformation and classification, [Imaging time series](https://pyts.readthedocs.io/en/latest/auto_examples/index.html#imaging-time-series).  \nTurn time series into images and use Neural Nets: [example](https://gist.github.com/oguiza/c9c373aec07b96047d1ba484f23b7b47), [example](https://github.com/kiss90/time-series-classification).  \n[sktime](https://github.com/alan-turing-institute/sktime), [sktime-dl](https://github.com/uea-machine-learning/sktime-dl) - Toolbox for (deep) learning with time series.   \n[adtk](https://github.com/arundo/adtk) - Time Series Anomaly Detection.  \n[rocket](https://github.com/angus924/rocket) - Time Series classification using random convolutional kernels.  \n[luminaire](https://github.com/zillow/luminaire) - Anomaly Detection for time series.  \n[etna](https://github.com/tinkoff-ai/etna) - Time Series library.  \n[Chaos Genius](https://github.com/chaos-genius/chaos_genius) - ML powered analytics engine for outlier/anomaly detection and root cause analysis.  \n\n##### Time Series Evaluation\n[TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) - Sklearn time series split.  \n[tscv](https://github.com/WenjieZ/TSCV) - Evaluation with gap.  \n\n#### Financial Data and Trading\nTutorial on using cvxpy: [1](https://calmcode.io/cvxpy-one/the-stigler-diet.html), [2](https://calmcode.io/cvxpy-two/introduction.html)  \n[pandas-datareader](https://pandas-datareader.readthedocs.io/en/latest/whatsnew.html) - Read stock data.  \n[yfinance](https://github.com/ranaroussi/yfinance) - Read stock data from Yahoo Finance.  \n[findatapy](https://github.com/cuemacro/findatapy) - Read stock data from various sources.  \n[ta](https://github.com/bukosabino/ta) - Technical analysis library.  \n[backtrader](https://github.com/mementum/backtrader) - Backtesting for trading strategies.  \n[surpriver](https://github.com/tradytics/surpriver) - Find high moving stocks before they move using anomaly detection and machine learning.  \n[ffn](https://github.com/pmorissette/ffn) - Financial functions.  \n[bt](https://github.com/pmorissette/bt) - Backtesting algorithms.  \n[alpaca-trade-api-python](https://github.com/alpacahq/alpaca-trade-api-python) - Commission-free trading through API.  \n[eiten](https://github.com/tradytics/eiten) - Eigen portfolios, minimum variance portfolios and other algorithmic investing strategies.  \n[tf-quant-finance](https://github.com/google/tf-quant-finance) - Quantitative finance tools in tensorflow, by Google.  \n[quantstats](https://github.com/ranaroussi/quantstats) - Portfolio management.  \n[Riskfolio-Lib](https://github.com/dcajasn/Riskfolio-Lib) - Portfolio optimization and strategic asset allocation.  \n[OpenBBTerminal](https://github.com/OpenBB-finance/OpenBBTerminal) - Terminal.  \n[mplfinance](https://github.com/matplotlib/mplfinance) - Financial markets data visualization.  \n\n##### Quantopian Stack\n[pyfolio](https://github.com/quantopian/pyfolio) - Portfolio and risk analytics.  \n[zipline](https://github.com/quantopian/zipline) - Algorithmic trading.  \n[alphalens](https://github.com/quantopian/alphalens) - Performance analysis of predictive stock factors.  \n[empyrical](https://github.com/quantopian/empyrical) - Financial risk metrics.  \n[trading_calendars](https://github.com/quantopian/trading_calendars) - Calendars for various securities exchanges.  \n\n#### Survival Analysis\n[Time-dependent Cox Model in R](https://stats.stackexchange.com/questions/101353/cox-regression-with-time-varying-covariates).  \n[lifelines](https://lifelines.readthedocs.io/en/latest/) - Survival analysis, Cox PH Regression, [talk](https://www.youtube.com/watch?v=aKZQUaNHYb0), [talk2](https://www.youtube.com/watch?v=fli-yE5grtY).  \n[scikit-survival](https://github.com/sebp/scikit-survival) - Survival analysis.  \n[xgboost](https://github.com/dmlc/xgboost) - `\"objective\": \"survival:cox\"` [NHANES example](https://slundberg.github.io/shap/notebooks/NHANES%20I%20Survival%20Model.html)  \n[survivalstan](https://github.com/hammerlab/survivalstan) - Survival analysis, [intro](http://www.hammerlab.org/2017/06/26/introducing-survivalstan/).  \n[convoys](https://github.com/better/convoys) - Analyze time lagged conversions.  \nRandomSurvivalForests (R packages: randomForestSRC, ggRandomForests).  \n[pysurvival](https://github.com/square/pysurvival) - Survival analysis.  \n[DeepSurvivalMachines](https://github.com/autonlab/DeepSurvivalMachines) - Fully Parametric Survival Regression.  \n[auton-survival](https://github.com/autonlab/auton-survival) - Regression, Counterfactual Estimation, Evaluation and Phenotyping with Censored Time-to-Events.  \n\n#### Outlier Detection & Anomaly Detection\n[sklearn](https://scikit-learn.org/stable/modules/outlier_detection.html) - Isolation Forest and others.  \n[pyod](https://pyod.readthedocs.io/en/latest/pyod.html) - Outlier Detection / Anomaly Detection.  \n[eif](https://github.com/sahandha/eif) - Extended Isolation Forest.  \n[AnomalyDetection](https://github.com/twitter/AnomalyDetection) - Anomaly detection (R package).  \n[luminol](https://github.com/linkedin/luminol) - Anomaly Detection and Correlation library from Linkedin.  \nDistances for comparing histograms and detecting outliers - [Talk](https://www.youtube.com/watch?v=U7xdiGc7IRU): [Kolmogorov-Smirnov](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ks_2samp.html), [Wasserstein](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html), [Energy Distance (Cramer)](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.energy_distance.html), [Kullback-Leibler divergence](https://scipy.github.io/devdocs/generated/scipy.stats.entropy.html).  \n[banpei](https://github.com/tsurubee/banpei) - Anomaly detection library based on singular spectrum transformation.  \n[telemanom](https://github.com/khundman/telemanom) - Detect anomalies in multivariate time series data using LSTMs.  \n[luminaire](https://github.com/zillow/luminaire) - Anomaly Detection for time series.  \n\n#### Concept Drift & Domain Shift\n[TorchDrift](https://github.com/TorchDrift/TorchDrift) - Drift Detection for PyTorch Models.  \n[alibi-detect](https://github.com/SeldonIO/alibi-detect) - Algorithms for outlier, adversarial and drift detection.  \n[evidently](https://github.com/evidentlyai/evidently) - Evaluate and monitor ML models from validation to production.  \n[Lipton et al. - Detecting and Correcting for Label Shift with Black Box Predictors](https://arxiv.org/abs/1802.03916).  \n[Bu et al. - A pdf-Free Change Detection Test Based on Density Difference Estimation](https://ieeexplore.ieee.org/document/7745962).  \n\n#### Ranking\n[lightning](https://github.com/scikit-learn-contrib/lightning) - Large-scale linear classification, regression and ranking.  \n\n#### Scoring\n[SLIM](https://github.com/ustunb/slim-python) - Scoring systems for classification, Supersparse linear integer models.  \n\n#### Causal Inference\n[CS 594 Causal Inference and Learning](https://www.cs.uic.edu/~elena/courses/fall19/cs594cil.html)  \n[Statistical Rethinking](https://github.com/rmcelreath/stat_rethinking_2022) - Video Lecture Series, Bayesian Statistics, Causal Models, [R](https://bookdown.org/content/4857/), [python](https://github.com/pymc-devs/resources/tree/master/Rethinking_2), [numpyro1](https://github.com/asuagar/statrethink-course-numpyro-2019), [numpyro2](https://fehiepsi.github.io/rethinking-numpyro/), [tensorflow-probability](https://github.com/ksachdeva/rethinking-tensorflow-probability).  \n[Python Causality Handbook](https://github.com/matheusfacure/python-causality-handbook)  \n[dowhy](https://github.com/py-why/dowhy) - Estimate causal effects.  \n[CausalImpact](https://github.com/tcassou/causal_impact) - Causal Impact Analysis ([R package](https://google.github.io/CausalImpact/CausalImpact.html)).  \n[causallib](https://github.com/IBM/causallib) - Modular causal inference analysis and model evaluations by IBM, [examples](https://github.com/IBM/causallib/tree/master/examples).  \n[causalml](https://github.com/uber/causalml) - Causal inference by Uber.  \n[upliftml](https://github.com/bookingcom/upliftml) - Causal inference by Booking.com.  \n[EconML](https://github.com/microsoft/EconML) - Heterogeneous Treatment Effects Estimation by Microsoft.  \n[causality](https://github.com/akelleh/causality) - Causal analysis using observational datasets.  \n[DoubleML](https://github.com/DoubleML/doubleml-for-py) - Machine Learning + Causal inference, [Tweet](https://twitter.com/ChristophMolnar/status/1574338002305880068), [Presentation](https://scholar.princeton.edu/sites/default/files/bstewart/files/felton.chern_.slides.20190318.pdf), [Paper](https://arxiv.org/abs/1608.00060v1).  \n\n##### Papers\n[Bours - Confounding](https://edisciplinas.usp.br/pluginfile.php/5625667/mod_resource/content/3/Nontechnicalexplanation-counterfactualdefinition-confounding.pdf)  \n[Bours - Effect Modification and Interaction](https://www.sciencedirect.com/science/article/pii/S0895435621000330)  \n\n#### Probabilistic Modeling and Bayes\n[Intro](https://erikbern.com/2018/10/08/the-hackers-guide-to-uncertainty-estimates.html), [Guide](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)  \n[PyMC3](https://docs.pymc.io/) - Bayesian modelling, [intro](https://docs.pymc.io/notebooks/getting_started)  \n[numpyro](https://github.com/pyro-ppl/numpyro) - Probabilistic programming with numpy, built on [pyro](https://github.com/pyro-ppl/pyro).  \n[pomegranate](https://github.com/jmschrei/pomegranate) - Probabilistic modelling, [talk](https://www.youtube.com/watch?v=dE5j6NW-Kzg).  \n[pmlearn](https://github.com/pymc-learn/pymc-learn) - Probabilistic machine learning.  \n[arviz](https://github.com/arviz-devs/arviz) - Exploratory analysis of Bayesian models.  \n[zhusuan](https://github.com/thu-ml/zhusuan) - Bayesian deep learning, generative models.  \n[edward](https://github.com/blei-lab/edward) - Probabilistic modeling, inference, and criticism, [Mixture Density Networks (MNDs)](http://edwardlib.org/tutorials/mixture-density-network), [MDN Explanation](https://towardsdatascience.com/a-hitchhikers-guide-to-mixture-density-networks-76b435826cca).  \n[Pyro](https://github.com/pyro-ppl/pyro) - Deep Universal Probabilistic Programming.  \n[tensorflow probability](https://github.com/tensorflow/probability) - Deep learning and probabilistic modelling, [talk1](https://www.youtube.com/watch?v=KJxmC5GCWe4), [notebook talk1](https://github.com/AlxndrMlk/PyDataGlobal2021/blob/main/00_PyData_Global_2021_nb_full.ipynb), [talk2](https://www.youtube.com/watch?v=BrwKURU-wpk), [example](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Ch1_Introduction_TFP.ipynb).  \n[bambi](https://github.com/bambinos/bambi) - High-level Bayesian model-building interface on top of PyMC3.  \n[neural-tangents](https://github.com/google/neural-tangents) - Infinite Neural Networks.  \n[bnlearn](https://github.com/erdogant/bnlearn) - Bayesian networks, parameter learning, inference and sampling methods.  \n\n#### Gaussian Processes\n[Visualization](http://www.infinitecuriosity.org/vizgp/), [Article](https://distill.pub/2019/visual-exploration-gaussian-processes/)  \n[GPyOpt](https://github.com/SheffieldML/GPyOpt) - Gaussian process optimization.   \n[GPflow](https://github.com/GPflow/GPflow) - Gaussian processes (Tensorflow).  \n[gpytorch](https://gpytorch.ai/) - Gaussian processes (Pytorch).  \n\n#### Stacking Models and Ensembles\n[Model Stacking Blog Post](http://blog.kaggle.com/2017/06/15/stacking-made-easy-an-introduction-to-stacknet-by-competitions-grandmaster-marios-michailidis-kazanova/)  \n[mlxtend](https://github.com/rasbt/mlxtend) - `EnsembleVoteClassifier`, `StackingRegressor`, `StackingCVRegressor` for model stacking.  \n[vecstack](https://github.com/vecxoz/vecstack) - Stacking ML models.  \n[StackNet](https://github.com/kaz-Anova/StackNet) - Stacking ML models.  \n[mlens](https://github.com/flennerhag/mlens) - Ensemble learning.  \n[combo](https://github.com/yzhao062/combo) - Combining ML models (stacking, ensembling).  \n\n#### Model Evaluation\n[pycm](https://github.com/sepandhaghighi/pycm) - Multi-class confusion matrix.  \n[pandas_ml](https://github.com/pandas-ml/pandas-ml) - Confusion matrix.  \nPlotting learning curve: [link](http://www.ritchieng.com/machinelearning-learning-curve/).  \n[yellowbrick](http://www.scikit-yb.org/en/latest/api/model_selection/learning_curve.html) - Learning curve.  \n[pyroc](https://github.com/noudald/pyroc) - Receiver Operating Characteristic (ROC) curves.  \n\n#### Model Uncertainty\n[awesome-conformal-prediction](https://github.com/valeman/awesome-conformal-prediction) - Uncertainty quantification.  \n[uncertainty-toolbox](https://github.com/uncertainty-toolbox/uncertainty-toolbox) - Predictive uncertainty quantification, calibration, metrics, and visualization.  \n\n#### Interpretable Classifiers and Regressors\n[skope-rules](https://github.com/scikit-learn-contrib/skope-rules) - Interpretable classifier, IF-THEN rules.  \n[sklearn-expertsys](https://github.com/tmadl/sklearn-expertsys) - Interpretable classifiers, Bayesian Rule List classifier.  \n\n#### Model Explanation, Interpretability, Feature Importance\n[Princeton - Reproducibility Crisis in ML\u2011based Science](https://sites.google.com/princeton.edu/rep-workshop)   \n[Book](https://christophm.github.io/interpretable-ml-book/agnostic.html), [Examples](https://github.com/jphall663/interpretable_machine_learning_with_python)  \n[shap](https://github.com/slundberg/shap) - Explain predictions of machine learning models, [talk](https://www.youtube.com/watch?v=C80SQe16Rao), [Good Shap intro](https://www.aidancooper.co.uk/a-non-technical-guide-to-interpreting-shap-analyses/).  \n[treeinterpreter](https://github.com/andosa/treeinterpreter) - Interpreting scikit-learn's decision tree and random forest predictions.  \n[lime](https://github.com/marcotcr/lime) - Explaining the predictions of any machine learning classifier, [talk](https://www.youtube.com/watch?v=C80SQe16Rao), [Warning (Myth 7)](https://crazyoscarchang.github.io/2019/02/16/seven-myths-in-machine-learning-research/).  \n[lime_xgboost](https://github.com/jphall663/lime_xgboost) - Create LIMEs for XGBoost.  \n[eli5](https://github.com/TeamHG-Memex/eli5) - Inspecting machine learning classifiers and explaining their predictions.  \n[lofo-importance](https://github.com/aerdem4/lofo-importance) - Leave One Feature Out Importance, [talk](https://www.youtube.com/watch?v=zqsQ2ojj7sE), examples: [1](https://www.kaggle.com/divrikwicky/pf-f-lofo-importance-on-adversarial-validation), [2](https://www.kaggle.com/divrikwicky/lofo-importance), [3](https://www.kaggle.com/divrikwicky/santanderctp-lofo-feature-importance).  \n[pybreakdown](https://github.com/MI2DataLab/pyBreakDown) - Generate feature contribution plots.  \n[pycebox](https://github.com/AustinRochford/PyCEbox) - Individual Conditional Expectation Plot Toolbox.  \n[pdpbox](https://github.com/SauceCat/PDPbox) - Partial dependence plot toolbox, [example](https://www.kaggle.com/dansbecker/partial-plots).  \n[partial_dependence](https://github.com/nyuvis/partial_dependence) - Visualize and cluster partial dependence.  \n[skater](https://github.com/datascienceinc/Skater) - Unified framework to enable model interpretation.  \n[anchor](https://github.com/marcotcr/anchor) - High-Precision Model-Agnostic Explanations for classifiers.  \n[l2x](https://github.com/Jianbo-Lab/L2X) - Instancewise feature selection as methodology for model interpretation.  \n[contrastive_explanation](https://github.com/MarcelRobeer/ContrastiveExplanation) - Contrastive explanations.  \n[DrWhy](https://github.com/ModelOriented/DrWhy) - Collection of tools for explainable AI.  \n[lucid](https://github.com/tensorflow/lucid) - Neural network interpretability.  \n[xai](https://github.com/EthicalML/XAI) - An eXplainability toolbox for machine learning.  \n[innvestigate](https://github.com/albermax/innvestigate) - A toolbox to investigate neural network predictions.  \n[dalex](https://github.com/pbiecek/DALEX) - Explanations for ML models (R package).  \n[interpretml](https://github.com/interpretml/interpret) - Fit interpretable models, explain models.  \n[shapash](https://github.com/MAIF/shapash) - Model interpretability.  \n[imodels](https://github.com/csinva/imodels) - Interpretable ML package.  \n[captum](https://github.com/pytorch/captum) - Model interpretability and understanding for PyTorch.  \n\n#### Automated Machine Learning\n[AdaNet](https://github.com/tensorflow/adanet) - Automated machine learning based on tensorflow.  \n[tpot](https://github.com/EpistasisLab/tpot) - Automated machine learning tool, optimizes machine learning pipelines.  \n[auto_ml](https://github.com/ClimbsRocks/auto_ml) - Automated machine learning for analytics & production.  \n[autokeras](https://github.com/jhfjhfj1/autokeras) - AutoML for deep learning.  \n[nni](https://github.com/Microsoft/nni) - Toolkit for neural architecture search and hyper-parameter tuning by Microsoft.  \n[automl-gs](https://github.com/minimaxir/automl-gs) - Automated machine learning.  \n[mljar](https://github.com/mljar/mljar-supervised) - Automated machine learning.  \n[automl_zero](https://github.com/google-research/google-research/tree/master/automl_zero) - Automatically discover computer programs that can solve machine learning tasks from Google.  \n[AlphaPy](https://github.com/ScottfreeLLC/AlphaPy) - Automated Machine Learning using scikit-learn xgboost, LightGBM and others.  \n\n#### Graph Representation Learning\n[Karate Club](https://github.com/benedekrozemberczki/karateclub) - Unsupervised learning on graphs.   \n[Pytorch Geometric](https://github.com/rusty1s/pytorch_geometric) - Graph representation learning with PyTorch.   \n[DLG](https://github.com/dmlc/dgl) - Graph representation learning with TensorFlow.   \n\n#### Convex optimization\n[cvxpy](https://github.com/cvxgrp/cvxpy) - Modeling language for convex optimization problems. Tutorial: [1](https://calmcode.io/cvxpy-one/the-stigler-diet.html), [2](https://calmcode.io/cvxpy-two/introduction.html)  \n\n#### Evolutionary Algorithms & Optimization\n[deap](https://github.com/DEAP/deap) - Evolutionary computation framework (Genetic Algorithm, Evolution strategies).  \n[evol](https://github.com/godatadriven/evol) - DSL for composable evolutionary algorithms, [talk](https://www.youtube.com/watch?v=68ABAU_V8qI&t=11m49s).  \n[platypus](https://github.com/Project-Platypus/Platypus) - Multiobjective optimization.  \n[autograd](https://github.com/HIPS/autograd) - Efficiently computes derivatives of numpy code.  \n[nevergrad](https://github.com/facebookresearch/nevergrad) - Derivation-free optimization.  \n[gplearn](https://gplearn.readthedocs.io/en/stable/) - Sklearn-like interface for genetic programming.  \n[blackbox](https://github.com/paulknysh/blackbox) - Optimization of expensive black-box functions.  \nOptometrist algorithm - [paper](https://www.nature.com/articles/s41598-017-06645-7).  \n[DeepSwarm](https://github.com/Pattio/DeepSwarm) - Neural architecture search.  \n[evotorch](https://github.com/nnaisense/evotorch) - Evolutionary computation library built on Pytorch.  \n\n#### Hyperparameter Tuning\n[sklearn](https://scikit-learn.org/stable/index.html) - [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).  \n[sklearn-deap](https://github.com/rsteca/sklearn-deap) - Hyperparameter search using genetic algorithms.  \n[hyperopt](https://github.com/hyperopt/hyperopt) - Hyperparameter optimization.  \n[hyperopt-sklearn](https://github.com/hyperopt/hyperopt-sklearn) - Hyperopt + sklearn.  \n[optuna](https://github.com/pfnet/optuna) - Hyperparamter optimization, [Talk](https://www.youtube.com/watch?v=tcrcLRopTX0).  \n[skopt](https://scikit-optimize.github.io/) - `BayesSearchCV` for Hyperparameter search.  \n[tune](https://ray.readthedocs.io/en/latest/tune.html) - Hyperparameter search with a focus on deep learning and deep reinforcement learning.  \n[hypergraph](https://github.com/aljabr0/hypergraph) - Global optimization methods and hyperparameter optimization.  \n[bbopt](https://github.com/evhub/bbopt) - Black box hyperparameter optimization.  \n[dragonfly](https://github.com/dragonfly/dragonfly) - Scalable Bayesian optimisation.  \n[botorch](https://github.com/pytorch/botorch) - Bayesian optimization in PyTorch.  \n[ax](https://github.com/facebook/Ax) - Adaptive Experimentation Platform by Facebook.  \n[lightning-hpo](https://github.com/Lightning-AI/lightning-hpo) - Hyperparameter optimization based on optuna.  \n\n#### Incremental Learning, Online Learning\nsklearn - [PassiveAggressiveClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html), [PassiveAggressiveRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveRegressor.html).  \n[river](https://github.com/online-ml/river) - Online machine learning.  \n[Kaggler](https://github.com/jeongyoonlee/Kaggler) - Online Learning algorithms.  \n[onelearn](https://github.com/onelearn/onelearn) - Online Random Forests.  \n\n#### Active Learning\n[Talk](https://www.youtube.com/watch?v=0efyjq5rWS4)  \n[modAL](https://github.com/modAL-python/modAL) - Active learning framework.  \n\n#### Reinforcement Learning\n[YouTube](https://www.youtube.com/playlist?list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT), [YouTube](https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs)  \nIntro to Monte Carlo Tree Search (MCTS) - [1](https://jeffbradberry.com/posts/2015/09/intro-to-monte-carlo-tree-search/), [2](http://mcts.ai/about/index.html), [3](https://medium.com/@quasimik/monte-carlo-tree-search-applied-to-letterpress-34f41c86e238)  \nAlphaZero methodology - [1](https://github.com/AppliedDataSciencePartners/DeepReinforcementLearning), [2](https://web.stanford.edu/~surag/posts/alphazero.html), [3](https://github.com/suragnair/alpha-zero-general), [Cheat Sheet](https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0)  \n[RLLib](https://ray.readthedocs.io/en/latest/rllib.html) - Library for reinforcement learning.  \n[Horizon](https://github.com/facebookresearch/Horizon/) - Facebook RL framework.  \n\n#### Deployment and Lifecycle Management\n\n##### Workflow Scheduling and Orchestration\n[airflow](https://github.com/apache/airflow) - Schedule and monitor workflows.  \n[prefect](https://github.com/PrefectHQ/prefect) - Python specific workflow scheduling.  \n[dagster](https://github.com/dagster-io/dagster) - Development, production and observation of data assets.  \n[ploomber](https://github.com/ploomber/ploomber) - Workflow orchestration.  \n[kestra](https://github.com/kestra-io/kestra) - Workflow orchestration.  \n[cml](https://github.com/iterative/cml) - CI/CD for Machine Learning Projects.  \n[rocketry](https://github.com/Miksus/rocketry) - Task scheduling.  \n\n##### Containerization and Docker\n[Reduce size of docker images (video)](https://www.youtube.com/watch?v=Z1Al4I4Os_A)  \n[Optimize Docker Image Size](https://www.augmentedmind.de/2022/02/06/optimize-docker-image-size/)  \n[cog](https://github.com/replicate/cog) - Facilitates building Docker images.  \n\n##### Dependency Management\n[dephell](https://github.com/dephell/dephell) - Dependency management.  \n[poetry](https://github.com/python-poetry/poetry) - Dependency management.  \n[pyup](https://github.com/pyupio/pyup) - Dependency management.  \n[pypi-timemachine](https://github.com/astrofrog/pypi-timemachine) - Install packages with pip as if you were in the past.  \n\n##### Data Versioning, Databases, Pipelines and Model Serving\n[dvc](https://github.com/iterative/dvc) - Version control for large files.  \n[hangar](https://github.com/tensorwerk/hangar-py) - Version control for tensor data.  \n[kedro](https://github.com/quantumblacklabs/kedro) - Build data pipelines.  \n[feast](https://github.com/feast-dev/feast) - Feature store. [Video](https://www.youtube.com/watch?v=_omcXenypmo).  \n[pinecone](https://www.pinecone.io/) - Database for vector search applications.  \n[truss](https://github.com/basetenlabs/truss) - Serve ML models.  \n[milvus](https://github.com/milvus-io/milvus) - Vector database for similarity search.  \n[mlem](https://github.com/iterative/mlem) - Version and deploy your ML models following GitOps principles.  \n\n##### Data Science Related\n[m2cgen](https://github.com/BayesWitnesses/m2cgen) - Transpile trained ML models into other languages.  \n[sklearn-porter](https://github.com/nok/sklearn-porter) - Transpile trained scikit-learn estimators to C, Java, JavaScript and others.  \n[mlflow](https://mlflow.org/) - Manage the machine learning lifecycle, including experimentation, reproducibility and deployment.  \n[modelchimp](https://github.com/ModelChimp/modelchimp) - Experiment Tracking.  \n[skll](https://github.com/EducationalTestingService/skll) - Command-line utilities to make it easier to run machine learning experiments.  \n[BentoML](https://github.com/bentoml/BentoML) - Package and deploy machine learning models for serving in production.  \n[dagster](https://github.com/dagster-io/dagster) - Tool with focus on dependency graphs.  \n[knockknock](https://github.com/huggingface/knockknock) - Be notified when your training ends.  \n[metaflow](https://github.com/Netflix/metaflow) - Lifecycle Management Tool by Netflix.  \n[cortex](https://github.com/cortexlabs/cortex) - Deploy machine learning models.  \n[Neptune](https://neptune.ai) - Experiment tracking and model registry.  \n[clearml](https://github.com/allegroai/clearml) - Experiment Manager, MLOps and Data-Management.  \n[polyaxon](https://github.com/polyaxon/polyaxon) - MLOps.  \n[sematic](https://github.com/sematic-ai/sematic) - Deploy machine learning models.  \n[zenml](https://github.com/zenml-io/zenml) - MLOPs.  \n\n#### Math and Background\n[All kinds of math and statistics resources](https://realnotcomplex.com/)  \nGilbert Strang - [Linear Algebra](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/index.htm)  \nGilbert Strang - [Matrix Methods in Data Analysis, Signal Processing, and Machine Learning\n](https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/)  \n\n#### Other\n[daft](https://github.com/dfm/daft) - Render probabilistic graphical models using matplotlib.  \n[unyt](https://github.com/yt-project/unyt) - Working with units.  \n[scrapy](https://github.com/scrapy/scrapy) - Web scraping library.  \n[VowpalWabbit](https://github.com/VowpalWabbit/vowpal_wabbit) - ML Toolkit from Microsoft.  \n[Python Record Linkage Toolkit](https://github.com/J535D165/recordlinkage) - link records in or between data sources. \n\n#### General Python Programming\n[more_itertools](https://more-itertools.readthedocs.io/en/latest/) - Extension of itertools.  \n[funcy](https://github.com/Suor/funcy) - Fancy and practical functional tools.  \n[dateparser](https://dateparser.readthedocs.io/en/latest/) - A better date parser.  \n[jellyfish](https://github.com/jamesturk/jellyfish) - Approximate string matching.   \n[coloredlogs](https://github.com/xolox/python-coloredlogs) - Colored logging output.    \n\n#### Resources\n[Distill.pub](https://distill.pub/) - Blog.   \n[Machine Learning Videos](https://github.com/dustinvtran/ml-videos)  \n[Data Science Notebooks](https://github.com/donnemartin/data-science-ipython-notebooks)  \n[Recommender Systems (Microsoft)](https://github.com/Microsoft/Recommenders)  \n[Datascience Cheatsheets](https://github.com/FavioVazquez/ds-cheatsheets)   \n\n##### Guidelines \n[datasharing](https://github.com/jtleek/datasharing) - Guide to data sharing.  \n\n##### Books\n[Chan - Introduction to Probability for Data Science](https://probability4datascience.com/index.html)  \n[Colonescu - Principles of Econometrics with R](https://bookdown.org/ccolonescu/RPoE4/)  \n\n##### Other Awesome Lists\n[Awesome Adversarial Machine Learning](https://github.com/yenchenlin/awesome-adversarial-machine-learning)    \n[Awesome AI Booksmarks](https://github.com/goodrahstar/my-awesome-AI-bookmarks)    \n[Awesome AI on Kubernetes](https://github.com/CognonicLabs/awesome-AI-kubernetes)    \n[Awesome Big Data](https://github.com/onurakpolat/awesome-bigdata)    \n[Awesome Business Machine Learning](https://github.com/firmai/business-machine-learning)    \n[Awesome Causality](https://github.com/rguo12/awesome-causality-algorithms)    \n[Awesome Community Detection](https://github.com/benedekrozemberczki/awesome-community-detection)    \n[Awesome CSV](https://github.com/secretGeek/AwesomeCSV)  \n[Awesome Cytodata](https://github.com/cytodata/awesome-cytodata)  \n[Awesome Data Science with Ruby](https://github.com/arbox/data-science-with-ruby)   \n[Awesome Dash](https://github.com/ucg8j/awesome-dash)   \n[Awesome Decision Trees](https://github.com/benedekrozemberczki/awesome-decision-tree-papers)    \n[Awesome Deep Learning](https://github.com/ChristosChristofidis/awesome-deep-learning)   \n[Awesome ETL](https://github.com/pawl/awesome-etl)   \n[Awesome Financial Machine Learning](https://github.com/firmai/financial-machine-learning)   \n[Awesome Fraud Detection](https://github.com/benedekrozemberczki/awesome-fraud-detection-papers)   \n[Awesome GAN Applications](https://github.com/nashory/gans-awesome-applications)   \n[Awesome Graph Classification](https://github.com/benedekrozemberczki/awesome-graph-classification)   \n[Awesome Industry Machine Learning](https://github.com/firmai/industry-machine-learning)  \n[Awesome Gradient Boosting](https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers)   \n[Awesome Learning with Label Noise](https://github.com/subeeshvasu/Awesome-Learning-with-Label-Noise)  \n[Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning#python)    \n[Awesome Machine Learning Books](http://matpalm.com/blog/cool_machine_learning_books/)  \n[Awesome Machine Learning Interpretability](https://github.com/jphall663/awesome-machine-learning-interpretability)     \n[Awesome Machine Learning Operations](https://github.com/EthicalML/awesome-machine-learning-operations)   \n[Awesome Metric Learning](https://github.com/kdhht2334/Survey_of_Deep_Metric_Learning)  \n[Awesome Monte Carlo Tree Search](https://github.com/benedekrozemberczki/awesome-monte-carlo-tree-search-papers)   \n[Awesome Neural Network Visualization](https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network)  \n[Awesome Online Machine Learning](https://github.com/MaxHalford/awesome-online-machine-learning)  \n[Awesome Pipeline](https://github.com/pditommaso/awesome-pipeline)  \n[Awesome Public APIs](https://github.com/public-apis/public-apis)  \n[Awesome Python](https://github.com/vinta/awesome-python)   \n[Awesome Python Data Science](https://github.com/krzjoa/awesome-python-datascience)   \n[Awesome Python Data Science](https://github.com/thomasjpfan/awesome-python-data-science)  \n[Awesome Python Data Science](https://github.com/amitness/toolbox)  \n[Awesome Pytorch](https://github.com/bharathgs/Awesome-pytorch-list)  \n[Awesome Quantitative Finance](https://github.com/wilsonfreitas/awesome-quant)  \n[Awesome Recommender Systems](https://github.com/grahamjenson/list_of_recommender_systems)  \n[Awesome Semantic Segmentation](https://github.com/mrgloom/awesome-semantic-segmentation)  \n[Awesome Sentence Embedding](https://github.com/Separius/awesome-sentence-embedding)  \n[Awesome Time Series](https://github.com/MaxBenChrist/awesome_time_series_in_python)  \n[Awesome Time Series Anomaly Detection](https://github.com/rob-med/awesome-TS-anomaly-detection)  \n[Awesome Visual Attentions](https://github.com/MenghaoGuo/Awesome-Vision-Attentions)  \n[Awesome Visual Transformer](https://github.com/dk-liang/Awesome-Visual-Transformer)  \n\n#### Lectures\n[NYU Deep Learning SP21](https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI) - Youtube Playlist.   \n\n#### Things I google a lot\n[Color codes](https://github.com/d3/d3-3.x-api-reference/blob/master/Ordinal-Scales.md#categorical-colors)  \n[Frequency codes for time series](https://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases)  \n[Date parsing codes](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior)  \n[Feature Calculators tsfresh](https://github.com/blue-yonder/tsfresh/blob/master/tsfresh/feature_extraction/feature_calculators.py)  \n\n## Contributing  \nDo you know a package that should be on this list? Did you spot a package that is no longer maintained and should be removed from this list? Then feel free to read the [contribution guidelines](CONTRIBUTING.md) and submit your pull request or create a new issue.  \n\n## License\n[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)\n",
	"apriori classification clustering data-mining feature-engineering flink flink-machine-learning flink-ml fm graph-algorithms graph-embedding kafka machine-learning recommender recommender-system regression statistics word2vec xgboost": "<font size=7>[English](README.en-US.md)| \u7b80\u4f53\u4e2d\u6587</font>\n\n# Alink\n\n Alink\u662f\u57fa\u4e8eFlink\u7684\u901a\u7528\u7b97\u6cd5\u5e73\u53f0,\u7531\u963f\u91cc\u5df4\u5df4\u8ba1\u7b97\u5e73\u53f0PAI\u56e2\u961f\u7814\u53d1,\u6b22\u8fce\u5927\u5bb6\u52a0\u5165Alink\u5f00\u6e90\u7528\u6237\u9489\u9489\u7fa4\u8fdb\u884c\u4ea4\u6d41\u3002\n \n \n<div align=center>\n<img src=\"https://img.alicdn.com/tfs/TB1kQU0sQY2gK0jSZFgXXc5OFXa-614-554.png\" height=\"25%\" width=\"25%\">\n</div>\n\n- Alink\u7ec4\u4ef6\u5217\u8868\uff1ahttp://alinklab.cn/manual/index.html\n- Alink\u6559\u7a0b\uff1ahttp://alinklab.cn/tutorial/index.html\n- Alink\u63d2\u4ef6\u4e0b\u8f7d\u5668\uff1ahttps://www.yuque.com/pinshu/alink_guide/plugin_downloader\n\n#### Alink\u6559\u7a0b\n<div align=center>\n<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01Z7sbCr1Hg22gLIsdk_!!6000000000786-0-tps-1280-781.jpg\" height=\"50%\" width=\"50%\">\n</div>\n\n- Alink\u6559\u7a0b\uff08Java\u7248\uff09\uff1ahttp://alinklab.cn/tutorial/book_java.html\n- Alink\u6559\u7a0b\uff08Python\u7248\uff09\uff1ahttp://alinklab.cn/tutorial/book_python.html\n- \u6e90\u4ee3\u7801\u5730\u5740\uff1ahttps://github.com/alibaba/Alink/tree/master/tutorial\n- Java\u7248\u7684\u6570\u636e\u548c\u8d44\u6599\u94fe\u63a5\uff1ahttp://alinklab.cn/tutorial/book_java_00_reference.html\n- Python\u7248\u7684\u6570\u636e\u548c\u8d44\u6599\u94fe\u63a5\uff1ahttp://alinklab.cn/tutorial/book_python_00_reference.html\n- Alink\u6559\u7a0b(Java\u7248)\u4ee3\u7801\u7684\u8fd0\u884c\u653b\u7565  http://alinklab.cn/tutorial/book_java_00_code_help.html\n- Alink\u6559\u7a0b(Python\u7248)\u4ee3\u7801\u7684\u8fd0\u884c\u653b\u7565  http://alinklab.cn/tutorial/book_python_00_code_help.html\n\n#### \u5f00\u6e90\u7b97\u6cd5\u5217\u8868\n\n<div align=center>\n<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01RKHbLE202moQzvYjW_!!6000000006792-2-tps-1876-955.png\" height=\"100%\" width=\"100%\">\n</div>\n\n#### PyAlink \u4f7f\u7528\u622a\u56fe\n\n<div align=center>\n<img src=\"https://img.alicdn.com/tfs/TB1TmKloAL0gK0jSZFxXXXWHVXa-2070-1380.png\" height=\"60%\" width=\"60%\">\n</div>\n\n# \u5feb\u901f\u5f00\u59cb\n\n## PyAlink \u4f7f\u7528\u4ecb\u7ecd\n\n### \u4f7f\u7528\u524d\u51c6\u5907\uff1a\n---------\n\n#### \u5305\u540d\u548c\u7248\u672c\u8bf4\u660e\uff1a\n\n  - PyAlink \u6839\u636e Alink \u6240\u652f\u6301\u7684 Flink \u7248\u672c\u63d0\u4f9b\u4e0d\u540c\u7684 Python \u5305\uff1a\n\u5176\u4e2d\uff0c`pyalink` \u5305\u5bf9\u5e94\u4e3a Alink \u6240\u652f\u6301\u7684\u6700\u65b0 Flink \u7248\u672c\uff0c\u5f53\u524d\u4e3a 1.13\uff0c\u800c `pyalink-flink-***` \u4e3a\u65e7\u7248\u672c\u7684 Flink \u7248\u672c\uff0c\u5f53\u524d\u63d0\u4f9b `pyalink-flink-1.12`, `pyalink-flink-1.11`, `pyalink-flink-1.10` \u548c `pyalink-flink-1.9`\u3002\n  - Python \u5305\u7684\u7248\u672c\u53f7\u4e0e Alink \u7684\u7248\u672c\u53f7\u4e00\u81f4\uff0c\u4f8b\u5982`1.6.0`\u3002\n\n####\u5b89\u88c5\u6b65\u9aa4\uff1a\n1. \u786e\u4fdd\u4f7f\u7528\u73af\u5883\u4e2d\u6709Python3\uff0c\u7248\u672c\u9650\u4e8e 3.6\uff0c3.7 \u548c 3.8\u3002\n2. \u786e\u4fdd\u4f7f\u7528\u73af\u5883\u4e2d\u5b89\u88c5\u6709 Java 8\u3002\n3. \u4f7f\u7528 pip \u547d\u4ee4\u8fdb\u884c\u5b89\u88c5\uff1a\n  `pip install pyalink`\u3001`pip install pyalink-flink-1.12`\u3001`pip install pyalink-flink-1.11`\u3001`pip install pyalink-flink-1.10` \u6216\u8005 `pip install pyalink-flink-1.9`\u3002\n  \n#### \u5b89\u88c5\u6ce8\u610f\u4e8b\u9879\uff1a\n\n1. `pyalink` \u548c `pyalink-flink-***` \u4e0d\u80fd\u540c\u65f6\u5b89\u88c5\uff0c\u4e5f\u4e0d\u80fd\u4e0e\u65e7\u7248\u672c\u540c\u65f6\u5b89\u88c5\u3002\n\u5982\u679c\u4e4b\u524d\u5b89\u88c5\u8fc7 `pyalink` \u6216\u8005 `pyalink-flink-***`\uff0c\u8bf7\u4f7f\u7528`pip uninstall pyalink` \u6216\u8005 `pip uninstall pyalink-flink-***` \u5378\u8f7d\u4e4b\u524d\u7684\u7248\u672c\u3002\n2. \u51fa\u73b0`pip`\u5b89\u88c5\u7f13\u6162\u6216\u4e0d\u6210\u529f\u7684\u60c5\u51b5\uff0c\u53ef\u4ee5\u53c2\u8003[\u8fd9\u7bc7\u6587\u7ae0](https://segmentfault.com/a/1190000006111096)\u4fee\u6539pip\u6e90\uff0c\u6216\u8005\u76f4\u63a5\u4f7f\u7528\u4e0b\u9762\u7684\u94fe\u63a5\u4e0b\u8f7d whl \u5305\uff0c\u7136\u540e\u4f7f\u7528 `pip` \u5b89\u88c5\uff1a\n   - Flink 1.13\uff1a[\u94fe\u63a5](https://alink-release.oss-cn-beijing.aliyuncs.com/v1.6.0/pyalink-1.6.0-py3-none-any.whl) (MD5: ed775a565071b181bbc708dd775a665b)\n   - Flink 1.12\uff1a[\u94fe\u63a5](https://alink-release.oss-cn-beijing.aliyuncs.com/v1.6.0/pyalink_flink_1.12-1.6.0-py3-none-any.whl) (MD5: 95a98d056cfdb68245cfe4ee982112d1)\n   - Flink 1.11\uff1a[\u94fe\u63a5](https://alink-release.oss-cn-beijing.aliyuncs.com/v1.6.0/pyalink_flink_1.11-1.6.0-py3-none-any.whl) (MD5: 8d88d16b01bc58bc932d46c607123670)\n   - Flink 1.10\uff1a[\u94fe\u63a5](https://alink-release.oss-cn-beijing.aliyuncs.com/v1.6.0/pyalink_flink_1.10-1.6.0-py3-none-any.whl) (MD5: 7b8477fe7cfb38e9e06b8b5e7c3eca4d)\n   - Flink 1.9: [\u94fe\u63a5](https://alink-release.oss-cn-beijing.aliyuncs.com/v1.6.0/pyalink_flink_1.9-1.6.0-py3-none-any.whl) (MD5: 404f0c6f7ea061ca8ad5de5278f0fa8b)\n3. \u5982\u679c\u6709\u591a\u4e2a\u7248\u672c\u7684 Python\uff0c\u53ef\u80fd\u9700\u8981\u4f7f\u7528\u7279\u5b9a\u7248\u672c\u7684 `pip`\uff0c\u6bd4\u5982 `pip3`\uff1b\u5982\u679c\u4f7f\u7528 Anaconda\uff0c\u5219\u9700\u8981\u5728 Anaconda \u547d\u4ee4\u884c\u4e2d\u8fdb\u884c\u5b89\u88c5\u3002\n\n### \u5f00\u59cb\u4f7f\u7528\uff1a\n-------\n\u53ef\u4ee5\u901a\u8fc7 Jupyter Notebook \u6765\u5f00\u59cb\u4f7f\u7528 PyAlink\uff0c\u80fd\u83b7\u5f97\u66f4\u597d\u7684\u4f7f\u7528\u4f53\u9a8c\u3002\n\n\u4f7f\u7528\u6b65\u9aa4\uff1a\n1. \u5728\u547d\u4ee4\u884c\u4e2d\u542f\u52a8Jupyter\uff1a`jupyter notebook`\uff0c\u5e76\u65b0\u5efa Python 3 \u7684 Notebook \u3002\n2. \u5bfc\u5165 pyalink \u5305\uff1a`from pyalink.alink import *`\u3002\n3. \u4f7f\u7528\u65b9\u6cd5\u521b\u5efa\u672c\u5730\u8fd0\u884c\u73af\u5883\uff1a\n`useLocalEnv(parallism, flinkHome=None, config=None)`\u3002\n\u5176\u4e2d\uff0c\u53c2\u6570 `parallism` \u8868\u793a\u6267\u884c\u6240\u4f7f\u7528\u7684\u5e76\u884c\u5ea6\uff1b`flinkHome` \u4e3a flink \u7684\u5b8c\u6574\u8def\u5f84\uff0c\u4e00\u822c\u60c5\u51b5\u4e0d\u9700\u8981\u8bbe\u7f6e\uff1b`config`\u4e3aFlink\u6240\u63a5\u53d7\u7684\u914d\u7f6e\u53c2\u6570\u3002\u8fd0\u884c\u540e\u51fa\u73b0\u5982\u4e0b\u6240\u793a\u7684\u8f93\u51fa\uff0c\u8868\u793a\u521d\u59cb\u5316\u8fd0\u884c\u73af\u5883\u6210\u529f\uff1a\n```\nJVM listening on ***\n```\n4. \u5f00\u59cb\u7f16\u5199 PyAlink \u4ee3\u7801\uff0c\u4f8b\u5982\uff1a\n```python\nsource = CsvSourceBatchOp()\\\n    .setSchemaStr(\"sepal_length double, sepal_width double, petal_length double, petal_width double, category string\")\\\n    .setFilePath(\"https://alink-release.oss-cn-beijing.aliyuncs.com/data-files/iris.csv\")\nres = source.select([\"sepal_length\", \"sepal_width\"])\ndf = res.collectToDataframe()\nprint(df)\n```\n\n### \u7f16\u5199\u4ee3\u7801\uff1a\n------\n\u5728 PyAlink \u4e2d\uff0c\u7b97\u6cd5\u7ec4\u4ef6\u63d0\u4f9b\u7684\u63a5\u53e3\u57fa\u672c\u4e0e Java API \u4e00\u81f4\uff0c\u5373\u901a\u8fc7\u9ed8\u8ba4\u6784\u9020\u65b9\u6cd5\u521b\u5efa\u4e00\u4e2a\u7b97\u6cd5\u7ec4\u4ef6\uff0c\u7136\u540e\u901a\u8fc7 `setXXX` \u8bbe\u7f6e\u53c2\u6570\uff0c\u901a\u8fc7 `link/linkTo/linkFrom` \u4e0e\u5176\u4ed6\u7ec4\u4ef6\u76f8\u8fde\u3002\n\u8fd9\u91cc\u5229\u7528 Jupyter Notebook \u7684\u81ea\u52a8\u8865\u5168\u673a\u5236\u53ef\u4ee5\u63d0\u4f9b\u4e66\u5199\u4fbf\u5229\u3002\n\n\u5bf9\u4e8e\u6279\u5f0f\u4f5c\u4e1a\uff0c\u53ef\u4ee5\u901a\u8fc7\u6279\u5f0f\u7ec4\u4ef6\u7684 `print/collectToDataframe/collectToDataframes` \u7b49\u65b9\u6cd5\u6216\u8005 `BatchOperator.execute()` \u6765\u89e6\u53d1\u6267\u884c\uff1b\u5bf9\u4e8e\u6d41\u5f0f\u4f5c\u4e1a\uff0c\u5219\u901a\u8fc7 `StreamOperator.execute()` \u6765\u542f\u52a8\u4f5c\u4e1a\u3002\n\n\n### \u66f4\u591a\u7528\u6cd5\uff1a\n------\n  - [DataFrame \u4e0e Operator \u4e92\u8f6c](docs/pyalink/pyalink-dataframe.md)\n  - [StreamOperator \u6570\u636e\u9884\u89c8](docs/pyalink/pyalink-stream-operator-preview.md)\n  - [UDF/UDTF/SQL \u4f7f\u7528](docs/pyalink/pyalink-udf.md)\n  - [\u4e0e PyFlink \u4e00\u540c\u4f7f\u7528](docs/pyalink/pyalink-pyflink.md)\n  - [PyAlink \u5e38\u89c1\u95ee\u9898](docs/pyalink/pyalink-qa.md)\n\n## Java \u63a5\u53e3\u4f7f\u7528\u4ecb\u7ecd\n----------\n\n### \u793a\u4f8b\u4ee3\u7801\n\n```java\nString URL = \"https://alink-release.oss-cn-beijing.aliyuncs.com/data-files/iris.csv\";\nString SCHEMA_STR = \"sepal_length double, sepal_width double, petal_length double, petal_width double, category string\";\n\nBatchOperator data = new CsvSourceBatchOp()\n        .setFilePath(URL)\n        .setSchemaStr(SCHEMA_STR);\n\nVectorAssembler va = new VectorAssembler()\n        .setSelectedCols(new String[]{\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"})\n        .setOutputCol(\"features\");\n\nKMeans kMeans = new KMeans().setVectorCol(\"features\").setK(3)\n        .setPredictionCol(\"prediction_result\")\n        .setPredictionDetailCol(\"prediction_detail\")\n        .setReservedCols(\"category\")\n        .setMaxIter(100);\n\nPipeline pipeline = new Pipeline().add(va).add(kMeans);\npipeline.fit(data).transform(data).print();\n```\n\n### Flink-1.13 \u7684 Maven \u4f9d\u8d56\n```xml\n<dependency>\n    <groupId>com.alibaba.alink</groupId>\n    <artifactId>alink_core_flink-1.13_2.11</artifactId>\n    <version>1.6.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-streaming-scala_2.11</artifactId>\n    <version>1.13.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-planner_2.11</artifactId>\n    <version>1.13.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-clients_2.11</artifactId>\n    <version>1.13.0</version>\n</dependency>\n```\n\n### Flink-1.12 \u7684 Maven \u4f9d\u8d56\n```xml\n<dependency>\n    <groupId>com.alibaba.alink</groupId>\n    <artifactId>alink_core_flink-1.12_2.11</artifactId>\n    <version>1.6.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-streaming-scala_2.11</artifactId>\n    <version>1.12.1</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-planner_2.11</artifactId>\n    <version>1.12.1</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-clients_2.11</artifactId>\n    <version>1.12.1</version>\n</dependency>\n```\n\n### Flink-1.11 \u7684 Maven \u4f9d\u8d56\n```xml\n<dependency>\n    <groupId>com.alibaba.alink</groupId>\n    <artifactId>alink_core_flink-1.11_2.11</artifactId>\n    <version>1.6.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-streaming-scala_2.11</artifactId>\n    <version>1.11.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-planner_2.11</artifactId>\n    <version>1.11.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-clients_2.11</artifactId>\n    <version>1.11.0</version>\n</dependency>\n```\n\n### Flink-1.10 \u7684 Maven \u4f9d\u8d56\n```xml\n<dependency>\n    <groupId>com.alibaba.alink</groupId>\n    <artifactId>alink_core_flink-1.10_2.11</artifactId>\n    <version>1.6.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-streaming-scala_2.11</artifactId>\n    <version>1.10.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-planner_2.11</artifactId>\n    <version>1.10.0</version>\n</dependency>\n```\n\n### Flink-1.9 \u7684 Maven \u4f9d\u8d56\n\n```xml\n<dependency>\n    <groupId>com.alibaba.alink</groupId>\n    <artifactId>alink_core_flink-1.9_2.11</artifactId>\n    <version>1.6.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-streaming-scala_2.11</artifactId>\n    <version>1.9.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-table-planner_2.11</artifactId>\n    <version>1.9.0</version>\n</dependency>\n```\n\n\n\n## \u5feb\u901f\u5f00\u59cb\u5728\u96c6\u7fa4\u4e0a\u8fd0\u884cAlink\u7b97\u6cd5\n--------\n\n1. \u51c6\u5907Flink\u96c6\u7fa4\n```shell\n  wget https://archive.apache.org/dist/flink/flink-1.13.0/flink-1.13.0-bin-scala_2.11.tgz\n  tar -xf flink-1.13.0-bin-scala_2.11.tgz && cd flink-1.13.0\n  ./bin/start-cluster.sh\n```\n\n2. \u51c6\u5907Alink\u7b97\u6cd5\u5305\n```shell\n  git clone https://github.com/alibaba/Alink.git\n  # add <scope>provided</scope> in pom.xml of alink_examples.\n  cd Alink && mvn -Dmaven.test.skip=true clean package shade:shade\n```\n\n3. \u8fd0\u884cJava\u793a\u4f8b\n```shell\n  ./bin/flink run -p 1 -c com.alibaba.alink.ALSExample [path_to_Alink]/examples/target/alink_examples-1.5-SNAPSHOT.jar\n  # ./bin/flink run -p 1 -c com.alibaba.alink.GBDTExample [path_to_Alink]/examples/target/alink_examples-1.5-SNAPSHOT.jar\n  # ./bin/flink run -p 1 -c com.alibaba.alink.KMeansExample [path_to_Alink]/examples/target/alink_examples-1.5-SNAPSHOT.jar\n```\n\n## \u90e8\u7f72\n----------\n\n[\u96c6\u7fa4\u90e8\u7f72](docs/deploy/cluster-deploy.md)\n",
	"accountability awesome awesome-list data-mining data-science explainable-ml fairness fatml iml interpretability interpretable-ai interpretable-deep-learning interpretable-machine-learning interpretable-ml machine-learning machine-learning-interpretability python r transparency xai": "# awesome-machine-learning-*interpretability* [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\nA curated, but probably biased and incomplete, list of awesome machine learning interpretability resources.\n\nIf you want to contribute to this list (*and please do!*) read over the [contribution guidelines](contributing.md), send a pull request, or contact me [@jpatrickhall](https://twitter.com/jpatrickhall).\n\n**An incomplete, imperfect blueprint for a more human-centered, lower-risk machine learning.** The resources in this repository can be used to do many of these things today. *The resources in this repository should not be considered legal compliance advice.*\n![alt-text](https://github.com/h2oai/mli-resources/blob/master/blueprint.png)\n</br>Image credit: H2O.ai Machine Learning Interpretability team, https://github.com/h2oai/mli-resources.\n\n\n## Table of Contents\n\n* [Comprehensive Software Examples and Tutorials](https://github.com/jphall663/awesome-machine-learning-interpretability#comprehensive-software-examples-and-tutorials)\n* Explainability- or Fairness-Enhancing Software Packages\n  * [Browser](https://github.com/jphall663/awesome-machine-learning-interpretability#browser)\n  * [Python](https://github.com/jphall663/awesome-machine-learning-interpretability#python)\n  * [R](https://github.com/jphall663/awesome-machine-learning-interpretability#r)\n* [Machine learning environment management tools](https://github.com/jphall663/awesome-machine-learning-interpretability#machine-learning-environment-management-tools)\n* [Free Books](https://github.com/jphall663/awesome-machine-learning-interpretability#free-books)\n* [Government and Regulatory Documents](https://github.com/jphall663/awesome-machine-learning-interpretability#government-and-regulatory-documents)\n* [Other Interpretability and Fairness Resources and Lists](https://github.com/jphall663/awesome-machine-learning-interpretability#other-interpretability-and-fairness-resources-and-lists)\n* [Review and General Papers](https://github.com/jphall663/awesome-machine-learning-interpretability#review-and-general-papers)\n* [Classes](https://github.com/jphall663/awesome-machine-learning-interpretability#classes)\n* Interpretable (\"Whitebox\") or Fair Modeling Packages\n  * [C/C++](https://github.com/jphall663/awesome-machine-learning-interpretability#cc)\n  * [Python](https://github.com/jphall663/awesome-machine-learning-interpretability#python-1)\n  * [R](https://github.com/jphall663/awesome-machine-learning-interpretability#r-1)\n* [AI Incident Tracker](https://github.com/jphall663/awesome-machine-learning-interpretability/blob/master/README.md#ai-incident-tracker)\n\n## Comprehensive Software Examples and Tutorials\n\n* [COMPAS Analysis Using Aequitas](https://github.com/dssg/aequitas/blob/master/docs/source/examples/compas_demo.ipynb)\n* [Explaining Quantitative Measures of Fairness (with SHAP)](https://github.com/slundberg/shap/blob/master/notebooks/overviews/Explaining%20quantitative%20measures%20of%20fairness.ipynb)\n* [Getting a Window into your Black Box Model](http://projects.rajivshah.com/inter/ReasonCode_NFL.html)\n* [From GLM to GBM Part 1](https://www.h2o.ai/blog/from-glm-to-gbm-part-1/)\n* [From GLM to GBM Part 2](https://www.h2o.ai/blog/from-glm-to-gbm-part-2/)\n* [IML](https://mybinder.org/v2/gh/christophM/iml/master?filepath=./notebooks/tutorial-intro.ipynb)\n* [Interpretable Machine Learning with Python](https://github.com/jphall663/interpretable_machine_learning_with_python)\n* [Interpreting Machine Learning Models with the iml Package](http://uc-r.github.io/iml-pkg)\n* [Interpretable Machine Learning using Counterfactuals](https://docs.seldon.io/projects/alibi/en/v0.2.0/examples/cf_mnist.html)\n* [Machine Learning Explainability by Kaggle Learn](https://www.kaggle.com/learn/machine-learning-explainability)\n* [Model Interpretability with DALEX](http://uc-r.github.io/dalex)\n* Model Interpretation series by Dipanjan (DJ) Sarkar:\n  * [The Importance of Human Interpretable Machine Learning](https://towardsdatascience.com/human-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476)\n  * [Model Interpretation Strategies](https://towardsdatascience.com/explainable-artificial-intelligence-part-2-model-interpretation-strategies-75d4afa6b739)\n  * [Hands-on Machine Learning Model Interpretation](https://towardsdatascience.com/explainable-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-e8ebe5afc608)\n  * [Interpreting Deep Learning Models for Computer Vision](https://towardsdatascience.com/explainable-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-e8ebe5afc608)\n* [Partial Dependence Plots in R](https://journal.r-project.org/archive/2017/RJ-2017-016/)\n* [Saliency Maps for Deep Learning](https://medium.com/@thelastalias/saliency-maps-for-deep-learning-part-1-vanilla-gradient-1d0665de3284)\n* [Visualizing ML Models with LIME](http://uc-r.github.io/lime)\n* [Visualizing and debugging deep convolutional networks](https://rohitghosh.github.io/2018/01/05/visualising-debugging-deep-neural-networks/)\n* [What does a CNN see?](https://colab.research.google.com/drive/1xM6UZ9OdpGDnHBljZ0RglHV_kBrZ4e-9)\n\n## Explainability- or Fairness-Enhancing Software Packages\n\n### Browser\n\n* [DiscriLens](https://github.com/wangqianwen0418/DiscriLens)\n* [manifold](https://github.com/uber/manifold)\n* [TensorBoard Projector](http://projector.tensorflow.org)\n* [What-if Tool](https://pair-code.github.io/what-if-tool/index.html#about)\n\n### Python\n\n* [acd](https://github.com/csinva/hierarchical_dnn_interpretations)\n* [aequitas](https://github.com/dssg/aequitas)\n* [AI Fairness 360](http://aif360.mybluemix.net)\n* [AI Explainability 360](https://github.com/IBM/AIX360)\n* [ALEPython](https://github.com/blent-ai/ALEPython)\n* [Aletheia](https://github.com/SelfExplainML/Aletheia)\n* [allennlp](https://github.com/allenai/allennlp)\n* [algofairness](https://github.com/algofairness)\n* [Alibi](https://github.com/SeldonIO/alibi)\n* [anchor](https://github.com/marcotcr/anchor)\n* [BlackBoxAuditing](https://github.com/algofairness/BlackBoxAuditing)\n* [casme](https://github.com/kondiz/casme)\n* [Causal Discovery Toolbox](https://github.com/FenTechSolutions/CausalDiscoveryToolbox)\n* [captum](https://github.com/pytorch/captum)\n* [causalml](https://github.com/uber/causalml)\n* [cdt15](https://github.com/cdt15)\n* [checklist](https://github.com/marcotcr/checklist)\n* [contextual-AI](https://github.com/SAP/contextual-ai)\n* [ContrastiveExplanation (Foil Trees)](https://github.com/MarcelRobeer/ContrastiveExplanation)\n* [counterfit](https://github.com/Azure/counterfit/)\n* [dalex](https://github.com/ModelOriented/DALEX)\n* [debiaswe](https://github.com/tolga-b/debiaswe)\n* [DeepExplain](https://github.com/marcoancona/DeepExplain)\n* [deeplift](https://github.com/kundajelab/deeplift)\n* [deepvis](https://github.com/yosinski/deep-visualization-toolbox)\n* [DiCE](https://github.com/interpretml/DiCE)\n* [DoWhy](https://github.com/microsoft/dowhy)\n* [ecco](https://github.com/jalammar/ecco)\n* [eli5](https://github.com/TeamHG-Memex/eli5)\n* [explainerdashboard](https://github.com/oegedijk/explainerdashboard)\n* [fairml](https://github.com/adebayoj/fairml)\n* [fairlearn](https://github.com/fairlearn/fairlearn)\n* [fairness-comparison](https://github.com/algofairness/fairness-comparison)\n* [fairness_measures_code](https://github.com/megantosh/fairness_measures_code)\n* [foolbox](https://github.com/bethgelab/foolbox)\n* [Grad-CAM](https://github.com/topics/grad-cam) (GitHub topic)\n* [gplearn](https://github.com/trevorstephens/gplearn)\n* [hate-functional-tests](https://github.com/paul-rottger/hate-functional-tests)\n* [imodels](https://github.com/csinva/imodels)\n* [iNNvestigate neural nets](https://github.com/albermax/innvestigate)\n* [Integrated-Gradients](https://github.com/ankurtaly/Integrated-Gradients)\n* [interpret](https://github.com/interpretml/interpret)\n* [interpret_with_rules](https://github.com/clips/interpret_with_rules)\n* [imodels](https://github.com/csinva/imodels)\n* [Keras-vis](https://github.com/raghakot/keras-vis)\n* [keract](https://github.com/philipperemy/keract/)\n* [L2X](https://github.com/Jianbo-Lab/L2X)\n* [lime](https://github.com/marcotcr/lime)\n* [LiFT](https://github.com/linkedin/LiFT)\n* [lit](https://github.com/pair-code/lit)\n* [lofo-importance](https://github.com/aerdem4/lofo-importance)\n* [lrp_toolbox](https://github.com/sebastian-lapuschkin/lrp_toolbox)\n* [MindsDB](https://github.com/mindsdb/mindsdb)\n* [MLextend](http://rasbt.github.io/mlxtend/)\n* [ml-fairness-gym](https://github.com/google/ml-fairness-gym)\n* [ml_privacy_meter](https://github.com/privacytrustlab/ml_privacy_meter)\n* [OptBinning](https://github.com/guillermo-navas-palencia/optbinning)\n* [parity-fairness](https://pypi.org/project/parity-fairness/)\n* [PDPbox](https://github.com/SauceCat/PDPbox)\n* [pyBreakDown](https://github.com/MI2DataLab/pyBreakDown)\n* [PyCEbox](https://github.com/AustinRochford/PyCEbox)\n* [pyGAM](https://github.com/dswah/pyGAM)\n* [pymc3](https://github.com/pymc-devs/pymc3)\n* [pytorch-innvestigate](https://github.com/fgxaos/pytorch-innvestigate)\n* [rationale](https://github.com/taolei87/rcnn/tree/master/code/rationale)\n* [responsibly](https://github.com/ResponsiblyAI/responsibly)\n* [revise-tool](https://github.com/princetonvisualai/revise-tool)\n* [robustness](https://github.com/MadryLab/robustness)\n* [RISE](https://github.com/eclique/RISE)\n* [sage](https://github.com/iancovert/sage/)\n* [SALib](https://github.com/SALib/SALib)\n* [scikit-fairness](https://github.com/koaning/scikit-fairness)\n* [shap](https://github.com/slundberg/shap)\n* [shapley](https://github.com/benedekrozemberczki/shapley)\n* [Skater](https://github.com/datascienceinc/Skater)\n* [tensorfow/cleverhans](https://github.com/tensorflow/cleverhans)\n* [tensorflow/lucid](https://github.com/tensorflow/lucid)\n* [tensorflow/fairness-indicators](https://github.com/tensorflow/fairness-indicators)\n* [tensorflow/model-analysis](https://github.com/tensorflow/model-analysis)\n* [tensorflow/model-card-toolkit](https://github.com/tensorflow/model-card-toolkit)\n* [tensorflow/model-remediation](https://github.com/tensorflow/model-remediation)\n* [tensorflow/privacy](https://github.com/tensorflow/privacy)\n* [tensorflow/tcav](https://github.com/tensorflow/tcav)\n* [tensorfuzz](https://github.com/brain-research/tensorfuzz)\n* [TensorWatch](https://github.com/microsoft/tensorwatch)\n* [TextFooler](https://github.com/jind11/TextFooler)\n* [tf-explain](https://github.com/sicara/tf-explain)\n* [Themis](https://github.com/LASER-UMASS/Themis)\n* [themis-ml](https://github.com/cosmicBboy/themis-ml)\n* [treeinterpreter](https://github.com/andosa/treeinterpreter)\n* [woe](https://github.com/boredbird/woe)\n* [xai](https://github.com/EthicalML/xai)\n* [xdeep](https://github.com/datamllab/xdeep)\n* [yellowbrick](https://github.com/DistrictDataLabs/yellowbrick)\n\n### R\n* [aif360](https://cran.r-project.org/web/packages/aif360/index.html)\n* [ALEPlot](https://cran.r-project.org/web/packages/ALEPlot/index.html)\n* [DrWhyAI](https://github.com/ModelOriented/DrWhy)\n* [DALEX](https://github.com/ModelOriented/DALEX)\n* [DALEXtra](https://cran.r-project.org/web/packages/DALEXtra/index.html)\n* [EloML](https://github.com/ModelOriented/EloML)\n* [ExplainPrediction](https://github.com/rmarko/ExplainPrediction)\n* [fastshap](https://github.com/bgreenwell/fastshap)\n* [fairness](https://cran.r-project.org/web/packages/fairness/index.html)\n* [fairmodels](https://github.com/ModelOriented/fairmodels)\n* [featureImportance](https://github.com/giuseppec/featureImportance)\n* [flashlight](https://github.com/mayer79/flashlight)\n* [forestmodel](https://cran.r-project.org/web/packages/forestmodel/index.html)\n* [fscaret](https://cran.r-project.org/web/packages/fscaret/)\n* [iBreakDown](https://github.com/ModelOriented/iBreakDown)\n* [ICEbox](https://cran.r-project.org/web/packages/ICEbox/index.html)\n* [iml](https://github.com/christophM/iml)\n* [ingredients](https://github.com/ModelOriented/ingredients)\n* [intepret](https://cran.r-project.org/web/packages/interpret/index.html)\n* [lightgbmExplainer](https://github.com/lantanacamara/lightgbmExplainer)\n* [lime](https://github.com/thomasp85/lime)\n* [live](https://cran.r-project.org/web/packages/live/index.html)\n* [mcr](https://github.com/aaronjfisher/mcr)\n* [modelDown](https://cran.r-project.org/web/packages/modelDown/index.html)\n* [modelOriented](https://github.com/ModelOriented)\n* [modelStudio](https://github.com/ModelOriented/modelStudio)\n* [pdp](https://bgreenwell.github.io/pdp/index.html)\n* [shapFlex](https://github.com/nredell/shapFlex)\n* [shapleyR](https://github.com/redichh/ShapleyR)\n* [shapper](https://cran.r-project.org/web/packages/shapper/index.html)\n* [smbinning](https://cran.r-project.org/web/packages/smbinning/index.html)\n* [vip](https://github.com/koalaverse/vip)\n* [xgboostExplainer](https://github.com/AppliedDataSciencePartners/xgboostExplainer)\n\n## Machine learning environment management tools\n\n* [dvc](https://dvc.org/)\n* [gigantum](https://github.com/gigantum)\n* [mlflow](https://mlflow.org/)\n* [mlmd](https://github.com/google/ml-metadata)\n* [modeldb](https://github.com/VertaAI/modeldb)\n* [whylabs](https://www.rsqrdai.org/)\n\n## Free Books\n\n* [An Introduction to Machine Learning Interpretability](https://www.h2o.ai/wp-content/uploads/2019/08/An-Introduction-to-Machine-Learning-Interpretability-Second-Edition.pdf)\n* [Explanatory Model Analysis](https://pbiecek.github.io/ema/)\n* [Fairness and Machine Learning](http://fairmlbook.org/)\n* [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)\n* [Responsible Machine Learning](https://www.h2o.ai/resources/ebook/responsible-machine-learning/) (requires email for now)\n\n## Government and Regulatory Documents\n\n* [12 CFR Part 1002 - Equal Credit Opportunity Act (Regulation B)](https://www.consumerfinance.gov/policy-compliance/rulemaking/regulations/1002/)\n* [A Regulatory Framework for AI: Recommendations for PIPEDA Reform](https://www.priv.gc.ca/en/about-the-opc/what-we-do/consultations/completed-consultations/consultation-ai/reg-fw_202011/)\n* [AI Principles: Recommendations on the Ethical Use of Artificial Intelligence by the Department of Defense](https://media.defense.gov/2019/Oct/31/2002204458/-1/-1/0/DIB_AI_PRINCIPLES_PRIMARY_DOCUMENT.PDF)\n* [THE AIM INITIATIVE](https://www.dni.gov/files/ODNI/documents/AIM-Strategy.pdf)\n* [Aiming for truth, fairness, and equity in your company\u2019s use of AI](https://www.ftc.gov/news-events/blogs/business-blog/2021/04/aiming-truth-fairness-equity-your-companys-use-ai)\n* [Algorithmic Accountability Act of 2019](https://www.wyden.senate.gov/imo/media/doc/Algorithmic%20Accountability%20Act%20of%202019%20Bill%20Text.pdf)\n* [ALGORITHM CHARTER FOR AOTEAROA NEW ZEALAND](https://data.govt.nz/assets/data-ethics/algorithm/Algorithm-Charter-2020_Final-English-1.pdf)\n* [Artificial Intelligence (AI) in the Securities Industry](https://www.finra.org/sites/default/files/2020-06/ai-report-061020.pdf)\n* [Article 22 EU GDPR](https://www.privacy-regulation.eu/en/article-22-automated-individual-decision-making-including-profiling-GDPR.htm)\n* [Assessment List for Trustworthy Artificial Intelligence (ALTAI) for self-assessment - Shaping Europe\u2019s digital future - European Commission](https://ec.europa.eu/digital-single-market/en/news/assessment-list-trustworthy-artificial-intelligence-altai-self-assessment)\n* [Audit of Governance and Protection of Department of Defense Artificial Intelligence Data and Technology](https://media.defense.gov/2020/Jul/01/2002347967/-1/-1/1/DODIG-2020-098.PDF)\n* [A Primer on Artificial Intelligence in Securities Markets](https://www.cftc.gov/media/2846/LabCFTC_PrimerArtificialIntelligence102119/download)\n* [Biometric Information Privacy Act](https://www.ilga.gov/legislation/ilcs/ilcs3.asp?ActID=3004&ChapterID=57)\n* [Booker Wyden Health Care Letters](https://www.scribd.com/document/437954989/Booker-Wyden-Health-Care-Letters#download)\n* [California Consumer Privacy Act (CCPA)](https://oag.ca.gov/privacy/ccpa)\n* [California Privacy Rights Act (CPRA)](https://www.oag.ca.gov/system/files/initiatives/pdfs/19-0021A1%20%28Consumer%20Privacy%20-%20Version%203%29_1.pdf)\n* [Consultation on the OPC\u2019s Proposals for ensuring appropriate regulation of artificial intelligence](https://www.priv.gc.ca/en/about-the-opc/what-we-do/consultations/consultation-ai/pos_ai_202001/)\n* [Civil liability regime for artificial intelligence](https://www.europarl.europa.eu/doceo/document/TA-9-2020-0276_EN.pdf)\n* [Data Ethics Framework](https://strategy-staging.data.gov/assets/docs/data-ethics-framework-action-14-draft-2020-sep-2.pdf)\n* [DEVELOPING FINANCIAL SECTOR RESILIENCE IN A DIGITAL WORLD: SELECTED THEMES IN TECHNOLOGY AND RELATED RISKS](https://www.osfi-bsif.gc.ca/Eng/Docs/tchrsk.pdf)\n* [Directive on Automated Decision Making](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32592)\n* [Executive Order on Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government](https://www.whitehouse.gov/presidential-actions/executive-order-promoting-use-trustworthy-artificial-intelligence-federal-government/)\n* [EEOC Letter (from U.S. senators re: hiring software)](https://www.bennet.senate.gov/public/_cache/files/0/a/0a439d4b-e373-4451-84ed-ba333ce6d1dd/672D2E4304D63A04CC3465C3C8BF1D21.letter-to-chair-dhillon.pdf)\n* [Facial Recognition and Biometric Technology Moratorium Act of 2020](https://drive.google.com/file/d/1gkTcjFtieMQdsQ01dmDa49B6HY9ZyKr8/view)\n* [Four Principles of Explainable Artificial Intelligence ](https://www.nist.gov/system/files/documents/2020/08/17/NIST%20Explainable%20AI%20Draft%20NISTIR8312%20%281%29.pdf)\n* [General principles for the use of Artificial Intelligence in the financial sector](https://www.dnb.nl/media/jkbip2jc/general-principles-for-the-use-of-artificial-intelligence-in-the-financial-sector.pdf)\n* [Gouvernance des algorithmes d\u2019intelligence artificielle dans le secteur financier (French)](https://acpr.banque-france.fr/sites/default/files/medias/documents/20200612_gouvernance_evaluation_ia.pdf)\n* [Innovation spotlight: Providing adverse action notices when using AI/ML models](https://www.consumerfinance.gov/about-us/blog/innovation-spotlight-providing-adverse-action-notices-when-using-ai-ml-models/)\n* [Office of Management and Budget Guidance for Regulation of Artificial Intelligence Applications](https://www.whitehouse.gov/wp-content/uploads/2020/11/M-21-06.pdf) (Finalized Nov. 2020)\n* [On Artificial Intelligence - A European approach to excellence and trust](https://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_en.pdf)\n* [Opinion of the German Data Ethics Commission](https://www.bmjv.de/SharedDocs/Downloads/DE/Themen/Fokusthemen/Gutachten_DEK_EN.pdf?__blob=publicationFile&v=2)\n* [Principles of Artificial Intelligence Ethics for the Intelligence Community](https://www.intel.gov/principles-of-artificial-intelligence-ethics-for-the-intelligence-community)\n* [Proposal for a Regulation laying down harmonised rules on artificial intelligence (Artificial Intelligence Act)](https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence-artificial-intelligence)\n* [Psychological Foundations of Explainability and Interpretability in Artificial Intelligence](https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8367.pdf)\n* [Questions and Answers to Clarify and Provide a Common Interpretation of the Uniform Guidelines on Employee Selection Procedures](https://www.eeoc.gov/laws/guidance/questions-and-answers-clarify-and-provide-common-interpretation-uniform-guidelines)\n* [Questions from the Commission on Protecting Privacy and Preventing Discrimination](https://auditor.utah.gov/wp-content/uploads/sites/6/2021/02/Office-of-the-State-Auditor-Questions-to-help-Procuring-Agencies-_-Entities-with-Software-Procurement-Feb-1-2021-Final.pdf)\n* [RE: Use of External Consumer Data and Information Sources in Underwriting for Life Insurance](https://www.dfs.ny.gov/industry_guidance/circular_letters/cl2019_01)\n* [Singapore Personal Data Protection Commission (PDPC) Model Artificial Intelligence Governance Framework](https://www.pdpc.gov.sg/Help-and-Resources/2020/01/Model-AI-Governance-Framework)\n* [SUPERVISORY GUIDANCE ON MODEL RISK MANAGEMENT](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)\n* [U.K. Information Commissioner's Office (ICO) AI Audting Framework (overview series)](https://ico.org.uk/about-the-ico/news-and-events/ai-blog-an-overview-of-the-auditing-framework-for-artificial-intelligence-and-its-core-components/)\n* [Artificial Intelligence/Machine Learning (AI/ML)-Based: Software as a Medical Device (SaMD) Action Plan](https://www.fda.gov/media/145022/download) (Updated Jan. 2021)\n* [U.S. House of Representatives Resolution on AI Strategy](https://hurd.house.gov/sites/hurd.house.gov/files/HURDTX_AI%20Res.pdf)\n* [Using Artificial Intelligence and Algorithms](https://www.ftc.gov/news-events/blogs/business-blog/2020/04/using-artificial-intelligence-algorithms)\n\n\n## Other Interpretability and Fairness Resources and Lists\n\n* [8 Principles of Responsible ML](https://ethical.institute/principles.html)\n* [ACM FAT* 2019 Youtube Playlist](https://www.youtube.com/playlist?list=PLXA0IWa3BpHk7fE8IH6wXNEfAZyr3A5Yb)\n* [Adversarial ML Threat Matrix](https://github.com/mitre/advmlthreatmatrix)\n* [AI Tools and Platforms](https://docs.google.com/spreadsheets/u/2/d/10pPQYmyNnYb6zshOKxBjJ704E0XUj2vJ9HCDfoZxAoA/htmlview#)\n* [AI Ethics Guidelines Global Inventory](https://algorithmwatch.org/en/project/ai-ethics-guidelines-global-inventory/)\n* [AI Incident Database](http://aiid.partnershiponai.org/)\n* [AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models](http://sameersingh.org/files/papers/allennlp-interpret-demo-emnlp19.pdf)\n* [Algorithms and prejudice](https://www.thesaturdaypaper.com.au/news/politics/2019/12/07/algorithms-and-prejudice/15756372009195)\n* [Awesome interpretable machine learning](https://github.com/lopusz/awesome-interpretable-machine-learning) ;)\n* [Awesome machine learning operations](https://github.com/EthicalML/awesome-machine-learning-operations)\n* [Awful AI](https://github.com/daviddao/awful-ai)\n* [algoaware](https://www.algoaware.eu/)\n* [BIML Interactive Machine Learning Risk Framework](https://berryvilleiml.com/interactive/)\n* [Beyond Explainability: A Practical Guide to Managing Risk in Machine Learning Models](https://go.immuta.com/beyond-explainability-white-paper)\n* [criticalML](https://github.com/rockita/criticalML)\n* [Data Feminism](https://mitpress.mit.edu/books/data-feminism)\n* [Dealing with Bias and Fairness in AI/ML/Data Science Systems](https://docs.google.com/presentation/d/17o_NzplYua5fcJFuGcy1V1-5GFAHk7oHAF4dN44NkUE)\n* [Debugging Machine Learning Models (ICLR workshop proceedings)](https://debug-ml-iclr2019.github.io/)\n* [Decision Points in AI Governance](https://cltc.berkeley.edu/wp-content/uploads/2020/05/Decision_Points_AI_Governance.pdf)\n* [De-identification Tools](https://www.nist.gov/itl/applied-cybersecurity/privacy-engineering/collaboration-space/focus-areas/de-id/tools)\n* [Deep Insights into Explainability and Interpretability of Machine Learning Algorithms and Applications to Risk Management](https://ww2.amstat.org/meetings/jsm/2019/onlineprogram/AbstractDetails.cfm?abstractid=303053)\n* [Distill](https://distill.pub)\n* [Faces in the Wild Benchmark Data](https://github.com/visionjo/facerec-bias-bfw)\n* [Fairness, Accountability, and Transparency in Machine Learning (FAT/ML) Scholarship](https://www.fatml.org/resources/relevant-scholarship)\n* [From Principles to Practice: An interdisciplinary framework to operationalise AI ethics](https://www.ai-ethics-impact.org/resource/blob/1961130/c6db9894ee73aefa489d6249f5ee2b9f/aieig---report---download-hb-data.pdf)\n* [How will the GDPR impact machine learning?](https://www.oreilly.com/radar/how-will-the-gdpr-impact-machine-learning/)\n* [Machine Learning Ethics References](https://github.com/radames/Machine-Learning-Ethics-References)\n* [Machine Learning Interpretability Resources](https://github.com/h2oai/mli-resources)\n* [Machine Learning: Considerations for fairly and transparently expanding access to credit](http://info.h2o.ai/rs/644-PKX-778/images/Machine%20Learning%20-%20Considerations%20for%20Fairly%20and%20Transparently%20Expanding%20Access%20to%20Credit.pdf)\n* [MIT AI Ethics Reading Group](https://mitaiethics.github.io/)\n* [On the Responsibility of Technologists: A Prologue and Primer](https://algo-stats.info/2018/04/15/on-the-responsibility-of-technologists-a-prologue-and-primer/)\n* [private-ai-resources](https://github.com/OpenMined/private-ai-resources)\n* [Problems with Shapley-value-based explanations as feature importance measures](https://arxiv.org/pdf/2002.11097v1.pdf)\n* [Real-World Model Debugging Strategies](https://medium.com/@jphall_22520/strategies-for-model-debugging-aa822f1097ce)\n* [ResponsibleAI](https://romanlutz.github.io/ResponsibleAI/)\n* [Robust ML](https://www.robust-ml.org/)\n* [Safe and Reliable Machine Learning](https://www.dropbox.com/s/sdu26h96bc0f4l7/FAT19-AI-Reliability-Final.pdf?dl=0)\n* [Sample AI Incident Response Checklist](https://bnh-ai.github.io/resources/)\n* [Ten Questions on AI Risk](https://fpf.org/wp-content/uploads/2020/06/Ten-Questions-on-AI-Risk-FPF.pdf)\n* [Testing and Debugging in Machine Learning](https://developers.google.com/machine-learning/testing-debugging)\n* [Troubleshooting Deep Neural Networks](http://josh-tobin.com/assets/pdf/troubleshooting-deep-neural-networks-01-19.pdf)\n* [Warning Signs: The Future of Privacy and Security in an Age of Machine Learning](https://fpf.org/wp-content/uploads/2019/09/FPF_WarningSigns_Report.pdf)\n* [When Not to Trust Your Explanations](https://docs.google.com/presentation/d/10a0PNKwoV3a1XChzvY-T1mWudtzUIZi3sCMzVwGSYfM/edit)\n* [XAI Resources](https://github.com/pbiecek/xai_resources)\n* [You Created A Machine Learning Application Now Make Sure It's Secure](https://www.oreilly.com/ideas/you-created-a-machine-learning-application-now-make-sure-its-secure)\n\n## Review and General Papers\n\n* [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://arxiv.org/pdf/1811.10104.pdf)\n* [A Comparative Study of Fairness-Enhancing Interventions in Machine Learning](https://arxiv.org/pdf/1802.04422.pdf)\n* [A Survey Of Methods For Explaining Black Box Models](https://arxiv.org/pdf/1802.01933.pdf)\n* [A Marauder\u2019s Map of Security and Privacy in Machine Learning](https://arxiv.org/pdf/1811.01134.pdf)\n* [Challenges for Transparency](https://arxiv.org/pdf/1708.01870.pdf)\n* [Closing the AI Accountability Gap](https://arxiv.org/pdf/2001.00973.pdf)\n* [Explaining by Removing: A Unified Framework for Model Explanation](https://arxiv.org/abs/2011.14878)\n* [Explaining Explanations: An Overview of Interpretability of Machine Learning](https://arxiv.org/pdf/1806.00069.pdf)\n* [Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI](https://arxiv.org/abs/1902.01876v1)\n* [Interpretable Machine Learning: Definitions, Methods, and Applications](https://arxiv.org/abs/1901.04592)\n* [Limitations of Interpretable Machine Learning](https://compstat-lmu.github.io/iml_methods_limitations/)\n* [Machine Learning Explainability in Finance](https://www.bankofengland.co.uk/-/media/boe/files/working-paper/2019/machine-learning-explainability-in-finance-an-application-to-default-risk-analysis)\n* [On the Art and Science of Machine Learning Explanations](https://arxiv.org/pdf/1810.02909.pdf)\n* [Please Stop Explaining Black Box Models for High-Stakes Decisions](https://arxiv.org/pdf/1811.10154.pdf)\n* [Software Engineering for Machine Learning: A Case Study](https://www.microsoft.com/en-us/research/uploads/prod/2019/03/amershi-icse-2019_Software_Engineering_for_Machine_Learning.pdf)\n* [The Mythos of Model Interpretability](https://arxiv.org/pdf/1606.03490.pdf)\n* [Towards A Rigorous Science of Interpretable Machine Learning](https://arxiv.org/pdf/1702.08608.pdf)\n* [Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims](https://arxiv.org/pdf/2004.07213.pdf)\n* [The Security of Machine Learning](https://people.eecs.berkeley.edu/~adj/publications/paper-files/SecML-MLJ2010.pdf)\n* [Techniques for Interpretable Machine Learning](https://arxiv.org/pdf/1808.00033.pdf)\n* [Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda](https://dl.acm.org/citation.cfm?id=3174156)\n* [Underspecification Presents Challenges for Credibility in Modern Machine Learning](https://arxiv.org/pdf/2011.03395.pdf)\n\n## Classes\n\n* [An Introduction to Data Ethics](https://www.scu.edu/ethics/focus-areas/technology-ethics/resources/an-introduction-to-data-ethics/)\n* [Certified Ethical Emerging Technologist](https://certnexus.com/certification/ceet/)\n* [Fairness in Machine Learning](https://fairmlclass.github.io/)\n* [Fast.ai Data Ethics course](http://ethics.fast.ai/syllabus/#lesson-2-bias--fairness)\n* [Human-Center Machine Learning](http://courses.mpi-sws.org/hcml-ws18/)\n* [Introduction to Responsible Machine Learning](https://jphall663.github.io/GWU_rml/)\n* [Trustworthy Deep Learning](https://berkeley-deep-learning.github.io/cs294-131-s19/)\n\n\n## Interpretable (\"Whitebox\") or Fair Modeling Packages\n\n### C/C++\n\n* [Born-again Tree Ensembles](https://github.com/vidalt/BA-Trees)\n* [Certifiably Optimal RulE ListS](https://github.com/nlarusstone/corels)\n\n### Python\n\n* [Bayesian Case Model](https://users.cs.duke.edu/~cynthia/code/BCM.zip)\n* [Bayesian Ors-Of-Ands](https://github.com/wangtongada/BOA)\n* [Bayesian Rule List (BRL)](https://users.cs.duke.edu/~cynthia/code/BRL_supplement_code.zip)\n* [Explainable Boosting Machine (EBM)/GA2M](https://github.com/interpretml/interpret)\n* [fair-classification](https://github.com/mbilalzafar/fair-classification)\n* [Falling Rule List (FRL)](https://users.cs.duke.edu/~cynthia/code/falling_rule_list.zip)\n* H2O-3\n  * [Penalized Generalized Linear Models](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2ogeneralizedlinearestimator)\n  * [Monotonic GBM](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2ogradientboostingestimator)\n  * [Sparse Principal Components (GLRM)](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2ogeneralizedlowrankestimator)\n* [learning-fair-representations](https://github.com/zjelveh/learning-fair-representations)\n* [Optimal Sparse Decision Trees](https://github.com/xiyanghu/OSDT)\n* [Monotonic](http://xgboost.readthedocs.io/en/latest/tutorials/monotonic.html) [XGBoost](http://xgboost.readthedocs.io/en/latest/)\n* [Multilayer Logical Perceptron (MLLP)](https://github.com/12wang3/mllp)\n* [pyGAM](https://github.com/dswah/pyGAM)\n* [pySS3](https://github.com/sergioburdisso/pyss3)\n* [Risk-SLIM](https://github.com/ustunb/risk-SLIM)\n* Scikit-learn\n  * [Decision Trees](http://scikit-learn.org/stable/modules/tree.html)\n  * [Generalized Linear Models](http://scikit-learn.org/stable/modules/linear_model.html)\n  * [Sparse Principal Components](http://scikit-learn.org/stable/modules/decomposition.html#sparse-principal-components-analysis-sparsepca-and-minibatchsparsepca)\n* [sklearn-expertsys](https://github.com/tmadl/sklearn-expertsys)\n* [skope-rules](https://github.com/scikit-learn-contrib/skope-rules)\n* [Super-sparse Linear Integer models (SLIMs)](https://github.com/ustunb/slim-python)\n* [tensorflow/lattice](https://github.com/tensorflow/lattice)\n* [This Looks Like That](https://github.com/cfchen-duke/ProtoPNet)\n\n### R\n\n* [arules](https://cran.r-project.org/web/packages/arules/index.html)\n* [Causal SVM](https://github.com/shangtai/githubcausalsvm)\n* [elasticnet](https://cran.r-project.org/web/packages/elasticnet/index.html)\n* [Explainable Boosting Machine (EBM)/GA2M](https://cran.r-project.org/web/packages/interpret/index.html)\n* [gam](https://cran.r-project.org/web/packages/gam/index.html)\n* [glm2](https://cran.r-project.org/web/packages/glm2/)\n* [glmnet](https://cran.r-project.org/web/packages/glmnet/index.html)\n* H2O-3\n  * [Penalized Generalized Linear Models](http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.glm.html)\n  * [Monotonic GBM](http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.gbm.html)\n  * [Sparse Principal Components (GLRM)](http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.glrm.html)\n* [Monotonic](http://xgboost.readthedocs.io/en/latest/tutorials/monotonic.html) [XGBoost](http://xgboost.readthedocs.io/en/latest/)\n* [quantreg](https://cran.r-project.org/web/packages/quantreg/index.html)\n* [rpart](https://cran.r-project.org/web/packages/rpart/index.html)\n* [RuleFit](http://statweb.stanford.edu/~jhf/R_RuleFit.html)\n* [Scalable Bayesian Rule Lists (SBRL)](https://users.cs.duke.edu/~cynthia/code/sbrl_1.0.tar.gz)\n\n## AI Incident Tracker\n\n* [Mar 1988 - A blot on the profession](https://www.bmj.com/content/296/6623/657)\n* [Jan 2010 - Are Face-Detection Cameras Racist?](http://content.time.com/time/business/article/0,8599,1954643,00.html)\n* [Jul 2015 - Google says sorry for racist auto-tag in photo app](https://www.theguardian.com/technology/2015/jul/01/google-sorry-racist-auto-tag-photo-app)\n* [Mar 2016 - Here Are the Microsoft Twitter Bot\u2019s Craziest Racist Rants](https://gizmodo.com/here-are-the-microsoft-twitter-bot-s-craziest-racist-ra-1766820160)\n* [Jun 2016 - Google faulted for racial bias in image search results for black teenagers](https://www.washingtonpost.com/news/morning-mix/wp/2016/06/10/google-faulted-for-racial-bias-in-image-search-results-for-black-teenagers/)\n* [Oct 2016 - 'Rogue' Algorithm Blamed for Historic Crash of the British Pound](https://gizmodo.com/rogue-algorithm-blamed-for-historic-crash-of-the-britis-1787523587)\n* [Oct 2016 - Crime-prediction tool PredPol amplifies racially biased policing, study shows](https://www.mic.com/articles/156286/crime-prediction-tool-pred-pol-only-amplifies-racially-biased-policing-study-shows)\n* [May 2017 - Houston Schools Must Face Teacher Evaluation Lawsuit](https://www.courthousenews.com/houston-schools-must-face-teacher-evaluation-lawsuit/)\n* [Jun 2017 - When a Computer Program Keeps You in Jail](https://www.nytimes.com/2017/06/13/opinion/how-computers-are-harming-criminal-justice.html)\n* [Jun 2017 - Antitrust: Commission fines Google \u20ac2.42 billion for abusing dominance as search engine by giving illegal advantage to own comparison shopping service](https://ec.europa.eu/commission/presscorner/detail/en/IP_17_1784)\n* [Jul 2017 - \u2018Balls have zero to me to me\u2019: What happened when Facebook\u2019s AI chatbots Bob & Alice created their own language](https://analyticsindiamag.com/facebook-ai-chatbots-created-their-own-language/)\n* [Jul 2017 - YouTube: Boston Dynamics' Atlas Falls Over After Demo at the Congress of Future Scientists and Technologists](https://www.youtube.com/watch?v=TxobtWAFh8o)\n* [Jul 2017 - Royal Free - Google DeepMind trial failed to comply with data protection law](https://ico.org.uk/about-the-ico/news-and-events/news-and-blogs/2017/07/royal-free-google-deepmind-trial-failed-to-comply-with-data-protection-law/)\n* [Nov 2017 - Hackers Say They've Broken Face ID a Week After iPhone X Release](https://www.wired.com/story/hackers-say-broke-face-id-security/)\n* [Nov 2017 - India\u2019s Friendly Robot Mitra Not Only Greets VIPs On The Stage, But Also Parties Like A Rockstar](https://analyticsindiamag.com/mitra-robot-ivanka-trump-modi-ges/) (Mitra trips over Ivanka Trump/PM Modi introduction)\n* [Jan 2018 - YouTube: CES 2018: Robot refuses to co-operate with LG chief - BBC News](https://www.youtube.com/watch?v=tQMtbWwbduA)\n* [Feb 2018 - Study finds gender and skin-type bias in commercial artificial-intelligence systems](http://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212)\n* [Mar 2018 - Self-Driving Uber Car Kills Pedestrian in Arizona, Where Robots Roam](https://www.nytimes.com/2018/03/19/technology/uber-driverless-fatality.html)\n* [Mar 2018 - AI-Assisted Fake Porn Is Here and We're All F***ed](https://www.vice.com/en_us/article/bj5and/ai-assisted-fake-porn-is-here-and-were-all-fucked)\n* [Jun 2018 - Facebook sent a doctor on a secret mission to ask hospitals to share patient data](https://www.cnbc.com/2018/04/05/facebook-building-8-explored-data-sharing-agreement-with-hospitals.html)\n* [Jul 2018 - Amazon\u2019s Face Recognition Falsely Matched 28 Members of Congress With Mugshots](https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28)\n* [Jul 2018 - IBM\u2019s Watson supercomputer recommended \u2018unsafe and incorrect\u2019 cancer treatments, internal documents show](https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/)\n* [Oct 2018 - Amazon scraps 'sexist AI' recruiting tool that showed bias against women](https://www.telegraph.co.uk/technology/2018/10/10/amazon-scraps-sexist-ai-recruiting-tool-showed-bias-against/)\n* [Nov 2018 - Facial recognition system in China mistakes bus ad for jaywalker](https://www.biometricupdate.com/201811/facial-recognition-system-in-china-mistakes-bus-ad-for-jaywalker)\n* [Dec 2018 - AI start-up that scanned babysitters halts launch following Post Report](https://www.washingtonpost.com/technology/2018/12/14/ai-start-up-that-scanned-babysitters-halts-launch-following-post-report/)\n* [Jan 2019 - Cambridge Analytica\u2019s parent pleads guilty to breaking UK data law](https://techcrunch.com/2019/01/09/cambridge-analyticas-parent-pleads-guilty-to-breaking-uk-data-law/)\n* [Apr 2019 - Facebook Executive Testifies on AI Failure to Detect the Christchurch Mosque Shooting Video](https://fortune.com/2019/04/24/facebook-new-zealand-terrorism-artificial-intelligence-ai/)\n* [May 2019 - Investor Sues After an AI\u2019s Automated Trades Cost Him $20 Million](https://futurism.com/investing-lawsuit-ai-trades-cost-millions)\n* [May 2019 - \nMillions of people uploaded photos to the Ever app. Then the company used them to develop facial recognition tools.](https://www.nbcnews.com/tech/security/millions-people-uploaded-photos-ever-app-then-company-used-them-n1003371)\n* [Jun 2019 - Google and the University of Chicago Are Sued Over Data Sharing](https://www.nytimes.com/2019/06/26/technology/google-university-chicago-data-sharing-lawsuit.html)\n* [Aug 2019 - LGBTQ+ creators file lawsuit against YouTube for discrimination](https://thenextweb.com/google/2019/08/14/lgbtq-youtube-discrimination-lawsuit/)\n* [Sep 2019 - The viral selfie app ImageNet Roulette seemed fun \u2013 until it called me a racist slur](https://www.theguardian.com/technology/2019/sep/17/imagenet-roulette-asian-racist-slur-selfie)\n* [Sep 2019 - Scammer Successfully Deepfaked CEO's Voice To Fool Underling Into Transferring $243,000](https://gizmodo.com/scammer-successfully-deepfaked-ceos-voice-to-fool-under-1837835066)\n* [Oct 2019 - Oh dear... AI models used to flag hate speech online are, er, racist against black people](https://www.theregister.com/2019/10/11/ai_black_people/)\n* [Oct 2019 - Dissecting racial bias in an algorithm used to manage the health of populations](https://science.sciencemag.org/content/366/6464/447)\n* [Nov 2019 - \nNY regulator investigating Apple Card for possible gender bias](https://www.nbcnews.com/tech/apple/ny-regulator-investigating-apple-card-possible-gender-bias-n1079581)\n* [Nov 2019 - Chinese-style facial recognition technology is trialled in Australian schools to register pupils - sparking major privacy concerns](https://www.dailymail.co.uk/news/article-7642411/Australian-schools-trial-facial-recognition-technology-attendance.html)\n* [Dec 2019 - Tenants sounded the alarm on facial recognition in their buildings. Lawmakers are listening](https://www.msn.com/en-us/news/politics/tenants-sounded-the-alarm-on-facial-recognition-in-their-buildings-lawmakers-are-listening/ar-BBYnaqB)\n* [Dec 2019 - Researchers bypass airport and payment facial recognition systems using masks](https://www.engadget.com/2019-12-16-facial-recognition-fooled-masks.html)\n* [Jan 2020 - Atlantic Plaza Towers tenants won a halt to facial recognition in their building: Now they\u2019re calling on a moratorium on all residential use](https://medium.com/@AINowInstitute/atlantic-plaza-towers-tenants-won-a-halt-to-facial-recognition-in-their-building-now-theyre-274289a6d8eb)\n* [Jan 2020 - Trivago misled consumers about hotel room rates](https://www.accc.gov.au/media-release/trivago-misled-consumers-about-hotel-room-rates)\n* [Feb 2020 - An Indian politician is using deepfake technology to win new voters](https://www.technologyreview.com/2020/02/19/868173/an-indian-politician-is-using-deepfakes-to-try-and-win-voters/)\n* [Feb 2020 - Suckers List: How Allstate\u2019s Secret Auto Insurance Algorithm Squeezes Big Spenders](https://themarkup.org/allstates-algorithm/2020/02/25/car-insurance-suckers-list)\n* [Feb 2020 - Tesla Autopilot gets tricked into accelerating from 35 to 85 mph with modified speed limit sign](https://electrek.co/2020/02/19/tesla-autopilot-tricked-accelerate-speed-limit-sign/)\n* [Mar 2020 - Netherlands: Court Prohibits Government\u2019s Use of AI Software to Detect Welfare Fraud](https://www.loc.gov/law/foreign-news/article/netherlands-court-prohibits-governments-use-of-ai-software-to-detect-welfare-fraud/)\n* [Mar 2020 - The End of Starsky Robotics](https://medium.com/starsky-robotics-blog/the-end-of-starsky-robotics-acb8a6a8a5f5)\n* [Apr 2020 - Google apologizes after its Vision AI produced racist results](https://algorithmwatch.org/en/story/google-vision-racism/)\n* [Apr 2020 - Google\u2019s medical AI was super accurate in a lab. Real life was a different story.](https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/)\n* [May 2020 - Researchers find major demographic differences in speech recognition accuracy](https://www.biometricupdate.com/202003/researchers-find-major-demographic-differences-in-speech-recognition-accuracy)\n* [May 2020 - Access Denied: Faulty Automated Background Checks Freeze Out Renters](https://themarkup.org/locked-out/2020/05/28/access-denied-faulty-automated-background-checks-freeze-out-renters)\n* [May 2020 - A.C.L.U. Accuses Clearview AI of Privacy \u2018Nightmare Scenario\u2019](https://www.nytimes.com/2020/05/28/technology/clearview-ai-privacy-lawsuit.html)\n* [May 2020 - Walmart Employees Are Out to Show Its Anti-Theft AI Doesn't Work](https://www.wired.com/story/walmart-shoplifting-artificial-intelligence-everseen/)\n* [May 2020 - Robodebt removed humans from Human Services, and the Government is facing the consequences](https://www.abc.net.au/news/2020-05-30/robodebt-stuart-robert-scott-morrison/12303322)\n* [May 2020 - The Most Devastating Software Mistake Of All Time. Why Is the Imperial Model Under Criticism?](https://analyticsindiamag.com/the-most-devastating-software-mistake-of-all-time-why-is-the-imperial-model-under-criticism/)\n* [Jun 2020 - Government\u2019s Use of Algorithm Serves Up False Fraud Charges](https://undark.org/2020/06/01/michigan-unemployment-fraud-algorithm/)\n* [Jun 2020 - Microsoft's robot editor confuses mixed-race Little Mix singers](https://www.theguardian.com/technology/2020/jun/09/microsofts-robot-journalist-confused-by-mixed-race-little-mix-singers)\n* [Jun 2020 - Tweet: \"This algorithm probably made this mistake ...\"](https://twitter.com/kareem_carr/status/1274462329653137419) (President Obama de-blurred into white male)\n* [Jun 2020 - Detroit Police Chief: Facial Recognition Software Misidentifies 96% of the Time](https://www.vice.com/en_us/article/dyzykz/detroit-police-chief-facial-recognition-software-misidentifies-96-of-the-time)\n* [Jun 2020 - Wrongfully Accused by an Algorithm](https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html)\n* [Jun 2020 - An Algorithm that \"Predicts\" Criminality Based on a Face Sparks a Furor](https://www.wired.com/story/algorithm-predicts-criminality-based-face-sparks-furor/)\n* [Jun 2020 - PwC facial recognition tool criticised for home working privacy invasion](https://www.personneltoday.com/hr/pwc-facial-recognition-tool-criticised-for-home-working-privacy-invasion/)\n* [Jun 2020 - Santa Cruz becomes the first U.S. city to ban predictive policing](https://www.latimes.com/california/story/2020-06-26/santa-cruz-becomes-first-u-s-city-to-ban-predictive-policing)\n* [Jun 2020 - YouTube Sued for Race Discrimination, Profiting from Hate Speech](https://news.bloomberglaw.com/class-action/youtube-sued-for-race-discrimination-profiting-from-hate-speech)\n* [Jul 2020 - ISIS 'still evading detection on Facebook', report says](https://www.bbc.com/news/technology-53389657)\n* [Jul 2020 - Meet the Secret Algorithm That's Keeping Students Out of College](https://www.wired.com/story/algorithm-set-students-grades-altered-futures/)\n* [Jul 2020 - Rite Aid deployed facial recognition systems in hundreds of U.S. stores](https://www.reuters.com/investigates/special-report/usa-riteaid-software/)\n* [Jul 2020 - Tweet: \"Oh, dear ...\" (GPT-3 anti-semitism)](https://mobile.twitter.com/jsellenberg/status/1289018551806894081)\n* [Jul 2020 - Google Ad Portal Equated \u201cBlack Girls\u201d with Porn](https://themarkup.org/google-the-giant/2020/07/23/google-advertising-keywords-black-girls)\n* [Jul 2020 - Facial biometrics training dataset leads to BIPA lawsuits against Amazon, Alphabet and Microsoft](https://www.biometricupdate.com/202007/facial-biometrics-training-dataset-leads-to-bipa-lawsuits-against-amazon-alphabet-and-microsoft)\n* [Jul 2020 - POLICE SURVEILLED GEORGE FLOYD PROTESTS WITH HELP FROM TWITTER-AFFILIATED STARTUP DATAMINR](https://theintercept.com/2020/07/09/twitter-dataminr-police-spy-surveillance-black-lives-matter-protests/)\n* [Jul 2020 - AI-Powered \u2018Genderify\u2019 Platform Shut Down After Bias-Based Backlash](https://syncedreview.com/2020/07/30/ai-powered-genderify-platform-shut-down-after-bias-based-backlash/)\n* [Aug 2020 - Police use of facial recognition unlawfully breached privacy rights, says Court of Appeal ruling](https://news.sky.com/story/police-use-of-facial-recognition-unlawfully-breached-privacy-rights-says-court-of-appeal-ruling-12047012)\n* [Aug 2020 - There is nothing 'fair' about judging A-levels by algorithm](https://www.telegraph.co.uk/opinion/2020/08/12/nothing-fair-judging-a-levels-algorithm/)\n* [Aug 2020 - When algorithms define kids by postcode: UK exam results chaos reveal too much reliance on data analytics](https://www.zdnet.com/article/when-algorithms-define-kids-by-postcode-uk-exam-results-chaos-reveal-too-much-reliance-on-data-analytics/)\n* [Aug 2020 - Macy\u2019s hit with privacy lawsuit over alleged use of controversial facial recognition software](https://www.chicagotribune.com/business/ct-biz-macys-lawsuit-clearview-facial-recognition-20200811-mstcyf7wufdjvbanpv6ehjtvni-story.html)\n* [Aug 2020 - Google\u2019s Advertising Platform Is Blocking Articles About Racism](https://slate.com/technology/2020/08/googles-ad-exchange-blocking-articles-about-racism.html) \n* [Aug 2020 - Home Office drops 'racist' algorithm from visa decisions](https://www.bbc.com/news/technology-53650758)\n* [Aug 2020 - De Blasio Will Reassess NYPD's Use Of Facial Recognition Tech After Protester Arrest](https://gothamist.com/news/de-blasio-will-reassess-nypds-use-facial-recognition-tech-after-protester-arrest)\n* [Aug 2020 - Facebook algorithm recommending Holocaust denial and fascist content, report finds](https://www.independent.co.uk/news/uk/home-news/facebook-holocaust-denial-fascist-right-wing-algorithm-report-a9673171.html)\n* [Aug 2020 - Report: AI Company Leaks Over 2.5M Medical Records](https://www.pcmag.com/news/report-ai-company-leaks-over-25m-medical-records)\n* [Aug 2020 - Watchdog investigates Barclays for spying on staff](https://www.advisen.com/tools/fpnproc/fpns/articles_new_5/P/374532561.html)\n* [Aug 2020 - PopID\u2019s face-based payments pose privacy and security risks](https://venturebeat.com/2020/08/27/popids-face-based-payments-pose-privacy-and-security-risks/)\n* [Aug 2020 - Tinder charges older people more](https://www.choice.com.au/electronics-and-technology/internet/using-online-services/articles/tinder-plus-costs-more-if-youre-older)\n* [Aug 2020 - Uber and Lyft pricing algorithms charge more in non-white areas](https://www.newscientist.com/article/2246202-uber-and-lyft-pricing-algorithms-charge-more-in-non-white-areas/)\n* [Sep 2020 - Pasco\u2019s sheriff uses data to guess who will commit crime. Then deputies \u2018hunt down\u2019 and harass them](https://www.tampabay.com/news/pasco/2020/09/03/pascos-sheriff-uses-data-to-guess-who-will-commit-crime-then-deputies-hunt-down-and-harass-them/)\n* [Sep 2020 - The Met Police didn\u2019t check if facial recognition tech was racist before trialling it](https://tech.newstatesman.com/public-sector/the-met-police-didnt-check-if-facial-recognition-tech-was-racist-before-trialling-it)\n* [Sep 2020 - These students figured out their tests were graded by AI \u2014 and the easy way to cheat](https://www.theverge.com/2020/9/2/21419012/edgenuity-online-class-ai-grading-keyword-mashing-students-school-cheating-algorithm-glitch)\n* [Sep 2020 - Google says Street View maps algorithm error blurred out Hong Kong protest graffiti aimed at Xi Jinping](https://hongkongfp.com/2020/09/07/google-says-street-view-maps-algorithm-error-blurred-out-hong-kong-protest-graffiti-aimed-at-xi-jinping/)\n* [Sep 2020 - AI attempts to ease fear of robots, blurts out it can\u2019t \u2018avoid destroying humankind\u2019](https://www.skynews.com.au/details/_6189352902001)\n* [Sep 2020 - Ola is facing a drivers\u2019 legal challenge over data access rights and algorithmic management](https://techcrunch.com/2020/09/10/ola-is-facing-a-drivers-legal-challenge-over-data-access-rights-and-algorithmic-management/)\n* [Sep 2020 - Instagram apologizes for removing images of Black British model](https://www.thejakartapost.com/life/2020/09/12/instagram-apologizes-for-removing-images-of-black-british-model.html)\n* [Sep 2020 - Tesla owner in Canada charged with \u2018sleeping\u2019 while driving over 90 mph](https://www.theverge.com/2020/9/18/21445168/tesla-driver-sleeping-police-charged-canada-autopilot)\n* [Sep 2020 - Female historians and male nurses do not exist, Google Translate tells its European users](https://algorithmwatch.org/en/story/google-translate-gender-bias/)\n* [Sep 2020 - Twitter is looking into why its photo preview appears to favor white faces over Black faces](https://www.theverge.com/2020/9/20/21447998/twitter-photo-preview-white-black-faces)\n* [Sep 2020 - Facebook Live\u2019s New Music Terms of Service Unfairly Impact Artists](https://news.bloomberglaw.com/ip-law/facebook-lives-new-music-terms-of-service-unfairly-impact-artists)\n* [Sep 2020 - CoreLogic\u2019s screening algorithm may have discriminated against renters: lawsuit](https://therealdeal.com/2020/09/25/corelogics-screening-algorithm-may-have-discriminated-against-renters-lawsuit/)\n* [Sep 2020 - Gradient Photo Editing App Criticized Over 'Racist' AI Face Feature](https://screenrant.com/gradient-photo-editing-app-racist-ai-face-feature/)\n* [Sep 2020 - ExamSoft\u2019s remote bar exam sparks privacy and facial recognition concerns](https://venturebeat.com/2020/09/29/examsofts-remote-bar-exam-sparks-privacy-and-facial-recognition-concerns/)\n* [Sep 2020 - \"Trustworthiness\" Study Is Basically Phrenology, Annoying Scientists, Historians, Just About Everyone](https://www.iflscience.com/technology/trustworthiness-study-is-basically-phrenology-annoying-scientists-historians-just-about-everyone/)\n* [Sep 2020 - IBM faces another age-discrimination lawsuit in Austin](https://www.bizjournals.com/austin/news/2020/09/29/ibm-hit-with-another-age-discrimination-lawsuit.html)\n* [Sep 2020 - Your favorite A.I. language tool is toxic](https://fortune.com/2020/09/29/artificial-intelligence-openai-gpt3-toxic/)\n* [Sep 2020 - Catching Amazon in a lie](https://www.revealnews.org/episodes/catching-amazon-in-a-lie/)\n* [Sep 2020 - Tweet: \"A faculty member has been asking how to stop Zoom from removing his head ...\"](https://twitter.com/colinmadland/status/1307111818981146626) (Zoom erasing darker-skinned professor's head)\n* [Sep 2020 - Whistleblowers charge CEO of NJ firm with inflating AI capability, calling employees \u201cdirty Indians\u201d](https://medcitynews.com/2020/09/whistleblowers-charge-ceo-of-nj-firm-with-inflating-ai-capability-calling-employees-dirty-indians/?rf=1)\n* [Oct 2020 - Jewish Baby Stroller Image Algorithm](https://www.timebulletin.com/jewish-baby-stroller-image-algorithm/)\n* [Oct 2020 - Instagram blames GDPR for failure to tackle rampant self-harm and eating-disorder images](https://www.telegraph.co.uk/technology/2020/10/04/exclusive-instagram-blames-gdpr-failure-tackle-rampant-self/)\n* [Oct 2020 - UK passport photo checker shows bias against dark-skinned women](https://www.bbc.co.uk/news/amp/technology-54349538)\n* [Oct 2020 - States Say the Online Bar Exam Was a Success. The Test-Taker Who Peed in His Seat Disagrees](https://www.law.com/2020/10/07/states-say-the-online-bar-exam-was-a-success-the-test-taker-who-peed-in-his-seat-disagrees/)\n* [Oct 2020 - Tiny Changes Let False Claims About COVID-19, Voting Evade Facebook Fact Checks](https://www.npr.org/2020/10/09/921791419/tiny-changes-let-false-claims-about-covid-19-voting-evade-facebook-fact-checks)\n* [Oct 2020 - Leaving Cert: Why the Government deserves an F for algorithms](https://www.irishtimes.com/business/technology/leaving-cert-why-the-government-deserves-an-f-for-algorithms-1.4374801)\n* [Oct 2020 - Lawsuit alleges biometric privacy violations from face recognition algorithm training](https://www.biometricupdate.com/202010/lawsuit-alleges-biometric-privacy-violations-from-face-recognition-algorithm-training)\n* [Oct 2020 - You\u2019re being watched: The dangers of ProctorU](http://udreview.com/youre-being-watched-the-dangers-of-proctoru/)\n* [Oct 2020 - Fake naked photos of thousands of women shared online](https://www.bbc.com/news/technology-54584127) \n* [Oct 2020 - Researchers find evidence of racial, gender, and socioeconomic bias in chest X-ray classifiers](https://venturebeat.com/2020/10/21/researchers-find-evidence-of-racial-gender-and-socioeconomic-bias-in-chest-x-ray-classifiers/)\n* [Oct 2020 - Uber sued by drivers over \u2018automated robo-firing'](https://www.bbc.com/news/business-54698858)\n* [Oct 2020 - How an Algorithm Blocked Kidney Transplants to Black Patients](https://www.wired.com/story/how-algorithm-blocked-kidney-transplants-black-patients/)\n* [Oct 2020 - Australian researchers have shown how you could become invisible to security cameras](https://www.theaustralian.com.au/business/technology/australian-researchers-at-data61-show-you-could-become-invisible-to-a-security-camera/news-story/491b70e05c8fbdd566c1b2fd30b6d427)\n* [Oct 2020 - EPIC files lawsuit to force release of ICE facial recognition documents](https://www.biometricupdate.com/202010/epic-files-lawsuit-to-force-release-of-ice-facial-recognition-documents)\n* [Oct 2020 - Researchers take a stand on algorithm design for job centers: Landing a job isn't always the right goal](https://www.sciencedaily.com/releases/2020/10/201029105001.htm)\n* [Oct 2020 - Facebook under fire for boosting right-wing news sources and throttling progressive alternatives](https://www.salon.com/2020/10/29/facebook-under-fire-for-boosting-right-wing-news-sources-and-throttling-progressive-alternatives/)\n* [Oct 2020 - AI Camera Ruins Soccer Game For Fans After Mistaking Referee's Bald Head For Ball](https://www.iflscience.com/technology/ai-camera-ruins-soccar-game-for-fans-after-mistaking-referees-bald-head-for-ball/)\n* [Oct 2020 - Researchers made an OpenAI GPT-3 medical chatbot as an experiment. It told a mock patient to kill themselves](https://www.theregister.com/2020/10/28/gpt3_medical_chatbot_experiment/)\n* [Oct 2020 - Top doctors slam Google for not backing up incredible claims of super-human cancer-spotting AI](https://www.theregister.com/2020/10/16/google_ai_research/)\n* [Nov 2020 - Researchers show that computer vision algorithms pretrained on ImageNet exhibit multiple, distressing biases](https://venturebeat.com/2020/11/03/researchers-show-that-computer-vision-algorithms-pretrained-on-imagenet-exhibit-multiple-distressing-biases/)\n* [Nov 2020 - Trivago loses appeal over misleading website algorithm ruling](https://www.zdnet.com/article/trivago-loses-appeal-over-misleading-website-algorithm-ruling/)\n* [Nov 2020 - Research finds gender bias within state funding model](https://kobi5.com/news/local-news/research-finds-gender-bias-within-state-funding-model-140286/)\n* [Nov 2020 - Split-Second 'Phantom' Images Can Fool Tesla's Autopilot](https://www.wired.com/story/tesla-model-x-autopilot-phantom-images/)\n* [Nov 2020 - Boris executes U-turn over controversial house building algorithm](https://thenegotiator.co.uk/boris-executes-u-turn-over-controversial-house-building-algorithm/)\n* [Nov 2020 - Top intel official warns of bias in military algorithms](https://www.c4isrnet.com/artificial-intelligence/2020/11/18/top-intel-official-warns-of-bias-in-military-algorithms/)\n* [Nov 2020 - Opinion: Artificial 'Intelligence': Unemployment system denied legitimate COVID-19 claims](https://www.detroitnews.com/story/opinion/2020/11/19/opinion-unemployment-system-denied-legitimate-covid-19-claims/6339115002/)\n* [Nov 2020 - LAPD ban facial recognition following alleged unauthorised use](https://iottechnews.com/news/2020/nov/19/lapd-ban-facial-recognition-unauthorised-use/)\n* [Nov 2020 - Instagram removed 80 PER CENT less graphic content about suicide during the first three months of lockdown after 'most of its moderators were sent home due to Covid rules'](https://www.dailymail.co.uk/news/article-8969151/Instagram-removed-80-CENT-graphic-content-suicide.html)\n* [Nov 2020 - \t\nFacebook's AI Mistakenly Bans Ads for Struggling Businesses](https://www.bloomberg.com/news/articles/2020-11-27/facebook-s-ai-mistakenly-bans-ads-for-struggling-businesses)\n* [Nov 2020 - A Bot Made Frank Sinatra Cover Britney Spears. YouTube Removed It Over Copyright Claims.](https://futurism.com/bot-frank-sinatra-britney-spears-youtube-copyright)\n* [Nov 2020 - Net exposure \"94-year-old man was picked up for facial recognition\" The bank involved apologized](https://m.news.cctv.com/2020/11/23/ARTI4quWfQGGMIdgx5jojaaj201123.shtml)\n* [Nov 2020 - Walmart Scraps Plan to Have Robots Scan Shelves](https://www.wsj.com/articles/walmart-shelves-plan-to-have-robots-scan-shelves-11604345341)\n* [Dec 2020 - Concern over potential gender bias in job recruitment algorithms](https://www.abc.net.au/news/2020-12-02/potential-gender-bias-in-job-recruitment-application-algorithms/12943832?nw=0)\n* [Dec 2020 - Facial Recognition Company Lied to School District About its Racist Tech](https://www.vice.com/en/article/qjpkmx/fac-recognition-company-lied-to-school-district-about-its-racist-tech)\n* [Dec 2020 - China\u2019s Huawei tested A.I. software that could identify Uighur Muslims and alert police, report says](https://www.cnbc.com/2020/12/09/chinas-huawei-tested-ai-software-that-could-identify-uighurs-report.html)\n* [Dec 2020 - We\u2019ve Known Brand Safety Tech Was Bad\u2014Here\u2019s How Bad](https://www.forbes.com/sites/augustinefou/2020/12/06/weve-known-brand-safety-tech-was-bad-this-is-how-badly-it-defunds-the-news)\n* [Dec 2020 - Hey Alexa, what's my PIN?](https://www.dailymail.co.uk/sciencetech/article-9029811/Hey-Alexa-whats-PIN-Voice-assistants-figure-taps-smartphone-keyboard.html)\n* [Dec 2020 - Waze sent commuters toward California wildfires, drivers say](https://www.usatoday.com/story/tech/news/2017/12/07/california-fires-navigation-apps-like-waze-sent-commuters-into-flames-drivers/930904001/)\n* [Dec 2020 - The Death and Life of an Admissions Algorithm](https://www.insidehighered.com/admissions/article/2020/12/14/u-texas-will-stop-using-controversial-algorithm-evaluate-phd)\n* [Dec 2020 - Algorithms searching for child abuse could be banned under new EU privacy rules](https://www.telegraph.co.uk/technology/2020/12/20/algorithms-searching-child-abuse-could-banned-new-eu-privacy/)\n* [Dec 2020 - Alibaba \u2018dismayed\u2019 by its cloud unit\u2019s ethnicity detection algorithm](https://techcrunch.com/2020/12/17/alibaba-ethnic-minority-algorithm/)\n* [Dec 2020 - Congress wants answers from Google about Timnit Gebru\u2019s firing](https://www.technologyreview.com/2020/12/17/1014994/congress-wants-answers-from-google-about-timnit-gebrus-firing/)\n* [Dec 2020 - California Bar Exam Flagged A THIRD Of Applicants As Cheating](https://abovethelaw.com/2020/12/california-bar-exam-flagged-a-third-of-applicants-as-cheating/?rf=1)\n* [Dec 2020 - TikTok videos that promote anorexia are misspelling common hashtags to beat the 'pro-ana' ban](https://www.insider.com/tiktok-bans-six-accounts-posting-eating-disorder-content)\n* [Dec 2020 - Facial Recognition Blamed For False Arrest And Jail Time](https://www.silicon.co.uk/e-regulation/facial-recognition-false-arrest-349782?cmpredirect)\n* [Dec 2020 - Girl, 12, is suing social media giant TikTok for alleged misuse of personal information and breaches of data protection laws](https://www.dailymail.co.uk/news/article-9100755/Girl-12-suing-TikTok-alleged-misuse-personal-information-data-protection-law-breaches.html)\n* [Dec 2020 - TikTok Deleted My Account Because I\u2019m a Latina Trans Woman](https://www.losangelesblade.com/2020/12/15/tiktok-deleted-my-account-because-im-a-latina-trans-woman/)\n* [Dec 2020 - Shopping mall robot fell off the escalator and knocked down passengers](https://s.weibo.com/weibo?q=%23%E5%95%86%E5%9C%BA%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%8E%89%E4%B8%8B%E6%89%B6%E6%A2%AF%E6%92%9E%E5%80%92%E4%B9%98%E5%AE%A2%23&from=default)\n* [Dec 2020 - Stanford apologizes for coronavirus vaccine plan that left out many front-line doctors](https://www.washingtonpost.com/health/2020/12/18/stanford-hospital-protest-covid-vaccine/)\n* [Dec 2020 - The Christchurch Shooter and YouTube\u2019s Radicalization Trap](https://www.wired.com/story/christchurch-shooter-youtube-radicalization-extremism/)\n* [Jan 2021 - Italian court rules against \u2018discriminatory\u2019 Deliveroo rider-ranking algorithm](https://techcrunch.com/2021/01/04/italian-court-rules-against-discriminatory-deliveroo-rider-ranking-algorithm/)\n* [Jan 2021 - A business owner who spent nearly $46 million on Facebook advertising says he's been booted from the platform without explanation](https://www.businessinsider.com/facebook-removed-shared-ceo-spent-46-million-on-ads-2021-1)\n* [Jan 2021 - FTC Orders Photo App to Delete Algorithms Built on Personal Data](https://epic.org/2021/01/ftc-orders-photo-app-to-delete.html)\n* [Jan 2021 - South Korean AI chatbot pulled from Facebook after hate speech towards minorities](https://www.theguardian.com/world/2021/jan/14/time-to-properly-socialise-hate-speech-ai-chatbot-pulled-from-facebook)\n* [Jan 2021 - Google Hit With $2B Antitrust Suit Over 'Rigging' Its Algorithm](https://www.law360.com/media/articles/1343696/google-hit-with-2b-antitrust-suit-over-rigging-its-algorithm)\n* [Jan 2021 - Judge Orders NJ Education Department To Turn Over S2 Algorithm](https://patch.com/new-jersey/brick/judge-orders-nj-education-department-turn-over-s2-algorithm)\n* [Jan 2021 - When an Israeli Farmer Declared War on an Algorithm](https://www.haaretz.com/israel-news/tech-news/.premium-when-an-israeli-farmer-declared-war-on-an-algorithm-1.9440728)\n* [Jan 2021 - Job Screening Service Halts Facial Analysis of Applicants](https://www.wired.com/story/job-screening-service-halts-facial-analysis-applicants/)\n* [Jan 2021 - Use of facial recognition tech sparks privacy fears](https://www.livemint.com/technology/tech-news/use-of-facial-recognition-tech-sparks-privacy-fears-11611536778871.html)\n* [Jan 2021 - South Korea has used AI to bring a dead superstar's voice back to the stage, but ethical concerns abound](https://www.kmov.com/south-korea-has-used-ai-to-bring-a-dead-superstars-voice-back-to-the-stage/article_f9df111e-b879-5c9e-80c9-aec19cbedc28.html?block_id=985917)\n* [Jan 2021 - SEC Orders BlueCrest to Pay $170 Million to Harmed Fund Investors](https://www.sec.gov/news/press-release/2020-308)\n* [Jan 2021 - University of Illinois to Discontinue Remote-Testing Software After Students Complain of Privacy Violation](https://www.techtimes.com/articles/256488/20210129/university-illinois-discontinue-remote-testing-software-students-complain-privacy-violation.htm)\n* [Jan 2021 - Amazon algorithms boost vaccine misinformation, says study](https://www.iol.co.za/technology/fintech/amazon-algorithms-boost-vaccine-misinformation-says-study-dc2105b8-dc86-4392-bc55-6555fe1dc77e)\n* [Jan 2021 - Patent applications listing AI as an inventor run into legal problems](https://www.chemistryworld.com/news/patent-applications-listing-ai-as-an-inventor-run-into-legal-problems/4013138.article)\n* [Jan 2021 - BIPOC students face disadvantages with exam monitoring software at the University of Toronto](https://thestrand.ca/bipoc-students-face-disadvantages-with-exam-monitoring-software-at-the-university-of-toronto/)\n* [Jan 2021 - \u2018for Some Reason I\u2019m Covered in Blood\u2019: Gpt-3 Contains Disturbing Bias Against Muslims](https://onezero.medium.com/for-some-reason-im-covered-in-blood-gpt-3-contains-disturbing-bias-against-muslims-693d275552bf)\n* [Feb 2021 - Utah audit of Banjo deal highlights concerns with AI, government contracts](https://www.ksl.com/article/50099679/utah-audit-of-banjo-deal-highlights-concerns-with-large-government-tech-agreements)\n* [Feb 2021 - Lingerie company Adore Me calls out TikTok for removing videos of Black, plus-size models](https://www.usatoday.com/story/tech/2021/02/05/tiktok-slammed-removing-videos-adore-me-black-plus-size-models/4402625001/)\n* [Feb 2021 - \u2018Orwellian\u2019 AI lie detector project challenged in EU court](https://techcrunch.com/2021/02/05/orwellian-ai-lie-detector-project-challenged-in-eu-court)\n* [Feb 2021 - Clearview AI\u2019s facial recognition technology violated federal and regional laws \u2013 RCI](https://thedailyguardian.net/clearview-ais-facial-recognition-technology-violated-federal-and-regional-laws-rci/)\n* [Feb 2021 - Beverly Hills cops try to weaponize Instagram\u2019s algorithms in failed attempt to thwart live streamers](https://thenextweb.com/neural/2021/02/09/beverly-hills-cops-try-to-weaponize-instagrams-algorithms-in-failed-attempt-to-thwart-live-streamers/)\n* [Feb 2021 - AI displays bias and inflexibility in civility detection, study finds](https://venturebeat.com/2021/02/10/ai-displays-bias-and-inflexibility-in-civility-detection-study-finds/)\n* [Feb 2021 - Why Is Facebook Rejecting These Fashion Ads?](https://www.nytimes.com/2021/02/11/style/disabled-fashion-facebook-discrimination.html)\n* [Feb 2021 - Sweden\u2019s data watchdog slaps police for unlawful use of Clearview AI](https://techcrunch.com/2021/02/12/swedens-data-watchdog-slaps-police-for-unlawful-use-of-clearview-ai/)\n* [Feb 2021 - AI-Wielding Hackers are Here](https://www.datacenterknowledge.com/security/ai-wielding-hackers-are-here)\n* [Feb 2021 - How Google Scholar Sidelines Research in Non\u2011English Languages](https://theswaddle.com/how-google-scholar-sidelines-research-in-non-english-languages/)\n* [Feb 2021 - DWP uses excessive surveillance on suspected fraudsters, report finds](https://www.theguardian.com/society/2021/feb/14/dwp-excessive-surveillance-on-suspected-fraudsters-privacy-international)\n* [Feb 2021 - Canada Rules Clearview\u2019s AI Scraping is Unlawful](https://www.hstoday.us/industry/canada-rules-clearviews-ai-scraping-is-unlawful/)\n* [Feb 2021 - INVESTIGATION: Facebook, Twitter Struggling in Fight against Balkan Content Violations](https://balkaninsight.com/2021/02/16/facebook-twitter-struggling-in-fight-against-balkan-content-violations/)\n* [Feb 2021 - Google slapped in France over misleading hotel star ratings](https://techcrunch.com/2021/02/15/google-slapped-in-france-over-misleading-hotel-star-ratings/)\n* [Feb 2021 - Colleagues of mine analyzed A.I.-based job interviews ...](https://twitter.com/hatr/status/1362129235297660929) (Tweet)\n* [Feb 2021 - YouTuber blocked for discussing 'black versus white' chess strategy](https://www.dailymail.co.uk/sciencetech/article-9279473/YouTube-algorithm-accidentally-blocked-chess-player-discussing-black-versus-white-strategy.html)\n* [Feb 2021 - Teaneck just banned facial recognition technology for police. Here's why](https://www.northjersey.com/story/news/bergen/teaneck/2021/02/25/teaneck-nj-bans-facial-recognition-usage-police-citing-bias/6802839002/)\n* [Feb 2021 - TikTok agrees to pay $92 million to settle teen privacy class-action lawsuit](https://www.zdnet.com/article/tiktok-agrees-to-pay-92-million-to-settle-teen-privacy-class-action-lawsuit/)\n* [Feb 2021 - Google fires top ethical AI expert Margaret Mitchell](https://www.zdnet.com/article/google-fires-top-ethical-ai-expert-margaret-mitchell/)\n* [Mar 2021 - UP Uses Facial Recognition Technology to Mete Out Discriminatory Treatment](https://www.theleaflet.in/up-uses-facial-recognition-technology-to-mete-out-discriminatory-treatment/#)\n* [Mar 2021 - Chatbots that resurrect the dead: legal experts weigh in on \u2018disturbing\u2019 technology](https://theconversation.com/chatbots-that-resurrect-the-dead-legal-experts-weigh-in-on-disturbing-technology-155436)\n* [Mar 2021 - \u201cIt\u2019s all the real thing,\u201d Tom Cruise insists, looking into the camera ...](https://twitter.com/thetimes/status/1366442334544658432)\n* [Mar 2021 - OpenAI\u2019s state-of-the-art machine vision AI is fooled by handwritten notes](https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron)\n* [Mar 2021 - Major Universities are Using Race as a \u201cHigh Impact Predictor\u201d of Student Success \u2013 The Markup\n](https://themarkup.org/news/2021/03/02/major-universities-are-using-race-as-a-high-impact-predictor-of-student-success)\n* [Mar 2021 - Instagram Suggested Posts To Users. It Served Up COVID-19 Falsehoods, Study Finds](https://www.npr.org/2021/03/09/975032249/instagram-suggested-posts-to-users-it-served-up-covid-19-falsehoods-study-finds)\n* [Mar 2021 - Tenant screening software faces national reckoning](https://www.nbcnews.com/tech/tech-news/tenant-screening-software-faces-national-reckoning-n1260975)\n* [Mar 2021 - Instagram algorithm recommends far-right parties and Covid conspiracy theories to users](https://www.thetimes.co.uk/article/instagram-algorithm-recommends-far-right-parties-and-covid-conspiracy-theories-to-users-qjthq2xtg)\n* [Mar 2021 - Google image search cements national stereotypes of 'racy' women](https://www.dw.com/en/google-image-search-cements-national-stereotypes-of-racy-women/a-56767605)\n* [Mar 2021 - Time-Out for Google](https://www.insidehighered.com/news/2021/03/09/tech-transparency-conference-suspends-google-sponsorship-over-transparency-concerns)\n* [Mar 2021 - Apple Censors URLs Containing \u201cAsian\u201d with Adult Filters](https://www.mcgilldaily.com/2021/03/apple-censors-urls-containing-asian-with-adult-filters/)\n* [Mar 2021 - Underpaid Workers Are Being Forced to Train Biased AI on Mechanical Turk](https://www.vice.com/en/article/88apnv/underpaid-workers-are-being-forced-to-train-biased-ai-on-mechanical-turk)\n* [Mar 2021 - New Study Reveals Coded Language Used to Fuel Anti-Semitism Online](https://thejewishvoice.com/2021/03/new-study-reveals-coded-language-used-to-fuel-anti-semitism-online/)\n* [Mar 2021 - Judge tells state to deliver records](https://www.arkansasonline.com/news/2021/mar/04/judge-tells-state-deliver-records/)\n* [Mar 2021 - Pennsylvania Woman Accused of Using Deepfake Technology to Harass Cheerleaders](https://www.nytimes.com/2021/03/14/us/raffaela-spone-victory-vipers-deepfake.html)\n* [Mar 2021 - Fears of 'digital dictatorship' as Myanmar deploys artificial intelligence](https://www.straitstimes.com/asia/se-asia/fears-of-digital-dictatorship-as-myanmar-deploys-artificial-intelligence)\n* [Mar 2021 - Amazon driver quits, saying the final straw was the company's new AI-powered truck cameras that can sense when workers yawn or don't use a seatbelt](https://news.yahoo.com/amazon-driver-quits-saying-final-164140625.html)\n* [Mar 2021 - INSTA-KID Fury over Facebook plot to make NEW Instagram for under 13s \u2013 as parents brand it \u2018dangerous\u2019](https://www.thesun.co.uk/tech/14389470/instagram-for-kids-under-13-plans/)\n* [Mar 2021 - How AI lets bigots and trolls flourish while censoring LGBTQ+ voices](https://www.mic.com/p/how-ai-lets-bigots-trolls-flourish-while-censoring-lgbtq-voices-66661864)\n* [Mar 2021 - Music recommendation algorithms are unfair to female artists, but we can change that](https://theconversation.com/music-recommendation-algorithms-are-unfair-to-female-artists-but-we-can-change-that-158016)\n* [Mar 2021 - Couriers say Uber\u2019s \u2018racist\u2019 facial identification tech got them fired](https://www.wired.co.uk/article/uber-eats-couriers-facial-recognition)\n* [Mar 2021 - Major flaws found in machine learning for COVID-19 diagnosis](https://venturebeat.com/2021/03/23/major-flaws-found-in-machine-learning-for-covid-19-diagnosis/)\n* [Mar 2021 - How a Stabbing in Israel Echoes Through the Fight Over Online Speech](https://www.nytimes.com/2021/03/24/technology/section-230-hearing-facebook.html)\n* [Apr 2021 - Researchers have found that even the best Speech recognition systems are actually biased](https://www.digitalinformationworld.com/2021/04/researchers-have-found-that-even-best.html)\n* [Apr 2021 - Research says Facebook's ad algorithm perpetuates gender bias](https://theintercept.com/2021/04/09/facebook-algorithm-gender-discrimination/) (see also [Research Outputs from Auditing for Discrimination in Job Ad Delivery](https://ant.isi.edu/datasets/addelivery/) on the USC Information Sciences Institute web site)\n* [Apr 2021 - Google AI chief Samy Bengio resigns over colleagues' firing and racial discrimination](https://www.wionews.com/technology/google-ai-chief-samy-bengio-resigns-over-colleagues-firing-and-racial-discrimination-375828)\n* [Apr 2021 - How medicine discriminates against non-white people and women](https://www.economist.com/science-and-technology/2021/04/08/how-medicine-discriminates-against-non-white-people-and-women)\n* [Apr 2021 - In scramble to respond to Covid-19, hospitals turned to models with high risk of bias](https://medcitynews.com/2021/04/in-scramble-to-respond-to-covid-19-hospitals-turned-to-models-with-high-risk-of-bias/)\n* [Apr 2021 - Home Office algorithm to detect sham marriages may contain built-in discrimination](https://www.thebureauinvestigates.com/stories/2021-04-19/home-office-algorithm-sham-marriages)\n* [Apr 2021 - Google translation AI botches legal terms 'enjoin,' 'garnish' -research](https://www.reuters.com/technology/google-translation-ai-botches-legal-terms-enjoin-garnish-research-2021-04-19/)\n* [Apr 2021 - Some FDA-approved AI medical devices are not \u2018adequately\u2019 evaluated, Stanford study says](https://venturebeat.com/2021/04/12/some-fda-approved-ai-medical-devices-are-not-adequately-evaluated-stanford-study-says/)\n* [Apr 2021 - Instagram apologises for mistake which targeted users with harmful diet content](https://www.harpersbazaar.com/uk/culture/culture-news/a36128394/instagram-harmful-diet-content/)\n* [Apr 2021 - Facebook, Princeton Must Face AI Data Theft Claims](https://www.law360.com/ip/articles/1375537/facebook-princeton-must-face-ai-data-theft-claims)\n* [Apr 2021 - Facebook sued for failing to remove anti-Muslim hate speech](https://www.thehindu.com/sci-tech/technology/internet/facebook-sued-for-failing-to-remove-anti-muslim-hate-speech/article34281168.ece)\n* [Apr 2021 - Post Office scandal: What the Horizon saga is all about](https://www.bbc.com/news/business-56718036)\n* [Apr 2021 - Facebook, Twitter, YouTube are pressed on \u2018poisonous\u2019 algorithms](https://www.latimes.com/business/technology/story/2021-04-27/facebook-twitter-youtube-pressed-on-poisonous-algorithms)\n* [Apr 2021 - BLACK MAN USES PASSPORT PHOTO AS EVIDENCE AI IS \u2018RACIST\u2019 IN VIRAL TIKTOK](https://www.independent.co.uk/life-style/ai-racist-robots-algorithm-tiktok-b1838521.html)\n* [Apr 2021 - Twitter allows \u2018Uncle Tim\u2019 to trend for hours after Sen. Tim Scott\u2019s rebuttal, and then took action](https://nypost.com/2021/04/29/sen-tim-scott-attacked-as-uncle-tim-on-twitter-after-gop-rebuttal/)\n* [Apr 2021 - Suicide Risk Prediction Models Could Perpetuate Racial Disparities](https://healthitanalytics.com/news/suicide-risk-prediction-models-could-perpetuate-racial-disparities)\n* [May 2021 - Amsterdam Court orders reinstatement of Uber drivers dismissed by algorithm](https://ukhumanrightsblog.com/2021/05/18/amsterdam-court-orders-reinstatement-of-uber-drivers-dismissed-by-algorithm/)\n* [May 2021 - This facial recognition website can turn anyone into a cop \u2014 or a stalker](https://www.washingtonpost.com/technology/2021/05/14/pimeyes-facial-recognition-search-secrecy/)\n* [May 2021 - Why you should be very wary of AI that \u2018processes\u2019 college video applications](https://thenextweb.com/news/why-you-should-be-very-wary-of-ai-that-processes-college-video-applications)\n* [May 2021 - Airbnb pricing algorithm led to increased racial disparities, study finds](https://www.ft.com/content/5b1471e0-ed4a-47f5-8f3f-0a1ee7f7999c)\n* [May 2021 - Uber commits crime using algorithms](https://www.newframe.com/uber-commits-crime-using-algorithms/).\n* [May 2021 - Deepfake detectors and datasets exhibit racial and gender bias, USC study shows](https://venturebeat.com/2021/05/06/deepfake-detectors-and-datasets-exhibit-racial-and-gender-bias-usc-study-shows/)\n* [May 2021 - TikTok\u2019s recommendation algorithm is promoting homophobia and anti-trans violence](https://www.losangelesblade.com/2021/05/18/tiktoks-recommendation-algorithm-is-promoting-homophobia-and-anti-trans-violence/)\n* [May 2021 - \u2018Grassroots\u2019 bot campaigns are coming. Governments don\u2019t have a plan to stop them](https://www.washingtonpost.com/outlook/2021/05/20/ai-bots-grassroots-astroturf/)\n* [May 2021 - Workplace and algorithm bias kill Palestine content on Facebook and Twitter](https://www.trtworld.com/magazine/workplace-and-algorithm-bias-kill-palestine-content-on-facebook-and-twitter-46842) \n* [May 2021 - Suit seeks to limit anti-Muslim speech on Facebook but roots of Islamophobia run far deeper](https://theconversation.com/suit-seeks-to-limit-anti-muslim-speech-on-facebook-but-roots-of-islamophobia-run-far-deeper-159418)\n* [May 2021 - AI emotion-detection software tested on Uyghurs](https://www.bbc.com/news/technology-57101248)\n* [May 2021 - An Insurance Startup Bragged It Uses AI to Detect Fraud. It Didn\u2019t Go Well](https://www.vice.com/en/article/z3x47y/an-insurance-startup-bragged-it-uses-ai-to-detect-fraud-it-didnt-go-well)\n* [May 2021 - Google's new AI skincare tool may not work on patients with darker skin tones](https://www.euronews.com/2021/05/26/google-s-new-ai-skincare-tool-may-not-work-on-patients-with-darker-skin-tones)\n* [May 2021 - Minn. Police Use of Facial Recognition Leads to Concerns](https://www.govtech.com/public-safety/minn-police-use-of-facial-recognition-leads-to-concerns)\n* [May 2021 - Facial recognition: Legal complaints lodged against Clearview AI in five countries](https://www.computing.co.uk/news/4032109/facial-recognition-legal-complaints-lodged-clearview-ai-countries)\n* [Jun 2021 - A Military Drone With A Mind Of Its Own Was Used In Combat, U.N. Says](https://www.npr.org/2021/06/01/1002196245/a-u-n-report-suggests-libya-saw-the-first-battlefield-killing-by-an-autonomous-d)\n* [Jun 2021 - Senate Democrats Urge Google To Investigate Racial Bias In Its Tools And The Company](https://www.npr.org/2021/06/02/1002525048/senate-democrats-to-google-investigate-racial-bias-in-your-tools-and-company)\n* [Jun 2021 - McDonald\u2019s Taking Voiceprints at Drive-Throughs Illinois BIPA Class Action](https://classactionsreporter.com/mcdonalds-taking-voiceprints-at-drive-throughs-illinois-bipa-class-action/)\n* [Jun 2021 - Legal notice to Hyderabad Police Commissioner highlights lack of lawfulness of facial recognition measures](https://www.medianama.com/2021/06/223-hyderabad-police-facial-recognition-surveillance-masood/)\n* [Jun 2021 - ATER ALERT: The Klein Law Firm Announces a Lead Plaintiff Deadline of July 12, 2021 in the Class Action Filed on Behalf of Aterian, Inc. Limited Shareholders](https://finance.yahoo.com/news/ater-alert-klein-law-firm-002300149.html)\n* [Jun 2021 - Have Google\u2019s Algorithm Updates Broken the Web?](https://centralrecorder.com/have-googles-algorithm-updates-broken-the-web/)\n* [Jun 2021 - How Airbnb failed its own anti-discrimination team\u2014and let racial disparities slip through the cracks](https://www.morningbrew.com/emerging-tech/stories/2021/06/15/airbnb-failed-antidiscrimination-teamand-let-racial-disparities-slip-cracks)\n* [Jun 2021 - Facial Recognition Failures Are Locking People Out of Unemployment Systems](https://www.vice.com/en/article/5dbywn/facial-recognition-failures-are-locking-people-out-of-unemployment-systems)\n",
	"chart charts data-visualization svg visualization": "# D3: Data-Driven Documents\n\n<a href=\"https://d3js.org\"><img src=\"https://d3js.org/logo.svg\" align=\"left\" hspace=\"10\" vspace=\"6\"></a>\n\n**D3** (or **D3.js**) is a JavaScript library for visualizing data using web standards. D3 helps you bring data to life using SVG, Canvas and HTML. D3 combines powerful visualization and interaction techniques with a data-driven approach to DOM manipulation, giving you the full capabilities of modern browsers and the freedom to design the right visual interface for your data.\n\n## Resources\n\n* [Introduction](https://observablehq.com/@d3/learn-d3)\n* [API Reference](https://github.com/d3/d3/blob/main/API.md)\n* [Releases](https://github.com/d3/d3/releases)\n* [Examples](https://observablehq.com/@d3/gallery)\n* [Wiki](https://github.com/d3/d3/wiki)\n\n## Installing\n\nIf you use npm, `npm install d3`. You can also download the [latest release on GitHub](https://github.com/d3/d3/releases/latest). For vanilla HTML in modern browsers, import D3 from Skypack:\n\n```html\n<script type=\"module\">\n\nimport * as d3 from \"https://cdn.skypack.dev/d3@7\";\n\nconst div = d3.selectAll(\"div\");\n\n</script>\n```\n\nFor legacy environments, you can load D3\u2019s UMD bundle from an npm-based CDN such as jsDelivr; a `d3` global is exported:\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/d3@7\"></script>\n<script>\n\nconst div = d3.selectAll(\"div\");\n\n</script>\n```\n\nYou can also use the standalone D3 microlibraries. For example, [d3-selection](https://github.com/d3/d3-selection):\n\n```html\n<script type=\"module\">\n\nimport {selectAll} from \"https://cdn.skypack.dev/d3-selection@3\";\n\nconst div = selectAll(\"div\");\n\n</script>\n```\n\nD3 is written using [ES2015 modules](http://www.2ality.com/2014/09/es6-modules-final.html). Create a custom bundle using Rollup, Webpack, or your preferred bundler. To import D3 into an ES2015 application, either import specific symbols from specific D3 modules:\n\n```js\nimport {scaleLinear} from \"d3-scale\";\n```\n\nOr import everything into a namespace (here, `d3`):\n\n```js\nimport * as d3 from \"d3\";\n```\n\nOr using dynamic import:\n\n```js\nconst d3 = await import(\"d3\");\n```\n\nYou can also import individual modules and combine them into a `d3` object using [Object.assign](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign):\n\n```js\nconst d3 = await Promise.all([\n  import(\"d3-format\"),\n  import(\"d3-geo\"),\n  import(\"d3-geo-projection\")\n]).then(d3 => Object.assign({}, ...d3));\n```\n",
	"apache canvas charting-library charts data-visualization data-viz echarts svg visualization": "# Apache ECharts\n\n<a href=\"https://echarts.apache.org/\">\n    <img style=\"vertical-align: top;\" src=\"./asset/logo.png?raw=true\" alt=\"logo\" height=\"50px\">\n</a>\n\nApache ECharts is a free, powerful charting and visualization library offering an easy way of adding intuitive, interactive, and highly customizable charts to your commercial products. It is written in pure JavaScript and based on <a href=\"https://github.com/ecomfe/zrender\">zrender</a>, which is a whole new lightweight canvas library.\n\n**[\u4e2d\u6587\u5b98\u7f51](https://echarts.apache.org/zh/index.html)** | **[ENGLISH HOMEPAGE](https://echarts.apache.org/en/index.html)**\n\n[![License](https://img.shields.io/npm/l/echarts?color=5470c6)](https://github.com/apache/echarts/blob/master/LICENSE) [![Latest npm release](https://img.shields.io/npm/v/echarts?color=91cc75)](https://www.npmjs.com/package/echarts) [![NPM downloads](https://img.shields.io/npm/dm/echarts.svg?label=npm%20downloads&style=flat&color=fac858)](https://www.npmjs.com/package/echarts) [![Contributors](https://img.shields.io/github/contributors/apache/echarts?color=3ba272)](https://github.com/apache/echarts/graphs/contributors)\n\n[![Build Status](https://github.com/apache/echarts/actions/workflows/ci.yml/badge.svg)](https://github.com/apache/echarts/actions/workflows/ci.yml)\n\n## Get Apache ECharts\n\nYou may choose one of the following methods:\n\n+ Download from the [official website](https://echarts.apache.org/download.html)\n+ `npm install echarts --save`\n+ CDN: [jsDelivr CDN](https://www.jsdelivr.com/package/npm/echarts?path=dist)\n\n## Docs\n\n+ [Get Started](https://echarts.apache.org/handbook)\n+ [API](https://echarts.apache.org/api.html)\n+ [Option Manual](https://echarts.apache.org/option.html)\n+ [Examples](https://echarts.apache.org/examples)\n\n## Get Help\n\n+ [GitHub Issues](https://github.com/apache/echarts/issues) for bug report and feature requests\n+ Email [dev@echarts.apache.org](mailto:dev@echarts.apache.org) for general questions\n+ Subscribe to the [mailing list](https://echarts.apache.org/maillist.html) to get updated with the project\n\n## Build\n\nBuild echarts source code:\n\nExecute the instructions in the root directory of the echarts:\n([Node.js](https://nodejs.org) is required)\n\n```shell\n# Install the dependencies from NPM:\nnpm install\n\n# Rebuild source code immediately in watch mode when changing the source code.\n# It opens the `./test` directory and you may open `-cases.html` to get the list\n# of all test cases.\n# If you wish to create a test case, run `npm run mktest:help` to learn more.\nnpm run dev\n\n# Check correctness of TypeScript code.\nnpm run checktype\n\n# If intending to build and get all types of the \"production\" files:\nnpm run release\n```\n\nThen the \"production\" files are generated in the `dist` directory.\n\n## Contribution\n\nIf you wish to debug locally or make pull requests, please refer to the [contributing](https://github.com/apache/echarts/blob/master/CONTRIBUTING.md) document.\n\n## Resources\n\n### Awesome ECharts\n\n[https://github.com/ecomfe/awesome-echarts](https://github.com/ecomfe/awesome-echarts)\n\n### Extensions\n\n+ [ECharts GL](https://github.com/ecomfe/echarts-gl) An extension pack of ECharts, which provides 3D plots, globe visualization, and WebGL acceleration.\n\n+ [Liquidfill \u6c34\u7403\u56fe](https://github.com/ecomfe/echarts-liquidfill)\n\n+ [Wordcloud \u5b57\u7b26\u4e91](https://github.com/ecomfe/echarts-wordcloud)\n\n+ [Extension for Baidu Map \u767e\u5ea6\u5730\u56fe\u6269\u5c55](https://github.com/apache/echarts/tree/master/extension-src/bmap) An extension provides a wrapper of Baidu Map Service SDK.\n\n+ [vue-echarts](https://github.com/ecomfe/vue-echarts) ECharts component for Vue.js\n\n+ [echarts-stat](https://github.com/ecomfe/echarts-stat) Statistics tool for ECharts\n\n## License\n\nECharts is available under the Apache License V2.\n\n## Code of Conduct\n\nPlease refer to [Apache Code of Conduct](https://www.apache.org/foundation/policies/conduct.html).\n\n## Paper\n\nDeqing Li, Honghui Mei, Yi Shen, Shuang Su, Wenli Zhang, Junting Wang, Ming Zu, Wei Chen.\n[ECharts: A Declarative Framework for Rapid Construction of Web-based Visualization](https://www.sciencedirect.com/science/article/pii/S2468502X18300068).\nVisual Informatics, 2018.\n",
	"alerting analytics business-intelligence dashboard data-visualization elasticsearch go grafana hacktoberfest influxdb metrics monitoring mysql postgres prometheus": "![Grafana](docs/logo-horizontal.png)\n\nThe open-source platform for monitoring and observability\n\n[![License](https://img.shields.io/github/license/grafana/grafana)](LICENSE)\n[![Drone](https://drone.grafana.net/api/badges/grafana/grafana/status.svg)](https://drone.grafana.net/grafana/grafana)\n[![Go Report Card](https://goreportcard.com/badge/github.com/grafana/grafana)](https://goreportcard.com/report/github.com/grafana/grafana)\n\nGrafana allows you to query, visualize, alert on and understand your metrics no matter where they are stored. Create, explore, and share dashboards with your team and foster a data-driven culture:\n\n- **Visualizations:** Fast and flexible client side graphs with a multitude of options. Panel plugins offer many different ways to visualize metrics and logs.\n- **Dynamic Dashboards:** Create dynamic & reusable dashboards with template variables that appear as dropdowns at the top of the dashboard.\n- **Explore Metrics:** Explore your data through ad-hoc queries and dynamic drilldown. Split view and compare different time ranges, queries and data sources side by side.\n- **Explore Logs:** Experience the magic of switching from metrics to logs with preserved label filters. Quickly search through all your logs or streaming them live.\n- **Alerting:** Visually define alert rules for your most important metrics. Grafana will continuously evaluate and send notifications to systems like Slack, PagerDuty, VictorOps, OpsGenie.\n- **Mixed Data Sources:** Mix different data sources in the same graph! You can specify a data source on a per-query basis. This works for even custom datasources.\n\n## Get started\n\n- [Get Grafana](https://grafana.com/get)\n- [Installation guides](https://grafana.com/docs/grafana/latest/setup-grafana/installation/)\n\nUnsure if Grafana is for you? Watch Grafana in action on [play.grafana.org](https://play.grafana.org/)!\n\n## Documentation\n\nThe Grafana documentation is available at [grafana.com/docs](https://grafana.com/docs/).\n\n## Contributing\n\nIf you're interested in contributing to the Grafana project:\n\n- Start by reading the [Contributing guide](https://github.com/grafana/grafana/blob/HEAD/CONTRIBUTING.md).\n- Learn how to set up your local environment, in our [Developer guide](https://github.com/grafana/grafana/blob/HEAD/contribute/developer-guide.md).\n- Explore our [beginner-friendly issues](https://github.com/grafana/grafana/issues?q=is%3Aopen+is%3Aissue+label%3A%22beginner+friendly%22).\n- Look through our [style guide and Storybook](https://developers.grafana.com/ui/latest/index.html).\n\n## Get involved\n\n- Follow [@grafana on Twitter](https://twitter.com/grafana/).\n- Read and subscribe to the [Grafana blog](https://grafana.com/blog/).\n- If you have a specific question, check out our [discussion forums](https://community.grafana.com/).\n- For general discussions, join us on the [official Slack](https://slack.grafana.com) team.\n\n## License\n\nGrafana is distributed under [AGPL-3.0-only](LICENSE). For Apache-2.0 exceptions, see [LICENSING.md](https://github.com/grafana/grafana/blob/HEAD/LICENSING.md).\n",
	"canvas canvas2d data-visualization game glsl javascript pixi pixijs renderer rendering rendering-2d-graphics rendering-engine webgl": "PixiJS \u2014 The HTML5 Creation Engine\n=============\n\n![pixi.js logo](https://pixijs.download/pixijs-banner-no-version.png)\n\n[![Discord](https://badgen.net/badge/icon/discord?icon=discord&label)](https://discord.gg/QrnxmQUPGV)\n[![npm version](https://badge.fury.io/js/pixi.js.svg)](https://badge.fury.io/js/pixi.js)\n[![Node.js CI](https://github.com/pixijs/pixijs/workflows/Node.js%20CI/badge.svg)](https://github.com/pixijs/pixijs/actions?query=workflow%3A%22Node.js+CI%22)\n\nThis project aims to provide a fast lightweight 2D library that works\nacross all devices. The PixiJS renderer allows everyone to enjoy the power of\nhardware acceleration without prior knowledge of WebGL. Also, it's fast. Really fast.\n\nIf you want to keep up to date with the latest PixiJS news then feel free to follow us on Twitter [@PixiJS](https://twitter.com/PixiJS)\nand we will keep you posted! You can also check back on [our site](https://www.pixijs.com)\nas any breakthroughs will be posted up there too!\n\n**We are now a part of the [Open Collective](https://opencollective.com/pixijs) and with your support you can help us make PixiJS even better. To make a donation, simply click the button below and we'll love you forever!**\n\n<div align=\"center\">\n  <a href=\"https://opencollective.com/pixijs/donate\" target=\"_blank\">\n    <img src=\"https://opencollective.com/pixijs/donate/button@2x.png?color=blue\" width=250 />\n  </a>\n</div>\n\n### What to Use PixiJS for and When to Use It\n\nPixiJS is a rendering library that will allow you to create rich, interactive graphics, cross-platform applications, and games without having to dive into the WebGL API or deal with browser and device compatibility.\n\nPixiJS has full [WebGL](https://en.wikipedia.org/wiki/WebGL) support and seamlessly falls back to HTML5's [canvas](https://en.wikipedia.org/wiki/Canvas_element) if needed. As a framework, PixiJS is a fantastic tool for authoring interactive content, *especially with the move away from Adobe Flash in recent years*. Use it for your graphics-rich, interactive websites, applications, and HTML5 games.  Out of the box, cross-platform compatibility and graceful degradation mean you have less work to do and have more fun doing it! If you want to create polished and refined experiences relatively quickly, without delving into dense, low-level code, all while avoiding the headaches of browser inconsistencies, then sprinkle your next project with some PixiJS magic!\n\n**Boost your development and feel free to use your imagination!**\n\n### Learn ###\n- Website: Find out more about PixiJS on the [official website](https://www.pixijs.com/).\n- Getting started:\n    - Check out @kittykatattack's comprehensive [tutorial](https://github.com/kittykatattack/learningPixi).\n    - Also check out @miltoncandelero's PixiJS tutorials aimed toward videogames with recipes, best practices and TypeScript / npm / webpack setup [here](https://www.pixijselementals.com/)\n- Examples: Get stuck right in and play around with PixiJS code and features right [here](https://pixijs.io/examples/)!\n- Docs: Get to know the PixiJS API by checking out the [docs](https://pixijs.io/docs/).\n- Guide: Supplementary guide to the API documentation [here](https://pixijs.io/guides/).\n- Wiki: Other misc tutorials and resources are [on the Wiki](https://github.com/pixijs/pixijs/wiki).\n\n### Community ###\n- Forums: Check out the [forum](https://www.html5gamedevs.com/forum/15-pixijs/) and [Stackoverflow](http://stackoverflow.com/search?q=pixi.js), both friendly places to ask your PixiJS questions.\n- Inspiration: Check out the [gallery](https://www.pixijs.com/gallery) to see some of the amazing things people have created!\n- Chat: You can join us on [Discord](https://discord.gg/QrnxmQUPGV) to chat about PixiJS.\n\n### Setup ###\n\nIt's easy to get started with PixiJS! Simply download a [prebuilt build](https://github.com/pixijs/pixi.js/wiki/FAQs#where-can-i-get-a-build)!\n\nAlternatively, PixiJS can be installed with [npm](https://docs.npmjs.com/getting-started/what-is-npm) or simply using a content delivery network (CDN) URL to embed PixiJS directly on your HTML page.\n\n_Note: After v4.5.0, support for the [Bower](https://bower.io) package manager has been dropped. Please see the [release notes](https://github.com/pixijs/pixi.js/releases/tag/v4.5.0) for more information._\n\n#### NPM Install\n\n```sh\nnpm install pixi.js\n```\n\nThere is no default export. The correct way to import PixiJS is:\n\n```js\nimport * as PIXI from 'pixi.js'\n```\n\n#### CDN Install\n\nVia jsDelivr:\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/pixi.js@7.x/dist/browser/pixi.min.js\"></script>\n```\n\nOr via unpkg:\n\n```html\n<script src=\"https://unpkg.com/pixi.js@7.x/dist/browser/pixi.min.js\"></script>\n```\n\n### Demos ###\n\n- [Filters Demo](https://pixijs.io/filters/tools/demo/)\n- [Run Pixie Run](http://work.goodboydigital.com/runpixierun/)\n- [Flash vs HTML](http://flashvhtml.com)\n- [Bunny Demo](http://www.goodboydigital.com/pixijs/bunnymark)\n- [Storm Brewing](http://www.goodboydigital.com/pixijs/storm)\n- [Render Texture Demo](http://www.goodboydigital.com/pixijs/examples/11)\n- [Primitives Demo](http://www.goodboydigital.com/pixijs/examples/13)\n- [Masking Demo](http://www.goodboydigital.com/pixijs/examples/14)\n- [Interaction Demo](http://www.goodboydigital.com/pixijs/examples/6)\n- [photonstorm's Balls Demo](http://gametest.mobi/pixi/balls)\n- [photonstorm's Morph Demo](http://gametest.mobi/pixi/morph)\n\nThanks to [@photonstorm](https://twitter.com/photonstorm) for providing\nthose last 2 examples and allowing us to share the source code :)\n\n### Contribute ###\n\nWant to be part of the PixiJS project? Great! All are welcome! We will get there quicker\ntogether :) Whether you find a bug, have a great feature request or you fancy owning a task\nfrom the road map above feel free to get in touch.\n\nMake sure to read the [Contributing Guide](.github/CONTRIBUTING.md)\nbefore submitting changes.\n\n### Current features ###\n\n- WebGL renderer (with automatic smart batching allowing for REALLY fast performance)\n- Canvas renderer (Fastest in town!)\n- Full scene graph\n- Super easy to use API (similar to the flash display list API)\n- Support for texture atlases\n- Asset loader / sprite sheet loader\n- Auto-detect which renderer should be used\n- Full Mouse and Multi-touch Interaction\n- Text\n- BitmapFont text\n- Multiline Text\n- Render Texture\n- Primitive Drawing\n- Masking\n- Filters\n- [User Plugins](https://github.com/pixijs/pixijs/wiki/v6-Resources)\n\n### Basic Usage Example ###\n\n```js\nimport { Application, Sprite, Assets } from 'pixi.js';\n\n// The application will create a renderer using WebGL, if possible,\n// with a fallback to a canvas render. It will also setup the ticker\n// and the root stage PIXI.Container\nconst app = new Application();\n\n// The application will create a canvas element for you that you\n// can then insert into the DOM\ndocument.body.appendChild(app.view);\n\n// load the texture we need\nconst texture = await Assets.load('bunny.png');\n\n// This creates a texture from a 'bunny.png' image\nconst bunny = new Sprite(texture);\n\n// Setup the position of the bunny\nbunny.x = app.renderer.width / 2;\nbunny.y = app.renderer.height / 2;\n\n// Rotate around the center\nbunny.anchor.x = 0.5;\nbunny.anchor.y = 0.5;\n\n// Add the bunny to the scene we are building\napp.stage.addChild(bunny);\n\n// Listen for frame updates\napp.ticker.add(() => {\n    // each frame we spin the bunny around a bit\n    bunny.rotation += 0.01;\n});\n```\n\n### How to build ###\n\nNote that for most users you don't need to build this project. If all you want is to use PixiJS, then\njust download one of our [prebuilt releases](https://github.com/pixijs/pixijs/releases). \nThe only time you should need to build PixiJS is if you are developing it.\n\nIf you don't already have Node.js and NPM, go install them. Then, in the folder where you have cloned\nthe repository, install the build dependencies using npm:\n\n```sh\nnpm install\n```\n\nThen, to build the source, run:\n\n```sh\nnpm run build\n```\n\n#### Error installing gl package\n\nIn most cases installing `gl` from npm should just work. However, if you run into problems you might need to adjust your system configuration and make sure all your dependencies are up to date\n\nPlease refer to the [gl installation guide](https://www.npmjs.com/package/gl/v/4.5.3-win64.0#system-dependencies) for more information.\n\n#### Error installing canvas package\n\nThe [canvas](https://www.npmjs.com/package/canvas) library currently being used does not have a pre-built version for every environment.\nWhen the package detects an unsupported environment, it will try to build from source.\n\nTo build from source you will need to make sure you have the following dependencies installed and then reinstall:\n\n`brew install pkg-config cairo pango libpng jpeg giflib librsvg`\n\nFor non-mac users, please refer to the [canvas installation guide](https://www.npmjs.com/package/canvas#compiling) for more information.\n\n### How to generate the documentation ###\n\nThe docs can be generated using npm:\n\n```sh\nnpm run docs\n```\n\nThe documentation uses [webdoc](https://github.com/webdoc-labs/webdoc) in combination with this template [pixi-webdoc-template](https://github.com/pixijs/pixi-webdoc-template). The configuration file can be found at [webdoc.conf.json](webdoc.conf.json)\n\n### License ###\n\nThis content is released under the (http://opensource.org/licenses/MIT) MIT License.\n",
	"chart d3 data-visualization react svg visualization visx vx": "<p align=\"center\">\n  <img src=\"./assets/visx-geometry.png\" />\n</p>\n\n<p align=\"center\">\n  <a title=\"npm version\" href=\"https://www.npmjs.com/~visx\">\n    <img src=\"https://img.shields.io/npm/v/@visx/demo.svg?style=flat-square\" />\n  </a>\n  <a title=\"build status\" href=\"https://travis-ci.org/airbnb/visx\">\n    <img src=\"https://travis-ci.org/airbnb/visx.svg?branch=master\" />\n  </a>\n  <a href='https://coveralls.io/github/airbnb/visx?branch=master'>\n    <img src='https://coveralls.io/repos/github/airbnb/visx/badge.svg?branch=master' alt='Coverage Status' />\n  </a>\n  <a title=\"@visx/shape npm downloads\" href=\"https://www.npmjs.com/package/@visx/shape\">\n    <img src=\"https://img.shields.io/npm/dm/@visx/shape.svg?style=flat-square\" />\n  </a>\n  <a href=\"https://app.fossa.io/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fhshoff%2Fvx?ref=badge_shield\" alt=\"FOSSA Status\">     <img src=\"https://app.fossa.io/api/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fhshoff%2Fvx.svg?type=shield\"/>\n  </a>\n  <a href=\"https://lernajs.io/\" alt=\"lerna\">\n     <img src=\"https://img.shields.io/badge/maintained%20with-lerna-cc00ff.svg\"/>\n  </a>\n</p>\n\n### visx\n\nvisx is a collection of reusable low-level visualization components. visx combines the power of d3\nto generate your visualization with the benefits of react for updating the DOM.\n\n<br />\n\n<p align=\"center\">\n  <strong>\n    <a href=\"https://airbnb.io/visx\">Docs</a>\n  </strong>\n  &bull;\n  <strong>\n    <a href=\"https://airbnb.io/visx/gallery\">Gallery</a>\n  </strong>\n  &bull;\n  <strong>\n    <a href=\"https://medium.com/vx-code/getting-started-with-vx-1756bb661410\">Blog</a>\n  </strong>\n  &bull;\n  <strong>\n    <a href=\"https://d3-slackin.herokuapp.com/\" title=\"Join https://d3js.slack.com\">Slack #visx</a>\n  </strong>\n  &bull;\n  <strong>\n    <a href=\"./CHANGELOG.md\">Changelog</a>\n  </strong>\n  &bull;\n  <strong>\n    <a href=\"https://medium.com/vx-code/getting-started-with-vx-1756bb661410\">Getting started tutorial</a>\n  </strong>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://airbnb.io/visx/gallery\">\n    <img src=\"./assets/visx-gallery.png\" />\n  </a>\n</p>\n\n## Usage\n\n[![Remix on Glitch](https://cdn.glitch.com/2703baf2-b643-4da7-ab91-7ee2a2d00b5b%2Fremix-button.svg)](https://glitch.com/edit/#!/remix/kind-modem)\n\nLet's make a simple bar graph.\n\nFirst we'll install the relevant packages:\n\n```bash\nnpm install --save @visx/mock-data @visx/group @visx/shape @visx/scale\n```\n\n<img src=\"./assets/simplebar.png\" height=\"150\" />\n\n```javascript\nimport React from 'react';\nimport { letterFrequency } from '@visx/mock-data';\nimport { Group } from '@visx/group';\nimport { Bar } from '@visx/shape';\nimport { scaleLinear, scaleBand } from '@visx/scale';\n\n// We'll use some mock data from `@visx/mock-data` for this.\nconst data = letterFrequency;\n\n// Define the graph dimensions and margins\nconst width = 500;\nconst height = 500;\nconst margin = { top: 20, bottom: 20, left: 20, right: 20 };\n\n// Then we'll create some bounds\nconst xMax = width - margin.left - margin.right;\nconst yMax = height - margin.top - margin.bottom;\n\n// We'll make some helpers to get at the data we want\nconst x = d => d.letter;\nconst y = d => +d.frequency * 100;\n\n// And then scale the graph by our data\nconst xScale = scaleBand({\n  range: [0, xMax],\n  round: true,\n  domain: data.map(x),\n  padding: 0.4,\n});\nconst yScale = scaleLinear({\n  range: [yMax, 0],\n  round: true,\n  domain: [0, Math.max(...data.map(y))],\n});\n\n// Compose together the scale and accessor functions to get point functions\nconst compose = (scale, accessor) => data => scale(accessor(data));\nconst xPoint = compose(xScale, x);\nconst yPoint = compose(yScale, y);\n\n// Finally we'll embed it all in an SVG\nfunction BarGraph(props) {\n  return (\n    <svg width={width} height={height}>\n      {data.map((d, i) => {\n        const barHeight = yMax - yPoint(d);\n        return (\n          <Group key={`bar-${i}`}>\n            <Bar\n              x={xPoint(d)}\n              y={yMax - barHeight}\n              height={barHeight}\n              width={xScale.bandwidth()}\n              fill=\"#fc2e1c\"\n            />\n          </Group>\n        );\n      })}\n    </svg>\n  );\n}\n\n// ... somewhere else, render it ...\n// <BarGraph />\n```\n\nFor more examples using `visx`, check out the [gallery](https://airbnb.io/visx/gallery).\n\n## Motivation\n\n**Goal**\n\nThe goal is to create a library of components you can use to make both your own reusable chart\nlibrary or your slick custom one-off chart. visx is largely unopinionated and is meant to be built\nupon. Keep your bundle sizes down and use only the packages you need.\n\n**How?**\n\nUnder the hood, visx is using d3 for the calculations and math. If you're creating your own awesome\nchart library on top of visx, it's easy to create a component api that hides d3 entirely. Meaning\nyour team could create charts as easily as using reusable react components.\n\n**But why?**\n\nMixing two mental models for updating the DOM is never a good time. Copy and pasting d3 code into\n`componentDidMount()` is just that. This collection of components lets you easily build your own\nreusable visualization charts or library without having to learn d3. No more selections or\n`enter()`/`exit()`/`update()`.\n\n## Roadmap\n\nLots coming soon, check out the [roadmap](./ROADMAP.md).\n\n## In the wild\n\n- [williaster/data-ui](https://github.com/williaster/data-ui)\n  ([Demo](https://williaster.github.io/data-ui/))\n- [dylanmoz/trello](https://github.com/DylanMoz/dylanmoz.github.io/blob/source/src/pages/trello/TrelloGraph.js)\n  ([Demo](http://dylanmoz.github.io/trello/))\n  ([How to Make Beautiful Graphs With vx and React-Motion](https://devblog.classy.org/how-to-make-beautiful-graphs-with-vx-and-react-motion-6ffe7aecf6f3))\n- [gkunthara/Crypto-Chart](https://github.com/gkunthara/Crypto-Chart)\n  ([Tutorial](https://medium.com/@georgekunthara/after-the-tutorial-the-first-react-app-4dce6645634e))\n- Collapsible tree with [`react-move`](https://github.com/react-tools/react-move) by\n  [@techniq](https://github.com/techniq) ([Demo](https://codesandbox.io/s/n3w687vmqj))\n  ([Radial demo](https://codesandbox.io/s/vmqwrkl395))\n  ([More info](https://github.com/airbnb/visx/issues/162#issuecomment-335029517))\n- Bitcoin 30-day price by [@hshoff](https://github.com/hshoff)\n  ([Github](https://github.com/hshoff/viewsource#1-bitcoin-price-chart))\n  ([YouTube](https://www.youtube.com/watch?v=oeE2tuspdHg))\n- Ethereum candlestick chart by [@hshoff](https://github.com/hshoff)\n  ([Github](https://github.com/hshoff/viewsource#2-ethereum-candlestick-chart))\n- Song data visualization through spotify by [@bother7](https://github.com/bother7)\n  ([Demo](https://spotalyzer-frontend.herokuapp.com/demo))\n  ([Github](https://github.com/bother7/spotalyzer_frontend))\n- Investment Calculator ([website](https://investmentcalculator.io/))\n- Animation with [`react-spring`](https://github.com/drcmda/react-spring/) by\n  [@drcmda](https://github.com/drcmda) ([Demo](https://codesandbox.io/embed/j3x61vjz5v))\n- Code Coverage Dashboard by [@ezy](https://github.com/ezy)\n  ([Demo](https://codecov-dash.herokuapp.com/))\n  ([Github](https://github.com/ezy/code-coverage-dashboard))\n- Ethereum Portfolio Toolkit by [@JayWelsh](https://github.com/JayWelsh)\n  ([Demo](https://cryptocape.com/)) ([Github](https://github.com/JayWelsh/CryptoCape))\n- Family tree by [@vkallore](https://github.com/vkallore)\n  ([Github](https://github.com/vkallore/d3-vx-family-tree))\n- South African Coronavirus Data Visuals by [@JayWelsh](https://github.com/JayWelsh)\n  ([Demo](https://coronamap.co.za/)) ([Github](https://github.com/JayWelsh/coronamap))\n- [CNN: Tracking America's Recovery](https://www.cnn.com/business/us-economic-recovery-coronavirus)\n- [Wall Street Journal: Americans Familiarize Themselves with the Word \u2018Forbearance\u2019](https://blogs.wsj.com/dailyshot/2020/04/13/the-daily-shot-americans-familiarize-themselves-with-the-word-forbearance/)\n  by [@rayshan](https://github.com/rayshan)\n  ([Demo](https://finance.shan.io/recessions-bear-markets-compared))\n- Dollar to food emoji caculator by [@gmlwo530](https://github.com/gmlwo530)\n  ([Demo](https://dollar-to-food-emoji.web.app/))\n  ([Github](https://github.com/gmlwo530/dollar-to-food-emoji))\n- [zh-TW] Taiwan Real-time Air Quality Index by\n  [@ArvinH](https://github.com/ArvinH)([Demo](https://codesandbox.io/s/simpleradar-aqi-with-tooltip-select-data-react-spring-item3?file=/Radar.tsx))([Tutorial](https://blog.arvinh.info/tech/datavis-visx))\n- tokenized BTC on ethereum stacked chart with brush by\n  [@sakulstra](https://github.com/sakulstra)([Demo](https://tokenizedbtc.info/))\n- [Escape From Tarkov Ammo Chart](https://eft.monster/) by\n  [@codenomial](https://github.com/codenomial)\n- [Pry](https://pry.co) Finance for Founders (dashboard by [@valtism](https://github.com/valtism))\n- [Data 2 the People](https://www.data2thepeople.org/) Donation Efficacy Analysis for Downballot Races ([Demo](https://donate.data2thepeople.org/)) ([Github](https://github.com/Data-2-the-People/skyfall/blob/master/components/Scatterplot.jsx))\n- [Augora](https://augora.fr) Display information of french deputies ([Demo](https://augora.fr/statistiques))([Github](https://github.com/Augora/Augora))\n- WHO Coronavirus (COVID-19) Dashboard is built on top of `vx`, earlier version of `visx`. ([Demo](https://covid19.who.int/))\n\nHave a project that's using `visx`? Open a pull request and we'll add it to the list.\n\n## FAQ\n\n1. What does `visx` stand for?\n\n   > visx stands for visualization components.\n\n1. Do you plan on supporting animation/transitions?\n\n   > A common criticism of visx is it doesn't have animation baked in, but this was a conscious\n   > choice. It's a powerful feature to not bake it in.\n   >\n   > Imagine your app already bundles `react-motion`, adding a hypothetical `@visx/animation` is\n   > bloat. Since visx is react, it already supports all react animation libs.\n   >\n   > Charting libraries are like style guides. Each org or app will eventually want full control\n   > over their own implementation.\n   >\n   > visx makes this easier for everyone. No need to reinvent the wheel each time.\n   >\n   > more info: https://github.com/airbnb/visx/issues/6\n   >\n   > examples:\n   >\n   > - Collapsible tree with [`react-move`](https://github.com/react-tools/react-move) by\n   >   [@techniq](https://github.com/techniq) ([Demo](https://codesandbox.io/s/n3w687vmqj))\n   >   ([Radial demo](https://codesandbox.io/s/vmqwrkl395))\n   > - Animation with `react-spring` by [@drcmda](https://github.com/drcmda)\n   >   ([Demo](https://codesandbox.io/embed/j3x61vjz5v))\n\n1. Do I have to use every package to make a chart?\n\n   > nope! pick and choose the packages you need.\n\n1. Can I use this to create my own library of charts for my team?\n\n   > Please do.\n\n1. Does visx work with [preact](https://preactjs.com/)?\n\n   > yup! need to alias `react` + `react-dom` and use `preact-compat`.\n\n1. I like using d3.\n\n   > Me too.\n\n## Development\n\nPlease see [CONTRIBUTING.md](./CONTRIBUTING.md)\n\n:v:\n\n[MIT](./LICENSE)\n\n[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fhshoff%2Fvx.svg?type=large)](https://app.fossa.io/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fhshoff%2Fvx?ref=badge_large)\n",
	"charting-library charts d3 data-visualization plotly plotly-dash regl visualization webgl": "<a href=\"https://plotly.com/javascript/\"><img src=\"https://images.plot.ly/logo/plotlyjs-logo@2x.png\" height=\"70\"></a>\n\n[![npm version](https://badge.fury.io/js/plotly.js.svg)](https://badge.fury.io/js/plotly.js)\n[![circle ci](https://circleci.com/gh/plotly/plotly.js.png?&style=shield&circle-token=1f42a03b242bd969756fc3e53ede204af9b507c0)](https://circleci.com/gh/plotly/plotly.js)\n[![MIT License](https://img.shields.io/badge/License-MIT-brightgreen.svg)](https://github.com/plotly/plotly.js/blob/master/LICENSE)\n\n[Plotly.js](https://plotly.com/javascript) is a standalone Javascript data visualization library, and it also powers the Python and R modules named `plotly` in those respective ecosystems (referred to as [Plotly.py](https://plotly.com/python) and [Plotly.R](http://plotly.com/r)).\n\nPlotly.js can be used to produce dozens of chart types and visualizations, including statistical charts, 3D graphs, scientific charts, SVG and tile maps, financial charts and more.\n\n<p align=\"center\">\n    <a href=\"https://plotly.com/javascript/\" target=\"_blank\">\n        <img src=\"https://raw.githubusercontent.com/cldougl/plot_images/add_r_img/plotly_2017.png\">\n    </a>\n</p>\n\n[Contact us](https://plotly.com/products/consulting-and-oem/) for Plotly.js consulting, dashboard development, application integration, and feature additions.\n\n## Table of contents\n\n* [Load as a node module](#load-as-a-node-module)\n* [Load via script tag](#load-via-script-tag)\n* [Bundles](#bundles)\n* [Alternative ways to load and build plotly.js](#alternative-ways-to-load-and-build-plotlyjs)\n* [Documentation](#documentation)\n* [Bugs and feature requests](#bugs-and-feature-requests)\n* [Contributing](#contributing)\n* [Notable contributors](#notable-contributors)\n* [Copyright and license](#copyright-and-license)\n* [Community](#community)\n\n---\n## Load as a node module\nInstall [a ready-to-use distributed bundle](https://github.com/plotly/plotly.js/blob/master/dist/README.md)\n```sh\nnpm i --save plotly.js-dist-min\n```\n\nand use import or require in node.js\n```js\n// ES6 module\nimport Plotly from 'plotly.js-dist-min'\n\n// CommonJS\nvar Plotly = require('plotly.js-dist-min')\n```\n\nYou may also consider using [`plotly.js-dist`](https://www.npmjs.com/package/plotly.js-dist) if you prefer using an unminified package.\n\n---\n## Load via script tag\n\n### The script HTML element\n> In the examples below `Plotly` object is added to the window scope by `script`. The `newPlot` method is then used to draw an interactive figure as described by `data` and `layout` into the desired `div` here named `gd`. As demonstrated in the example above basic knowledge of `html` and [JSON](https://en.wikipedia.org/wiki/JSON) syntax is enough to get started i.e. with/without JavaScript! To learn and build more with plotly.js please visit [plotly.js documentation](https://plotly.com/javascript).\n\n```html\n<head>\n    <script src=\"https://cdn.plot.ly/plotly-2.16.3.min.js\"></script>\n</head>\n<body>\n    <div id=\"gd\"></div>\n\n    <script>\n        Plotly.newPlot(\"gd\", /* JSON object */ {\n            \"data\": [{ \"y\": [1, 2, 3] }],\n            \"layout\": { \"width\": 600, \"height\": 400}\n        })\n    </script>\n</body>\n```\n\nAlternatively you may consider using [native ES6 import](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules) in the script tag.\n```html\n<script type=\"module\">\n    import \"https://cdn.plot.ly/plotly-2.16.3.min.js\"\n    Plotly.newPlot(\"gd\", [{ y: [1, 2, 3] }])\n</script>\n```\n\nFastly supports Plotly.js with free CDN service. Read more at <https://www.fastly.com/open-source>.\n\n### Un-minified versions are also available on CDN\nWhile non-minified source files may contain characters outside UTF-8, it is recommended that you specify the `charset` when loading those bundles.\n```html\n<script src=\"https://cdn.plot.ly/plotly-2.16.3.js\" charset=\"utf-8\"></script>\n```\n\n> Please note that as of v2 the \"plotly-latest\" outputs (e.g. https://cdn.plot.ly/plotly-latest.min.js) will no longer be updated on the CDN, and will stay at the last v1 patch v1.58.5. Therefore, to use the CDN with plotly.js v2 and higher, you must specify an exact plotly.js version.\n\n### MathJax\nYou could load either version two or version three of MathJax files, for example:\n```html\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG.js\"></script>\n```\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-svg.js\"></script>\n```\n\n> When using MathJax version 3, it is also possible to use `chtml` output on the other parts of the page in addition to `svg` output for the plotly graph.\nPlease refer to `devtools/test_dashboard/index-mathjax3chtml.html` to see an example.\n\n\n## Bundles\nThere are two kinds of plotly.js bundles:\n1. Complete and partial official bundles that are distributed to `npm` and the `CDN`, described in [the dist README](https://github.com/plotly/plotly.js/blob/master/dist/README.md).\n2. Custom bundles you can create yourself to optimize the size of bundle depending on your needs. Please visit [CUSTOM_BUNDLE](https://github.com/plotly/plotly.js/blob/master/CUSTOM_BUNDLE.md) for more information.\n\n---\n## Alternative ways to load and build plotly.js\nIf your library needs to bundle or directly load [plotly.js/lib/index.js](https://github.com/plotly/plotly.js/blob/master/lib/index.js) or parts of its modules similar to [index-basic](https://github.com/plotly/plotly.js/blob/master/lib/index-basic.js) in some other way than via an official or a custom bundle, or in case you want to tweak the default build configurations of `browserify` or `webpack`, etc. then please visit [`BUILDING.md`](https://github.com/plotly/plotly.js/blob/master/BUILDING.md).\n\n---\n## Documentation\n\nOfficial plotly.js documentation is hosted at [https://plotly.com/javascript](https://plotly.com/javascript).\n\nThese pages are generated by the Plotly [graphing-library-docs repo](https://github.com/plotly/graphing-library-docs) built with [Jekyll](https://jekyllrb.com/) and publicly hosted on GitHub Pages.\nFor more info about contributing to Plotly documentation, please read through [contributing guidelines](https://github.com/plotly/graphing-library-docs/blob/master/README.md).\n\n---\n## Bugs and feature requests\n\nHave a bug or a feature request? Please [open a Github issue](https://github.com/plotly/plotly.js/issues/new) keeping in mind the [issue guidelines](https://github.com/plotly/plotly.js/blob/master/.github/ISSUE_TEMPLATE.md). You may also want to read about [how changes get made to Plotly.js](https://github.com/plotly/plotly.js/blob/master/CONTRIBUTING.md)\n\n---\n## Contributing\n\nPlease read through our [contributing guidelines](https://github.com/plotly/plotly.js/blob/master/CONTRIBUTING.md). Included are directions for opening issues, using plotly.js in your project and notes on development.\n\n---\n## Notable contributors\n\nPlotly.js is at the core of a large and dynamic ecosystem with many contributors who file issues, reproduce bugs, suggest improvements, write code in this repo (and other upstream or downstream ones) and help users in the Plotly community forum. The following people deserve special recognition for their outsized contributions to this ecosystem:\n\n|   | GitHub | Twitter | Status |\n|---|--------|---------|--------|\n|**Alex C. Johnson**| [@alexcjohnson](https://github.com/alexcjohnson) | | Active, Maintainer |\n|**Mojtaba Samimi** | [@archmoj](https://github.com/archmoj) | [@solarchvision](https://twitter.com/solarchvision) | Active, Maintainer |\n|**Antoine Roy-Gobeil** | [@antoinerg](https://github.com/antoinerg) | | Active, Maintainer |\n|**Nicolas Kruchten** | [@nicolaskruchten](https://github.com/nicolaskruchten) | [@nicolaskruchten](https://twitter.com/nicolaskruchten) | Active, Maintainer |\n|**Jon Mease** | [@jonmmease](https://github.com/jonmmease) | [@jonmmease](https://twitter.com/jonmmease) | Active |\n|**\u00c9tienne T\u00e9treault-Pinard**| [@etpinard](https://github.com/etpinard) | [@etpinard](https://twitter.com/etpinard) | Hall of Fame |\n|**Mikola Lysenko**| [@mikolalysenko](https://github.com/mikolalysenko) | [@MikolaLysenko](https://twitter.com/MikolaLysenko) | Hall of Fame |\n|**Ricky Reusser**| [@rreusser](https://github.com/rreusser) | [@rickyreusser](https://twitter.com/rickyreusser) | Hall of Fame |\n|**Dmitry Yv.** | [@dy](https://github.com/dy) | [@DimaYv](https://twitter.com/dimayv)| Hall of Fame |\n|**Robert Monfera**| [@monfera](https://github.com/monfera) | [@monfera](https://twitter.com/monfera) | Hall of Fame |\n|**Robert M\u00f6stl** | [@rmoestl](https://github.com/rmoestl) | [@rmoestl](https://twitter.com/rmoestl) | Hall of Fame |\n|**Nicolas Riesco**| [@n-riesco](https://github.com/n-riesco) | | Hall of Fame |\n|**Mikl\u00f3s Tusz**| [@mdtusz](https://github.com/mdtusz) | [@mdtusz](https://twitter.com/mdtusz)| Hall of Fame |\n|**Chelsea Douglas**| [@cldougl](https://github.com/cldougl) | | Hall of Fame |\n|**Ben Postlethwaite**| [@bpostlethwaite](https://github.com/bpostlethwaite) | | Hall of Fame |\n|**Chris Parmer**| [@chriddyp](https://github.com/chriddyp) | | Hall of Fame |\n|**Alex Vados**| [@alexander-daniel](https://github.com/alexander-daniel) | | Hall of Fame |\n\n---\n## Copyright and license\n\nCode and documentation copyright 2021 Plotly, Inc.\n\nCode released under the [MIT license](https://github.com/plotly/plotly.js/blob/master/LICENSE).\n\n### Versioning\n\nThis project is maintained under the [Semantic Versioning guidelines](https://semver.org/).\n\nSee the [Releases section](https://github.com/plotly/plotly.js/releases) of our GitHub project for changelogs for each release version of plotly.js.\n\n---\n## Community\n\n* Follow [@plotlygraphs](https://twitter.com/plotlygraphs) on Twitter for the latest Plotly news.\n* Implementation help may be found on community.plot.com (tagged [`plotly-js`](https://community.plotly.com/c/plotly-js)) or\n  on Stack Overflow (tagged [`plotly`](https://stackoverflow.com/questions/tagged/plotly)).\n* Developers should use the keyword `plotly` on packages which modify or add to the functionality of plotly.js when distributing through [npm](https://www.npmjs.com/browse/keyword/plotly).\n",
	"charts data-visualization graphs interactive javascript svg visualization": "<p align=\"center\"><img src=\"https://apexcharts.com/media/apexcharts-logo.png\"></p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/apexcharts/apexcharts.js/blob/master/LICENSE\"><img src=\"https://img.shields.io/badge/License-MIT-brightgreen.svg\" alt=\"License\"></a>\n  <a href=\"https://travis-ci.com/apexcharts/apexcharts.js\"><img src=\"https://api.travis-ci.com/apexcharts/apexcharts.js.svg?branch=master\" alt=\"build\" /></a>\n  <img alt=\"downloads\" src=\"https://img.shields.io/npm/dm/apexcharts.svg\"/>\n  <a href=\"https://www.npmjs.com/package/apexcharts\"><img src=\"https://img.shields.io/npm/v/apexcharts.svg\" alt=\"ver\"></a>\n  <img alt=\"size\" src=\"https://badgen.net/bundlephobia/min/apexcharts?label=size\">\n  <a href=\"https://cdn.jsdelivr.net/npm/apexcharts@3.12.0/types/apexcharts.d.ts\"><img src=\"https://badgen.net/npm/types/apexcharts\"/></a>\n  <a href=\"https://github.com/prettier/prettier\"><img src=\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\" alt=\"prettier\"></a>\n  <a href=\"https://www.jsdelivr.com/package/npm/apexcharts\"><img src=\"https://data.jsdelivr.com/v1/package/npm/apexcharts/badge\" alt=\"jsdelivr\" /></a>\n  <a href=\"https://codeclimate.com/github/apexcharts/apexcharts.js\"><img src=\"https://badgen.net/codeclimate/maintainability/apexcharts/apexcharts.js\" /></a>\n  <img src=\"https://badgen.net/codeclimate/tech-debt/apexcharts/apexcharts.js\"/>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://twitter.com/intent/tweet?text=Create%20visualizations%20with%20this%20free%20and%20open-source%20JavaScript%20Chart%20library&url=https://www.apexcharts.com&hashtags=javascript,charts,visualizations,developers,apexcharts\"><img src=\"https://img.shields.io/twitter/url/http/shields.io.svg?style=social\"> </a>\n</p>\n\n<p align=\"center\">A modern JavaScript charting library that allows you to build interactive data visualizations with simple API and 100+ ready-to-use samples. Packed with the features that you expect, ApexCharts includes over a dozen chart types that deliver beautiful, responsive visualizations in your apps and dashboards. ApexCharts is an MIT-licensed open-source project that can be used in commercial and non-commercial projects.</p>\n\n<p align=\"center\"><a href=\"https://apexcharts.com/javascript-chart-demos/\"><img\n      src=\"https://apexcharts.com/media/apexcharts-banner.png\"></a></p>\n\n<br />\n\n## Browsers support\n\n| [<img src=\"https://raw.githubusercontent.com/alrra/browser-logos/master/src/firefox/firefox_48x48.png\" alt=\"Firefox\" width=\"24px\" height=\"24px\" />](http://godban.github.io/browsers-support-badges/)<br/>Firefox | [<img src=\"https://raw.githubusercontent.com/alrra/browser-logos/master/src/chrome/chrome_48x48.png\" alt=\"Chrome\" width=\"24px\" height=\"24px\" />](http://godban.github.io/browsers-support-badges/)<br/>Chrome | [<img src=\"https://raw.githubusercontent.com/alrra/browser-logos/master/src/safari/safari_48x48.png\" alt=\"Safari\" width=\"24px\" height=\"24px\" />](http://godban.github.io/browsers-support-badges/)<br/>Safari | [<img src=\"https://raw.githubusercontent.com/alrra/browser-logos/master/src/edge/edge_48x48.png\" alt=\"Edge\" width=\"24px\" height=\"24px\" />](http://godban.github.io/browsers-support-badges/)<br/> Edge | [<img src=\"https://user-images.githubusercontent.com/17712401/124668393-30772d00-de87-11eb-9360-3199c3b68b95.png\" alt=\"IE\" width=\"24px\" height=\"24px\" />](http://godban.github.io/browsers-support-badges/)<br/> IE11 |\n| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| 31+ \u2714                                                                                                                                                                                                             | 35+ \u2714                                                                                                                                                                                                         | 6+ \u2714                                                                                                                                                                                                          | Edge \u2714                                                                                                                                                                                                 | [(IE11)](#using-it-with-ie11) \u2714                                                                                                                                                                  |\n\n## Download and Installation\n\n##### Installing via npm\n\n```bash\nnpm install apexcharts --save\n```\n\n##### Direct &lt;script&gt; include\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/apexcharts\"></script>\n```\n\n## Wrappers for Vue/React/Angular/Stencil\n\nIntegrate easily with 3rd party frameworks\n\n- [vue-apexcharts](https://github.com/apexcharts/vue-apexcharts)\n- [react-apexcharts](https://github.com/apexcharts/react-apexcharts)\n- [ng-apexcharts](https://github.com/apexcharts/ng-apexcharts) - Plugin by [Morris Janatzek](https://morrisj.net/)\n- [stencil-apexcharts](https://github.com/apexcharts/stencil-apexcharts)\n\n### Unofficial Wrappers\n\nUseful links to wrappers other than the popular frameworks mentioned above\n\n- [apexcharter](https://github.com/dreamRs/apexcharter) - Htmlwidget for ApexCharts\n- [apexcharts.rb](https://github.com/styd/apexcharts.rb) - Ruby wrapper for ApexCharts\n- [larapex-charts](https://github.com/ArielMejiaDev/larapex-charts) - Laravel wrapper for ApexCharts\n- [blazor-apexcharts](https://github.com/apexcharts/Blazor-ApexCharts) - Blazor wrapper for ApexCharts [demo](https://apexcharts.github.io/Blazor-ApexCharts/)\n- [svelte-apexcharts](https://github.com/galkatz373/svelte-apexcharts) - Svelte wrapper for ApexCharts\n\n\n## Usage\n\n```js\nimport ApexCharts from 'apexcharts'\n```\n\nTo create a basic bar chart with minimal configuration, write as follows:\n\n```js\nvar options = {\n  chart: {\n    type: 'bar'\n  },\n  series: [\n    {\n      name: 'sales',\n      data: [30, 40, 35, 50, 49, 60, 70, 91, 125]\n    }\n  ],\n  xaxis: {\n    categories: [1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]\n  }\n}\n\nvar chart = new ApexCharts(document.querySelector('#chart'), options)\nchart.render()\n```\n\nThis will render the following chart\n\n<p align=\"center\"><a href=\"https://apexcharts.com/javascript-chart-demos/column-charts/\"><img src=\"https://apexcharts.com/media/first-bar-chart.svg\"></a></p>\n\n### A little more than the basic\n\nYou can create a combination of different charts, sync them and give your desired look with unlimited possibilities.\nBelow is an example of synchronized charts with github style.\n\n<p align=\"center\"><a href=\"https://apexcharts.com/javascript-chart-demos/area-charts/github-style/\"><img src=\"https://apexcharts.com/media/github-charts.gif\"></a></p>\n\n## Interactivity\n\nZoom, Pan, and Scroll through data. Make selections and load other charts using those selections.\nAn example showing some interactivity\n\n<p align=\"center\"><a href=\"https://codepen.io/apexcharts/pen/QrbEQg\" target=\"_blank\"><img src=\"https://apexcharts.com/media/interactivity.gif\" alt=\"interactive chart\"></a></p>\n\n## Dynamic Series Update\n\nAnother approach is to Drill down charts where one selection updates the data of other charts.\nAn example of loading dynamic series into charts is shown below\n\n<p align=\"center\"><a href=\"https://apexcharts.com/javascript-chart-demos/column-charts/dynamic-loaded-chart/\"><img src=\"https://apexcharts.com/media/dynamic-selection.gif\" alt=\"dynamic-loading-chart\" /></a></p>\n\n## Annotations\n\nAnnotations allow you to write custom text on specific values or on axes values. Valuable to expand the visual appeal of your chart and make it more informative.\n\n<p align=\"center\"><a href=\"https://apexcharts.com/docs/annotations/\"><img src=\"https://apexcharts.com/media/annotations.png\" alt=\"annotations\" /></a></p>\n\n## Mixed Charts\n\nYou can combine more than one chart type to create a combo/mixed chart. Possible combinations can be line/area/column together in a single chart. Each chart type can have its own y-axis.\n\n<p align=\"center\"><a href=\"https://apexcharts.com/javascript-chart-demos/mixed-charts/\"><img src=\"https://apexcharts.com/wp-content/uploads/2018/05/line-column-area-mixed-chart.svg\" alt=\"annotations\" width=\"490\" /></a></p>\n\n## Candlestick\n\nUse a candlestick chart (a common financial chart) to describe price changes of a security, derivative, or currency. The below image shows how you can use another chart as a brush/preview pane which acts as a handle to browse the main candlestick chart.\n\n<p align=\"center\"><a href=\"https://apexcharts.com/javascript-chart-demos/candlestick-charts/\"><img src=\"https://apexcharts.com/media/candlestick.png\" alt=\"candlestick\" width=\"490\" /></a></p>\n\n## Heatmaps\n\nUse Heatmaps to represent data through colors and shades. Frequently used with bigger data collections, they are valuable for recognizing patterns and areas of focus.\n\n<p align=\"center\"><a href=\"https://apexcharts.com/javascript-chart-demos/heatmap-charts/\"><img src=\"https://apexcharts.com/media/heatmap-charts.png\" alt=\"heatmap\" /></a></p>\n\n## Gauges\n\nThe tiny gauges are an important part of a dashboard and are useful in displaying single-series data. A demo of these gauges:\n\n<p align=\"center\"><a href=\"https://apexcharts.com/javascript-chart-demos/radialbar-charts/\"><img src=\"https://apexcharts.com/media/radialbars-gauges.png\" width=\"490\" alt=\"radialbar-chart\" /></a></p>\n\n## Sparklines\n\nUtilize sparklines to indicate trends in data, for example, occasional increments or declines, monetary cycles, or to feature the most extreme and least values:\n\n<p align=\"center\"><a href=\"https://apexcharts.com/javascript-chart-demos/sparklines/\"><img src=\"https://apexcharts.com/media/sparklines.png\" alt=\"sparkline-chart\" /></a></p>\n\n\n## Need Advanced Data Grid for your next project? \nWe partnered with Infragistics, creators of the fastest data grids on the planet! Ignite UI Grids can handle unlimited rows and columns of data while providing access to custom templates and real-time data updates. \n\n<p align=\"center\"><a href=\"https://www.infragistics.com/products/ignite-ui-angular/angular/components/grid/grid\" target=\"_blank\"><img src=\"https://apexcharts.com/media/infragistics-data-grid.png\" /></a></p>\n\nFeaturing an intuitive API for easy theming and branding, you can quickly bind to data with minimal hand-on coding. The grid is available in most of your favorite frameworks:  \n\n<a target=\"_blank\" href=\"https://www.infragistics.com/products/ignite-ui-angular/angular/components/grid/grid\">Angular Data Grid</a> | <a target=\"_blank\" href=\"https://www.infragistics.com/products/ignite-ui-react/react/components/grids\">React Data Grid</a> | <a target=\"_blank\" href=\"https://www.infragistics.com/products/ignite-ui-blazor/blazor/components/data-grid\">Blazor Data Grid</a> | <a target=\"_blank\" href=\"https://www.infragistics.com/products/ignite-ui-web-components/web-components/components/data-grid\">Web Components DataGrid</a> | <a target=\"_blank\" href=\"https://www.igniteui.com/grid/overview\">jQuery Data Grid </a>\n\n## What's included\n\nThe download bundle includes the following files and directories providing a minified single file in the dist folder. Every asset including icon/css is bundled in the js itself to avoid loading multiple files.\n\n```\napexcharts/\n\u251c\u2500\u2500 dist/\n\u2502   \u2514\u2500\u2500 apexcharts.min.js\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 assets/\n\u2502   \u251c\u2500\u2500 charts/\n\u2502   \u251c\u2500\u2500 modules/\n\u2502   \u251c\u2500\u2500 utils/\n\u2502   \u2514\u2500\u2500 apexcharts.js\n\u2514\u2500\u2500 samples/\n```\n\n## Using it with IE11\n\nIf you need to make it work with IE11, you need to include these polyfills before including ApexCharts\n\n- [promise-polyfill](https://cdn.jsdelivr.net/npm/promise-polyfill@8/dist/polyfill.min.js)\n- [classlist.js](https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill)\n- [ResizeObserver polyfill](https://cdn.jsdelivr.net/npm/@juggle/resize-observer)\n- [findIndex](https://cdn.jsdelivr.net/npm/findindex_polyfill_mdn) - You will need this only if you require timeline/rangebar charts\n- [canvg](https://unpkg.com/canvg@3.0.4/lib/umd.js) - You will need this only if you require PNG download of your charts\n\n## Development\n\n#### Install dependencies and run the project\n\n```bash\nnpm install\nnpm run dev\n```\n\nThis will start the webpack watch and any changes you make to `src` folder will auto-compile and output will be produced in the `dist` folder.\n\n#### Minifying the src\n\n```bash\nnpm run build\n```\n\n## Where do I go next?\n\nHead over to the <a href=\"https://apexcharts.com/docs/\">documentation</a> section to read more about how to use different kinds of charts and explore all options.\n\n## Contacts\n\nEmail: <a href=\"info@apexcharts.com\">info@apexcharts.com</a>\n\nTwitter: <a href=\"https://twitter.com/apexcharts\">@apexcharts</a>\n\nFacebook: <a href=\"https://facebook.com/apexcharts\">fb.com/apexcharts</a>\n\n## Dependency\n\nApexCharts uses <a href=\"https://svgdotjs.github.io/\" target=\"_blank\">SVG.js</a> for drawing shapes, animations, applying svg filters, and a lot more under the hood. The library is bundled in the final build file, so you don't need to include it.\n\n## License\n\nApexCharts is released under MIT license. You are free to use, modify and distribute this software, as long as the copyright header is left intact.\n",
	"awesome awesome-list bigdata data data-analytics data-science data-stream data-visualization data-warehouse database distributed-database series-database stream-processing streaming-data visualize-data": "# Awesome Big Data\n\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\nA curated list of awesome big data frameworks, resources and other awesomeness. Inspired by [awesome-php](https://github.com/ziadoz/awesome-php), [awesome-python](https://github.com/vinta/awesome-python), [awesome-ruby](https://github.com/Sdogruyol/awesome-ruby), [hadoopecosystemtable](http://hadoopecosystemtable.github.io/) & [big-data](http://usefulstuff.io/big-data/).\n\nYour contributions are always welcome!\n\n- [Awesome Big Data](#awesome-big-data)\n  - [RDBMS](#rdbms)\n  - [Frameworks](#frameworks)\n  - [Distributed Programming](#distributed-programming)\n  - [Distributed Filesystem](#distributed-filesystem)\n  - [Distributed Index](#distributed-index)\n  - [Document Data Model](#document-data-model)\n  - [Key Map Data Model](#key-map-data-model)\n  - [Key-value Data Model](#key-value-data-model)\n  - [Graph Data Model](#graph-data-model)\n  - [Columnar Databases](#columnar-databases)\n  - [NewSQL Databases](#newsql-databases)\n  - [Time-Series Databases](#time-series-databases)\n  - [SQL-like processing](#sql-like-processing)\n  - [Data Ingestion](#data-ingestion)\n  - [Service Programming](#service-programming)\n  - [Scheduling](#scheduling)\n  - [Machine Learning](#machine-learning)\n  - [Benchmarking](#benchmarking)\n  - [Security](#security)\n  - [System Deployment](#system-deployment)\n  - [Applications](#applications)\n  - [Search engine and framework](#search-engine-and-framework)\n  - [MySQL forks and evolutions](#mysql-forks-and-evolutions)\n  - [PostgreSQL forks and evolutions](#postgresql-forks-and-evolutions)\n  - [Memcached forks and evolutions](#memcached-forks-and-evolutions)\n  - [Embedded Databases](#embedded-databases)\n  - [Business Intelligence](#business-intelligence)\n  - [Data Visualization](#data-visualization)\n  - [Internet of things and sensor data](#internet-of-things-and-sensor-data)\n  - [Interesting Readings](#interesting-readings)\n  - [Interesting Papers](#interesting-papers)\n    - [2015 - 2016](#2015---2016)\n    - [2013 - 2014](#2013---2014)\n    - [2011 - 2012](#2011---2012)\n    - [2001 - 2010](#2001---2010)\n  - [Videos](#videos)\n  - [Books](#books)\n      - [Streaming](#streaming)\n      - [Distributed systems](#distributed-systems)\n      - [Graph Based approach](#graph-based-approach)\n    - [Data Visualization](#data-visualization-1)\n- [Other Awesome Lists](#other-awesome-lists)\n\n## RDBMS\n* [MySQL](https://www.mysql.com/) The world's most popular open source database.\n* [PostgreSQL](https://www.postgresql.org/) The world's most advanced open source database.\n* [Oracle Database](http://www.oracle.com/us/corporate/features/database-12c/index.html) - object-relational database management system.\n* [Teradata](http://www.teradata.com/products-and-services/teradata-database/) - high-performance MPP data warehouse platform.\n\n## Frameworks\n\n* [Bistro](https://github.com/facebook/bistro) - general-purpose data processing engine for both batch and stream analytics. It is based on a novel data model, which represents data via *functions* and processes data via *column operations* as opposed to having only set operations in conventional approaches like MapReduce or SQL.\n* [IBM Streams](https://www.ibm.com/analytics/us/en/technology/stream-computing/) - platform for distributed processing and real-time analytics.  Integrates with many of the popular technologies in the Big Data ecosystem (Kafka, HDFS, Spark, etc.)\n* [Apache Hadoop](http://hadoop.apache.org/) - framework for distributed processing. Integrates\u00a0MapReduce (parallel processing), YARN (job scheduling) and HDFS (distributed file system).\n* [Tigon](https://github.com/caskdata/tigon) - High Throughput Real-time Stream Processing Framework.\n* [Pachyderm](http://pachyderm.io/) - Pachyderm is a data storage platform built on Docker and Kubernetes to provide reproducible data processing and analysis.\n* [Polyaxon](https://github.com/polyaxon/polyaxon) - A platform for reproducible and scalable machine learning and deep learning.\n* [Smooks](https://github.com/smooks/smooks) - An extensible Java framework for building XML and non-XML (CSV, EDI, Java, etc...) streaming applications.\n\n## Distributed Programming\n\n* [AddThis Hydra](https://github.com/addthis/hydra) - distributed data processing and storage system originally developed at AddThis.\n* [AMPLab SIMR](http://databricks.github.io/simr/) - run Spark on Hadoop MapReduce v1.\n* [Apache APEX](https://apex.apache.org/) - a unified, enterprise platform for big data stream and batch processing.\n* [Apache Beam](https://beam.apache.org/) - an unified model and set of language-specific SDKs for defining and executing data processing workflows.\n* [Apache Crunch](http://crunch.apache.org/) - a simple Java API for tasks like joining and data aggregation that are tedious to implement on plain MapReduce.\n* [Apache DataFu](http://incubator.apache.org/projects/datafu.html) - collection of user-defined functions for\u00a0Hadoop and Pig developed by LinkedIn.\n* [Apache Flink](http://flink.apache.org/) - high-performance runtime, and automatic program optimization.\n* [Apache Gearpump](http://gearpump.apache.org/) - real-time big data streaming engine based on Akka.\n* [Apache Gora](http://gora.apache.org/) - framework for in-memory data model and persistence.\n* [Apache Hama](http://hama.apache.org/) - BSP (Bulk Synchronous Parallel) computing framework.\n* [Apache MapReduce](https://wiki.apache.org/hadoop/MapReduce/) - programming model for processing large data sets with a parallel, distributed algorithm on a cluster.\n* [Apache Pig](https://pig.apache.org/) - high level language to express data analysis programs for Hadoop.\n* [Apache REEF](http://reef.apache.org/) - retainable evaluator execution framework to simplify and unify the lower layers of big data systems.\n* [Apache S4](http://incubator.apache.org/projects/s4.html) - framework for stream processing, implementation of S4.\n* [Apache Spark](http://spark.apache.org/) - framework for\u00a0in-memory cluster computing.\n* [Apache Spark Streaming](https://spark.apache.org/docs/latest/streaming-programming-guide.html) - framework for stream processing, part of Spark.\n* [Apache Storm](http://storm.apache.org) - framework for stream processing by Twitter also on YARN.\n* [Apache Samza](http://samza.apache.org/) - stream processing framework, based on Kafka and YARN.\n* [Apache Tez](http://tez.apache.org/) - application framework\u00a0for executing a complex DAG (directed acyclic graph) of tasks, built on\u00a0YARN.\n* [Apache Twill](https://incubator.apache.org/projects/twill.html) - abstraction over YARN that reduces the complexity of developing distributed applications.\n* [Baidu Bigflow](http://bigflow.cloud/en/index.html) - an interface that allows for writing distributed computing programs providing lots of simple, flexible, powerful APIs to easily handle data of any scale.\n* [Cascalog](http://cascalog.org/) - data processing and querying library.\n* [Cheetah](http://vldbarc.org/pvldb/vldb2010/pvldb_vol3/I08.pdf) - High Performance, Custom Data Warehouse on Top of MapReduce.\n* [Concurrent Cascading](http://www.cascading.org/) - framework for data management/analytics on Hadoop.\n* [Damballa Parkour](https://github.com/damballa/parkour) - MapReduce library for Clojure.\n* [Datasalt Pangool](https://github.com/datasalt/pangool) - alternative MapReduce paradigm.\n* [DataTorrent StrAM](https://www.datatorrent.com/) - real-time engine is designed to enable distributed, asynchronous, real time in-memory big-data computations in as unblocked a way as possible, with minimal overhead and impact on performance.\n* [Facebook Corona](https://www.facebook.com/notes/facebook-engineering/under-the-hood-scheduling-mapreduce-jobs-more-efficiently-with-corona/10151142560538920) - Hadoop enhancement which removes single point of failure.\n* [Facebook Peregrine](http://peregrine_mapreduce.bitbucket.org/) - Map Reduce framework.\n* [Facebook Scuba](https://www.facebook.com/notes/facebook-engineering/under-the-hood-data-diving-with-scuba/10150599692628920) - distributed in-memory datastore.\n* [Google Dataflow](https://googledevelopers.blogspot.it/2014/06/cloud-platform-at-google-io-new-big.html) - create data pipelines to help them\u00e6ingest, transform and analyze data.\n* [Google MapReduce](https://research.google.com/archive/mapreduce.html) - map reduce framework.\n* [Google MillWheel](https://research.google.com/pubs/pub41378.html) - fault tolerant stream processing framework.\n* [IBM Streams](https://www.ibm.com/analytics/us/en/technology/stream-computing/) - platform for distributed processing and real-time analytics.  Provides toolkits for advanced analytics like geospatial, time series, etc. out of the box.\n* [JAQL](https://code.google.com/p/jaql/) - declarative programming language for working with structured, semi-structured and unstructured data.\n* [Kite](http://kitesdk.org/docs/current/) - is a set of libraries, tools, examples, and documentation focused on making it easier to build systems on top of the Hadoop ecosystem.\n* [Metamarkets Druid](http://druid.io/) - framework for real-time analysis of large datasets.\n* [Netflix PigPen](https://github.com/Netflix/PigPen) - map-reduce for Clojure which compiles to Apache Pig.\n* [Nokia Disco](http://discoproject.org/) - MapReduce framework developed by Nokia.\n* [Onyx](http://www.onyxplatform.org/) - Distributed computation for the cloud.\n* [Pinterest Pinlater](https://medium.com/@Pinterest_Engineering/pinlater-an-asynchronous-job-execution-system-b8664cb8aa7d) - asynchronous job execution system.\n* [Pydoop](http://crs4.github.io/pydoop/) - Python MapReduce and HDFS API for Hadoop.\n* [Ray](https://github.com/ray-project/ray) - A fast and simple framework for building and running distributed applications. \n* [Rackerlabs Blueflood](http://blueflood.io/) - multi-tenant distributed metric processing system\n* [Skale](https://github.com/skale-me/skale-engine) - High performance distributed data processing in NodeJS.\n* [Stratosphere](http://stratosphere.eu/) - general purpose cluster computing framework.\n* [Streamdrill](https://streamdrill.com/) - useful for counting activities of event streams over different time windows and finding the most active one.\n* [streamsx.topology](https://github.com/IBMStreams/streamsx.topology) - Libraries to enable building IBM Streams application in Java, Python or Scala.\n* [Tuktu](https://github.com/UnderstandLingBV/Tuktu) - Easy-to-use platform for batch and streaming computation, built using Scala, Akka and Play!\n* [Twitter Heron](https://github.com/twitter/heron) - Heron is a realtime, distributed, fault-tolerant stream processing engine from Twitter replacing Storm.\n* [Twitter Scalding](https://github.com/twitter/scalding) - Scala library for Map Reduce jobs, built on Cascading.\n* [Twitter Summingbird](https://github.com/twitter/summingbird) - Streaming MapReduce with Scalding and Storm, by Twitter.\n* [Twitter TSAR](https://blog.twitter.com/engineering/en_us/a/2014/tsar-a-timeseries-aggregator.html) - TimeSeries AggregatoR by Twitter.\n* [Wallaroo](http://www.wallaroolabs.com/community) - The ultrafast and elastic data processing engine. Big or fast data - no fuss, no Java needed.\n\n## Distributed Filesystem\n\n* [Ambry](https://github.com/linkedin/ambry) - a distributed object store that supports storage of trillion of small immutable objects as well as billions of large objects.\n* [Apache HDFS](http://hadoop.apache.org/) - a way to store large files across multiple machines.\n* [Apache Kudu](http://kudu.apache.org/) - Hadoop's storage layer to enable fast analytics on fast data.\n* [BeeGFS](https://www.beegfs.io/content/) - formerly FhGFS, parallel distributed file system.\n* [Ceph Filesystem](http://ceph.com/ceph-storage/file-system/) - software storage platform designed.\n* [Disco DDFS](http://disco.readthedocs.org/en/latest/howto/ddfs.html) - distributed filesystem.\n* [Facebook Haystack](https://www.facebook.com/note.php?note_id=76191543919) - object storage system.\n* [Google GFS](http://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf) - distributed filesystem.\n* [Google Megastore](https://research.google.com/pubs/pub36971.html) - scalable, highly available storage.\n* [GridGain](https://www.gridgain.com/) - GGFS, Hadoop compliant in-memory file system.\n* [Lustre file system](http://wiki.lustre.org/) - high-performance distributed filesystem.\n* [Microsoft Azure Data Lake Store](https://hadoop.apache.org/docs/current/hadoop-azure-datalake/index.html) - HDFS-compatible storage in Azure cloud\n* [Quantcast File System QFS](https://www.quantcast.com/about-us/quantcast-file-system/) - open-source distributed file system.\n* [Red Hat GlusterFS](http://gluster.org/) - scale-out network-attached storage file system.\n* [Seaweed-FS](https://github.com/chrislusf/seaweedfs) - simple and highly scalable distributed file system.\n* [Alluxio](http://www.alluxio.org/) - reliable file sharing at memory speed across cluster frameworks.\n* [Tahoe-LAFS](https://www.tahoe-lafs.org/trac/tahoe-lafs) - decentralized cloud storage system.\n* [Baidu File System](https://github.com/baidu/bfs) - distributed filesystem.\n\n## Distributed Index\n\n* [Pilosa](https://github.com/pilosa/pilosa) Open source distributed bitmap index that dramatically accelerates queries across multiple, massive data sets. \n\n## Document Data Model\n\n* [Actian Versant](https://www.actian.com/data-management/ingres-sql-rdbms/) - commercial object-oriented database management systems .\n* [Crate Data](https://crate.io/) - is an open source massively scalable data store. It requires zero administration.\n* [Facebook Apollo](http://www.infoq.com/news/2014/06/facebook-apollo) - Facebook\u2019s Paxos-like NoSQL database.\n* [jumboDB](http://comsysto.github.io/jumbodb/) - document oriented datastore over Hadoop.\n* [LinkedIn Espresso](https://engineering.linkedin.com/data) - horizontally scalable document-oriented NoSQL data store.\n* [MarkLogic](http://www.marklogic.com/) - Schema-agnostic Enterprise NoSQL database technology.\n* [Microsoft Azure DocumentDB](https://azure.microsoft.com/en-us/services/cosmos-db/) - NoSQL cloud database service with protocol support for MongoDB \n* [MongoDB](https://www.mongodb.com/) - Document-oriented database system.\n* [RavenDB](https://ravendb.net/) - A transactional, open-source Document Database.\n* [RethinkDB](https://rethinkdb.com/) - document database that supports queries like table joins and group by.\n\n## Key Map Data Model\n\n**Note**: There is some term confusion in the industry, and two different things are called \"Columnar Databases\". Some, listed here, are distributed, persistent databases built around the \"key-map\" data model: all data has a (possibly composite) key, with which a map of key-value pairs is associated. In some systems, multiple such value maps can be associated with a key, and these maps are referred to as \"column families\" (with value map keys being referred to as \"columns\").\n\nAnother group of technologies that can also be called \"columnar databases\" is distinguished by how it stores data, on disk or in memory -- rather than storing data the traditional way, where all column values for a given key are stored next to each other, \"row by row\", these systems store all *column* values next to each other. So more work is needed to get all columns for a given key, but less work is needed to get all values for a given column.\n\nThe former group is referred to as \"key map data model\" here. The line between these and the [Key-value Data Model](#key-value-data-model) stores is fairly blurry.\n\nThe latter, being more about the storage format than about the data model, is listed under [Columnar Databases](#columnar-databases).\n\nYou can read more about this distinction on Prof. Daniel Abadi's blog: [Distinguishing two major types of Column Stores](http://dbmsmusings.blogspot.com/2010/03/distinguishing-two-major-types-of_29.html).\n\n* [Apache Accumulo](http://accumulo.apache.org/) - distributed key/value store, built on\u00a0Hadoop.\n* [Apache Cassandra](http://cassandra.apache.org/) - column-oriented distributed datastore, inspired by\u00a0BigTable.\n* [Apache HBase](http://hbase.apache.org/) - column-oriented distributed datastore, inspired by BigTable.\n* [Baidu Tera](https://github.com/baidu/tera) - an Internet-scale database, inspired by BigTable.\n* [Facebook HydraBase](https://code.facebook.com/posts/321111638043166/hydrabase-the-evolution-of-hbase-facebook/) - evolution of HBase made by Facebook.\n* [Google BigTable](http://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf) - column-oriented distributed datastore.\n* [Google Cloud Datastore](https://cloud.google.com/datastore/docs/concepts/overview) - is a fully managed, schemaless database for storing non-relational data over BigTable.\n* [Hypertable](http://www.hypertable.org/) - column-oriented distributed datastore, inspired by\u00a0BigTable.\n* [InfiniDB](https://github.com/infinidb/infinidb/) - is accessed through a MySQL interface and use massive parallel processing to parallelize queries.\n* [Tephra](https://github.com/caskdata/tephra) - Transactions for HBase.\n* [Twitter Manhattan](https://blog.twitter.com/engineering/en_us/a/2014/manhattan-our-real-time-multi-tenant-distributed-database-for-twitter-scale.html) - real-time, multi-tenant distributed database for Twitter scale.\n* [ScyllaDB](http://www.scylladb.com/) - column-oriented distributed datastore written in C++, totally compatible with Apache Cassandra.\n\n\n## Key-value Data Model\n\n* [Aerospike](http://www.aerospike.com/) - NoSQL flash-optimized, in-memory. Open source and \"Server code in 'C' (not Java or Erlang) precisely tuned to avoid context switching and memory copies.\"\n* [Amazon DynamoDB](https://aws.amazon.com/dynamodb/) - distributed key/value store, implementation of\u00a0Dynamo paper.\n* [Badger](https://open.dgraph.io/post/badger/) - a fast, simple, efficient, and persistent key-value store written natively in Go.\n* [Bolt](https://github.com/boltdb/bolt) - an embedded key-value database for Go.\n* [BTDB](https://github.com/Bobris/BTDB) - Key Value Database in .Net with Object DB Layer, RPC, dynamic IL and much more\n* [BuntDB](https://github.com/tidwall/buntdb) - a fast, embeddable, in-memory key/value database for Go with custom indexing and geospatial support.\n* [Edis](https://github.com/cbd/edis) - is a protocol-compatible Server replacement for Redis.\n* [ElephantDB](https://github.com/nathanmarz/elephantdb) - Distributed database specialized in exporting data from Hadoop.\n* [EventStore](https://geteventstore.com/) - distributed time series database.\n* [GhostDB](https://github.com/jakekgrog/GhostDB) - a distributed, in-memory, general purpose key-value data store that delivers microsecond performance at any scale.\n* [Graviton](https://github.com/deroproject/graviton) - a simple, fast, versioned, authenticated, embeddable key-value store database in pure Go(lang).\n* [GridDB](https://github.com/griddb/griddb_nosql) - suitable for sensor data stored in a timeseries.\n* [HyperDex](https://github.com/rescrv/HyperDex) - a scalable, next generation key-value and document store with a wide array of features, including consistency, fault tolerance and high performance.\n* [Ignite](https://ignite.apache.org/index.html) - is an in-memory key-value data store providing full SQL-compliant data access that can optionally be backed by disk storage.\n* [LinkedIn Krati](https://github.com/linkedin-sna/sna-page/tree/master/krati) - is a simple persistent data store with very low latency and high throughput.\n* [Linkedin Voldemort](http://www.project-voldemort.com/voldemort/) - distributed key/value storage system.\n* [Oracle NoSQL Database](http://www.oracle.com/technetwork/database/database-technologies/nosqldb/overview/index.html) - distributed key-value database by Oracle Corporation.\n* [Redis](https://redis.io/) - in memory key value datastore.\n* [Riak](https://github.com/basho/riak) - a decentralized datastore.\n* [Storehaus](https://github.com/twitter/storehaus) - library to work with asynchronous key value stores, by Twitter.\n* [SummitDB](https://github.com/tidwall/summitdb) - an in-memory, NoSQL key/value database, with disk persistance and using the Raft consensus algorithm.\n* [Tarantool](https://github.com/tarantool/tarantool) - an efficient NoSQL database and a Lua application server.\n* [TiKV](https://github.com/pingcap/tikv) - a distributed key-value database powered by Rust and inspired by Google Spanner and HBase.\n* [Tile38](https://github.com/tidwall/tile38) - a geolocation data store, spatial index, and realtime geofence, supporting a variety of object types including latitude/longitude points, bounding boxes, XYZ tiles, Geohashes, and GeoJSON\n* [TreodeDB](https://github.com/Treode/store) - key-value store that's replicated and sharded and provides atomic multirow writes.\n\n\n## Graph Data Model\n\n* [AgensGraph](http://www.agensgraph.com/) - a new generation multi-model graph database for the modern complex data environment.\n* [Apache Giraph](http://giraph.apache.org/) - implementation of Pregel, based on Hadoop.\n* [Apache Spark Bagel](http://spark.apache.org/docs/0.7.3/bagel-programming-guide.html) - implementation of Pregel, part of Spark.\n* [ArangoDB](https://www.arangodb.com/) - multi model distributed database.\n* [DGraph](https://github.com/dgraph-io/dgraph) - A scalable, distributed, low latency, high throughput graph database aimed at providing Google production level scale and throughput, with low enough latency to be serving real time user queries, over terabytes of structured data.\n* [EliasDB](https://github.com/krotik/eliasdb) - a lightweight graph based database that does not require any third-party libraries.\n* [Facebook TAO](https://www.facebook.com/notes/facebook-engineering/tao-the-power-of-the-graph/10151525983993920) - TAO is the distributed data store that is widely used at facebook to store and serve the social graph.\n* [GCHQ Gaffer](https://github.com/gchq/Gaffer) - Gaffer by GCHQ is a framework that makes it easy to store large-scale graphs in which the nodes and edges have statistics.\n* [Google Cayley](https://github.com/cayleygraph/cayley) - open-source graph database.\n* [Google Pregel](http://kowshik.github.io/JPregel/pregel_paper.pdf) - graph processing framework.\n* [GraphLab PowerGraph](https://turi.com/products/create/docs/) - a core C++ GraphLab API and a collection of high-performance machine learning and data mining toolkits built on top of the GraphLab API.\n* [GraphX](https://amplab.cs.berkeley.edu/publication/graphx-grades/) - resilient Distributed Graph System on Spark.\n* [Gremlin](https://github.com/tinkerpop/gremlin) - graph traversal Language.\n* [Infovore](https://github.com/paulhoule/infovore) - RDF-centric Map/Reduce framework.\n* [Intel GraphBuilder](https://01.org/graphbuilder/) - tools to construct large-scale graphs on top of Hadoop.\n* [JanusGraph](http://janusgraph.org) - open-source, distributed graph database\n  with multiple options for storage backends (Bigtable, HBase, Cassandra, etc.)\n  and indexing backends (Elasticsearch, Solr, Lucene).\n* [MapGraph](https://www.blazegraph.com/mapgraph-technology/) - Massively Parallel Graph processing on GPUs.\n* [Microsoft Graph Engine](https://github.com/Microsoft/GraphEngine) - a distributed in-memory data processing engine, underpinned by a strongly-typed in-memory key-value store and a general distributed computation engine.\n* [Neo4j](https://neo4j.com/) - graph database written entirely in Java.\n* [OrientDB](http://orientdb.com/) - document and graph database.\n* [Phoebus](https://github.com/xslogic/phoebus) - framework for large scale graph processing.\n* [Titan](http://thinkaurelius.github.io/titan/) - distributed graph database, built over Cassandra.\n* [Twitter FlockDB](https://github.com/twitter-archive/flockdb) - distributed graph database.\n* [NodeXL](https://nodexl.codeplex.com/) - A free, open-source template for Microsoft\u00ae Excel\u00ae 2007, 2010, 2013 and 2016 that makes it easy to explore network graphs.\n\n\n## Columnar Databases\n\n**Note** please read the note on [Key-Map Data Model](#key-map-data-model) section.\n\n* [Columnar Storage](http://the-paper-trail.org/blog/columnar-storage/) - an explanation of what columnar storage is and when you might want it.\n* [Actian Vector](http://www.actian.com/) - column-oriented analytic database.\n* [ClickHouse](https://clickhouse.yandex/) - an open-source column-oriented database management system that allows generating analytical data reports in real time.\n* [EventQL](http://eventql.io/) - a distributed, column-oriented database built for large-scale event collection and analytics.\n* [MonetDB](https://www.monetdb.org/) - column store database.\n* [Parquet](http://parquet.apache.org/) - columnar storage format for Hadoop.\n* [Pivotal Greenplum](https://pivotal.io/pivotal-greenplum) - purpose-built, dedicated analytic data warehouse that offers a columnar engine as well as a traditional row-based one.\n* [Vertica](https://www.vertica.com/) - is designed to manage large, fast-growing volumes of data and provide very fast query performance when used for data warehouses.\n* [SQream DB](http://sqream.com/) - A GPU powered big data database, designed for analytics and data warehousing, with ANSI-92 compliant SQL, suitable for data sets from 10TB to 1PB.\n* [Google BigQuery](https://cloud.google.com/bigquery/what-is-bigquery) - Google's cloud offering backed by their pioneering work on Dremel.\n* [Amazon Redshift](https://aws.amazon.com/redshift/) - Amazon's cloud offering, also based on a columnar datastore backend.\n* [IndexR](https://github.com/shunfei/indexr) - an open-source columnar storage format for fast & realtime analytic with big data.\n* [LocustDB](https://github.com/cswinter/LocustDB) - an experimental analytics database aiming to set a new standard for query performance on commodity hardware. \n\n## NewSQL Databases\n\n* [Actian Ingres](http://www.actian.com/products/operational-databases/) - commercially supported, open-source SQL relational database management system.\n* [ActorDB](https://github.com/biokoda/actordb) - a distributed SQL database with the scalability of a KV store, while keeping the query capabilities of a relational database.\n* [Amazon RedShift](http://aws.amazon.com/redshift/) - data warehouse service, based on PostgreSQL.\n* [BayesDB](https://github.com/probcomp/BayesDB) - statistic oriented SQL database.\n* [Bedrock](http://bedrockdb.com/) - a simple, modular, networked and distributed transaction layer built atop SQLite.\n* [CitusDB](https://www.citusdata.com/) - scales out PostgreSQL through sharding and replication.\n* [Cockroach](https://github.com/cockroachdb/cockroach) - Scalable, Geo-Replicated, Transactional Datastore.\n* [Comdb2](https://github.com/bloomberg/comdb2) - a clustered RDBMS built on optimistic concurrency control techniques.\n* [Datomic](http://www.datomic.com/) - distributed database designed to enable scalable, flexible and intelligent applications.\n* [FoundationDB](https://foundationdb.com/) - distributed database, inspired by\u00a0F1.\n* [Google F1](https://research.google.com/pubs/pub41344.html) - distributed SQL database built on Spanner.\n* [Google Spanner](https://research.google.com/archive/spanner.html) - globally distributed semi-relational database.\n* [H-Store](http://hstore.cs.brown.edu/) - is an experimental main-memory, parallel database management system that is optimized for on-line transaction processing (OLTP) applications.\n* [Haeinsa](https://github.com/VCNC/haeinsa) - linearly scalable multi-row, multi-table transaction library for HBase based on Percolator.\n* [HandlerSocket](https://www.percona.com/doc/percona-server/5.5/performance/handlersocket.html) - NoSQL plugin for MySQL/MariaDB.\n* [InfiniSQL](http://www.infinisql.org/) - infinity scalable RDBMS.\n* [KarelDB](https://github.com/rayokota/kareldb) - a relational database backed by Apache Kafka.\n* [Map-D](https://www.mapd.com/) - GPU in-memory database, big data analysis and visualization platform.\n* [MemSQL](http://www.memsql.com/) - in memory SQL database witho optimized columnar storage on flash.\n* [NuoDB](http://www.nuodb.com/) - SQL/ACID compliant distributed database.\n* [Oracle TimesTen in-Memory Database](http://www.oracle.com/technetwork/database/database-technologies/timesten/overview/index.html) - in-memory, relational database management system with persistence and recoverability.\n* [Pivotal GemFire XD](http://gemfirexd.docs.pivotal.io/latest/) - Low-latency, in-memory, distributed SQL data store. Provides SQL interface to in-memory table data, persistable in HDFS.\n* [SAP HANA](https://hana.sap.com/abouthana.html) - is an in-memory, column-oriented, relational database management system.\n* [SenseiDB](http://senseidb.github.io/sensei/) - distributed, realtime, semi-structured database.\n* [Sky](http://skydb.io/) - database used for flexible, high performance analysis of behavioral data.\n* [SymmetricDS](http://www.symmetricds.org/) - open source software for both file and database synchronization.\n* [TiDB](https://github.com/pingcap/tidb) - TiDB is a distributed SQL database. Inspired by the design of Google F1.\n* [VoltDB](https://www.voltdb.com/) - claims to be fastest in-memory database.\n* [yugabyteDB](https://github.com/YugaByte/yugabyte-db) - open source, high-performance, distributed SQL database compatible with PostgreSQL.\n\n## Time-Series Databases\n\n* [Axibase Time Series Database](http://axibase.com/products/axibase-time-series-database/) - Integrated time series database on top of HBase with built-in visualization, rule-engine and SQL support.\n* [Chronix](http://chronix.io/) - a time series storage built to store time series highly compressed and for fast access times.\n* [Cube](http://square.github.io/cube/) - uses MongoDB to store time series data.\n* [Heroic](https://spotify.github.io/heroic/#!/index) - is a scalable time series database based on Cassandra and Elasticsearch.\n* [InfluxDB](https://www.influxdata.com/) - a time series database with optimised IO and queries, supports pgsql and influx wire protocols.\n* [QuestDB](https://questdb.io/) - high-performance, open-source SQL database for applications in financial services, IoT, machine learning, DevOps and observability.\n* [IronDB](https://www.circonus.com/irondb/) - scalable, general-purpose time series database.\n* [Kairosdb](https://github.com/kairosdb/kairosdb) - similar to OpenTSDB but allows for Cassandra.\n* [M3DB](http://m3db.github.io/m3/m3db/) - a distributed time series database that can be used for storing realtime metrics at long retention.\n* [Newts](https://opennms.github.io/newts/) - a time series database based on Apache Cassandra.\n* [TDengine](https://github.com/taosdata/TDengine/) - a time series database in C utilizing unique features of IoT to improve read/write throughput and reduce space needed to store data\n* [OpenTSDB](http://opentsdb.net) - distributed time series database on top of HBase.\n* [Prometheus](https://prometheus.io/) - a time series database and service monitoring system.\n* [Beringei](https://github.com/facebookincubator/beringei) - Facebook's in-memory time-series database.\n* [TrailDB](http://traildb.io/) - an efficient tool for storing and querying series of events.\n* [Druid](https://github.com/druid-io/druid/) Column oriented distributed data store ideal for powering interactive applications\n* [Riak-TS](http://basho.com/products/riak-ts/) Riak TS is the only enterprise-grade NoSQL time series database optimized specifically for IoT and Time Series data.\n* [Akumuli](https://github.com/akumuli/Akumuli) Akumuli is a numeric time-series database. It can be used to capture, store and process time-series data in real-time. The word \"akumuli\" can be translated from esperanto as \"accumulate\".\n* [Rhombus](https://github.com/Pardot/Rhombus) A time-series object store for Cassandra that handles all the complexity of building wide row indexes.\n* [Dalmatiner DB](https://github.com/dalmatinerdb/dalmatinerdb) Fast distributed metrics database\n* [Blueflood](https://github.com/rackerlabs/blueflood) A distributed system designed to ingest and process time series data\n* [Timely](https://github.com/NationalSecurityAgency/timely) Timely is a time series database application that provides secure access to time series data based on Accumulo and Grafana.\n* [SiriDB](https://github.com/transceptor-technology/siridb-server) Highly-scalable, robust and fast, open source time series database with cluster functionality.\n* [Thanos](https://github.com/improbable-eng/thanos) - Thanos is a set of components to create a highly available metric system with unlimited storage capacity using multiple (existing) Prometheus deployments.\n* [VictoriaMetrics](https://github.com/VictoriaMetrics/VictoriaMetrics) - fast, scalable and resource-effective open-source TSDB compatible with Prometheus. Single-node and cluster versions included\n\n## SQL-like processing\n\n* [Actian SQL for Hadoop](http://www.actian.com/analytic-database/vectorh-sql-hadoop) - high performance interactive SQL access to all Hadoop data.\n* [Apache Drill](http://drill.apache.org/) - framework for interactive analysis, inspired by Dremel.\n* [Apache HCatalog](https://cwiki.apache.org/confluence/display/Hive/HCatalog) - table and storage management layer for Hadoop.\n* [Apache Hive](http://hive.apache.org/) - SQL-like data warehouse system for Hadoop.\n* [Apache Calcite](http://calcite.apache.org/) - framework that allows efficient translation of queries involving heterogeneous and federated data.\n* [Apache Phoenix](http://phoenix.apache.org/index.html) - SQL skin over HBase.\n* [Aster Database](http://www.teradata.com/products-and-services/Teradata-Aster/teradata-aster-database) - SQL-like analytic processing for MapReduce.\n* [Cloudera Impala](https://www.cloudera.com/products/apache-hadoop/impala.html) - framework for interactive analysis, Inspired by Dremel.\n* [Concurrent Lingual](http://www.cascading.org/projects/lingual/) - SQL-like query language for Cascading.\n* [Datasalt Splout SQL](http://www.datasalt.com/products/splout-sql/) - full SQL query engine for big datasets.\n* [Dremio](https://www.dremio.com/) - an open-source, SQL-like Data-as-a-Service Platform based on Apache Arrow.\n* [Facebook PrestoDB](https://prestodb.io/) - distributed SQL query engine.\n* [Google BigQuery](https://research.google.com/pubs/pub36632.html) - framework for interactive analysis, implementation of Dremel.\n* [Materialize](https://github.com/materializeinc/materialize) - is a streaming database for real-time applications using SQL for queries and supporting a large fraction of PostgreSQL.\n* [Invantive SQL](https://documentation.invantive.com/2017R2/invantive-sql-grammar/invantive-sql-grammar-17.30.html) - SQL engine for online and on-premise use with integrated local data replication and 70+ connectors.\n* [PipelineDB](https://www.pipelinedb.com/) - an open-source relational database that runs SQL queries continuously on streams, incrementally storing results in tables.\n* [Pivotal HDB](https://pivotal.io/pivotal-hdb) - SQL-like data warehouse system for\u00a0Hadoop.\n* [RainstorDB](http://rainstor.com/products/rainstor-database/) - database for storing petabyte-scale volumes of structured and semi-structured data.\n* [Spark Catalyst](https://github.com/apache/spark/tree/master/sql) - is a Query Optimization Framework for Spark and Shark.\n* [SparkSQL](https://databricks.com/blog/2014/03/26/spark-sql-manipulating-structured-data-using-spark-2.html) - Manipulating Structured Data Using Spark.\n* [Splice Machine](https://www.splicemachine.com/) - a full-featured SQL-on-Hadoop RDBMS with ACID transactions.\n* [Stinger](https://hortonworks.com/innovation/stinger/) - interactive query for Hive.\n* [Tajo](http://tajo.apache.org/) - distributed data warehouse system on Hadoop.\n* [Trafodion](https://wiki.trafodion.org/wiki/index.php/Main_Page) - enterprise-class SQL-on-HBase solution targeting big data transactional or operational workloads.\n\n## Data Ingestion\n* [redpanda](https://vectorized.io/redpanda) - A Kafka\u00ae replacement for mission critical systems; 10x faster. Written in C++.\n* [Amazon Kinesis](https://aws.amazon.com/kinesis/) - real-time processing of streaming data at massive scale.\n* [Amazon Web Services Glue](https://aws.amazon.com/glue/) -  serverless fully managed extract, transform, and load (ETL) service\n* [Census](https://getcensus.com/) - A reverse ETL product that let you sync data from your data warehouse to SaaS Applications. No engineering favors required\u2014just SQL.\n* [Apache Chukwa](http://chukwa.apache.org/) - data collection system.\n* [Apache Flume](http://flume.apache.org/) - service to manage large amount of log data.\n* [Apache Kafka](http://kafka.apache.org/) - distributed publish-subscribe messaging system.\n* [Apache NiFi](https://nifi.apache.org/) - Apache NiFi is an integrated data logistics platform for automating the movement of data between disparate systems.\n* [Apache Pulsar](https://github.com/apache/pulsar) - a distributed pub-sub messaging platform with a very flexible messaging model and an intuitive client API.\n* [Apache Sqoop](http://sqoop.apache.org/) - tool to transfer data between Hadoop and a structured datastore.\n* [Embulk](http://www.embulk.org) - open-source bulk data loader that helps data transfer between various databases, storages, file formats, and cloud services.\n* [Facebook Scribe](https://github.com/facebookarchive/scribe) - streamed log data aggregator.\n* [Fluentd](http://www.fluentd.org) - tool to collect events and logs.\n* [Gazette](https://github.com/gazette/core) - Distributed streaming infrastructure built on cloud storage which makes it easy to mix and match batch and streaming paradigms.\n* [Google Photon](https://research.google.com/pubs/pub41318.html) - geographically distributed system for joining multiple continuously flowing streams of data in real-time with high scalability and low latency.\n* [Heka](https://github.com/mozilla-services/heka) - open source stream processing software system.\n* [HIHO](https://github.com/sonalgoyal/hiho) - framework for connecting disparate data sources with Hadoop.\n* [Kestrel](https://github.com/papertrail/kestrel) - distributed message queue system.\n* [LinkedIn Databus](https://engineering.linkedin.com/data) - stream of change capture events for a database.\n* [LinkedIn Kamikaze](https://github.com/linkedin/kamikaze) - utility package for compressing sorted integer arrays.\n* [LinkedIn White Elephant](https://github.com/linkedin/white-elephant) - log aggregator and dashboard.\n* [Logstash](https://www.elastic.co/products/logstash) - a tool for managing events and logs.\n* [Netflix Suro](https://github.com/Netflix/suro) - log agregattor like Storm and Samza based on Chukwa.\n* [Pinterest Secor](https://github.com/pinterest/secor) - is a service implementing Kafka log persistance.\n* [Linkedin Gobblin](https://github.com/linkedin/gobblin) - linkedin's universal data ingestion framework.\n* [Skizze](https://github.com/skizzehq/skizze) - sketch data store to deal with all problems around counting and sketching using probabilistic data-structures.\n* [StreamSets Data Collector](https://github.com/streamsets/datacollector) - continuous big data ingest infrastructure with a simple to use IDE.\n* [Alooma](https://www.alooma.com/integrations/mysql) - data pipeline as a service enabling moving data sources such as MySQL into data warehouses.\n* [RudderStack](https://github.com/rudderlabs/rudder-server) - an open source customer data infrastructure (segment, mParticle  alternative) written in go.\n\n## Service Programming\n\n* [Akka Toolkit](http://akka.io/) - runtime for distributed, and fault tolerant event-driven applications on the JVM.\n* [Apache Avro](http://avro.apache.org/) - data serialization system.\n* [Apache Curator](http://curator.apache.org/) - Java libaries for Apache ZooKeeper.\n* [Apache Karaf](http://karaf.apache.org/) - OSGi runtime that runs on top of any OSGi framework.\n* [Apache Thrift](http://thrift.apache.org//) - framework to build binary protocols.\n* [Apache Zookeeper](http://zookeeper.apache.org/) - centralized service for process management.\n* [Google Chubby](https://research.google.com/archive/chubby.html) - a lock service for loosely-coupled distributed systems.\n* [Hydrosphere Mist](https://github.com/Hydrospheredata/mist) - a service for exposing Apache Spark analytics jobs and machine learning models as realtime, batch or reactive web services.\n* [Linkedin Norbert](https://engineering.linkedin.com/data) - cluster manager.\n* [Mara](https://github.com/mara/data-integration) - A lightweight opinionated ETL framework, halfway between plain scripts and Apache Airflow\n* [OpenMPI](https://www.open-mpi.org/) - message passing framework.\n* [Serf](https://www.serf.io/) - decentralized solution for service discovery and orchestration.\n* [Spotify Luigi](https://github.com/spotify/luigi) - a Python package for building complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization, handling failures, command line integration, and much more.\n* [Spring XD](https://github.com/spring-projects/spring-xd) - distributed and extensible system for data ingestion, real time analytics, batch processing, and data export.\n* [Twitter Elephant Bird](https://github.com/twitter/elephant-bird) - libraries for working with LZOP-compressed data.\n* [Twitter Finagle](https://twitter.github.io/finagle/) - asynchronous network stack for the JVM.\n\n## Scheduling\n\n* [Apache Airflow](https://github.com/apache/incubator-airflow) - a platform to programmatically author, schedule and monitor workflows.\n* [Apache Aurora](http://aurora.apache.org/) - is a service scheduler that runs on top of Apache Mesos.\n* [Apache Falcon](http://falcon.apache.org/) - data management framework.\n* [Apache Oozie](http://oozie.apache.org/) - workflow job scheduler.\n* [Azure Data Factory](https://docs.microsoft.com/en-us/azure/data-factory/data-factory-introduction) - cloud-based pipeline orchestration for on-prem, cloud and HDInsight\n* [Chronos](http://mesos.github.io/chronos/) - distributed and fault-tolerant scheduler.\n* [Cronicle](https://github.com/jhuckaby/Cronicle) - Distributed, easy to install, NodeJS based, task scheduler\n* [Dagster](https://github.com/dagster-io/dagster) - a data orchestrator for machine learning, analytics, and ETL.\n* [Linkedin Azkaban](https://azkaban.github.io/) - batch workflow job scheduler.\n* [Schedoscope](https://github.com/ottogroup/schedoscope) - Scala DSL for agile scheduling of Hadoop jobs.\n* [Sparrow](https://github.com/radlab/sparrow) - scheduling platform.\n\n\n## Machine Learning\n\n* [Azure ML Studio](https://studio.azureml.net/) - Cloud-based AzureML, R, Python Machine Learning platform\n* [brain](https://github.com/harthur/brain) - Neural networks in JavaScript.\n* [Oryx](https://github.com/OryxProject/oryx) - Lambda architecture on Apache Spark, Apache Kafka for real-time large scale machine learning.\n* [Concurrent Pattern](http://www.cascading.org/projects/pattern/) - machine learning library for Cascading.\n* [convnetjs](https://github.com/karpathy/convnetjs) - Deep Learning in Javascript. Train Convolutional Neural Networks (or ordinary ones) in your browser.\n* [DataVec](https://github.com/deeplearning4j/DataVec) - A vectorization and data preprocessing library for deep learning in Java and Scala. Part of the Deeplearning4j ecosystem. \n* [Deeplearning4j](https://github.com/deeplearning4j) - Fast, open deep learning for the JVM (Java, Scala, Clojure). A neural network configuration layer powered by a C++ library. Uses Spark and Hadoop to train nets on multiple GPUs and CPUs.\n* [Decider](https://github.com/danielsdeleo/Decider) - Flexible and Extensible Machine Learning in Ruby.\n* [ENCOG](http://www.heatonresearch.com/encog/) - machine learning framework that supports a variety of advanced algorithms, as well as support classes to normalize and process data.\n* [etcML](http://www.etcml.com/) - text classification with machine learning.\n* [Etsy Conjecture](https://github.com/etsy/Conjecture) - scalable Machine Learning in Scalding.\n* [Feast](https://github.com/gojek/feast) - A feature store for the management, discovery, and access of machine learning features. Feast provides a consistent view of feature data for both model training and model serving.\n* [GraphLab Create](https://dato.com/products/create/) - A machine learning platform in Python with a broad collection of ML toolkits, data engineering, and deployment tools.\n* [H2O](https://github.com/h2oai/h2o-3/) - statistical, machine learning and math runtime with Hadoop. R and Python.\n* [Karate Club](https://github.com/benedekrozemberczki/karateclub) - An unsupervised machine learning library for graph structured data. Python\n* [Keras](https://github.com/fchollet/keras) - An intuitive neural net API inspired by Torch that runs atop Theano and Tensorflow.\n* [Lambdo](https://github.com/johnsonc/lambdo) - Lambdo is a workflow engine which significantly simplifies the analysis process by unifying feature engineering and machine learning operations.\n* [Little Ball of Fur](https://github.com/benedekrozemberczki/littleballoffur) - A subsampling library for graph structured data. Python\n* [Mahout](http://mahout.apache.org/) - An Apache-backed machine learning library for Hadoop.\n* [MLbase](http://www.mlbase.org/) - distributed machine learning libraries for the BDAS stack.\n* [MLPNeuralNet](https://github.com/nikolaypavlov/MLPNeuralNet) - Fast multilayer perceptron neural network library for iOS and Mac OS X.\n* [ML Workspace](https://github.com/ml-tooling/ml-workspace) - All-in-one web-based IDE specialized for machine learning and data science.\n* [MOA](http://moa.cms.waikato.ac.nz) - MOA performs big data stream mining in real time, and large scale machine learning.\n* [MonkeyLearn](https://monkeylearn.com/) - Text mining made easy. Extract and classify data from text.\n* [ND4J](https://github.com/deeplearning4j/nd4j) - A matrix library for the JVM. Numpy for Java. \n* [nupic](https://github.com/numenta/nupic) - Numenta Platform for Intelligent Computing: a brain-inspired machine intelligence platform, and biologically accurate neural network based on cortical learning algorithms.\n* [PredictionIO](http://predictionio.incubator.apache.org/index.html) - machine learning server buit on Hadoop, Mahout and Cascading.\n* [PyTorch Geometric Temporal](https://github.com/benedekrozemberczki/pytorch_geometric_temporal) - a temporal extension library for PyTorch Geometric .\n* [RL4J](https://github.com/deeplearning4j/rl4j) - Reinforcement learning for Java and Scala. Includes Deep-Q learning and A3C algorithms, and integrates with Open AI's Gym. Runs in the Deeplearning4j ecosystem. \n* [SAMOA](http://samoa.incubator.apache.org/) - distributed streaming machine learning framework.\n* [scikit-learn](https://github.com/scikit-learn/scikit-learn) - scikit-learn: machine learning in Python.\n* [Shapley](https://github.com/benedekrozemberczki/shapley) - A data-driven framework to quantify the value of classifiers in a machine learning ensemble. \n* [Spark MLlib](http://spark.apache.org/docs/0.9.0/mllib-guide.html) - a Spark implementation of some common machine learning (ML) functionality.\n* [Sibyl](https://users.soe.ucsc.edu/~niejiazhong/slides/chandra.pdf) - System for Large Scale Machine Learning at Google.\n* [TensorFlow](https://github.com/tensorflow/tensorflow) - Library from Google for machine learning using data flow graphs.\n* [Theano](https://github.com/theano) - A Python-focused machine learning library supported by the University of Montreal.\n* [Torch](https://github.com/torch) - A deep learning library with a Lua API, supported by NYU and Facebook.\n* [Velox](https://github.com/amplab/velox-modelserver) - System for serving machine learning predictions.\n* [Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit/wiki) - learning system sponsored by Microsoft and Yahoo!.\n* [WEKA](http://www.cs.waikato.ac.nz/ml/weka/) - suite of machine learning software.\n* [BidMach](https://github.com/BIDData/BIDMach) - CPU and GPU-accelerated Machine Learning Library.\n\n## Benchmarking\n\n* [Apache Hadoop Benchmarking](https://issues.apache.org/jira/browse/MAPREDUCE-3561) - micro-benchmarks for testing Hadoop performances.\n* [Berkeley SWIM Benchmark](https://github.com/SWIMProjectUCB/SWIM/wiki) - real-world big data workload benchmark.\n* [Intel HiBench](https://github.com/intel-hadoop/HiBench) - a Hadoop benchmark suite.\n* [PUMA Benchmarking](https://issues.apache.org/jira/browse/MAPREDUCE-5116) - benchmark suite for MapReduce applications.\n* [Yahoo Gridmix3](http://yahoohadoop.tumblr.com/post/98294079296/gridmix3-emulating-production-workload-for) - Hadoop cluster benchmarking from Yahoo engineer team.\n* [Deeplearning4j Benchmarks](https://github.com/deeplearning4j/dl4j-benchmark)\n\n## Security\n* [Apache Ranger](http://ranger.apache.org/) - Central security admin & fine-grained authorization for Hadoop\n* [Apache Eagle](http://eagle.apache.org/) - real time monitoring solution\n* [Apache Knox Gateway](http://knox.apache.org/) - single point of secure access for Hadoop clusters.\n* [Apache Sentry](http://incubator.apache.org/projects/sentry.html) - security module for data stored in Hadoop.\n* [BDA](https://github.com/kotobukki/BDA/) - The vulnerability detector for Hadoop and Spark\n\n## System Deployment\n\n* [Apache Ambari](http://ambari.apache.org/) - operational framework for Hadoop mangement.\n* [Apache Bigtop](http://bigtop.apache.org//) - system deployment framework for the Hadoop ecosystem.\n* [Apache Helix](http://helix.apache.org/) - cluster management framework.\n* [Apache Mesos](http://mesos.apache.org/) - cluster manager.\n* [Apache Slider](https://github.com/apache/incubator-slider) - is a YARN application to deploy existing distributed applications on YARN.\n* [Apache Whirr](http://whirr.apache.org/) - set of libraries for running cloud services.\n* [Apache YARN](https://hortonworks.com/hadoop/yarn/) - Cluster manager.\n* [Brooklyn](http://brooklyncentral.github.io/) - library that simplifies application deployment and management.\n* [Buildoop](http://buildoop.github.io/) - Similar to Apache BigTop based on Groovy language.\n* [Cloudera HUE](http://gethue.com/) - web application for interacting with Hadoop.\n* [Facebook Prism](http://www.wired.com/2012/08/facebook-prism/) - multi datacenters replication system.\n* [Google Borg](https://www.wired.com/2013/03/google-borg-twitter-mesos/all/) - job scheduling and monitoring system.\n* [Google Omega](https://www.youtube.com/watch?v=0ZFMlO98Jkc) - job scheduling and monitoring system.\n* [Hortonworks HOYA](https://hortonworks.com/blog/introducing-hoya-hbase-on-yarn/) - application that can deploy HBase cluster on YARN.\n* [Kubernetes](https://kubernetes.io/) - a system for automating deployment, scaling, and management of containerized applications.\n* [Marathon](https://github.com/mesosphere/marathon) - Mesos framework for long-running services.\n* [Linkis](https://github.com/WeBankFinTech/Linkis) - Linkis helps easily connect to various back-end computation/storage engines.\n\n## Applications\n\n* [411](https://github.com/etsy/411) - an web application for alert management resulting from scheduled searches into Elasticsearch.\n* [Adobe spindle](https://github.com/adobe-research/spindle) - Next-generation web analytics processing with Scala, Spark, and Parquet.\n* [Apache Metron](http://metron.apache.org/) - a platform that integrates a variety of open source big data technologies in order to offer a centralized tool for security monitoring and analysis.\n* [Apache Nutch](http://nutch.apache.org/) - open source web crawler.\n* [Apache OODT](http://oodt.apache.org/) - capturing, processing and sharing of data for NASA's scientific archives.\n* [Apache Tika](https://tika.apache.org/) - content analysis toolkit.\n* [Argus](https://github.com/salesforce/Argus) - Time series monitoring and alerting platform.\n* [AthenaX](https://github.com/uber/AthenaX) - a streaming analytics platform that enables users to run production-quality, large scale streaming analytics using Structured Query Language (SQL).\n* [Atlas](https://github.com/Netflix/atlas) - a backend for managing dimensional time series data.\n* [Countly](https://count.ly/) - open source mobile and web analytics platform, based on Node.js & MongoDB.\n* [Domino](https://www.dominodatalab.com/) - Run, scale, share, and deploy models \u2014 without any infrastructure.\n* [Eclipse BIRT](http://www.eclipse.org/birt/) - Eclipse-based reporting system.\n* [ElastAert](https://github.com/Yelp/elastalert) - ElastAlert is a simple framework for alerting on anomalies, spikes, or other patterns of interest from data in ElasticSearch.\n* [Eventhub](https://github.com/Codecademy/EventHub) - open source event analytics platform.\n* [HASH](https://hash.ai) - open source simulation and visualization platform.\n* [Hermes](https://github.com/allegro/hermes) - asynchronous message broker built on top of Kafka.\n* [Hunk](https://www.splunk.com/en_us/download/hunk.html) - Splunk analytics for Hadoop.\n* [Imhotep](http://opensource.indeedeng.io/imhotep/) - Large scale analytics platform by indeed.\n* [Indicative](https://www.indicative.com/) - Web & mobile analytics tool, with data warehouse (AWS, BigQuery) integration.\n* [Jupyter](https://jupyter.org/) - Notebook and project application for interactive data science and scientific computing across all programming languages.\n* [MADlib](http://madlib.incubator.apache.org/community/) - data-processing library of an RDBMS to analyze data.\n* [Kapacitor](https://github.com/influxdata/kapacitor) - an open source framework for processing, monitoring, and alerting on time series data.\n* [Kylin](http://kylin.apache.org/) - open source Distributed Analytics Engine from eBay.\n* [PivotalR](https://github.com/pivotalsoftware/PivotalR) - R on Pivotal HD / HAWQ and PostgreSQL.\n* [Rakam](https://github.com/rakam-io/rakam) - open-source real-time custom analytics platform powered by Postgresql, Kinesis and PrestoDB. \n* [Qubole](https://www.qubole.com/) - auto-scaling Hadoop cluster, built-in data connectors.\n* [SnappyData](https://github.com/SnappyDataInc/snappydata) - a distributed in-memory data store for real-time operational analytics, delivering stream analytics, OLTP (online transaction processing) and OLAP (online analytical processing) built on Spark in a single integrated cluster.\n* [Snowplow](https://github.com/snowplow/snowplow) - enterprise-strength web and event analytics, powered by Hadoop, Kinesis, Redshift and Postgres.\n* [SparkR](http://amplab-extras.github.io/SparkR-pkg/) - R frontend for Spark.\n* [Splunk](https://www.splunk.com/) - analyzer for machine-generated data.\n* [Sumo Logic](https://www.sumologic.com/) - cloud based analyzer for machine-generated data.\n* [Talend](http://www.talend.com/products/big-data/) - unified open source environment for YARN, Hadoop, HBASE, Hive, HCatalog & Pig.\n\n## Search engine and framework\n\n* [Apache Lucene](http://lucene.apache.org/) - Search engine library.\n* [Apache Solr](http://lucene.apache.org/solr/) - Search platform for Apache Lucene.\n* [Elassandra](https://github.com/strapdata/elassandra) - is a fork of Elasticsearch modified to run on top of Apache Cassandra in a scalable and resilient peer-to-peer architecture.\n* [ElasticSearch](https://www.elastic.co/) - Search and analytics engine based on Apache\u00a0Lucene.\n* [Enigma.io](https://www.enigma.com/) \u2013 Freemium robust web application for exploring, filtering, analyzing, searching and exporting massive datasets scraped from across the Web.\n* [Google Caffeine](https://googleblog.blogspot.it/2010/06/our-new-search-index-caffeine.html) - continuous indexing system.\n* [Google Percolator](https://research.google.com/pubs/pub36726.html) - continuous indexing system.\n* [HBase Coprocessor](https://blogs.apache.org/hbase/entry/coprocessor_introduction) - implementation of\u00a0Percolator, part of\u00a0HBase.\n* [Lily HBase Indexer](http://ngdata.github.io/hbase-indexer/) - quickly and easily search for any content stored in HBase.\n* [LinkedIn Bobo](http://senseidb.github.io/bobo/) - is a Faceted Search implementation written purely in Java, an extension to Apache Lucene.\n* [LinkedIn Cleo](https://github.com/linkedin/cleo) - is a flexible software library for enabling rapid development of partial, out-of-order and real-time typeahead search.\n* [LinkedIn Galene](https://engineering.linkedin.com/search/did-you-mean-galene) - search architecture at LinkedIn.\n* [LinkedIn Zoie](https://github.com/senseidb/zoie) - is a realtime search/indexing system written in Java.\n* [MG4J](http://mg4j.di.unimi.it/) - MG4J (Managing Gigabytes for Java) is a full-text search engine for large document collections written in Java. It is highly customisable, high-performance and provides state-of-the-art features and new research algorithms.\n* [Sphinx Search Server](http://sphinxsearch.com/) - fulltext search engine.\n* [Vespa](http://vespa.ai/) - is an engine for low-latency computation over large data sets. It stores and indexes your data such that queries, selection and processing over the data can be performed at serving time.\n* [Facebook Faiss](https://github.com/facebookresearch/faiss) - is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. Faiss is written in C++ with complete wrappers for Python/numpy.\n* [Annoy](https://github.com/spotify/annoy) - is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are mmapped into memory so that many processes may share the same data.\n* [Weaviate](https://github.com/semi-technologies/weaviate) - Weaviate is a GraphQL-based semantic search engine with build-in (word) embeddings.\n\n## MySQL forks and evolutions\n\n* [Amazon RDS](https://aws.amazon.com/rds/) - MySQL databases in Amazon's cloud.\n* [Drizzle](http://www.drizzle.org/) - evolution of MySQL 6.0.\n* [Google Cloud SQL](https://cloud.google.com/sql/docs/) - MySQL databases in Google's cloud.\n* [MariaDB](https://mariadb.org/) - enhanced, drop-in replacement for MySQL.\n* [MySQL Cluster](https://www.mysql.com/products/cluster/) - MySQL implementation using NDB Cluster storage engine.\n* [Percona Server](https://www.percona.com/software/mysql-database/percona-server) - enhanced, drop-in replacement for MySQL.\n* [ProxySQL](https://github.com/renecannao/proxysql) - High Performance Proxy for MySQL.\n* [TokuDB](https://www.percona.com/) - TokuDB is a storage engine for MySQL and MariaDB.\n* [WebScaleSQL](http://webscalesql.org/) - is a collaboration among engineers from several companies that face similar challenges in running MySQL at scale.\n\n## PostgreSQL forks and evolutions\n\n* [HadoopDB](http://db.cs.yale.edu/hadoopdb/hadoopdb.html) - hybrid of MapReduce and DBMS.\n* [IBM Netezza](http://www-01.ibm.com/software/data/netezza/) - high-performance data warehouse appliances.\n* [Postgres-XL](http://www.postgres-xl.org/) - Scalable Open Source PostgreSQL-based Database Cluster.\n* [RecDB](http://www-users.cs.umn.edu/~sarwat/RecDB/) - Open Source Recommendation Engine Built Entirely Inside PostgreSQL.\n* [Stado](http://www.stormdb.com/community/stado) - open source MPP database system solely targeted at data warehousing and data mart applications.\n* [Yahoo Everest](https://www.scribd.com/doc/3159239/70-Everest-PGCon-RT) - multi-peta-byte database / MPP derived by PostgreSQL.\n* [TimescaleDB](http://www.timescale.com/) - An open-source time-series database optimized for fast ingest and complex queries\n* [PipelineDB](https://www.pipelinedb.com/) - The Streaming SQL Database. An open-source relational database that runs SQL queries continuously on streams, incrementally storing results in tables\n\n## Memcached forks and evolutions\n\n* [Facebook McDipper](https://www.facebook.com/notes/facebook-engineering/mcdipper-a-key-value-cache-for-flash-storage/10151347090423920) - key/value cache for flash storage.\n* [Facebook Memcached](https://www.facebook.com/notes/facebook-engineering/scaling-memcache-at-facebook/10151411410803920) - fork of Memcache.\n* [Twemproxy](https://github.com/twitter/twemproxy) - A fast, light-weight proxy for memcached and redis.\n* [Twitter Fatcache](https://github.com/twitter/fatcache) - key/value cache for flash storage.\n* [Twitter Twemcache](https://github.com/twitter/twemcache) - fork of Memcache.\n\n## Embedded Databases\n\n* [Actian PSQL](http://www.actian.com/products/operational-databases/) - ACID-compliant DBMS developed by Pervasive Software, optimized for embedding in applications.\n* [BerkeleyDB](https://www.oracle.com/database/berkeley-db/index.html) - a software library that provides a high-performance embedded database for key/value data.\n* [HanoiDB](https://github.com/krestenkrab/hanoidb) - Erlang LSM BTree Storage.\n* [LevelDB](https://github.com/google/leveldb) - a fast key-value storage library written at Google that provides an ordered mapping from string keys to string values.\n* [LMDB](https://symas.com/mdb/) - ultra-fast, ultra-compact key-value embedded data store developed by Symas.\n* [RocksDB](http://rocksdb.org/) - embeddable persistent key-value store for fast storage based on LevelDB.\n\n## Business Intelligence\n\n* [BIME Analytics](https://www.bimeanalytics.com/?lang=en) - business intelligence platform in the cloud.\n* [Blazer](https://github.com/ankane/blazer) - business intelligence made simple.\n* [Chartio](https://chartio.com) - lean business intelligence platform to visualize and explore your data.\n* [Count](https://count.co) - notebook-based anlytics and visualisation platform using SQL or drag-and-drop.\n* [datapine](https://www.datapine.com/) - self-service business intelligence tool in the cloud.\n* [Dekart](https://dekart.xyz/) - Large scale geospatial analytics for Google BigQuery based on Kepler.gl.\n* [GoodData](https://www.gooddata.com/) - platform for data products and embedded analytics.\n* [Jaspersoft](https://www.jaspersoft.com/) - powerful business intelligence suite.\n* [Jedox Palo](https://www.jedox.com/en/) - customisable Business Intelligence platform.\n* [Jethrodata](https://jethro.io/) - Interactive Big Data Analytics.\n* [intermix.io](https://intermix.io/) - Performance Monitoring for Amazon Redshift\n* [Metabase](https://github.com/metabase/metabase) - The simplest, fastest way to get business intelligence and analytics to everyone in your company.\n* [Microsoft](http://www.microsoft.com/en-us/server-cloud/solutions/business-intelligence/default.aspx) - business intelligence software and platform.\n* [Microstrategy](https://www.microstrategy.com/) - software platforms for business intelligence, mobile intelligence, and network applications.\n* [Numeracy](https://numeracy.co/) - Fast, clean SQL client and business intelligence.\n* [Pentaho](http://www.pentaho.com/) - business intelligence platform.\n* [Qlik](http://www.qlik.com/us/) - business intelligence and analytics platform.\n* [Redash](https://redash.io/) - Open source business intelligence platform, supporting multiple data sources and planned queries.\n* [Saiku Analytics](https://www.meteorite.bi/) - Open source analytics platform.\n* [Knowage](https://www.knowage-suite.com/) - open source business intelligence platform. (former [SpagoBi](http://www.spagobi.org/))\n* [SparklineData SNAP](http://sparklinedata.com/) - modern B.I platform powered by Apache Spark.\n* [Tableau](https://www.tableau.com/) - business intelligence platform.\n* [Zoomdata](https://www.zoomdata.com/) - Big Data Analytics.\n\n\n## Data Visualization\n\n* [Airpal](https://github.com/airbnb/airpal) - Web UI for PrestoDB.\n* [AnyChart](http://www.anychart.com) - fast, simple and flexible JavaScript (HTML5) charting library featuring pure JS API.\n* [Arbor](https://github.com/samizdatco/arbor) - graph visualization library using web workers and jQuery.\n* [Banana](https://github.com/LucidWorks/banana) - visualize logs and time-stamped data stored in Solr. Port of Kibana.\n* [Bloomery](https://github.com/ufukomer/bloomery) - Web UI for Impala.\n* [Bokeh](http://bokeh.pydata.org/en/latest/) - A powerful Python interactive visualization library that targets modern web browsers for presentation, with the goal of providing elegant, concise construction of novel graphics in the style of D3.js, but also delivering this capability with high-performance interactivity over very large or streaming datasets.\n* [C3](http://c3js.org/) - D3-based reusable chart library\n* [CartoDB](https://github.com/CartoDB/cartodb) - open-source or freemium hosting for geospatial databases with powerful front-end editing capabilities and a robust API.\n* [chartd](http://chartd.co/) - responsive, retina-compatible charts with just an img tag.\n* [Chart.js](http://www.chartjs.org/) - open source HTML5 Charts visualizations.\n* [Chartist.js](https://github.com/gionkunz/chartist-js) - another open source HTML5 Charts visualization.\n* [Crossfilter](http://square.github.io/crossfilter/) -  JavaScript library for exploring large multivariate datasets in the browser. Works well with dc.js and d3.js.\n* [Cubism](https://github.com/square/cubism) - JavaScript library for time series visualization.\n* [Cytoscape](http://cytoscape.github.io/) - JavaScript library for visualizing complex networks.\n* [DC.js](http://dc-js.github.io/dc.js/) - Dimensional charting built to work natively with crossfilter rendered using d3.js. Excellent for connecting charts/additional metadata to hover events in D3.\n* [D3](https://d3js.org/) - javaScript library for manipulating documents.\n* [D3.compose](https://github.com/CSNW/d3.compose) - Compose complex, data-driven visualizations from reusable charts and components.\n* [D3Plus](http://d3plus.org) - A fairly robust set of reusable charts and styles for d3.js.\n* [Dash](https://github.com/plotly/dash) - Analytical Web Apps for Python, R, Julia, and Jupyter. Built on top of plotly, no JS required\n* [Dekart](https://dekart.xyz/) - Large scale geospatial analytics for Google BigQuery based on Kepler.gl.\n* [DevExtreme React Chart](https://devexpress.github.io/devextreme-reactive/react/chart/) - High-performance plugin-based React chart for Bootstrap and Material Design.\n* [Echarts](https://github.com/ecomfe/echarts) - Baidus enterprise charts.\n* [Envisionjs](https://github.com/HumbleSoftware/envisionjs) - dynamic HTML5 visualization.\n* [FnordMetric](https://metrictools.org/) - write SQL queries that return SVG charts rather than tables\n* [Frappe Charts](https://frappe.io/charts) - GitHub-inspired simple and modern SVG charts for the web with zero dependencies.\n* [Freeboard](https://github.com/Freeboard/freeboard) - pen source real-time dashboard builder for IOT and other web mashups.\n* [Gephi](https://github.com/gephi/gephi) - An award-winning open-source platform for visualizing and manipulating large graphs and network connections. It's like Photoshop, but for graphs. Available for Windows and Mac OS X.\n* [Google Charts](https://developers.google.com/chart/) - simple charting API.\n* [Grafana](https://grafana.com/) - graphite dashboard frontend, editor and graph composer.\n* [Graphite](http://graphiteapp.org/) - scalable Realtime Graphing.\n* [Highcharts](https://www.highcharts.com/) - simple and flexible charting API.\n* [IPython](http://ipython.org/) - provides a rich architecture for interactive computing.\n* [Kibana](https://www.elastic.co/products/kibana) - visualize logs and time-stamped data\n* [Lumify](http://lumify.io/) - open source big data analysis and visualization platform\n* [Matplotlib](https://github.com/matplotlib/matplotlib) - plotting with Python.\n* [Metricsgraphic.js](https://metricsgraphicsjs.org/) - a library built on top of D3 that is optimized for time-series data\n* [NVD3](http://nvd3.org/) - chart components for d3.js.\n* [Peity](https://github.com/benpickles/peity) - Progressive SVG bar, line and pie charts.\n* [Plot.ly](https://plot.ly/) - Easy-to-use web service that allows for rapid creation of complex charts, from heatmaps to histograms. Upload data to create and style charts with Plotly's online spreadsheet. Fork others' plots.\n* [Plotly.js](https://github.com/plotly/plotly.js) The open source javascript graphing library that powers plotly.\n* [Recline](https://github.com/okfn/recline) - simple but powerful library for building data applications in pure Javascript and HTML.\n* [Redash](https://github.com/getredash/redash) - open-source platform to query and visualize data.\n* [ReCharts](http://recharts.org/) - A composable charting library built on React components\n* [Shiny](http://shiny.rstudio.com/) - a web application framework for R.\n* [Sigma.js](https://github.com/jacomyal/sigma.js) - JavaScript library dedicated to graph drawing.\n* [Superset](https://github.com/apache/incubator-superset) - a data exploration platform designed to be visual, intuitive and interactive, making it easy to slice, dice and visualize data and perform analytics at the speed of thought.\n* [Vega](https://github.com/vega/vega) - a visualization grammar.\n* [Zeppelin](https://github.com/ZEPL/zeppelin) - a notebook-style collaborative data analysis.\n* [Zing Charts](https://www.zingchart.com/) - JavaScript charting library for big data.\n* [DataSphere Studio](https://github.com/WeBankFinTech/DataSphereStudio) - one-stop data application development management portal.\n\n## Internet of things and sensor data\n* [Apache Edgent (Incubating)](http://edgent.apache.org/) - a programming model and micro-kernel style runtime that can be embedded in gateways and small footprint edge devices enabling local, real-time, analytics on the edge devices.\n* [Azure IoT Hub](https://azure.microsoft.com/en-us/services/iot-hub/) - Cloud-based bi-directional monitoring and messaging hub\n* [TempoIQ](https://www.tempoiq.com/) - Cloud-based sensor analytics.\n* [2lemetry](http://2lemetry.com/) - Platform for Internet of things.\n* [Pubnub](https://www.pubnub.com/) - Data stream network\n* [ThingWorx](https://www.thingworx.com/) - Rapid development and connection of intelligent systems\n* [IFTTT](https://ifttt.com/) - If this then that\n* [Evrything](https://evrythng.com/)- Making products smart\n* [NetLytics](https://github.com/marty90/netlytics/) - Analytics platform to process network data on Spark.\n* [Ably](https://ably.com/) - Pub/sub messaging platform for IoT \n\n## Interesting Readings\n\n* [Big Data Benchmark](https://amplab.cs.berkeley.edu/benchmark/) - Benchmark of Redshift, Hive, Shark, Impala and Stiger/Tez.\n* [NoSQL Comparison](https://kkovacs.eu/cassandra-vs-mongodb-vs-couchdb-vs-redis) - Cassandra vs MongoDB vs CouchDB vs Redis vs Riak vs HBase vs Couchbase vs Neo4j vs Hypertable vs ElasticSearch vs Accumulo vs VoltDB vs Scalaris comparison.\n* [Monitoring Kafka performance](https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics?ref=awesome) - Guide to monitoring Apache Kafka, including native methods for metrics collection.\n* [Monitoring Hadoop performance](https://www.datadoghq.com/blog/monitor-hadoop-metrics?ref=awesome) - Guide to monitoring Hadoop, with an overview of Hadoop architecture, and native methods for metrics collection.\n* [Monitoring Cassandra performance](https://www.datadoghq.com/blog/how-to-monitor-cassandra-performance-metrics/?ref=awesome) - Guide to monitoring Cassandra, including native methods for metrics collection.\n\n## Interesting Papers\n\n### 2015 - 2016\n* [2015](http://www.vldb.org/pvldb/vol8/p1804-ching.pdf) - **Facebook** - One Trillion Edges: Graph Processing at Facebook-Scale.\n\n### 2013 - 2014\n* [2014](http://infolab.stanford.edu/~ullman/mmds/book.pdf) - **Stanford** - Mining of Massive Datasets.\n* [2013](https://amplab.cs.berkeley.edu/wp-content/uploads/2013/03/eurosys13-paper83.pdf) - **AMPLab** - Presto: Distributed Machine Learning and Graph Processing with Sparse Matrices.\n* [2013](https://amplab.cs.berkeley.edu/wp-content/uploads/2013/01/dmx1.pdf) - **AMPLab** - MLbase: A Distributed Machine-learning System.\n* [2013](https://amplab.cs.berkeley.edu/wp-content/uploads/2013/02/shark_sigmod2013.pdf) - **AMPLab** - Shark: SQL and Rich Analytics at Scale.\n* [2013](https://amplab.cs.berkeley.edu/wp-content/uploads/2013/05/grades-graphx_with_fonts.pdf) - **AMPLab** - GraphX: A Resilient Distributed Graph System on Spark.\n* [2013](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40671.pdf) - **Google** - HyperLogLog in Practice: Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm.\n* [2013](http://research.microsoft.com/pubs/200169/now-vldb.pdf) - **Microsoft** - Scalable Progressive Analytics on Big Data in the Cloud.\n* [2013](http://static.druid.io/docs/druid.pdf) - **Metamarkets** - Druid: A Real-time Analytical Data Store.\n* [2013](http://db.disi.unitn.eu/pages/VLDBProgram/pdf/industry/p764-rae.pdf) - **Google** - Online, Asynchronous Schema Change in F1.\n* [2013](http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/41344.pdf) - **Google** - F1: A Distributed SQL Database That Scales.\n* [2013](http://db.disi.unitn.eu/pages/VLDBProgram/pdf/industry/p734-akidau.pdf) - **Google** - MillWheel: Fault-Tolerant Stream Processing at Internet Scale.\n* [2013](http://db.disi.unitn.eu/pages/VLDBProgram/pdf/industry/p767-wiener.pdf) - **Facebook** - Scuba: Diving into Data at Facebook.\n* [2013](http://db.disi.unitn.eu/pages/VLDBProgram/pdf/industry/p871-curtiss.pdf) - **Facebook** - Unicorn: A System for Searching the Social Graph.\n* [2013](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf) - **Facebook** - Scaling Memcache at Facebook.\n\n### 2011 - 2012\n\n* [2012](http://vldb.org/pvldb/vol5/p1771_georgelee_vldb2012.pdf) - **Twitter** - The Unified Logging Infrastructure\nfor Data Analytics at Twitter.\n* [2012](https://amplab.cs.berkeley.edu/wp-content/uploads/2013/04/blinkdb_vldb12_demo.pdf) - **AMPLab** - Blink and It\u2019s Done: Interactive Queries on Very Large Data.\n* [2012](https://www.usenix.org/system/files/login/articles/zaharia.pdf) - **AMPLab** - Fast and Interactive Analytics over Hadoop Data with Spark.\n* [2012](https://amplab.cs.berkeley.edu/wp-content/uploads/2012/03/mod482-xin1.pdf) - **AMPLab** - Shark: Fast Data Analysis Using Coarse-grained Distributed Memory.\n* [2012](https://www.usenix.org/legacy/event/nsdi11/tech/full_papers/Bolosky.pdf) - **Microsoft** - Paxos Replicated State Machines as the Basis of a High-Performance Data Store.\n* [2012](http://research.microsoft.com/pubs/178045/ppaoxs-paper29.pdf) - **Microsoft** - Paxos Made Parallel.\n* [2012](https://arxiv.org/pdf/1203.5485.pdf) - **AMPLab** - BlinkDB: Queries with Bounded Errors and Bounded Response Times on Very Large Data.\n* [2012](http://vldb.org/pvldb/vol5/p1436_alexanderhall_vldb2012.pdf) - **Google** - Processing a trillion cells per mouse click.\n* [2012](http://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf) - **Google** - Spanner: Google\u2019s Globally-Distributed Database.\n* [2011](https://amplab.cs.berkeley.edu/wp-content/uploads/2011/06/euro118-ananthanarayanan.pdf) - **AMPLab** - Scarlett: Coping with Skewed Popularity Content in MapReduce Clusters.\n* [2011](https://amplab.cs.berkeley.edu/wp-content/uploads/2011/06/Mesos-A-Platform-for-Fine-Grained-Resource-Sharing-in-the-Data-Center.pdf) - **AMPLab** - Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center.\n* [2011](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36971.pdf) - **Google** - Megastore: Providing Scalable, Highly Available Storage for Interactive Services.\n\n### 2001 - 2010\n\n* [2010](https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf) - **Facebook** - Finding a needle in Haystack: Facebook\u2019s photo storage.\n* [2010](https://amplab.cs.berkeley.edu/wp-content/uploads/2011/06/Spark-Cluster-Computing-with-Working-Sets.pdf) - **AMPLab** - Spark: Cluster Computing with Working Sets.\n* [2010](http://kowshik.github.io/JPregel/pregel_paper.pdf) - **Google** - Pregel: A System for Large-Scale Graph Processing.\n* [2010](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36726.pdf) - **Google** - Large-scale Incremental Processing Using Distributed Transactions and Noti\ufb01cations base of Percolator and Caffeine.\n* [2010](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36632.pdf) - **Google** - Dremel: Interactive Analysis of Web-Scale Datasets.\n* [2010](http://leoneu.github.io/) - **Yahoo** - S4: Distributed Stream Computing Platform.\n* [2009](http://www.cs.umd.edu/~abadi/papers/hadoopdb.pdf) - HadoopDB: An Architectural Hybrid of MapReduce and DBMS Technologies for Analytical Workloads.\t\n* [2008](https://cwiki.apache.org/confluence/download/attachments/120729877/chukwa_cca08.pdf?version=1&modificationDate=1562667399000&api=v2) - **AMPLab** - Chukwa: A large-scale monitoring system.\n* [2007](http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf) - **Amazon** - Dynamo: Amazon\u2019s Highly Available Key-value Store.\n* [2006](http://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf) - **Google** - The Chubby lock service for loosely-coupled distributed systems.\n* [2006](http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//archive/bigtable-osdi06.pdf) - **Google** - Bigtable: A Distributed Storage System for Structured Data.\n* [2004](http://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf) - **Google** - MapReduce: Simplied Data Processing on Large Clusters.\n* [2003](http://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf) - **Google** - The Google File System.\n\n## Videos\n\n* [Spark in Motion](https://www.manning.com/livevideo/spark-in-motion) - Spark in Motion teaches you how to use Spark for batch and streaming data analytics.\n* [Machine Learning, Data Science and Deep Learning with Python ](https://www.manning.com/livevideo/machine-learning-data-science-and-deep-learning-with-python) - LiveVideo tutorial that covers machine learning, Tensorflow, artificial intelligence, and neural networks.\n* [Data warehouse schema design - dimensional modeling and star schema](https://snir.dev/talks/data-warehouse-schema-design) - Introduction to schema design for data warehouse using the star schema method.\n* [Elasticsearch 7 and Elastic Stack](https://www.manning.com/livevideo/elasticsearch-7-and-elastic-stack) - LiveVideo tutorial that covers searching, analyzing, and visualizing big data on a cluster with Elasticsearch, Logstash, Beats, Kibana, and more.\n\n## Books\n\n#### Streaming\n* [Data Science at Scale with Python and Dask](https://www.manning.com/books/data-science-at-scale-with-python-and-dask) - Data Science at Scale with Python and Dask teaches you how to build distributed data projects that can handle huge amounts of data.\n* [Streaming Data](https://www.manning.com/books/streaming-data) - Streaming Data introduces the concepts and requirements of streaming and real-time data systems.\n* [Storm Applied](https://www.manning.com/books/storm-applied) - Storm Applied is a practical guide to using Apache Storm for the real-world tasks associated with processing and analyzing real-time data streams.\n* [Fundamentals of Stream Processing: Application Design, Systems, and Analytics](http://www.cambridge.org/us/academic/subjects/engineering/communications-and-signal-processing/fundamentals-stream-processing-application-design-systems-and-analytics) - This comprehensive, hands-on guide combining the fundamental building blocks and emerging research in stream processing is ideal for application designers, system builders, analytic developers, as well as students and researchers in the field.\n* [Stream Data Processing: A Quality of Service Perspective](http://www.springer.com/us/book/9780387710020) - Presents a new paradigm suitable for stream and complex event processing.\n* [Unified Log Processing](https://www.manning.com/books/event-streams-in-action) - Unified Log Processing is a practical guide to implementing a unified log of event streams (Kafka or Kinesis) in your business\n* [Kafka Streams in Action](https://www.manning.com/books/kafka-streams-in-action) - Kafka Streams in Action teaches you everything you need to know to implement stream processing on data flowing into your Kafka platform, allowing you to focus on getting more from your data without sacrificing time or effort.\n* [Big Data](https://www.manning.com/books/big-data) - Big Data teaches you to build big data systems using an architecture that takes advantage of clustered hardware along with new tools designed specifically to capture and analyze web-scale data.\n* [Spark in Action](https://www.manning.com/books/spark-in-action) & [Spark in Action 2nd Ed.](https://www.manning.com/books/spark-in-action-second-edition) - Spark in Action teaches you the theory and skills you need to effectively handle batch and streaming data using Spark. Fully updated for Spark 2.0.\n* [Kafka in Action](https://www.manning.com/books/kafka-in-action) - Kafka in Action is a fast-paced introduction to every aspect of working with Kafka you need to really reap its benefits.\n* [Fusion in Action](https://www.manning.com/books/fusion-in-action) - Fusion in Action teaches you to build a full-featured data analytics pipeline, including document and data search and distributed data clustering.\n* [Reactive Data Handling](https://www.manning.com/books/reactive-data-handling) - Reactive Data Handling is a collection of five hand-picked chapters, selected by Manuel Bernhardt, that introduce you to building reactive applications capable of handling real-time processing with large data loads--free eBook! \n* [Azure Data Engineering](https://www.manning.com/books/azure-data-engineering) - A book about data engineering in general and the Azure platform specifically \n* [Grokking Streaming Systems](https://www.manning.com/books/grokking-streaming-systems) - Grokking Streaming Systems helps you unravel what streaming systems are, how they work, and whether they\u2019re right for your business. Written to be tool-agnostic, you\u2019ll be able to apply what you learn no matter which framework you choose.\n\n#### Distributed systems\n* [Distributed Systems for fun and profit](http://book.mixu.net/distsys/) \u2013 Theory of distributed systems. Include parts about time and ordering, replication and impossibility results.\n\n#### Graph Based approach\n* [Graph-Powered Machine Learning](https://www.manning.com/books/graph-powered-machine-learning) - Alessandro Negro. Combine graph theory and models to improve machine learning projects\n\n### Data Visualization\n * [The beauty of data visualization](https://www.youtube.com/watch?v=5Zg-C8AAIGg)\n * [Designing Data Visualizations with Noah Iliinsky](https://www.youtube.com/watch?v=R-oiKt7bUU8)\n * [Hans Rosling's 200 Countries, 200 Years, 4 Minutes](https://www.youtube.com/watch?v=jbkSRLYSojo)\n * [Ice Bucket Challenge Data Visualization](https://www.youtube.com/watch?v=qTEchen97rQ)\n\n\n# Other Awesome Lists\n- Other awesome lists [awesome-awesomeness](https://github.com/bayandin/awesome-awesomeness).\n- Even more lists [awesome](https://github.com/sindresorhus/awesome).\n- Another list? [list](https://github.com/jnv/lists).\n- WTF! [awesome-awesome-awesome](https://github.com/t3chnoboy/awesome-awesome-awesome).\n- Analytics [awesome-analytics](https://github.com/onurakpolat/awesome-analytics).\n- Public Datasets [awesome-public-datasets](https://github.com/awesomedata/awesome-public-datasets).\n- Graph Classification [awesome-graph-classification](https://github.com/benedekrozemberczki/awesome-graph-classification).\n- Network Embedding [awesome-network-embedding](https://github.com/chihming/awesome-network-embedding).\n- Community Detection [awesome-community-detection](https://github.com/benedekrozemberczki/awesome-community-detection).\n- Decision Tree Papers [awesome-decision-tree-papers](https://github.com/benedekrozemberczki/awesome-decision-tree-papers).\n- Fraud Detection Papers [awesome-fraud-detection-papers](https://github.com/benedekrozemberczki/awesome-fraud-detection-papers).\n- Gradient Boosting Papers [awesome-gradient-boosting-papers](https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers).\n- Monte Carlo Tree Search Papers [awesome-monte-carlo-tree-search-papers](https://github.com/benedekrozemberczki/awesome-monte-carlo-tree-search-papers).\n- Kafka [awesome-kafka](https://github.com/monksy/awesome-kafka).\n- [Google Bigtable](https://github.com/zrosenbauer/awesome-bigtable).\n",
	"data-visualization geospatial-analysis javascript maps python visualization webgl": "<p align=\"right\">\n  <a href=\"https://npmjs.org/package/deck.gl\">\n    <img src=\"https://img.shields.io/npm/v/deck.gl.svg?style=flat-square\" alt=\"version\" />\n  </a>\n  <a href=\"https://github.com/visgl/deck.gl/actions?query=workflow%3Atest+branch%3Amaster\">\n    <img src=\"https://github.com/visgl/deck.gl/workflows/test/badge.svg?branch=master\" alt=\"build\" />\n  </a>\n  <a href=\"https://npmjs.org/package/deck.gl\">\n    <img src=\"https://img.shields.io/npm/dm/@deck.gl/core.svg?style=flat-square\" alt=\"downloads\" />\n  </a>\n  <a href='https://coveralls.io/github/visgl/deck.gl?branch=master'>\n    <img src='https://img.shields.io/coveralls/visgl/deck.gl.svg?style=flat-square' alt='Coverage Status' />\n  </a>\n</p>\n\n<h1 align=\"center\">deck.gl | <a href=\"https://deck.gl\">Website</a></h1>\n\n<h5 align=\"center\"> WebGL2-powered, highly performant large-scale data visualization</h5>\n\n[![docs](http://i.imgur.com/mvfvgf0.jpg)](https://visgl.github.io/deck.gl)\n\n\ndeck.gl is designed to simplify high-performance, WebGL-based visualization of large data sets. Users can quickly get impressive visual results with minimal effort by composing existing layers, or leverage deck.gl's extensible architecture to address custom needs.\n\ndeck.gl maps **data** (usually an array of JSON objects) into a stack of visual **layers** - e.g. icons, polygons, texts; and look at them with **views**: e.g. map, first-person, orthographic.\n\ndeck.gl handles a number of challenges out of the box:\n\n* Performant rendering and updating of large data sets\n* Interactive event handling such as picking, highlighting and filtering\n* Cartographic projections and integration with major basemap providers\n* A catalog of proven, well-tested layers\n\nDeck.gl is designed to be highly customizable. All layers come with flexible APIs to allow programmatic control of each aspect of the rendering. All core classes such are easily extendable by the users to address custom use cases.\n\n## Flavors\n\n### Script Tag\n\n```html\n<script src=\"https://unpkg.com/deck.gl@latest/dist.min.js\"></script>\n```\n\n- [Get started](/docs/get-started/using-standalone.md#using-the-scripting-api)\n- [Full examples](https://github.com/visgl/deck.gl/tree/master/examples/get-started/scripting)\n\n### NPM Module\n\n```bash\nnpm install deck.gl\n```\n\n#### Pure JS\n\n- [Get started](/docs/get-started/using-standalone.md)\n- [Full examples](/examples/get-started/pure-js)\n\n#### React\n\n- [Get started](/docs/get-started/using-with-react.md)\n- [Full examples](/examples/get-started/react)\n\n### Python\n\n```bash\npip install pydeck\n```\n\n- [Get started](https://pydeck.gl/installation.html)\n- [Examples](https://pydeck.gl/)\n\n### Third-Party Goodies\n\n- [deckgl-typings](https://github.com/danmarshall/deckgl-typings) (Typescript)\n- [mapdeck](https://symbolixau.github.io/mapdeck/articles/mapdeck.html) (R)\n- [vega-deck.gl](https://github.com/microsoft/SandDance/tree/master/packages/vega-deck.gl) ([Vega](https://vega.github.io/))\n- [earthengine-layers](https://earthengine-layers.com/) ([Google Earth Engine](https://earthengine.google.com/))\n- [deck.gl-native](https://github.com/UnfoldedInc/deck.gl-native) (C++)\n- [deck.gl-raster](https://github.com/kylebarron/deck.gl-raster/) (Computation on rasters)\n\n## Learning Resources\n\n* [API documentation](https://deck.gl/#/documentation) for the latest release\n* [Website demos](https://deck.gl/#/examples) with links to source\n* [Interactive playground](https://deck.gl/playground)\n* [deck.gl Codepen demos](https://codepen.io/vis-gl/)\n* [deck.gl Observable demos](https://beta.observablehq.com/@pessimistress)\n* [vis.gl Medium blog](https://medium.com/vis-gl)\n* [deck.gl Slack workspace](https://join.slack.com/t/deckgl/shared_invite/zt-7oeoqie8-NQqzSp5SLTFMDeNSPxi7eg)\n\n## Contributing\n\ndeck.gl is part of vis.gl, an [OpenJS Foundation](https://openjsf.org/) project. Read the [contribution guidelines](/CONTRIBUTING.md) if you are interested in contributing.\n\n\n## Attributions\n\n#### Data sources\n\nData sources are listed in each example.\n\n\n#### The deck.gl project is supported by\n\n<a href=\"https://www.unfolded.ai\"><img src=\"https://raw.githubusercontent.com/visgl/deck.gl-data/master/images/branding/unfolded.png\" height=\"32\" /></a>\n<a href=\"https://www.foursquare.com\"><img src=\"https://raw.githubusercontent.com/visgl/deck.gl-data/master/images/branding/fsq.svg\" height=\"40\" /></a>\n\n<a href=\"https://www.carto.com\"><img src=\"https://raw.githubusercontent.com/visgl/deck.gl-data/master/images/branding/carto.svg\" height=\"48\" /></a>\n\n<a href=\"https://www.mapbox.com\"><img src=\"https://raw.githubusercontent.com/visgl/deck.gl-data/master/images/branding/mapbox.svg\" height=\"44\" /></a>\n<a href=\"https://www.uber.com\"><img src=\"https://raw.githubusercontent.com/visgl/deck.gl-data/master/images/branding/uber.png\" height=\"40\" /></a>\n\n<a href=\"https://www.browserstack.com/\"><img src=\"https://d98b8t1nnulk5.cloudfront.net/production/images/static/logo.svg\" alt=\"BrowserStack\" width=\"200\" /></a>\n",
	"deep-learning deep-neural-networks distributed machine-learning ml neural-network python tensorflow": "<div align=\"center\">\n  <img src=\"https://www.tensorflow.org/images/tf_logo_horizontal.png\">\n</div>\n\n[![Python](https://img.shields.io/pypi/pyversions/tensorflow.svg?style=plastic)](https://badge.fury.io/py/tensorflow)\n[![PyPI](https://badge.fury.io/py/tensorflow.svg)](https://badge.fury.io/py/tensorflow)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4724125.svg)](https://doi.org/10.5281/zenodo.4724125)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1486/badge)](https://bestpractices.coreinfrastructure.org/projects/1486)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/tensorflow/tensorflow/badge)](https://api.securityscorecards.dev/projects/github.com/tensorflow/tensorflow)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/tensorflow.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:tensorflow)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/tensorflow-py.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:tensorflow-py)\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v1.4%20adopted-ff69b4.svg)](CODE_OF_CONDUCT.md)\n\n**`Documentation`** |\n------------------- |\n[![Documentation](https://img.shields.io/badge/api-reference-blue.svg)](https://www.tensorflow.org/api_docs/) |\n\n[TensorFlow](https://www.tensorflow.org/) is an end-to-end open source platform\nfor machine learning. It has a comprehensive, flexible ecosystem of\n[tools](https://www.tensorflow.org/resources/tools),\n[libraries](https://www.tensorflow.org/resources/libraries-extensions), and\n[community](https://www.tensorflow.org/community) resources that lets\nresearchers push the state-of-the-art in ML and developers easily build and\ndeploy ML-powered applications.\n\nTensorFlow was originally developed by researchers and engineers working on the\nGoogle Brain team within Google's Machine Intelligence Research organization to\nconduct machine learning and deep neural networks research. The system is\ngeneral enough to be applicable in a wide variety of other domains, as well.\n\nTensorFlow provides stable [Python](https://www.tensorflow.org/api_docs/python)\nand [C++](https://www.tensorflow.org/api_docs/cc) APIs, as well as\nnon-guaranteed backward compatible API for\n[other languages](https://www.tensorflow.org/api_docs).\n\nKeep up-to-date with release announcements and security updates by subscribing\nto\n[announce@tensorflow.org](https://groups.google.com/a/tensorflow.org/forum/#!forum/announce).\nSee all the [mailing lists](https://www.tensorflow.org/community/forums).\n\n## Install\n\nSee the [TensorFlow install guide](https://www.tensorflow.org/install) for the\n[pip package](https://www.tensorflow.org/install/pip), to\n[enable GPU support](https://www.tensorflow.org/install/gpu), use a\n[Docker container](https://www.tensorflow.org/install/docker), and\n[build from source](https://www.tensorflow.org/install/source).\n\nTo install the current release, which includes support for\n[CUDA-enabled GPU cards](https://www.tensorflow.org/install/gpu) *(Ubuntu and\nWindows)*:\n\n```\n$ pip install tensorflow\n```\n\nOther devices (DirectX and MacOS-metal) are supported using\n[Device plugins](https://www.tensorflow.org/install/gpu_plugins#available_devices).\n\nA smaller CPU-only package is also available:\n\n```\n$ pip install tensorflow-cpu\n```\n\nTo update TensorFlow to the latest version, add `--upgrade` flag to the above\ncommands.\n\n*Nightly binaries are available for testing using the\n[tf-nightly](https://pypi.python.org/pypi/tf-nightly) and\n[tf-nightly-cpu](https://pypi.python.org/pypi/tf-nightly-cpu) packages on PyPi.*\n\n#### *Try your first TensorFlow program*\n\n```shell\n$ python\n```\n\n```python\n>>> import tensorflow as tf\n>>> tf.add(1, 2).numpy()\n3\n>>> hello = tf.constant('Hello, TensorFlow!')\n>>> hello.numpy()\nb'Hello, TensorFlow!'\n```\n\nFor more examples, see the\n[TensorFlow tutorials](https://www.tensorflow.org/tutorials/).\n\n## Contribution guidelines\n\n**If you want to contribute to TensorFlow, be sure to review the\n[contribution guidelines](CONTRIBUTING.md). This project adheres to TensorFlow's\n[code of conduct](CODE_OF_CONDUCT.md). By participating, you are expected to\nuphold this code.**\n\n**We use [GitHub issues](https://github.com/tensorflow/tensorflow/issues) for\ntracking requests and bugs, please see\n[TensorFlow Discuss](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss)\nfor general questions and discussion, and please direct specific questions to\n[Stack Overflow](https://stackoverflow.com/questions/tagged/tensorflow).**\n\nThe TensorFlow project strives to abide by generally accepted best practices in\nopen-source software development.\n\n## Continuous build status\n\nYou can find more community-supported platforms and configurations in the\n[TensorFlow SIG Build community builds table](https://github.com/tensorflow/build#community-supported-tensorflow-builds).\n\n### Official Builds\n\nBuild Type                    | Status                                                                                                                                                                           | Artifacts\n----------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------\n**Linux CPU**                 | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-cc.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-cc.html)           | [PyPI](https://pypi.org/project/tf-nightly/)\n**Linux GPU**                 | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-gpu-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-gpu-py3.html) | [PyPI](https://pypi.org/project/tf-nightly-gpu/)\n**Linux XLA**                 | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-xla.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-xla.html)         | TBA\n**macOS**                     | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/macos-py2-cc.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/macos-py2-cc.html)     | [PyPI](https://pypi.org/project/tf-nightly/)\n**Windows CPU**               | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-cpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-cpu.html)       | [PyPI](https://pypi.org/project/tf-nightly/)\n**Windows GPU**               | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-gpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-gpu.html)       | [PyPI](https://pypi.org/project/tf-nightly-gpu/)\n**Android**                   | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/android.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/android.html)               | [Download](https://bintray.com/google/tensorflow/tensorflow/_latestVersion)\n**Raspberry Pi 0 and 1**      | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi01-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi01-py3.html)           | [Py3](https://storage.googleapis.com/tensorflow-nightly/tensorflow-1.10.0-cp34-none-linux_armv6l.whl)\n**Raspberry Pi 2 and 3**      | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi23-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi23-py3.html)           | [Py3](https://storage.googleapis.com/tensorflow-nightly/tensorflow-1.10.0-cp34-none-linux_armv7l.whl)\n**Libtensorflow MacOS CPU**   | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/macos/latest/macos_cpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Linux CPU**   | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/ubuntu_16/latest/cpu/ubuntu_cpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Linux GPU**   | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/ubuntu_16/latest/gpu/ubuntu_gpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Windows CPU** | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/windows/latest/cpu/windows_cpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Windows GPU** | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/windows/latest/gpu/windows_gpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n\n## Resources\n\n*   [TensorFlow.org](https://www.tensorflow.org)\n*   [TensorFlow Tutorials](https://www.tensorflow.org/tutorials/)\n*   [TensorFlow Official Models](https://github.com/tensorflow/models/tree/master/official)\n*   [TensorFlow Examples](https://github.com/tensorflow/examples)\n*   [TensorFlow Codelabs](https://codelabs.developers.google.com/?cat=TensorFlow)\n*   [TensorFlow Blog](https://blog.tensorflow.org)\n*   [Learn ML with TensorFlow](https://www.tensorflow.org/resources/learn-ml)\n*   [TensorFlow Twitter](https://twitter.com/tensorflow)\n*   [TensorFlow YouTube](https://www.youtube.com/channel/UC0rqucBdTuFTjJiefW5t-IQ)\n*   [TensorFlow model optimization roadmap](https://www.tensorflow.org/model_optimization/guide/roadmap)\n*   [TensorFlow White Papers](https://www.tensorflow.org/about/bib)\n*   [TensorBoard Visualization Toolkit](https://github.com/tensorflow/tensorboard)\n*   [TensorFlow Code Search](https://cs.opensource.google/tensorflow/tensorflow)\n\nLearn more about the\n[TensorFlow community](https://www.tensorflow.org/community) and how to\n[contribute](https://www.tensorflow.org/community/contribute).\n\n## Courses\n\n*   [Deep Learning with Tensorflow from Edx](https://www.edx.org/course/deep-learning-with-tensorflow)\n*   [DeepLearning.AI TensorFlow Developer Professional Certificate from Coursera](https://www.coursera.org/specializations/tensorflow-in-practice)\n*   [TensorFlow: Data and Deployment from Coursera](https://www.coursera.org/specializations/tensorflow-data-and-deployment)\n*   [Getting Started with TensorFlow 2 from Coursera](https://www.coursera.org/learn/getting-started-with-tensor-flow2)\n*   [TensorFlow: Advanced Techniques from Coursera](https://www.coursera.org/specializations/tensorflow-advanced-techniques)\n*   [TensorFlow 2 for Deep Learning Specialization from Coursera](https://www.coursera.org/specializations/tensorflow2-deeplearning)\n*   [Intro to TensorFlow for A.I, M.L, and D.L from Coursera](https://www.coursera.org/learn/introduction-tensorflow)\n*   [Machine Learning with TensorFlow on GCP from Coursera](https://www.coursera.org/specializations/machine-learning-tensorflow-gcp)\n*   [Intro to TensorFlow for Deep Learning from Udacity](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187)\n*   [Introduction to TensorFlow Lite from Udacity](https://www.udacity.com/course/intro-to-tensorflow-lite--ud190)\n\n## License\n\n[Apache License 2.0](LICENSE)\n",
	"bert deep-learning flax hacktoberfest jax language-model language-models machine-learning model-hub natural-language-processing nlp nlp-library pretrained-models python pytorch pytorch-transformers seq2seq speech-recognition tensorflow transformer": "<!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n<p align=\"center\">\n    <br>\n    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers_logo_name.png\" width=\"400\"/>\n    <br>\n<p>\n<p align=\"center\">\n    <a href=\"https://circleci.com/gh/huggingface/transformers\">\n        <img alt=\"Build\" src=\"https://img.shields.io/circleci/build/github/huggingface/transformers/main\">\n    </a>\n    <a href=\"https://github.com/huggingface/transformers/blob/main/LICENSE\">\n        <img alt=\"GitHub\" src=\"https://img.shields.io/github/license/huggingface/transformers.svg?color=blue\">\n    </a>\n    <a href=\"https://huggingface.co/docs/transformers/index\">\n        <img alt=\"Documentation\" src=\"https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online\">\n    </a>\n    <a href=\"https://github.com/huggingface/transformers/releases\">\n        <img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/huggingface/transformers.svg\">\n    </a>\n    <a href=\"https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md\">\n        <img alt=\"Contributor Covenant\" src=\"https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg\">\n    </a>\n    <a href=\"https://zenodo.org/badge/latestdoi/155220641\"><img src=\"https://zenodo.org/badge/155220641.svg\" alt=\"DOI\"></a>\n</p>\n\n<h4 align=\"center\">\n    <p>\n        <b>English</b> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/README_zh-hans.md\">\u7b80\u4f53\u4e2d\u6587</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/README_zh-hant.md\">\u7e41\u9ad4\u4e2d\u6587</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/README_ko.md\">\ud55c\uad6d\uc5b4</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/README_es.md\">Espa\u00f1ol</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/README_ja.md\">\u65e5\u672c\u8a9e</a>\n    <p>\n</h4>\n\n<h3 align=\"center\">\n    <p>State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow</p>\n</h3>\n\n<h3 align=\"center\">\n    <a href=\"https://hf.co/course\"><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png\"></a>\n</h3>\n\n\ud83e\udd17 Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.\n\nThese models can be applied on:\n\n* \ud83d\udcdd Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.\n* \ud83d\uddbc\ufe0f Images, for tasks like image classification, object detection, and segmentation.\n* \ud83d\udde3\ufe0f Audio, for tasks like speech recognition and audio classification.\n\nTransformer models can also perform tasks on **several modalities combined**, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.\n\n\ud83e\udd17 Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our [model hub](https://huggingface.co/models). At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.\n\n\ud83e\udd17 Transformers is backed by the three most popular deep learning libraries \u2014 [Jax](https://jax.readthedocs.io/en/latest/), [PyTorch](https://pytorch.org/) and [TensorFlow](https://www.tensorflow.org/) \u2014 with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.\n\n## Online demos\n\nYou can test most of our models directly on their pages from the [model hub](https://huggingface.co/models). We also offer [private model hosting, versioning, & an inference API](https://huggingface.co/pricing) for public and private models.\n\nHere are a few examples:\n\n In Natural Language Processing:\n- [Masked word completion with BERT](https://huggingface.co/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France)\n- [Name Entity Recognition with Electra](https://huggingface.co/dbmdz/electra-large-discriminator-finetuned-conll03-english?text=My+name+is+Sarah+and+I+live+in+London+city)\n- [Text generation with GPT-2](https://huggingface.co/gpt2?text=A+long+time+ago%2C+)\n- [Natural Language Inference with RoBERTa](https://huggingface.co/roberta-large-mnli?text=The+dog+was+lost.+Nobody+lost+any+animal)\n- [Summarization with BART](https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+was+the+first+structure+to+reach+a+height+of+300+metres.+Due+to+the+addition+of+a+broadcasting+aerial+at+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct)\n- [Question answering with DistilBERT](https://huggingface.co/distilbert-base-uncased-distilled-squad?text=Which+name+is+also+used+to+describe+the+Amazon+rainforest+in+English%3F&context=The+Amazon+rainforest+%28Portuguese%3A+Floresta+Amaz%C3%B4nica+or+Amaz%C3%B4nia%3B+Spanish%3A+Selva+Amaz%C3%B3nica%2C+Amazon%C3%ADa+or+usually+Amazonia%3B+French%3A+For%C3%AAt+amazonienne%3B+Dutch%3A+Amazoneregenwoud%29%2C+also+known+in+English+as+Amazonia+or+the+Amazon+Jungle%2C+is+a+moist+broadleaf+forest+that+covers+most+of+the+Amazon+basin+of+South+America.+This+basin+encompasses+7%2C000%2C000+square+kilometres+%282%2C700%2C000+sq+mi%29%2C+of+which+5%2C500%2C000+square+kilometres+%282%2C100%2C000+sq+mi%29+are+covered+by+the+rainforest.+This+region+includes+territory+belonging+to+nine+nations.+The+majority+of+the+forest+is+contained+within+Brazil%2C+with+60%25+of+the+rainforest%2C+followed+by+Peru+with+13%25%2C+Colombia+with+10%25%2C+and+with+minor+amounts+in+Venezuela%2C+Ecuador%2C+Bolivia%2C+Guyana%2C+Suriname+and+French+Guiana.+States+or+departments+in+four+nations+contain+%22Amazonas%22+in+their+names.+The+Amazon+represents+over+half+of+the+planet%27s+remaining+rainforests%2C+and+comprises+the+largest+and+most+biodiverse+tract+of+tropical+rainforest+in+the+world%2C+with+an+estimated+390+billion+individual+trees+divided+into+16%2C000+species)\n- [Translation with T5](https://huggingface.co/t5-base?text=My+name+is+Wolfgang+and+I+live+in+Berlin)\n\nIn Computer Vision:\n- [Image classification with ViT](https://huggingface.co/google/vit-base-patch16-224)\n- [Object Detection with DETR](https://huggingface.co/facebook/detr-resnet-50)\n- [Semantic Segmentation with SegFormer](https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512)\n- [Panoptic Segmentation with DETR](https://huggingface.co/facebook/detr-resnet-50-panoptic)\n\nIn Audio:\n- [Automatic Speech Recognition with Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base-960h)\n- [Keyword Spotting with Wav2Vec2](https://huggingface.co/superb/wav2vec2-base-superb-ks)\n\nIn Multimodal tasks:\n- [Visual Question Answering with ViLT](https://huggingface.co/dandelin/vilt-b32-finetuned-vqa)\n\n**[Write With Transformer](https://transformer.huggingface.co)**, built by the Hugging Face team, is the official demo of this repo\u2019s text generation capabilities.\n\n## If you are looking for custom support from the Hugging Face team\n\n<a target=\"_blank\" href=\"https://huggingface.co/support\">\n    <img alt=\"HuggingFace Expert Acceleration Program\" src=\"https://cdn-media.huggingface.co/marketing/transformers/new-support-improved.png\" style=\"max-width: 600px; border: 1px solid #eee; border-radius: 4px; box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);\">\n</a><br>\n\n## Quick tour\n\nTo immediately use a model on a given input (text, image, audio, ...), we provide the `pipeline` API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:\n\n```python\n>>> from transformers import pipeline\n\n# Allocate a pipeline for sentiment-analysis\n>>> classifier = pipeline('sentiment-analysis')\n>>> classifier('We are very happy to introduce pipeline to the transformers repository.')\n[{'label': 'POSITIVE', 'score': 0.9996980428695679}]\n```\n\nThe second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \"positive\" with a confidence of 99.97%.\n\nMany tasks have a pre-trained `pipeline` ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:\n\n``` python\n>>> import requests\n>>> from PIL import Image\n>>> from transformers import pipeline\n\n# Download an image with cute cats\n>>> url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"\n>>> image_data = requests.get(url, stream=True).raw\n>>> image = Image.open(image_data)\n\n# Allocate a pipeline for object detection\n>>> object_detector = pipeline('object-detection')\n>>> object_detector(image)\n[{'score': 0.9982201457023621,\n  'label': 'remote',\n  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}},\n {'score': 0.9960021376609802,\n  'label': 'remote',\n  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}},\n {'score': 0.9954745173454285,\n  'label': 'couch',\n  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}},\n {'score': 0.9988006353378296,\n  'label': 'cat',\n  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}},\n {'score': 0.9986783862113953,\n  'label': 'cat',\n  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]\n```\n\nHere we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:\n\n<h3 align=\"center\">\n    <a><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\" width=\"400\"></a>\n    <a><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample_post_processed.png\" width=\"400\"></a>\n</h3>\n\nYou can learn more about the tasks supported by the `pipeline` API in [this tutorial](https://huggingface.co/docs/transformers/task_summary).\n\nIn addition to `pipeline`, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:\n```python\n>>> from transformers import AutoTokenizer, AutoModel\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n>>> model = AutoModel.from_pretrained(\"bert-base-uncased\")\n\n>>> inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n>>> outputs = model(**inputs)\n```\n\nAnd here is the equivalent code for TensorFlow:\n```python\n>>> from transformers import AutoTokenizer, TFAutoModel\n\n>>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n>>> model = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n\n>>> inputs = tokenizer(\"Hello world!\", return_tensors=\"tf\")\n>>> outputs = model(**inputs)\n```\n\nThe tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.\n\nThe model itself is a regular [Pytorch `nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) or a [TensorFlow `tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) (depending on your backend) which you can use as usual. [This tutorial](https://huggingface.co/docs/transformers/training) explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our `Trainer` API to quickly fine-tune on a new dataset.\n\n## Why should I use transformers?\n\n1. Easy-to-use state-of-the-art models:\n    - High performance on natural language understanding & generation, computer vision, and audio tasks.\n    - Low barrier to entry for educators and practitioners.\n    - Few user-facing abstractions with just three classes to learn.\n    - A unified API for using all our pretrained models.\n\n1. Lower compute costs, smaller carbon footprint:\n    - Researchers can share trained models instead of always retraining.\n    - Practitioners can reduce compute time and production costs.\n    - Dozens of architectures with over 60,000 pretrained models across all modalities.\n\n1. Choose the right framework for every part of a model's lifetime:\n    - Train state-of-the-art models in 3 lines of code.\n    - Move a single model between TF2.0/PyTorch/JAX frameworks at will.\n    - Seamlessly pick the right framework for training, evaluation and production.\n\n1. Easily customize a model or an example to your needs:\n    - We provide examples for each architecture to reproduce the results published by its original authors.\n    - Model internals are exposed as consistently as possible.\n    - Model files can be used independently of the library for quick experiments.\n\n## Why shouldn't I use transformers?\n\n- This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.\n- The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, [Accelerate](https://huggingface.co/docs/accelerate)).\n- While we strive to present as many use cases as possible, the scripts in our [examples folder](https://github.com/huggingface/transformers/tree/main/examples) are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.\n\n## Installation\n\n### With pip\n\nThis repository is tested on Python 3.6+, Flax 0.3.2+, PyTorch 1.3.1+ and TensorFlow 2.3+.\n\nYou should install \ud83e\udd17 Transformers in a [virtual environment](https://docs.python.org/3/library/venv.html). If you're unfamiliar with Python virtual environments, check out the [user guide](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).\n\nFirst, create a virtual environment with the version of Python you're going to use and activate it.\n\nThen, you will need to install at least one of Flax, PyTorch or TensorFlow.\nPlease refer to [TensorFlow installation page](https://www.tensorflow.org/install/), [PyTorch installation page](https://pytorch.org/get-started/locally/#start-locally) and/or [Flax](https://github.com/google/flax#quick-install) and [Jax](https://github.com/google/jax#installation) installation pages regarding the specific installation command for your platform.\n\nWhen one of those backends has been installed, \ud83e\udd17 Transformers can be installed using pip as follows:\n\n```bash\npip install transformers\n```\n\nIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must [install the library from source](https://huggingface.co/docs/transformers/installation#installing-from-source).\n\n### With conda\n\nSince Transformers version v4.0.0, we now have a conda channel: `huggingface`.\n\n\ud83e\udd17 Transformers can be installed using conda as follows:\n\n```shell script\nconda install -c huggingface transformers\n```\n\nFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.\n\n> **_NOTE:_**  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in [this issue](https://github.com/huggingface/huggingface_hub/issues/1062).\n\n## Model architectures\n\n**[All the model checkpoints](https://huggingface.co/models)** provided by \ud83e\udd17 Transformers are seamlessly integrated from the huggingface.co [model hub](https://huggingface.co) where they are uploaded directly by [users](https://huggingface.co/users) and [organizations](https://huggingface.co/organizations).\n\nCurrent number of checkpoints: ![](https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen)\n\n\ud83e\udd17 Transformers currently provides the following architectures (see [here](https://huggingface.co/docs/transformers/model_summary) for a high-level summary of each them):\n\n1. **[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)** (from Google Research and the Toyota Technological Institute at Chicago) released with the paper [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942), by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.\n1. **[Audio Spectrogram Transformer](https://huggingface.co/docs/transformers/main/model_doc/audio-spectrogram-transformer)** (from MIT) released with the paper [AST: Audio Spectrogram Transformer](https://arxiv.org/abs/2104.01778) by Yuan Gong, Yu-An Chung, James Glass.\n1. **[BART](https://huggingface.co/docs/transformers/model_doc/bart)** (from Facebook) released with the paper [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461) by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.\n1. **[BARThez](https://huggingface.co/docs/transformers/model_doc/barthez)** (from \u00c9cole polytechnique) released with the paper [BARThez: a Skilled Pretrained French Sequence-to-Sequence Model](https://arxiv.org/abs/2010.12321) by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.\n1. **[BARTpho](https://huggingface.co/docs/transformers/model_doc/bartpho)** (from VinAI Research) released with the paper [BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese](https://arxiv.org/abs/2109.09701) by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.\n1. **[BEiT](https://huggingface.co/docs/transformers/model_doc/beit)** (from Microsoft) released with the paper [BEiT: BERT Pre-Training of Image Transformers](https://arxiv.org/abs/2106.08254) by Hangbo Bao, Li Dong, Furu Wei.\n1. **[BERT](https://huggingface.co/docs/transformers/model_doc/bert)** (from Google) released with the paper [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.\n1. **[BERT For Sequence Generation](https://huggingface.co/docs/transformers/model_doc/bert-generation)** (from Google) released with the paper [Leveraging Pre-trained Checkpoints for Sequence Generation Tasks](https://arxiv.org/abs/1907.12461) by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.\n1. **[BERTweet](https://huggingface.co/docs/transformers/model_doc/bertweet)** (from VinAI Research) released with the paper [BERTweet: A pre-trained language model for English Tweets](https://aclanthology.org/2020.emnlp-demos.2/) by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.\n1. **[BigBird-Pegasus](https://huggingface.co/docs/transformers/model_doc/bigbird_pegasus)** (from Google Research) released with the paper [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062) by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.\n1. **[BigBird-RoBERTa](https://huggingface.co/docs/transformers/model_doc/big_bird)** (from Google Research) released with the paper [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062) by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.\n1. **[Blenderbot](https://huggingface.co/docs/transformers/model_doc/blenderbot)** (from Facebook) released with the paper [Recipes for building an open-domain chatbot](https://arxiv.org/abs/2004.13637) by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.\n1. **[BlenderbotSmall](https://huggingface.co/docs/transformers/model_doc/blenderbot-small)** (from Facebook) released with the paper [Recipes for building an open-domain chatbot](https://arxiv.org/abs/2004.13637) by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.\n1. **[BLOOM](https://huggingface.co/docs/transformers/model_doc/bloom)** (from BigScience workshop) released by the [BigScience Workshop](https://bigscience.huggingface.co/).\n1. **[BORT](https://huggingface.co/docs/transformers/model_doc/bort)** (from Alexa) released with the paper [Optimal Subarchitecture Extraction For BERT](https://arxiv.org/abs/2010.10499) by Adrian de Wynter and Daniel J. Perry.\n1. **[ByT5](https://huggingface.co/docs/transformers/model_doc/byt5)** (from Google Research) released with the paper [ByT5: Towards a token-free future with pre-trained byte-to-byte models](https://arxiv.org/abs/2105.13626) by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.\n1. **[CamemBERT](https://huggingface.co/docs/transformers/model_doc/camembert)** (from Inria/Facebook/Sorbonne) released with the paper [CamemBERT: a Tasty French Language Model](https://arxiv.org/abs/1911.03894) by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Su\u00e1rez*, Yoann Dupont, Laurent Romary, \u00c9ric Villemonte de la Clergerie, Djam\u00e9 Seddah and Beno\u00eet Sagot.\n1. **[CANINE](https://huggingface.co/docs/transformers/model_doc/canine)** (from Google Research) released with the paper [CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation](https://arxiv.org/abs/2103.06874) by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.\n1. **[CLIP](https://huggingface.co/docs/transformers/model_doc/clip)** (from OpenAI) released with the paper [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.\n1. **[CLIPSeg](https://huggingface.co/docs/transformers/main/model_doc/clipseg)** (from University of G\u00f6ttingen) released with the paper [Image Segmentation Using Text and Image Prompts](https://arxiv.org/abs/2112.10003) by Timo L\u00fcddecke and Alexander Ecker.\n1. **[CodeGen](https://huggingface.co/docs/transformers/model_doc/codegen)** (from Salesforce) released with the paper [A Conversational Paradigm for Program Synthesis](https://arxiv.org/abs/2203.13474) by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.\n1. **[Conditional DETR](https://huggingface.co/docs/transformers/model_doc/conditional_detr)** (from Microsoft Research Asia) released with the paper [Conditional DETR for Fast Training Convergence](https://arxiv.org/abs/2108.06152) by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.\n1. **[ConvBERT](https://huggingface.co/docs/transformers/model_doc/convbert)** (from YituTech) released with the paper [ConvBERT: Improving BERT with Span-based Dynamic Convolution](https://arxiv.org/abs/2008.02496) by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.\n1. **[ConvNeXT](https://huggingface.co/docs/transformers/model_doc/convnext)** (from Facebook AI) released with the paper [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545) by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.\n1. **[CPM](https://huggingface.co/docs/transformers/model_doc/cpm)** (from Tsinghua University) released with the paper [CPM: A Large-scale Generative Chinese Pre-trained Language Model](https://arxiv.org/abs/2012.00413) by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.\n1. **[CTRL](https://huggingface.co/docs/transformers/model_doc/ctrl)** (from Salesforce) released with the paper [CTRL: A Conditional Transformer Language Model for Controllable Generation](https://arxiv.org/abs/1909.05858) by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.\n1. **[CvT](https://huggingface.co/docs/transformers/model_doc/cvt)** (from Microsoft) released with the paper [CvT: Introducing Convolutions to Vision Transformers](https://arxiv.org/abs/2103.15808) by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.\n1. **[Data2Vec](https://huggingface.co/docs/transformers/model_doc/data2vec)** (from Facebook) released with the paper [Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language](https://arxiv.org/abs/2202.03555) by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.\n1. **[DeBERTa](https://huggingface.co/docs/transformers/model_doc/deberta)** (from Microsoft) released with the paper [DeBERTa: Decoding-enhanced BERT with Disentangled Attention](https://arxiv.org/abs/2006.03654) by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.\n1. **[DeBERTa-v2](https://huggingface.co/docs/transformers/model_doc/deberta-v2)** (from Microsoft) released with the paper [DeBERTa: Decoding-enhanced BERT with Disentangled Attention](https://arxiv.org/abs/2006.03654) by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.\n1. **[Decision Transformer](https://huggingface.co/docs/transformers/model_doc/decision_transformer)** (from Berkeley/Facebook/Google) released with the paper [Decision Transformer: Reinforcement Learning via Sequence Modeling](https://arxiv.org/abs/2106.01345) by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.\n1. **[Deformable DETR](https://huggingface.co/docs/transformers/model_doc/deformable_detr)** (from SenseTime Research) released with the paper [Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://arxiv.org/abs/2010.04159) by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.\n1. **[DeiT](https://huggingface.co/docs/transformers/model_doc/deit)** (from Facebook) released with the paper [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877) by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Herv\u00e9 J\u00e9gou.\n1. **[DETR](https://huggingface.co/docs/transformers/model_doc/detr)** (from Facebook) released with the paper [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872) by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.\n1. **[DialoGPT](https://huggingface.co/docs/transformers/model_doc/dialogpt)** (from Microsoft Research) released with the paper [DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation](https://arxiv.org/abs/1911.00536) by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.\n1. **[DiNAT](https://huggingface.co/docs/transformers/main/model_doc/dinat)** (from SHI Labs) released with the paper [Dilated Neighborhood Attention Transformer](https://arxiv.org/abs/2209.15001) by Ali Hassani and Humphrey Shi.\n1. **[DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert)** (from HuggingFace), released together with the paper [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108) by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into [DistilGPT2](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation), RoBERTa into [DistilRoBERTa](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation), Multilingual BERT into [DistilmBERT](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation) and a German version of DistilBERT.\n1. **[DiT](https://huggingface.co/docs/transformers/model_doc/dit)** (from Microsoft Research) released with the paper [DiT: Self-supervised Pre-training for Document Image Transformer](https://arxiv.org/abs/2203.02378) by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.\n1. **[Donut](https://huggingface.co/docs/transformers/model_doc/donut)** (from NAVER), released together with the paper [OCR-free Document Understanding Transformer](https://arxiv.org/abs/2111.15664) by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.\n1. **[DPR](https://huggingface.co/docs/transformers/model_doc/dpr)** (from Facebook) released with the paper [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2004.04906) by Vladimir Karpukhin, Barlas O\u011fuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.\n1. **[DPT](https://huggingface.co/docs/transformers/master/model_doc/dpt)** (from Intel Labs) released with the paper [Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413) by Ren\u00e9 Ranftl, Alexey Bochkovskiy, Vladlen Koltun.\n1. **[ELECTRA](https://huggingface.co/docs/transformers/model_doc/electra)** (from Google Research/Stanford University) released with the paper [ELECTRA: Pre-training text encoders as discriminators rather than generators](https://arxiv.org/abs/2003.10555) by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.\n1. **[EncoderDecoder](https://huggingface.co/docs/transformers/model_doc/encoder-decoder)** (from Google Research) released with the paper [Leveraging Pre-trained Checkpoints for Sequence Generation Tasks](https://arxiv.org/abs/1907.12461) by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.\n1. **[ERNIE](https://huggingface.co/docs/transformers/model_doc/ernie)** (from Baidu) released with the paper [ERNIE: Enhanced Representation through Knowledge Integration](https://arxiv.org/abs/1904.09223) by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.\n1. **[ESM](https://huggingface.co/docs/transformers/model_doc/esm)** (from Meta AI) are transformer protein language models.  **ESM-1b** was released with the paper [Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences](https://www.pnas.org/content/118/15/e2016239118) by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. **ESM-1v** was released with the paper [Language models enable zero-shot prediction of the effects of mutations on protein function](https://doi.org/10.1101/2021.07.09.450648) by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. **ESM-2 and ESMFold** were released with the paper [Language models of protein sequences at the scale of evolution enable accurate structure prediction](https://doi.org/10.1101/2022.07.20.500902) by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.\n1. **[FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5)** (from Google AI) released in the repository [google-research/t5x](https://github.com/google-research/t5x/blob/main/docs/models.md#flan-t5-checkpoints) by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei\n1. **[FlauBERT](https://huggingface.co/docs/transformers/model_doc/flaubert)** (from CNRS) released with the paper [FlauBERT: Unsupervised Language Model Pre-training for French](https://arxiv.org/abs/1912.05372) by Hang Le, Lo\u00efc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Beno\u00eet Crabb\u00e9, Laurent Besacier, Didier Schwab.\n1. **[FLAVA](https://huggingface.co/docs/transformers/model_doc/flava)** (from Facebook AI) released with the paper [FLAVA: A Foundational Language And Vision Alignment Model](https://arxiv.org/abs/2112.04482) by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.\n1. **[FNet](https://huggingface.co/docs/transformers/model_doc/fnet)** (from Google Research) released with the paper [FNet: Mixing Tokens with Fourier Transforms](https://arxiv.org/abs/2105.03824) by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.\n1. **[Funnel Transformer](https://huggingface.co/docs/transformers/model_doc/funnel)** (from CMU/Google Brain) released with the paper [Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing](https://arxiv.org/abs/2006.03236) by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.\n1. **[GLPN](https://huggingface.co/docs/transformers/model_doc/glpn)** (from KAIST) released with the paper [Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth](https://arxiv.org/abs/2201.07436) by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.\n1. **[GPT](https://huggingface.co/docs/transformers/model_doc/openai-gpt)** (from OpenAI) released with the paper [Improving Language Understanding by Generative Pre-Training](https://blog.openai.com/language-unsupervised/) by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.\n1. **[GPT Neo](https://huggingface.co/docs/transformers/model_doc/gpt_neo)** (from EleutherAI) released in the repository [EleutherAI/gpt-neo](https://github.com/EleutherAI/gpt-neo) by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.\n1. **[GPT NeoX](https://huggingface.co/docs/transformers/model_doc/gpt_neox)** (from EleutherAI) released with the paper [GPT-NeoX-20B: An Open-Source Autoregressive Language Model](https://arxiv.org/abs/2204.06745) by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel Weinbach\n1. **[GPT NeoX Japanese](https://huggingface.co/docs/transformers/model_doc/gpt_neox_japanese)** (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.\n1. **[GPT-2](https://huggingface.co/docs/transformers/model_doc/gpt2)** (from OpenAI) released with the paper [Language Models are Unsupervised Multitask Learners](https://blog.openai.com/better-language-models/) by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.\n1. **[GPT-J](https://huggingface.co/docs/transformers/model_doc/gptj)** (from EleutherAI) released in the repository [kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax/) by Ben Wang and Aran Komatsuzaki.\n1. **[GroupViT](https://huggingface.co/docs/transformers/model_doc/groupvit)** (from UCSD, NVIDIA) released with the paper [GroupViT: Semantic Segmentation Emerges from Text Supervision](https://arxiv.org/abs/2202.11094) by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.\n1. **[Hubert](https://huggingface.co/docs/transformers/model_doc/hubert)** (from Facebook) released with the paper [HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units](https://arxiv.org/abs/2106.07447) by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.\n1. **[I-BERT](https://huggingface.co/docs/transformers/model_doc/ibert)** (from Berkeley) released with the paper [I-BERT: Integer-only BERT Quantization](https://arxiv.org/abs/2101.01321) by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.\n1. **[ImageGPT](https://huggingface.co/docs/transformers/model_doc/imagegpt)** (from OpenAI) released with the paper [Generative Pretraining from Pixels](https://openai.com/blog/image-gpt/) by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.\n1. **[Jukebox](https://huggingface.co/docs/transformers/main/model_doc/jukebox)** (from OpenAI) released with the paper [Jukebox: A Generative Model for Music](https://arxiv.org/pdf/2005.00341.pdf) by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.\n1. **[LayoutLM](https://huggingface.co/docs/transformers/model_doc/layoutlm)** (from Microsoft Research Asia) released with the paper [LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318) by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.\n1. **[LayoutLMv2](https://huggingface.co/docs/transformers/model_doc/layoutlmv2)** (from Microsoft Research Asia) released with the paper [LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding](https://arxiv.org/abs/2012.14740) by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.\n1. **[LayoutLMv3](https://huggingface.co/docs/transformers/model_doc/layoutlmv3)** (from Microsoft Research Asia) released with the paper [LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking](https://arxiv.org/abs/2204.08387) by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.\n1. **[LayoutXLM](https://huggingface.co/docs/transformers/model_doc/layoutxlm)** (from Microsoft Research Asia) released with the paper [LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding](https://arxiv.org/abs/2104.08836) by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.\n1. **[LED](https://huggingface.co/docs/transformers/model_doc/led)** (from AllenAI) released with the paper [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150) by Iz Beltagy, Matthew E. Peters, Arman Cohan.\n1. **[LeViT](https://huggingface.co/docs/transformers/model_doc/levit)** (from Meta AI) released with the paper [LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference](https://arxiv.org/abs/2104.01136) by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Herv\u00e9 J\u00e9gou, Matthijs Douze.\n1. **[LiLT](https://huggingface.co/docs/transformers/model_doc/lilt)** (from South China University of Technology) released with the paper [LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding](https://arxiv.org/abs/2202.13669) by Jiapeng Wang, Lianwen Jin, Kai Ding.\n1. **[Longformer](https://huggingface.co/docs/transformers/model_doc/longformer)** (from AllenAI) released with the paper [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150) by Iz Beltagy, Matthew E. Peters, Arman Cohan.\n1. **[LongT5](https://huggingface.co/docs/transformers/model_doc/longt5)** (from Google AI) released with the paper [LongT5: Efficient Text-To-Text Transformer for Long Sequences](https://arxiv.org/abs/2112.07916) by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.\n1. **[LUKE](https://huggingface.co/docs/transformers/model_doc/luke)** (from Studio Ousia) released with the paper [LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention](https://arxiv.org/abs/2010.01057) by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.\n1. **[LXMERT](https://huggingface.co/docs/transformers/model_doc/lxmert)** (from UNC Chapel Hill) released with the paper [LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering](https://arxiv.org/abs/1908.07490) by Hao Tan and Mohit Bansal.\n1. **[M-CTC-T](https://huggingface.co/docs/transformers/model_doc/mctct)** (from Facebook) released with the paper [Pseudo-Labeling For Massively Multilingual Speech Recognition](https://arxiv.org/abs/2111.00161) by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.\n1. **[M2M100](https://huggingface.co/docs/transformers/model_doc/m2m_100)** (from Facebook) released with the paper [Beyond English-Centric Multilingual Machine Translation](https://arxiv.org/abs/2010.11125) by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.\n1. **[MarianMT](https://huggingface.co/docs/transformers/model_doc/marian)** Machine translation models trained using [OPUS](http://opus.nlpl.eu/) data by J\u00f6rg Tiedemann. The [Marian Framework](https://marian-nmt.github.io/) is being developed by the Microsoft Translator Team.\n1. **[MarkupLM](https://huggingface.co/docs/transformers/model_doc/markuplm)** (from Microsoft Research Asia) released with the paper [MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding](https://arxiv.org/abs/2110.08518) by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.\n1. **[MaskFormer](https://huggingface.co/docs/transformers/model_doc/maskformer)** (from Meta and UIUC) released with the paper [Per-Pixel Classification is Not All You Need for Semantic Segmentation](https://arxiv.org/abs/2107.06278) by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.\n1. **[mBART](https://huggingface.co/docs/transformers/model_doc/mbart)** (from Facebook) released with the paper [Multilingual Denoising Pre-training for Neural Machine Translation](https://arxiv.org/abs/2001.08210) by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.\n1. **[mBART-50](https://huggingface.co/docs/transformers/model_doc/mbart)** (from Facebook) released with the paper [Multilingual Translation with Extensible Multilingual Pretraining and Finetuning](https://arxiv.org/abs/2008.00401) by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.\n1. **[Megatron-BERT](https://huggingface.co/docs/transformers/model_doc/megatron-bert)** (from NVIDIA) released with the paper [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism](https://arxiv.org/abs/1909.08053) by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.\n1. **[Megatron-GPT2](https://huggingface.co/docs/transformers/model_doc/megatron_gpt2)** (from NVIDIA) released with the paper [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism](https://arxiv.org/abs/1909.08053) by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.\n1. **[mLUKE](https://huggingface.co/docs/transformers/model_doc/mluke)** (from Studio Ousia) released with the paper [mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models](https://arxiv.org/abs/2110.08151) by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.\n1. **[MobileBERT](https://huggingface.co/docs/transformers/model_doc/mobilebert)** (from CMU/Google Brain) released with the paper [MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices](https://arxiv.org/abs/2004.02984) by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.\n1. **[MobileNetV1](https://huggingface.co/docs/transformers/model_doc/mobilenet_v1)** (from Google Inc.) released with the paper [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861) by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.\n1. **[MobileNetV2](https://huggingface.co/docs/transformers/model_doc/mobilenet_v2)** (from Google Inc.) released with the paper [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381) by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.\n1. **[MobileViT](https://huggingface.co/docs/transformers/model_doc/mobilevit)** (from Apple) released with the paper [MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer](https://arxiv.org/abs/2110.02178) by Sachin Mehta and Mohammad Rastegari.\n1. **[MPNet](https://huggingface.co/docs/transformers/model_doc/mpnet)** (from Microsoft Research) released with the paper [MPNet: Masked and Permuted Pre-training for Language Understanding](https://arxiv.org/abs/2004.09297) by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.\n1. **[MT5](https://huggingface.co/docs/transformers/model_doc/mt5)** (from Google AI) released with the paper [mT5: A massively multilingual pre-trained text-to-text transformer](https://arxiv.org/abs/2010.11934) by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.\n1. **[MVP](https://huggingface.co/docs/transformers/model_doc/mvp)** (from RUC AI Box) released with the paper [MVP: Multi-task Supervised Pre-training for Natural Language Generation](https://arxiv.org/abs/2206.12131) by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.\n1. **[NAT](https://huggingface.co/docs/transformers/main/model_doc/nat)** (from SHI Labs) released with the paper [Neighborhood Attention Transformer](https://arxiv.org/abs/2204.07143) by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.\n1. **[Nezha](https://huggingface.co/docs/transformers/model_doc/nezha)** (from Huawei Noah\u2019s Ark Lab) released with the paper [NEZHA: Neural Contextualized Representation for Chinese Language Understanding](https://arxiv.org/abs/1909.00204) by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.\n1. **[NLLB](https://huggingface.co/docs/transformers/model_doc/nllb)** (from Meta) released with the paper [No Language Left Behind: Scaling Human-Centered Machine Translation](https://arxiv.org/abs/2207.04672) by the NLLB team.\n1. **[Nystr\u00f6mformer](https://huggingface.co/docs/transformers/model_doc/nystromformer)** (from the University of Wisconsin - Madison) released with the paper [Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention](https://arxiv.org/abs/2102.03902) by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.\n1. **[OPT](https://huggingface.co/docs/transformers/master/model_doc/opt)** (from Meta AI) released with the paper [OPT: Open Pre-trained Transformer Language Models](https://arxiv.org/abs/2205.01068) by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.\n1. **[OWL-ViT](https://huggingface.co/docs/transformers/model_doc/owlvit)** (from Google AI) released with the paper [Simple Open-Vocabulary Object Detection with Vision Transformers](https://arxiv.org/abs/2205.06230) by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.\n1. **[Pegasus](https://huggingface.co/docs/transformers/model_doc/pegasus)** (from Google) released with the paper [PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization](https://arxiv.org/abs/1912.08777) by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.\n1. **[PEGASUS-X](https://huggingface.co/docs/transformers/model_doc/pegasus_x)** (from Google) released with the paper [Investigating Efficiently Extending Transformers for Long Input Summarization](https://arxiv.org/abs/2208.04347) by Jason Phang, Yao Zhao, and Peter J. Liu.\n1. **[Perceiver IO](https://huggingface.co/docs/transformers/model_doc/perceiver)** (from Deepmind) released with the paper [Perceiver IO: A General Architecture for Structured Inputs & Outputs](https://arxiv.org/abs/2107.14795) by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier H\u00e9naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, Jo\u00e3o Carreira.\n1. **[PhoBERT](https://huggingface.co/docs/transformers/model_doc/phobert)** (from VinAI Research) released with the paper [PhoBERT: Pre-trained language models for Vietnamese](https://www.aclweb.org/anthology/2020.findings-emnlp.92/) by Dat Quoc Nguyen and Anh Tuan Nguyen.\n1. **[PLBart](https://huggingface.co/docs/transformers/model_doc/plbart)** (from UCLA NLP) released with the paper [Unified Pre-training for Program Understanding and Generation](https://arxiv.org/abs/2103.06333) by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.\n1. **[PoolFormer](https://huggingface.co/docs/transformers/model_doc/poolformer)** (from Sea AI Labs) released with the paper [MetaFormer is Actually What You Need for Vision](https://arxiv.org/abs/2111.11418) by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.\n1. **[ProphetNet](https://huggingface.co/docs/transformers/model_doc/prophetnet)** (from Microsoft Research) released with the paper [ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training](https://arxiv.org/abs/2001.04063) by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.\n1. **[QDQBert](https://huggingface.co/docs/transformers/model_doc/qdqbert)** (from NVIDIA) released with the paper [Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation](https://arxiv.org/abs/2004.09602) by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.\n1. **[RAG](https://huggingface.co/docs/transformers/model_doc/rag)** (from Facebook) released with the paper [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401) by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, Sebastian Riedel, Douwe Kiela.\n1. **[REALM](https://huggingface.co/docs/transformers/model_doc/realm.html)** (from Google Research) released with the paper [REALM: Retrieval-Augmented Language Model Pre-Training](https://arxiv.org/abs/2002.08909) by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.\n1. **[Reformer](https://huggingface.co/docs/transformers/model_doc/reformer)** (from Google Research) released with the paper [Reformer: The Efficient Transformer](https://arxiv.org/abs/2001.04451) by Nikita Kitaev, \u0141ukasz Kaiser, Anselm Levskaya.\n1. **[RegNet](https://huggingface.co/docs/transformers/model_doc/regnet)** (from META Platforms) released with the paper [Designing Network Design Space](https://arxiv.org/abs/2003.13678) by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Doll\u00e1r.\n1. **[RemBERT](https://huggingface.co/docs/transformers/model_doc/rembert)** (from Google Research) released with the paper [Rethinking embedding coupling in pre-trained language models](https://arxiv.org/abs/2010.12821) by Hyung Won Chung, Thibault F\u00e9vry, Henry Tsai, M. Johnson, Sebastian Ruder.\n1. **[ResNet](https://huggingface.co/docs/transformers/model_doc/resnet)** (from Microsoft Research) released with the paper [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.\n1. **[RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta)** (from Facebook), released together with the paper [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.\n1. **[RoCBert](https://huggingface.co/docs/transformers/main/model_doc/roc_bert)** (from WeChatAI) released with the paper [RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining](https://aclanthology.org/2022.acl-long.65.pdf) by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.\n1. **[RoFormer](https://huggingface.co/docs/transformers/model_doc/roformer)** (from ZhuiyiTechnology), released together with the paper [RoFormer: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/abs/2104.09864) by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.\n1. **[SegFormer](https://huggingface.co/docs/transformers/model_doc/segformer)** (from NVIDIA) released with the paper [SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203) by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.\n1. **[SEW](https://huggingface.co/docs/transformers/model_doc/sew)** (from ASAPP) released with the paper [Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition](https://arxiv.org/abs/2109.06870) by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.\n1. **[SEW-D](https://huggingface.co/docs/transformers/model_doc/sew_d)** (from ASAPP) released with the paper [Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition](https://arxiv.org/abs/2109.06870) by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.\n1. **[SpeechToTextTransformer](https://huggingface.co/docs/transformers/model_doc/speech_to_text)** (from Facebook), released together with the paper [fairseq S2T: Fast Speech-to-Text Modeling with fairseq](https://arxiv.org/abs/2010.05171) by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.\n1. **[SpeechToTextTransformer2](https://huggingface.co/docs/transformers/model_doc/speech_to_text_2)** (from Facebook), released together with the paper [Large-Scale Self- and Semi-Supervised Learning for Speech Translation](https://arxiv.org/abs/2104.06678) by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.\n1. **[Splinter](https://huggingface.co/docs/transformers/model_doc/splinter)** (from Tel Aviv University), released together with the paper [Few-Shot Question Answering by Pretraining Span Selection](https://arxiv.org/abs/2101.00438) by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.\n1. **[SqueezeBERT](https://huggingface.co/docs/transformers/model_doc/squeezebert)** (from Berkeley) released with the paper [SqueezeBERT: What can computer vision teach NLP about efficient neural networks?](https://arxiv.org/abs/2006.11316) by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.\n1. **[Swin Transformer](https://huggingface.co/docs/transformers/model_doc/swin)** (from Microsoft) released with the paper [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030) by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.\n1. **[Swin Transformer V2](https://huggingface.co/docs/transformers/model_doc/swinv2)** (from Microsoft) released with the paper [Swin Transformer V2: Scaling Up Capacity and Resolution](https://arxiv.org/abs/2111.09883) by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.\n1. **[SwitchTransformers](https://huggingface.co/docs/transformers/main/model_doc/switch_transformers)** (from Google) released with the paper [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/abs/2101.03961) by William Fedus, Barret Zoph, Noam Shazeer.\n1. **[T5](https://huggingface.co/docs/transformers/model_doc/t5)** (from Google AI) released with the paper [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.\n1. **[T5v1.1](https://huggingface.co/docs/transformers/model_doc/t5v1.1)** (from Google AI) released in the repository [google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511) by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.\n1. **[Table Transformer](https://huggingface.co/docs/transformers/model_doc/table-transformer)** (from Microsoft Research) released with the paper [PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents](https://arxiv.org/abs/2110.00061) by Brandon Smock, Rohith Pesala, Robin Abraham.\n1. **[TAPAS](https://huggingface.co/docs/transformers/model_doc/tapas)** (from Google AI) released with the paper [TAPAS: Weakly Supervised Table Parsing via Pre-training](https://arxiv.org/abs/2004.02349) by Jonathan Herzig, Pawe\u0142 Krzysztof Nowak, Thomas M\u00fcller, Francesco Piccinno and Julian Martin Eisenschlos.\n1. **[TAPEX](https://huggingface.co/docs/transformers/model_doc/tapex)** (from Microsoft Research) released with the paper [TAPEX: Table Pre-training via Learning a Neural SQL Executor](https://arxiv.org/abs/2107.07653) by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.\n1. **[Time Series Transformer](https://huggingface.co/docs/transformers/model_doc/time_series_transformer)**  (from HuggingFace).\n1. **[Trajectory Transformer](https://huggingface.co/docs/transformers/model_doc/trajectory_transformers)** (from the University of California at Berkeley) released with the paper [Offline Reinforcement Learning as One Big Sequence Modeling Problem](https://arxiv.org/abs/2106.02039) by Michael Janner, Qiyang Li, Sergey Levine\n1. **[Transformer-XL](https://huggingface.co/docs/transformers/model_doc/transfo-xl)** (from Google/CMU) released with the paper [Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/abs/1901.02860) by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.\n1. **[TrOCR](https://huggingface.co/docs/transformers/model_doc/trocr)** (from Microsoft), released together with the paper [TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models](https://arxiv.org/abs/2109.10282) by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.\n1. **[UL2](https://huggingface.co/docs/transformers/model_doc/ul2)** (from Google Research) released with the paper [Unifying Language Learning Paradigms](https://arxiv.org/abs/2205.05131v1) by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald Metzler\n1. **[UniSpeech](https://huggingface.co/docs/transformers/model_doc/unispeech)** (from Microsoft Research) released with the paper [UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data](https://arxiv.org/abs/2101.07597) by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.\n1. **[UniSpeechSat](https://huggingface.co/docs/transformers/model_doc/unispeech-sat)** (from Microsoft Research) released with the paper [UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING](https://arxiv.org/abs/2110.05752) by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.\n1. **[VAN](https://huggingface.co/docs/transformers/model_doc/van)** (from Tsinghua University and Nankai University) released with the paper [Visual Attention Network](https://arxiv.org/abs/2202.09741) by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.\n1. **[VideoMAE](https://huggingface.co/docs/transformers/model_doc/videomae)** (from Multimedia Computing Group, Nanjing University) released with the paper [VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training](https://arxiv.org/abs/2203.12602) by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.\n1. **[ViLT](https://huggingface.co/docs/transformers/model_doc/vilt)** (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper [ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision](https://arxiv.org/abs/2102.03334) by Wonjae Kim, Bokyung Son, Ildoo Kim.\n1. **[Vision Transformer (ViT)](https://huggingface.co/docs/transformers/model_doc/vit)** (from Google AI) released with the paper [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.\n1. **[VisualBERT](https://huggingface.co/docs/transformers/model_doc/visual_bert)** (from UCLA NLP) released with the paper [VisualBERT: A Simple and Performant Baseline for Vision and Language](https://arxiv.org/pdf/1908.03557) by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.\n1. **[ViTMAE](https://huggingface.co/docs/transformers/model_doc/vit_mae)** (from Meta AI) released with the paper [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377) by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, Ross Girshick.\n1. **[ViTMSN](https://huggingface.co/docs/transformers/model_doc/vit_msn)** (from Meta AI) released with the paper [Masked Siamese Networks for Label-Efficient Learning](https://arxiv.org/abs/2204.07141) by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.\n1. **[Wav2Vec2](https://huggingface.co/docs/transformers/model_doc/wav2vec2)** (from Facebook AI) released with the paper [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477) by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.\n1. **[Wav2Vec2-Conformer](https://huggingface.co/docs/transformers/model_doc/wav2vec2-conformer)** (from Facebook AI) released with the paper [FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ](https://arxiv.org/abs/2010.05171) by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.\n1. **[Wav2Vec2Phoneme](https://huggingface.co/docs/transformers/model_doc/wav2vec2_phoneme)** (from Facebook AI) released with the paper [Simple and Effective Zero-shot Cross-lingual Phoneme Recognition](https://arxiv.org/abs/2109.11680) by Qiantong Xu, Alexei Baevski, Michael Auli.\n1. **[WavLM](https://huggingface.co/docs/transformers/model_doc/wavlm)** (from Microsoft Research) released with the paper [WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing](https://arxiv.org/abs/2110.13900) by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.\n1. **[Whisper](https://huggingface.co/docs/transformers/model_doc/whisper)** (from OpenAI) released with the paper [Robust Speech Recognition via Large-Scale Weak Supervision](https://cdn.openai.com/papers/whisper.pdf) by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.\n1. **[X-CLIP](https://huggingface.co/docs/transformers/model_doc/xclip)** (from Microsoft Research) released with the paper [Expanding Language-Image Pretrained Models for General Video Recognition](https://arxiv.org/abs/2208.02816) by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.\n1. **[XGLM](https://huggingface.co/docs/transformers/model_doc/xglm)** (From Facebook AI) released with the paper [Few-shot Learning with Multilingual Language Models](https://arxiv.org/abs/2112.10668) by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.\n1. **[XLM](https://huggingface.co/docs/transformers/model_doc/xlm)** (from Facebook) released together with the paper [Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291) by Guillaume Lample and Alexis Conneau.\n1. **[XLM-ProphetNet](https://huggingface.co/docs/transformers/model_doc/xlm-prophetnet)** (from Microsoft Research) released with the paper [ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training](https://arxiv.org/abs/2001.04063) by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.\n1. **[XLM-RoBERTa](https://huggingface.co/docs/transformers/model_doc/xlm-roberta)** (from Facebook AI), released together with the paper [Unsupervised Cross-lingual Representation Learning at Scale](https://arxiv.org/abs/1911.02116) by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.\n1. **[XLM-RoBERTa-XL](https://huggingface.co/docs/transformers/model_doc/xlm-roberta-xl)** (from Facebook AI), released together with the paper [Larger-Scale Transformers for Multilingual Masked Language Modeling](https://arxiv.org/abs/2105.00572) by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.\n1. **[XLNet](https://huggingface.co/docs/transformers/model_doc/xlnet)** (from Google/CMU) released with the paper [\u200bXLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237) by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.\n1. **[XLS-R](https://huggingface.co/docs/transformers/model_doc/xls_r)** (from Facebook AI) released with the paper [XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale](https://arxiv.org/abs/2111.09296) by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.\n1. **[XLSR-Wav2Vec2](https://huggingface.co/docs/transformers/model_doc/xlsr_wav2vec2)** (from Facebook AI) released with the paper [Unsupervised Cross-Lingual Representation Learning For Speech Recognition](https://arxiv.org/abs/2006.13979) by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.\n1. **[YOLOS](https://huggingface.co/docs/transformers/model_doc/yolos)** (from Huazhong University of Science & Technology) released with the paper [You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection](https://arxiv.org/abs/2106.00666) by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.\n1. **[YOSO](https://huggingface.co/docs/transformers/model_doc/yoso)** (from the University of Wisconsin - Madison) released with the paper [You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling](https://arxiv.org/abs/2111.09714) by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.\n1. Want to contribute a new model? We have added a **detailed guide and templates** to guide you in the process of adding a new model. You can find them in the [`templates`](./templates) folder of the repository. Be sure to check the [contributing guidelines](./CONTRIBUTING.md) and contact the maintainers or open an issue to collect feedbacks before starting your PR.\n\nTo check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the \ud83e\udd17 Tokenizers library, refer to [this table](https://huggingface.co/docs/transformers/index#supported-frameworks).\n\nThese implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the [documentation](https://github.com/huggingface/transformers/tree/main/examples).\n\n\n## Learn more\n\n| Section | Description |\n|-|-|\n| [Documentation](https://huggingface.co/docs/transformers/) | Full API documentation and tutorials |\n| [Task summary](https://huggingface.co/docs/transformers/task_summary) | Tasks supported by \ud83e\udd17 Transformers |\n| [Preprocessing tutorial](https://huggingface.co/docs/transformers/preprocessing) | Using the `Tokenizer` class to prepare data for the models |\n| [Training and fine-tuning](https://huggingface.co/docs/transformers/training) | Using the models provided by \ud83e\udd17 Transformers in a PyTorch/TensorFlow training loop and the `Trainer` API |\n| [Quick tour: Fine-tuning/usage scripts](https://github.com/huggingface/transformers/tree/main/examples) | Example scripts for fine-tuning models on a wide range of tasks |\n| [Model sharing and uploading](https://huggingface.co/docs/transformers/model_sharing) | Upload and share your fine-tuned models with the community |\n| [Migration](https://huggingface.co/docs/transformers/migration) | Migrate to \ud83e\udd17 Transformers from `pytorch-transformers` or `pytorch-pretrained-bert` |\n\n## Citation\n\nWe now have a [paper](https://www.aclweb.org/anthology/2020.emnlp-demos.6/) you can cite for the \ud83e\udd17 Transformers library:\n```bibtex\n@inproceedings{wolf-etal-2020-transformers,\n    title = \"Transformers: State-of-the-Art Natural Language Processing\",\n    author = \"Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R\u00e9mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\",\n    month = oct,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-demos.6\",\n    pages = \"38--45\"\n}\n```\n",
	"autograd deep-learning gpu machine-learning neural-network numpy python tensor": "![PyTorch Logo](https://github.com/pytorch/pytorch/blob/master/docs/source/_static/img/pytorch-logo-dark.png)\n\n--------------------------------------------------------------------------------\n\nPyTorch is a Python package that provides two high-level features:\n- Tensor computation (like NumPy) with strong GPU acceleration\n- Deep neural networks built on a tape-based autograd system\n\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n\nOur trunk health (Continuous Integration signals) can be found at [hud.pytorch.org](https://hud.pytorch.org/ci/pytorch/pytorch/master).\n\n<!-- toc -->\n\n- [More About PyTorch](#more-about-pytorch)\n  - [A GPU-Ready Tensor Library](#a-gpu-ready-tensor-library)\n  - [Dynamic Neural Networks: Tape-Based Autograd](#dynamic-neural-networks-tape-based-autograd)\n  - [Python First](#python-first)\n  - [Imperative Experiences](#imperative-experiences)\n  - [Fast and Lean](#fast-and-lean)\n  - [Extensions Without Pain](#extensions-without-pain)\n- [Installation](#installation)\n  - [Binaries](#binaries)\n    - [NVIDIA Jetson Platforms](#nvidia-jetson-platforms)\n  - [From Source](#from-source)\n    - [Prerequisites](#prerequisites)\n    - [Install Dependencies](#install-dependencies)\n    - [Get the PyTorch Source](#get-the-pytorch-source)\n    - [Install PyTorch](#install-pytorch)\n      - [Adjust Build Options (Optional)](#adjust-build-options-optional)\n  - [Docker Image](#docker-image)\n    - [Using pre-built images](#using-pre-built-images)\n    - [Building the image yourself](#building-the-image-yourself)\n  - [Building the Documentation](#building-the-documentation)\n  - [Previous Versions](#previous-versions)\n- [Getting Started](#getting-started)\n- [Resources](#resources)\n- [Communication](#communication)\n- [Releases and Contributing](#releases-and-contributing)\n- [The Team](#the-team)\n- [License](#license)\n\n<!-- tocstop -->\n\n## More About PyTorch\n\nAt a granular level, PyTorch is a library that consists of the following components:\n\n| Component | Description |\n| ---- | --- |\n| [**torch**](https://pytorch.org/docs/stable/torch.html) | A Tensor library like NumPy, with strong GPU support |\n| [**torch.autograd**](https://pytorch.org/docs/stable/autograd.html) | A tape-based automatic differentiation library that supports all differentiable Tensor operations in torch |\n| [**torch.jit**](https://pytorch.org/docs/stable/jit.html) | A compilation stack (TorchScript) to create serializable and optimizable models from PyTorch code  |\n| [**torch.nn**](https://pytorch.org/docs/stable/nn.html) | A neural networks library deeply integrated with autograd designed for maximum flexibility |\n| [**torch.multiprocessing**](https://pytorch.org/docs/stable/multiprocessing.html) | Python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and Hogwild training |\n| [**torch.utils**](https://pytorch.org/docs/stable/data.html) | DataLoader and other utility functions for convenience |\n\nUsually, PyTorch is used either as:\n\n- A replacement for NumPy to use the power of GPUs.\n- A deep learning research platform that provides maximum flexibility and speed.\n\nElaborating Further:\n\n### A GPU-Ready Tensor Library\n\nIf you use NumPy, then you have used Tensors (a.k.a. ndarray).\n\n![Tensor illustration](./docs/source/_static/img/tensor_illustration.png)\n\nPyTorch provides Tensors that can live either on the CPU or the GPU and accelerates the\ncomputation by a huge amount.\n\nWe provide a wide variety of tensor routines to accelerate and fit your scientific computation needs\nsuch as slicing, indexing, mathematical operations, linear algebra, reductions.\nAnd they are fast!\n\n### Dynamic Neural Networks: Tape-Based Autograd\n\nPyTorch has a unique way of building neural networks: using and replaying a tape recorder.\n\nMost frameworks such as TensorFlow, Theano, Caffe, and CNTK have a static view of the world.\nOne has to build a neural network and reuse the same structure again and again.\nChanging the way the network behaves means that one has to start from scratch.\n\nWith PyTorch, we use a technique called reverse-mode auto-differentiation, which allows you to\nchange the way your network behaves arbitrarily with zero lag or overhead. Our inspiration comes\nfrom several research papers on this topic, as well as current and past work such as\n[torch-autograd](https://github.com/twitter/torch-autograd),\n[autograd](https://github.com/HIPS/autograd),\n[Chainer](https://chainer.org), etc.\n\nWhile this technique is not unique to PyTorch, it's one of the fastest implementations of it to date.\nYou get the best of speed and flexibility for your crazy research.\n\n![Dynamic graph](https://github.com/pytorch/pytorch/blob/master/docs/source/_static/img/dynamic_graph.gif)\n\n### Python First\n\nPyTorch is not a Python binding into a monolithic C++ framework.\nIt is built to be deeply integrated into Python.\nYou can use it naturally like you would use [NumPy](https://www.numpy.org/) / [SciPy](https://www.scipy.org/) / [scikit-learn](https://scikit-learn.org) etc.\nYou can write your new neural network layers in Python itself, using your favorite libraries\nand use packages such as [Cython](https://cython.org/) and [Numba](http://numba.pydata.org/).\nOur goal is to not reinvent the wheel where appropriate.\n\n### Imperative Experiences\n\nPyTorch is designed to be intuitive, linear in thought, and easy to use.\nWhen you execute a line of code, it gets executed. There isn't an asynchronous view of the world.\nWhen you drop into a debugger or receive error messages and stack traces, understanding them is straightforward.\nThe stack trace points to exactly where your code was defined.\nWe hope you never spend hours debugging your code because of bad stack traces or asynchronous and opaque execution engines.\n\n### Fast and Lean\n\nPyTorch has minimal framework overhead. We integrate acceleration libraries\nsuch as [Intel MKL](https://software.intel.com/mkl) and NVIDIA ([cuDNN](https://developer.nvidia.com/cudnn), [NCCL](https://developer.nvidia.com/nccl)) to maximize speed.\nAt the core, its CPU and GPU Tensor and neural network backends\nare mature and have been tested for years.\n\nHence, PyTorch is quite fast \u2013 whether you run small or large neural networks.\n\nThe memory usage in PyTorch is extremely efficient compared to Torch or some of the alternatives.\nWe've written custom memory allocators for the GPU to make sure that\nyour deep learning models are maximally memory efficient.\nThis enables you to train bigger deep learning models than before.\n\n### Extensions Without Pain\n\nWriting new neural network modules, or interfacing with PyTorch's Tensor API was designed to be straightforward\nand with minimal abstractions.\n\nYou can write new neural network layers in Python using the torch API\n[or your favorite NumPy-based libraries such as SciPy](https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html).\n\nIf you want to write your layers in C/C++, we provide a convenient extension API that is efficient and with minimal boilerplate.\nNo wrapper code needs to be written. You can see [a tutorial here](https://pytorch.org/tutorials/advanced/cpp_extension.html) and [an example here](https://github.com/pytorch/extension-cpp).\n\n\n## Installation\n\n### Binaries\nCommands to install binaries via Conda or pip wheels are on our website: [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)\n\n\n#### NVIDIA Jetson Platforms\n\nPython wheels for NVIDIA's Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX, and Jetson AGX Orin are provided [here](https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048) and the L4T container is published [here](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch)\n\nThey require JetPack 4.2 and above, and [@dusty-nv](https://github.com/dusty-nv) and [@ptrblck](https://github.com/ptrblck) are maintaining them.\n\n\n### From Source\n\n#### Prerequisites\nIf you are installing from source, you will need:\n- Python 3.7 or later (for Linux, Python 3.7.6+ or 3.8.1+ is needed)\n- A C++14 compatible compiler, such as clang\n\nWe highly recommend installing an [Anaconda](https://www.anaconda.com/distribution/#download-section) environment. You will get a high-quality BLAS library (MKL) and you get controlled dependency versions regardless of your Linux distro.\n\nIf you want to compile with CUDA support, install the following (note that CUDA is not supported on macOS)\n- [NVIDIA CUDA](https://developer.nvidia.com/cuda-downloads) 10.2 or above\n- [NVIDIA cuDNN](https://developer.nvidia.com/cudnn) v7 or above\n- [Compiler](https://gist.github.com/ax3l/9489132) compatible with CUDA\n\nNote: You could refer to the [cuDNN Support Matrix](https://docs.nvidia.com/deeplearning/cudnn/pdf/cuDNN-Support-Matrix.pdf) for cuDNN versions with the various supported CUDA, CUDA driver and NVIDIA hardware\n\nIf you want to disable CUDA support, export the environment variable `USE_CUDA=0`.\nOther potentially useful environment variables may be found in `setup.py`.\n\nIf you are building for NVIDIA's Jetson platforms (Jetson Nano, TX1, TX2, AGX Xavier), Instructions to install PyTorch for Jetson Nano are [available here](https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/)\n\nIf you want to compile with ROCm support, install\n- [AMD ROCm](https://rocmdocs.amd.com/en/latest/Installation_Guide/Installation-Guide.html) 4.0 and above installation\n- ROCm is currently supported only for Linux systems.\n\nIf you want to disable ROCm support, export the environment variable `USE_ROCM=0`.\nOther potentially useful environment variables may be found in `setup.py`.\n\n#### Install Dependencies\n\n**Common**\n\n```bash\nconda install astunparse numpy ninja pyyaml setuptools cmake cffi typing_extensions future six requests dataclasses\n```\n\n**On Linux**\n\n```bash\nconda install mkl mkl-include\n# CUDA only: Add LAPACK support for the GPU if needed\nconda install -c pytorch magma-cuda110  # or the magma-cuda* that matches your CUDA version from https://anaconda.org/pytorch/repo\n```\n\n**On MacOS**\n\n```bash\n# Add this package on intel x86 processor machines only\nconda install mkl mkl-include\n# Add these packages if torch.distributed is needed\nconda install pkg-config libuv\n```\n\n**On Windows**\n\n```bash\nconda install mkl mkl-include\n# Add these packages if torch.distributed is needed.\n# Distributed package support on Windows is a prototype feature and is subject to changes.\nconda install -c conda-forge libuv=1.39\n```\n\n#### Get the PyTorch Source\n```bash\ngit clone --recursive https://github.com/pytorch/pytorch\ncd pytorch\n# if you are updating an existing checkout\ngit submodule sync\ngit submodule update --init --recursive --jobs 0\n```\n\n#### Install PyTorch\n**On Linux**\n\nIf you're compiling for AMD ROCm then first run this command:\n```bash\n# Only run this if you're compiling for ROCm\npython tools/amd_build/build_amd.py\n```\n\nInstall PyTorch\n```bash\nexport CMAKE_PREFIX_PATH=${CONDA_PREFIX:-\"$(dirname $(which conda))/../\"}\npython setup.py develop\n```\n\nNote that if you are using [Anaconda](https://www.anaconda.com/distribution/#download-section), you may experience an error caused by the linker:\n\n```plaintext\nbuild/temp.linux-x86_64-3.7/torch/csrc/stub.o: file not recognized: file format not recognized\ncollect2: error: ld returned 1 exit status\nerror: command 'g++' failed with exit status 1\n```\n\nThis is caused by `ld` from the Conda environment shadowing the system `ld`. You should use a newer version of Python that fixes this issue. The recommended Python version is 3.7.6+ and 3.8.1+.\n\n**On macOS**\n\n```bash\nexport CMAKE_PREFIX_PATH=${CONDA_PREFIX:-\"$(dirname $(which conda))/../\"}\nMACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py develop\n```\n\n**On Windows**\n\nChoose Correct Visual Studio Version.\n\nSometimes there are regressions in new versions of Visual Studio, so\nit's best to use the same Visual Studio Version [16.8.5](https://github.com/pytorch/pytorch/blob/master/.circleci/scripts/vs_install.ps1) as Pytorch CI's.\n\nPyTorch CI uses Visual C++ BuildTools, which come with Visual Studio Enterprise,\nProfessional, or Community Editions. You can also install the build tools from\nhttps://visualstudio.microsoft.com/visual-cpp-build-tools/. The build tools *do not*\ncome with Visual Studio Code by default.\n\nIf you want to build legacy python code, please refer to [Building on legacy code and CUDA](https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md#building-on-legacy-code-and-cuda)\n\n**CPU-only builds**\n\nIn this mode PyTorch computations will run on your CPU, not your GPU\n\n```cmd\nconda activate\npython setup.py develop\n```\n\nNote on OpenMP: The desired OpenMP implementation is Intel OpenMP (iomp). In order to link against iomp, you'll need to manually download the library and set up the building environment by tweaking `CMAKE_INCLUDE_PATH` and `LIB`. The instruction [here](https://github.com/pytorch/pytorch/blob/master/docs/source/notes/windows.rst#building-from-source) is an example for setting up both MKL and Intel OpenMP. Without these configurations for CMake, Microsoft Visual C OpenMP runtime (vcomp) will be used.\n\n**CUDA based build**\n\nIn this mode PyTorch computations will leverage your GPU via CUDA for faster number crunching\n\n[NVTX](https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm) is needed to build Pytorch with CUDA.\nNVTX is a part of CUDA distributive, where it is called \"Nsight Compute\". To install it onto an already installed CUDA run CUDA installation once again and check the corresponding checkbox.\nMake sure that CUDA with Nsight Compute is installed after Visual Studio.\n\nCurrently, VS 2017 / 2019, and Ninja are supported as the generator of CMake. If `ninja.exe` is detected in `PATH`, then Ninja will be used as the default generator, otherwise, it will use VS 2017 / 2019.\n<br/> If Ninja is selected as the generator, the latest MSVC will get selected as the underlying toolchain.\n\nAdditional libraries such as\n[Magma](https://developer.nvidia.com/magma), [oneDNN, a.k.a MKLDNN or DNNL](https://github.com/oneapi-src/oneDNN), and [Sccache](https://github.com/mozilla/sccache) are often needed. Please refer to the [installation-helper](https://github.com/pytorch/pytorch/tree/master/.jenkins/pytorch/win-test-helpers/installation-helpers) to install them.\n\nYou can refer to the [build_pytorch.bat](https://github.com/pytorch/pytorch/blob/master/.jenkins/pytorch/win-test-helpers/build_pytorch.bat) script for some other environment variables configurations\n\n\n```cmd\ncmd\n\n:: Set the environment variables after you have downloaded and unzipped the mkl package,\n:: else CMake would throw an error as `Could NOT find OpenMP`.\nset CMAKE_INCLUDE_PATH={Your directory}\\mkl\\include\nset LIB={Your directory}\\mkl\\lib;%LIB%\n\n:: Read the content in the previous section carefully before you proceed.\n:: [Optional] If you want to override the underlying toolset used by Ninja and Visual Studio with CUDA, please run the following script block.\n:: \"Visual Studio 2019 Developer Command Prompt\" will be run automatically.\n:: Make sure you have CMake >= 3.12 before you do this when you use the Visual Studio generator.\nset CMAKE_GENERATOR_TOOLSET_VERSION=14.27\nset DISTUTILS_USE_SDK=1\nfor /f \"usebackq tokens=*\" %i in (`\"%ProgramFiles(x86)%\\Microsoft Visual Studio\\Installer\\vswhere.exe\" -version [15^,17^) -products * -latest -property installationPath`) do call \"%i\\VC\\Auxiliary\\Build\\vcvarsall.bat\" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%\n\n:: [Optional] If you want to override the CUDA host compiler\nset CUDAHOSTCXX=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.27.29110\\bin\\HostX64\\x64\\cl.exe\n\npython setup.py develop\n\n```\n\n##### Adjust Build Options (Optional)\n\nYou can adjust the configuration of cmake variables optionally (without building first), by doing\nthe following. For example, adjusting the pre-detected directories for CuDNN or BLAS can be done\nwith such a step.\n\nOn Linux\n```bash\nexport CMAKE_PREFIX_PATH=${CONDA_PREFIX:-\"$(dirname $(which conda))/../\"}\npython setup.py build --cmake-only\nccmake build  # or cmake-gui build\n```\n\nOn macOS\n```bash\nexport CMAKE_PREFIX_PATH=${CONDA_PREFIX:-\"$(dirname $(which conda))/../\"}\nMACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only\nccmake build  # or cmake-gui build\n```\n\n### Docker Image\n\n#### Using pre-built images\n\nYou can also pull a pre-built docker image from Docker Hub and run with docker v19.03+\n\n```bash\ndocker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest\n```\n\nPlease note that PyTorch uses shared memory to share data between processes, so if torch multiprocessing is used (e.g.\nfor multithreaded data loaders) the default shared memory segment size that container runs with is not enough, and you\nshould increase shared memory size either with `--ipc=host` or `--shm-size` command line options to `nvidia-docker run`.\n\n#### Building the image yourself\n\n**NOTE:** Must be built with a docker version > 18.06\n\nThe `Dockerfile` is supplied to build images with CUDA 11.1 support and cuDNN v8.\nYou can pass `PYTHON_VERSION=x.y` make variable to specify which Python version is to be used by Miniconda, or leave it\nunset to use the default.\n```bash\nmake -f docker.Makefile\n# images are tagged as docker.io/${your_docker_username}/pytorch\n```\n\n### Building the Documentation\n\nTo build documentation in various formats, you will need [Sphinx](http://www.sphinx-doc.org) and the\nreadthedocs theme.\n\n```bash\ncd docs/\npip install -r requirements.txt\n```\nYou can then build the documentation by running `make <format>` from the\n`docs/` folder. Run `make` to get a list of all available output formats.\n\nIf you get a katex error run `npm install katex`.  If it persists, try\n`npm install -g katex`\n\n> Note: if you installed `nodejs` with a different package manager (e.g.,\n`conda`) then `npm` will probably install a version of `katex` that is not\ncompatible with your version of `nodejs` and doc builds will fail.\nA combination of versions that is known to work is `node@6.13.1` and\n`katex@0.13.18`. To install the latter with `npm` you can run\n```npm install -g katex@0.13.18```\n\n### Previous Versions\n\nInstallation instructions and binaries for previous PyTorch versions may be found\non [our website](https://pytorch.org/previous-versions).\n\n\n## Getting Started\n\nThree-pointers to get you started:\n- [Tutorials: get you started with understanding and using PyTorch](https://pytorch.org/tutorials/)\n- [Examples: easy to understand PyTorch code across all domains](https://github.com/pytorch/examples)\n- [The API Reference](https://pytorch.org/docs/)\n- [Glossary](https://github.com/pytorch/pytorch/blob/master/GLOSSARY.md)\n\n## Resources\n\n* [PyTorch.org](https://pytorch.org/)\n* [PyTorch Tutorials](https://pytorch.org/tutorials/)\n* [PyTorch Examples](https://github.com/pytorch/examples)\n* [PyTorch Models](https://pytorch.org/hub/)\n* [Intro to Deep Learning with PyTorch from Udacity](https://www.udacity.com/course/deep-learning-pytorch--ud188)\n* [Intro to Machine Learning with PyTorch from Udacity](https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229)\n* [Deep Neural Networks with PyTorch from Coursera](https://www.coursera.org/learn/deep-neural-networks-with-pytorch)\n* [PyTorch Twitter](https://twitter.com/PyTorch)\n* [PyTorch Blog](https://pytorch.org/blog/)\n* [PyTorch YouTube](https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw)\n\n## Communication\n* Forums: Discuss implementations, research, etc. https://discuss.pytorch.org\n* GitHub Issues: Bug reports, feature requests, install issues, RFCs, thoughts, etc.\n* Slack: The [PyTorch Slack](https://pytorch.slack.com/) hosts a primary audience of moderate to experienced PyTorch users and developers for general chat, online discussions, collaboration, etc. If you are a beginner looking for help, the primary medium is [PyTorch Forums](https://discuss.pytorch.org). If you need a slack invite, please fill this form: https://goo.gl/forms/PP1AGvNHpSaJP8to1\n* Newsletter: No-noise, a one-way email newsletter with important announcements about PyTorch. You can sign-up here: https://eepurl.com/cbG0rv\n* Facebook Page: Important announcements about PyTorch. https://www.facebook.com/pytorch\n* For brand guidelines, please visit our website at [pytorch.org](https://pytorch.org/)\n\n## Releases and Contributing\n\nPyTorch has a 90-day release cycle (major releases). Please let us know if you encounter a bug by [filing an issue](https://github.com/pytorch/pytorch/issues).\n\nWe appreciate all contributions. If you are planning to contribute back bug-fixes, please do so without any further discussion.\n\nIf you plan to contribute new features, utility functions, or extensions to the core, please first open an issue and discuss the feature with us.\nSending a PR without discussion might end up resulting in a rejected PR because we might be taking the core in a different direction than you might be aware of.\n\nTo learn more about making a contribution to Pytorch, please see our [Contribution page](CONTRIBUTING.md).\n\n## The Team\n\nPyTorch is a community-driven project with several skillful engineers and researchers contributing to it.\n\nPyTorch is currently maintained by [Adam Paszke](https://apaszke.github.io/), [Sam Gross](https://github.com/colesbury), [Soumith Chintala](http://soumith.ch) and [Gregory Chanan](https://github.com/gchanan) with major contributions coming from hundreds of talented individuals in various forms and means.\nA non-exhaustive but growing list needs to mention: Trevor Killeen, Sasank Chilamkurthy, Sergey Zagoruyko, Adam Lerer, Francisco Massa, Alykhan Tejani, Luca Antiga, Alban Desmaison, Andreas Koepf, James Bradbury, Zeming Lin, Yuandong Tian, Guillaume Lample, Marat Dukhan, Natalia Gimelshein, Christian Sarofeen, Martin Raison, Edward Yang, Zachary Devito.\n\nNote: This project is unrelated to [hughperkins/pytorch](https://github.com/hughperkins/pytorch) with the same name. Hugh is a valuable contributor to the Torch community and has helped with many things Torch and PyTorch.\n\n## License\n\nPyTorch has a BSD-style license, as found in the [LICENSE](LICENSE) file.\n",
	"hacktoberfest lstm machine-learning ocr ocr-engine tesseract tesseract-ocr": "# Tesseract OCR\n\n[![Build status](https://ci.appveyor.com/api/projects/status/miah0ikfsf0j3819/branch/master?svg=true)](https://ci.appveyor.com/project/zdenop/tesseract/)\n[![Build status](https://github.com/tesseract-ocr/tesseract/workflows/sw/badge.svg)](https://github.com/tesseract-ocr/tesseract/actions/workflows/sw.yml)\\\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/tesseract-ocr/badge.svg)](https://scan.coverity.com/projects/tesseract-ocr)\n[![CodeQL](https://github.com/tesseract-ocr/tesseract/workflows/CodeQL/badge.svg)](https://github.com/tesseract-ocr/tesseract/security/code-scanning)\n[![OSS-Fuzz](https://img.shields.io/badge/oss--fuzz-fuzzing-brightgreen)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=2&q=proj:tesseract-ocr)\n\\\n[![GitHub license](https://img.shields.io/badge/license-Apache--2.0-blue.svg)](https://raw.githubusercontent.com/tesseract-ocr/tesseract/main/LICENSE)\n[![Downloads](https://img.shields.io/badge/download-all%20releases-brightgreen.svg)](https://github.com/tesseract-ocr/tesseract/releases/)\n\n## Table of Contents\n\n* [Tesseract OCR](#tesseract-ocr)\n  * [About](#about)\n  * [Brief history](#brief-history)\n  * [Installing Tesseract](#installing-tesseract)\n  * [Running Tesseract](#running-tesseract)\n  * [For developers](#for-developers)\n  * [Support](#support)\n  * [License](#license)\n  * [Dependencies](#dependencies)\n  * [Latest Version of README](#latest-version-of-readme)\n\n## About\n\nThis package contains an **OCR engine** - `libtesseract` and a **command line program** - `tesseract`.\n\nTesseract 4 adds a new neural net (LSTM) based OCR engine which is focused on line recognition, but also still supports the legacy Tesseract OCR engine of Tesseract 3 which works by recognizing character patterns. Compatibility with Tesseract 3 is enabled by using the Legacy OCR Engine mode (--oem 0).\nIt also needs [traineddata](https://tesseract-ocr.github.io/tessdoc/Data-Files.html) files which support the legacy engine, for example those from the [tessdata](https://github.com/tesseract-ocr/tessdata) repository.\n\nThe lead developer is Ray Smith. The maintainer is Zdenko Podobny. For a list of contributors see [AUTHORS](https://github.com/tesseract-ocr/tesseract/blob/main/AUTHORS)\nand GitHub's log of [contributors](https://github.com/tesseract-ocr/tesseract/graphs/contributors).\n\nTesseract has **unicode (UTF-8) support**, and can **recognize more than 100 languages** \"out of the box\".\n\nTesseract supports **[various image formats](https://tesseract-ocr.github.io/tessdoc/InputFormats)** including PNG, JPEG and TIFF.\n\nTesseract supports **various output formats**: plain text, hOCR (HTML), PDF, invisible-text-only PDF, TSV and ALTO (the last one - since version 4.1.0).\n\nYou should note that in many cases, in order to get better OCR results, you'll need to **[improve the quality](https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html) of the image** you are giving Tesseract.\n\nThis project **does not include a GUI application**. If you need one, please see the [3rdParty](https://tesseract-ocr.github.io/tessdoc/User-Projects-%E2%80%93-3rdParty.html) documentation.\n\nTesseract **can be trained to recognize other languages**.\nSee [Tesseract Training](https://tesseract-ocr.github.io/tessdoc/Training-Tesseract.html) for more information.\n\n## Brief history\n\nTesseract was originally developed at Hewlett-Packard Laboratories Bristol UK and at Hewlett-Packard Co, Greeley Colorado USA between 1985 and 1994, with some more changes made in 1996 to port to Windows, and some C++izing in 1998. In 2005 Tesseract was open sourced by HP. From 2006 until November 2018 it was developed by Google.\n\nMajor version 5 is the current stable version and started with release\n[5.0.0](https://github.com/tesseract-ocr/tesseract/releases/tag/5.0.0) on November 30, 2021. Newer minor versions and bugfix versions are available from\n[GitHub](https://github.com/tesseract-ocr/tesseract/releases/).\n\nLatest source code is available from [main branch on GitHub](https://github.com/tesseract-ocr/tesseract/tree/main).\nOpen issues can be found in [issue tracker](https://github.com/tesseract-ocr/tesseract/issues),\nand [planning documentation](https://tesseract-ocr.github.io/tessdoc/Planning.html).\n\nSee **[Release Notes](https://tesseract-ocr.github.io/tessdoc/ReleaseNotes.html)**\nand **[Change Log](https://github.com/tesseract-ocr/tesseract/blob/main/ChangeLog)** for more details of the releases.\n\n## Installing Tesseract\n\nYou can either [Install Tesseract via pre-built binary package](https://tesseract-ocr.github.io/tessdoc/Installation.html)\nor [build it from source](https://tesseract-ocr.github.io/tessdoc/Compiling.html).\n\nA C++ compiler with good C++17 support is required for building Tesseract from source.\n\n## Running Tesseract\n\nBasic **[command line usage](https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html)**:\n\n    tesseract imagename outputbase [-l lang] [--oem ocrenginemode] [--psm pagesegmode] [configfiles...]\n\nFor more information about the various command line options use `tesseract --help` or `man tesseract`.\n\nExamples can be found in the [documentation](https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html#simplest-invocation-to-ocr-an-image).\n\n## For developers\n\nDevelopers can use `libtesseract` [C](https://github.com/tesseract-ocr/tesseract/blob/main/include/tesseract/capi.h) or\n[C++](https://github.com/tesseract-ocr/tesseract/blob/main/include/tesseract/baseapi.h) API to build their own application. If you need bindings to `libtesseract` for other programming languages, please see the\n[wrapper](https://tesseract-ocr.github.io/tessdoc/AddOns.html#tesseract-wrappers) section in the AddOns documentation.\n\nDocumentation of Tesseract generated from source code by doxygen can be found on [tesseract-ocr.github.io](https://tesseract-ocr.github.io/).\n\n## Support\n\nBefore you submit an issue, please review **[the guidelines for this repository](https://github.com/tesseract-ocr/tesseract/blob/main/CONTRIBUTING.md)**.\n\nFor support, first read the [documentation](https://tesseract-ocr.github.io/tessdoc/),\nparticularly the [FAQ](https://tesseract-ocr.github.io/tessdoc/FAQ.html) to see if your problem is addressed there.\nIf not, search the [Tesseract user forum](https://groups.google.com/g/tesseract-ocr), the [Tesseract developer forum](https://groups.google.com/g/tesseract-dev) and [past issues](https://github.com/tesseract-ocr/tesseract/issues), and if you still can't find what you need, ask for support in the mailing-lists.\n\nMailing-lists:\n\n* [tesseract-ocr](https://groups.google.com/g/tesseract-ocr) - For tesseract users.\n* [tesseract-dev](https://groups.google.com/g/tesseract-dev) - For tesseract developers.\n\nPlease report an issue only for a **bug**, not for asking questions.\n\n## License\n\n    The code in this repository is licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n\n**NOTE**: This software depends on other packages that may be licensed under different open source licenses.\n\nTesseract uses [Leptonica library](http://leptonica.com/) which essentially\nuses a [BSD 2-clause license](http://leptonica.com/about-the-license.html).\n\n## Dependencies\n\nTesseract uses [Leptonica library](https://github.com/DanBloomberg/leptonica)\nfor opening input images (e.g. not documents like pdf).\nIt is suggested to use leptonica with built-in support for [zlib](https://zlib.net),\n[png](https://sourceforge.net/projects/libpng) and\n[tiff](http://www.simplesystems.org/libtiff) (for multipage tiff).\n\n## Latest Version of README\n\nFor the latest online version of the README.md see:\n\n<https://github.com/tesseract-ocr/tesseract/blob/main/README.md>\n",
	"face-detection face-recognition machine-learning python": "# Face Recognition\n\n_You can also read a translated version of this file [in Chinese \u7b80\u4f53\u4e2d\u6587\u7248](https://github.com/ageitgey/face_recognition/blob/master/README_Simplified_Chinese.md) or [in Korean \ud55c\uad6d\uc5b4](https://github.com/ageitgey/face_recognition/blob/master/README_Korean.md) or [in Japanese \u65e5\u672c\u8a9e](https://github.com/m-i-k-i/face_recognition/blob/master/README_Japanese.md)._\n\nRecognize and manipulate faces from Python or from the command line with\nthe world's simplest face recognition library.\n\nBuilt using [dlib](http://dlib.net/)'s state-of-the-art face recognition\nbuilt with deep learning. The model has an accuracy of 99.38% on the\n[Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/) benchmark.\n\nThis also provides a simple `face_recognition` command line tool that lets\nyou do face recognition on a folder of images from the command line!\n\n\n[![PyPI](https://img.shields.io/pypi/v/face_recognition.svg)](https://pypi.python.org/pypi/face_recognition)\n[![Build Status](https://github.com/ageitgey/face_recognition/workflows/CI/badge.svg?branch=master&event=push)](https://github.com/ageitgey/face_recognition/actions?query=workflow%3ACI)\n[![Documentation Status](https://readthedocs.org/projects/face-recognition/badge/?version=latest)](http://face-recognition.readthedocs.io/en/latest/?badge=latest)\n\n## Features\n\n#### Find faces in pictures\n\nFind all the faces that appear in a picture:\n\n![](https://cloud.githubusercontent.com/assets/896692/23625227/42c65360-025d-11e7-94ea-b12f28cb34b4.png)\n\n```python\nimport face_recognition\nimage = face_recognition.load_image_file(\"your_file.jpg\")\nface_locations = face_recognition.face_locations(image)\n```\n\n#### Find and manipulate facial features in pictures\n\nGet the locations and outlines of each person's eyes, nose, mouth and chin.\n\n![](https://cloud.githubusercontent.com/assets/896692/23625282/7f2d79dc-025d-11e7-8728-d8924596f8fa.png)\n\n```python\nimport face_recognition\nimage = face_recognition.load_image_file(\"your_file.jpg\")\nface_landmarks_list = face_recognition.face_landmarks(image)\n```\n\nFinding facial features is super useful for lots of important stuff. But you can also use it for really stupid stuff\nlike applying [digital make-up](https://github.com/ageitgey/face_recognition/blob/master/examples/digital_makeup.py) (think 'Meitu'):\n\n![](https://cloud.githubusercontent.com/assets/896692/23625283/80638760-025d-11e7-80a2-1d2779f7ccab.png)\n\n#### Identify faces in pictures\n\nRecognize who appears in each photo.\n\n![](https://cloud.githubusercontent.com/assets/896692/23625229/45e049b6-025d-11e7-89cc-8a71cf89e713.png)\n\n```python\nimport face_recognition\nknown_image = face_recognition.load_image_file(\"biden.jpg\")\nunknown_image = face_recognition.load_image_file(\"unknown.jpg\")\n\nbiden_encoding = face_recognition.face_encodings(known_image)[0]\nunknown_encoding = face_recognition.face_encodings(unknown_image)[0]\n\nresults = face_recognition.compare_faces([biden_encoding], unknown_encoding)\n```\n\nYou can even use this library with other Python libraries to do real-time face recognition:\n\n![](https://cloud.githubusercontent.com/assets/896692/24430398/36f0e3f0-13cb-11e7-8258-4d0c9ce1e419.gif)\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py) for the code.\n\n## Online Demos\n\nUser-contributed shared Jupyter notebook demo (not officially supported): [![Deepnote](https://beta.deepnote.org/buttons/try-in-a-jupyter-notebook.svg)](https://beta.deepnote.org/launch?template=face_recognition)\n\n## Installation\n\n### Requirements\n\n  * Python 3.3+ or Python 2.7\n  * macOS or Linux (Windows not officially supported, but might work)\n\n### Installation Options:\n\n#### Installing on Mac or Linux\n\nFirst, make sure you have dlib already installed with Python bindings:\n\n  * [How to install dlib from source on macOS or Ubuntu](https://gist.github.com/ageitgey/629d75c1baac34dfa5ca2a1928a7aeaf)\n  \nThen, make sure you have cmake installed:  \n \n```brew install cmake```\n\nFinally, install this module from pypi using `pip3` (or `pip2` for Python 2):\n\n```bash\npip3 install face_recognition\n```\n\nAlternatively, you can try this library with [Docker](https://www.docker.com/), see [this section](#deployment).\n\nIf you are having trouble with installation, you can also try out a\n[pre-configured VM](https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b).\n\n#### Installing on an Nvidia Jetson Nano board\n\n * [Jetson Nano installation instructions](https://medium.com/@ageitgey/build-a-hardware-based-face-recognition-system-for-150-with-the-nvidia-jetson-nano-and-python-a25cb8c891fd)\n   * Please follow the instructions in the article carefully. There is current a bug in the CUDA libraries on the Jetson Nano that will cause this library to fail silently if you don't follow the instructions in the article to comment out a line in dlib and recompile it.\n\n#### Installing on Raspberry Pi 2+\n\n  * [Raspberry Pi 2+ installation instructions](https://gist.github.com/ageitgey/1ac8dbe8572f3f533df6269dab35df65)\n\n#### Installing on FreeBSD\n\n```bash\npkg install graphics/py-face_recognition\n```\n\n#### Installing on Windows\n\nWhile Windows isn't officially supported, helpful users have posted instructions on how to install this library:\n\n  * [@masoudr's Windows 10 installation guide (dlib + face_recognition)](https://github.com/ageitgey/face_recognition/issues/175#issue-257710508)\n\n#### Installing a pre-configured Virtual Machine image\n\n  * [Download the pre-configured VM image](https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b) (for VMware Player or VirtualBox).\n\n## Usage\n\n### Command-Line Interface\n\nWhen you install `face_recognition`, you get two simple command-line \nprograms:\n\n* `face_recognition` - Recognize faces in a photograph or folder full for \n   photographs.\n* `face_detection` - Find faces in a photograph or folder full for photographs.\n\n#### `face_recognition` command line tool\n\nThe `face_recognition` command lets you recognize faces in a photograph or \nfolder full  for photographs.\n\nFirst, you need to provide a folder with one picture of each person you\nalready know. There should be one image file for each person with the\nfiles named according to who is in the picture:\n\n![known](https://cloud.githubusercontent.com/assets/896692/23582466/8324810e-00df-11e7-82cf-41515eba704d.png)\n\nNext, you need a second folder with the files you want to identify:\n\n![unknown](https://cloud.githubusercontent.com/assets/896692/23582465/81f422f8-00df-11e7-8b0d-75364f641f58.png)\n\nThen in you simply run the command `face_recognition`, passing in\nthe folder of known people and the folder (or single image) with unknown\npeople and it tells you who is in each image:\n\n```bash\n$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/\n\n/unknown_pictures/unknown.jpg,Barack Obama\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person\n```\n\nThere's one line in the output for each face. The data is comma-separated\nwith the filename and the name of the person found.\n\nAn `unknown_person` is a face in the image that didn't match anyone in\nyour folder of known people.\n\n#### `face_detection` command line tool\n\nThe `face_detection` command lets you find the location (pixel coordinatates) \nof any faces in an image.\n\nJust run the command `face_detection`, passing in a folder of images \nto check (or a single image):\n\n```bash\n$ face_detection  ./folder_with_pictures/\n\nexamples/image1.jpg,65,215,169,112\nexamples/image2.jpg,62,394,211,244\nexamples/image2.jpg,95,941,244,792\n```\n\nIt prints one line for each face that was detected. The coordinates\nreported are the top, right, bottom and left coordinates of the face (in pixels).\n \n##### Adjusting Tolerance / Sensitivity\n\nIf you are getting multiple matches for the same person, it might be that\nthe people in your photos look very similar and a lower tolerance value\nis needed to make face comparisons more strict.\n\nYou can do that with the `--tolerance` parameter. The default tolerance\nvalue is 0.6 and lower numbers make face comparisons more strict:\n\n```bash\n$ face_recognition --tolerance 0.54 ./pictures_of_people_i_know/ ./unknown_pictures/\n\n/unknown_pictures/unknown.jpg,Barack Obama\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person\n```\n\nIf you want to see the face distance calculated for each match in order\nto adjust the tolerance setting, you can use `--show-distance true`:\n\n```bash\n$ face_recognition --show-distance true ./pictures_of_people_i_know/ ./unknown_pictures/\n\n/unknown_pictures/unknown.jpg,Barack Obama,0.378542298956785\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person,None\n```\n\n##### More Examples\n\nIf you simply want to know the names of the people in each photograph but don't\ncare about file names, you could do this:\n\n```bash\n$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/ | cut -d ',' -f2\n\nBarack Obama\nunknown_person\n```\n\n##### Speeding up Face Recognition\n\nFace recognition can be done in parallel if you have a computer with\nmultiple CPU cores. For example, if your system has 4 CPU cores, you can\nprocess about 4 times as many images in the same amount of time by using\nall your CPU cores in parallel.\n\nIf you are using Python 3.4 or newer, pass in a `--cpus <number_of_cpu_cores_to_use>` parameter:\n\n```bash\n$ face_recognition --cpus 4 ./pictures_of_people_i_know/ ./unknown_pictures/\n```\n\nYou can also pass in `--cpus -1` to use all CPU cores in your system.\n\n#### Python Module\n\nYou can import the `face_recognition` module and then easily manipulate\nfaces with just a couple of lines of code. It's super easy!\n\nAPI Docs: [https://face-recognition.readthedocs.io](https://face-recognition.readthedocs.io/en/latest/face_recognition.html).\n\n##### Automatically find all the faces in an image\n\n```python\nimport face_recognition\n\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_locations = face_recognition.face_locations(image)\n\n# face_locations is now an array listing the co-ordinates of each face!\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture.py)\n to try it out.\n\nYou can also opt-in to a somewhat more accurate deep-learning-based face detection model.\n\nNote: GPU acceleration (via NVidia's CUDA library) is required for good\nperformance with this model. You'll also want to enable CUDA support\nwhen compliling `dlib`.\n\n```python\nimport face_recognition\n\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_locations = face_recognition.face_locations(image, model=\"cnn\")\n\n# face_locations is now an array listing the co-ordinates of each face!\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture_cnn.py)\n to try it out.\n\nIf you have a lot of images and a GPU, you can also\n[find faces in batches](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_batches.py).\n\n##### Automatically locate the facial features of a person in an image\n\n```python\nimport face_recognition\n\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_landmarks_list = face_recognition.face_landmarks(image)\n\n# face_landmarks_list is now an array with the locations of each facial feature in each face.\n# face_landmarks_list[0]['left_eye'] would be the location and outline of the first person's left eye.\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/find_facial_features_in_picture.py)\n to try it out.\n\n##### Recognize faces in images and identify who they are\n\n```python\nimport face_recognition\n\npicture_of_me = face_recognition.load_image_file(\"me.jpg\")\nmy_face_encoding = face_recognition.face_encodings(picture_of_me)[0]\n\n# my_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!\n\nunknown_picture = face_recognition.load_image_file(\"unknown.jpg\")\nunknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]\n\n# Now we can see the two face encodings are of the same person with `compare_faces`!\n\nresults = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)\n\nif results[0] == True:\n    print(\"It's a picture of me!\")\nelse:\n    print(\"It's not a picture of me!\")\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/recognize_faces_in_pictures.py)\n to try it out.\n\n## Python Code Examples\n\nAll the examples are available [here](https://github.com/ageitgey/face_recognition/tree/master/examples).\n\n\n#### Face Detection\n\n* [Find faces in a photograph](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture.py)\n* [Find faces in a photograph (using deep learning)](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture_cnn.py)\n* [Find faces in batches of images w/ GPU (using deep learning)](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_batches.py)\n* [Blur all the faces in a live video using your webcam (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/blur_faces_on_webcam.py)\n\n#### Facial Features\n\n* [Identify specific facial features in a photograph](https://github.com/ageitgey/face_recognition/blob/master/examples/find_facial_features_in_picture.py)\n* [Apply (horribly ugly) digital make-up](https://github.com/ageitgey/face_recognition/blob/master/examples/digital_makeup.py)\n\n#### Facial Recognition\n\n* [Find and recognize unknown faces in a photograph based on photographs of known people](https://github.com/ageitgey/face_recognition/blob/master/examples/recognize_faces_in_pictures.py)\n* [Identify and draw boxes around each person in a photo](https://github.com/ageitgey/face_recognition/blob/master/examples/identify_and_draw_boxes_on_faces.py)\n* [Compare faces by numeric face distance instead of only True/False matches](https://github.com/ageitgey/face_recognition/blob/master/examples/face_distance.py)\n* [Recognize faces in live video using your webcam - Simple / Slower Version (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam.py)\n* [Recognize faces in live video using your webcam - Faster Version (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py)\n* [Recognize faces in a video file and write out new video file (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_video_file.py)\n* [Recognize faces on a Raspberry Pi w/ camera](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_on_raspberry_pi.py)\n* [Run a web service to recognize faces via HTTP (Requires Flask to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/web_service_example.py)\n* [Recognize faces with a K-nearest neighbors classifier](https://github.com/ageitgey/face_recognition/blob/master/examples/face_recognition_knn.py)\n* [Train multiple images per person then recognize faces using a SVM](https://github.com/ageitgey/face_recognition/blob/master/examples/face_recognition_svm.py)\n\n## Creating a Standalone Executable\nIf you want to create a standalone executable that can run without the need to install `python` or `face_recognition`, you can use [PyInstaller](https://github.com/pyinstaller/pyinstaller). However, it requires some custom configuration to work with this library. See [this issue](https://github.com/ageitgey/face_recognition/issues/357) for how to do it.\n\n## Articles and Guides that cover `face_recognition`\n\n- My article on how Face Recognition works: [Modern Face Recognition with Deep Learning](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78)\n  - Covers the algorithms and how they generally work\n- [Face recognition with OpenCV, Python, and deep learning](https://www.pyimagesearch.com/2018/06/18/face-recognition-with-opencv-python-and-deep-learning/) by Adrian Rosebrock\n  - Covers how to use face recognition in practice\n- [Raspberry Pi Face Recognition](https://www.pyimagesearch.com/2018/06/25/raspberry-pi-face-recognition/) by Adrian Rosebrock\n  - Covers how to use this on a Raspberry Pi\n- [Face clustering with Python](https://www.pyimagesearch.com/2018/07/09/face-clustering-with-python/) by Adrian Rosebrock\n  - Covers how to automatically cluster photos based on who appears in each photo using unsupervised learning\n\n## How Face Recognition Works\n\nIf you want to learn how face location and recognition work instead of\ndepending on a black box library, [read my article](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78).\n\n## Caveats\n\n* The face recognition model is trained on adults and does not work very well on children. It tends to mix\n  up children quite easy using the default comparison threshold of 0.6.\n* Accuracy may vary between ethnic groups. Please see [this wiki page](https://github.com/ageitgey/face_recognition/wiki/Face-Recognition-Accuracy-Problems#question-face-recognition-works-well-with-european-individuals-but-overall-accuracy-is-lower-with-asian-individuals) for more details.\n\n## <a name=\"deployment\">Deployment to Cloud Hosts (Heroku, AWS, etc)</a>\n\nSince `face_recognition` depends on `dlib` which is written in C++, it can be tricky to deploy an app\nusing it to a cloud hosting provider like Heroku or AWS.\n\nTo make things easier, there's an example Dockerfile in this repo that shows how to run an app built with\n`face_recognition` in a [Docker](https://www.docker.com/) container. With that, you should be able to deploy\nto any service that supports Docker images.\n\nYou can try the Docker image locally by running: `docker-compose up --build`\n\nThere are also [several prebuilt Docker images.](docker/README.md)\n\nLinux users with a GPU (drivers >= 384.81) and [Nvidia-Docker](https://github.com/NVIDIA/nvidia-docker) installed can run the example on the GPU: Open the [docker-compose.yml](docker-compose.yml) file and uncomment the `dockerfile: Dockerfile.gpu` and `runtime: nvidia` lines.\n\n## Having problems?\n\nIf you run into problems, please read the [Common Errors](https://github.com/ageitgey/face_recognition/wiki/Common-Errors) section of the wiki before filing a github issue.\n\n## Thanks\n\n* Many, many thanks to [Davis King](https://github.com/davisking) ([@nulhom](https://twitter.com/nulhom))\n  for creating dlib and for providing the trained facial feature detection and face encoding models\n  used in this library. For more information on the ResNet that powers the face encodings, check out\n  his [blog post](http://blog.dlib.net/2017/02/high-quality-face-recognition-with-deep.html).\n* Thanks to everyone who works on all the awesome Python data science libraries like numpy, scipy, scikit-image,\n  pillow, etc, etc that makes this kind of stuff so easy and fun in Python.\n* Thanks to [Cookiecutter](https://github.com/audreyr/cookiecutter) and the\n  [audreyr/cookiecutter-pypackage](https://github.com/audreyr/cookiecutter-pypackage) project template\n  for making Python project packaging way more tolerable.\n",
	"deep-face-swap deep-learning deep-neural-networks deepface deepfakes deeplearning face-swap faceswap fakeapp machine-learning myfakeapp neural-nets neural-networks openfaceswap": "# deepfakes_faceswap\n<p align=\"center\">\n  <a href=\"https://faceswap.dev\"><img src=\"https://i.imgur.com/zHvjHnb.png\"></img></a>\n<br />FaceSwap is a tool that utilizes deep learning to recognize and swap faces in pictures and videos.\n</p>\n<p align=\"center\">\n<img src = \"https://i.imgur.com/nWHFLDf.jpg\"></img>\n</p>\n\n<p align=\"center\">\n<a href=\"https://www.patreon.com/bePatron?u=23238350\"><img src=\"https://c5.patreon.com/external/logo/become_a_patron_button.png\"></img></a>\n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"https://discord.gg/FC54sYg\"><img src=\"https://i.imgur.com/gIpztkv.png\"></img></a></p>\n\n<p align=\"center\">\n  <a href=\"https://www.dailymotion.com/video/x810mot\"><img src=\"https://user-images.githubusercontent.com/36920800/178301720-b69841bb-a1ca-4c20-91db-a2a10f5692ca.png\"></img></a>\n<br />Emma Stone/Scarlett Johansson FaceSwap using the Phaze-A model\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.youtube.com/watch?v=r1jng79a5xc\"><img src=\"https://img.youtube.com/vi/r1jng79a5xc/0.jpg\"></img></a>\n<br />Jennifer Lawrence/Steve Buscemi FaceSwap using the Villain model\n</p>\n\n![Build Status](https://github.com/deepfakes/faceswap/actions/workflows/pytest.yml/badge.svg) [![Documentation Status](https://readthedocs.org/projects/faceswap/badge/?version=latest)](https://faceswap.readthedocs.io/en/latest/?badge=latest)\n\nMake sure you check out [INSTALL.md](INSTALL.md) before getting started.\n\n- [deepfakes_faceswap](#deepfakes_faceswap)\n- [Manifesto](#manifesto)\n  - [FaceSwap has ethical uses.](#faceswap-has-ethical-uses)\n- [How To setup and run the project](#how-to-setup-and-run-the-project)\n- [Overview](#overview)\n  - [Extract](#extract)\n  - [Train](#train)\n  - [Convert](#convert)\n  - [GUI](#gui)\n- [General notes:](#general-notes)\n- [Help I need support!](#help-i-need-support)\n  - [Discord Server](#discord-server)\n  - [FaceSwap Forum](#faceswap-forum)\n- [Donate](#donate)\n  - [Patreon](#patreon)\n  - [One time Donations](#one-time-donations)\n    - [@torzdf](#torzdf)\n    - [@andenixa](#andenixa)\n- [How to contribute](#how-to-contribute)\n  - [For people interested in the generative models](#for-people-interested-in-the-generative-models)\n  - [For devs](#for-devs)\n  - [For non-dev advanced users](#for-non-dev-advanced-users)\n  - [For end-users](#for-end-users)\n  - [For haters](#for-haters)\n- [About github.com/deepfakes](#about-githubcomdeepfakes)\n  - [What is this repo?](#what-is-this-repo)\n  - [Why this repo?](#why-this-repo)\n  - [Why is it named 'deepfakes' if it is not /u/deepfakes?](#why-is-it-named-deepfakes-if-it-is-not-udeepfakes)\n  - [What if /u/deepfakes feels bad about that?](#what-if-udeepfakes-feels-bad-about-that)\n- [About machine learning](#about-machine-learning)\n  - [How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?](#how-does-a-computer-know-how-to-recognizeshape-faces-how-does-machine-learning-work-what-is-a-neural-network)\n\n# Manifesto\n\n## FaceSwap has ethical uses.\n\nWhen faceswapping was first developed and published, the technology was groundbreaking, it was a huge step in AI development. It was also completely ignored outside of academia because the code was confusing and fragmentary. It required a thorough understanding of complicated AI techniques and took a lot of effort to figure it out. Until one individual brought it together into a single, cohesive collection. It ran, it worked, and as is so often the way with new technology emerging on the internet, it was immediately used to create inappropriate content. Despite the inappropriate uses the software was given originally, it was the first AI code that anyone could download, run and learn by experimentation without having a Ph.D. in math, computer theory, psychology, and more. Before \"deepfakes\" these techniques were like black magic, only practiced by those who could understand all of the inner workings as described in esoteric and endlessly complicated books and papers.\n\n\"Deepfakes\" changed all that and anyone could participate in AI development. To us, developers, the release of this code opened up a fantastic learning opportunity. It allowed us to build on ideas developed by others, collaborate with a variety of skilled coders, experiment with AI whilst learning new skills and ultimately contribute towards an emerging technology which will only see more mainstream use as it progresses.\n\nAre there some out there doing horrible things with similar software? Yes. And because of this, the developers have been following strict ethical standards. Many of us don't even use it to create videos, we just tinker with the code to see what it does. Sadly, the media concentrates only on the unethical uses of this software. That is, unfortunately, the nature of how it was first exposed to the public, but it is not representative of why it was created, how we use it now, or what we see in its future. Like any technology, it can be used for good or it can be abused. It is our intention to develop FaceSwap in a way that its potential for abuse is minimized whilst maximizing its potential as a tool for learning, experimenting and, yes, for legitimate faceswapping.\n\nWe are not trying to denigrate celebrities or to demean anyone. We are programmers, we are engineers, we are Hollywood VFX artists, we are activists, we are hobbyists, we are human beings. To this end, we feel that it's time to come out with a standard statement of what this software is and isn't as far as us developers are concerned.\n\n- FaceSwap is not for creating inappropriate content.\n- FaceSwap is not for changing faces without consent or with the intent of hiding its use.\n- FaceSwap is not for any illicit, unethical, or questionable purposes.\n- FaceSwap exists to experiment and discover AI techniques, for social or political commentary, for movies, and for any number of ethical and reasonable uses.\n\nWe are very troubled by the fact that FaceSwap can be used for unethical and disreputable things. However, we support the development of tools and techniques that can be used ethically as well as provide education and experience in AI for anyone who wants to learn it hands-on. We will take a zero tolerance approach to anyone using this software for any unethical purposes and will actively discourage any such uses.\n\n# How To setup and run the project\nFaceSwap is a Python program that will run on multiple Operating Systems including Windows, Linux, and MacOS.\n\nSee [INSTALL.md](INSTALL.md) for full installation instructions. You will need a modern GPU with CUDA support for best performance. AMD GPUs are partially supported.\n\n# Overview\nThe project has multiple entry points. You will have to:\n - Gather photos and/or videos\n - **Extract** faces from your raw photos\n - **Train** a model on the faces extracted from the photos/videos\n - **Convert** your sources with the model\n\nCheck out [USAGE.md](USAGE.md) for more detailed instructions.\n\n## Extract\nFrom your setup folder, run `python faceswap.py extract`. This will take photos from `src` folder and extract faces into `extract` folder.\n\n## Train\nFrom your setup folder, run `python faceswap.py train`. This will take photos from two folders containing pictures of both faces and train a model that will be saved inside the `models` folder.\n\n## Convert\nFrom your setup folder, run `python faceswap.py convert`. This will take photos from `original` folder and apply new faces into `modified` folder.\n\n## GUI\nAlternatively, you can run the GUI by running `python faceswap.py gui`\n\n# General notes:\n- All of the scripts mentioned have `-h`/`--help` options with arguments that they will accept. You're smart, you can figure out how this works, right?!\n\nNB: there is a conversion tool for video. This can be accessed by running `python tools.py effmpeg -h`. Alternatively, you can use [ffmpeg](https://www.ffmpeg.org) to convert video into photos, process images, and convert images back to the video.\n\n\n**Some tips:**\n\nReusing existing models will train much faster than starting from nothing.\nIf there is not enough training data, start with someone who looks similar, then switch the data.\n\n# Help I need support!\n## Discord Server\nYour best bet is to join the [FaceSwap Discord server](https://discord.gg/FC54sYg) where there are plenty of users willing to help. Please note that, like this repo, this is a SFW Server!\n\n## FaceSwap Forum\nAlternatively, you can post questions in the [FaceSwap Forum](https://faceswap.dev/forum). Please do not post general support questions in this repo as they are liable to be deleted without response.\n\n# Donate\nThe developers work tirelessly to improve and develop FaceSwap. Many hours have been put in to provide the software as it is today, but this is an extremely time-consuming process with no financial reward. If you enjoy using the software, please consider donating to the devs, so they can spend more time implementing improvements.\n\n## Patreon\nThe best way to support us is through our Patreon page:\n\n[![become-a-patron](https://c5.patreon.com/external/logo/become_a_patron_button.png)](https://www.patreon.com/bePatron?u=23238350)\n\n## One time Donations\nAlternatively you can give a one off donation to any of our Devs:\n### @torzdf\n There is very little FaceSwap code that hasn't been touched by torzdf. He is responsible for implementing the GUI, FAN aligner, MTCNN detector and porting the Villain, DFL-H128 and DFaker models to FaceSwap, as well as significantly improving many areas of the code.\n\n**Bitcoin:** bc1qpm22suz59ylzk0j7qk5e4c7cnkjmve2rmtrnc6\n\n**Ethereum:** 0xd3e954dC241B87C4E8E1A801ada485DC1d530F01\n\n**Monero:** 45dLrtQZ2pkHizBpt3P3yyJKkhcFHnhfNYPMSnz3yVEbdWm3Hj6Kr5TgmGAn3Far8LVaQf1th2n3DJVTRkfeB5ZkHxWozSX\n\n**Paypal:** [![torzdf](https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=JZ8PP3YE9J62L)\n\n### @andenixa\nCreator of the Unbalanced and OHR models, as well as expanding various capabilities within the training process. Andenixa is currently working on new models and will take requests for donations.\n\n**Paypal:** [![andenixa](https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=NRVLQYGS6NWTU)\n\n# How to contribute\n\n## For people interested in the generative models\n - Go to the 'faceswap-model' to discuss/suggest/commit alternatives to the current algorithm.\n\n## For devs\n - Read this README entirely\n - Fork the repo\n - Play with it\n - Check issues with the 'dev' tag\n - For devs more interested in computer vision and openCV, look at issues with the 'opencv' tag. Also feel free to add your own alternatives/improvements\n\n## For non-dev advanced users\n - Read this README entirely\n - Clone the repo\n - Play with it\n - Check issues with the 'advuser' tag\n - Also go to the '[faceswap Forum](https://faceswap.dev/forum)' and help others.\n\n## For end-users\n - Get the code here and play with it if you can\n - You can also go to the [faceswap Forum](https://faceswap.dev/forum) and help or get help from others.\n - Be patient. This is a relatively new technology for developers as well. Much effort is already being put into making this program easy to use for the average user. It just takes time!\n - **Notice** Any issue related to running the code has to be opened in the [faceswap Forum](https://faceswap.dev/forum)!\n\n## For haters\nSorry, no time for that.\n\n# About github.com/deepfakes\n\n## What is this repo?\nIt is a community repository for active users.\n\n## Why this repo?\nThe joshua-wu repo seems not active. Simple bugs like missing _http://_ in front of urls have not been solved since days.\n\n## Why is it named 'deepfakes' if it is not /u/deepfakes?\n 1. Because a typosquat would have happened sooner or later as project grows\n 2. Because we wanted to recognize the original author\n 3. Because it will better federate contributors and users\n\n## What if /u/deepfakes feels bad about that?\nThis is a friendly typosquat, and it is fully dedicated to the project. If /u/deepfakes wants to take over this repo/user and drive the project, he is welcomed to do so (Raise an issue, and he will be contacted on Reddit). Please do not send /u/deepfakes messages for help with the code you find here.\n\n# About machine learning\n\n## How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?\nIt's complicated. Here's a good video that makes the process understandable:\n[![How Machines Learn](https://img.youtube.com/vi/R9OHn5ZF4Uo/0.jpg)](https://www.youtube.com/watch?v=R9OHn5ZF4Uo)\n\nHere's a slightly more in depth video that tries to explain the basic functioning of a neural network:\n[![How Machines Learn](https://img.youtube.com/vi/aircAruvnKk/0.jpg)](https://www.youtube.com/watch?v=aircAruvnKk)\n\ntl;dr: training data + trial and error\n",
	"deep-learning examples machine-learning python tensorflow tutorial": "# TensorFlow Examples\n\nThis tutorial was designed for easily diving into TensorFlow, through examples. For readability, it includes both notebooks and source codes with explanation, for both TF v1 & v2.\n\nIt is suitable for beginners who want to find clear and concise examples about TensorFlow. Besides the traditional 'raw' TensorFlow implementations, you can also find the latest TensorFlow API practices (such as `layers`, `estimator`, `dataset`, ...).\n\n**Update (05/16/2020):** Moving all default examples to TF2. For TF v1 examples: [check here](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1).\n\n## Tutorial index\n\n#### 0 - Prerequisite\n- [Introduction to Machine Learning](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/0_Prerequisite/ml_introduction.ipynb).\n- [Introduction to MNIST Dataset](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/0_Prerequisite/mnist_dataset_intro.ipynb).\n\n#### 1 - Introduction\n- **Hello World** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/1_Introduction/helloworld.ipynb)). Very simple example to learn how to print \"hello world\" using TensorFlow 2.0+.\n- **Basic Operations** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/1_Introduction/basic_operations.ipynb)). A simple example that cover TensorFlow 2.0+ basic operations.\n\n#### 2 - Basic Models\n- **Linear Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/linear_regression.ipynb)). Implement a Linear Regression with TensorFlow 2.0+.\n- **Logistic Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/logistic_regression.ipynb)). Implement a Logistic Regression with TensorFlow 2.0+.\n- **Word2Vec (Word Embedding)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/word2vec.ipynb)). Build a Word Embedding Model (Word2Vec) from Wikipedia data, with TensorFlow 2.0+.\n- **GBDT (Gradient Boosted Decision Trees)** ([notebooks](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/gradient_boosted_trees.ipynb)). Implement a Gradient Boosted Decision Trees with TensorFlow 2.0+ to predict house value using Boston Housing dataset.\n\n#### 3 - Neural Networks\n##### Supervised\n\n- **Simple Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/neural_network.ipynb)). Use TensorFlow 2.0 'layers' and 'model' API to build a simple neural network to classify MNIST digits dataset.\n- **Simple Neural Network (low-level)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/neural_network_raw.ipynb)). Raw implementation of a simple neural network to classify MNIST digits dataset.\n- **Convolutional Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/convolutional_network.ipynb)). Use TensorFlow 2.0+ 'layers' and 'model' API to build a convolutional neural network to classify MNIST digits dataset.\n- **Convolutional Neural Network (low-level)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/convolutional_network_raw.ipynb)). Raw implementation of a convolutional neural network to classify MNIST digits dataset.\n- **Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/recurrent_network.ipynb)). Build a recurrent neural network (LSTM) to classify MNIST digits dataset, using TensorFlow 2.0 'layers' and 'model' API.\n- **Bi-directional Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/bidirectional_rnn.ipynb)). Build a bi-directional recurrent neural network (LSTM) to classify MNIST digits dataset, using TensorFlow 2.0+ 'layers' and 'model' API.\n- **Dynamic Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/dynamic_rnn.ipynb)). Build a recurrent neural network (LSTM) that performs dynamic calculation to classify sequences of variable length, using TensorFlow 2.0+ 'layers' and 'model' API.\n\n##### Unsupervised\n- **Auto-Encoder** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/autoencoder.ipynb)). Build an auto-encoder to encode an image to a lower dimension and re-construct it.\n- **DCGAN (Deep Convolutional Generative Adversarial Networks)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/dcgan.ipynb)). Build a Deep Convolutional Generative Adversarial Network (DCGAN) to generate images from noise.\n\n#### 4 - Utilities\n- **Save and Restore a model** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/4_Utils/save_restore_model.ipynb)). Save and Restore a model with TensorFlow 2.0+.\n- **Build Custom Layers & Modules** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/4_Utils/build_custom_layers.ipynb)). Learn how to build your own layers / modules and integrate them into TensorFlow 2.0+ Models.\n- **Tensorboard** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/4_Utils/tensorboard.ipynb)). Track and visualize neural network computation graph, metrics, weights and more using TensorFlow 2.0+ tensorboard.\n\n#### 5 - Data Management\n- **Load and Parse data** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/5_DataManagement/load_data.ipynb)). Build efficient data pipeline with TensorFlow 2.0 (Numpy arrays, Images, CSV files, custom data, ...).\n- **Build and Load TFRecords** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/5_DataManagement/tfrecords.ipynb)). Convert data into TFRecords format, and load them with TensorFlow 2.0+.\n- **Image Transformation (i.e. Image Augmentation)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/5_DataManagement/image_transformation.ipynb)). Apply various image augmentation techniques with TensorFlow 2.0+, to generate distorted images for training.\n\n#### 6 - Hardware\n- **Multi-GPU Training** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/6_Hardware/multigpu_training.ipynb)). Train a convolutional neural network with multiple GPUs on CIFAR-10 dataset.\n\n## TensorFlow v1\n\nThe tutorial index for TF v1 is available here: [TensorFlow v1.15 Examples](tensorflow_v1). Or see below for a list of the examples.\n\n## Dataset\nSome examples require MNIST dataset for training and testing. Don't worry, this dataset will automatically be downloaded when running examples.\nMNIST is a database of handwritten digits, for a quick description of that dataset, you can check [this notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/0_Prerequisite/mnist_dataset_intro.ipynb).\n\nOfficial Website: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).\n\n## Installation\n\nTo download all the examples, simply clone this repository:\n```\ngit clone https://github.com/aymericdamien/TensorFlow-Examples\n```\n\nTo run them, you also need the latest version of TensorFlow. To install it:\n```\npip install tensorflow\n```\n\nor (with GPU support):\n```\npip install tensorflow_gpu\n```\n\nFor more details about TensorFlow installation, you can check [TensorFlow Installation Guide](https://www.tensorflow.org/install/)\n\n\n## TensorFlow v1 Examples - Index\n\nThe tutorial index for TF v1 is available here: [TensorFlow v1.15 Examples](tensorflow_v1).\n\n#### 0 - Prerequisite\n- [Introduction to Machine Learning](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/tensorflow_v1/0_Prerequisite/ml_introduction.ipynb).\n- [Introduction to MNIST Dataset](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/tensorflow_v1/0_Prerequisite/mnist_dataset_intro.ipynb).\n\n#### 1 - Introduction\n- **Hello World** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/1_Introduction/helloworld.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/1_Introduction/helloworld.py)). Very simple example to learn how to print \"hello world\" using TensorFlow.\n- **Basic Operations** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/tensorflow_v1/1_Introduction/basic_operations.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-examples/Examples/blob/master/tensorflow_v1/1_Introduction/basic_operations.py)). A simple example that cover TensorFlow basic operations.\n- **TensorFlow Eager API basics** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/1_Introduction/basic_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/1_Introduction/basic_eager_api.py)). Get started with TensorFlow's Eager API.\n\n#### 2 - Basic Models\n- **Linear Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/linear_regression.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/linear_regression.py)). Implement a Linear Regression with TensorFlow.\n- **Linear Regression (eager api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/linear_regression_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/linear_regression_eager_api.py)). Implement a Linear Regression using TensorFlow's Eager API.\n- **Logistic Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/logistic_regression.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/logistic_regression.py)). Implement a Logistic Regression with TensorFlow.\n- **Logistic Regression (eager api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/logistic_regression_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/logistic_regression_eager_api.py)). Implement a Logistic Regression using TensorFlow's Eager API.\n- **Nearest Neighbor** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/nearest_neighbor.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/nearest_neighbor.py)). Implement Nearest Neighbor algorithm with TensorFlow.\n- **K-Means** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/kmeans.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/kmeans.py)). Build a K-Means classifier with TensorFlow.\n- **Random Forest** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/random_forest.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/random_forest.py)). Build a Random Forest classifier with TensorFlow.\n- **Gradient Boosted Decision Tree (GBDT)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/gradient_boosted_decision_tree.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/gradient_boosted_decision_tree.py)). Build a Gradient Boosted Decision Tree (GBDT) with TensorFlow.\n- **Word2Vec (Word Embedding)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/word2vec.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/word2vec.py)). Build a Word Embedding Model (Word2Vec) from Wikipedia data, with TensorFlow.\n\n#### 3 - Neural Networks\n##### Supervised\n\n- **Simple Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/3_NeuralNetworks/notebooks/neural_network_raw.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/neural_network_raw.py)). Build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset. Raw TensorFlow implementation.\n- **Simple Neural Network (tf.layers/estimator api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/neural_network.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/neural_network.py)). Use TensorFlow 'layers' and 'estimator' API to build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset.\n- **Simple Neural Network (eager api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/neural_network_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/neural_network_eager_api.py)). Use TensorFlow Eager API to build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset.\n- **Convolutional Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/convolutional_network_raw.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/convolutional_network_raw.py)). Build a convolutional neural network to classify MNIST digits dataset. Raw TensorFlow implementation.\n- **Convolutional Neural Network (tf.layers/estimator api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/convolutional_network.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/convolutional_network.py)). Use TensorFlow 'layers' and 'estimator' API to build a convolutional neural network to classify MNIST digits dataset.\n- **Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/recurrent_network.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/recurrent_network.py)). Build a recurrent neural network (LSTM) to classify MNIST digits dataset.\n- **Bi-directional Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/bidirectional_rnn.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/bidirectional_rnn.py)). Build a bi-directional recurrent neural network (LSTM) to classify MNIST digits dataset.\n- **Dynamic Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/dynamic_rnn.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/dynamic_rnn.py)). Build a recurrent neural network (LSTM) that performs dynamic calculation to classify sequences of different length.\n\n##### Unsupervised\n- **Auto-Encoder** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/autoencoder.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/autoencoder.py)). Build an auto-encoder to encode an image to a lower dimension and re-construct it.\n- **Variational Auto-Encoder** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/variational_autoencoder.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/variational_autoencoder.py)). Build a variational auto-encoder (VAE), to encode and generate images from noise.\n- **GAN (Generative Adversarial Networks)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/gan.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/gan.py)). Build a Generative Adversarial Network (GAN) to generate images from noise.\n- **DCGAN (Deep Convolutional Generative Adversarial Networks)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/dcgan.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/dcgan.py)). Build a Deep Convolutional Generative Adversarial Network (DCGAN) to generate images from noise.\n\n#### 4 - Utilities\n- **Save and Restore a model** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/4_Utils/save_restore_model.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/4_Utils/save_restore_model.py)). Save and Restore a model with TensorFlow.\n- **Tensorboard - Graph and loss visualization** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/4_Utils/tensorboard_basic.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/4_Utils/tensorboard_basic.py)). Use Tensorboard to visualize the computation Graph and plot the loss.\n- **Tensorboard - Advanced visualization** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/4_Utils/tensorboard_advanced.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/4_Utils/tensorboard_advanced.py)). Going deeper into Tensorboard; visualize the variables, gradients, and more...\n\n#### 5 - Data Management\n- **Build an image dataset** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/build_an_image_dataset.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/5_DataManagement/build_an_image_dataset.py)). Build your own images dataset with TensorFlow data queues, from image folders or a dataset file.\n- **TensorFlow Dataset API** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/tensorflow_dataset_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/5_DataManagement/tensorflow_dataset_api.py)). Introducing TensorFlow Dataset API for optimizing the input data pipeline.\n- **Load and Parse data** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/load_data.ipynb)). Build efficient data pipeline (Numpy arrays, Images, CSV files, custom data, ...).\n- **Build and Load TFRecords** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/tfrecords.ipynb)). Convert data into TFRecords format, and load them.\n- **Image Transformation (i.e. Image Augmentation)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/image_transformation.ipynb)). Apply various image augmentation techniques, to generate distorted images for training.\n\n#### 6 - Multi GPU\n- **Basic Operations on multi-GPU** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/6_MultiGPU/multigpu_basics.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/6_MultiGPU/multigpu_basics.py)). A simple example to introduce multi-GPU in TensorFlow.\n- **Train a Neural Network on multi-GPU** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/6_MultiGPU/multigpu_cnn.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/6_MultiGPU/multigpu_cnn.py)). A clear and simple TensorFlow implementation to train a convolutional neural network on multiple GPUs.\n\n## More Examples\nThe following examples are coming from [TFLearn](https://github.com/tflearn/tflearn), a library that provides a simplified interface for TensorFlow. You can have a look, there are many [examples](https://github.com/tflearn/tflearn/tree/master/examples) and [pre-built operations and layers](http://tflearn.org/doc_index/#api).\n\n### Tutorials\n- [TFLearn Quickstart](https://github.com/tflearn/tflearn/blob/master/tutorials/intro/quickstart.md). Learn the basics of TFLearn through a concrete machine learning task. Build and train a deep neural network classifier.\n\n### Examples\n- [TFLearn Examples](https://github.com/tflearn/tflearn/blob/master/examples). A large collection of examples using TFLearn.\n\n",
	"hacktoberfest hpc julia julia-language machine-learning numerical programming-language science scientific": "<a name=\"logo\"/>\n<div align=\"center\">\n<a href=\"https://julialang.org/\" target=\"_blank\">\n<img src=\"doc/src/assets/logo.svg\" alt=\"Julia Logo\" width=\"210\" height=\"142\"></img>\n</a>\n</div>\n\n<table>\n    <!-- Docs -->\n    <tr>\n        <td>Documentation</td>\n        <td>\n            <a href=\"https://docs.julialang.org\"><img src='https://img.shields.io/badge/docs-v1-blue.svg'/></a>\n        </td>\n    </tr>\n    <!-- Continuous integration\n    To change the badge to point to a different pipeline, it is not sufficient to simply change the `?branch=` part.\n    You need to go to the Buildkite website and get the SVG URL for the correct pipeline. -->\n    <tr>\n        <td>Continuous integration</td>\n        <td>\n            <a href=\"https://buildkite.com/julialang/julia-master\"><img src='https://badge.buildkite.com/f28e0d28b345f9fad5856ce6a8d64fffc7c70df8f4f2685cd8.svg?branch=master'/></a>\n        </td>\n    </tr>\n    <!-- Coverage -->\n    <tr>\n        <td>Code coverage</td>\n        <td>\n            <a href=\"https://coveralls.io/r/JuliaLang/julia?branch=master\"><img src='https://img.shields.io/coveralls/github/JuliaLang/julia/master.svg?label=coveralls'/></a> <a href=\"https://codecov.io/github/JuliaLang/julia?branch=master\"><img src='https://img.shields.io/codecov/c/github/JuliaLang/julia/master.svg?label=codecov'/></a>\n        </td>\n    </tr>\n</table>\n\n## The Julia Language\n\nJulia is a high-level, high-performance dynamic language for technical\ncomputing.  The main homepage for Julia can be found at\n[julialang.org](https://julialang.org/).  This is the GitHub\nrepository of Julia source code, including instructions for compiling\nand installing Julia, below.\n\n## Resources\n\n- **Homepage:** <https://julialang.org>\n- **Binaries:** <https://julialang.org/downloads/>\n- **Source code:** <https://github.com/JuliaLang/julia>\n- **Documentation:** <https://docs.julialang.org>\n- **Packages:** <https://julialang.org/packages/>\n- **Discussion forum:** <https://discourse.julialang.org>\n- **Slack:** <https://julialang.slack.com> (get an invite from <https://julialang.org/slack/>)\n- **YouTube:** <https://www.youtube.com/user/JuliaLanguage>\n- **Code coverage:** <https://coveralls.io/r/JuliaLang/julia>\n\nNew developers may find the notes in\n[CONTRIBUTING](https://github.com/JuliaLang/julia/blob/master/CONTRIBUTING.md)\nhelpful to start contributing to the Julia codebase.\n\n### External Resources\n\n- [**StackOverflow**](https://stackoverflow.com/questions/tagged/julia-lang)\n- [**Twitter**](https://twitter.com/JuliaLanguage)\n- [**Learning resources**](https://julialang.org/learning/)\n\n## Binary Installation\n\nIf you would rather not compile the latest Julia from source,\nplatform-specific tarballs with pre-compiled binaries are also\n[available for download](https://julialang.org/downloads/). The\ndownloads page also provides details on the\n[different tiers of support](https://julialang.org/downloads/#supported_platforms)\nfor OS and platform combinations.\n\nIf everything works correctly, you will see a Julia banner and an\ninteractive prompt into which you can enter expressions for\nevaluation.  You can read about [getting\nstarted](https://docs.julialang.org/en/v1/manual/getting-started/) in the manual.\n\n**Note**: Although some system package managers provide Julia, such\ninstallations are neither maintained nor endorsed by the Julia\nproject. They may be outdated, broken and/or unmaintained. We\nrecommend you use the official Julia binaries instead.\n\n## Building Julia\n\nFirst, make sure you have all the [required\ndependencies](https://github.com/JuliaLang/julia/blob/master/doc/src/devdocs/build/build.md#required-build-tools-and-external-libraries) installed.\nThen, acquire the source code by cloning the git repository:\n\n    git clone https://github.com/JuliaLang/julia.git\n\nand then use the command prompt to change into the resulting julia directory. By default you will be building the latest unstable version of\nJulia. However, most users should use the [most recent stable version](https://github.com/JuliaLang/julia/releases)\nof Julia. You can get this version by running:\n\n    git checkout v1.8.3\n\nTo build the `julia` executable, run `make` from within the julia directory.\n\nBuilding Julia requires 2GiB of disk space and approximately 4GiB of virtual memory.\n\n**Note:** The build process will fail badly if any of the build directory's parent directories have spaces or other shell meta-characters such as `$` or `:` in their names (this is due to a limitation in GNU make).\n\nOnce it is built, you can run the `julia` executable. From within the julia directory, run\n\n    ./julia\n\nYour first test of Julia determines whether your build is working\nproperly. From the julia\ndirectory, type `make testall`. You should see output that\nlists a series of running tests; if they complete without error, you\nshould be in good shape to start using Julia.\n\nYou can read about [getting\nstarted](https://docs.julialang.org/en/v1/manual/getting-started/)\nin the manual.\n\nDetailed build instructions, should they be necessary,\nare included in the [build documentation](https://github.com/JuliaLang/julia/blob/master/doc/src/devdocs/build/).\n\n### Uninstalling Julia\n\nBy default, Julia does not install anything outside the directory it was cloned\ninto and `~/.julia`. Julia and the vast majority of Julia packages can be\ncompletely uninstalled by deleting these two directories.\n\n## Source Code Organization\n\nThe Julia source code is organized as follows:\n\n| Directory         | Contents                                                           |\n| -                 | -                                                                  |\n| `base/`           | source code for the Base module (part of Julia's standard library) |\n| `stdlib/`         | source code for other standard library packages                    |\n| `cli/`            | source for the command line interface/REPL                         |\n| `contrib/`        | miscellaneous scripts                                              |\n| `deps/`           | external dependencies                                              |\n| `doc/src/`        | source for the user manual                                         |\n| `src/`            | source for Julia language core                                     |\n| `test/`           | test suites                                                        |\n| `usr/`            | binaries and shared libraries loaded by Julia's standard libraries |\n\n## Terminal, Editors and IDEs\n\nThe Julia REPL is quite powerful. See the section in the manual on\n[the Julia REPL](https://docs.julialang.org/en/v1/stdlib/REPL/)\nfor more details.\n\nOn Windows we highly recommend running Julia in a modern terminal,\nsuch as [Windows Terminal from the Microsoft Store](https://aka.ms/terminal).\n\nSupport for editing Julia is available for many\n[widely used editors](https://github.com/JuliaEditorSupport):\n[Emacs](https://github.com/JuliaEditorSupport/julia-emacs),\n[Vim](https://github.com/JuliaEditorSupport/julia-vim),\n[Sublime Text](https://github.com/JuliaEditorSupport/Julia-sublime), and many\nothers.\n\nFor users who prefer IDEs, we recommend using VS Code with the\n[julia-vscode](https://www.julia-vscode.org/) plugin.\nFor notebook users, [Jupyter](https://jupyter.org/) notebook support is available through the\n[IJulia](https://github.com/JuliaLang/IJulia.jl) package, and\nthe [Pluto.jl](https://github.com/fonsp/Pluto.jl) package provides Pluto notebooks.\n",
	"100-days-of-code-log 100daysofcode deep-learning implementation infographics linear-algebra linear-regression logistic-regression machine-learning machine-learning-algorithms naive-bayes-classifier python scikit-learn siraj-raval siraj-raval-challenge support-vector-machines svm tutorial": "# 100-Days-Of-ML-Code\n\n100 Days of Machine Learning Coding as proposed by [Siraj Raval](https://github.com/llSourcell)\n\nGet the datasets from [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/tree/master/datasets)\n\n## Data PreProcessing | Day 1\nCheck out the code from [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%201_Data%20PreProcessing.md).\n\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%201.jpg\">\n</p>\n\n## Simple Linear Regression | Day 2\nCheck out the code from [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day2_Simple_Linear_Regression.md).\n\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%202.jpg\">\n</p>\n\n## Multiple Linear Regression | Day 3\nCheck out the code from [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day3_Multiple_Linear_Regression.md).\n\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%203.jpg\">\n</p>\n\n## Logistic Regression | Day 4\n\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%204.jpg\">\n</p>\n\n## Logistic Regression | Day 5\nMoving forward into #100DaysOfMLCode today I dived into the deeper depth of what Logistic Regression actually is and what is the math involved behind it. Learned how cost function is calculated and then how to apply gradient descent algorithm to cost function to minimize the error in prediction.  \nDue to less time I will now be posting an infographic on alternate days.\nAlso if someone wants to help me out in documentaion of code and already has some experince in the field and knows Markdown for github please contact me on LinkedIn :) .\n\n## Implementing Logistic Regression | Day 6\nCheck out the Code [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%206%20Logistic%20Regression.md)\n\n## K Nearest Neighbours | Day 7\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%207.jpg\">\n</p>\n\n## Math Behind Logistic Regression | Day 8 \n\n#100DaysOfMLCode To clear my insights on logistic regression I was searching on the internet for some resource or article and I came across this article (https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc) by Saishruthi Swaminathan. \n\nIt gives a detailed description of Logistic Regression. Do check it out.\n\n## Support Vector Machines | Day 9\nGot an intution on what SVM is and how it is used to solve Classification problem.\n\n## SVM and KNN | Day 10\nLearned more about how SVM works and implementing the K-NN algorithm.\n\n## Implementation of K-NN | Day 11  \n\nImplemented the K-NN algorithm for classification. #100DaysOfMLCode \nSupport Vector Machine Infographic is halfway complete. Will update it tomorrow.\n\n## Support Vector Machines | Day 12\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2012.jpg\">\n</p>\n\n## Naive Bayes Classifier | Day 13\n\nContinuing with #100DaysOfMLCode today I went through the Naive Bayes classifier.\nI am also implementing the SVM in python using scikit-learn. Will update the code soon.\n\n## Implementation of SVM | Day 14\nToday I implemented SVM on linearly related data. Used Scikit-Learn library. In Scikit-Learn we have SVC classifier which we use to achieve this task. Will be using kernel-trick on next implementation.\nCheck the code [here](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2013%20SVM.md).\n\n## Naive Bayes Classifier and Black Box Machine Learning | Day 15\nLearned about different types of naive bayes classifiers. Also started the lectures by [Bloomberg](https://bloomberg.github.io/foml/#home). First one in the playlist was Black Box Machine Learning. It gives the whole overview about prediction functions, feature extraction, learning algorithms, performance evaluation, cross-validation, sample bias, nonstationarity, overfitting, and hyperparameter tuning.\n\n## Implemented SVM using Kernel Trick | Day 16\nUsing Scikit-Learn library implemented SVM algorithm along with kernel function which maps our data points into higher dimension to find optimal hyperplane. \n\n## Started Deep learning Specialization on Coursera | Day 17\nCompleted the whole Week 1 and Week 2 on a single day. Learned Logistic regression as Neural Network. \n\n## Deep learning Specialization on Coursera | Day 18\nCompleted the Course 1 of the deep learning specialization. Implemented a neural net in python.\n\n## The Learning Problem , Professor Yaser Abu-Mostafa | Day 19\nStarted Lecture 1 of 18 of Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa. It was basically an introduction to the upcoming lectures. He also explained Perceptron Algorithm.\n\n## Started Deep learning Specialization Course 2 | Day 20\nCompleted the Week 1 of Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization.\n\n## Web Scraping | Day 21\nWatched some tutorials on how to do web scraping using Beautiful Soup in order to collect data for building a model.\n\n## Is Learning Feasible? | Day 22\nLecture 2 of 18 of Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa. Learned about Hoeffding Inequality.\n\n## Decision Trees | Day 23\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2023.jpg\">\n</p>\n\n## Introduction To Statistical Learning Theory | Day 24\nLec 3 of Bloomberg ML course introduced some of the core concepts like input space, action space, outcome space, prediction functions, loss functions, and hypothesis spaces.\n\n## Implementing Decision Trees | Day 25\nCheck the code [here.](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2025%20Decision%20Tree.md)\n\n## Jumped To Brush up Linear Algebra | Day 26\nFound an amazing [channel](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw) on youtube 3Blue1Brown. It has a playlist called Essence of Linear Algebra. Started off by completing 4 videos which gave a complete overview of Vectors, Linear Combinations, Spans, Basis Vectors, Linear Transformations and Matrix Multiplication. \n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\n\n## Jumped To Brush up Linear Algebra | Day 27\nContinuing with the playlist completed next 4 videos discussing topics 3D Transformations, Determinants, Inverse Matrix, Column Space, Null Space and Non-Square Matrices.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\n\n## Jumped To Brush up Linear Algebra | Day 28\nIn the playlist of 3Blue1Brown completed another 3 videos from the essence of linear algebra. \nTopics covered were Dot Product and Cross Product.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\n\n\n## Jumped To Brush up Linear Algebra | Day 29\nCompleted the whole playlist today, videos 12-14. Really an amazing playlist to refresh the concepts of Linear Algebra.\nTopics covered were the change of basis, Eigenvectors and Eigenvalues, and Abstract Vector Spaces.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\n\n## Essence of calculus | Day 30\nCompleting the playlist - Essence of Linear Algebra by 3blue1brown a suggestion popped up by youtube regarding a series of videos again by the same channel 3Blue1Brown. Being already impressed by the previous series on Linear algebra I dived straight into it.\nCompleted about 5 videos on topics such as Derivatives, Chain Rule, Product Rule, and derivative of exponential.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)\n\n## Essence of calculus | Day 31\nWatched 2 Videos on topic Implicit Diffrentiation and Limits from the playlist Essence of Calculus.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)\n\n## Essence of calculus | Day 32\nWatched the remaining 4 videos covering topics Like Integration and Higher order derivatives.\n\nLink to the playlist [here.](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)\n\n## Random Forests | Day 33\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2033.jpg\">\n</p>\n\n## Implementing Random Forests | Day 34\nCheck the code [here.](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2034%20Random_Forest.md)\n\n## But what *is* a Neural Network? | Deep learning, chapter 1  | Day 35\nAn Amazing Video on neural networks by 3Blue1Brown youtube channel. This video gives a good understanding of Neural Networks and uses Handwritten digit dataset to explain the concept. \nLink To the [video.](https://www.youtube.com/watch?v=aircAruvnKk&t=7s)\n\n## Gradient descent, how neural networks learn | Deep learning, chapter 2 | Day 36\nPart two of neural networks by 3Blue1Brown youtube channel. This video explains the concepts of Gradient Descent in an interesting way. 169 must watch and highly recommended.\nLink To the [video.](https://www.youtube.com/watch?v=IHZwWFHWa-w)\n\n## What is backpropagation really doing? | Deep learning, chapter 3 | Day 37\nPart three of neural networks by 3Blue1Brown youtube channel. This video mostly discusses the partial derivatives and backpropagation.\nLink To the [video.](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n\n## Backpropagation calculus | Deep learning, chapter 4 | Day 38\nPart four of neural networks by 3Blue1Brown youtube channel. The goal here is to represent, in somewhat more formal terms, the intuition for how backpropagation works and the video moslty discusses the partial derivatives and backpropagation.\nLink To the [video.](https://www.youtube.com/watch?v=tIeHLnjs5U8)\n\n## Deep Learning with Python, TensorFlow, and Keras tutorial | Day 39\nLink To the [video.](https://www.youtube.com/watch?v=wQ8BIBpya2k&t=19s&index=2&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN)\n\n## Loading in your own data - Deep Learning basics with Python, TensorFlow and Keras p.2 | Day 40\nLink To the [video.](https://www.youtube.com/watch?v=j-3vuBynnOE&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&index=2)\n\n## Convolutional Neural Networks - Deep Learning basics with Python, TensorFlow and Keras p.3 | Day 41\nLink To the [video.](https://www.youtube.com/watch?v=WvoLTXIjBYU&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&index=3)\n\n## Analyzing Models with TensorBoard - Deep Learning with Python, TensorFlow and Keras p.4 | Day 42\nLink To the [video.](https://www.youtube.com/watch?v=BqgTU7_cBnk&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&index=4)\n\n## K Means Clustering | Day 43\nMoved to Unsupervised Learning and studied about Clustering.\nWorking on my website check it out [avikjain.me](http://www.avikjain.me/)\nAlso found a wonderful animation that can help to easily understand K - Means Clustering [Link](http://shabal.in/visuals/kmeans/6.html)\n\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2043.jpg\">\n</p>\n\n## K Means Clustering Implementation | Day 44\nImplemented K Means Clustering. Check the code [here.]()\n\n## Digging Deeper | NUMPY  | Day 45\nGot a new book \"Python Data Science HandBook\" by JK VanderPlas Check the Jupyter notebooks [here.](https://github.com/jakevdp/PythonDataScienceHandbook)\n<br>Started with chapter 2 : Introduction to Numpy. Covered topics like Data Types, Numpy arrays and Computations on Numpy arrays.\n<br>Check the code - \n<br>[Introduction to NumPy](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.00-Introduction-to-NumPy.ipynb)\n<br>[Understanding Data Types in Python](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.01-Understanding-Data-Types.ipynb)\n<br>[The Basics of NumPy Arrays](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.02-The-Basics-Of-NumPy-Arrays.ipynb)\n<br>[Computation on NumPy Arrays: Universal Functions](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.03-Computation-on-arrays-ufuncs.ipynb)\n\n## Digging Deeper | NUMPY | Day 46\nChapter 2 : Aggregations, Comparisions and Broadcasting\n<br>Link to Notebook:\n<br>[Aggregations: Min, Max, and Everything In Between](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.04-Computation-on-arrays-aggregates.ipynb)\n<br>[Computation on Arrays: Broadcasting](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.05-Computation-on-arrays-broadcasting.ipynb)\n<br>[Comparisons, Masks, and Boolean Logic](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.06-Boolean-Arrays-and-Masks.ipynb)\n\n## Digging Deeper | NUMPY | Day 47\nChapter 2 : Fancy Indexing, sorting arrays, Struchered Data\n<br>Link to Notebook:\n<br>[Fancy Indexing](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.07-Fancy-Indexing.ipynb)\n<br>[Sorting Arrays](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.08-Sorting.ipynb)\n<br>[Structured Data: NumPy's Structured Arrays](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.09-<br>Structured-Data-NumPy.ipynb)\n\n## Digging Deeper | PANDAS | Day 48\nChapter 3 : Data Manipulation with Pandas\n<br> Covered Various topics like Pandas Objects, Data Indexing and Selection, Operating on Data, Handling Missing Data, Hierarchical Indexing, ConCat and Append.\n<br>Link To the Notebooks:\n<br>[Data Manipulation with Pandas](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.00-Introduction-to-Pandas.ipynb)\n<br>[Introducing Pandas Objects](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.01-Introducing-Pandas-Objects.ipynb)\n<br>[Data Indexing and Selection](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.02-Data-Indexing-and-Selection.ipynb)\n<br>[Operating on Data in Pandas](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.03-Operations-in-Pandas.ipynb)\n<br>[Handling Missing Data](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.04-Missing-Values.ipynb)\n<br>[Hierarchical Indexing](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.05-Hierarchical-Indexing.ipynb)\n<br>[Combining Datasets: Concat and Append](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.06-Concat-And-Append.ipynb)\n\n## Digging Deeper | PANDAS | Day 49\nChapter 3: Completed following topics- Merge and Join, Aggregation and grouping and Pivot Tables.\n<br>[Combining Datasets: Merge and Join](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.07-Merge-and-Join.ipynb)\n<br>[Aggregation and Grouping](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.08-Aggregation-and-Grouping.ipynb)\n<br>[Pivot Tables](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.09-Pivot-Tables.ipynb)\n\n## Digging Deeper | PANDAS | Day 50\nChapter 3: Vectorized Strings Operations, Working with Time Series\n<br>Links to Notebooks:\n<br>[Vectorized String Operations](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.10-Working-With-Strings.ipynb)\n<br>[Working with Time Series](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.11-Working-with-Time-Series.ipynb)\n<br>[High-Performance Pandas: eval() and query()](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.12-Performance-Eval-and-Query.ipynb)\n\n## Digging Deeper | MATPLOTLIB | Day 51\nChapter 4: Visualization with Matplotlib \nLearned about Simple Line Plots, Simple Scatter Plotsand Density and Contour Plots.\n<br>Links to Notebooks: \n<br>[Visualization with Matplotlib](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.00-Introduction-To-Matplotlib.ipynb)\n<br>[Simple Line Plots](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.01-Simple-Line-Plots.ipynb)\n<br>[Simple Scatter Plots](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.02-Simple-Scatter-Plots.ipynb)\n<br>[Visualizing Errors](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.03-Errorbars.ipynb)\n<br>[Density and Contour Plots](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.04-Density-and-Contour-Plots.ipynb)\n\n## Digging Deeper | MATPLOTLIB | Day 52\nChapter 4: Visualization with Matplotlib \nLearned about Histograms, How to customize plot legends, colorbars, and buliding Multiple Subplots.\n<br>Links to Notebooks: \n<br>[Histograms, Binnings, and Density](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.05-Histograms-and-Binnings.ipynb)\n<br>[Customizing Plot Legends](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.06-Customizing-Legends.ipynb)\n<br>[Customizing Colorbars](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.07-Customizing-Colorbars.ipynb)\n<br>[Multiple Subplots](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.08-Multiple-Subplots.ipynb)\n<br>[Text and Annotation](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.09-Text-and-Annotation.ipynb)\n\n## Digging Deeper | MATPLOTLIB | Day 53\nChapter 4: Covered Three Dimensional Plotting in Mathplotlib.\n<br>Links to Notebooks:\n<br>[Three-Dimensional Plotting in Matplotlib](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.12-Three-Dimensional-Plotting.ipynb)\n\n## Hierarchical Clustering | Day 54\nStudied about Hierarchical Clustering.\nCheck out this amazing [Visualization.](https://cdn-images-1.medium.com/max/800/1*ET8kCcPpr893vNZFs8j4xg.gif)\n<p align=\"center\">\n  <img src=\"https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2054.jpg\">\n</p>\n",
	"book chinese computer-vision deep-learning machine-learning natural-language-processing notebook python": "# \u52a8\u624b\u5b66\u6df1\u5ea6\u5b66\u4e60\uff08Dive into Deep Learning\uff0cD2L.ai\uff09\n\n[![Build Status](http://ci.d2l.ai/job/d2l-zh/job/master/badge/icon)](http://ci.d2l.ai/job/d2l-zh/job/master/)\n\n[\u7b2c\u4e00\u7248\uff1azh-v1.D2L.ai](https://zh-v1.d2l.ai/) |  [\u7b2c\u4e8c\u7248\u9884\u89c8\u7248\uff1azh.D2L.ai](https://zh.d2l.ai)  | \u5b89\u88c5\u548c\u4f7f\u7528\u4e66\u4e2d\u6e90\u4ee3\u7801\uff1a[\u7b2c\u4e00\u7248](https://zh-v1.d2l.ai/chapter_prerequisite/install.html) [\u7b2c\u4e8c\u7248](https://zh.d2l.ai/chapter_installation/index.html) | \u5f53\u524d\u7248\u672c: v2.0.0-beta1\n\n<h5 align=\"center\"><i>\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u4f73\u65b9\u6cd5\u662f\u5b66\u4ee5\u81f4\u7528\u3002</i></h5>\n\n<p align=\"center\">\n  <img width=\"200\"  src=\"static/frontpage/_images/eq.jpg\">\n  <img width=\"200\"  src=\"static/frontpage/_images/figure.jpg\">\n  <img width=\"200\"  src=\"static/frontpage/_images/code.jpg\">\n  <img width=\"200\"  src=\"static/frontpage/_images/notebook.gif\">\n</p>\n\n\u672c\u5f00\u6e90\u9879\u76ee\u4ee3\u8868\u4e86\u6211\u4eec\u7684\u4e00\u79cd\u5c1d\u8bd5\uff1a\u6211\u4eec\u5c06\u6559\u7ed9\u8bfb\u8005\u6982\u5ff5\u3001\u80cc\u666f\u77e5\u8bc6\u548c\u4ee3\u7801\uff1b\u6211\u4eec\u5c06\u5728\u540c\u4e00\u4e2a\u5730\u65b9\u9610\u8ff0\u5256\u6790\u95ee\u9898\u6240\u9700\u7684\u6279\u5224\u6027\u601d\u7ef4\u3001\u89e3\u51b3\u95ee\u9898\u6240\u9700\u7684\u6570\u5b66\u77e5\u8bc6\uff0c\u4ee5\u53ca\u5b9e\u73b0\u89e3\u51b3\u65b9\u6848\u6240\u9700\u7684\u5de5\u7a0b\u6280\u80fd\u3002\n\n\u6211\u4eec\u7684\u76ee\u6807\u662f\u521b\u5efa\u4e00\u4e2a\u4e3a\u5b9e\u73b0\u4ee5\u4e0b\u76ee\u6807\u7684\u7edf\u4e00\u8d44\u6e90\uff1a\n1. \u6240\u6709\u4eba\u5747\u53ef\u5728\u7f51\u4e0a\u514d\u8d39\u83b7\u53d6\uff1b\n1. \u63d0\u4f9b\u8db3\u591f\u7684\u6280\u672f\u6df1\u5ea6\uff0c\u4ece\u800c\u5e2e\u52a9\u8bfb\u8005\u5b9e\u9645\u6210\u4e3a\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u79d1\u5b66\u5bb6\uff1a\u65e2\u7406\u89e3\u6570\u5b66\u539f\u7406\uff0c\u53c8\u80fd\u591f\u5b9e\u73b0\u5e76\u4e0d\u65ad\u6539\u8fdb\u65b9\u6cd5\uff1b\n1. \u5305\u542b\u53ef\u8fd0\u884c\u7684\u4ee3\u7801\uff0c\u4e3a\u8bfb\u8005\u5c55\u793a\u5982\u4f55\u5728\u5b9e\u9645\u4e2d\u89e3\u51b3\u95ee\u9898\u3002\u8fd9\u6837\u4e0d\u4ec5\u76f4\u63a5\u5c06\u6570\u5b66\u516c\u5f0f\u5bf9\u5e94\u6210\u5b9e\u9645\u4ee3\u7801\uff0c\u800c\u4e14\u53ef\u4ee5\u4fee\u6539\u4ee3\u7801\u3001\u89c2\u5bdf\u7ed3\u679c\u5e76\u53ca\u65f6\u83b7\u53d6\u7ecf\u9a8c\uff1b\n1. \u5141\u8bb8\u6211\u4eec\u548c\u6574\u4e2a\u793e\u533a\u4e0d\u65ad\u5feb\u901f\u8fed\u4ee3\u5185\u5bb9\uff0c\u4ece\u800c\u7d27\u8ddf\u4ecd\u5728\u9ad8\u901f\u53d1\u5c55\u7684\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\uff1b\n1. \u7531\u5305\u542b\u6709\u5173\u6280\u672f\u7ec6\u8282\u95ee\u7b54\u7684\u8bba\u575b\u4f5c\u4e3a\u8865\u5145\uff0c\u4f7f\u5927\u5bb6\u53ef\u4ee5\u76f8\u4e92\u7b54\u7591\u5e76\u4ea4\u6362\u7ecf\u9a8c\u3002\n\n<h5 align=\"center\">\u5c06\u672c\u4e66\uff08\u4e2d\u82f1\u6587\u7248\uff09\u7528\u4f5c\u6559\u6750\u6216\u53c2\u8003\u4e66\u7684\u5927\u5b66</h5>\n<p align=\"center\">\n  <img width=\"400\"  src=\"http://en.d2l.ai.s3-website-us-west-2.amazonaws.com/_images/map.png\">\n</p>\n\n\u5982\u679c\u672c\u4e66\u5bf9\u4f60\u6709\u5e2e\u52a9\uff0c\u8bf7Star (\u2605) \u672c\u4ed3\u5e93\u6216\u5f15\u7528\u672c\u4e66\u7684\u82f1\u6587\u7248\uff1a\n\n```\n@article{zhang2021dive,\n    title={Dive into Deep Learning},\n    author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},\n    journal={arXiv preprint arXiv:2106.11342},\n    year={2021}\n}\n```\n\n## \u672c\u4e66\u7684\u7b2c\u4e8c\u7248\n\n\u867d\u7136\u7eb8\u8d28\u4e66\u7b2c\u4e00\u7248\u5df2\u7ecf\u51fa\u7248\uff0c\u4f46\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u4f9d\u7136\u5728\u8fc5\u901f\u53d1\u5c55\u3002\u4e3a\u4e86\u5f97\u5230\u6765\u81ea\u66f4\u5e7f\u6cdb\u7684\u82f1\u6587\u5f00\u6e90\u793e\u533a\u7684\u5e2e\u52a9\uff0c\u4ece\u800c\u63d0\u5347\u672c\u4e66\u8d28\u91cf\uff0c\u672c\u4e66\u7684\u7b2c\u4e8c\u7248\u6b63\u5728\u7528\u82f1\u6587\u5199\u3002\u82f1\u6587\u7248\u6b63\u4e0d\u65ad\u88ab\u642c\u56de\u4e2d\u6587\u7248\u4e2d\u3002\n\n\u76ee\u524d\uff0c\u82f1\u6587\u7248\u5df2\u8d85\u8fc7160\u8282\uff08\u4e2d\u6587\u7248\u517196\u8282\uff09\uff0c\u4f8b\u5982\u589e\u52a0\u4e86\u7406\u8bba\u80cc\u666f\uff08\u5982\u4f18\u5316\u6536\u655b\u5206\u6790\uff09\u3001\u786c\u4ef6\u8bbe\u8ba1\uff08\u5982\u53c2\u6570\u670d\u52a1\u5668\uff09\u3001\u5168\u65b0\u7bc7\u7ae0\uff08\u5982\u6ce8\u610f\u529b\u673a\u5236\u3001\u63a8\u8350\u7cfb\u7edf\u3001\u6df1\u5ea6\u5b66\u4e60\u7684\u6570\u5b66\u3001\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff09\u3001\u5e94\u7528\u79cd\u7c7b\uff08\u5982\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\uff09\u3001\u6a21\u578b\u79cd\u7c7b\uff08\u5982Transformer\u3001BERT\uff09\u7b49\uff0c\u5e76\u4f18\u5316\u91cd\u7ec4\u4e86\u5927\u91cf\u7ae0\u8282\uff08\u5982\u5c06\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7bc7\u7ae0\u6309\u4ece\u9884\u8bad\u7ec3\u8868\u5f81\u3001\u5230\u6a21\u578b\u8bbe\u8ba1\u3001\u518d\u5230\u4e0b\u6e38\u5e94\u7528\u91cd\u6784\uff09\u3002\n\n\u6b22\u8fce\u5173\u6ce8\u672c\u4e66[\u7b2c\u4e8c\u7248\u7684\u82f1\u6587\u5f00\u6e90\u9879\u76ee](https://github.com/d2l-ai/d2l-en)\u3002\n\n## \u4e2d\u82f1\u6587\u6559\u5b66\u8d44\u6e90\n\n\u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821 2019 \u5e74\u6625\u5b66\u671f [*Introduction to Deep Learning* \u8bfe\u7a0b](http://courses.d2l.ai/berkeley-stat-157/index.html)\u6559\u6750\uff08\u540c\u65f6\u63d0\u4f9b\u542b\u6559\u5b66\u89c6\u9891\u5730\u5740\u7684[\u4e2d\u6587\u7248\u8bfe\u4ef6](https://github.com/d2l-ai/berkeley-stat-157/tree/master/slides-zh)\uff09\u3002\n\n## \u5b66\u672f\u754c\u63a8\u8350\n\n> <p>\"Dive into this book if you want to dive into deep learning!\"</p>\n> <b>&mdash; \u97e9\u5bb6\u709c\uff0cACM \u9662\u58eb\u3001IEEE \u9662\u58eb\uff0c\u7f8e\u56fd\u4f0a\u5229\u8bfa\u4f0a\u5927\u5b66\u9999\u69df\u5206\u6821\u8ba1\u7b97\u673a\u7cfb Michael Aiken Chair \u6559\u6388</b>\n\n> <p>\"This is a highly welcome addition to the machine learning literature.\"</p>\n> <b>&mdash; Bernhard Sch\u00f6lkopf\uff0cACM \u9662\u58eb\u3001\u5fb7\u56fd\u56fd\u5bb6\u79d1\u5b66\u9662\u9662\u58eb\uff0c\u5fb7\u56fd\u9a6c\u514b\u65af\u2022\u666e\u6717\u514b\u7814\u7a76\u6240\u667a\u80fd\u7cfb\u7edf\u9662\u9662\u957f</b>\n\n> <p>\"\u4e66\u4e2d\u4ee3\u7801\u53ef\u8c13\u2018\u6240\u5b66\u5373\u6240\u7528\u2019\u3002\"</p>\n> <b>&mdash; \u5468\u5fd7\u534e\uff0cACM \u9662\u58eb\u3001IEEE \u9662\u58eb\u3001AAAS \u9662\u58eb\uff0c\u5357\u4eac\u5927\u5b66\u8ba1\u7b97\u673a\u79d1\u5b66\u4e0e\u6280\u672f\u7cfb\u4e3b\u4efb</b>\n\n> <p>\"\u8fd9\u672c\u4e66\u53ef\u4ee5\u5e2e\u52a9\u6df1\u5ea6\u5b66\u4e60\u5b9e\u8df5\u8005\u5feb\u901f\u63d0\u5347\u81ea\u5df1\u7684\u80fd\u529b\u3002\"</p>\n> <b>&mdash; \u5f20\u6f7c\uff0cASA \u9662\u58eb\u3001IMS \u9662\u58eb\uff0c\u9999\u6e2f\u79d1\u6280\u5927\u5b66\u8ba1\u7b97\u673a\u7cfb\u548c\u6570\u5b66\u7cfb\u6559\u6388</b>\n\n## \u5de5\u4e1a\u754c\u63a8\u8350\n\n> <p>\"\u4e00\u672c\u4f18\u79c0\u7684\u6df1\u5ea6\u5b66\u4e60\u6559\u6750\uff0c\u503c\u5f97\u4efb\u4f55\u60f3\u4e86\u89e3\u6df1\u5ea6\u5b66\u4e60\u4f55\u4ee5\u5f15\u7206\u4eba\u5de5\u667a\u80fd\u9769\u547d\u7684\u4eba\u5173\u6ce8\u3002\"</p>\n> <b>&mdash; \u9ec4\u4ec1\u52cb\uff0cNVIDIA\u521b\u59cb\u4eba & CEO</b>\n\n> <p>\"\u300a\u52a8\u624b\u5b66\u6df1\u5ea6\u5b66\u4e60\u300b\u662f\u6700\u9002\u5408\u5de5\u4e1a\u754c\u7814\u53d1\u5de5\u7a0b\u5e08\u5b66\u4e60\u7684\u3002\u6211\u6beb\u65e0\u4fdd\u7559\u5730\u5411\u5e7f\u5927\u7684\u8bfb\u8005\u4eec\u5f3a\u70c8\u63a8\u8350\u3002\"</p>\n> <b>&mdash; \u4f59\u51ef\uff0c\u5730\u5e73\u7ebf\u516c\u53f8\u521b\u59cb\u4eba & CEO</b>\n\n> <p>\"\u5f3a\u70c8\u63a8\u8350\u8fd9\u672c\u4e66\uff01\u6211\u7279\u522b\u8d5e\u8d4f\u8fd9\u79cd\u624b\u8111\u4e00\u4f53\u7684\u5b66\u4e60\u65b9\u5f0f\u3002\"</p>\n> <b>&mdash; \u6f06\u8fdc\uff0c\u8682\u8681\u91d1\u670d\u526f\u603b\u88c1\u3001\u9996\u5e2dAI\u79d1\u5b66\u5bb6</b>\n\n> <p>\"\u300a\u52a8\u624b\u5b66\u6df1\u5ea6\u5b66\u4e60\u300b\u662f\u4e00\u672c\u5f88\u5bb9\u6613\u8ba9\u5b66\u4e60\u8005\u4e0a\u763e\u7684\u4e66\u3002\"</p>\n> <b>&mdash; \u6c88\u5f3a\uff0c\u5c06\u95e8\u521b\u6295\u521b\u59cb\u5408\u4f19\u4eba</b>\n\n## \u8d21\u732e\n\n\u611f\u8c22[\u793e\u533a\u8d21\u732e\u8005\u4eec](https://github.com/d2l-ai/d2l-zh/graphs/contributors)\u4e3a\u6bcf\u4e00\u4f4d\u8bfb\u8005\u6539\u8fdb\u8fd9\u672c\u5f00\u6e90\u4e66\u3002\n\n[\u5982\u4f55\u8d21\u732e](https://zh-v2.d2l.ai/chapter_appendix-tools-for-deep-learning/contributing.html) | [\u81f4\u8c22](https://zh-v2.d2l.ai/chapter_preface/index.html) | [\u8ba8\u8bba\u6216\u62a5\u544a\u95ee\u9898](https://discuss.d2l.ai/c/chinese-version/16) | [\u5176\u4ed6](INFO.md)\n",
	"arxiv creating-deepfakes deep-face-swap deep-learning deep-neural-networks deepface deepfacelab deepfakes deeplearning face-swap faceswap fakeapp machine-learning neural-nets neural-networks": "\ufeff<table align=\"center\" border=\"0\">\n\n<tr><td colspan=2 align=\"center\">\n\n# DeepFaceLab  \n\n<a href=\"https://arxiv.org/abs/2005.05535\">\n\n<img src=\"https://static.arxiv.org/static/browse/0.3.0/images/icons/favicon.ico\" width=14></img>\nhttps://arxiv.org/abs/2005.05535</a>\n\n\n### the leading software for creating deepfakes\n\n<img src=\"doc/DFL_welcome.png\" align=\"center\">\n\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n<p align=\"center\">\n\n![](doc/logo_tensorflow.png)\n![](doc/logo_cuda.png)\n![](doc/logo_directx.png)\n\n</p>\n\nMore than 95% of deepfake videos are created with DeepFaceLab.\n\nDeepFaceLab is used by such popular youtube channels as\n\n|![](doc/tiktok_icon.png) [deeptomcruise](https://www.tiktok.com/@deeptomcruise)|![](doc/tiktok_icon.png) [1facerussia](https://www.tiktok.com/@1facerussia)|![](doc/tiktok_icon.png) [arnoldschwarzneggar](https://www.tiktok.com/@arnoldschwarzneggar)\n|---|---|---|\n\n|![](doc/tiktok_icon.png) [mariahcareyathome?](https://www.tiktok.com/@mariahcareyathome?)|![](doc/tiktok_icon.png) [diepnep](https://www.tiktok.com/@diepnep)|![](doc/tiktok_icon.png) [mr__heisenberg](https://www.tiktok.com/@mr__heisenberg)|![](doc/tiktok_icon.png) [deepcaprio](https://www.tiktok.com/@deepcaprio)\n|---|---|---|---|\n\n|![](doc/youtube_icon.png) [VFXChris Ume](https://www.youtube.com/channel/UCGf4OlX_aTt8DlrgiH3jN3g/videos)|![](doc/youtube_icon.png) [Sham00k](https://www.youtube.com/channel/UCZXbWcv7fSZFTAZV4beckyw/videos)|\n|---|---|\n\n|![](doc/youtube_icon.png) [Collider videos](https://www.youtube.com/watch?v=A91P2qtPT54&list=PLayt6616lBclvOprvrC8qKGCO-mAhPRux)|![](doc/youtube_icon.png) [iFake](https://www.youtube.com/channel/UCC0lK2Zo2BMXX-k1Ks0r7dg/videos)|![](doc/youtube_icon.png) [NextFace](https://www.youtube.com/channel/UCFh3gL0a8BS21g-DHvXZEeQ/videos)|\n|---|---|---|\n\n|![](doc/youtube_icon.png) [Futuring Machine](https://www.youtube.com/channel/UCC5BbFxqLQgfnWPhprmQLVg)|![](doc/youtube_icon.png) [RepresentUS](https://www.youtube.com/channel/UCRzgK52MmetD9aG8pDOID3g)|![](doc/youtube_icon.png) [Corridor Crew](https://www.youtube.com/c/corridorcrew/videos)|\n|---|---|---|\n\n|![](doc/youtube_icon.png) [DeepFaker](https://www.youtube.com/channel/UCkHecfDTcSazNZSKPEhtPVQ)|![](doc/youtube_icon.png) [DeepFakes in movie](https://www.youtube.com/c/DeepFakesinmovie/videos)|\n|---|---|\n\n|![](doc/youtube_icon.png) [DeepFakeCreator](https://www.youtube.com/channel/UCkNFhcYNLQ5hr6A6lZ56mKA)|![](doc/youtube_icon.png) [Jarkan](https://www.youtube.com/user/Jarkancio/videos)|\n|---|---|\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n# What can I do using DeepFaceLab?\n\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n## Replace the face\n\n<img src=\"doc/replace_the_face.jpg\" align=\"center\">\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n## De-age the face\n\n</td></tr>\n\n<tr><td align=\"center\" width=\"50%\">\n\n<img src=\"doc/deage_0_1.jpg\" align=\"center\">\n\n</td>\n<td align=\"center\" width=\"50%\">\n\n<img src=\"doc/deage_0_2.jpg\" align=\"center\">\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n![](doc/youtube_icon.png) https://www.youtube.com/watch?v=Ddx5B-84ebo\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n## Replace the head\n\n</td></tr>\n\n\n<tr><td align=\"center\" width=\"50%\">\n\n<img src=\"doc/head_replace_0_1.jpg\" align=\"center\">\n\n</td>\n<td align=\"center\" width=\"50%\">\n\n<img src=\"doc/head_replace_0_2.jpg\" align=\"center\">\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n![](doc/youtube_icon.png) https://www.youtube.com/watch?v=xr5FHd0AdlQ\n\n</td></tr>\n\n<tr><td align=\"center\" width=\"50%\">\n\n<img src=\"doc/head_replace_1_1.jpg\" align=\"center\">\n\n</td>\n<td align=\"center\" width=\"50%\">\n\n<img src=\"doc/head_replace_1_2.jpg\" align=\"center\">\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n![](doc/youtube_icon.png) https://www.youtube.com/watch?v=RTjgkhMugVw\n\n</td></tr>\n\n<tr><td align=\"center\" width=\"50%\">\n\n<img src=\"doc/head_replace_2_1.jpg\" align=\"center\">\n\n</td>\n<td align=\"center\" width=\"50%\">\n\n<img src=\"doc/head_replace_2_2.jpg\" align=\"center\">\n\n</td></tr>\n\n<tr><td colspan=2  align=\"center\">\n\n![](doc/youtube_icon.png) https://www.youtube.com/watch?v=R9f7WD0gKPo\n\n</td></tr>\n\n\n<tr><td colspan=2 align=\"center\">\n\n## Manipulate politicians lips\n(voice replacement is not included!)\n(also requires a skill in video editors such as *Adobe After Effects* or *Davinci Resolve*)\n\n<img src=\"doc/political_speech2.jpg\" align=\"center\">\n\n![](doc/youtube_icon.png) https://www.youtube.com/watch?v=IvY-Abd2FfM\n\n<img src=\"doc/political_speech3.jpg\" align=\"center\">\n\n![](doc/youtube_icon.png) https://www.youtube.com/watch?v=ERQlaJ_czHU\n\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n# Deepfake native resolution progress\n\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n<img src=\"doc/deepfake_progress.png\" align=\"center\">\n\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n<img src=\"doc/make_everything_ok.png\" align=\"center\">\n\nUnfortunately, there is no \"make everything ok\" button in DeepFaceLab. You should spend time studying the workflow and growing your skills. A skill in programs such as *AfterEffects* or *Davinci Resolve* is also desirable.\n\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n## Mini tutorial\n\n<a href=\"https://www.youtube.com/watch?v=kOIMXt8KK8M\">\n\n<img src=\"doc/mini_tutorial.jpg\" align=\"center\">\n\n</a>\n\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n## Releases\n\n</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://tinyurl.com/2p9cvt25\">Windows (magnet link)</a>\n</td><td align=\"center\">Last release. Use torrent client to download.</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://mega.nz/folder/Po0nGQrA#dbbttiNWojCt8jzD4xYaPw\">Windows (Mega.nz)</a>\n</td><td align=\"center\">Contains new and prev releases.</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://disk.yandex.ru/d/7i5XTKIKVg5UUg\">Windows (yandex.ru)</a>\n</td><td align=\"center\">Contains new and prev releases.</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://github.com/chervonij/DFL-Colab\">Google Colab (github)</a>\n</td><td align=\"center\">by @chervonij . You can train fakes for free using Google Colab.</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://github.com/nagadit/DeepFaceLab_Linux\">Linux (github)</a>\n</td><td align=\"center\">by @nagadit</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://github.com/elemantalcode/dfl\">CentOS Linux (github)</a>\n</td><td align=\"center\">May be outdated. By @elemantalcode</td></tr>\n\n</table>\n\n<table align=\"center\" border=\"0\">\n\n<tr><td colspan=2 align=\"center\">\n\n## Links\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n### Guides and tutorials\n\n</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide\">DeepFaceLab guide</a>\n</td><td align=\"center\">Main guide</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=18459#pid18459\">Faceset creation guide</a>\n</td><td align=\"center\">How to create the right faceset</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://mrdeepfakes.com/forums/thread-guide-deepfacelab-google-colab-tutorial\">Google Colab guide</a>\n</td><td align=\"center\">Guide how to train the fake on Google Colab</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://mrdeepfakes.com/forums/thread-deepfacelab-2-0-compositing-in-davinci-resolve-vegas-pro-and-after-effects\">Compositing</a>\n</td><td align=\"center\">To achieve the highest quality, compose deepfake manually in video editors such as Davinci Resolve or Adobe AfterEffects</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://mrdeepfakes.com/forums/thread-deepfacelab-2-0-discussion-tips-suggestions\">Discussion and suggestions</a>\n</td><td align=\"center\"></td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n### Supplementary material\n\n</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://mrdeepfakes.com/forums/forum-celebrity-facesets\">Ready to work facesets</a>\n</td><td align=\"center\">Celebrity facesets made by community</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://mrdeepfakes.com/forums/forum-trained-models\">Pretrained models</a>\n</td><td align=\"center\">Pretrained models made by community</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n### Communication groups\n\n</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://discord.gg/rxa7h9M6rH\">Discord</a>\n</td><td align=\"center\">Official discord channel. English / Russian.</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://t.me/joinchat/ElkhqlgJ0I5HhdJyFar80w\">Telegram group</a>\n</td><td align=\"center\">Official telegram group. English / Russian. For anonymous communication. Don't forget to hide your phone number</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://mrdeepfakes.com/forums/forum-russian-community\">\u0420\u0443\u0441\u0441\u043a\u0438\u0439 \u0444\u043e\u0440\u0443\u043c</a>\n</td><td align=\"center\"></td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://mrdeepfakes.com/forums/\">mrdeepfakes</a>\n</td><td align=\"center\">the biggest NSFW English community</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://www.reddit.com/r/DeepFakesSFW/new/\">reddit r/DeepFakesSFW/</a>\n</td><td align=\"center\">Post your deepfakes there !</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://www.reddit.com/r/RUdeepfakes/new/\">reddit r/RUdeepfakes/</a>\n</td><td align=\"center\">\u041f\u043e\u0441\u0442\u0438\u043c \u0440\u0443\u0441\u0441\u043a\u0438\u0435 \u0434\u0438\u043f\u0444\u0435\u0439\u043a\u0438 \u0441\u044e\u0434\u0430 !</td></tr>\n\n<tr><td align=\"right\">\nQQ\u7fa4124500433\n</td><td align=\"center\">\u4e2d\u6587\u4ea4\u6d41QQ\u7fa4\uff0c\u5546\u52a1\u5408\u4f5c\u627e\u7fa4\u4e3b</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://www.dfldata.xyz\">dfldata.xyz</a>\n</td><td align=\"center\">\u4e2d\u6587\u4ea4\u6d41\u8bba\u575b\uff0c\u514d\u8d39\u8f6f\u4ef6\u6559\u7a0b\u3001\u6a21\u578b\u3001\u4eba\u8138\u6570\u636e</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://www.deepfaker.xyz/\">deepfaker.xyz</a>\n</td><td align=\"center\">\u4e2d\u6587\u5b66\u4e60\u7ad9\uff08\u975e\u5b98\u65b9)</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n## Related works\n\n</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://github.com/iperov/DeepFaceLive\">DeepFaceLive</a>\n</td><td align=\"center\">Real-time face swap for PC streaming or video calls</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://github.com/neuralchen/SimSwap\">neuralchen/SimSwap</a>\n</td><td align=\"center\">Swapping face using ONE single photo \u4e00\u5f20\u56fe\u514d\u8bad\u7ec3\u6362\u8138</td></tr>\n\n<tr><td align=\"right\">\n<a href=\"https://github.com/deepfakes/faceswap\">deepfakes/faceswap</a>\n</td><td align=\"center\">Something that was before DeepFaceLab and still remains in the past</td></tr>\n\n</td></tr>\n</table>\n\n<table align=\"center\" border=\"0\">\n\n<tr><td colspan=2 align=\"center\">\n\n## How I can help the project?\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n### Sponsor deepfake research and DeepFaceLab development.\n\n</td></tr>\n<!--\n<tr><td colspan=2 align=\"center\">\n<a href=\"https://www.paypal.com/paypalme/DeepFaceLab\">Donate via Paypal</a>\n</td></tr>\n-->\n<tr><td colspan=2 align=\"center\">\n<a href=\"https://money.yandex.ru/to/41001142318065\">Donate via Yandex.Money</a>\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\nbitcoin:bc1qkhh7h0gwwhxgg6h6gpllfgstkd645fefrd5s6z\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n### Collect facesets\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\nYou can collect faceset of any celebrity that can be used in DeepFaceLab and share it <a href=\"https://mrdeepfakes.com/forums/forum-celebrity-facesets\">in the community</a>\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n### Star this repo\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\nRegister github account and push \"Star\" button.\n\n</td></tr>\n\n</table>\n\n\n\n<table align=\"center\" border=\"0\">\n<tr><td colspan=2 align=\"center\">\n\n## Meme zone\n\n</td></tr>\n\n<tr><td align=\"center\" width=\"50%\">\n\n<img src=\"doc/meme1.jpg\" align=\"center\">\n\n</td>\n\n<td align=\"center\" width=\"50%\">\n\n<img src=\"doc/meme2.jpg\" align=\"center\">\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n<sub>#deepfacelab #deepfakes #faceswap #face-swap #deep-learning #deeplearning #deep-neural-networks #deepface #deep-face-swap #fakeapp #fake-app #neural-networks #neural-nets #tensorflow #cuda #nvidia</sub>\n\n</td></tr>\n\n\n\n</table>\n",
	"deep-learning machine-learning vision": "# Caffe\n\n[![Build Status](https://travis-ci.org/BVLC/caffe.svg?branch=master)](https://travis-ci.org/BVLC/caffe)\n[![License](https://img.shields.io/badge/license-BSD-blue.svg)](LICENSE)\n\nCaffe is a deep learning framework made with expression, speed, and modularity in mind.\nIt is developed by Berkeley AI Research ([BAIR](http://bair.berkeley.edu))/The Berkeley Vision and Learning Center (BVLC) and community contributors.\n\nCheck out the [project site](http://caffe.berkeleyvision.org) for all the details like\n\n- [DIY Deep Learning for Vision with Caffe](https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit#slide=id.p)\n- [Tutorial Documentation](http://caffe.berkeleyvision.org/tutorial/)\n- [BAIR reference models](http://caffe.berkeleyvision.org/model_zoo.html) and the [community model zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo)\n- [Installation instructions](http://caffe.berkeleyvision.org/installation.html)\n\nand step-by-step examples.\n\n## Custom distributions\n\n - [Intel Caffe](https://github.com/BVLC/caffe/tree/intel) (Optimized for CPU and support for multi-node), in particular Intel\u00ae Xeon processors.\n- [OpenCL Caffe](https://github.com/BVLC/caffe/tree/opencl) e.g. for AMD or Intel devices.\n- [Windows Caffe](https://github.com/BVLC/caffe/tree/windows)\n\n## Community\n\n[![Join the chat at https://gitter.im/BVLC/caffe](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/BVLC/caffe?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nPlease join the [caffe-users group](https://groups.google.com/forum/#!forum/caffe-users) or [gitter chat](https://gitter.im/BVLC/caffe) to ask questions and talk about methods and models.\nFramework development discussions and thorough bug reports are collected on [Issues](https://github.com/BVLC/caffe/issues).\n\nHappy brewing!\n\n## License and Citation\n\nCaffe is released under the [BSD 2-Clause license](https://github.com/BVLC/caffe/blob/master/LICENSE).\nThe BAIR/BVLC reference models are released for unrestricted use.\n\nPlease cite Caffe in your publications if it helps your research:\n\n    @article{jia2014caffe,\n      Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},\n      Journal = {arXiv preprint arXiv:1408.5093},\n      Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},\n      Year = {2014}\n    }\n",
	"coreml deep-learning ios machine-learning ml object-detection onnx pytorch tflite yolo yolov3 yolov4 yolov5": "<div align=\"center\">\n<p>\n   <a align=\"left\" href=\"https://ultralytics.com/yolov3\" target=\"_blank\">\n   <img width=\"850\" src=\"https://user-images.githubusercontent.com/26833433/99805965-8f2ca800-2b3d-11eb-8fad-13a96b222a23.jpg\"></a>\n</p>\n<br>\n<div>\n   <a href=\"https://github.com/ultralytics/yolov3/actions\"><img src=\"https://github.com/ultralytics/yolov3/workflows/CI%20CPU%20testing/badge.svg\" alt=\"CI CPU testing\"></a>\n   <a href=\"https://zenodo.org/badge/latestdoi/264818686\"><img src=\"https://zenodo.org/badge/264818686.svg\" alt=\"YOLOv3 Citation\"></a>\n   <a href=\"https://hub.docker.com/r/ultralytics/yolov3\"><img src=\"https://img.shields.io/docker/pulls/ultralytics/yolov3?logo=docker\" alt=\"Docker Pulls\"></a>\n   <br>\n   <a href=\"https://colab.research.google.com/github/ultralytics/yolov3/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n   <a href=\"https://www.kaggle.com/ultralytics/yolov3\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n   <a href=\"https://join.slack.com/t/ultralytics/shared_invite/zt-w29ei8bp-jczz7QYUmDtgo6r6KcMIAg\"><img src=\"https://img.shields.io/badge/Slack-Join_Forum-blue.svg?logo=slack\" alt=\"Join Forum\"></a>\n</div>\n<br>\n<div align=\"center\">\n   <a href=\"https://github.com/ultralytics\">\n   <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-github.png\" width=\"2%\"/>\n   </a>\n   <img width=\"2%\" />\n   <a href=\"https://www.linkedin.com/company/ultralytics\">\n   <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-linkedin.png\" width=\"2%\"/>\n   </a>\n   <img width=\"2%\" />\n   <a href=\"https://twitter.com/ultralytics\">\n   <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-twitter.png\" width=\"2%\"/>\n   </a>\n   <img width=\"2%\" />\n   <a href=\"https://youtube.com/ultralytics\">\n   <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-youtube.png\" width=\"2%\"/>\n   </a>\n   <img width=\"2%\" />\n   <a href=\"https://www.facebook.com/ultralytics\">\n   <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-facebook.png\" width=\"2%\"/>\n   </a>\n   <img width=\"2%\" />\n   <a href=\"https://www.instagram.com/ultralytics/\">\n   <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-instagram.png\" width=\"2%\"/>\n   </a>\n</div>\n\n<br>\n<p>\nYOLOv3 \ud83d\ude80 is a family of object detection architectures and models pretrained on the COCO dataset, and represents <a href=\"https://ultralytics.com\">Ultralytics</a>\n open-source research into future vision AI methods, incorporating lessons learned and best practices evolved over thousands of hours of research and development.\n</p>\n\n<!--\n<a align=\"center\" href=\"https://ultralytics.com/yolov3\" target=\"_blank\">\n<img width=\"800\" src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/banner-api.png\"></a>\n-->\n\n</div>\n\n## <div align=\"center\">Documentation</div>\n\nSee the [YOLOv3 Docs](https://docs.ultralytics.com) for full documentation on training, testing and deployment.\n\n## <div align=\"center\">Quick Start Examples</div>\n\n<details open>\n<summary>Install</summary>\n\n[**Python>=3.6.0**](https://www.python.org/) is required with all\n[requirements.txt](https://github.com/ultralytics/yolov3/blob/master/requirements.txt) installed including\n[**PyTorch>=1.7**](https://pytorch.org/get-started/locally/):\n<!-- $ sudo apt update && apt install -y libgl1-mesa-glx libsm6 libxext6 libxrender-dev -->\n\n```bash\n$ git clone https://github.com/ultralytics/yolov3\n$ cd yolov3\n$ pip install -r requirements.txt\n```\n\n</details>\n\n<details open>\n<summary>Inference</summary>\n\nInference with YOLOv3 and [PyTorch Hub](https://github.com/ultralytics/yolov5/issues/36). Models automatically download\nfrom the [latest YOLOv3 release](https://github.com/ultralytics/yolov3/releases).\n\n```python\nimport torch\n\n# Model\nmodel = torch.hub.load('ultralytics/yolov3', 'yolov3')  # or yolov3-spp, yolov3-tiny, custom\n\n# Images\nimg = 'https://ultralytics.com/images/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list\n\n# Inference\nresults = model(img)\n\n# Results\nresults.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n```\n\n</details>\n\n\n\n<details>\n<summary>Inference with detect.py</summary>\n\n`detect.py` runs inference on a variety of sources, downloading models automatically from\nthe [latest YOLOv3 release](https://github.com/ultralytics/yolov3/releases) and saving results to `runs/detect`.\n\n```bash\n$ python detect.py --source 0  # webcam\n                            img.jpg  # image\n                            vid.mp4  # video\n                            path/  # directory\n                            path/*.jpg  # glob\n                            'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n                            'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n```\n\n</details>\n\n<details>\n<summary>Training</summary>\n\n\n\n<img width=\"800\" src=\"https://user-images.githubusercontent.com/26833433/90222759-949d8800-ddc1-11ea-9fa1-1c97eed2b963.png\">\n\n</details>\n\n<details open>\n<summary>Tutorials</summary>\n\n* [Train Custom Data](https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data)&nbsp; \ud83d\ude80 RECOMMENDED\n* [Tips for Best Training Results](https://github.com/ultralytics/yolov3/wiki/Tips-for-Best-Training-Results)&nbsp; \u2618\ufe0f\n  RECOMMENDED\n* [Weights & Biases Logging](https://github.com/ultralytics/yolov5/issues/1289)&nbsp; \ud83c\udf1f NEW\n* [Roboflow for Datasets, Labeling, and Active Learning](https://github.com/ultralytics/yolov5/issues/4975)&nbsp; \ud83c\udf1f NEW\n* [Multi-GPU Training](https://github.com/ultralytics/yolov5/issues/475)\n* [PyTorch Hub](https://github.com/ultralytics/yolov5/issues/36)&nbsp; \u2b50 NEW\n* [TorchScript, ONNX, CoreML Export](https://github.com/ultralytics/yolov5/issues/251) \ud83d\ude80\n* [Test-Time Augmentation (TTA)](https://github.com/ultralytics/yolov5/issues/303)\n* [Model Ensembling](https://github.com/ultralytics/yolov5/issues/318)\n* [Model Pruning/Sparsity](https://github.com/ultralytics/yolov5/issues/304)\n* [Hyperparameter Evolution](https://github.com/ultralytics/yolov5/issues/607)\n* [Transfer Learning with Frozen Layers](https://github.com/ultralytics/yolov5/issues/1314)&nbsp; \u2b50 NEW\n* [TensorRT Deployment](https://github.com/wang-xinyu/tensorrtx)\n\n</details>\n\n## <div align=\"center\">Environments</div>\n\nGet started in seconds with our verified environments. Click each icon below for details.\n\n<div align=\"center\">\n    <a href=\"https://colab.research.google.com/github/ultralytics/yolov3/blob/master/tutorial.ipynb\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-colab-small.png\" width=\"15%\"/>\n    </a>\n    <a href=\"https://www.kaggle.com/ultralytics/yolov3\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-kaggle-small.png\" width=\"15%\"/>\n    </a>\n    <a href=\"https://hub.docker.com/r/ultralytics/yolov3\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-docker-small.png\" width=\"15%\"/>\n    </a>\n    <a href=\"https://github.com/ultralytics/yolov3/wiki/AWS-Quickstart\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-aws-small.png\" width=\"15%\"/>\n    </a>\n    <a href=\"https://github.com/ultralytics/yolov3/wiki/GCP-Quickstart\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-gcp-small.png\" width=\"15%\"/>\n    </a>\n</div>\n\n## <div align=\"center\">Integrations</div>\n\n<div align=\"center\">\n    <a href=\"https://wandb.ai/site?utm_campaign=repo_yolo_readme\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-wb-long.png\" width=\"49%\"/>\n    </a>\n    <a href=\"https://roboflow.com/?ref=ultralytics\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-roboflow-long.png\" width=\"49%\"/>\n    </a>\n</div>\n\n|Weights and Biases|Roboflow \u2b50 NEW|\n|:-:|:-:|\n|Automatically track and visualize all your YOLOv3 training runs in the cloud with [Weights & Biases](https://wandb.ai/site?utm_campaign=repo_yolo_readme)|Label and export your custom datasets directly to YOLOv3 for training with [Roboflow](https://roboflow.com/?ref=ultralytics) |\n\n\n## <div align=\"center\">Why YOLOv5</div>\n\n<p align=\"left\"><img width=\"800\" src=\"https://user-images.githubusercontent.com/26833433/136901921-abcfcd9d-f978-4942-9b97-0e3f202907df.png\"></p>\n<details>\n  <summary>YOLOv3-P5 640 Figure (click to expand)</summary>\n\n<p align=\"left\"><img width=\"800\" src=\"https://user-images.githubusercontent.com/26833433/136763877-b174052b-c12f-48d2-8bc4-545e3853398e.png\"></p>\n</details>\n<details>\n  <summary>Figure Notes (click to expand)</summary>\n\n* **COCO AP val** denotes mAP@0.5:0.95 metric measured on the 5000-image [COCO val2017](http://cocodataset.org) dataset over various inference sizes from 256 to 1536.\n* **GPU Speed** measures average inference time per image on [COCO val2017](http://cocodataset.org) dataset using a [AWS p3.2xlarge](https://aws.amazon.com/ec2/instance-types/p3/) V100 instance at batch-size 32.\n* **EfficientDet** data from [google/automl](https://github.com/google/automl) at batch size 8.\n* **Reproduce** by `python val.py --task study --data coco.yaml --iou 0.7 --weights yolov5n6.pt yolov5s6.pt yolov5m6.pt yolov5l6.pt yolov5x6.pt`\n</details>\n\n### Pretrained Checkpoints\n\n[assets]: https://github.com/ultralytics/yolov5/releases\n[TTA]: https://github.com/ultralytics/yolov5/issues/303\n\n|Model |size<br><sup>(pixels) |mAP<sup>val<br>0.5:0.95 |mAP<sup>val<br>0.5 |Speed<br><sup>CPU b1<br>(ms) |Speed<br><sup>V100 b1<br>(ms) |Speed<br><sup>V100 b32<br>(ms) |params<br><sup>(M) |FLOPs<br><sup>@640 (B)\n|---                    |---  |---    |---    |---    |---    |---    |---    |---\n|[YOLOv5n][assets]      |640  |28.4   |46.0   |**45** |**6.3**|**0.6**|**1.9**|**4.5**\n|[YOLOv5s][assets]      |640  |37.2   |56.0   |98     |6.4    |0.9    |7.2    |16.5\n|[YOLOv5m][assets]      |640  |45.2   |63.9   |224    |8.2    |1.7    |21.2   |49.0\n|[YOLOv5l][assets]      |640  |48.8   |67.2   |430    |10.1   |2.7    |46.5   |109.1\n|[YOLOv5x][assets]      |640  |50.7   |68.9   |766    |12.1   |4.8    |86.7   |205.7\n|                       |     |       |       |       |       |       |       |\n|[YOLOv5n6][assets]     |1280 |34.0   |50.7   |153    |8.1    |2.1    |3.2    |4.6\n|[YOLOv5s6][assets]     |1280 |44.5   |63.0   |385    |8.2    |3.6    |16.8   |12.6\n|[YOLOv5m6][assets]     |1280 |51.0   |69.0   |887    |11.1   |6.8    |35.7   |50.0\n|[YOLOv5l6][assets]     |1280 |53.6   |71.6   |1784   |15.8   |10.5   |76.8   |111.4\n|[YOLOv5x6][assets]<br>+ [TTA][TTA]|1280<br>1536 |54.7<br>**55.4** |**72.4**<br>72.3 |3136<br>- |26.2<br>- |19.4<br>- |140.7<br>- |209.8<br>-\n\n<details>\n  <summary>Table Notes (click to expand)</summary>\n\n* All checkpoints are trained to 300 epochs with default settings and hyperparameters.\n* **mAP<sup>val</sup>** values are for single-model single-scale on [COCO val2017](http://cocodataset.org) dataset.<br>Reproduce by `python val.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65`\n* **Speed** averaged over COCO val images using a [AWS p3.2xlarge](https://aws.amazon.com/ec2/instance-types/p3/) instance. NMS times (~1 ms/img) not included.<br>Reproduce by `python val.py --data coco.yaml --img 640 --conf 0.25 --iou 0.45`\n* **TTA** [Test Time Augmentation](https://github.com/ultralytics/yolov5/issues/303) includes reflection and scale augmentations.<br>Reproduce by `python val.py --data coco.yaml --img 1536 --iou 0.7 --augment`\n\n</details>\n\n## <div align=\"center\">Contribute</div>\n\nWe love your input! We want to make contributing to YOLOv3 as easy and transparent as possible. Please see our [Contributing Guide](CONTRIBUTING.md) to get started, and fill out the [YOLOv3 Survey](https://ultralytics.com/survey?utm_source=github&utm_medium=social&utm_campaign=Survey) to send us feedback on your experiences. Thank you to all our contributors!\n\n<a href=\"https://github.com/ultralytics/yolov3/graphs/contributors\"><img src=\"https://opencollective.com/ultralytics/contributors.svg?width=990\" /></a>\n\n\n## <div align=\"center\">Contact</div>\n\nFor YOLOv3 bugs and feature requests please visit [GitHub Issues](https://github.com/ultralytics/yolov3/issues). For business inquiries or\nprofessional support requests please visit [https://ultralytics.com/contact](https://ultralytics.com/contact).\n\n<br>\n\n<div align=\"center\">\n    <a href=\"https://github.com/ultralytics\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-github.png\" width=\"3%\"/>\n    </a>\n    <img width=\"3%\" />\n    <a href=\"https://www.linkedin.com/company/ultralytics\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-linkedin.png\" width=\"3%\"/>\n    </a>\n    <img width=\"3%\" />\n    <a href=\"https://twitter.com/ultralytics\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-twitter.png\" width=\"3%\"/>\n    </a>\n    <img width=\"3%\" />\n    <a href=\"https://youtube.com/ultralytics\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-youtube.png\" width=\"3%\"/>\n    </a>\n    <img width=\"3%\" />\n    <a href=\"https://www.facebook.com/ultralytics\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-facebook.png\" width=\"3%\"/>\n    </a>\n    <img width=\"3%\" />\n    <a href=\"https://www.instagram.com/ultralytics/\">\n        <img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/logo-social-instagram.png\" width=\"3%\"/>\n    </a>\n</div>\n",
	"coursera machine-learning": "**\u65af\u5766\u798f\u5927\u5b662014\uff08\u5434\u6069\u8fbe\uff09\u673a\u5668\u5b66\u4e60\u6559\u7a0b\u4e2d\u6587\u7b14\u8bb0**\n\n\u8bfe\u7a0b\u5730\u5740\uff1a<https://www.coursera.org/course/ml>\n\n[**\u7b14\u8bb0\u5728\u7ebf\u9605\u8bfb**](http://www.ai-start.com/ml2014)\n\n**Machine Learning**(\u673a\u5668\u5b66\u4e60)\u662f\u7814\u7a76\u8ba1\u7b97\u673a\u600e\u6837\u6a21\u62df\u6216\u5b9e\u73b0\u4eba\u7c7b\u7684\u5b66\u4e60\u884c\u4e3a\uff0c\u4ee5\u83b7\u53d6\u65b0\u7684\u77e5\u8bc6\u6216\u6280\u80fd\uff0c\u91cd\u65b0\u7ec4\u7ec7\u5df2\u6709\u7684\u77e5\u8bc6\u7ed3\u6784\u4f7f\u4e4b\u4e0d\u65ad\u6539\u5584\u81ea\u8eab\u7684\u6027\u80fd\u3002\u5b83\u662f\u4eba\u5de5\u667a\u80fd\u7684\u6838\u5fc3\uff0c\u662f\u4f7f\u8ba1\u7b97\u673a\u5177\u6709\u667a\u80fd\u7684\u6839\u672c\u9014\u5f84\uff0c\u5176\u5e94\u7528\u904d\u53ca\u4eba\u5de5\u667a\u80fd\u7684\u5404\u4e2a\u9886\u57df\uff0c\u5b83\u4e3b\u8981\u4f7f\u7528\u5f52\u7eb3\u3001\u7efc\u5408\u800c\u4e0d\u662f\u6f14\u8bd1\u3002\u5728\u8fc7\u53bb\u7684\u5341\u5e74\u4e2d\uff0c\u673a\u5668\u5b66\u4e60\u5e2e\u52a9\u6211\u4eec\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff0c\u6709\u6548\u7684\u8bed\u97f3\u8bc6\u522b\uff0c\u6709\u6548\u7684\u7f51\u7edc\u641c\u7d22\uff0c\u5e76\u6781\u5927\u5730\u63d0\u9ad8\u4e86\u4eba\u7c7b\u57fa\u56e0\u7ec4\u7684\u8ba4\u8bc6\u3002\u673a\u5668\u5b66\u4e60\u662f\u5f53\u4eca\u975e\u5e38\u666e\u904d\uff0c\u4f60\u53ef\u80fd\u4f1a\u4f7f\u7528\u8fd9\u4e00\u5929\u51e0\u5341\u500d\u800c\u4e0d\u81ea\u77e5\u3002\u5f88\u591a\u7814\u7a76\u8005\u4e5f\u8ba4\u4e3a\u8fd9\u662f\u6700\u597d\u7684\u4eba\u5de5\u667a\u80fd\u7684\u53d6\u5f97\u65b9\u5f0f\u3002\u5728\u672c\u8bfe\u4e2d\uff0c\u60a8\u5c06\u5b66\u4e60\u6700\u6709\u6548\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5e76\u83b7\u5f97\u5b9e\u8df5\uff0c\u8ba9\u5b83\u4eec\u4e3a\u81ea\u5df1\u7684\u5de5\u4f5c\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u4f60\u4f1a\u4e0d\u4ec5\u5f97\u5230\u7406\u8bba\u57fa\u7840\u7684\u5b66\u4e60\uff0c\u800c\u4e14\u83b7\u5f97\u90a3\u4e9b\u9700\u8981\u5feb\u901f\u548c\u5f3a\u5927\u7684\u5e94\u7528\u6280\u672f\u89e3\u51b3\u95ee\u9898\u7684\u5b9e\u7528\u6280\u672f\u3002\u6700\u540e\uff0c\u4f60\u4f1a\u5b66\u5230\u4e00\u4e9b\u7845\u8c37\u5229\u7528\u673a\u5668\u5b66\u4e60\u548c\u4eba\u5de5\u667a\u80fd\u7684\u6700\u4f73\u5b9e\u8df5\u521b\u65b0\u3002\n\n\u672c\u8bfe\u7a0b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e7f\u6cdb\u7684\u4ecb\u7ecd\u673a\u5668\u5b66\u4e60\u3001\u6570\u636e\u6316\u6398\u3001\u7edf\u8ba1\u6a21\u5f0f\u8bc6\u522b\u7684\u8bfe\u7a0b\u3002\u4e3b\u9898\u5305\u62ec\uff1a\n\n\uff08\u4e00\uff09\u76d1\u7763\u5b66\u4e60\uff08\u53c2\u6570/\u975e\u53c2\u6570\u7b97\u6cd5\uff0c\u652f\u6301\u5411\u91cf\u673a\uff0c\u6838\u51fd\u6570\uff0c\u795e\u7ecf\u7f51\u7edc\uff09\u3002\n\n\uff08\u4e8c\uff09\u65e0\u76d1\u7763\u5b66\u4e60\uff08\u805a\u7c7b\uff0c\u964d\u7ef4\uff0c\u63a8\u8350\u7cfb\u7edf\uff0c\u6df1\u5165\u5b66\u4e60\u63a8\u8350\uff09\u3002\n\n\uff08\u4e09\uff09\u5728\u673a\u5668\u5b66\u4e60\u7684\u6700\u4f73\u5b9e\u8df5\uff08\u504f\u5dee/\u65b9\u5dee\u7406\u8bba\uff1b\u5728\u673a\u5668\u5b66\u4e60\u548c\u4eba\u5de5\u667a\u80fd\u521b\u65b0\u8fc7\u7a0b\uff09\u3002\u672c\u8bfe\u7a0b\u8fd8\u5c06\u4f7f\u7528\u5927\u91cf\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u60a8\u8fd8\u5c06\u5b66\u4e60\u5982\u4f55\u8fd0\u7528\u5b66\u4e60\u7b97\u6cd5\u6784\u5efa\u667a\u80fd\u673a\u5668\u4eba\uff08\u611f\u77e5\uff0c\u63a7\u5236\uff09\uff0c\u6587\u672c\u7684\u7406\u89e3\uff08**Web**\u641c\u7d22\uff0c\u53cd\u5783\u573e\u90ae\u4ef6\uff09\uff0c\u8ba1\u7b97\u673a\u89c6\u89c9\uff0c\u533b\u7597\u4fe1\u606f\uff0c\u97f3\u9891\uff0c\u6570\u636e\u6316\u6398\uff0c\u548c\u5176\u4ed6\u9886\u57df\u3002\n\n\u672c\u8bfe\u7a0b\u9700\u898110\u5468\u517118\u8282\u8bfe\uff0c\u76f8\u5bf9\u4ee5\u524d\u7684\u673a\u5668\u5b66\u4e60\u89c6\u9891\uff0c\u8fd9\u4e2a\u89c6\u9891\u66f4\u52a0\u6e05\u6670\uff0c\u800c\u4e14\u6bcf\u8bfe\u90fd\u6709**ppt**\u8bfe\u4ef6\uff0c\u63a8\u8350\u5b66\u4e60\u3002\n\n\u672c\u4eba2014\u5e74\u4e0b\u534a\u5e74\u5f00\u59cb\u7ffb\u8bd1\u672c\u8bfe\u7a0b\u5b57\u5e55\uff0c\u5e76\u5199\u4e86\u8bfe\u7a0b\u7684\u4e2d\u6587\u7b14\u8bb0\u3002\u7b14\u8bb0\u88ab\u4e0b\u8f7d\u4e86\u51e0\u4e07\u6b21\uff0c\u5e94\u8be5\u5e2e\u52a9\u4e86\u4e0d\u5c11\u4eba\uff0c\u4e5f\u6709\u5f88\u591a\u4eba\u4e00\u76f4\u5728\u5e2e\u52a9\u6211\uff0c\u73b0\u5728\u6211\u628a\u7b14\u8bb0\u7684**word**\u539f\u7a3f\u548c**markdown**\u539f\u7a3f\u5206\u4eab\u7ed9\u5927\u5bb6\u3002\n\n**markdown**\u7684\u7b14\u8bb0\u548c\u8bfe\u7a0b\u4e2d\u82f1\u6587\u5b57\u5e55\u6211\u5c06\u653e\u5728**github**\uff0c\u5e0c\u671b\u5927\u5bb6\u80fd\u7ee7\u7eed\u5b8c\u5584\u3002\u4e3a\u65b9\u4fbf\u6570\u5b66\u516c\u5f0f\u7684\u5728\u7ebf\u663e\u793a\uff0c\u5728\u7ebf\u89c2\u770b\u7684\u662f**html**\u6587\u4ef6\uff0c\u516c\u5f0f\u5df2\u7ecf\u88ab\u8f6c\u4e3a\u56fe\u7247\uff0c\u516c\u5f0f\u6e90\u7801\u5728**markdown**\u6587\u4ef6\u3002\n\n**\u6700\u540e\u60f3\u5bf9\u5404\u4f4d\u670b\u53cb\u8bf4\uff1a**\n**\u8d60\u4eba\u73ab\u7470\uff0c\u624b\u6709\u4f59\u9999\uff01**\n**\u5728\u4eba\u5de5\u667a\u80fd\u7684\u9053\u8def\u4e0a\uff0c\u4f60\u4e0d\u662f\u4e00\u4e2a\u4eba\u5728\u6218\u6597\uff01**\n\n\u9ec4\u6d77\u5e7f\n\n2018-3-26 \u591c\n\n\u5fae\u4fe1\u516c\u4f17\u53f7\uff1a\u673a\u5668\u5b66\u4e60\u521d\u5b66\u8005 ![gongzhong](images/gongzhong.jpg)\n[\u6211\u7684\u77e5\u4e4e](https://www.zhihu.com/people/fengdu78/activities)\n\n\u53c2\u8003\uff1a\n\n1. https://www.coursera.org/course/ml \u673a\u5668\u5b66\u4e60\u516c\u5f00\u8bfe\n2. https://mooc.guokr.com/note/12/ [\u5c0f\u5c0f\u4eba_V](https://mooc.guokr.com/user/2133483357/) \u7684\u4e2a\u4eba\u7b14\u8bb0\n\n3. \u300a\u7edf\u8ba1\u5b66\u4e60\u65b9\u6cd5\u300b\u674e\u822a   \n4. \u300a\u673a\u5668\u5b66\u4e60\u8bfe\u300b\u90b9\u535a\n\n\u5907\u6ce8\uff1a\u5434\u6069\u8fbe\u8001\u5e08\u7684\u6df1\u5ea6\u5b66\u4e60\u8bfe\uff08deepLearning.ai\uff09\u7684\u7b14\u8bb0\u5730\u5740\uff1ahttps://github.com/fengdu78/deeplearning_ai_books\n\n-----------------------\n\n\u6587\u4ef6\u5939\u8bf4\u660e\uff1a\n\n**docx**\uff1a\u7b14\u8bb0\u7684**word**\u7248\u672c\n\n**markdown**\uff1a\u7b14\u8bb0\u7684**markdown**\u7248\u672c\n\n**html**\uff1a\u7b14\u8bb0\u7684**html**\u7248\u672c\n\n**images**\uff1a\u7b14\u8bb0\u7684\u56fe\u7247\n\n**ppt**\uff1a\u8bfe\u7a0b\u7684\u539f\u7248\u8bfe\u4ef6\n\n**srt**\uff1a\u8bfe\u7a0b\u7684\u4e2d\u82f1\u6587\u5b57\u5e55\uff08**mp4**\u6587\u4ef6\u9700\u8981\u5728\u767e\u5ea6\u4e91\u4e0b\u8f7d\uff0c\u5927\u5bb6\u53ef\u4ee5\u7528\u8bb0\u4e8b\u672c\u6216\u8005\u5b57\u5e55\u7f16\u8f91\u8f6f\u4ef6\u6765\u7f16\u8f91\u5b57\u5e55\uff0c\u5171\u540c\u5b8c\u5584\u3002\n\n\u767e\u5ea6\u4e91\u94fe\u63a5\uff1ahttps://pan.baidu.com/s/1h8QjqBlOm0Exh7orm9teMQ \u5bc6\u7801\uff1ad3we\uff0c\u4e0b\u8f7d\u540e\u89e3\u538b\uff09\n\n**code**\uff1a\u8bfe\u7a0b\u7684**python**\u4ee3\u7801\n\n\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b\u89c6\u9891\uff1ahttps://www.bilibili.com/video/BV1W34y1i7xK\n\n[\u7b14\u8bb0\u5728\u7ebf\u9605\u8bfb](http://www.ai-start.com/ml2014)\n\n\u7b14\u8bb0pdf\u7248\u672c\u4e0b\u8f7d \uff1a\u89c1**Github**\u6839\u76ee\u5f55\u3002\n\n\u673a\u5668\u5b66\u4e60qq\u7fa4\uff1a955171419\uff08\u6211\u4eec\u670913\u4e2a\u7fa4\uff0c\u52a0\u8fc7\u4e00\u4e2a\u5c31\u4e0d\u9700\u8981\u52a0\u4e86\uff09\n\n-----------------------\n\n# \u673a\u5668\u5b66\u4e60\u6559\u7a0b\u4e2d\u6587\u7b14\u8bb0\u76ee\u5f55\n\n- [\u7b2c\u4e00\u5468](markdown/week1.md)\n\n\u4e00\u3001 \u5f15\u8a00(**Introduction**) \n\n1.1 \u6b22\u8fce \n\n1.2 \u673a\u5668\u5b66\u4e60\u662f\u4ec0\u4e48\uff1f \n\n1.3 \u76d1\u7763\u5b66\u4e60 \n\n1.4 \u65e0\u76d1\u7763\u5b66\u4e60 \n\n\u4e8c\u3001\u5355\u53d8\u91cf\u7ebf\u6027\u56de\u5f52(**Linear Regression with One Variable**) \n\n2.1 \u6a21\u578b\u8868\u793a \n\n2.2 \u4ee3\u4ef7\u51fd\u6570 \n\n2.3 \u4ee3\u4ef7\u51fd\u6570\u7684\u76f4\u89c2\u7406\u89e3I \n\n2.4 \u4ee3\u4ef7\u51fd\u6570\u7684\u76f4\u89c2\u7406\u89e3II \n\n2.5 \u68af\u5ea6\u4e0b\u964d \n\n2.6 \u68af\u5ea6\u4e0b\u964d\u7684\u76f4\u89c2\u7406\u89e3 \n\n2.7 \u68af\u5ea6\u4e0b\u964d\u7684\u7ebf\u6027\u56de\u5f52 \n\n2.8 \u63a5\u4e0b\u6765\u7684\u5185\u5bb9 \n\n\u4e09\u3001\u7ebf\u6027\u4ee3\u6570\u56de\u987e(**Linear Algebra Review**) \n\n3.1 \u77e9\u9635\u548c\u5411\u91cf \n\n3.2 \u52a0\u6cd5\u548c\u6807\u91cf\u4e58\u6cd5 \n\n3.3 \u77e9\u9635\u5411\u91cf\u4e58\u6cd5 \n\n3.4 \u77e9\u9635\u4e58\u6cd5 \n\n3.5 \u77e9\u9635\u4e58\u6cd5\u7684\u6027\u8d28 \n\n3.6 \u9006\u3001\u8f6c\u7f6e\n\n- [\u7b2c\u4e8c\u5468](markdown/week2.md)\n\n\u56db\u3001\u591a\u53d8\u91cf\u7ebf\u6027\u56de\u5f52(**Linear Regression with Multiple Variables**) \n\n4.1 \u591a\u7ef4\u7279\u5f81 \n\n4.2 \u591a\u53d8\u91cf\u68af\u5ea6\u4e0b\u964d \n\n4.3 \u68af\u5ea6\u4e0b\u964d\u6cd5\u5b9e\u8df51-\u7279\u5f81\u7f29\u653e \n\n4.4 \u68af\u5ea6\u4e0b\u964d\u6cd5\u5b9e\u8df52-\u5b66\u4e60\u7387 \n\n4.5 \u7279\u5f81\u548c\u591a\u9879\u5f0f\u56de\u5f52 \n\n4.6 \u6b63\u89c4\u65b9\u7a0b \n\n4.7 \u6b63\u89c4\u65b9\u7a0b\u53ca\u4e0d\u53ef\u9006\u6027\uff08\u9009\u4fee\uff09 \n\n\u4e94\u3001Octave\u6559\u7a0b(**Octave Tutorial**) \n\n5.1 \u57fa\u672c\u64cd\u4f5c \n\n5.2 \u79fb\u52a8\u6570\u636e \n\n5.3 \u8ba1\u7b97\u6570\u636e \n\n5.4 \u7ed8\u56fe\u6570\u636e \n\n5.5 \u63a7\u5236\u8bed\u53e5\uff1a**for**\uff0c**while**\uff0c**if**\u8bed\u53e5 \n\n5.6 \u5411\u91cf\u5316 88\n\n5.7 \u5de5\u4f5c\u548c\u63d0\u4ea4\u7684\u7f16\u7a0b\u7ec3\u4e60 \n\n- [\u7b2c\u4e09\u5468](markdown/week3.md)\n\n\u516d\u3001\u903b\u8f91\u56de\u5f52(**Logistic Regression**) \n\n6.1 \u5206\u7c7b\u95ee\u9898 \n\n6.2 \u5047\u8bf4\u8868\u793a \n\n6.3 \u5224\u5b9a\u8fb9\u754c \n\n6.4 \u4ee3\u4ef7\u51fd\u6570 \n\n6.5 \u7b80\u5316\u7684\u6210\u672c\u51fd\u6570\u548c\u68af\u5ea6\u4e0b\u964d \n\n6.6 \u9ad8\u7ea7\u4f18\u5316 \n\n6.7 \u591a\u7c7b\u522b\u5206\u7c7b\uff1a\u4e00\u5bf9\u591a \n\n\u4e03\u3001\u6b63\u5219\u5316(**Regularization**) \n\n7.1 \u8fc7\u62df\u5408\u7684\u95ee\u9898 \n\n7.2 \u4ee3\u4ef7\u51fd\u6570 \n\n7.3 \u6b63\u5219\u5316\u7ebf\u6027\u56de\u5f52 \n\n7.4 \u6b63\u5219\u5316\u7684\u903b\u8f91\u56de\u5f52\u6a21\u578b \n\n- [\u7b2c\u56db\u5468](markdown/week4.md)\n\n\u7b2c\u516b\u3001\u795e\u7ecf\u7f51\u7edc\uff1a\u8868\u8ff0(**Neural Networks: Representation**) \n\n8.1 \u975e\u7ebf\u6027\u5047\u8bbe \n\n8.2 \u795e\u7ecf\u5143\u548c\u5927\u8111 \n\n8.3 \u6a21\u578b\u8868\u793a1 \n\n8.4 \u6a21\u578b\u8868\u793a2 \n\n8.5 \u6837\u672c\u548c\u76f4\u89c2\u7406\u89e31 \n\n8.6 \u6837\u672c\u548c\u76f4\u89c2\u7406\u89e3II \n\n8.7 \u591a\u7c7b\u5206\u7c7b \n\n- [\u7b2c\u4e94\u5468](markdown/week5.md)\n\n\u4e5d\u3001\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60(**Neural Networks: Learning**) \n\n9.1 \u4ee3\u4ef7\u51fd\u6570 \n\n9.2 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5 \n\n9.3 \u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u7684\u76f4\u89c2\u7406\u89e3 \n\n9.4 \u5b9e\u73b0\u6ce8\u610f\uff1a\u5c55\u5f00\u53c2\u6570 \n\n9.5 \u68af\u5ea6\u68c0\u9a8c \n\n9.6 \u968f\u673a\u521d\u59cb\u5316 \n\n9.7 \u7efc\u5408\u8d77\u6765 \n\n9.8 \u81ea\u4e3b\u9a7e\u9a76 \n\n- [\u7b2c\u516d\u5468](markdown/week6.md)\n\n\u5341\u3001\u5e94\u7528\u673a\u5668\u5b66\u4e60\u7684\u5efa\u8bae(**Advice for Applying Machine Learning**) \n\n10.1 \u51b3\u5b9a\u4e0b\u4e00\u6b65\u505a\u4ec0\u4e48 \n\n10.2 \u8bc4\u4f30\u4e00\u4e2a\u5047\u8bbe \n\n10.3 \u6a21\u578b\u9009\u62e9\u548c\u4ea4\u53c9\u9a8c\u8bc1\u96c6 \n\n10.4 \u8bca\u65ad\u504f\u5dee\u548c\u65b9\u5dee \n\n10.5 \u6b63\u5219\u5316\u548c\u504f\u5dee/\u65b9\u5dee \n\n10.6 \u5b66\u4e60\u66f2\u7ebf \n\n10.7 \u51b3\u5b9a\u4e0b\u4e00\u6b65\u505a\u4ec0\u4e48 \n\n\u5341\u4e00\u3001\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u8bbe\u8ba1(**Machine Learning System Design**) \n\n11.1 \u9996\u5148\u8981\u505a\u4ec0\u4e48 \n\n11.2 \u8bef\u5dee\u5206\u6790 \n\n11.3 \u7c7b\u504f\u659c\u7684\u8bef\u5dee\u5ea6\u91cf \n\n11.4 \u67e5\u51c6\u7387\u548c\u67e5\u5168\u7387\u4e4b\u95f4\u7684\u6743\u8861 \n\n11.5 \u673a\u5668\u5b66\u4e60\u7684\u6570\u636e \n\n[\u7b2c7\u5468](markdown/week7.md)\n\n\u5341\u4e8c\u3001\u652f\u6301\u5411\u91cf\u673a(**Support Vector Machines**) \n\n12.1 \u4f18\u5316\u76ee\u6807 \n\n12.2 \u5927\u8fb9\u754c\u7684\u76f4\u89c2\u7406\u89e3 \n\n12.3 \u6570\u5b66\u80cc\u540e\u7684\u5927\u8fb9\u754c\u5206\u7c7b\uff08\u9009\u4fee\uff09 \n\n12.4 \u6838\u51fd\u65701 \n\n12.5 \u6838\u51fd\u65702 \n\n12.6 \u4f7f\u7528\u652f\u6301\u5411\u91cf\u673a \n\n- [\u7b2c\u516b\u5468](markdown/week8.md)\n\n\u5341\u4e09\u3001\u805a\u7c7b(**Clustering**) \n\n13.1 \u65e0\u76d1\u7763\u5b66\u4e60\uff1a\u7b80\u4ecb \n\n13.2 K-\u5747\u503c\u7b97\u6cd5 \n\n13.3 \u4f18\u5316\u76ee\u6807 \n\n13.4 \u968f\u673a\u521d\u59cb\u5316\n\n13.5 \u9009\u62e9\u805a\u7c7b\u6570 \n\n\u5341\u56db\u3001\u964d\u7ef4(**Dimensionality Reduction**) \n\n14.1 \u52a8\u673a\u4e00\uff1a\u6570\u636e\u538b\u7f29 \n\n14.2 \u52a8\u673a\u4e8c\uff1a\u6570\u636e\u53ef\u89c6\u5316 \n\n14.3 \u4e3b\u6210\u5206\u5206\u6790\u95ee\u9898 \n\n14.4 \u4e3b\u6210\u5206\u5206\u6790\u7b97\u6cd5 \n\n14.5 \u9009\u62e9\u4e3b\u6210\u5206\u7684\u6570\u91cf \n\n14.6 \u91cd\u5efa\u7684\u538b\u7f29\u8868\u793a \n\n14.7 \u4e3b\u6210\u5206\u5206\u6790\u6cd5\u7684\u5e94\u7528\u5efa\u8bae \n\n- [\u7b2c\u4e5d\u5468](markdown/week9.md)\n\n\u5341\u4e94\u3001\u5f02\u5e38\u68c0\u6d4b(**Anomaly Detection**) \n\n15.1 \u95ee\u9898\u7684\u52a8\u673a \n\n15.2 \u9ad8\u65af\u5206\u5e03 \n\n15.3 \u7b97\u6cd5 \n\n15.4 \u5f00\u53d1\u548c\u8bc4\u4ef7\u4e00\u4e2a\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf \n\n15.5 \u5f02\u5e38\u68c0\u6d4b\u4e0e\u76d1\u7763\u5b66\u4e60\u5bf9\u6bd4 \n\n15.6 \u9009\u62e9\u7279\u5f81 \n\n15.7 \u591a\u5143\u9ad8\u65af\u5206\u5e03\uff08\u9009\u4fee\uff09 \n\n15.8 \u4f7f\u7528\u591a\u5143\u9ad8\u65af\u5206\u5e03\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\uff08\u9009\u4fee\uff09 \n\n\u5341\u516d\u3001\u63a8\u8350\u7cfb\u7edf(**Recommender Systems**) \n\n16.1 \u95ee\u9898\u5f62\u5f0f\u5316 \n\n16.2 \u57fa\u4e8e\u5185\u5bb9\u7684\u63a8\u8350\u7cfb\u7edf \n\n16.3 \u534f\u540c\u8fc7\u6ee4 \n\n16.4 \u534f\u540c\u8fc7\u6ee4\u7b97\u6cd5 \n\n16.5 \u5411\u91cf\u5316\uff1a\u4f4e\u79e9\u77e9\u9635\u5206\u89e3 \n\n16.6 \u63a8\u884c\u5de5\u4f5c\u4e0a\u7684\u7ec6\u8282\uff1a\u5747\u503c\u5f52\u4e00\u5316 \n\n- [\u7b2c\u5341\u5468](markdown/week10.md)\n\n\u5341\u4e03\u3001\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60(**Large Scale Machine Learning**) \n\n17.1 \u5927\u578b\u6570\u636e\u96c6\u7684\u5b66\u4e60 \n\n17.2 \u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5 \n\n17.3 \u5c0f\u6279\u91cf\u68af\u5ea6\u4e0b\u964d \n\n17.4 \u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6536\u655b \n\n17.5 \u5728\u7ebf\u5b66\u4e60 \n\n17.6 \u6620\u5c04\u5316\u7b80\u548c\u6570\u636e\u5e76\u884c \n\n\u5341\u516b\u3001\u5e94\u7528\u5b9e\u4f8b\uff1a\u56fe\u7247\u6587\u5b57\u8bc6\u522b(**Application Example: Photo OCR**) \n\n18.1 \u95ee\u9898\u63cf\u8ff0\u548c\u6d41\u7a0b\u56fe\n\n18.2 \u6ed1\u52a8\u7a97\u53e3 \n\n18.3 \u83b7\u53d6\u5927\u91cf\u6570\u636e\u548c\u4eba\u5de5\u6570\u636e \n\n18.4 \u4e0a\u9650\u5206\u6790\uff1a\u54ea\u90e8\u5206\u7ba1\u9053\u7684\u63a5\u4e0b\u53bb\u505a \n\n\u5341\u4e5d\u3001\u603b\u7ed3(**Conclusion**) \n\n19.1 \u603b\u7ed3\u548c\u81f4\u8c22 \n\n------\n\n\n\n**\u673a\u5668\u5b66\u4e60qq\u7fa4\uff1a955171419\uff08\u6211\u4eec\u670913\u4e2a\u7fa4\uff0c\u52a0\u8fc7\u4e00\u4e2a\u5c31\u4e0d\u9700\u8981\u52a0\u4e86\uff09** \n\n",
	"deep-learning deep-neural-networks machine-learning": "# Awesome - Most Cited Deep Learning Papers\n\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\n[Notice] This list is not being maintained anymore because of the overwhelming amount of deep learning papers published every day since 2017.\n\nA curated list of the most cited deep learning papers (2012-2016)\n\nWe believe that there exist *classic* deep learning papers which are worth reading regardless of their application domain. Rather than providing overwhelming amount of papers, We would like to provide a *curated list* of the awesome deep learning papers which are considered as *must-reads* in certain research domains.\n\n## Background\n\nBefore this list, there exist other *awesome deep learning lists*, for example, [Deep Vision](https://github.com/kjw0612/awesome-deep-vision) and [Awesome Recurrent Neural Networks](https://github.com/kjw0612/awesome-rnn). Also, after this list comes out, another awesome list for deep learning beginners, called [Deep Learning Papers Reading Roadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap), has been created and loved by many deep learning researchers.\n\nAlthough the *Roadmap List* includes lots of important deep learning papers, it feels overwhelming for me to read them all. As I mentioned in the introduction, I believe that seminal works can give us lessons regardless of their application domain. Thus, I would like to introduce **top 100 deep learning papers** here as a good starting point of overviewing deep learning researches.\n\nTo get the news for newly released papers everyday, follow my [twitter](https://twitter.com/TerryUm_ML) or [facebook page](https://www.facebook.com/terryum.io/)! \n\n## Awesome list criteria\n\n1. A list of **top 100 deep learning papers** published from 2012 to 2016 is suggested.\n2. If a paper is added to the list, another paper (usually from *More Papers from 2016\" section) should be removed to keep top 100 papers. (Thus, removing papers is also important contributions as well as adding papers)\n3. Papers that are important, but failed to be included in the list, will be listed in *More than Top 100* section.\n4. Please refer to *New Papers* and *Old Papers* sections for the papers published in recent 6 months or before 2012.\n\n*(Citation criteria)*\n- **< 6 months** : *New Papers* (by discussion)\n- **2016** :  +60 citations or \"More Papers from 2016\"\n- **2015** :  +200 citations\n- **2014** :  +400 citations\n- **2013** :  +600 citations\n- **2012** :  +800 citations\n- **~2012** : *Old Papers* (by discussion)\n\nPlease note that we prefer seminal deep learning papers that can be applied to various researches rather than application papers. For that reason, some papers that meet the criteria may not be accepted while others can be. It depends on the impact of the paper, applicability to other researches scarcity of the research domain, and so on.\n\n**We need your contributions!**\n\nIf you have any suggestions (missing papers, new papers, key researchers or typos), please feel free to edit and pull a request.\n(Please read the [contributing guide](https://github.com/terryum/awesome-deep-learning-papers/blob/master/Contributing.md) for further instructions, though just letting me know the title of papers can also be a big contribution to us.)\n\n(Update) You can download all top-100 papers with [this](https://github.com/terryum/awesome-deep-learning-papers/blob/master/fetch_papers.py) and collect all authors' names with [this](https://github.com/terryum/awesome-deep-learning-papers/blob/master/get_authors.py). Also, [bib file](https://github.com/terryum/awesome-deep-learning-papers/blob/master/top100papers.bib) for all top-100 papers are available. Thanks, doodhwala, [Sven](https://github.com/sunshinemyson) and [grepinsight](https://github.com/grepinsight)!\n\n+ Can anyone contribute the code for obtaining the statistics of the authors of Top-100 papers?\n\n\n## Contents\n\n* [Understanding / Generalization / Transfer](#understanding--generalization--transfer)\n* [Optimization / Training Techniques](#optimization--training-techniques)\n* [Unsupervised / Generative Models](#unsupervised--generative-models)\n* [Convolutional Network Models](#convolutional-neural-network-models)\n* [Image Segmentation / Object Detection](#image-segmentation--object-detection)\n* [Image / Video / Etc](#image--video--etc)\n* [Natural Language Processing / RNNs](#natural-language-processing--rnns)\n* [Speech / Other Domain](#speech--other-domain)\n* [Reinforcement Learning / Robotics](#reinforcement-learning--robotics)\n* [More Papers from 2016](#more-papers-from-2016)\n\n*(More than Top 100)*\n\n* [New Papers](#new-papers) : Less than 6 months\n* [Old Papers](#old-papers) : Before 2012\n* [HW / SW / Dataset](#hw--sw--dataset) : Technical reports\n* [Book / Survey / Review](#book--survey--review)\n* [Video Lectures / Tutorials / Blogs](#video-lectures--tutorials--blogs)\n* [Appendix: More than Top 100](#appendix-more-than-top-100) : More papers not in the list\n\n* * *\n\n### Understanding / Generalization / Transfer\n- **Distilling the knowledge in a neural network** (2015), G. Hinton et al. [[pdf]](http://arxiv.org/pdf/1503.02531)\n- **Deep neural networks are easily fooled: High confidence predictions for unrecognizable images** (2015), A. Nguyen et al. [[pdf]](http://arxiv.org/pdf/1412.1897)\n- **How transferable are features in deep neural networks?** (2014), J. Yosinski et al. [[pdf]](http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf)\n- **CNN features off-the-Shelf: An astounding baseline for recognition** (2014), A. Razavian et al. [[pdf]](http://www.cv-foundation.org//openaccess/content_cvpr_workshops_2014/W15/papers/Razavian_CNN_Features_Off-the-Shelf_2014_CVPR_paper.pdf)\n- **Learning and transferring mid-Level image representations using convolutional neural networks** (2014), M. Oquab et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf)\n- **Visualizing and understanding convolutional networks** (2014), M. Zeiler and R. Fergus [[pdf]](http://arxiv.org/pdf/1311.2901)\n- **Decaf: A deep convolutional activation feature for generic visual recognition** (2014), J. Donahue et al. [[pdf]](http://arxiv.org/pdf/1310.1531)\n\n<!---[Key researchers]  [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Jason Yosinski](https://scholar.google.ca/citations?hl=en&user=gxL1qj8AAAAJ) -->\n\n### Optimization / Training Techniques\n- **Training very deep networks** (2015), R. Srivastava et al. [[pdf]](http://papers.nips.cc/paper/5850-training-very-deep-networks.pdf)\n- **Batch normalization: Accelerating deep network training by reducing internal covariate shift** (2015), S. Loffe and C. Szegedy [[pdf]](http://arxiv.org/pdf/1502.03167)\n- **Delving deep into rectifiers: Surpassing human-level performance on imagenet classification** (2015), K. He et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf)\n- **Dropout: A simple way to prevent neural networks from overfitting** (2014), N. Srivastava et al. [[pdf]](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n- **Adam: A method for stochastic optimization** (2014), D. Kingma and J. Ba [[pdf]](http://arxiv.org/pdf/1412.6980)\n- **Improving neural networks by preventing co-adaptation of feature detectors** (2012), G. Hinton et al. [[pdf]](http://arxiv.org/pdf/1207.0580.pdf)\n- **Random search for hyper-parameter optimization** (2012) J. Bergstra and Y. Bengio [[pdf]](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a)\n\n<!---[Key researchers] [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Christian Szegedy](https://scholar.google.ca/citations?hl=en&user=3QeF7mAAAAAJ), [Sergey Ioffe](https://scholar.google.ca/citations?user=S5zOyIkAAAAJ), [Kaming He](https://scholar.google.ca/citations?hl=en&user=DhtAFkwAAAAJ), [Diederik P. Kingma](https://scholar.google.ca/citations?hl=en&user=yyIoQu4AAAAJ)-->\n\n### Unsupervised / Generative Models\n- **Pixel recurrent neural networks** (2016), A. Oord et al. [[pdf]](http://arxiv.org/pdf/1601.06759v2.pdf)\n- **Improved techniques for training GANs** (2016), T. Salimans et al. [[pdf]](http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf)\n- **Unsupervised representation learning with deep convolutional generative adversarial networks** (2015), A. Radford et al. [[pdf]](https://arxiv.org/pdf/1511.06434v2)\n- **DRAW: A recurrent neural network for image generation** (2015), K. Gregor et al. [[pdf]](http://arxiv.org/pdf/1502.04623)\n- **Generative adversarial nets** (2014), I. Goodfellow et al. [[pdf]](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)\n- **Auto-encoding variational Bayes** (2013), D. Kingma and M. Welling [[pdf]](http://arxiv.org/pdf/1312.6114)\n- **Building high-level features using large scale unsupervised learning** (2013), Q. Le et al. [[pdf]](http://arxiv.org/pdf/1112.6209)\n\n<!---[Key researchers] [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Ian Goodfellow](https://scholar.google.ca/citations?user=iYN86KEAAAAJ), [Alex Graves](https://scholar.google.ca/citations?user=DaFHynwAAAAJ)-->\n### Convolutional Neural Network Models\n- **Rethinking the inception architecture for computer vision** (2016), C. Szegedy et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf)\n- **Inception-v4, inception-resnet and the impact of residual connections on learning** (2016), C. Szegedy et al. [[pdf]](http://arxiv.org/pdf/1602.07261)\n- **Identity Mappings in Deep Residual Networks** (2016), K. He et al. [[pdf]](https://arxiv.org/pdf/1603.05027v2.pdf)\n- **Deep residual learning for image recognition** (2016), K. He et al. [[pdf]](http://arxiv.org/pdf/1512.03385)\n- **Spatial transformer network** (2015), M. Jaderberg et al., [[pdf]](http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf)\n- **Going deeper with convolutions** (2015), C. Szegedy et al.  [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)\n- **Very deep convolutional networks for large-scale image recognition** (2014), K. Simonyan and A. Zisserman [[pdf]](http://arxiv.org/pdf/1409.1556)\n- **Return of the devil in the details: delving deep into convolutional nets** (2014), K. Chatfield et al. [[pdf]](http://arxiv.org/pdf/1405.3531)\n- **OverFeat: Integrated recognition, localization and detection using convolutional networks** (2013), P. Sermanet et al. [[pdf]](http://arxiv.org/pdf/1312.6229)\n- **Maxout networks** (2013), I. Goodfellow et al. [[pdf]](http://arxiv.org/pdf/1302.4389v4)\n- **Network in network** (2013), M. Lin et al. [[pdf]](http://arxiv.org/pdf/1312.4400)\n- **ImageNet classification with deep convolutional neural networks** (2012), A. Krizhevsky et al. [[pdf]](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n\n<!---[Key researchers]  [Christian Szegedy](https://scholar.google.ca/citations?hl=en&user=3QeF7mAAAAAJ), [Kaming He](https://scholar.google.ca/citations?hl=en&user=DhtAFkwAAAAJ), [Shaoqing Ren](https://scholar.google.ca/citations?hl=en&user=AUhj438AAAAJ), [Jian Sun](https://scholar.google.ca/citations?hl=en&user=ALVSZAYAAAAJ), [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Yann LeCun](https://scholar.google.ca/citations?hl=en&user=WLN3QrAAAAAJ)-->\n\n### Image: Segmentation / Object Detection\n- **You only look once: Unified, real-time object detection** (2016), J. Redmon et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf)\n- **Fully convolutional networks for semantic segmentation** (2015), J. Long et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)\n- **Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks** (2015), S. Ren et al. [[pdf]](http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf)\n- **Fast R-CNN** (2015), R. Girshick [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf)\n- **Rich feature hierarchies for accurate object detection and semantic segmentation** (2014), R. Girshick et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf)\n- **Spatial pyramid pooling in deep convolutional networks for visual recognition** (2014), K. He et al. [[pdf]](http://arxiv.org/pdf/1406.4729)\n- **Semantic image segmentation with deep convolutional nets and fully connected CRFs**, L. Chen et al. [[pdf]](https://arxiv.org/pdf/1412.7062)\n- **Learning hierarchical features for scene labeling** (2013), C. Farabet et al. [[pdf]](https://hal-enpc.archives-ouvertes.fr/docs/00/74/20/77/PDF/farabet-pami-13.pdf)\n\n<!---[Key researchers]  [Ross Girshick](https://scholar.google.ca/citations?hl=en&user=W8VIEZgAAAAJ), [Jeff Donahue](https://scholar.google.ca/citations?hl=en&user=UfbuDH8AAAAJ), [Trevor Darrell](https://scholar.google.ca/citations?hl=en&user=bh-uRFMAAAAJ)-->\n\n### Image / Video / Etc\n- **Image Super-Resolution Using Deep Convolutional Networks** (2016), C. Dong et al. [[pdf]](https://arxiv.org/pdf/1501.00092v3.pdf)\n- **A neural algorithm of artistic style** (2015), L. Gatys et al. [[pdf]](https://arxiv.org/pdf/1508.06576)\n- **Deep visual-semantic alignments for generating image descriptions** (2015), A. Karpathy and L. Fei-Fei [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.pdf)\n- **Show, attend and tell: Neural image caption generation with visual attention** (2015), K. Xu et al. [[pdf]](http://arxiv.org/pdf/1502.03044)\n- **Show and tell: A neural image caption generator** (2015), O. Vinyals et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf)\n- **Long-term recurrent convolutional networks for visual recognition and description** (2015), J. Donahue et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper.pdf)\n- **VQA: Visual question answering** (2015), S. Antol et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Antol_VQA_Visual_Question_ICCV_2015_paper.pdf)\n- **DeepFace: Closing the gap to human-level performance in face verification** (2014), Y. Taigman et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Taigman_DeepFace_Closing_the_2014_CVPR_paper.pdf):\n- **Large-scale video classification with convolutional neural networks** (2014), A. Karpathy et al. [[pdf]](http://vision.stanford.edu/pdf/karpathy14.pdf)\n- **Two-stream convolutional networks for action recognition in videos** (2014), K. Simonyan et al. [[pdf]](http://papers.nips.cc/paper/5353-two-stream-convolutional-networks-for-action-recognition-in-videos.pdf)\n- **3D convolutional neural networks for human action recognition** (2013), S. Ji et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_JiXYY10.pdf)\n\n<!---[Key researchers]  [Oriol Vinyals](https://scholar.google.ca/citations?user=NkzyCvUAAAAJ), [Andrej Karpathy](https://scholar.google.ca/citations?user=l8WuQJgAAAAJ)-->\n\n<!---[Key researchers]  [Alex Graves](https://scholar.google.ca/citations?user=DaFHynwAAAAJ)-->\n\n### Natural Language Processing / RNNs\n- **Neural Architectures for Named Entity Recognition** (2016), G. Lample et al. [[pdf]](http://aclweb.org/anthology/N/N16/N16-1030.pdf)\n- **Exploring the limits of language modeling** (2016), R. Jozefowicz et al. [[pdf]](http://arxiv.org/pdf/1602.02410)\n- **Teaching machines to read and comprehend** (2015), K. Hermann et al. [[pdf]](http://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf)\n- **Effective approaches to attention-based neural machine translation** (2015), M. Luong et al. [[pdf]](https://arxiv.org/pdf/1508.04025)\n- **Conditional random fields as recurrent neural networks** (2015), S. Zheng and S. Jayasumana. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zheng_Conditional_Random_Fields_ICCV_2015_paper.pdf)\n- **Memory networks** (2014), J. Weston et al. [[pdf]](https://arxiv.org/pdf/1410.3916)\n- **Neural turing machines** (2014), A. Graves et al. [[pdf]](https://arxiv.org/pdf/1410.5401)\n- **Neural machine translation by jointly learning to align and translate** (2014), D. Bahdanau et al. [[pdf]](http://arxiv.org/pdf/1409.0473)\n- **Sequence to sequence learning with neural networks** (2014), I. Sutskever et al. [[pdf]](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n- **Learning phrase representations using RNN encoder-decoder for statistical machine translation** (2014), K. Cho et al. [[pdf]](http://arxiv.org/pdf/1406.1078)\n- **A convolutional neural network for modeling sentences** (2014), N. Kalchbrenner et al. [[pdf]](http://arxiv.org/pdf/1404.2188v1)\n- **Convolutional neural networks for sentence classification** (2014), Y. Kim [[pdf]](http://arxiv.org/pdf/1408.5882)\n- **Glove: Global vectors for word representation** (2014), J. Pennington et al. [[pdf]](http://anthology.aclweb.org/D/D14/D14-1162.pdf)\n- **Distributed representations of sentences and documents** (2014), Q. Le and T. Mikolov [[pdf]](http://arxiv.org/pdf/1405.4053)\n- **Distributed representations of words and phrases and their compositionality** (2013), T. Mikolov et al. [[pdf]](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n- **Efficient estimation of word representations in vector space** (2013), T. Mikolov et al.  [[pdf]](http://arxiv.org/pdf/1301.3781)\n- **Recursive deep models for semantic compositionality over a sentiment treebank** (2013), R. Socher et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.383.1327&rep=rep1&type=pdf)\n- **Generating sequences with recurrent neural networks** (2013), A. Graves. [[pdf]](https://arxiv.org/pdf/1308.0850)\n\n<!---[Key researchers]  [Kyunghyun Cho](https://scholar.google.ca/citations?user=0RAmmIAAAAAJ), [Oriol Vinyals](https://scholar.google.ca/citations?user=NkzyCvUAAAAJ), [Richard Socher](https://scholar.google.ca/citations?hl=en&user=FaOcyfMAAAAJ), [Tomas Mikolov](https://scholar.google.ca/citations?user=oBu8kMMAAAAJ), [Christopher D. Manning](https://scholar.google.ca/citations?user=1zmDOdwAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ)-->\n\n### Speech / Other Domain\n- **End-to-end attention-based large vocabulary speech recognition** (2016), D. Bahdanau et al. [[pdf]](https://arxiv.org/pdf/1508.04395)\n- **Deep speech 2: End-to-end speech recognition in English and Mandarin** (2015), D. Amodei et al. [[pdf]](https://arxiv.org/pdf/1512.02595)\n- **Speech recognition with deep recurrent neural networks** (2013), A. Graves [[pdf]](http://arxiv.org/pdf/1303.5778.pdf)\n- **Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups** (2012), G. Hinton et al. [[pdf]](http://www.cs.toronto.edu/~asamir/papers/SPM_DNN_12.pdf)\n- **Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition** (2012) G. Dahl et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.337.7548&rep=rep1&type=pdf)\n- **Acoustic modeling using deep belief networks** (2012), A. Mohamed et al. [[pdf]](http://www.cs.toronto.edu/~asamir/papers/speechDBN_jrnl.pdf)\n\n<!---[Key researchers]  [Alex Graves](https://scholar.google.ca/citations?user=DaFHynwAAAAJ), [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Dong Yu](https://scholar.google.ca/citations?hl=en&user=tMY31_gAAAAJ)-->\n\n### Reinforcement Learning / Robotics\n- **End-to-end training of deep visuomotor policies** (2016), S. Levine et al. [[pdf]](http://www.jmlr.org/papers/volume17/15-522/source/15-522.pdf)\n- **Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection** (2016), S. Levine et al. [[pdf]](https://arxiv.org/pdf/1603.02199)\n- **Asynchronous methods for deep reinforcement learning** (2016), V. Mnih et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/mniha16.pdf)\n- **Deep Reinforcement Learning with Double Q-Learning** (2016), H. Hasselt et al. [[pdf]](https://arxiv.org/pdf/1509.06461.pdf )\n- **Mastering the game of Go with deep neural networks and tree search** (2016), D. Silver et al. [[pdf]](http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)\n- **Continuous control with deep reinforcement learning** (2015), T. Lillicrap et al. [[pdf]](https://arxiv.org/pdf/1509.02971)\n- **Human-level control through deep reinforcement learning** (2015), V. Mnih et al. [[pdf]](http://www.davidqiu.com:8888/research/nature14236.pdf)\n- **Deep learning for detecting robotic grasps** (2015), I. Lenz et al. [[pdf]](http://www.cs.cornell.edu/~asaxena/papers/lenz_lee_saxena_deep_learning_grasping_ijrr2014.pdf)\n- **Playing atari with deep reinforcement learning** (2013), V. Mnih et al. [[pdf]](http://arxiv.org/pdf/1312.5602.pdf))\n\n<!---[Key researchers]  [Sergey Levine](https://scholar.google.ca/citations?user=8R35rCwAAAAJ), [Volodymyr Mnih](https://scholar.google.ca/citations?hl=en&user=rLdfJ1gAAAAJ), [David Silver](https://scholar.google.ca/citations?user=-8DNE4UAAAAJ)-->\n\n### More Papers from 2016\n- **Layer Normalization** (2016), J. Ba et al. [[pdf]](https://arxiv.org/pdf/1607.06450v1.pdf)\n- **Learning to learn by gradient descent by gradient descent** (2016), M. Andrychowicz et al. [[pdf]](http://arxiv.org/pdf/1606.04474v1)\n- **Domain-adversarial training of neural networks** (2016), Y. Ganin et al. [[pdf]](http://www.jmlr.org/papers/volume17/15-239/source/15-239.pdf)\n- **WaveNet: A Generative Model for Raw Audio** (2016), A. Oord et al. [[pdf]](https://arxiv.org/pdf/1609.03499v2) [[web]](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)\n- **Colorful image colorization** (2016), R. Zhang et al. [[pdf]](https://arxiv.org/pdf/1603.08511)\n- **Generative visual manipulation on the natural image manifold** (2016), J. Zhu et al. [[pdf]](https://arxiv.org/pdf/1609.03552)\n- **Texture networks: Feed-forward synthesis of textures and stylized images** (2016), D Ulyanov et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/ulyanov16.pdf)\n- **SSD: Single shot multibox detector** (2016), W. Liu et al. [[pdf]](https://arxiv.org/pdf/1512.02325)\n- **SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size** (2016), F. Iandola et al. [[pdf]](http://arxiv.org/pdf/1602.07360)\n- **Eie: Efficient inference engine on compressed deep neural network** (2016), S. Han et al. [[pdf]](http://arxiv.org/pdf/1602.01528)\n- **Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1** (2016), M. Courbariaux et al. [[pdf]](https://arxiv.org/pdf/1602.02830)\n- **Dynamic memory networks for visual and textual question answering** (2016), C. Xiong et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/xiong16.pdf)\n- **Stacked attention networks for image question answering** (2016), Z. Yang et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_Stacked_Attention_Networks_CVPR_2016_paper.pdf)\n- **Hybrid computing using a neural network with dynamic external memory** (2016), A. Graves et al. [[pdf]](https://www.gwern.net/docs/2016-graves.pdf)\n- **Google's neural machine translation system: Bridging the gap between human and machine translation** (2016), Y. Wu et al. [[pdf]](https://arxiv.org/pdf/1609.08144)\n\n* * *\n\n\n### New papers\n*Newly published papers (< 6 months) which are worth reading*\n- MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (2017), Andrew G. Howard et al. [[pdf]](https://arxiv.org/pdf/1704.04861.pdf)\n- Convolutional Sequence to Sequence Learning (2017), Jonas Gehring et al. [[pdf]](https://arxiv.org/pdf/1705.03122)\n- A Knowledge-Grounded Neural Conversation Model (2017), Marjan Ghazvininejad et al. [[pdf]](https://arxiv.org/pdf/1702.01932)\n- Accurate, Large Minibatch SGD:Training ImageNet in 1 Hour (2017), Priya Goyal et al. [[pdf]](https://research.fb.com/wp-content/uploads/2017/06/imagenet1kin1h3.pdf)\n- TACOTRON: Towards end-to-end speech synthesis (2017), Y. Wang et al. [[pdf]](https://arxiv.org/pdf/1703.10135.pdf)\n- Deep Photo Style Transfer (2017), F. Luan et al. [[pdf]](http://arxiv.org/pdf/1703.07511v1.pdf)\n- Evolution Strategies as a Scalable Alternative to Reinforcement Learning (2017), T. Salimans et al. [[pdf]](http://arxiv.org/pdf/1703.03864v1.pdf)\n- Deformable Convolutional Networks (2017), J. Dai et al. [[pdf]](http://arxiv.org/pdf/1703.06211v2.pdf)\n- Mask R-CNN (2017), K. He et al. [[pdf]](https://128.84.21.199/pdf/1703.06870)\n- Learning to discover cross-domain relations with generative adversarial networks (2017), T. Kim et al. [[pdf]](http://arxiv.org/pdf/1703.05192v1.pdf) \n- Deep voice: Real-time neural text-to-speech (2017), S. Arik et al., [[pdf]](http://arxiv.org/pdf/1702.07825v2.pdf)\n- PixelNet: Representation of the pixels, by the pixels, and for the pixels (2017), A. Bansal et al. [[pdf]](http://arxiv.org/pdf/1702.06506v1.pdf)\n- Batch renormalization: Towards reducing minibatch dependence in batch-normalized models (2017), S. Ioffe. [[pdf]](https://arxiv.org/abs/1702.03275)\n- Wasserstein GAN (2017), M. Arjovsky et al. [[pdf]](https://arxiv.org/pdf/1701.07875v1)\n- Understanding deep learning requires rethinking generalization (2017), C. Zhang et al. [[pdf]](https://arxiv.org/pdf/1611.03530)\n- Least squares generative adversarial networks (2016), X. Mao et al. [[pdf]](https://arxiv.org/abs/1611.04076v2)\n\n\n### Old Papers\n*Classic papers published before 2012*\n- An analysis of single-layer networks in unsupervised feature learning (2011), A. Coates et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf)\n- Deep sparse rectifier neural networks (2011), X. Glorot et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_GlorotBB11.pdf)\n- Natural language processing (almost) from scratch (2011), R. Collobert et al. [[pdf]](http://arxiv.org/pdf/1103.0398)\n- Recurrent neural network based language model (2010), T. Mikolov et al. [[pdf]](http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf)\n- Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010), P. Vincent et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.297.3484&rep=rep1&type=pdf)\n- Learning mid-level features for recognition (2010), Y. Boureau [[pdf]](http://ece.duke.edu/~lcarin/boureau-cvpr-10.pdf)\n- A practical guide to training restricted boltzmann machines (2010), G. Hinton [[pdf]](http://www.csri.utoronto.ca/~hinton/absps/guideTR.pdf)\n- Understanding the difficulty of training deep feedforward neural networks (2010), X. Glorot and Y. Bengio [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_GlorotB10.pdf)\n- Why does unsupervised pre-training help deep learning (2010), D. Erhan et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_ErhanCBV10.pdf)\n- Learning deep architectures for AI (2009), Y. Bengio. [[pdf]](http://sanghv.com/download/soft/machine%20learning,%20artificial%20intelligence,%20mathematics%20ebooks/ML/learning%20deep%20architectures%20for%20AI%20(2009).pdf)\n- Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009), H. Lee et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.802&rep=rep1&type=pdf)\n- Greedy layer-wise training of deep networks (2007), Y. Bengio et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_739.pdf)\n- Reducing the dimensionality of data with neural networks, G. Hinton and R. Salakhutdinov. [[pdf]](http://homes.mpimf-heidelberg.mpg.de/~mhelmsta/pdf/2006%20Hinton%20Salakhudtkinov%20Science.pdf)\n- A fast learning algorithm for deep belief nets (2006), G. Hinton et al. [[pdf]](http://nuyoo.utm.mx/~jjf/rna/A8%20A%20fast%20learning%20algorithm%20for%20deep%20belief%20nets.pdf)\n- Gradient-based learning applied to document recognition (1998), Y. LeCun et al. [[pdf]](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n- Long short-term memory (1997), S. Hochreiter and J. Schmidhuber. [[pdf]](http://www.mitpressjournals.org/doi/pdfplus/10.1162/neco.1997.9.8.1735)\n\n\n### HW / SW / Dataset\n-  SQuAD: 100,000+ Questions for Machine Comprehension of Text (2016), Rajpurkar et al. [[pdf]](https://arxiv.org/pdf/1606.05250.pdf)\n- OpenAI gym (2016), G. Brockman et al. [[pdf]](https://arxiv.org/pdf/1606.01540)\n- TensorFlow: Large-scale machine learning on heterogeneous distributed systems (2016), M. Abadi et al. [[pdf]](http://arxiv.org/pdf/1603.04467)\n- Theano: A Python framework for fast computation of mathematical expressions, R. Al-Rfou et al.\n- Torch7: A matlab-like environment for machine learning, R. Collobert et al. [[pdf]](https://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf)\n- MatConvNet: Convolutional neural networks for matlab (2015), A. Vedaldi and K. Lenc [[pdf]](http://arxiv.org/pdf/1412.4564)\n- Imagenet large scale visual recognition challenge (2015), O. Russakovsky et al. [[pdf]](http://arxiv.org/pdf/1409.0575)\n- Caffe: Convolutional architecture for fast feature embedding (2014), Y. Jia et al. [[pdf]](http://arxiv.org/pdf/1408.5093)\n\n\n### Book / Survey / Review\n- On the Origin of Deep Learning (2017), H. Wang and Bhiksha Raj. [[pdf]](https://arxiv.org/pdf/1702.07800)\n- Deep Reinforcement Learning: An Overview (2017), Y. Li, [[pdf]](http://arxiv.org/pdf/1701.07274v2.pdf)\n- Neural Machine Translation and Sequence-to-sequence Models(2017): A Tutorial, G. Neubig. [[pdf]](http://arxiv.org/pdf/1703.01619v1.pdf)\n- Neural Network and Deep Learning (Book, Jan 2017), Michael Nielsen. [[html]](http://neuralnetworksanddeeplearning.com/index.html)\n- Deep learning (Book, 2016), Goodfellow et al. [[html]](http://www.deeplearningbook.org/)\n- LSTM: A search space odyssey (2016), K. Greff et al. [[pdf]](https://arxiv.org/pdf/1503.04069.pdf?utm_content=buffereddc5&utm_medium=social&utm_source=plus.google.com&utm_campaign=buffer)\n- Tutorial on Variational Autoencoders (2016), C. Doersch. [[pdf]](https://arxiv.org/pdf/1606.05908)\n- Deep learning (2015), Y. LeCun, Y. Bengio and G. Hinton [[pdf]](https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)\n- Deep learning in neural networks: An overview (2015), J. Schmidhuber [[pdf]](http://arxiv.org/pdf/1404.7828)\n- Representation learning: A review and new perspectives (2013), Y. Bengio et al. [[pdf]](http://arxiv.org/pdf/1206.5538)\n\n### Video Lectures / Tutorials / Blogs\n\n*(Lectures)*\n- CS231n, Convolutional Neural Networks for Visual Recognition, Stanford University [[web]](http://cs231n.stanford.edu/)\n- CS224d, Deep Learning for Natural Language Processing, Stanford University [[web]](http://cs224d.stanford.edu/)\n- Oxford Deep NLP 2017, Deep Learning for Natural Language Processing, University of Oxford [[web]](https://github.com/oxford-cs-deepnlp-2017/lectures)\n\n*(Tutorials)*\n- NIPS 2016 Tutorials, Long Beach [[web]](https://nips.cc/Conferences/2016/Schedule?type=Tutorial)\n- ICML 2016 Tutorials, New York City [[web]](http://techtalks.tv/icml/2016/tutorials/)\n- ICLR 2016 Videos, San Juan [[web]](http://videolectures.net/iclr2016_san_juan/)\n- Deep Learning Summer School 2016, Montreal [[web]](http://videolectures.net/deeplearning2016_montreal/)\n- Bay Area Deep Learning School 2016, Stanford [[web]](https://www.bayareadlschool.org/)\n\n*(Blogs)*\n- OpenAI [[web]](https://www.openai.com/)\n- Distill [[web]](http://distill.pub/)\n- Andrej Karpathy Blog [[web]](http://karpathy.github.io/)\n- Colah's Blog [[Web]](http://colah.github.io/)\n- WildML [[Web]](http://www.wildml.com/)\n- FastML [[web]](http://www.fastml.com/)\n- TheMorningPaper [[web]](https://blog.acolyer.org)\n\n### Appendix: More than Top 100\n*(2016)*\n- A character-level decoder without explicit segmentation for neural machine translation (2016), J. Chung et al. [[pdf]](https://arxiv.org/pdf/1603.06147)\n- Dermatologist-level classification of skin cancer with deep neural networks (2017), A. Esteva et al. [[html]](http://www.nature.com/nature/journal/v542/n7639/full/nature21056.html)\n- Weakly supervised object localization with multi-fold multiple instance learning (2017), R. Gokberk et al. [[pdf]](https://arxiv.org/pdf/1503.00949)\n- Brain tumor segmentation with deep neural networks (2017), M. Havaei et al. [[pdf]](https://arxiv.org/pdf/1505.03540)\n- Professor Forcing: A New Algorithm for Training Recurrent Networks (2016), A. Lamb et al. [[pdf]](https://arxiv.org/pdf/1610.09038)\n- Adversarially learned inference (2016), V. Dumoulin et al. [[web]](https://ishmaelbelghazi.github.io/ALI/)[[pdf]](https://arxiv.org/pdf/1606.00704v1)\n- Understanding convolutional neural networks (2016), J. Koushik [[pdf]](https://arxiv.org/pdf/1605.09081v1)\n- Taking the human out of the loop: A review of bayesian optimization (2016), B. Shahriari et al. [[pdf]](https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf)\n- Adaptive computation time for recurrent neural networks (2016), A. Graves [[pdf]](http://arxiv.org/pdf/1603.08983)\n- Densely connected convolutional networks (2016), G. Huang et al. [[pdf]](https://arxiv.org/pdf/1608.06993v1)\n- Region-based convolutional networks for accurate object detection and segmentation (2016), R. Girshick et al. \n- Continuous deep q-learning with model-based acceleration (2016), S. Gu et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/gu16.pdf)\n- A thorough examination of the cnn/daily mail reading comprehension task (2016), D. Chen et al. [[pdf]](https://arxiv.org/pdf/1606.02858)\n- Achieving open vocabulary neural machine translation with hybrid word-character models, M. Luong and C. Manning. [[pdf]](https://arxiv.org/pdf/1604.00788)\n- Very Deep Convolutional Networks for Natural Language Processing (2016), A. Conneau et al. [[pdf]](https://arxiv.org/pdf/1606.01781)\n- Bag of tricks for efficient text classification (2016), A. Joulin et al. [[pdf]](https://arxiv.org/pdf/1607.01759)\n- Efficient piecewise training of deep structured models for semantic segmentation (2016), G. Lin et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lin_Efficient_Piecewise_Training_CVPR_2016_paper.pdf)\n- Learning to compose neural networks for question answering (2016), J. Andreas et al. [[pdf]](https://arxiv.org/pdf/1601.01705)\n- Perceptual losses for real-time style transfer and super-resolution (2016), J. Johnson et al. [[pdf]](https://arxiv.org/pdf/1603.08155)\n- Reading text in the wild with convolutional neural networks (2016), M. Jaderberg et al. [[pdf]](http://arxiv.org/pdf/1412.1842)\n- What makes for effective detection proposals? (2016), J. Hosang et al. [[pdf]](https://arxiv.org/pdf/1502.05082)\n- Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks (2016), S. Bell et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Bell_Inside-Outside_Net_Detecting_CVPR_2016_paper.pdf).\n- Instance-aware semantic segmentation via multi-task network cascades (2016), J. Dai et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Dai_Instance-Aware_Semantic_Segmentation_CVPR_2016_paper.pdf)\n- Conditional image generation with pixelcnn decoders (2016), A. van den Oord et al. [[pdf]](http://papers.nips.cc/paper/6527-tree-structured-reinforcement-learning-for-sequential-object-localization.pdf)\n- Deep networks with stochastic depth (2016), G. Huang et al., [[pdf]](https://arxiv.org/pdf/1603.09382)\n- Consistency and Fluctuations For Stochastic Gradient Langevin Dynamics (2016), Yee Whye Teh et al. [[pdf]](http://www.jmlr.org/papers/volume17/teh16a/teh16a.pdf)\n\n*(2015)*\n- Ask your neurons: A neural-based approach to answering questions about images (2015), M. Malinowski et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Malinowski_Ask_Your_Neurons_ICCV_2015_paper.pdf)\n- Exploring models and data for image question answering (2015), M. Ren et al. [[pdf]](http://papers.nips.cc/paper/5640-stochastic-variational-inference-for-hidden-markov-models.pdf)\n- Are you talking to a machine? dataset and methods for multilingual image question (2015), H. Gao et al. [[pdf]](http://papers.nips.cc/paper/5641-are-you-talking-to-a-machine-dataset-and-methods-for-multilingual-image-question.pdf)\n- Mind's eye: A recurrent visual representation for image caption generation (2015), X. Chen and C. Zitnick. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Chen_Minds_Eye_A_2015_CVPR_paper.pdf)\n- From captions to visual concepts and back (2015), H. Fang et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Fang_From_Captions_to_2015_CVPR_paper.pdf).\n- Towards AI-complete question answering: A set of prerequisite toy tasks (2015), J. Weston et al. [[pdf]](http://arxiv.org/pdf/1502.05698)\n- Ask me anything: Dynamic memory networks for natural language processing (2015), A. Kumar et al. [[pdf]](http://arxiv.org/pdf/1506.07285)\n- Unsupervised learning of video representations using LSTMs (2015), N. Srivastava et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v37/srivastava15.pdf)\n- Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2015), S. Han et al. [[pdf]](https://arxiv.org/pdf/1510.00149)\n- Improved semantic representations from tree-structured long short-term memory networks (2015), K. Tai et al. [[pdf]](https://arxiv.org/pdf/1503.00075)\n- Character-aware neural language models (2015), Y. Kim et al. [[pdf]](https://arxiv.org/pdf/1508.06615)\n- Grammar as a foreign language (2015), O. Vinyals et al. [[pdf]](http://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf)\n- Trust Region Policy Optimization (2015), J. Schulman et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf)\n- Beyond short snippents: Deep networks for video classification (2015) [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Ng_Beyond_Short_Snippets_2015_CVPR_paper.pdf)\n- Learning Deconvolution Network for Semantic Segmentation (2015), H. Noh et al. [[pdf]](https://arxiv.org/pdf/1505.04366v1)\n- Learning spatiotemporal features with 3d convolutional networks (2015), D. Tran et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Tran_Learning_Spatiotemporal_Features_ICCV_2015_paper.pdf)\n- Understanding neural networks through deep visualization (2015), J. Yosinski et al. [[pdf]](https://arxiv.org/pdf/1506.06579)\n- An Empirical Exploration of Recurrent Network Architectures (2015), R. Jozefowicz et al.  [[pdf]](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n- Deep generative image models using a\ufffc laplacian pyramid of adversarial networks (2015), E.Denton et al. [[pdf]](http://papers.nips.cc/paper/5773-deep-generative-image-models-using-a-laplacian-pyramid-of-adversarial-networks.pdf)\n- Gated Feedback Recurrent Neural Networks (2015), J. Chung et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v37/chung15.pdf)\n- Fast and accurate deep network learning by exponential linear units (ELUS) (2015), D. Clevert et al. [[pdf]](https://arxiv.org/pdf/1511.07289.pdf%5Cnhttp://arxiv.org/abs/1511.07289%5Cnhttp://arxiv.org/abs/1511.07289)\n- Pointer networks (2015), O. Vinyals et al. [[pdf]](http://papers.nips.cc/paper/5866-pointer-networks.pdf)\n- Visualizing and Understanding Recurrent Networks (2015), A. Karpathy et al. [[pdf]](https://arxiv.org/pdf/1506.02078)\n- Attention-based models for speech recognition (2015), J. Chorowski et al. [[pdf]](http://papers.nips.cc/paper/5847-attention-based-models-for-speech-recognition.pdf)\n- End-to-end memory networks (2015), S. Sukbaatar et al. [[pdf]](http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf)\n- Describing videos by exploiting temporal structure (2015), L. Yao et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yao_Describing_Videos_by_ICCV_2015_paper.pdf)\n- A neural conversational model (2015), O. Vinyals and Q. Le. [[pdf]](https://arxiv.org/pdf/1506.05869.pdf)\n- Improving distributional similarity with lessons learned from word embeddings, O. Levy et al. [[pdf]] (https://www.transacl.org/ojs/index.php/tacl/article/download/570/124)\n- Transition-Based Dependency Parsing with Stack Long Short-Term Memory (2015), C. Dyer et al. [[pdf]](http://aclweb.org/anthology/P/P15/P15-1033.pdf)\n- Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs (2015), M. Ballesteros et al. [[pdf]](http://aclweb.org/anthology/D/D15/D15-1041.pdf)\n- Finding function in form: Compositional character models for open vocabulary word representation (2015), W. Ling et al. [[pdf]](http://aclweb.org/anthology/D/D15/D15-1176.pdf)\n\n\n*(~2014)*\n- DeepPose: Human pose estimation via deep neural networks (2014), A. Toshev and C. Szegedy [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Toshev_DeepPose_Human_Pose_2014_CVPR_paper.pdf)\n- Learning a Deep Convolutional Network for Image Super-Resolution (2014, C. Dong et al. [[pdf]](https://www.researchgate.net/profile/Chen_Change_Loy/publication/264552416_Lecture_Notes_in_Computer_Science/links/53e583e50cf25d674e9c280e.pdf)\n- Recurrent models of visual attention (2014), V. Mnih et al. [[pdf]](http://arxiv.org/pdf/1406.6247.pdf)\n- Empirical evaluation of gated recurrent neural networks on sequence modeling (2014), J. Chung et al. [[pdf]](https://arxiv.org/pdf/1412.3555)\n- Addressing the rare word problem in neural machine translation (2014), M. Luong et al. [[pdf]](https://arxiv.org/pdf/1410.8206)\n- On the properties of neural machine translation: Encoder-decoder approaches (2014), K. Cho et. al.\n- Recurrent neural network regularization (2014), W. Zaremba et al. [[pdf]](http://arxiv.org/pdf/1409.2329)\n- Intriguing properties of neural networks (2014), C. Szegedy et al. [[pdf]](https://arxiv.org/pdf/1312.6199.pdf)\n- Towards end-to-end speech recognition with recurrent neural networks (2014), A. Graves and N. Jaitly. [[pdf]](http://www.jmlr.org/proceedings/papers/v32/graves14.pdf)\n- Scalable object detection using deep neural networks (2014), D. Erhan et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Erhan_Scalable_Object_Detection_2014_CVPR_paper.pdf)\n- On the importance of initialization and momentum in deep learning (2013), I. Sutskever et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2013_sutskever13.pdf)\n- Regularization of neural networks using dropconnect (2013), L. Wan et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2013_wan13.pdf)\n- Learning Hierarchical Features for Scene Labeling (2013), C. Farabet et al. [[pdf]](https://hal-enpc.archives-ouvertes.fr/docs/00/74/20/77/PDF/farabet-pami-13.pdf)\n- Linguistic Regularities in Continuous Space Word Representations (2013), T. Mikolov et al. [[pdf]](http://www.aclweb.org/anthology/N13-1#page=784)\n- Large scale distributed deep networks (2012), J. Dean et al. [[pdf]](http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf)\n- A Fast and Accurate Dependency Parser using Neural Networks. Chen and Manning. [[pdf]](http://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf)\n\n\n\n## Acknowledgement\n\nThank you for all your contributions. Please make sure to read the [contributing guide](https://github.com/terryum/awesome-deep-learning-papers/blob/master/Contributing.md) before you make a pull request.\n\n## License\n[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)\n\nTo the extent possible under law, [Terry T. Um](https://www.facebook.com/terryum.io/) has waived all copyright and related or neighboring rights to this work.\n",
	"computer-vision deep-learning deep-learning-tutorial deep-neural-networks dnn neural-network object-detection scaled-yolov4 scaledyolov4 yolo yolov3 yolov4": "# Yolo v4, v3 and v2 for Windows and Linux\n\n## (neural networks for object detection)\n\n* Paper **YOLOv7**: https://arxiv.org/abs/2207.02696\n\n* source code YOLOv7 - Pytorch (use to reproduce results): https://github.com/WongKinYiu/yolov7\n\n----\n\n* Paper **YOLOv4**: https://arxiv.org/abs/2004.10934\n\n* source code YOLOv4 - Darknet (use to reproduce results): https://github.com/AlexeyAB/darknet\n\n----\n\n* Paper **Scaled-YOLOv4 (CVPR 2021)**: https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Scaled-YOLOv4_Scaling_Cross_Stage_Partial_Network_CVPR_2021_paper.html\n\n* source code Scaled-YOLOv4 - Pytorch (use to reproduce results): https://github.com/WongKinYiu/ScaledYOLOv4\n\n----\n\n### YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors\n\n* **Paper**: https://arxiv.org/abs/2207.02696\n\n* **source code - Pytorch (use to reproduce results):** https://github.com/WongKinYiu/yolov7\n\n\nYOLOv7 is more accurate and faster than YOLOv5 by **120%** FPS, than YOLOX by **180%** FPS, than Dual-Swin-T by **1200%** FPS, than ConvNext by **550%** FPS, than SWIN-L by **500%** FPS, than PPYOLOE-X by **150%** FPS.\n\nYOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56.8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100, batch=1. \n\n* YOLOv7-e6 (55.9% AP, 56 FPS V100 b=1) by `+500%` FPS faster than SWIN-L C-M-RCNN (53.9% AP, 9.2 FPS A100 b=1)\n* YOLOv7-e6 (55.9% AP, 56 FPS V100 b=1) by `+550%` FPS faster than ConvNeXt-XL C-M-RCNN (55.2% AP, 8.6 FPS A100 b=1)\n* YOLOv7-w6 (54.6% AP, 84 FPS V100 b=1) by `+120%` FPS faster than YOLOv5-X6-r6.1 (55.0% AP, 38 FPS V100 b=1)\n* YOLOv7-w6 (54.6% AP, 84 FPS V100 b=1) by `+1200%` FPS faster than Dual-Swin-T C-M-RCNN (53.6% AP, 6.5 FPS V100 b=1)\n* YOLOv7x (52.9% AP, 114 FPS V100 b=1) by `+150%` FPS faster than PPYOLOE-X (51.9% AP, 45 FPS V100 b=1)\n* YOLOv7 (51.2% AP, 161 FPS V100 b=1) by `+180%` FPS faster than YOLOX-X (51.1% AP, 58 FPS V100 b=1)\n\n\n----\n\n![more5](https://user-images.githubusercontent.com/4096485/179425274-f55a36d4-8450-4471-816b-8c105841effd.jpg)\n\n----\n\n![image](https://user-images.githubusercontent.com/4096485/177675030-a929ee00-0eba-4d93-95c2-225231d0fd61.png)\n\n\n----\n\nMore details in articles on medium:\n\n- [Scaled_YOLOv4](https://alexeyab84.medium.com/scaled-yolo-v4-is-the-best-neural-network-for-object-detection-on-ms-coco-dataset-39dfa22fa982?source=friends_link&sk=c8553bfed861b1a7932f739d26f487c8)\n- [YOLOv4](https://medium.com/@alexeyab84/yolov4-the-most-accurate-real-time-neural-network-on-ms-coco-dataset-73adfd3602fe?source=friends_link&sk=6039748846bbcf1d960c3061542591d7)\n\nManual: https://github.com/AlexeyAB/darknet/wiki\n\nDiscussion:\n\n- [Reddit](https://www.reddit.com/r/MachineLearning/comments/gydxzd/p_yolov4_the_most_accurate_realtime_neural/)\n- [Google-groups](https://groups.google.com/forum/#!forum/darknet)\n- [Discord](https://discord.gg/zSq8rtW)\n\nAbout Darknet framework: http://pjreddie.com/darknet/\n\n[![Darknet Continuous Integration](https://github.com/AlexeyAB/darknet/workflows/Darknet%20Continuous%20Integration/badge.svg)](https://github.com/AlexeyAB/darknet/actions?query=workflow%3A%22Darknet+Continuous+Integration%22)\n[![CircleCI](https://circleci.com/gh/AlexeyAB/darknet.svg?style=svg)](https://circleci.com/gh/AlexeyAB/darknet)\n[![Contributors](https://img.shields.io/github/contributors/AlexeyAB/Darknet.svg)](https://github.com/AlexeyAB/darknet/graphs/contributors)\n[![License: Unlicense](https://img.shields.io/badge/license-Unlicense-blue.svg)](https://github.com/AlexeyAB/darknet/blob/master/LICENSE)\n[![DOI](https://zenodo.org/badge/75388965.svg)](https://zenodo.org/badge/latestdoi/75388965)\n[![arxiv.org](http://img.shields.io/badge/cs.CV-arXiv%3A2004.10934-B31B1B.svg)](https://arxiv.org/abs/2004.10934)\n[![arxiv.org](http://img.shields.io/badge/cs.CV-arXiv%3A2011.08036-B31B1B.svg)](https://arxiv.org/abs/2011.08036)\n[![colab](https://user-images.githubusercontent.com/4096485/86174089-b2709f80-bb29-11ea-9faf-3d8dc668a1a5.png)](https://colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE)\n[![colab](https://user-images.githubusercontent.com/4096485/86174097-b56b9000-bb29-11ea-9240-c17f6bacfc34.png)](https://colab.research.google.com/drive/1_GdoqCJWXsChrOiY8sZMr_zbr_fH-0Fg)\n\n- [YOLOv4 model zoo](https://github.com/AlexeyAB/darknet/wiki/YOLOv4-model-zoo)\n- [Requirements (and how to install dependencies)](#requirements-for-windows-linux-and-macos)\n- [Pre-trained models](#pre-trained-models)\n- [FAQ - frequently asked questions](https://github.com/AlexeyAB/darknet/wiki/FAQ---frequently-asked-questions)\n- [Explanations in issues](https://github.com/AlexeyAB/darknet/issues?q=is%3Aopen+is%3Aissue+label%3AExplanations)\n- [Yolo v4 in other frameworks (TensorRT, TensorFlow, PyTorch, OpenVINO, OpenCV-dnn, TVM,...)](#yolo-v4-in-other-frameworks)\n- [Datasets](#datasets)\n\n- [Yolo v4, v3 and v2 for Windows and Linux](#yolo-v4-v3-and-v2-for-windows-and-linux)\n  - [(neural networks for object detection)](#neural-networks-for-object-detection)\n    - [GeForce RTX 2080 Ti](#geforce-rtx-2080-ti)\n      - [Youtube video of results](#youtube-video-of-results)\n      - [How to evaluate AP of YOLOv4 on the MS COCO evaluation server](#how-to-evaluate-ap-of-yolov4-on-the-ms-coco-evaluation-server)\n      - [How to evaluate FPS of YOLOv4 on GPU](#how-to-evaluate-fps-of-yolov4-on-gpu)\n      - [Pre-trained models](#pre-trained-models)\n    - [Requirements for Windows, Linux and macOS](#requirements-for-windows-linux-and-macos)\n    - [Yolo v4 in other frameworks](#yolo-v4-in-other-frameworks)\n      - [Datasets](#datasets)\n    - [Improvements in this repository](#improvements-in-this-repository)\n      - [How to use on the command line](#how-to-use-on-the-command-line)\n        - [For using network video-camera mjpeg-stream with any Android smartphone](#for-using-network-video-camera-mjpeg-stream-with-any-android-smartphone)\n    - [How to compile on Linux/macOS (using `CMake`)](#how-to-compile-on-linuxmacos-using-cmake)\n    - [Using also PowerShell](#using-also-powershell)\n    - [How to compile on Linux (using `make`)](#how-to-compile-on-linux-using-make)\n    - [How to compile on Windows (using `CMake`)](#how-to-compile-on-windows-using-cmake)\n    - [How to compile on Windows (using `vcpkg`)](#how-to-compile-on-windows-using-vcpkg)\n  - [How to train with multi-GPU](#how-to-train-with-multi-gpu)\n  - [How to train (to detect your custom objects)](#how-to-train-to-detect-your-custom-objects)\n    - [How to train tiny-yolo (to detect your custom objects)](#how-to-train-tiny-yolo-to-detect-your-custom-objects)\n  - [When should I stop training](#when-should-i-stop-training)\n    - [Custom object detection](#custom-object-detection)\n  - [How to improve object detection](#how-to-improve-object-detection)\n  - [How to mark bounded boxes of objects and create annotation files](#how-to-mark-bounded-boxes-of-objects-and-create-annotation-files)\n  - [How to use Yolo as DLL and SO libraries](#how-to-use-yolo-as-dll-and-so-libraries)\n  - [Citation](#citation)\n\n![Darknet Logo](http://pjreddie.com/media/files/darknet-black-small.png)\n\n![scaled_yolov4](https://user-images.githubusercontent.com/4096485/112776361-281d8380-9048-11eb-8083-8728b12dcd55.png) AP50:95 - FPS (Tesla V100) Paper: https://arxiv.org/abs/2011.08036\n\n----\n\n![modern_gpus](https://user-images.githubusercontent.com/4096485/82835867-f1c62380-9ecd-11ea-9134-1598ed2abc4b.png) AP50:95 / AP50 - FPS (Tesla V100) Paper: https://arxiv.org/abs/2004.10934\n\ntkDNN-TensorRT accelerates YOLOv4 **~2x** times for batch=1 and **3x-4x** times for batch=4.\n\n- tkDNN: https://github.com/ceccocats/tkDNN\n- OpenCV: https://gist.github.com/YashasSamaga/48bdb167303e10f4d07b754888ddbdcf\n\n### GeForce RTX 2080 Ti\n\n| Network Size               | Darknet, FPS (avg) | tkDNN TensorRT FP32, FPS | tkDNN TensorRT FP16, FPS | OpenCV FP16, FPS | tkDNN TensorRT FP16 batch=4, FPS | OpenCV FP16 batch=4, FPS | tkDNN Speedup |\n|:--------------------------:|:------------------:|-------------------------:|-------------------------:|-----------------:|---------------------------------:|-------------------------:|--------------:|\n|320                         | 100                | 116                      | **202**                  | 183              | 423                              | **430**                  | **4.3x**      |\n|416                         | 82                 | 103                      | **162**                  | 159              | 284                              | **294**                  | **3.6x**      |\n|512                         | 69                 | 91                       | 134                      | **138**          | 206                              | **216**                  | **3.1x**      |\n|608                         | 53                 | 62                       | 103                      | **115**          | 150                              | **150**                  | **2.8x**      |\n|Tiny 416                    | 443                | 609                      | **790**                  | 773              | **1774**                         | 1353                     | **3.5x**      |\n|Tiny 416 CPU Core i7 7700HQ | 3.4                | -                        | -                        | 42               | -                                | 39                       | **12x**       |\n\n- Yolo v4 Full comparison: [map_fps](https://user-images.githubusercontent.com/4096485/80283279-0e303e00-871f-11ea-814c-870967d77fd1.png)\n- Yolo v4 tiny comparison: [tiny_fps](https://user-images.githubusercontent.com/4096485/85734112-6e366700-b705-11ea-95d1-fcba0de76d72.png)\n- CSPNet: [paper](https://arxiv.org/abs/1911.11929) and [map_fps](https://user-images.githubusercontent.com/4096485/71702416-6645dc00-2de0-11ea-8d65-de7d4b604021.png) comparison: https://github.com/WongKinYiu/CrossStagePartialNetworks\n- Yolo v3 on MS COCO: [Speed / Accuracy (mAP@0.5) chart](https://user-images.githubusercontent.com/4096485/52151356-e5d4a380-2683-11e9-9d7d-ac7bc192c477.jpg)\n- Yolo v3 on MS COCO (Yolo v3 vs RetinaNet) - Figure 3: https://arxiv.org/pdf/1804.02767v1.pdf\n- Yolo v2 on Pascal VOC 2007: https://hsto.org/files/a24/21e/068/a2421e0689fb43f08584de9d44c2215f.jpg\n- Yolo v2 on Pascal VOC 2012 (comp4): https://hsto.org/files/3a6/fdf/b53/3a6fdfb533f34cee9b52bdd9bb0b19d9.jpg\n\n#### Youtube video of results\n\n| [![Yolo v4](https://user-images.githubusercontent.com/4096485/101360000-1a33cf00-38ae-11eb-9e5e-b29c5fb0afbe.png)](https://youtu.be/1_SiUOYUoOI \"Yolo v4\") |  [![Scaled Yolo v4](https://user-images.githubusercontent.com/4096485/101359389-43a02b00-38ad-11eb-866c-f813e96bf61a.png)](https://youtu.be/YDFf-TqJOFE \"Scaled Yolo v4\") |\n|---|---|\n\nOthers: https://www.youtube.com/user/pjreddie/videos\n\n#### How to evaluate AP of YOLOv4 on the MS COCO evaluation server\n\n1. Download and unzip test-dev2017 dataset from MS COCO server: http://images.cocodataset.org/zips/test2017.zip\n2. Download list of images for Detection tasks and replace the paths with yours: https://raw.githubusercontent.com/AlexeyAB/darknet/master/scripts/testdev2017.txt\n3. Download `yolov4.weights` file 245 MB: [yolov4.weights](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights) (Google-drive mirror [yolov4.weights](https://drive.google.com/open?id=1cewMfusmPjYWbrnuJRuKhPMwRe_b9PaT) )\n4. Content of the file `cfg/coco.data` should be\n\n```ini\nclasses= 80\ntrain  = <replace with your path>/trainvalno5k.txt\nvalid = <replace with your path>/testdev2017.txt\nnames = data/coco.names\nbackup = backup\neval=coco\n```\n\n5. Create `/results/` folder near with `./darknet` executable file\n6. Run validation: `./darknet detector valid cfg/coco.data cfg/yolov4.cfg yolov4.weights`\n7. Rename the file  `/results/coco_results.json` to `detections_test-dev2017_yolov4_results.json` and compress it to `detections_test-dev2017_yolov4_results.zip`\n8. Submit file `detections_test-dev2017_yolov4_results.zip` to the MS COCO evaluation server for the `test-dev2019 (bbox)`\n\n#### How to evaluate FPS of YOLOv4 on GPU\n\n1. Compile Darknet with `GPU=1 CUDNN=1 CUDNN_HALF=1 OPENCV=1` in the `Makefile`\n2. Download `yolov4.weights` file 245 MB: [yolov4.weights](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights) (Google-drive mirror [yolov4.weights](https://drive.google.com/open?id=1cewMfusmPjYWbrnuJRuKhPMwRe_b9PaT) )\n3. Get any .avi/.mp4 video file (preferably not more than 1920x1080 to avoid bottlenecks in CPU performance)\n4. Run one of two commands and look at the AVG FPS:\n\n- include video_capturing + NMS + drawing_bboxes:\n    `./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights test.mp4 -dont_show -ext_output`\n- exclude video_capturing + NMS + drawing_bboxes:\n    `./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights test.mp4 -benchmark`\n\n#### Pre-trained models\n\nThere are weights-file for different cfg-files (trained for MS COCO dataset):\n\nFPS on RTX 2070 (R) and Tesla V100 (V):\n\n- [yolov4-p6.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-p6.cfg) - 1280x1280 - **72.1% mAP@0.5 (54.0% AP@0.5:0.95) - 32(V) FPS** - xxx BFlops (xxx FMA) - 487 MB: [yolov4-p6.weights](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-p6.weights)\n  - pre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-p6.conv.289\n\n- [yolov4-p5.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-p5.cfg) - 896x896 - **70.0% mAP@0.5 (51.6% AP@0.5:0.95) - 43(V) FPS** - xxx BFlops (xxx FMA) - 271 MB: [yolov4-p5.weights](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-p5.weights)\n  - pre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-p5.conv.232\n\n- [yolov4-csp-x-swish.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-csp-x-swish.cfg) - 640x640 - **69.9% mAP@0.5 (51.5% AP@0.5:0.95) - 23(R) FPS / 50(V) FPS** - 221 BFlops (110 FMA) - 381 MB: [yolov4-csp-x-swish.weights](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-csp-x-swish.weights)\n  - pre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-csp-x-swish.conv.192\n\n- [yolov4-csp-swish.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-csp-swish.cfg) - 640x640 - **68.7% mAP@0.5 (50.0% AP@0.5:0.95) - 70(V) FPS** - 120 (60 FMA) - 202 MB: [yolov4-csp-swish.weights](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-csp-swish.weights)\n  - pre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-csp-swish.conv.164\n\n- [yolov4x-mish.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4x-mish.cfg) - 640x640 - **68.5% mAP@0.5 (50.1% AP@0.5:0.95) - 23(R) FPS / 50(V) FPS** - 221 BFlops (110 FMA) - 381 MB: [yolov4x-mish.weights](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4x-mish.weights)\n  - pre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4x-mish.conv.166\n\n- [yolov4-csp.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-csp.cfg) - 202 MB: [yolov4-csp.weights](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-csp.weights) paper [Scaled Yolo v4](https://arxiv.org/abs/2011.08036)\n\n    just change `width=` and `height=` parameters in `yolov4-csp.cfg` file and use the same `yolov4-csp.weights` file for all cases:\n  - `width=640 height=640` in cfg: **67.4% mAP@0.5 (48.7% AP@0.5:0.95) - 70(V) FPS** - 120 (60 FMA) BFlops\n  - `width=512 height=512` in cfg: **64.8% mAP@0.5 (46.2% AP@0.5:0.95) - 93(V) FPS** - 77 (39 FMA) BFlops\n  - pre-trained weights for training: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-csp.conv.142\n\n- [yolov4.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg) - 245 MB: [yolov4.weights](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights) (Google-drive mirror [yolov4.weights](https://drive.google.com/open?id=1cewMfusmPjYWbrnuJRuKhPMwRe_b9PaT) ) paper [Yolo v4](https://arxiv.org/abs/2004.10934)\n    just change `width=` and `height=` parameters in `yolov4.cfg` file and use the same `yolov4.weights` file for all cases:\n  - `width=608 height=608` in cfg: **65.7% mAP@0.5 (43.5% AP@0.5:0.95) - 34(R) FPS / 62(V) FPS** - 128.5 BFlops\n  - `width=512 height=512` in cfg: **64.9% mAP@0.5 (43.0% AP@0.5:0.95) - 45(R) FPS / 83(V) FPS** - 91.1 BFlops\n  - `width=416 height=416` in cfg: **62.8% mAP@0.5 (41.2% AP@0.5:0.95) - 55(R) FPS / 96(V) FPS** - 60.1 BFlops\n  - `width=320 height=320` in cfg:   **60% mAP@0.5 (  38% AP@0.5:0.95) - 63(R) FPS / 123(V) FPS** - 35.5 BFlops\n\n- [yolov4-tiny.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny.cfg) - **40.2% mAP@0.5 - 371(1080Ti) FPS / 330(RTX2070) FPS** - 6.9 BFlops - 23.1 MB: [yolov4-tiny.weights](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights)\n\n- [enet-coco.cfg (EfficientNetB0-Yolov3)](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/enet-coco.cfg) - **45.5% mAP@0.5 - 55(R) FPS** - 3.7 BFlops - 18.3 MB: [enetb0-coco_final.weights](https://drive.google.com/file/d/1FlHeQjWEQVJt0ay1PVsiuuMzmtNyv36m/view)\n\n- [yolov3-openimages.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3-openimages.cfg) - 247 MB - 18(R) FPS - OpenImages dataset: [yolov3-openimages.weights](https://pjreddie.com/media/files/yolov3-openimages.weights)\n\n<details><summary><b>CLICK ME</b> - Yolo v3 models</summary>\n\n- [csresnext50-panet-spp-original-optimal.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/csresnext50-panet-spp-original-optimal.cfg) - **65.4% mAP@0.5 (43.2% AP@0.5:0.95) - 32(R) FPS** - 100.5 BFlops - 217 MB: [csresnext50-panet-spp-original-optimal_final.weights](https://drive.google.com/open?id=1_NnfVgj0EDtb_WLNoXV8Mo7WKgwdYZCc)\n\n- [yolov3-spp.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3-spp.cfg) - **60.6% mAP@0.5 - 38(R) FPS** - 141.5 BFlops - 240 MB: [yolov3-spp.weights](https://pjreddie.com/media/files/yolov3-spp.weights)\n\n- [csresnext50-panet-spp.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/csresnext50-panet-spp.cfg) - **60.0% mAP@0.5 - 44 FPS** - 71.3 BFlops - 217 MB: [csresnext50-panet-spp_final.weights](https://drive.google.com/file/d/1aNXdM8qVy11nqTcd2oaVB3mf7ckr258-/view?usp=sharing)\n\n- [yolov3.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3.cfg) - **55.3% mAP@0.5 - 66(R) FPS** - 65.9 BFlops - 236 MB: [yolov3.weights](https://pjreddie.com/media/files/yolov3.weights)\n\n- [yolov3-tiny.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3-tiny.cfg) - **33.1% mAP@0.5 - 345(R) FPS** - 5.6 BFlops - 33.7 MB: [yolov3-tiny.weights](https://pjreddie.com/media/files/yolov3-tiny.weights)\n\n- [yolov3-tiny-prn.cfg](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3-tiny-prn.cfg) - **33.1% mAP@0.5 - 370(R) FPS** - 3.5 BFlops - 18.8 MB: [yolov3-tiny-prn.weights](https://drive.google.com/file/d/18yYZWyKbo4XSDVyztmsEcF9B_6bxrhUY/view?usp=sharing)\n\n</details>\n\n<details><summary><b>CLICK ME</b> - Yolo v2 models</summary>\n\n- `yolov2.cfg` (194 MB COCO Yolo v2) - requires 4 GB GPU-RAM: https://pjreddie.com/media/files/yolov2.weights\n- `yolo-voc.cfg` (194 MB VOC Yolo v2) - requires 4 GB GPU-RAM: http://pjreddie.com/media/files/yolo-voc.weights\n- `yolov2-tiny.cfg` (43 MB COCO Yolo v2) - requires 1 GB GPU-RAM: https://pjreddie.com/media/files/yolov2-tiny.weights\n- `yolov2-tiny-voc.cfg` (60 MB VOC Yolo v2) - requires 1 GB GPU-RAM: http://pjreddie.com/media/files/yolov2-tiny-voc.weights\n- `yolo9000.cfg` (186 MB Yolo9000-model) - requires 4 GB GPU-RAM: http://pjreddie.com/media/files/yolo9000.weights\n\n</details>\n\nPut it near compiled: darknet.exe\n\nYou can get cfg-files by path: `darknet/cfg/`\n\n### Requirements for Windows, Linux and macOS\n\n- **CMake >= 3.18**: https://cmake.org/download/\n- **Powershell** (already installed on windows): https://docs.microsoft.com/en-us/powershell/scripting/install/installing-powershell\n- **CUDA >= 10.2**: https://developer.nvidia.com/cuda-toolkit-archive (on Linux do [Post-installation Actions](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions))\n- **OpenCV >= 2.4**: use your preferred package manager (brew, apt), build from source using [vcpkg](https://github.com/Microsoft/vcpkg) or download from [OpenCV official site](https://opencv.org/releases.html) (on Windows set system variable `OpenCV_DIR` = `C:\\opencv\\build` - where are the `include` and `x64` folders [image](https://user-images.githubusercontent.com/4096485/53249516-5130f480-36c9-11e9-8238-a6e82e48c6f2.png))\n- **cuDNN >= 8.0.2** https://developer.nvidia.com/rdp/cudnn-archive (on **Linux** follow steps described here https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installlinux-tar , on **Windows** follow steps described here https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installwindows)\n- **GPU with CC >= 3.0**: https://en.wikipedia.org/wiki/CUDA#GPUs_supported\n\n### Yolo v4 in other frameworks\n\n- **Pytorch - Scaled-YOLOv4:** https://github.com/WongKinYiu/ScaledYOLOv4\n- **TensorFlow:** `pip install yolov4` YOLOv4 on TensorFlow 2.0 / TFlite / Android: https://github.com/hunglc007/tensorflow-yolov4-tflite\n    Official TF models: https://github.com/tensorflow/models/tree/master/official/vision/beta/projects/yolo\n    For YOLOv4 - convert `yolov4.weights`/`cfg` files to `yolov4.pb` by using [TNTWEN](https://github.com/TNTWEN/OpenVINO-YOLOV4) project, and to `yolov4.tflite` [TensorFlow-lite](https://www.tensorflow.org/lite/guide/get_started#2_convert_the_model_format)\n- **OpenCV** the fastest implementation of YOLOv4 for CPU (x86/ARM-Android), OpenCV can be compiled with [OpenVINO-backend](https://github.com/opencv/opencv/wiki/Intel's-Deep-Learning-Inference-Engine-backend) for running on (Myriad X / USB Neural Compute Stick / Arria FPGA), use `yolov4.weights`/`cfg` with: [C++ example](https://github.com/opencv/opencv/blob/8c25a8eb7b10fb50cda323ee6bec68aa1a9ce43c/samples/dnn/object_detection.cpp#L192-L221) or [Python example](https://github.com/opencv/opencv/blob/8c25a8eb7b10fb50cda323ee6bec68aa1a9ce43c/samples/dnn/object_detection.py#L129-L150)\n- **Intel OpenVINO 2021.2:** supports YOLOv4 (NPU Myriad X / USB Neural Compute Stick / Arria FPGA): https://devmesh.intel.com/projects/openvino-yolov4-49c756 read this [manual](https://github.com/TNTWEN/OpenVINO-YOLOV4) (old [manual](https://software.intel.com/en-us/articles/OpenVINO-Using-TensorFlow#converting-a-darknet-yolo-model) ) (for [Scaled-YOLOv4](https://github.com/WongKinYiu/ScaledYOLOv4/tree/yolov4-large) models use https://github.com/Chen-MingChang/pytorch_YOLO_OpenVINO_demo )\n- **PyTorch > ONNX**:\n  - [WongKinYiu/PyTorch_YOLOv4](https://github.com/WongKinYiu/PyTorch_YOLOv4)\n  - [maudzung/3D-YOLOv4](https://github.com/maudzung/Complex-YOLOv4-Pytorch)\n  - [Tianxiaomo/pytorch-YOLOv4](https://github.com/Tianxiaomo/pytorch-YOLOv4)\n  - [YOLOv5](https://github.com/ultralytics/yolov5)\n- **ONNX** on Jetson for YOLOv4: https://developer.nvidia.com/blog/announcing-onnx-runtime-for-jetson/ and https://github.com/ttanzhiqiang/onnx_tensorrt_project\n- **nVidia Transfer Learning Toolkit (TLT>=3.0)** Training and Detection https://docs.nvidia.com/metropolis/TLT/tlt-user-guide/text/object_detection/yolo_v4.html\n- **TensorRT+tkDNN**: https://github.com/ceccocats/tkDNN#fps-results\n- **Deepstream 5.0 / TensorRT for YOLOv4** https://github.com/NVIDIA-AI-IOT/yolov4_deepstream or https://github.com/marcoslucianops/DeepStream-Yolo read [Yolo is natively supported in DeepStream 4.0](https://news.developer.nvidia.com/deepstream-sdk-4-now-available/) and [PDF](https://docs.nvidia.com/metropolis/deepstream/Custom_YOLO_Model_in_the_DeepStream_YOLO_App.pdf). Additionally [jkjung-avt/tensorrt_demos](https://github.com/jkjung-avt/tensorrt_demos) or [wang-xinyu/tensorrtx](https://github.com/wang-xinyu/tensorrtx)\n- **Triton Inference Server / TensorRT** https://github.com/isarsoft/yolov4-triton-tensorrt\n- **DirectML** https://github.com/microsoft/DirectML/tree/master/Samples/yolov4\n- **OpenCL** (Intel, AMD, Mali GPUs for macOS & GNU/Linux) https://github.com/sowson/darknet\n- **HIP** for Training and Detection on AMD GPU https://github.com/os-hackathon/darknet\n- **ROS** (Robot Operating System) https://github.com/engcang/ros-yolo-sort\n- **Xilinx Zynq Ultrascale+ Deep Learning Processor (DPU) ZCU102/ZCU104:** https://github.com/Xilinx/Vitis-In-Depth-Tutorial/tree/master/Machine_Learning/Design_Tutorials/07-yolov4-tutorial\n- **Amazon Neurochip / Amazon EC2 Inf1 instances** 1.85 times higher throughput and 37% lower cost per image for TensorFlow based YOLOv4 model, using Keras [URL](https://aws.amazon.com/ru/blogs/machine-learning/improving-performance-for-deep-learning-based-object-detection-with-an-aws-neuron-compiled-yolov4-model-on-aws-inferentia/)\n- **TVM** - compilation of deep learning models (Keras, MXNet, PyTorch, Tensorflow, CoreML, DarkNet) into minimum deployable modules on diverse hardware backend (CPUs, GPUs, FPGA, and specialized accelerators): https://tvm.ai/about\n- **Tencent/ncnn:** the fastest inference of YOLOv4 on mobile phone CPU: https://github.com/Tencent/ncnn\n- **OpenDataCam** - It detects, tracks and counts moving objects by using YOLOv4: https://github.com/opendatacam/opendatacam#-hardware-pre-requisite\n- **Netron** - Visualizer for neural networks: https://github.com/lutzroeder/netron\n\n#### Datasets\n\n- MS COCO: use `./scripts/get_coco_dataset.sh` to get labeled MS COCO detection dataset\n- OpenImages: use `python ./scripts/get_openimages_dataset.py` for labeling train detection dataset\n- Pascal VOC: use `python ./scripts/voc_label.py` for labeling Train/Test/Val detection datasets\n- ILSVRC2012 (ImageNet classification): use `./scripts/get_imagenet_train.sh` (also `imagenet_label.sh` for labeling valid set)\n- German/Belgium/Russian/LISA/MASTIF Traffic Sign Datasets for Detection - use this parsers: https://github.com/angeligareta/Datasets2Darknet#detection-task\n- List of other datasets: https://github.com/AlexeyAB/darknet/tree/master/scripts#datasets\n\n### Improvements in this repository\n\n- developed State-of-the-Art object detector YOLOv4\n- added State-of-Art models: CSP, PRN, EfficientNet\n- added layers: [conv_lstm], [scale_channels] SE/ASFF/BiFPN, [local_avgpool], [sam], [Gaussian_yolo], [reorg3d] (fixed [reorg]), fixed [batchnorm]\n- added the ability for training recurrent models (with layers conv-lstm`[conv_lstm]`/conv-rnn`[crnn]`) for accurate detection on video\n- added data augmentation: `[net] mixup=1 cutmix=1 mosaic=1 blur=1`. Added activations: SWISH, MISH, NORM_CHAN, NORM_CHAN_SOFTMAX\n- added the ability for training with GPU-processing using CPU-RAM to increase the mini_batch_size and increase accuracy (instead of batch-norm sync)\n- improved binary neural network performance **2x-4x times** for Detection on CPU and GPU if you trained your own weights by using this XNOR-net model (bit-1 inference) : https://github.com/AlexeyAB/darknet/blob/master/cfg/yolov3-tiny_xnor.cfg\n- improved neural network performance **~7%** by fusing 2 layers into 1: Convolutional + Batch-norm\n- improved performance: Detection **2x times**, on GPU Volta/Turing (Tesla V100, GeForce RTX, ...) using Tensor Cores if `CUDNN_HALF` defined in the `Makefile` or `darknet.sln`\n- improved performance **~1.2x** times on FullHD, **~2x** times on 4K, for detection on the video (file/stream) using `darknet detector demo`...\n- improved performance **3.5 X times** of data augmentation for training (using OpenCV SSE/AVX functions instead of hand-written functions) - removes bottleneck for training on multi-GPU or GPU Volta\n- improved performance of detection and training on Intel CPU with AVX (Yolo v3 **~85%**)\n- optimized memory allocation during network resizing when `random=1`\n- optimized GPU initialization for detection - we use batch=1 initially instead of re-init with batch=1\n- added correct calculation of **mAP, F1, IoU, Precision-Recall** using command `darknet detector map`...\n- added drawing of chart of average-Loss and accuracy-mAP (`-map` flag) during training\n- run `./darknet detector demo ... -json_port 8070 -mjpeg_port 8090` as JSON and MJPEG server to get results online over the network by using your soft or Web-browser\n- added calculation of anchors for training\n- added example of Detection and Tracking objects: https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp\n- run-time tips and warnings if you use incorrect cfg-file or dataset\n- added support for Windows\n- many other fixes of code...\n\nAnd added manual - [How to train Yolo v4-v2 (to detect your custom objects)](#how-to-train-to-detect-your-custom-objects)\n\nAlso, you might be interested in using a simplified repository where is implemented INT8-quantization (+30% speedup and -1% mAP reduced): https://github.com/AlexeyAB/yolo2_light\n\n#### How to use on the command line\n\nIf you use `build.ps1` script or the makefile (Linux only) you will find `darknet` in the root directory.\n\nIf you use the deprecated Visual Studio solutions, you will find `darknet` in the directory `\\build\\darknet\\x64`.\n\nIf you customize build with CMake GUI, darknet executable will be installed in your preferred folder.\n\n- Yolo v4 COCO - **image**: `./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights -thresh 0.25`\n- **Output coordinates** of objects: `./darknet detector test cfg/coco.data yolov4.cfg yolov4.weights -ext_output dog.jpg`\n- Yolo v4 COCO - **video**: `./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights -ext_output test.mp4`\n- Yolo v4 COCO - **WebCam 0**: `./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights -c 0`\n- Yolo v4 COCO for **net-videocam** - Smart WebCam: `./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights http://192.168.0.80:8080/video?dummy=param.mjpg`\n- Yolo v4 - **save result videofile res.avi**: `./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights test.mp4 -out_filename res.avi`\n- Yolo v3 **Tiny** COCO - video: `./darknet detector demo cfg/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights test.mp4`\n- **JSON and MJPEG server** that allows multiple connections from your soft or Web-browser `ip-address:8070` and 8090: `./darknet detector demo ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights test50.mp4 -json_port 8070 -mjpeg_port 8090 -ext_output`\n- Yolo v3 Tiny **on GPU #1**: `./darknet detector demo cfg/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights -i 1 test.mp4`\n- Alternative method Yolo v3 COCO - image: `./darknet detect cfg/yolov4.cfg yolov4.weights -i 0 -thresh 0.25`\n- Train on **Amazon EC2**, to see mAP & Loss-chart using URL like: `http://ec2-35-160-228-91.us-west-2.compute.amazonaws.com:8090` in the Chrome/Firefox (**Darknet should be compiled with OpenCV**):\n    `./darknet detector train cfg/coco.data yolov4.cfg yolov4.conv.137 -dont_show -mjpeg_port 8090 -map`\n- 186 MB Yolo9000 - image: `./darknet detector test cfg/combine9k.data cfg/yolo9000.cfg yolo9000.weights`\n- Remember to put data/9k.tree and data/coco9k.map under the same folder of your app if you use the cpp api to build an app\n- To process a list of images `data/train.txt` and save results of detection to `result.json` file use:\n    `./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights -ext_output -dont_show -out result.json < data/train.txt`\n- To process a list of images `data/train.txt` and save results of detection to `result.txt` use:\n    `./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights -dont_show -ext_output < data/train.txt > result.txt`\n- Pseudo-labelling - to process a list of images `data/new_train.txt` and save results of detection in Yolo training format for each image as label `<image_name>.txt` (in this way you can increase the amount of training data) use:\n    `./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights -thresh 0.25 -dont_show -save_labels < data/new_train.txt`\n- To calculate anchors: `./darknet detector calc_anchors data/obj.data -num_of_clusters 9 -width 416 -height 416`\n- To check accuracy mAP@IoU=50: `./darknet detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_7000.weights`\n- To check accuracy mAP@IoU=75: `./darknet detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_7000.weights -iou_thresh 0.75`\n\n##### For using network video-camera mjpeg-stream with any Android smartphone\n\n1. Download for Android phone mjpeg-stream soft: IP Webcam / Smart WebCam\n\n    - Smart WebCam - preferably: https://play.google.com/store/apps/details?id=com.acontech.android.SmartWebCam2\n    - IP Webcam: https://play.google.com/store/apps/details?id=com.pas.webcam\n\n2. Connect your Android phone to computer by WiFi (through a WiFi-router) or USB\n3. Start Smart WebCam on your phone\n4. Replace the address below, on shown in the phone application (Smart WebCam) and launch:\n\n- Yolo v4 COCO-model: `./darknet detector demo data/coco.data yolov4.cfg yolov4.weights http://192.168.0.80:8080/video?dummy=param.mjpg -i 0`\n\n### How to compile on Linux/macOS (using `CMake`)\n\nThe `CMakeLists.txt` will attempt to find installed optional dependencies like CUDA, cudnn, ZED and build against those. It will also create a shared object library file to use `darknet` for code development.\n\nTo update CMake on Ubuntu, it's better to follow guide here: https://apt.kitware.com/ or https://cmake.org/download/\n\n```bash\ngit clone https://github.com/AlexeyAB/darknet\ncd darknet\nmkdir build_release\ncd build_release\ncmake ..\ncmake --build . --target install --parallel 8\n```\n\n### Using also PowerShell\n\nInstall: `Cmake`, `CUDA`, `cuDNN` [How to install dependencies](#requirements)\n\nInstall powershell for your OS (Linux or MacOS) ([guide here](https://docs.microsoft.com/en-us/powershell/scripting/install/installing-powershell)).\n\nOpen PowerShell type these commands\n\n```PowerShell\ngit clone https://github.com/AlexeyAB/darknet\ncd darknet\n./build.ps1 -UseVCPKG -EnableOPENCV -EnableCUDA -EnableCUDNN\n```\n\n- remove options like `-EnableCUDA` or `-EnableCUDNN` if you are not interested into\n- remove option `-UseVCPKG` if you plan to manually provide OpenCV library to darknet or if you do not want to enable OpenCV integration\n- add option `-EnableOPENCV_CUDA` if you want to build OpenCV with CUDA support - very slow to build! (requires `-UseVCPKG`)\n\nIf you open the `build.ps1` script at the beginning you will find all available switches.\n\n### How to compile on Linux (using `make`)\n\nJust do `make` in the darknet directory. (You can try to compile and run it on Google Colab in cloud [link](https://colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE) (press \u00abOpen in Playground\u00bb button at the top-left corner) and watch the video [link](https://www.youtube.com/watch?v=mKAEGSxwOAY) )\nBefore make, you can set such options in the `Makefile`: [link](https://github.com/AlexeyAB/darknet/blob/9c1b9a2cf6363546c152251be578a21f3c3caec6/Makefile#L1)\n\n- `GPU=1` to build with CUDA to accelerate by using GPU (CUDA should be in `/usr/local/cuda`)\n- `CUDNN=1` to build with cuDNN v5-v7 to accelerate training by using GPU (cuDNN should be in `/usr/local/cudnn`)\n- `CUDNN_HALF=1` to build for Tensor Cores (on Titan V / Tesla V100 / DGX-2 and later) speedup Detection 3x, Training 2x\n- `OPENCV=1` to build with OpenCV 4.x/3.x/2.4.x - allows to detect on video files and video streams from network cameras or web-cams\n- `DEBUG=1` to build debug version of Yolo\n- `OPENMP=1` to build with OpenMP support to accelerate Yolo by using multi-core CPU\n- `LIBSO=1` to build a library `darknet.so` and binary runnable file `uselib` that uses this library. Or you can try to run so `LD_LIBRARY_PATH=./:$LD_LIBRARY_PATH ./uselib test.mp4` How to use this SO-library from your own code - you can look at C++ example: https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp\n    or use in such a way: `LD_LIBRARY_PATH=./:$LD_LIBRARY_PATH ./uselib data/coco.names cfg/yolov4.cfg yolov4.weights test.mp4`\n- `ZED_CAMERA=1` to build a library with ZED-3D-camera support (should be ZED SDK installed), then run\n    `LD_LIBRARY_PATH=./:$LD_LIBRARY_PATH ./uselib data/coco.names cfg/yolov4.cfg yolov4.weights zed_camera`\n- You also need to specify for which graphics card the code is generated. This is done by setting `ARCH=`. If you use a never version than CUDA 11 you further need to edit line 20 from Makefile and remove `-gencode arch=compute_30,code=sm_30 \\` as Kepler GPU support was dropped in CUDA 11. You can also drop the general `ARCH=` and just uncomment `ARCH=` for your graphics card.\n\n### How to compile on Windows (using `CMake`)\n\nRequires:\n\n- MSVC: https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community\n- CMake GUI: `Windows win64-x64 Installer`https://cmake.org/download/\n- Download Darknet zip-archive with the latest commit and uncompress it: [master.zip](https://github.com/AlexeyAB/darknet/archive/master.zip)\n\nIn Windows:\n\n- Start (button) -> All programs -> CMake -> CMake (gui) ->\n\n- [look at image](https://habrastorage.org/webt/pz/s1/uu/pzs1uu4heb7vflfcjqn-lxy-aqu.jpeg) In CMake: Enter input path to the darknet Source, and output path to the Binaries -> Configure (button) -> Optional platform for generator: `x64`  -> Finish -> Generate -> Open Project ->\n\n- in MS Visual Studio: Select: x64 and Release -> Build -> Build solution\n\n- find the executable file `darknet.exe` in the output path to the binaries you specified\n\n![x64 and Release](https://habrastorage.org/webt/ay/ty/f-/aytyf-8bufe7q-16yoecommlwys.jpeg)\n\n### How to compile on Windows (using `vcpkg`)\n\nThis is the recommended approach to build Darknet on Windows.\n\n1. Install Visual Studio 2017 or 2019. In case you need to download it, please go here: [Visual Studio Community](http://visualstudio.com). Remember to install English language pack, this is mandatory for vcpkg!\n\n2. Install CUDA enabling VS Integration during installation.\n\n3. Open Powershell (Start -> All programs -> Windows Powershell) and type these commands:\n\n```PowerShell\nSet-ExecutionPolicy unrestricted -Scope CurrentUser -Force\ngit clone https://github.com/AlexeyAB/darknet\ncd darknet\n.\\build.ps1 -UseVCPKG -EnableOPENCV -EnableCUDA -EnableCUDNN\n```\n\n(add option `-EnableOPENCV_CUDA` if you want to build OpenCV with CUDA support - very slow to build! - or remove options like `-EnableCUDA` or `-EnableCUDNN` if you are not interested in them). If you open the `build.ps1` script at the beginning you will find all available switches.\n\n## How to train with multi-GPU\n\n1. Train it first on 1 GPU for like 1000 iterations: `darknet.exe detector train cfg/coco.data cfg/yolov4.cfg yolov4.conv.137`\n\n2. Then stop and by using partially-trained model `/backup/yolov4_1000.weights` run training with multigpu (up to 4 GPUs): `darknet.exe detector train cfg/coco.data cfg/yolov4.cfg /backup/yolov4_1000.weights -gpus 0,1,2,3`\n\nIf you get a Nan, then for some datasets better to decrease learning rate, for 4 GPUs set `learning_rate = 0,00065` (i.e. learning_rate = 0.00261 / GPUs). In this case also increase 4x times `burn_in =` in your cfg-file. I.e. use `burn_in = 4000` instead of `1000`.\n\nhttps://groups.google.com/d/msg/darknet/NbJqonJBTSY/Te5PfIpuCAAJ\n\n## How to train (to detect your custom objects)\n\n(to train old Yolo v2 `yolov2-voc.cfg`, `yolov2-tiny-voc.cfg`, `yolo-voc.cfg`, `yolo-voc.2.0.cfg`, ... [click by the link](https://github.com/AlexeyAB/darknet/tree/47c7af1cea5bbdedf1184963355e6418cb8b1b4f#how-to-train-pascal-voc-data))\n\nTraining Yolo v4 (and v3):\n\n0. For training `cfg/yolov4-custom.cfg` download the pre-trained weights-file (162 MB): [yolov4.conv.137](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137) (Google drive mirror [yolov4.conv.137](https://drive.google.com/open?id=1JKF-bdIklxOOVy-2Cr5qdvjgGpmGfcbp) )\n1. Create file `yolo-obj.cfg` with the same content as in `yolov4-custom.cfg` (or copy `yolov4-custom.cfg` to `yolo-obj.cfg)` and:\n\n- change line batch to [`batch=64`](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L3)\n- change line subdivisions to [`subdivisions=16`](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L4)\n- change line max_batches to (`classes*2000`, but not less than number of training images and not less than `6000`), f.e. [`max_batches=6000`](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L20) if you train for 3 classes\n- change line steps to 80% and 90% of max_batches, f.e. [`steps=4800,5400`](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L22)\n- set network size `width=416 height=416` or any value multiple of 32: https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L8-L9\n- change line `classes=80` to your number of objects in each of 3 `[yolo]`-layers:\n  - https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L610\n  - https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L696\n  - https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L783\n- change [`filters=255`] to filters=(classes + 5)x3 in the 3 `[convolutional]` before each `[yolo]` layer, keep in mind that it only has to be the last `[convolutional]` before each of the `[yolo]` layers.\n  - https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L603\n  - https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L689\n  - https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L776\n- when using [`[Gaussian_yolo]`](https://github.com/AlexeyAB/darknet/blob/6e5bdf1282ad6b06ed0e962c3f5be67cf63d96dc/cfg/Gaussian_yolov3_BDD.cfg#L608)  layers, change [`filters=57`] filters=(classes + 9)x3 in the 3 `[convolutional]` before each `[Gaussian_yolo]` layer\n  - https://github.com/AlexeyAB/darknet/blob/6e5bdf1282ad6b06ed0e962c3f5be67cf63d96dc/cfg/Gaussian_yolov3_BDD.cfg#L604\n  - https://github.com/AlexeyAB/darknet/blob/6e5bdf1282ad6b06ed0e962c3f5be67cf63d96dc/cfg/Gaussian_yolov3_BDD.cfg#L696\n  - https://github.com/AlexeyAB/darknet/blob/6e5bdf1282ad6b06ed0e962c3f5be67cf63d96dc/cfg/Gaussian_yolov3_BDD.cfg#L789\n\nSo if `classes=1` then should be `filters=18`. If `classes=2` then write `filters=21`.\n**(Do not write in the cfg-file: filters=(classes + 5)x3)**\n\n(Generally `filters` depends on the `classes`, `coords` and number of `mask`s, i.e. filters=`(classes + coords + 1)*<number of mask>`, where `mask` is indices of anchors. If `mask` is absence, then filters=`(classes + coords + 1)*num`)\n\nSo for example, for 2 objects, your file `yolo-obj.cfg` should differ from `yolov4-custom.cfg` in such lines in each of **3** [yolo]-layers:\n\n```ini\n[convolutional]\nfilters=21\n\n[region]\nclasses=2\n```\n\n2. Create file `obj.names` in the directory `build\\darknet\\x64\\data\\`, with objects names - each in new line\n3. Create file `obj.data` in the directory `build\\darknet\\x64\\data\\`, containing (where **classes = number of objects**):\n\n  ```ini\n  classes = 2\n  train  = data/train.txt\n  valid  = data/test.txt\n  names = data/obj.names\n  backup = backup/\n  ```\n\n4. Put image-files (.jpg) of your objects in the directory `build\\darknet\\x64\\data\\obj\\`\n5. You should label each object on images from your dataset. Use this visual GUI-software for marking bounded boxes of objects and generating annotation files for Yolo v2 & v3: https://github.com/AlexeyAB/Yolo_mark\n\nIt will create `.txt`-file for each `.jpg`-image-file - in the same directory and with the same name, but with `.txt`-extension, and put to file: object number and object coordinates on this image, for each object in new line:\n\n`<object-class> <x_center> <y_center> <width> <height>`\n\n  Where:\n\n- `<object-class>` - integer object number from `0` to `(classes-1)`\n- `<x_center> <y_center> <width> <height>` - float values **relative** to width and height of image, it can be equal from `(0.0 to 1.0]`\n- for example: `<x> = <absolute_x> / <image_width>` or `<height> = <absolute_height> / <image_height>`\n- attention: `<x_center> <y_center>` - are center of rectangle (are not top-left corner)\n\n  For example for `img1.jpg` you will be created `img1.txt` containing:\n\n  ```csv\n  1 0.716797 0.395833 0.216406 0.147222\n  0 0.687109 0.379167 0.255469 0.158333\n  1 0.420312 0.395833 0.140625 0.166667\n  ```\n\n6. Create file `train.txt` in directory `build\\darknet\\x64\\data\\`, with filenames of your images, each filename in new line, with path relative to `darknet.exe`, for example containing:\n\n  ```csv\n  data/obj/img1.jpg\n  data/obj/img2.jpg\n  data/obj/img3.jpg\n  ```\n\n7. Download pre-trained weights for the convolutional layers and put to the directory `build\\darknet\\x64`\n    - for `yolov4.cfg`, `yolov4-custom.cfg` (162 MB): [yolov4.conv.137](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137) (Google drive mirror [yolov4.conv.137](https://drive.google.com/open?id=1JKF-bdIklxOOVy-2Cr5qdvjgGpmGfcbp) )\n    - for `yolov4-tiny.cfg`, `yolov4-tiny-3l.cfg`, `yolov4-tiny-custom.cfg` (19 MB): [yolov4-tiny.conv.29](https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29)  \n    - for `csresnext50-panet-spp.cfg` (133 MB): [csresnext50-panet-spp.conv.112](https://drive.google.com/file/d/16yMYCLQTY_oDlCIZPfn_sab6KD3zgzGq/view?usp=sharing)\n    - for `yolov3.cfg, yolov3-spp.cfg` (154 MB): [darknet53.conv.74](https://pjreddie.com/media/files/darknet53.conv.74)\n    - for `yolov3-tiny-prn.cfg , yolov3-tiny.cfg` (6 MB): [yolov3-tiny.conv.11](https://drive.google.com/file/d/18v36esoXCh-PsOKwyP2GWrpYDptDY8Zf/view?usp=sharing)\n    - for `enet-coco.cfg (EfficientNetB0-Yolov3)` (14 MB): [enetb0-coco.conv.132](https://drive.google.com/file/d/1uhh3D6RSn0ekgmsaTcl-ZW53WBaUDo6j/view?usp=sharing)\n\n8. Start training by using the command line: `darknet.exe detector train data/obj.data yolo-obj.cfg yolov4.conv.137`\n\n   To train on Linux use command: `./darknet detector train data/obj.data yolo-obj.cfg yolov4.conv.137` (just use `./darknet` instead of `darknet.exe`)\n\n   - (file `yolo-obj_last.weights` will be saved to the `build\\darknet\\x64\\backup\\` for each 100 iterations)\n   - (file `yolo-obj_xxxx.weights` will be saved to the `build\\darknet\\x64\\backup\\` for each 1000 iterations)\n   - (to disable Loss-Window use `darknet.exe detector train data/obj.data yolo-obj.cfg yolov4.conv.137 -dont_show`, if you train on computer without monitor like a cloud Amazon EC2)\n   - (to see the mAP & Loss-chart during training on remote server without GUI, use command `darknet.exe detector train data/obj.data yolo-obj.cfg yolov4.conv.137 -dont_show -mjpeg_port 8090 -map` then open URL `http://ip-address:8090` in Chrome/Firefox browser)\n\n8.1. For training with mAP (mean average precisions) calculation for each 4 Epochs (set `valid=valid.txt` or `train.txt` in `obj.data` file) and run: `darknet.exe detector train data/obj.data yolo-obj.cfg yolov4.conv.137 -map`\n\n9. After training is complete - get result `yolo-obj_final.weights` from path `build\\darknet\\x64\\backup\\`\n\n   - After each 100 iterations you can stop and later start training from this point. For example, after 2000 iterations you can stop training, and later just start training using: `darknet.exe detector train data/obj.data yolo-obj.cfg backup\\yolo-obj_2000.weights`\n\n    (in the original repository https://github.com/pjreddie/darknet the weights-file is saved only once every 10 000 iterations `if(iterations > 1000)`)\n\n   - Also you can get result earlier than all 45000 iterations.\n\n **Note:** If during training you see `nan` values for `avg` (loss) field - then training goes wrong, but if `nan` is in some other lines - then training goes well.\n\n **Note:** If you changed width= or height= in your cfg-file, then new width and height must be divisible by 32.\n\n **Note:** After training use such command for detection: `darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights`\n\n  **Note:** if error `Out of memory` occurs then in `.cfg`-file you should increase `subdivisions=16`, 32 or 64: [link](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L4)\n\n### How to train tiny-yolo (to detect your custom objects)\n\nDo all the same steps as for the full yolo model as described above. With the exception of:\n\n- Download file with the first 29-convolutional layers of yolov4-tiny: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\n (Or get this file from yolov4-tiny.weights file by using command: `darknet.exe partial cfg/yolov4-tiny-custom.cfg yolov4-tiny.weights yolov4-tiny.conv.29 29`\n- Make your custom model `yolov4-tiny-obj.cfg` based on `cfg/yolov4-tiny-custom.cfg` instead of `yolov4.cfg`\n- Start training: `darknet.exe detector train data/obj.data yolov4-tiny-obj.cfg yolov4-tiny.conv.29`\n\nFor training Yolo based on other models ([DenseNet201-Yolo](https://github.com/AlexeyAB/darknet/blob/master/build/darknet/x64/densenet201_yolo.cfg) or [ResNet50-Yolo](https://github.com/AlexeyAB/darknet/blob/master/build/darknet/x64/resnet50_yolo.cfg)), you can download and get pre-trained weights as showed in this file: https://github.com/AlexeyAB/darknet/blob/master/build/darknet/x64/partial.cmd\nIf you made you custom model that isn't based on other models, then you can train it without pre-trained weights, then will be used random initial weights.\n\n## When should I stop training\n\nUsually sufficient 2000 iterations for each class(object), but not less than number of training images and not less than 6000 iterations in total. But for a more precise definition when you should stop training, use the following manual:\n\n1. During training, you will see varying indicators of error, and you should stop when no longer decreases **0.XXXXXXX avg**:\n\n  > Region Avg IOU: 0.798363, Class: 0.893232, Obj: 0.700808, No Obj: 0.004567, Avg Recall: 1.000000,  count: 8\n  > Region Avg IOU: 0.800677, Class: 0.892181, Obj: 0.701590, No Obj: 0.004574, Avg Recall: 1.000000,  count: 8\n  >\n  > **9002**: 0.211667, **0.60730 avg**, 0.001000 rate, 3.868000 seconds, 576128 images\n  > Loaded: 0.000000 seconds\n\n- **9002** - iteration number (number of batch)\n- **0.60730 avg** - average loss (error) - **the lower, the better**\n\n  When you see that average loss **0.xxxxxx avg** no longer decreases at many iterations then you should stop training. The final average loss can be from `0.05` (for a small model and easy dataset) to `3.0` (for a big model and a difficult dataset).\n  \n  Or if you train with flag `-map` then you will see mAP indicator `Last accuracy mAP@0.5 = 18.50%` in the console - this indicator is better than Loss, so train while mAP increases.\n\n2. Once training is stopped, you should take some of last `.weights`-files from `darknet\\build\\darknet\\x64\\backup` and choose the best of them:\n\nFor example, you stopped training after 9000 iterations, but the best result can give one of previous weights (7000, 8000, 9000). It can happen due to over-fitting. **Over-fitting** - is case when you can detect objects on images from training-dataset, but can't detect objects on any others images. You should get weights from **Early Stopping Point**:\n\n![Over-fitting](https://hsto.org/files/5dc/7ae/7fa/5dc7ae7fad9d4e3eb3a484c58bfc1ff5.png)\n\nTo get weights from Early Stopping Point:\n\n  2.1. At first, in your file `obj.data` you must specify the path to the validation dataset `valid = valid.txt` (format of `valid.txt` as in `train.txt`), and if you haven't validation images, just copy `data\\train.txt` to `data\\valid.txt`.\n\n  2.2 If training is stopped after 9000 iterations, to validate some of previous weights use this commands:\n\n(If you use another GitHub repository, then use `darknet.exe detector recall`... instead of `darknet.exe detector map`...)\n\n- `darknet.exe detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_7000.weights`\n- `darknet.exe detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_8000.weights`\n- `darknet.exe detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_9000.weights`\n\nAnd compare last output lines for each weights (7000, 8000, 9000):\n\nChoose weights-file **with the highest mAP (mean average precision)** or IoU (intersect over union)\n\nFor example, **bigger mAP** gives weights `yolo-obj_8000.weights` - then **use this weights for detection**.\n\nOr just train with `-map` flag:\n\n`darknet.exe detector train data/obj.data yolo-obj.cfg yolov4.conv.137 -map`\n\nSo you will see mAP-chart (red-line) in the Loss-chart Window. mAP will be calculated for each 4 Epochs using `valid=valid.txt` file that is specified in `obj.data` file (`1 Epoch = images_in_train_txt / batch` iterations)\n\n(to change the max x-axis value - change [`max_batches=`](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L20) parameter to `2000*classes`, f.e. `max_batches=6000` for 3 classes)\n\n![loss_chart_map_chart](https://hsto.org/webt/yd/vl/ag/ydvlagutof2zcnjodstgroen8ac.jpeg)\n\nExample of custom object detection: `darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights`\n\n- **IoU** (intersect over union) - average intersect over union of objects and detections for a certain threshold = 0.24\n\n- **mAP** (mean average precision) - mean value of `average precisions` for each class, where `average precision` is average value of 11 points on PR-curve for each possible threshold (each probability of detection) for the same class (Precision-Recall in terms of PascalVOC, where Precision=TP/(TP+FP) and Recall=TP/(TP+FN) ), page-11: http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf\n\n**mAP** is default metric of precision in the PascalVOC competition, **this is the same as AP50** metric in the MS COCO competition.\nIn terms of Wiki, indicators Precision and Recall have a slightly different meaning than in the PascalVOC competition, but **IoU always has the same meaning**.\n\n![precision_recall_iou](https://hsto.org/files/ca8/866/d76/ca8866d76fb840228940dbf442a7f06a.jpg)\n\n### Custom object detection\n\nExample of custom object detection: `darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights`\n\n| ![Yolo_v2_training](https://hsto.org/files/d12/1e7/515/d121e7515f6a4eb694913f10de5f2b61.jpg) | ![Yolo_v2_training](https://hsto.org/files/727/c7e/5e9/727c7e5e99bf4d4aa34027bb6a5e4bab.jpg) |\n|---|---|\n\n## How to improve object detection\n\n1. Before training:\n\n- set flag `random=1` in your `.cfg`-file - it will increase precision by training Yolo for different resolutions: [link](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L788)\n\n- increase network resolution in your `.cfg`-file (`height=608`, `width=608` or any value multiple of 32) - it will increase precision\n\n- check that each object that you want to detect is mandatory labeled in your dataset - no one object in your data set should not be without label. In the most training issues - there are wrong labels in your dataset (got labels by using some conversion script, marked with a third-party tool, ...). Always check your dataset by using: https://github.com/AlexeyAB/Yolo_mark\n\n- my Loss is very high and mAP is very low, is training wrong? Run training with `-show_imgs` flag at the end of training command, do you see correct bounded boxes of objects (in windows or in files `aug_...jpg`)? If no - your training dataset is wrong.\n\n- for each object which you want to detect - there must be at least 1 similar object in the Training dataset with about the same: shape, side of object, relative size, angle of rotation, tilt, illumination. So desirable that your training dataset include images with objects at different: scales, rotations, lightings, from different sides, on different backgrounds - you should preferably have 2000 different images for each class or more, and you should train `2000*classes` iterations or more\n\n- desirable that your training dataset include images with non-labeled objects that you do not want to detect - negative samples without bounded box (empty `.txt` files) - use as many images of negative samples as there are images with objects\n\n- What is the best way to mark objects: label only the visible part of the object, or label the visible and overlapped part of the object, or label a little more than the entire object (with a little gap)? Mark as you like - how would you like it to be detected.\n\n- for training with a large number of objects in each image, add the parameter `max=200` or higher value in the last `[yolo]`-layer or `[region]`-layer in your cfg-file (the global maximum number of objects that can be detected by YoloV3 is `0,0615234375*(width*height)` where are width and height are parameters from `[net]` section in cfg-file)\n  \n- for training for small objects (smaller than 16x16 after the image is resized to 416x416) - set `layers = 23` instead of https://github.com/AlexeyAB/darknet/blob/6f718c257815a984253346bba8fb7aa756c55090/cfg/yolov4.cfg#L895\n  - set `stride=4` instead of https://github.com/AlexeyAB/darknet/blob/6f718c257815a984253346bba8fb7aa756c55090/cfg/yolov4.cfg#L892\n  - set `stride=4` instead of https://github.com/AlexeyAB/darknet/blob/6f718c257815a984253346bba8fb7aa756c55090/cfg/yolov4.cfg#L989\n  \n- for training for both small and large objects use modified models:\n  - Full-model: 5 yolo layers: https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3_5l.cfg\n  - Tiny-model: 3 yolo layers: https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny-3l.cfg\n  - YOLOv4: 3 yolo layers: https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-custom.cfg\n  \n- If you train the model to distinguish Left and Right objects as separate classes (left/right hand, left/right-turn on road signs, ...) then for disabling flip data augmentation - add `flip=0` here: https://github.com/AlexeyAB/darknet/blob/3d2d0a7c98dbc8923d9ff705b81ff4f7940ea6ff/cfg/yolov3.cfg#L17\n  \n- General rule - your training dataset should include such a set of relative sizes of objects that you want to detect:\n  - `train_network_width * train_obj_width / train_image_width ~= detection_network_width * detection_obj_width / detection_image_width`\n  - `train_network_height * train_obj_height / train_image_height ~= detection_network_height * detection_obj_height / detection_image_height`\n\n  I.e. for each object from Test dataset there must be at least 1 object in the Training dataset with the same class_id and about the same relative size:\n\n  `object width in percent from Training dataset` ~= `object width in percent from Test dataset`\n\n  That is, if only objects that occupied 80-90% of the image were present in the training set, then the trained network will not be able to detect objects that occupy 1-10% of the image.\n\n- to speedup training (with decreasing detection accuracy) set param `stopbackward=1` for layer-136 in cfg-file\n\n- each: `model of object, side, illumination, scale, each 30 grad` of the turn and inclination angles - these are *different objects* from an internal perspective of the neural network. So the more *different objects* you want to detect, the more complex network model should be used.\n\n- to make the detected bounded boxes more accurate, you can add 3 parameters `ignore_thresh = .9 iou_normalizer=0.5 iou_loss=giou` to each `[yolo]` layer and train, it will increase mAP@0.9, but decrease mAP@0.5.\n\n- Only if you are an **expert** in neural detection networks - recalculate anchors for your dataset for `width` and `height` from cfg-file:\n`darknet.exe detector calc_anchors data/obj.data -num_of_clusters 9 -width 416 -height 416`\nthen set the same 9 `anchors` in each of 3 `[yolo]`-layers in your cfg-file. But you should change indexes of anchors `masks=` for each [yolo]-layer, so for YOLOv4 the 1st-[yolo]-layer has anchors smaller than 30x30, 2nd smaller than 60x60, 3rd remaining, and vice versa for YOLOv3. Also you should change the `filters=(classes + 5)*<number of mask>` before each [yolo]-layer. If many of the calculated anchors do not fit under the appropriate layers - then just try using all the default anchors.\n\n2. After training - for detection:\n\n- Increase network-resolution by set in your `.cfg`-file (`height=608` and `width=608`) or (`height=832` and `width=832`) or (any value multiple of 32) - this increases the precision and makes it possible to detect small objects: [link](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L8-L9)\n\n- it is not necessary to train the network again, just use `.weights`-file already trained for 416x416 resolution\n\n- to get even greater accuracy you should train with higher resolution 608x608 or 832x832, note: if error `Out of memory` occurs then in `.cfg`-file you should increase `subdivisions=16`, 32 or 64: [link](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L4)\n\n## How to mark bounded boxes of objects and create annotation files\n\nHere you can find repository with GUI-software for marking bounded boxes of objects and generating annotation files for Yolo v2 - v4: https://github.com/AlexeyAB/Yolo_mark\n\nWith example of: `train.txt`, `obj.names`, `obj.data`, `yolo-obj.cfg`, `air`1-6`.txt`, `bird`1-4`.txt` for 2 classes of objects (air, bird) and `train_obj.cmd` with example how to train this image-set with Yolo v2 - v4\n\nDifferent tools for marking objects in images:\n\n1. in C++: https://github.com/AlexeyAB/Yolo_mark\n2. in Python: https://github.com/tzutalin/labelImg\n3. in Python: https://github.com/Cartucho/OpenLabeling\n4. in C++: https://www.ccoderun.ca/darkmark/\n5. in JavaScript: https://github.com/opencv/cvat\n6. in C++: https://github.com/jveitchmichaelis/deeplabel\n7. in C#: https://github.com/BMW-InnovationLab/BMW-Labeltool-Lite\n8. DL-Annotator for Windows ($30): [url](https://www.microsoft.com/en-us/p/dlannotator/9nsx79m7t8fn?activetab=pivot:overviewtab)\n9. v7labs - the greatest cloud labeling tool ($1.5 per hour): https://www.v7labs.com/\n\n## How to use Yolo as DLL and SO libraries\n\n- on Linux\n  - using `build.sh` or\n  - build `darknet` using `cmake` or\n  - set `LIBSO=1` in the `Makefile` and do `make`\n- on Windows\n  - using `build.ps1` or\n  - build `darknet` using `cmake` or\n  - compile `build\\darknet\\yolo_cpp_dll.sln` solution or `build\\darknet\\yolo_cpp_dll_no_gpu.sln` solution\n\nThere are 2 APIs:\n\n- C API: https://github.com/AlexeyAB/darknet/blob/master/include/darknet.h\n  - Python examples using the C API:\n    - https://github.com/AlexeyAB/darknet/blob/master/darknet.py\n    - https://github.com/AlexeyAB/darknet/blob/master/darknet_video.py\n\n- C++ API: https://github.com/AlexeyAB/darknet/blob/master/include/yolo_v2_class.hpp\n  - C++ example that uses C++ API: https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp\n\n----\n\n1. To compile Yolo as C++ DLL-file `yolo_cpp_dll.dll` - open the solution `build\\darknet\\yolo_cpp_dll.sln`, set **x64** and **Release**, and do the: Build -> Build yolo_cpp_dll\n    - You should have installed **CUDA 10.2**\n    - To use cuDNN do: (right click on project) -> properties -> C/C++ -> Preprocessor -> Preprocessor Definitions, and add at the beginning of line: `CUDNN;`\n\n2. To use Yolo as DLL-file in your C++ console application - open the solution `build\\darknet\\yolo_console_dll.sln`, set **x64** and **Release**, and do the: Build -> Build yolo_console_dll\n\n    - you can run your console application from Windows Explorer `build\\darknet\\x64\\yolo_console_dll.exe`\n    **use this command**: `yolo_console_dll.exe data/coco.names yolov4.cfg yolov4.weights test.mp4`\n\n    - after launching your console application and entering the image file name - you will see info for each object:\n    `<obj_id> <left_x> <top_y> <width> <height> <probability>`\n    - to use simple OpenCV-GUI you should uncomment line `//#define OPENCV` in `yolo_console_dll.cpp`-file: [link](https://github.com/AlexeyAB/darknet/blob/a6cbaeecde40f91ddc3ea09aa26a03ab5bbf8ba8/src/yolo_console_dll.cpp#L5)\n    - you can see source code of simple example for detection on the video file: [link](https://github.com/AlexeyAB/darknet/blob/ab1c5f9e57b4175f29a6ef39e7e68987d3e98704/src/yolo_console_dll.cpp#L75)\n\n`yolo_cpp_dll.dll`-API: [link](https://github.com/AlexeyAB/darknet/blob/master/src/yolo_v2_class.hpp#L42)\n\n```cpp\nstruct bbox_t {\n    unsigned int x, y, w, h;    // (x,y) - top-left corner, (w, h) - width & height of bounded box\n    float prob;                    // confidence - probability that the object was found correctly\n    unsigned int obj_id;        // class of object - from range [0, classes-1]\n    unsigned int track_id;        // tracking id for video (0 - untracked, 1 - inf - tracked object)\n    unsigned int frames_counter;// counter of frames on which the object was detected\n};\n\nclass Detector {\npublic:\n        Detector(std::string cfg_filename, std::string weight_filename, int gpu_id = 0);\n        ~Detector();\n\n        std::vector<bbox_t> detect(std::string image_filename, float thresh = 0.2, bool use_mean = false);\n        std::vector<bbox_t> detect(image_t img, float thresh = 0.2, bool use_mean = false);\n        static image_t load_image(std::string image_filename);\n        static void free_image(image_t m);\n\n#ifdef OPENCV\n        std::vector<bbox_t> detect(cv::Mat mat, float thresh = 0.2, bool use_mean = false);\n        std::shared_ptr<image_t> mat_to_image_resize(cv::Mat mat) const;\n#endif\n};\n```\n\n## Citation\n\n```\n@misc{bochkovskiy2020yolov4,\n      title={YOLOv4: Optimal Speed and Accuracy of Object Detection}, \n      author={Alexey Bochkovskiy and Chien-Yao Wang and Hong-Yuan Mark Liao},\n      year={2020},\n      eprint={2004.10934},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n```\n\n```\n@InProceedings{Wang_2021_CVPR,\n    author    = {Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},\n    title     = {{Scaled-YOLOv4}: Scaling Cross Stage Partial Network},\n    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n    month     = {June},\n    year      = {2021},\n    pages     = {13029-13038}\n}\n```\n",
	"deep-neural-networks latex": "# PlotNeuralNet\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.2526396.svg)](https://doi.org/10.5281/zenodo.2526396)\n\nLatex code for drawing neural networks for reports and presentation. Have a look into examples to see how they are made. Additionally, lets consolidate any improvements that you make and fix any bugs to help more people with this code.\n\n## Examples\n\nFollowing are some network representations:\n\n<p align=\"center\"><img  src=\"https://user-images.githubusercontent.com/17570785/50308846-c2231880-049c-11e9-8763-3daa1024de78.png\" width=\"85%\" height=\"85%\"></p>\n<h6 align=\"center\">FCN-8 (<a href=\"https://www.overleaf.com/read/kkqntfxnvbsk\">view on Overleaf</a>)</h6>\n\n\n<p align=\"center\"><img  src=\"https://user-images.githubusercontent.com/17570785/50308873-e2eb6e00-049c-11e9-9587-9da6bdec011b.png\" width=\"85%\" height=\"85%\"></p>\n<h6 align=\"center\">FCN-32 (<a href=\"https://www.overleaf.com/read/wsxpmkqvjnbs\">view on Overleaf</a>)</h6>\n\n\n<p align=\"center\"><img  src=\"https://user-images.githubusercontent.com/17570785/50308911-03b3c380-049d-11e9-92d9-ce15669017ad.png\" width=\"85%\" height=\"85%\"></p>\n<h6 align=\"center\">Holistically-Nested Edge Detection (<a href=\"https://www.overleaf.com/read/jxhnkcnwhfxp\">view on Overleaf</a>)</h6>\n\n## Getting Started\n1. Install the following packages on Ubuntu.\n    * Ubuntu 16.04\n        ```\n        sudo apt-get install texlive-latex-extra\n        ```\n\n    * Ubuntu 18.04.2\nBase on this [website](https://gist.github.com/rain1024/98dd5e2c6c8c28f9ea9d), please install the following packages.\n        ```\n        sudo apt-get install texlive-latex-base\n        sudo apt-get install texlive-fonts-recommended\n        sudo apt-get install texlive-fonts-extra\n        sudo apt-get install texlive-latex-extra\n        ```\n\n    * Windows\n    1. Download and install [MikTeX](https://miktex.org/download).\n    2. Download and install bash runner on Windows, recommends [Git bash](https://git-scm.com/download/win) or Cygwin(https://www.cygwin.com/)\n\n2. Execute the example as followed.\n    ```\n    cd pyexamples/\n    bash ../tikzmake.sh test_simple\n    ```\n\n## TODO\n\n- [X] Python interface\n- [ ] Add easy legend functionality\n- [ ] Add more layer shapes like TruncatedPyramid, 2DSheet etc\n- [ ] Add examples for RNN and likes.\n\n## Latex usage\n\nSee [`examples`](examples) directory for usage.\n\n## Python usage\n\nFirst, create a new directory and a new Python file:\n\n    $ mkdir my_project\n    $ cd my_project\n    vim my_arch.py\n\nAdd the following code to your new file:\n\n```python\nimport sys\nsys.path.append('../')\nfrom pycore.tikzeng import *\n\n# defined your arch\narch = [\n    to_head( '..' ),\n    to_cor(),\n    to_begin(),\n    to_Conv(\"conv1\", 512, 64, offset=\"(0,0,0)\", to=\"(0,0,0)\", height=64, depth=64, width=2 ),\n    to_Pool(\"pool1\", offset=\"(0,0,0)\", to=\"(conv1-east)\"),\n    to_Conv(\"conv2\", 128, 64, offset=\"(1,0,0)\", to=\"(pool1-east)\", height=32, depth=32, width=2 ),\n    to_connection( \"pool1\", \"conv2\"),\n    to_Pool(\"pool2\", offset=\"(0,0,0)\", to=\"(conv2-east)\", height=28, depth=28, width=1),\n    to_SoftMax(\"soft1\", 10 ,\"(3,0,0)\", \"(pool1-east)\", caption=\"SOFT\"  ),\n    to_connection(\"pool2\", \"soft1\"),\n    to_end()\n    ]\n\ndef main():\n    namefile = str(sys.argv[0]).split('.')[0]\n    to_generate(arch, namefile + '.tex' )\n\nif __name__ == '__main__':\n    main()\n```\n\nNow, run the program as follows:\n\n    bash ../tikzmake.sh my_arch\n\n\n\n",
	"ai computer-vision computervision deep-learning deep-neural-networks deeplearning machine-learning opencv opencv-cpp opencv-library opencv-python opencv-tutorial opencv3": "# LearnOpenCV\nThis repo contains code for Computer Vision, Deep learning, and AI articles shared on our blog [LearnOpenCV.com](https://www.LearnOpenCV.com).\n\nWant to become an expert in AI? [AI Courses by OpenCV](https://opencv.org/courses/) is a great place to start.\n\n<a href=\"https://opencv.org/courses/\">\n<p align=\"center\">\n<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/04/AI-Courses-By-OpenCV-Github.png\">\n</p>\n</a>\n\n## List of Blog Posts\n| Blog Post | |\n| ------------- |:-------------|\n|[FCOS - Anchor Free Object Detection Explained](learnopencv.com/fcos-anchor-free-object-detection-explained/)|[Code](https://github.com/spmallick/learnopencv/tree/master/FCOS-Inference-using-PyTorch)|\n| [YOLOv6 Custom Dataset Training \u2013 Underwater Trash Detection](https://learnopencv.com/yolov6-custom-dataset-training/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv6-Custom-Dataset-Training-Underwater-Trash-Detection) |\n|[What is EXIF Data in Images?](https://www.learnopencv.com/what-is-exif-data-in-images/)|[Code](https://github.com/spmallick/learnopencv/tree/master/What-is-EXIF-Data-in-Images)|\n|[t-SNE: T-Distributed Stochastic Neighbor Embedding Explained](https://learnopencv.com/t-sne-t-distributed-stochastic-neighbor-embedding-explained/)|[Code](https://github.com/spmallick/learnopencv/tree/master/t-SNE-with-Tensorboard)|\n|[CenterNet: Objects as Points \u2013 Anchor-free Object Detection Explained](https://learnopencv.com/centernet-anchor-free-object-detection-explained/)|[Code](https://github.com/spmallick/learnopencv/tree/master/centernet-with-tf-hub)|\n|[YOLOv7 Pose vs MediaPipe in Human Pose Estimation](https://learnopencv.com/yolov7-pose-vs-mediapipe-in-human-pose-estimation/)|[Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv7-Pose-vs-MediaPipe-in-Human-Pose-Estimation)|\n|[YOLOv6 Object Detection \u2013 Paper Explanation and Inference](https://learnopencv.com/yolov6-object-detection/)|[Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv6-Object-Detection-Paper-Explanation-and-Inference)|\n|[YOLOX Object Detector Paper Explanation and Custom Training](https://learnopencv.com/yolox-object-detector-paper-explanation-and-custom-training/)|[Code](https://github.com/spmallick/learnopencv/tree/master/YOLOX-Object-Detection-Paper-Explanation-and-Custom-Training)|\n|[Driver Drowsiness Detection Using Mediapipe In Python](https://learnopencv.com/driver-drowsiness-detection-using-mediapipe-in-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Driver-Drowsiness-detection-using-Mediapipe-in-Python)|\n|[GTC 2022 Big Bang AI announcements: Everything you need to know](https://learnopencv.com/gtc-2022-big-bang-ai-announcements-everything-you-need-to-know/)||\n|[NVIDIA GTC 2022 : The most important AI event this Fall](https://learnopencv.com/nvidia-gtc-2022-the-most-important-ai-event-this-fall/)||\n|[Object Tracking and Reidentification with FairMOT](https://learnopencv.com/object-tracking-and-reidentification-with-fairmot/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Object-Tracking-and-Reidentification-with-FairMOT) |\n|[What is Face Detection? \u2013 The Ultimate Guide for 2022](https://learnopencv.com/what-is-face-detection-the-ultimate-guide/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Face-Detection-Ultimate-Guide) |\n|[Document Scanner: Custom Semantic Segmentation using PyTorch-DeepLabV3](https://learnopencv.com/custom-document-segmentation-using-deep-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Document-Scanner-Custom-Semantic-Segmentation-using-PyTorch-DeepLabV3)|\n|[Fine Tuning YOLOv7 on Custom Dataset](https://learnopencv.com/fine-tuning-yolov7-on-custom-dataset/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-YOLOv7)|\n|[Center Stage for Zoom Calls using MediaPipe](https://learnopencv.com/Center-Stage-for-zoom-call-using-mediapipe/)|[Code](https://github.com/spmallick/learnopencv/tree/master/CenterStage)|\n|[Mean Average Precision (mAP) in Object Detection](https://learnopencv.com/mean-average-precision-map-object-detection-model-evaluation-metric/)||\n|[YOLOv7 Object Detection Paper Explanation and Inference](https://learnopencv.com/yolov7-object-detection-paper-explanation-and-inference/)|[Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv7-Object-Detection-Paper-Explanation-and-Inference)|\n|[Pothole Detection using YOLOv4 and Darknet](https://learnopencv.com/pothole-detection-using-yolov4-and-darknet/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Pothole-Detection-using-YOLOv4-and-Darknet)|\n|[Automatic Document Scanner using OpenCV](https://learnopencv.com/automatic-document-scanner-using-opencv/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Automatic-Document-Scanner)|\n|[Demystifying GPU architectures for deep learning: Part 2](https://learnopencv.com/demystifying-gpu-architectures-for-deep-learning-part-2/)|[Code](https://github.com/spmallick/learnopencv/tree/master/gpu_arch_and_CUDA)|\n|[Demystifying GPU Architectures For Deep Learning](https://learnopencv.com/demystifying-gpu-architectures-for-deep-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/gpu_arch_and_CUDA)|\n|[Intersection-over-Union(IoU)-in-Object-Detection-and-Segmentation](https://learnopencv.com/intersection-over-unioniou-in-object-detection-and-segmentation/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Intersection-over-Union-IoU-in-Object-Detection-and-Segmentation)|\n|[Understanding Multiple Object Tracking using DeepSORT](https://learnopencv.com/understanding-multiple-object-tracking-using-deepsort/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Understanding-Multiple-Object-Tracking-using-DeepSORT)|\n|[Optical Character Recognition using PaddleOCR](https://learnopencv.com/optical-character-recognition-using-paddleocr/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Optical-Character-Recognition-using-PaddleOCR)|\n|[Gesture Control in Zoom Call using Mediapipe](https://learnopencv.com/gesture-control-in-zoom-call-using-mediapipe/)|[Code](https://github.com/spmallick/learnopencv/tree/master/zoom-gestures)|\n|[A Deep Dive into Tensorflow Model Optimization](https://learnopencv.com/deep-dive-into-tensorflow-model-optimization-toolkit/)|[Code](https://github.com/spmallick/learnopencv/tree/master/A-Deep-Dive-into-Tensorflow-Model-Optimization)|\n|[DepthAI Pipeline Overview: Creating a Complex Pipeline](https://learnopencv.com/depthai-pipeline-overview-creating-a-complex-pipeline/)|[Code](https://github.com/spmallick/learnopencv/tree/master/OAK-DepthAi-Pipeline-Overview)|\n|[TensorFlow Lite Model Maker: Create Models for On-Device Machine Learning](https://learnopencv.com/tensorflow-lite-model-maker-create-models-for-on-device-machine-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Tensorflow-Lite-Model-Maker-Create-Models-for-On-Device-ML)|\n|[TensorFlow Lite: Model Optimization for\tOn Device Machine Learning](https://learnopencv.com/tensorflow-lite-model-optimization-for-on-device-machine-learning)|[Code](https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Lite-Model-Optimization-for-On-Device-MachineLearning)|\n|[Object detection with depth measurement using pre-trained models with OAK-D](https://learnopencv.com/object-detection-with-depth-measurement-with-oak-d/)|[Code](https://github.com/spmallick/learnopencv/tree/master/OAK-Object-Detection-with-Depth)|\n|[Custom Object Detection Training using YOLOv5](https://learnopencv.com/custom-object-detection-training-using-yolov5/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Custom-Object-Detection-Training-using-YOLOv5)|\n|[Object Detection using Yolov5 and OpenCV DNN (C++/Python)](https://learnopencv.com/object-detection-using-yolov5-and-opencv-dnn-in-c-and-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python)|\n|[Create Snapchat/Instagram filters using Mediapipe](https://learnopencv.com/create-snapchat-instagram-filters-using-mediapipe/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Create-AR-filters-using-Mediapipe)|\n|[AUTOSAR C++ compliant deep learning inference with TensorRT](https://learnopencv.com/autosar-c-compliant-deep-learning-inference-with-tensorrt/)|[Code](https://github.com/spmallick/learnopencv/tree/master/industrial_cv_TensorRT_cpp)|\n|[NVIDIA GTC 2022 Day 4 Highlights: Meet the new Jetson Orin](https://learnopencv.com/nvidia-gtc-2022-day-4-highlights-meet-the-new-jetson-orin/)||\n|[NVIDIA GTC 2022 Day 3 Highlights: Deep Dive into Hopper architecture](https://learnopencv.com/nvidia-gtc-2022-day-3-highlights-deep-dive-into-hopper-architecture/)||\n|[NVIDIA GTC 2022 Day 2 Highlights: Jensen\u2019s Keynote](https://learnopencv.com/nvidia-gtc-2022-day-2-highlights/)||\n|[NVIDIA GTC 2022 Day 1 Highlights: Brilliant Start](https://learnopencv.com/gtc-day-1-highlights/)||\n|[Automatic License Plate Recognition using Python](https://learnopencv.com/automatic-license-plate-recognition-using-deep-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/ALPR)|\n|[Building a Poor Body Posture Detection and Alert System using MediaPipe](https://learnopencv.com/building-a-body-posture-analysis-system-using-mediapipe/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Posture-analysis-system-using-MediaPipe-Pose)|\n|[Introduction to MediaPipe](https://learnopencv.com/introduction-to-mediapipe/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Introduction-to-MediaPipe)|\n|[Disparity Estimation using Deep Learning](https://learnopencv.com/disparity-estimation-using-deep-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Disparity-Estimation-Using-Deep-Learning)|\n|[How to build Chrome Dino game bot using OpenCV Feature Matching](https://learnopencv.com/how-to-build-chrome-dino-game-bot-using-opencv-feature-matching/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Chrome-Dino-Bot-using-OpenCV-feature-matching)|\n|[Top 10 Sources to Find Computer Vision and AI Models](https://learnopencv.com/top-10-sources-to-find-computer-vision-and-ai-models/)||\n|[Multi-Attribute and Graph-based Object Detection](https://learnopencv.com/multi-attribute-and-graph-based-object-detection/)||\n|[Plastic Waste Detection with Deep Learning](https://learnopencv.com/plastic-waste-detection-with-deep-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Plastic-Waste-Detection-with-Deep-Learning)|\n|[Ensemble Deep Learning-based Defect Classification and Detection in SEM Images](https://learnopencv.com/ensemble-deep-learning-based-defect-classification-and-detection-in-sem-images/)||\n|[Building Industrial embedded deep learning inference pipelines with TensorRT](https://learnopencv.com/building-industrial-embedded-deep-learning-inference-pipelines-with-tensorrt/)|[Code](https://github.com/spmallick/learnopencv/tree/master/industrial_cv_TensorRT_python)|\n|[Transfer Learning for Medical Images](https://learnopencv.com/transfer-learning-for-medical-images/)||\n|[Stereo Vision and Depth Estimation using OpenCV AI Kit](https://learnopencv.com/stereo-vision-and-depth-estimation-using-opencv-ai-kit/)|[Code](https://github.com/spmallick/learnopencv/tree/master/oak-getting-started)|\n|[Introduction to OpenCV AI Kit and DepthAI](https://learnopencv.com/introduction-to-opencv-ai-kit-and-depthai/)|[Code](https://github.com/spmallick/learnopencv/tree/master/oak-getting-started)|\n|[WeChat QR Code Scanner in OpenCV](https://learnopencv.com/wechat-qr-code-scanner-in-opencv)|[Code](https://github.com/spmallick/learnopencv/tree/master/WeChat-QRCode-Scanner-OpenCV)|\n|[AI behind the Diwali 2021 \u2018Not just a Cadbury ad\u2019](https://learnopencv.com/ai-behind-the-diwali-2021-not-just-a-cadbury-ad/)| |\n|[Model Selection and Benchmarking with Modelplace.AI](https://learnopencv.com/model-selection-and-benchmarking-with-modelplace-ai/)|[Model Zoo](https://modelplace.ai/)|\n|[Real-time style transfer in a zoom meeting](https://learnopencv.com/real-time-style-transfer-in-a-zoom-meeting/)|[Code](https://github.com/spmallick/learnopencv/tree/master/style-transfer-zoom)|\n| [Introduction to OpenVino Deep Learning Workbench](https://learnopencv.com/introduction-to-openvino-deep-learning-workbench/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Introduction-to-OpenVino-Deep-Learning-Workbench) |\n| [Running OpenVino Models on Intel Integrated GPU](https://learnopencv.com/running-openvino-models-on-intel-integrated-gpu/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Running-OpenVino-Models-on-Intel-Integrated-GPU) |\n|[Post Training Quantization with OpenVino Toolkit](https://learnopencv.com/post-training-quantization-with-openvino-toolkit/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Post-Training-Quantization-with-OpenVino-Toolkit)|\n|[Introduction to Intel OpenVINO Toolkit](https://learnopencv.com/introduction-to-intel-openvino-toolkit/)||\n|[Human Action Recognition using Detectron2 and LSTM](https://learnopencv.com/human-action-recognition-using-detectron2-and-lstm/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Human-Action-Recognition-Using-Detectron2-And-Lstm)|\n|[Pix2Pix:Image-to-Image Translation in PyTorch & TensorFlow](https://learnopencv.com/paired-image-to-image-translation-pix2pix/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Image-to-Image-Translation-with-GAN)|\n|[Conditional GAN (cGAN) in PyTorch and TensorFlow](https://learnopencv.com/conditional-gan-cgan-in-pytorch-and-tensorflow/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Conditional-GAN-PyTorch-TensorFlow)|\n|[Deep Convolutional GAN in PyTorch and TensorFlow](https://learnopencv.com/deep-convolutional-gan-in-pytorch-and-tensorflow/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Deep-Convolutional-GAN)|\n|[Introduction to Generative Adversarial Networks (GANs)](https://learnopencv.com/introduction-to-generative-adversarial-networks/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Intro-to-Generative-Adversarial-Network)|\n|[Human Pose Estimation using Keypoint RCNN in PyTorch](https://learnopencv.com/human-pose-estimation-using-keypoint-rcnn-in-pytorch/)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Keypoint-RCNN)|\n|[Non Maximum Suppression: Theory and Implementation in PyTorch](https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch)|[Code](https://github.com/spmallick/learnopencv/tree/master/Non-Maximum-Suppression)|\n|[MRNet \u2013 The Multi-Task Approach](https://learnopencv.com/mrnet-multitask-approach/)| [Code](https://github.com/spmallick/learnopencv/tree/master/MRnet-MultiTask-Approach) |\n|[Generative and Discriminative Models](https://learnopencv.com/generative-and-discriminative-models/)| |\n|[Playing Chrome's T-Rex Game with Facial Gestures](https://learnopencv.com/playing-chromes-t-rex-game-with-facial-gestures/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Playing-Chrome-TRex-Game-with-Facial-Gestures) |\n|[Variational Autoencoder in TensorFlow](https://learnopencv.com/variational-autoencoder-in-tensorflow/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Variational-Autoencoder-TensorFlow) |\n|[Autoencoder in TensorFlow 2: Beginner\u2019s Guide](https://learnopencv.com/autoencoder-in-tensorflow-2-beginners-guide/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Autoencoder-in-TensorFlow) |\n|[Deep Learning with OpenCV DNN Module: A Definitive Guide](https://learnopencv.com/deep-learning-with-opencvs-dnn-module-a-definitive-guide/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Deep-Learning-with-OpenCV-DNN-Module) |\n|[Depth perception using stereo camera (Python/C++)](https://learnopencv.com/depth-perception-using-stereo-camera-python-c/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Depth-Perception-Using-Stereo-Camera) |\n|[Contour Detection using OpenCV (Python/C++)](https://learnopencv.com/contour-detection-using-opencv-python-c/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Contour-Detection-using-OpenCV) |\n|[Super Resolution in OpenCV](https://learnopencv.com/super-resolution-in-opencv/)| [Code](https://github.com/spmallick/learnopencv/blob/master/Super-Resolution-in-OpenCV) |\n|[Improving Illumination in Night Time Images](https://learnopencv.com/improving-illumination-in-night-time-images/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Improving-Illumination-in-Night-Time-Images) |\n|[Video Classification and Human Activity Recognition](https://learnopencv.com/introduction-to-video-classification-and-human-activity-recognition/) | [Code](https://github.com/spmallick/learnopencv/tree/master/video-classification-and-human-activity-recognition) |\n|[How to use OpenCV DNN Module with Nvidia GPU on Windows](https://learnopencv.com/how-to-use-opencv-dnn-module-with-nvidia-gpu-on-windows) | [Code](https://github.com/spmallick/learnopencv/tree/master/OpenCV-dnn-gpu-support-Windows) |\n|[How to use OpenCV DNN Module with NVIDIA GPUs](https://learnopencv.com/opencv-dnn-with-gpu-support/) | [Code](https://github.com/spmallick/learnopencv/tree/master/OpenCV-dnn-gpu-support-Linux) |\n|[Code OpenCV in Visual Studio](https://learnopencv.com/code-opencv-in-visual-studio/) | |\n|[Install OpenCV on Windows \u2013 C++ / Python](https://learnopencv.com/install-opencv-on-windows/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Install-OpenCV-Windows-exe) |\n|[Face Recognition with ArcFace](https://www.learnopencv.com/face-recognition-with-arcface/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Face-Recognition-with-ArcFace)|\n|[Background Subtraction with OpenCV and BGS Libraries](https://www.learnopencv.com/background-subtraction-with-opencv-and-bgs-libraries/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Background-Subtraction) |\n|[RAFT: Optical Flow estimation using Deep Learning](https://learnopencv.com/optical-flow-using-deep-learning-raft/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Optical-Flow-Estimation-using-Deep-Learning-RAFT)|\n|[Making A Low-Cost Stereo Camera Using OpenCV](https://www.learnopencv.com/making-a-low-cost-stereo-camera-using-opencv/)|[Code](https://github.com/spmallick/learnopencv/tree/master/stereo-camera)|\n|[Optical Flow in OpenCV (C++/Python)](https://www.learnopencv.com/optical-flow-in-opencv)|[Code](https://github.com/spmallick/learnopencv/tree/master/Optical-Flow-in-OpenCV)|\n|[Introduction to Epipolar Geometry and Stereo Vision](https://www.learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/)|[Code](https://github.com/spmallick/learnopencv/tree/master/EpipolarGeometryAndStereoVision)|\n|[Classification With Localization: Convert any keras Classifier to a Detector](https://www.learnopencv.com/classification-with-localization/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Classification-with-localization-convert-any-keras-classifier-into-a-detector/README.md) |\n|[Photoshop Filters in OpenCV](https://www.learnopencv.com/photoshop-filters-in-opencv/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Photoshop-Filters-in-OpenCV)|\n|[Tetris Game using OpenCV Python](https://www.learnopencv.com/tetris-with-opencv-python)|[Code](https://github.com/spmallick/learnopencv/tree/master/Tetris)|\n|[Image Classification with OpenCV for Android](https://www.learnopencv.com/image-classification-with-opencv-for-android/) | [Code](https://github.com/spmallick/learnopencv/tree/master/DNN-OpenCV-Classification-Android) |\n|[Image Classification with OpenCV Java](https://www.learnopencv.com/image-classification-with-opencv-java)|[Code](https://github.com/spmallick/learnopencv/tree/master/DNN-OpenCV-Classification-with-Java) |\n|[PyTorch to Tensorflow Model Conversion](https://www.learnopencv.com/pytorch-to-tensorflow-model-conversion/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-to-TensorFlow-Model-Conversion) |\n|[Snake Game with OpenCV Python](https://www.learnopencv.com/snake-game-with-opencv-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/SnakeGame) |\n|[Stanford MRNet Challenge: Classifying Knee MRIs](https://www.learnopencv.com/stanford-mrnet-challenge-classifying-knee-mris/)|[Code](https://github.com/spmallick/learnopencv/tree/master/MRNet-Single-Model) |\n|[Experiment Logging with TensorBoard and wandb](https://www.learnopencv.com/experiment-logging-with-tensorboard-and-wandb)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Vision-Experiment-Logging) |\n|[Understanding Lens Distortion](https://www.learnopencv.com/understanding-lens-distortion/)|[Code](https://github.com/spmallick/learnopencv/tree/master/UnderstandingLensDistortion) |\n|[Image Matting with state-of-the-art Method \u201cF, B, Alpha Matting\u201d](https://www.learnopencv.com/image-matting-with-state-of-the-art-method-f-b-alpha-matting/)|[Code](https://github.com/spmallick/learnopencv/tree/master/FBAMatting) |\n|[Bag Of Tricks For Image Classification - Let's check if it is working or not](https://www.learnopencv.com/bag-of-tricks-for-image-classification-lets-check-if-it-is-working-or-not/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Bag-Of-Tricks-For-Image-Classification) |\n|[Getting Started with OpenCV CUDA Module](https://www.learnopencv.com/getting-started-opencv-cuda-module/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Getting-Started-OpenCV-CUDA-Module) |\n|[Training a Custom Object Detector with DLIB & Making Gesture Controlled Applications](https://www.learnopencv.com/training-a-custom-object-detector-with-dlib-making-gesture-controlled-applications/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Training_a_custom_hand_detector_with_dlib) |\n|[How To Run Inference Using TensorRT C++ API](https://www.learnopencv.com/how-to-run-inference-using-tensorrt-c-api/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-ONNX-TensorRT-CPP) |\n|[Using Facial Landmarks for Overlaying Faces with Medical Masks](https://www.learnopencv.com/using-facial-landmarks-for-overlaying-faces-with-masks/)|[Code](https://github.com/spmallick/learnopencv/tree/master/FaceMaskOverlay) |\n|[Tensorboard with PyTorch Lightning](https://www.learnopencv.com/tensorboard-with-pytorch-lightning)|[Code](https://github.com/spmallick/learnopencv/tree/master/TensorBoard-With-Pytorch-Lightning) |\n|[Otsu's Thresholding with OpenCV](https://www.learnopencv.com/otsu-thresholding-with-opencv/)|[Code](https://github.com/spmallick/learnopencv/tree/master/otsu-method) |\n|[PyTorch-to-CoreML-model-conversion](https://www.learnopencv.com/pytorch-to-coreml-model-conversion/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-to-CoreML-model-conversion) |\n|[Playing Rock, Paper, Scissors with AI](https://www.learnopencv.com/playing-rock-paper-scissors-with-ai/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Playing-rock-paper-scissors-with-AI) |\n|[CNN Receptive Field Computation Using Backprop with TensorFlow](https://www.learnopencv.com/cnn-receptive-field-computation-using-backprop-with-tensorflow/)|[Code](https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Receptive-Field-With-Backprop)|\n|[CNN Fully Convolutional Image Classification with TensorFlow](https://www.learnopencv.com/cnn-fully-convolutional-image-classification-with-tensorflow) | [Code](https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Fully-Convolutional-Image-Classification) |\n|[How to convert a model from PyTorch to TensorRT and speed up inference](https://www.learnopencv.com/how-to-convert-a-model-from-pytorch-to-tensorrt-and-speed-up-inference/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-ONNX-TensorRT) |\n|[Efficient image loading](https://www.learnopencv.com/efficient-image-loading/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Efficient-image-loading) |\n|[Graph Convolutional Networks: Model Relations In Data](https://www.learnopencv.com/graph-convolutional-networks-model-relations-in-data/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Graph-Convolutional-Networks-Model-Relations-In-Data)|\n|[Getting Started with Federated Learning with PyTorch and PySyft](https://www.learnopencv.com/federated-learning-using-pytorch-and-pysyft/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Federated-Learning-Intro)|\n|[Creating a Virtual Pen & Eraser](http://www.learnopencv.com/creating-a-virtual-pen-and-eraser-with-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Creating-a-Virtual-Pen-and-Eraser) |\n|[Getting Started with PyTorch Lightning](https://www.learnopencv.com/getting-started-with-pytorch-lightning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Pytorch-Lightning)|\n|[Multi-Label Image Classification with PyTorch: Image Tagging](https://www.learnopencv.com/multi-label-image-classification-with-pytorch-image-tagging/)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Multi-Label-Image-Classification-Image-Tagging)|\n|[Funny Mirrors Using OpenCV](https://www.learnopencv.com/Funny-Mirrors-Using-OpenCV/)|[code](https://github.com/spmallick/learnopencv/tree/master/FunnyMirrors)|\n|[t-SNE for ResNet feature visualization](https://www.learnopencv.com/t-sne-for-feature-visualization/)|[Code](https://github.com/spmallick/learnopencv/tree/master/TSNE)|\n|[Multi-Label Image Classification with Pytorch](https://www.learnopencv.com/multi-label-image-classification-with-pytorch/)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Multi-Label-Image-Classification)|\n|[CNN Receptive Field Computation Using Backprop](https://www.learnopencv.com/cnn-receptive-field-computation-using-backprop/)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Receptive-Field-With-Backprop)|\n|[CNN Receptive Field Computation Using Backprop with TensorFlow](https://www.learnopencv.com/cnn-receptive-field-computation-using-backprop-with-tensorflow/)|[Code](https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Receptive-Field-With-Backprop)|\n|[Augmented Reality using AruCo Markers in OpenCV(C++ and Python)](https://www.learnopencv.com/augmented-reality-using-aruco-markers-in-opencv-(c++-python)/) |[Code](https://github.com/spmallick/learnopencv/tree/master/AugmentedRealityWithArucoMarkers)|\n|[Fully Convolutional Image Classification on Arbitrary Sized Image](https://www.learnopencv.com/fully-convolutional-image-classification-on-arbitrary-sized-image/)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Fully-Convolutional-Image-Classification)|\n|[Camera Calibration using OpenCV](https://www.learnopencv.com/camera-calibration-using-opencv/) |[Code](https://github.com/spmallick/learnopencv/tree/master/CameraCalibration)|\n|[Geometry of Image Formation](https://www.learnopencv.com/geometry-of-image-formation/) ||\n|[Ensuring Training Reproducibility in Pytorch](https://www.learnopencv.com/ensuring-training-reproducibility-in-pytorch) ||\n|[Gaze Tracking](https://www.learnopencv.com/gaze-tracking/) ||\n|[Simple Background Estimation in Videos Using OpenCV](https://www.learnopencv.com/simple-background-estimation-in-videos-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/VideoBackgroundEstimation)|\n|[Applications of Foreground-Background separation with Semantic Segmentation](https://www.learnopencv.com/applications-of-foreground-background-separation-with-semantic-segmentation/) | [Code](https://github.com/spmallick/learnopencv/tree/master/app-seperation-semseg) |\n|[EfficientNet: Theory + Code](https://www.learnopencv.com/efficientnet-theory-code) | [Code](https://github.com/spmallick/learnopencv/tree/master/EfficientNet) |\n|[PyTorch for Beginners: Mask R-CNN Instance Segmentation with PyTorch](https://www.learnopencv.com/mask-r-cnn-instance-segmentation-with-pytorch/) | [Code](./PyTorch-Mask-RCNN) |\n|[PyTorch for Beginners: Faster R-CNN Object Detection with PyTorch](https://www.learnopencv.com/faster-r-cnn-object-detection-with-pytorch) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-faster-RCNN) |\n|[PyTorch for Beginners: Semantic Segmentation using torchvision](https://www.learnopencv.com/pytorch-for-beginners-semantic-segmentation-using-torchvision/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Segmentation-torchvision) |\n|[PyTorch for Beginners: Comparison of pre-trained models for Image Classification](https://www.learnopencv.com/image-classification-using-pre-trained-models-using-pytorch/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Image-classification-pre-trained-models/Image_Classification_using_pre_trained_models.ipynb) |\n|[PyTorch for Beginners: Basics](https://www.learnopencv.com/pytorch-for-beginners-basics/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-for-Beginners/PyTorch_for_Beginners.ipynb) |\n|[PyTorch Model Inference using ONNX and Caffe2](https://www.learnopencv.com/pytorch-model-inference-using-onnx-and-caffe2/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Inference-for-PyTorch-Models/ONNX-Caffe2) |\n|[Image Classification Using Transfer Learning in PyTorch](https://www.learnopencv.com/image-classification-using-transfer-learning-in-pytorch/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Image-Classification-in-PyTorch) |\n|[Hangman: Creating games in OpenCV](https://www.learnopencv.com/hangman-creating-games-in-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Hangman) |\n|[Image Inpainting with OpenCV (C++/Python)](https://www.learnopencv.com/image-inpainting-with-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Image-Inpainting) |\n|[Hough Transform with OpenCV (C++/Python)](https://www.learnopencv.com/hough-transform-with-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Hough-Transform) |\n|[Xeus-Cling: Run C++ code in Jupyter Notebook](https://www.learnopencv.com/xeus-cling-run-c-code-in-jupyter-notebook/) | [Code](https://github.com/spmallick/learnopencv/tree/master/XeusCling) |\n|[Gender & Age Classification using OpenCV Deep Learning ( C++/Python )](https://www.learnopencv.com/age-gender-classification-using-opencv-deep-learning-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/AgeGender) |\n|[Invisibility Cloak using Color Detection and Segmentation with OpenCV](https://www.learnopencv.com/invisibility-cloak-using-color-detection-and-segmentation-with-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/InvisibilityCloak) |\n|[Fast Image Downloader for Open Images V4 (Python)](https://www.learnopencv.com/fast-image-downloader-for-open-images-v4/) | [Code](https://github.com/spmallick/learnopencv/tree/master/downloadOpenImages) |\n|[Deep Learning based Text Detection Using OpenCV (C++/Python)](https://www.learnopencv.com/deep-learning-based-text-detection-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/TextDetectionEAST) |\n|[Video Stabilization Using Point Feature Matching in OpenCV](https://www.learnopencv.com/video-stabilization-using-point-feature-matching-in-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/VideoStabilization) |\n|[Training YOLOv3 : Deep Learning based Custom Object Detector](https://www.learnopencv.com/training-yolov3-deep-learning-based-custom-object-detector/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv3-Training-Snowman-Detector\t) |\n|[Using OpenVINO with OpenCV](https://www.learnopencv.com/using-openvino-with-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/OpenVINO-OpenCV) |\n|[Duplicate Search on Quora Dataset](https://www.learnopencv.com/duplicate-search-on-quora-dataset/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Quora-Dataset-Duplicate-Search) |\n|[Shape Matching using Hu Moments (C++/Python)](https://www.learnopencv.com/shape-matching-using-hu-moments-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/HuMoments) |\n|[Install OpenCV 4 on CentOS (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-centos-7/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-centos.sh) |\n|[Install OpenCV 3.4.4 on CentOS (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-centos-7/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-centos.sh) |\n|[Install OpenCV 3.4.4 on Red Hat (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-red-hat/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-red-hat.sh) |\n|[Install OpenCV 4 on Red Hat (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-red-hat/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-on-red-hat.sh) |\n|[Install OpenCV 4 on macOS (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-macos/) | [Code](https://github.com/spmallick/learnopencv/tree/master/InstallScripts/installOpenCV-4-macos.sh) |\n|[Install OpenCV 3.4.4 on Raspberry Pi](https://www.learnopencv.com/install-opencv-3-4-4-on-raspberry-pi/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-raspberry-pi.sh) |\n|[Install OpenCV 3.4.4 on macOS (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-macos/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-macos.sh) |\n|[OpenCV QR Code Scanner (C++ and Python)](https://www.learnopencv.com/opencv-qr-code-scanner-c-and-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/QRCode-OpenCV) |\n|[Install OpenCV 3.4.4 on Windows (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-windows/) | [Code](https://github.com/spmallick/learnopencv/tree/master/InstallScripts/Windows-3) |\n|[Install OpenCV 3.4.4 on Ubuntu 16.04 (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-ubuntu-16-04/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-Ubuntu-16-04.sh) |\n|[Install OpenCV 3.4.4 on Ubuntu 18.04 (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-ubuntu-18-04/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-Ubuntu-18-04.sh) |\n|[Universal Sentence Encoder](https://www.learnopencv.com/universal-sentence-encoder) | [Code](https://github.com/spmallick/learnopencv/blob/master/Universal-Sentence-Encoder) |\n|[Install OpenCV 4 on Raspberry Pi](https://www.learnopencv.com/install-opencv-4-on-raspberry-pi/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-raspberry-pi.sh) |\n|[Install OpenCV 4 on Windows (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-windows/) | [Code](https://github.com/spmallick/learnopencv/tree/master/InstallScripts/Windows-4) |\n|[Hand Keypoint Detection using Deep Learning and OpenCV](https://www.learnopencv.com/hand-keypoint-detection-using-deep-learning-and-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/HandPose)|\n|[Deep learning based Object Detection and Instance Segmentation using Mask R-CNN in OpenCV (Python / C++)](https://www.learnopencv.com/deep-learning-based-object-detection-and-instance-segmentation-using-mask-r-cnn-in-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Mask-RCNN) |\n|[Install OpenCV 4 on Ubuntu 18.04 (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-ubuntu-18-04/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-on-Ubuntu-18-04.sh) |\n|[Install OpenCV 4 on Ubuntu 16.04 (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-ubuntu-16-04/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-on-Ubuntu-16-04.sh) |\n|[Multi-Person Pose Estimation in OpenCV using OpenPose](https://www.learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/) | [Code](https://github.com/spmallick/learnopencv/tree/master/OpenPose-Multi-Person) |\n|[Heatmap for Logo Detection using OpenCV (Python)](https://www.learnopencv.com/heatmap-for-logo-detection-using-opencv-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/heatmap)|\n|[Deep Learning based Object Detection using YOLOv3 with OpenCV ( Python / C++ )](https://www.learnopencv.com/deep-learning-based-object-detection-using-yolov3-with-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ObjectDetection-YOLO)|\n|[Convex Hull using OpenCV in Python and C++](https://www.learnopencv.com/convex-hull-using-opencv-in-python-and-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ConvexHull)|\n|[MultiTracker : Multiple Object Tracking using OpenCV (C++/Python)](https://www.learnopencv.com/multitracker-multiple-object-tracking-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/MultiObjectTracker) |\n|[Convolutional Neural Network based Image Colorization using OpenCV](https://www.learnopencv.com/convolutional-neural-network-based-image-colorization-using-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Colorization)|\n|[SVM using scikit-learn](https://www.learnopencv.com/svm-using-scikit-learn-in-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/SVM-using-Python)|\n|[GOTURN: Deep Learning based Object Tracking](https://www.learnopencv.com/goturn-deep-learning-based-object-tracking/) | [Code](https://github.com/spmallick/learnopencv/tree/master/GOTURN)|\n|[Find the Center of a Blob (Centroid) using OpenCV (C++/Python)](https://www.learnopencv.com/find-center-of-blob-centroid-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/CenterofBlob)|\n|[Support Vector Machines (SVM)](https://www.learnopencv.com/support-vector-machines-svm/)|[Code](https://github.com/spmallick/learnopencv/tree/master/SVM-using-Python)|\n|[Batch Normalization in Deep Networks](https://www.learnopencv.com/batch-normalization-in-deep-networks/) | [Code](https://github.com/spmallick/learnopencv/tree/master/BatchNormalization)|\n|[Deep Learning based Character Classification using Synthetic Dataset](https://www.learnopencv.com/deep-learning-character-classification-using-synthetic-dataset/) | [Code](https://github.com/spmallick/learnopencv/tree/master/CharClassification)|\n|[Image Quality Assessment : BRISQUE](https://www.learnopencv.com/image-quality-assessment-brisque/)| [Code](https://github.com/spmallick/learnopencv/tree/master/ImageMetrics)|\n|[Understanding AlexNet](https://www.learnopencv.com/understanding-alexnet/)||\n|[Deep Learning based Text Recognition (OCR) using Tesseract and OpenCV](https://www.learnopencv.com/deep-learning-based-text-recognition-ocr-using-tesseract-and-opencv/)| [Code](https://github.com/spmallick/learnopencv/tree/master/OCR)|\n|[Deep Learning based Human Pose Estimation using OpenCV ( C++ / Python )](https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/)|[ Code](https://github.com/spmallick/learnopencv/tree/master/OpenPose)|\n|[Number of Parameters and Tensor Sizes in a Convolutional Neural Network (CNN)](https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/)| |\n|[How to convert your OpenCV C++ code into a Python module](https://www.learnopencv.com/how-to-convert-your-opencv-c-code-into-a-python-module/)|[ Code](https://github.com/spmallick/learnopencv/tree/master/pymodule)|\n|[CV4Faces : Best Project Award 2018](https://www.learnopencv.com/cv4faces-best-project-award-2018/)| |\n|[Facemark : Facial Landmark Detection using OpenCV](https://www.learnopencv.com/facemark-facial-landmark-detection-using-opencv/)|[ Code](https://github.com/spmallick/learnopencv/tree/master/FacialLandmarkDetection)|\n|[Image Alignment (Feature Based) using OpenCV (C++/Python)](https://www.learnopencv.com/image-alignment-feature-based-using-opencv-c-python/)| [Code](https://github.com/spmallick/learnopencv/tree/master/ImageAlignment-FeatureBased)|\n|[Barcode and QR code Scanner using ZBar and OpenCV](https://www.learnopencv.com/barcode-and-qr-code-scanner-using-zbar-and-opencv/)| [Code](https://github.com/spmallick/learnopencv/tree/master/barcode-QRcodeScanner)|\n|[Keras Tutorial : Fine-tuning using pre-trained models](https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Keras-Fine-Tuning)|\n|[OpenCV Transparent API](https://www.learnopencv.com/opencv-transparent-api/)| |\n|[Face Reconstruction using EigenFaces (C++/Python)](https://www.learnopencv.com/face-reconstruction-using-eigenfaces-cpp-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/ReconstructFaceUsingEigenFaces) |\n|[Eigenface using OpenCV (C++/Python)](https://www.learnopencv.com/eigenface-using-opencv-c-python/)| [Code](https://github.com/spmallick/learnopencv/tree/master/EigenFace)|\n|[Principal Component Analysis](https://www.learnopencv.com/principal-component-analysis/)| |\n|[Keras Tutorial : Transfer Learning using pre-trained models](https://www.learnopencv.com/keras-tutorial-transfer-learning-using-pre-trained-models/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Keras-Transfer-Learning) |\n|[Keras Tutorial : Using pre-trained Imagenet models](https://www.learnopencv.com/keras-tutorial-using-pre-trained-imagenet-models/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Keras-ImageNet-Models) |\n|[Technical Aspects of a Digital SLR](https://www.learnopencv.com/technical-aspects-of-a-digital-slr/) | |\n|[Using Harry Potter interactive wand with OpenCV to create magic](https://www.learnopencv.com/using-harry-potter-interactive-wand-with-opencv-to-create-magic/)| |\n|[Install OpenCV 3 and Dlib on Windows ( Python only )](https://www.learnopencv.com/install-opencv-3-and-dlib-on-windows-python-only/)| |\n|[Image Classification using Convolutional Neural Networks in Keras](https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras)      | [Code](https://github.com/spmallick/learnopencv/tree/master/KerasCNN-CIFAR)|\n|[Understanding Autoencoders using Tensorflow (Python)](https://www.learnopencv.com/understanding-autoencoders-using-tensorflow-python/)      | [Code](https://github.com/spmallick/learnopencv/tree/master/DenoisingAutoencoder)|\n|[Best Project Award : Computer Vision for Faces](https://www.learnopencv.com/best-project-award-computer-vision-for-faces/) | |\n|[Understanding Activation Functions in Deep Learning](https://www.learnopencv.com/understanding-activation-functions-in-deep-learning/)      | |\n|[Image Classification using Feedforward Neural Network in Keras](https://www.learnopencv.com/image-classification-using-feedforward-neural-network-in-keras/)      | [Code](https://github.com/spmallick/learnopencv/tree/master/KerasMLP-MNIST)|\n|[Exposure Fusion using OpenCV (C++/Python)](https://www.learnopencv.com/exposure-fusion-using-opencv-cpp-python/)      | [Code](https://github.com/spmallick/learnopencv/tree/master/ExposureFusion)|\n|[Understanding Feedforward Neural Networks](https://www.learnopencv.com/understanding-feedforward-neural-networks/)      | |\n|[High Dynamic Range (HDR) Imaging using OpenCV (C++/Python)](http://www.learnopencv.com/high-dynamic-range-hdr-imaging-using-opencv-cpp-python)      | [Code](https://github.com/spmallick/learnopencv/tree/master/hdr)|\n|[Deep learning using Keras \u2013 The Basics](http://www.learnopencv.com/deep-learning-using-keras-the-basics)      | [Code](https://github.com/spmallick/learnopencv/tree/master/keras-linear-regression)|\n|[Selective Search for Object Detection (C++ / Python)](http://www.learnopencv.com/selective-search-for-object-detection-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/SelectiveSearch) |\n|[Installing Deep Learning Frameworks on Ubuntu with CUDA support](http://www.learnopencv.com/installing-deep-learning-frameworks-on-ubuntu-with-cuda-support/) | |\n|[Parallel Pixel Access in OpenCV using forEach](http://www.learnopencv.com/parallel-pixel-access-in-opencv-using-foreach/) | [Code](https://github.com/spmallick/learnopencv/tree/master/forEach) |\n|[cvui: A GUI lib built on top of OpenCV drawing primitives](http://www.learnopencv.com/cvui-gui-lib-built-on-top-of-opencv-drawing-primitives/) | [Code](https://github.com/spmallick/learnopencv/tree/master/UI-cvui) |\n|[Install Dlib on Windows](http://www.learnopencv.com/install-dlib-on-windows/) | |\n|[Install Dlib on Ubuntu](http://www.learnopencv.com/install-dlib-on-ubuntu/) | |\n|[Install OpenCV3 on Ubuntu](http://www.learnopencv.com/install-opencv3-on-ubuntu/) | |\n|[Read, Write and Display a video using OpenCV ( C++/ Python )](http://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/VideoReadWriteDisplay) |\n|[Install Dlib on MacOS](http://www.learnopencv.com/install-dlib-on-macos/) | |\n|[Install OpenCV 3 on MacOS](http://www.learnopencv.com/install-opencv3-on-macos/) | |\n|[Install OpenCV 3 on Windows](http://www.learnopencv.com/install-opencv3-on-windows/) | |\n|[Get OpenCV Build Information ( getBuildInformation )](http://www.learnopencv.com/get-opencv-build-information-getbuildinformation/) | |\n|[Color spaces in OpenCV (C++ / Python)](http://www.learnopencv.com/color-spaces-in-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ColorSpaces)|\n|[Neural Networks : A 30,000 Feet View for Beginners](http://www.learnopencv.com/neural-networks-a-30000-feet-view-for-beginners/) | |\n|[Alpha Blending using OpenCV (C++ / Python)](http://www.learnopencv.com/alpha-blending-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/AlphaBlending) |\n|[User stories : How readers of this blog are applying their knowledge to build applications](http://www.learnopencv.com/user-stories-how-readers-of-this-blog-are-applying-their-knowledge-to-build-applications/) | |\n|[How to select a bounding box ( ROI ) in OpenCV (C++/Python) ?](http://www.learnopencv.com/how-to-select-a-bounding-box-roi-in-opencv-cpp-python/) | |\n|[Automatic Red Eye Remover using OpenCV (C++ / Python)](http://www.learnopencv.com/automatic-red-eye-remover-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/RedEyeRemover) |\n|[Bias-Variance Tradeoff in Machine Learning](http://www.learnopencv.com/bias-variance-tradeoff-in-machine-learning/) | |\n|[Embedded Computer Vision: Which device should you choose?](http://www.learnopencv.com/embedded-computer-vision-which-device-should-you-choose/) | |\n|[Object Tracking using OpenCV (C++/Python)](http://www.learnopencv.com/object-tracking-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/tracking) |\n|[Handwritten Digits Classification : An OpenCV ( C++ / Python ) Tutorial](http://www.learnopencv.com/handwritten-digits-classification-an-opencv-c-python-tutorial/) | [Code](https://github.com/spmallick/learnopencv/tree/master/digits-classification) |\n|[Training a better Haar and LBP cascade based Eye Detector using OpenCV](http://www.learnopencv.com/training-better-haar-lbp-cascade-eye-detector-opencv/) | |\n|[Deep Learning Book Gift Recipients](http://www.learnopencv.com/deep-learning-book-gift-recipients/) | |\n|[Minified OpenCV Haar and LBP Cascades](http://www.learnopencv.com/minified-opencv-haar-and-lbp-cascades/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ninjaEyeDetector)|\n|[Deep Learning Book Gift](http://www.learnopencv.com/deep-learning-book-gift/) | |\n|[Histogram of Oriented Gradients](http://www.learnopencv.com/histogram-of-oriented-gradients/) | |\n|[Image Recognition and Object Detection : Part 1](http://www.learnopencv.com/image-recognition-and-object-detection-part1/) | |\n|[Head Pose Estimation using OpenCV and Dlib](http://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/) | [Code](https://github.com/spmallick/learnopencv/tree/master/HeadPose) |\n|[Live CV : A Computer Vision Coding Application](http://www.learnopencv.com/live-cv/) | |\n|[Approximate Focal Length for Webcams and Cell Phone Cameras](http://www.learnopencv.com/approximate-focal-length-for-webcams-and-cell-phone-cameras/) | |\n|[Configuring Qt for OpenCV on OSX](http://www.learnopencv.com/configuring-qt-for-opencv-on-osx/) | [Code](https://github.com/spmallick/learnopencv/tree/master/qt-test) |\n|[Rotation Matrix To Euler Angles](http://www.learnopencv.com/rotation-matrix-to-euler-angles/) | [Code](https://github.com/spmallick/learnopencv/tree/master/RotationMatrixToEulerAngles) |\n|[Speeding up Dlib\u2019s Facial Landmark Detector](http://www.learnopencv.com/speeding-up-dlib-facial-landmark-detector/) | |\n|[Warp one triangle to another using OpenCV ( C++ / Python )](http://www.learnopencv.com/warp-one-triangle-to-another-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/WarpTriangle) |\n|[Average Face : OpenCV ( C++ / Python ) Tutorial](http://www.learnopencv.com/average-face-opencv-c-python-tutorial/) | [Code](https://github.com/spmallick/learnopencv/tree/master/FaceAverage) |\n|[Face Swap using OpenCV ( C++ / Python )](http://www.learnopencv.com/face-swap-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/FaceSwap) |\n|[Face Morph Using OpenCV \u2014 C++ / Python](http://www.learnopencv.com/face-morph-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/FaceMorph) |\n|[Deep Learning Example using NVIDIA DIGITS 3 on EC2](http://www.learnopencv.com/deep-learning-example-using-nvidia-digits-3-on-ec2/) | |\n|[NVIDIA DIGITS 3 on EC2](http://www.learnopencv.com/nvidia-digits-3-on-ec2/) | |\n|[Homography Examples using OpenCV ( Python / C ++ )](http://www.learnopencv.com/homography-examples-using-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Homography) |\n|[Filling holes in an image using OpenCV ( Python / C++ )](http://www.learnopencv.com/filling-holes-in-an-image-using-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Holes) |\n|[How to find frame rate or frames per second (fps) in OpenCV ( Python / C++ ) ?](http://www.learnopencv.com/how-to-find-frame-rate-or-frames-per-second-fps-in-opencv-python-cpp/) | [Code](https://github.com/spmallick/learnopencv/tree/master/FPS) |\n|[Delaunay Triangulation and Voronoi Diagram using OpenCV ( C++ / Python) ](http://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Delaunay) |\n|[OpenCV (C++ vs Python) vs MATLAB for Computer Vision](http://www.learnopencv.com/opencv-c-vs-python-vs-matlab-for-computer-vision/) | |\n|[Facial Landmark Detection](http://www.learnopencv.com/facial-landmark-detection/) | |\n|[Why does OpenCV use BGR color format ?](http://www.learnopencv.com/why-does-opencv-use-bgr-color-format/) | |\n|[Computer Vision for Predicting Facial Attractiveness](http://www.learnopencv.com/computer-vision-for-predicting-facial-attractiveness/) | [Code](https://github.com/spmallick/learnopencv/tree/master/FacialAttractiveness) |\n|[applyColorMap for pseudocoloring in OpenCV ( C++ / Python )](http://www.learnopencv.com/applycolormap-for-pseudocoloring-in-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Colormap) |\n|[Image Alignment (ECC) in OpenCV ( C++ / Python )](http://www.learnopencv.com/image-alignment-ecc-in-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ImageAlignment) |\n|[How to find OpenCV version in Python and C++ ?](http://www.learnopencv.com/how-to-find-opencv-version-python-cpp/) | |\n|[Baidu banned from ILSVRC 2015](http://www.learnopencv.com/baidu-banned-from-ilsvrc-2015/) | |\n|[OpenCV Transparent API](http://www.learnopencv.com/opencv-transparent-api/) | |\n|[How Computer Vision Solved the Greatest Soccer Mystery of All Time](http://www.learnopencv.com/how-computer-vision-solved-the-greatest-soccer-mystery-of-all-times/) | |\n|[Embedded Vision Summit 2015](http://www.learnopencv.com/embedded-vision-summit-2015/) | |\n|[Read an Image in OpenCV ( Python, C++ )](http://www.learnopencv.com/read-an-image-in-opencv-python-cpp/) | [Code](https://github.com/spmallick/learnopencv/tree/master/imread) |\n|[Non-Photorealistic Rendering using OpenCV ( Python, C++ )](http://www.learnopencv.com/non-photorealistic-rendering-using-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/NonPhotorealisticRendering) |\n|[Seamless Cloning using OpenCV ( Python , C++ )](http://www.learnopencv.com/seamless-cloning-using-opencv-python-cpp/) | [Code](https://github.com/spmallick/learnopencv/tree/master/SeamlessCloning) |\n|[OpenCV Threshold ( Python , C++ )](http://www.learnopencv.com/opencv-threshold-python-cpp/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Threshold) |\n|[Blob Detection Using OpenCV ( Python, C++ )](http://www.learnopencv.com/blob-detection-using-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/BlobDetector) |\n|[Turn your OpenCV Code into a Web API in under 10 minutes \u2014 Part 1](http://www.learnopencv.com/turn-your-opencv-Code-into-a-web-api-in-under-10-minutes-part-1/) | |\n|[How to compile OpenCV sample Code ?](http://www.learnopencv.com/how-to-compile-opencv-sample-Code/) | |\n|[Install OpenCV 3 on Yosemite ( OSX 10.10.x )](http://www.learnopencv.com/install-opencv-3-on-yosemite-osx-10-10-x/) | |\n",
	"c-plus-plus c-sharp cntk cognitive-toolkit deep-learning deep-neural-networks distributed java machine-learning neural-network python": "## CNTK\n\n| **Chat** | **Windows build status** | **Linux build status** |\n|-------------|-------------|---------------|\n| [![Join the chat at https://gitter.im/Microsoft/CNTK](https://badges.gitter.im/Microsoft/CNTK.svg)](https://gitter.im/Microsoft/CNTK?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) | [![Build Status](https://aiinfra.visualstudio.com/_apis/public/build/definitions/a95b3960-90bb-440b-bd18-d3ec5d1cf8c3/126/badge)](https://cntk.ai/nightly-windows.html) | [![Build Status](https://aiinfra.visualstudio.com/_apis/public/build/definitions/a95b3960-90bb-440b-bd18-d3ec5d1cf8c3/127/badge)](https://cntk.ai/nightly-linux.html) |\n\nThe Microsoft Cognitive Toolkit (https://cntk.ai) is a unified deep learning toolkit that describes neural networks as a series of computational steps via a directed graph. In this directed graph, leaf nodes represent input values or network parameters, while other nodes represent matrix operations upon their inputs. CNTK allows users to easily realize and combine popular model types such as feed-forward DNNs, convolutional nets (CNNs), and recurrent networks (RNNs/LSTMs). It implements stochastic gradient descent (SGD, error backpropagation) learning with automatic differentiation and parallelization across multiple GPUs and servers. CNTK has been available under an open-source license since April 2015. It is our hope that the community will take advantage of CNTK to share ideas more quickly through the exchange of open source working code.\n\n## Installation\n\n* [Setup CNTK](https://docs.microsoft.com/en-us/cognitive-toolkit/Setup-CNTK-on-your-machine)\n    * Windows ([Python-only](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-windows-python) / [Script-driven](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-windows-binary-script) / [Manual](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-windows-binary-manual))\n    * Linux ([Python-only](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-linux-python) / [Script-driven](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-linux-binary-script) / [Manual](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-linux-binary-manual) / [Docker](https://docs.microsoft.com/en-us/cognitive-toolkit/cntk-docker-containers))\n* [CNTK backend for Keras](https://docs.microsoft.com/en-us/cognitive-toolkit/using-cntk-with-keras)\n* [Setup CNTK development environment](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-development-environment)\n    * Windows ([Script-driven](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-with-script-on-windows) / [Manual](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-windows))\n    * Linux ([Manual](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-linux))\n    \n### Installing nightly packages\n\nIf you prefer to use latest CNTK bits from master, use one of the CNTK nightly packages:\n\n* [Nightly packages for Windows](https://cntk.ai/nightly-windows.html)\n* [Nightly packages for Linux](https://cntk.ai/nightly-linux.html)\n\n## Learning CNTK\n\nYou can learn more about using and contributing to CNTK with the following resources:\n\n* [General documentation](https://docs.microsoft.com/en-us/cognitive-toolkit/)\n* [Python API documentation](https://cntk.ai/pythondocs/)\n* [Evaluation documentation (C++, C#/.NET, Python, Java)](https://docs.microsoft.com/en-us/cognitive-toolkit/CNTK-Evaluation-Overview)\n* [Manual](https://github.com/Microsoft/CNTK/tree/master/Manual)\n* [Tutorials](https://docs.microsoft.com/en-us/cognitive-toolkit/tutorials)\n* [Examples](https://docs.microsoft.com/en-us/cognitive-toolkit/Examples)\n* [Pretrained models](./PretrainedModels)\n* [Blog](https://www.microsoft.com/en-us/cognitive-toolkit/blog/)\n* [Presentations](https://docs.microsoft.com/en-us/cognitive-toolkit/Presentations)\n* [License](./LICENSE.md)\n\n## More information\n\n* [Contribute to CNTK](https://docs.microsoft.com/en-us/cognitive-toolkit/Contributing-to-CNTK)\n* [FAQ](https://docs.microsoft.com/en-us/cognitive-toolkit/CNTK-FAQ)\n* [Feedback](https://docs.microsoft.com/en-us/cognitive-toolkit/Feedback-Channels)\n\n## Disclaimer\n\nDear community, \n\nWith our ongoing contributions to ONNX and the ONNX Runtime, we have made it easier to interoperate within the AI framework ecosystem and to access high performance, cross-platform inferencing capabilities for both traditional ML models and deep neural networks. Over the last few years we have been privileged to develop such key open-source machine learning projects, including the Microsoft Cognitive Toolkit, which has enabled its users to leverage industry-wide advancements in deep learning at scale. \n\nToday\u2019s 2.7 release will be the last main release of CNTK. We may have some subsequent minor releases for bug fixes, but these will be evaluated on a case-by-case basis. There are no plans for new feature development post this release. \n\nThe CNTK 2.7 release has full support for ONNX 1.4.1, and we encourage those seeking to operationalize their CNTK models to take advantage of ONNX and the ONNX Runtime. Moving forward, users can continue to leverage evolving ONNX innovations via the number of frameworks that support it. For example, users can natively export ONNX models from PyTorch or convert TensorFlow models to ONNX with the TensorFlow-ONNX converter. \n\nWe are incredibly grateful for all the support we have received from contributors and users over the years since the initial open-source release of CNTK. CNTK has enabled both Microsoft teams and external users to execute complex and large-scale workloads in all manner of deep learning applications, such as historical breakthroughs in speech recognition achieved by Microsoft Speech researchers, the originators of the framework. \n\nAs ONNX is increasingly employed in serving models used across Microsoft products such as Bing and Office, we are dedicated to synthesizing innovations from research with the rigorous demands of production to progress the ecosystem forward. \n\nAbove all, our goal is to make innovations in deep learning across the software and hardware stacks as open and accessible as possible. We will be working hard to bring both the existing strengths of CNTK and new state-of-the-art research into other open-source projects to truly broaden the reach of such technologies. \n\nWith gratitude, \n\n-- The CNTK Team \n\n## Microsoft Open Source Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## News\n\n> You can find more news on [the official project feed](https://docs.microsoft.com/en-us/cognitive-toolkit/news)\n\n***2019-03-29.*** CNTK 2.7.0\n## Highlights of this release\n* Moved to CUDA 10 for both Windows and Linux.\n* Support advance RNN loop in ONNX export.\n* Export larger than 2GB models in ONNX format.\n* Support FP16 in Brain Script train action.\n\n## CNTK support for CUDA 10\n\n### CNTK now supports CUDA 10. This requires an update to build environment to Visual Studio 2017 v15.9 for Windows.\n\nTo setup build and runtime environment on Windows:\n* Install [Visual Studio 2017](https://www.visualstudio.com/downloads/). Note: going forward for CUDA 10 and beyond, it is no longer required to install and run with the specific VC Tools version 14.11.\n* Install [Nvidia CUDA 10](https://developer.nvidia.com/cuda-downloads?target_os=Windows&target_arch=x86_64)\n* From PowerShell, run:\n    [DevInstall.ps1](../Tools/devInstall/Windows/DevInstall.ps1)\n* Start Visual Studio 2017 and open [CNTK.sln](./CNTK.sln).\n\nTo setup build and runtime environment on Linux using docker, please build Unbuntu 16.04 docker image using Dockerfiles [here](./Tools/docker). For other Linux systems, please refer to the Dockerfiles to setup dependent libraries for CNTK.\n\n## Support advance RNN loop in ONNX export\nCNTK models with recursive loops can be exported to ONNX models with scan ops.\n\n## Export larger than 2GB models in ONNX format\nTo export models larger than 2GB in ONNX format, use cntk.Function API:\nsave(self, filename, format=ModelFormat.CNTKv2, use_external_files_to_store_parameters=False)\nwith 'format' set to ModelFormat.ONNX and use_external_files_to_store_parameters set to True.\nIn this case, model parameters are saved in external files. Exported models shall be used with external parameter files when doing model evaluation with onnxruntime.\n\n***2018-11-26.***  \n[Netron](https://github.com/lutzroeder/netron) now supports visualizing CNTK v1 and CNTK v2 `.model` files.\n\n<img src=https://cntk.ai/Images/netron/netron-cntk-dark-1.png alt=\"NetronCNTKDark1\" width=\"300\"> <img src=https://cntk.ai/Images/netron/netron-cntk-light-1.png alt=\"NetronCNTKLight1\" width=\"300\">\n\n\n### Project changelog\n\n***2018-09-17.*** CNTK 2.6.0\n## Efficient group convolution\nThe implementation of group convolution in CNTK has been updated. The updated implementation moves away from creating a sub-graph for group convolution (using slicing and splicing), and instead uses cuDNN7 and MKL2017 APIs directly. This improves the experience both in terms of performance and model size. \n\nAs an example, for a single group convolution op with the following attributes:\n\n- Input tensor (C, H, W) = (32, 128, 128)\n- Number of output channels = 32 (channel multiplier is 1)\n- Groups = 32 (depth wise convolution)\n- Kernel size = (5, 5)\n\nThe comparison numbers for this single node are as follows:\n\n| First Header  | GPU exec. time (in millisec., 1000 run avg.) | CPU exec. time (in millisec., 1000 run avg.) | Model Size (in KB, CNTK format)\n| ------------- | ------------- | ------------- | ------------- |\n| Old implementation  | 9.349  | 41.921  | 38  |\n| New implementation  | 6.581  | 9.963  | 5  |\n| Speedup/savings   Approx.  | 30%  Approx.  | 65-75%   Approx.  | 87% |\n\n## Sequential Convolution\nThe implementation of sequential convolution in CNTK has been updated. The updated implementation creates a separate sequential convolution layer. Different from regular convolution layer, this operation convolves also on the dynamic axis(sequence), and filter_shape[0] is applied to that axis. The updated implementation supports broader cases, such as where stride > 1 for the sequence axis.\n\nFor example, a sequential convolution over a batch of one-channel black-and-white images. The images have the same fixed height of 640, but each with width of variable lengths. The width is then represented by sequential axis. Padding is enabled, and strides for both width and height are 2.\n\n     >>> f = SequentialConvolution((3,3), reduction_rank=0, pad=True, strides=(2,2), activation=C.relu)\n     >>> x = C.input_variable(**Sequence[Tensor[640]])\n     >>> x.shape\n         (640,)\n     >>> h = f(x)\n     >>> h.shape\n         (320,)\n     >>> f.W.shape\n         (1, 1, 3, 3)\n\n## Operators\n### depth_to_space and space_to_depth\nThere is a breaking change in the **depth_to_space** and **space_to_depth** operators. These have been updated to match ONNX specification, specifically\nthe permutation for how the depth dimension is placed as blocks in the spatial dimensions, and vice-versa, has been changed. Please refer to the updated doc\nexamples for these two ops to see the change.\n\n### Tan and Atan\nAdded support for trigonometric ops `Tan` and `Atan`.\n\n### ELU\nAdded support for `alpha` attribute in ELU op.\n\n### Convolution\nUpdated auto padding algorithms of `Convolution` to produce symmetric padding at best effort on CPU, without affecting the final convolution output values. This update increases the range of cases that could be covered by MKL API and improves the performance, E.g. ResNet50.\n\n## Default arguments order\nThere is a breaking change in the **arguments** property in CNTK python API. The default behavior has been updated to return arguments in python order instead of in C++ order. This way it will return arguments in the same order as they are fed into ops. If you wish to still get arguments in C++ order, you can simply override the global option. This change should only affect the following ops: Times, TransposeTimes, and Gemm(internal). \n\n## Bug fixes\n- Updated doc for Convolution layer to include group and dilation arguments.\n- Added improved input validation for group convolution.\n- Updated `LogSoftMax` to use more numerically stable implementation.\n- Fixed Gather op's incorrect gradient value.\n- Added validation for 'None' node in python clone substitution.\n- Added validation for padding channel axis in convolution.\n- Added CNTK native default lotusIR logger to fix the \"Attempt to use DefaultLogger\" error when loading some ONNX models.\n- Added proper initialization for ONNX TypeStrToProtoMap.\n- Updated python doctest to handle different print format for newer version numpy(version >= 1.14).\n- Fixed Pooling(CPU) to produce correct output values when kernel center is on padded input cells.\n\n## ONNX\n### Updates\n- Updated CNTK's ONNX import/export to use ONNX 1.2 spec.\n- Major update to how batch and sequence axes are handled in export and import. As a result, the complex scenarios and edge cases are handled accurately.\n- Updated CNTK's ONNX `BatchNormalization` op export/import to latest spec.\n- Added model domain to ONNX model export.\n- Improved error reporting during import and export of ONNX models.\n- Updated `DepthToSpace` and `SpaceToDepth` ops to match ONNX spec on the permutation for how the depth dimension is placed as block dimension.\n- Added support for exporting `alpha` attribute in `ELU` ONNX op.\n- Major overhaul to `Convolution` and `Pooling` export. Unlike before, these ops do not export an explicit `Pad` op in any situation.\n- Major overhaul to `ConvolutionTranspose` export and import. Attributes such as `output_shape`, `output_padding`, and `pads` are fully supported.\n- Added support for CNTK's `StopGradient` as a no-op.\n- Added ONNX support for TopK op.\n- Added ONNX support for sequence ops: sequence.slice, sequence.first, sequence.last, sequence.reduce_sum, sequence.reduce_max, sequence.softmax. For these ops, there is no need to expand ONNX spec. CNTK ONNX exporter just builds computation equivalent graphs for these sequence ops.\n- Added full support for Softmax op.\n- Made CNTK broadcast ops compatible with ONNX specification.\n- Handle to_batch, to_sequence, unpack_batch, sequence.unpack ops in CNTK ONNX exporter.\n- ONNX tests to export ONNX test cases for other toolkits to run and to validate.\n- Fixed `Hardmax`/`Softmax`/`LogSoftmax` import/export.\n- Added support for `Select` op export.\n- Added import/export support for several trigonometric ops.\n- Updated CNTK support for ONNX `MatMul` op.\n- Updated CNTK support for ONNX `Gemm` op.\n- Updated CNTK's ONNX `MeanVarianceNormalization` op export/import to latest spec.\n- Updated CNTK's ONNX `LayerNormalization` op export/import to latest spec.\n- Updated CNTK's ONNX `PRelu` op export/import to latest spec.\n- Updated CNTK's ONNX `Gather` op export/import to latest spec.\n- Updated CNTK's ONNX `ImageScaler` op export/import to latest spec.\n- Updated CNTK's ONNX `Reduce` ops export/import to latest spec.\n- Updated CNTK's ONNX `Flatten` op export/import to latest spec.\n- Added CNTK support for ONNX `Unsqueeze` op.\n\n### Bug or minor fixes:\n- Updated LRN op to match ONNX 1.2 spec where the `size` attribute has the semantics of diameter, not radius. Added validation if LRN kernel size is larger than channel size.\n- Updated `Min`/`Max` import implementation to handle variadic inputs.\n- Fixed possible file corruption when resaving on top of existing ONNX model file.\n\n## .Net Support\nThe Cntk.Core.Managed library has officially been converted to .Net Standard and supports .Net Core and .Net Framework applications on both Windows and Linux. Starting from this release, .Net developers should be able to restore CNTK Nuget packages using new .Net SDK style project file with package management format set to PackageReference.\n\nThe following C# code now works on both Windows and Linux:\n\n     >>> var weightParameterName = \"weight\";\n\t >>> var biasParameterName = \"bias\";\n\t >>> var inputName = \"input\";\n\t >>> var outputDim = 2;\n\t >>> var inputDim = 3;\n\t >>> Variable inputVariable = Variable.InputVariable(new int[] { inputDim }, DataType.Float, inputName);\n\t >>> var weightParameter = new Parameter(new int[] { outputDim, inputDim }, DataType.Float, 1, device, weightParameterName);\n\t >>> var biasParameter = new Parameter(new int[] { outputDim }, DataType.Float, 0, device, biasParameterName);\n\t >>> \n     >>> Function modelFunc = CNTKLib.Times(weightParameter, inputVariable) + biasParameter;\n\nFor example, simply adding an ItemGroup clause in the .csproj file of a .Net Core application is sufficient:\n     >>> <Project Sdk=\"Microsoft.NET.Sdk\">\n     >>>\n     >>>   <PropertyGroup>\n     >>>     <TargetFramework>netcoreapp2.1</TargetFramework>\n     >>>     <Platforms>x64</Platforms>\n     >>>   </PropertyGroup>\n     >>>\n     >>>   <ItemGroup>\n     >>>     <PackageReference Include=\"CNTK.GPU\" Version=\"2.6.0\" />\n     >>>   </ItemGroup>\n     >>>\n     >>> </Project>\n\n### Bug or minor fixes:\n- Fixed C# string and char to native wstring and wchar UTF conversion issues on Linux.\n- Fixed multibyte and wide character conversions across the codebase.\n- Fixed Nuget package mechanism to pack for .Net Standard.\n- Fixed a memory leak issue in Value class in C# API where Dispose was not called upon object destruction.\n\n## Misc\n\n\n***2018-04-16.*** CNTK 2.5.1\n\nRepack CNTK 2.5 with third party libraries included in the bundles (Python wheel packages)\n\n---\n\n***2018-03-15.*** CNTK 2.5\n\nChange profiler details output format to be `chrome://tracing`\n\nEnable per-node timing. Working example [here](/Examples/Image/Classification/MLP/Python/SimpleMNIST.py)\n* per-node timing creates items in profiler details when profiler is enabled.\n* usage in Python:\n\n```python\nimport cntk as C\nC.debugging.debug.set_node_timing(True)\nC.debugging.start_profiler() # optional\nC.debugging.enable_profiler() # optional\n#<trainer|evaluator|function> executions\n<trainer|evaluator|function>.print_node_timing()\nC.debugging.stop_profiler()\n```\n\nExample profiler details view in `chrome://tracing`\n![ProfilerDetailWithNodeTiming](https://cntk.ai/Images/ProfilerDetailWithNodeTiming.jpg)\n\nCPU inference performance improvements using MKL\n* Accelerates some common tensor ops in Intel CPU inference for float32, especially for fully connected networks\n* Can be turned on/off by `cntk.cntk_py.enable_cpueval_optimization()/cntk.cntk_py.disable_cpueval_optimization()`\n\n1BitSGD incorporated into CNTK\n* `1BitSGD` source code is now available with CNTK license (MIT license) under `Source/1BitSGD/`\n* `1bitsgd` build target was merged into existing gpu target\n\nNew loss function: hierarchical softmax\n* Thanks @yaochengji for the contribution!\n\nDistributed Training with Multiple Learners\n* Trainer now accepts multiple parameter learners for distributed training. With this change, different parameters of a network can be learned by different learners in a single training session. This also facilitates distributed training for GANs. For more information, please refer to the [Basic_GAN_Distributed.py](/Examples/Image/GAN/Basic_GAN_Distributed.py) and the [cntk.learners.distributed_multi_learner_test.py](/bindings/python/cntk/learners/tests/distributed_multi_learner_test.py)\n\nOperators\n* Added `MeanVarianceNormalization` operator. \n\nBug fixes\n* Fixed convergence issue in Tutorial 201B\n* Fixed pooling/unpooling to support free dimension for sequences\n* Fixed crash in `CNTKBinaryFormat` deserializer when crossing sweep boundary\n* Fixed shape inference bug in RNN step function for scalar broadcasting\n* Fixed a build bug when `mpi=no`\n* Improved distributed training aggregation speed by increasing packing threshold, and expose the knob in V2\n* Fixed a memory leak in MKL layout\n* Fixed a bug in `cntk.convert` API in `misc.converter.py`, which prevents converting complex networks.\n\nONNX\n* Updates\n    * CNTK exported ONNX models are now `ONNX.checker` compliant. \n    * Added ONNX support for CNTK\u2019s `OptimizedRNNStack` operator (LSTM only).\n    * Added support for LSTM and GRU operators\n    * Added support for experimental ONNX op `MeanVarianceNormalization`.\n    * Added support for experimental ONNX op `Identity`.\n    * Added support for exporting CNTK\u2019s `LayerNormalization` layer using ONNX `MeanVarianceNormalization` op.\n* Bug or minor fixes:\n    * Axis attribute is optional in CNTK\u2019s ONNX `Concat` operator.\n    * Bug fix in ONNX broadcasting for scalars.\n    * Bug fix in ONNX ConvTranspose operator. \n    * Backward compatibility bug fix in `LeakyReLu` (argument \u2018alpha\u2019 reverted to type double).\n\nMisc\n* Added a new API `find_by_uid()` under `cntk.logging.graph`. \n\n---\n\n***2018-02-28.*** CNTK supports nightly build\n\nIf you prefer to use latest CNTK bits from master, use one of the CNTK nightly package.\n* [Nightly packages for Windows](https://cntk.ai/nightly-windows.html)\n* [Nightly packages for Linux](https://cntk.ai/nightly-linux.html)\n\nAlternatively, you can also click corresponding build badge to land to nightly build page.\n\n---\n\n***2018-01-31.* CNTK 2.4**\n\nHighlights:\n* Moved to CUDA9, cuDNN 7 and Visual Studio 2017.\n* Removed Python 3.4 support.\n* Added Volta GPU and FP16 support.\n* Better ONNX support.\n* CPU perf improvement.\n* More OPs.\n\nOPs\n* `top_k` operation: in the forward pass it computes the top (largest) k values and corresponding indices along the specified axis. In the backward pass the gradient is scattered to the top k elements (an element not in the top k gets a zero gradient).\n* `gather` operation now supports an axis argument\n* `squeeze` and `expand_dims` operations for easily removing and adding singleton axes\n* `zeros_like` and `ones_like` operations. In many situations you can just rely on CNTK correctly broadcasting a simple 0 or 1 but sometimes you need the actual tensor.\n* `depth_to_space`: Rearranges elements in the input tensor from the depth dimension into spatial blocks. Typical use of this operation is for implementing sub-pixel convolution for some image super-resolution models.\n* `space_to_depth`: Rearranges elements in the input tensor from the spatial dimensions to the depth dimension. It is largely the inverse of DepthToSpace.\n* `sum` operation: Create a new Function instance that computes element-wise sum of input tensors.\n* `softsign` operation: Create a new Function instance that computes the element-wise softsign of a input tensor.\n* `asinh` operation: Create a new Function instance that computes the element-wise asinh of a input tensor.\n* `log_softmax` operation: Create a new Function instance that computes the logsoftmax normalized values of a input tensor.\n* `hard_sigmoid` operation: Create a new Function instance that computes the hard_sigmoid normalized values of a input tensor.\n* `element_and`, `element_not`, `element_or`, `element_xor` element-wise logic operations\n* `reduce_l1` operation: Computes the L1 norm of the input tensor's element along the provided axes.\n* `reduce_l2` operation: Computes the L2 norm of the input tensor's element along the provided axes.\n* `reduce_sum_square` operation: Computes the sum square of the input tensor's element along the provided axes.\n* `image_scaler` operation: Alteration of image by scaling its individual values.\n\nONNX\n* There have been several improvements to ONNX support in CNTK.\n* Updates\n  * Updated ONNX `Reshape` op to handle `InferredDimension`.\n  * Adding `producer_name` and `producer_version` fields to ONNX models.\n  * Handling the case when neither `auto_pad` nor `pads` atrribute is specified in ONNX `Conv` op.\n* Bug fixes\n  * Fixed bug in ONNX `Pooling` op serialization\n  * Bug fix to create ONNX `InputVariable` with only one batch axis.\n  * Bug fixes and updates to implementation of ONNX `Transpose` op to match updated spec.\n  * Bug fixes and updates to implementation of ONNX `Conv`, `ConvTranspose`, and `Pooling` ops to match updated spec.\n\nOperators\n* Group convolution\n  * Fixed bug in group convolution. Output of CNTK `Convolution` op will change for groups > 1. More optimized implementation of group convolution is expected in the next release.\n  * Better error reporting for group convolution in `Convolution` layer.\n\nHalide Binary Convolution\n- The CNTK build can now use optional [Halide](http://halide-lang.org/) libraries to build `Cntk.BinaryConvolution.so/dll` library that can be used with the `netopt` module. The library contains optimized binary convolution operators that perform better than the python based binarized convolution operators. To enable Halide in the build, please download [Halide release](https://github.com/halide/Halide/releases) and set `HALIDE_PATH` environment varibale before starting a build. In Linux, you can use `./configure --with-halide[=directory]` to enable it. For more information on how to use this feature, please refer to [How_to_use_network_optimization](https://github.com/Microsoft/CNTK/blob/master/Manual/Manual_How_to_use_network_optimizations.ipynb).\n\nSee more in the [Release Notes](https://docs.microsoft.com/en-us/cognitive-toolkit/ReleaseNotes/CNTK_2_4_Release_Notes).\nGet the Release from the [CNTK Releases page](https://github.com/Microsoft/CNTK/releases).\n",
	"deep-learning deep-neural-networks dnn keras machine-learning ml mxnet neural-network onnx pytorch scikit-learn tensorflow": "<!--- SPDX-License-Identifier: Apache-2.0 -->\n\n<p align=\"center\"><img width=\"40%\" src=\"https://github.com/onnx/onnx/raw/main/docs/onnx-horizontal-color.png\" /></p>\n\n\n[![Build Status](https://dev.azure.com/onnx-pipelines/onnx/_apis/build/status/Windows-CI?branchName=main)](https://dev.azure.com/onnx-pipelines/onnx/_build/latest?definitionId=5&branchName=main)\n[![Build Status](https://dev.azure.com/onnx-pipelines/onnx/_apis/build/status/Linux-CI?branchName=main)](https://dev.azure.com/onnx-pipelines/onnx/_build/latest?definitionId=7&branchName=main)\n[![Build Status](https://dev.azure.com/onnx-pipelines/onnx/_apis/build/status/MacOS-CI?branchName=main)](https://dev.azure.com/onnx-pipelines/onnx/_build/latest?definitionId=6&branchName=main)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3313/badge)](https://bestpractices.coreinfrastructure.org/projects/3313)\n\n[Open Neural Network Exchange (ONNX)](https://onnx.ai) is an open ecosystem that empowers AI developers\nto choose the right tools as their project evolves. ONNX provides an open source format for AI models, both deep learning and traditional ML. It defines an extensible computation graph model, as well as definitions of built-in operators and standard\ndata types. Currently we focus on the capabilities needed for inferencing (scoring).\n\nONNX is [widely supported](http://onnx.ai/supported-tools) and can be found in many frameworks, tools, and hardware. Enabling interoperability between different frameworks and streamlining the path from research to production helps increase the speed of innovation in the AI community. We invite the community to join us and further evolve ONNX.\n\n# Use ONNX\n* [Documentation of ONNX Python Package](https://onnx.ai/onnx/)\n* [Tutorials for creating ONNX models](https://github.com/onnx/tutorials).\n* [Pre-trained ONNX models](https://github.com/onnx/models)\n\n# Learn about the ONNX spec\n* [Overview](docs/Overview.md)\n* [ONNX intermediate representation spec](docs/IR.md)\n* [Versioning principles of the spec](docs/Versioning.md)\n* [Operators documentation](docs/Operators.md) (development version)\n* [Operators documentation](https://onnx.ai/onnx/operators/index.html) (latest release)\n* [Python API Overview](docs/PythonAPIOverview.md)\n\n# Programming utilities for working with ONNX Graphs\n* [Shape and Type Inference](docs/ShapeInference.md)\n* [Graph Optimization](https://github.com/onnx/optimizer)\n* [Opset Version Conversion](docs/VersionConverter.md)\n\n# Contribute\nONNX is a [community project](community/readme.md). We encourage you to join the effort and contribute feedback, ideas, and code. You can participate in the [Special Interest Groups](community/sigs.md) and [Working Groups](community/working-groups.md) to shape the future of ONNX.\n\nCheck out our [contribution guide](docs/CONTRIBUTING.md) to get started.\n\nIf you think some operator should be added to ONNX specification, please read\n[this document](docs/AddNewOp.md).\n\n# Discuss\nWe encourage you to open [Issues](https://github.com/onnx/onnx/issues), or use [Slack](https://lfaifoundation.slack.com/) (If you have not joined yet, please use this [link](https://join.slack.com/t/lfaifoundation/shared_invite/zt-o65errpw-gMTbwNr7FnNbVXNVFkmyNA) to join the group) for more real-time discussion.\n\n# Follow Us\nStay up to date with the latest ONNX news. [[Facebook](https://www.facebook.com/onnxai/)] [[Twitter](https://twitter.com/onnxai)]\n\n\n# Installation\n\n## Official Python packages\nONNX released packages are published in PyPi.\n```\npip install onnx\n```\n\n[Weekly packages](https://test.pypi.org/project/onnx-weekly/) are published in test pypi to enable experimentation and early testing.\n\n## vcpkg packages\nonnx is in the maintenance list of [vcpkg](https://github.com/microsoft/vcpkg), you can easily use vcpkg to build and install it.\n```\ngit clone https://github.com/microsoft/vcpkg.git\ncd vcpkg\n./bootstrap-vcpkg.bat # For powershell\n./bootstrap-vcpkg.sh # For bash\n./vcpkg install onnx\n```\n\n## Conda packages\nA binary build of ONNX is available from [Conda](https://conda.io), in [conda-forge](https://conda-forge.org/):\n```\nconda install -c conda-forge onnx\n```\n\n\n## Build ONNX from Source\nBefore building from source uninstall any existing versions of onnx `pip uninstall onnx`.\n\nc++17 or higher C++ compiler version is required to build ONNX from source on Windows. For other platforms, please use C++11 or higher versions.\n\nGenerally speaking, you need to install [protobuf C/C++ libraries and tools](https://github.com/protocolbuffers/protobuf) before proceeding forward. Then depending on how you installed protobuf, you need to set environment variable CMAKE_ARGS to \"-DONNX_USE_PROTOBUF_SHARED_LIBS=ON\" or \"-DONNX_USE_PROTOBUF_SHARED_LIBS=OFF\".  For example, you may need to run the following command:\n\nLinux:\n```bash\nexport CMAKE_ARGS=\"-DONNX_USE_PROTOBUF_SHARED_LIBS=ON\"\n```\nWindows:\n```bat\nset CMAKE_ARGS=\"-DONNX_USE_PROTOBUF_SHARED_LIBS=ON\"\n```\n\nThe ON/OFF depends on what kind of protobuf library you have. Shared libraries are files ending with \\*.dll/\\*.so/\\*.dylib. Static libraries are files ending with \\*.a/\\*.lib. This option depends on how you get your protobuf library and how it was built. And it is default OFF. You don't need to run the commands above if you'd prefer to use a static protobuf library.\n\n\n### Windows\nIf you are building ONNX from source, it is recommended that you also build Protobuf locally as a static library. The version distributed with conda-forge is a DLL, but ONNX expects it to be a static library. Building protobuf locally also lets you control the version of protobuf. The tested and recommended version is 3.20.2.\n\nThe instructions in this README assume you are using Visual Studio.  It is recommended that you run all the commands from a shell started from \"x64 Native Tools Command Prompt for VS 2019\" and keep the build system generator for cmake (e.g., cmake -G \"Visual Studio 16 2019\") consistent while building protobuf as well as ONNX.\n\nYou can get protobuf by running the following commands:\n```bat\ngit clone https://github.com/protocolbuffers/protobuf.git\ncd protobuf\ngit checkout v3.20.2\ncd cmake\ncmake -G \"Visual Studio 16 2019\" -A x64 -DCMAKE_INSTALL_PREFIX=<protobuf_install_dir> -Dprotobuf_MSVC_STATIC_RUNTIME=OFF -Dprotobuf_BUILD_SHARED_LIBS=OFF -Dprotobuf_BUILD_TESTS=OFF -Dprotobuf_BUILD_EXAMPLES=OFF .\nmsbuild protobuf.sln /m /p:Configuration=Release\nmsbuild INSTALL.vcxproj /p:Configuration=Release\n```\nThen it will be built as a static library and installed to <protobuf_install_dir>. Please add the bin directory(which contains protoc.exe) to your PATH.\n\n```bat\nset PATH=<protobuf_install_dir>/bin;%PATH%\n```\n\nPlease note: if your protobuf_install_dir contains spaces, **do not** add quotation marks around it.\n\nAlternative: if you don't want to change your PATH, you can set ONNX_PROTOC_EXECUTABLE instead.\n```bat\nset CMAKE_ARGS=-DONNX_PROTOC_EXECUTABLE=<full_path_to_protoc.exe>\n```\n\nThen you can build ONNX as:\n```\ngit clone https://github.com/onnx/onnx.git\ncd onnx\ngit submodule update --init --recursive\n# prefer lite proto\nset CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON\npip install -e .\n```\n\n### Linux\n\nFirst, you need to install protobuf. The minimum Protobuf compiler (protoc) version required by ONNX is 3.0.0. Please note that old protoc versions might not work with `CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON`.\n\nUbuntu 18.04 (and newer) users may choose to install protobuf via\n```bash\napt-get install python3-pip python3-dev libprotobuf-dev protobuf-compiler\n```\nIn this case, it is required to add `-DONNX_USE_PROTOBUF_SHARED_LIBS=ON` to CMAKE_ARGS in the ONNX build step.\n\nA more general way is to build and install it from source. See the instructions below for more details.\n\n<details>\n  <summary> Installing Protobuf from source </summary>\n\n  Debian/Ubuntu:\n  ```bash\n    git clone https://github.com/protocolbuffers/protobuf.git\n    cd protobuf\n    git checkout v3.20.2\n    git submodule update --init --recursive\n    mkdir build_source && cd build_source\n    cmake ../cmake -Dprotobuf_BUILD_SHARED_LIBS=OFF -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_INSTALL_SYSCONFDIR=/etc -DCMAKE_POSITION_INDEPENDENT_CODE=ON -Dprotobuf_BUILD_TESTS=OFF -DCMAKE_BUILD_TYPE=Release\n    make -j$(nproc)\n    make install\n  ```\n\n  CentOS/RHEL/Fedora:\n  ```bash\n    git clone https://github.com/protocolbuffers/protobuf.git\n    cd protobuf\n    git checkout v3.20.2\n    git submodule update --init --recursive\n    mkdir build_source && cd build_source\n    cmake ../cmake  -DCMAKE_INSTALL_LIBDIR=lib64 -Dprotobuf_BUILD_SHARED_LIBS=OFF -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_INSTALL_SYSCONFDIR=/etc -DCMAKE_POSITION_INDEPENDENT_CODE=ON -Dprotobuf_BUILD_TESTS=OFF -DCMAKE_BUILD_TYPE=Release\n    make -j$(nproc)\n    make install\n  ```\n\n  Here \"-DCMAKE_POSITION_INDEPENDENT_CODE=ON\" is crucial. By default static libraries are built without \"-fPIC\" flag, they are not position independent code. But shared libraries must be position independent code. Python C/C++ extensions(like ONNX) are shared libraries. So if a static library was not built with \"-fPIC\", it can't be linked to such a shared library.\n\n  Once build is successful, update PATH to include protobuf paths.\n\n</details>\n\n\nThen you can build ONNX as:\n```\ngit clone https://github.com/onnx/onnx.git\ncd onnx\ngit submodule update --init --recursive\n# Optional: prefer lite proto\nexport CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON\npip install -e .\n```\n\n### Mac\n\n```\nexport NUM_CORES=`sysctl -n hw.ncpu`\nbrew update\nbrew install autoconf && brew install automake\nwget https://github.com/protocolbuffers/protobuf/releases/download/v3.20.2/protobuf-cpp-3.20.2.tar.gz\ntar -xvf protobuf-cpp-3.20.2.tar.gz\ncd protobuf-3.20.2\nmkdir build_source && cd build_source\ncmake ../cmake -Dprotobuf_BUILD_SHARED_LIBS=OFF -DCMAKE_POSITION_INDEPENDENT_CODE=ON -Dprotobuf_BUILD_TESTS=OFF -DCMAKE_BUILD_TYPE=Release\nmake -j${NUM_CORES}\nmake install\n```\n\nOnce build is successful, update PATH to include protobuf paths.\n\nThen you can build ONNX as:\n```\ngit clone --recursive https://github.com/onnx/onnx.git\ncd onnx\n# Optional: prefer lite proto\nset CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON\npip install -e .\n```\n\n\n## Verify Installation\nAfter installation, run\n\n```\npython -c \"import onnx\"\n```\n\nto verify it works.\n\n\n## Common Build Options\nFor full list refer to CMakeLists.txt\n**Environment variables**\n* `USE_MSVC_STATIC_RUNTIME` should be 1 or 0, not ON or OFF. When set to 1 onnx links statically to runtime library.\n**Default**: USE_MSVC_STATIC_RUNTIME=0\n\n* `DEBUG` should be 0 or 1. When set to 1 onnx is built in debug mode. or debug versions of the dependencies, you need to open the [CMakeLists file](CMakeLists.txt) and append a letter `d` at the end of the package name lines. For example, `NAMES protobuf-lite` would become `NAMES protobuf-lited`.\n**Default**: Debug=0\n\n**CMake variables**\n* `ONNX_USE_PROTOBUF_SHARED_LIBS` should be ON or OFF.\n**Default**: ONNX_USE_PROTOBUF_SHARED_LIBS=OFF USE_MSVC_STATIC_RUNTIME=0\n`ONNX_USE_PROTOBUF_SHARED_LIBS` determines how onnx links to protobuf libraries.\n    - When set to ON - onnx will dynamically link to protobuf shared libs, PROTOBUF_USE_DLLS will be defined as described [here](https://github.com/protocolbuffers/protobuf/blob/master/cmake/README.md#dlls-vs-static-linking), Protobuf_USE_STATIC_LIBS will be set to OFF and `USE_MSVC_STATIC_RUNTIME` must be 0.\n    - When set to OFF - onnx will link statically to protobuf, and Protobuf_USE_STATIC_LIBS will be set to ON (to force the use of the static libraries) and `USE_MSVC_STATIC_RUNTIME` can be 0 or 1.\n\n* `ONNX_USE_LITE_PROTO` should be ON or OFF. When set to ON onnx uses lite protobuf instead of full protobuf.\n**Default**: ONNX_USE_LITE_PROTO=OFF\n\n* `ONNX_WERROR` should be ON or OFF. When set to ON warnings are treated as errors.\n**Default**: ONNX_WERROR=OFF in local builds, ON in CI and release pipelines.\n\n\n## Common Errors\n* Note: the `import onnx` command does not work from the source checkout directory; in this case you'll see `ModuleNotFoundError: No module named 'onnx.onnx_cpp2py_export'`. Change into another directory to fix this error.\n\n* If you run into any issues while building Protobuf as a static library, please ensure that shared Protobuf libraries, like libprotobuf, are not installed on your device or in the conda environment. If these shared libraries exist, either remove them to build Protobuf from source as a static library, or skip the Protobuf build from source to use the shared version directly.\n\n* If you run into any issues while building ONNX from source, and your error message reads, \"Could not find pythonXX.lib\", ensure that you have consistent Python versions for common commands, such as `python` and `pip`. Clean all existing build files and rebuild ONNX again.\n\n# Testing\n\nONNX uses [pytest](https://docs.pytest.org) as test driver. In order to run tests, you will first need to install pytest:\n\n```\npip install pytest nbval\n```\n\nAfter installing pytest, use the following command to run tests.\n\n```\npytest\n```\n\n# Development\n\nCheck out the [contributor guide](docs/CONTRIBUTING.md) for instructions.\n\n# License\n\n[Apache License v2.0](LICENSE)\n\n# Code of Conduct\n\n[ONNX Open Source Code of Conduct](https://onnx.ai/codeofconduct.html)\n",
	"awesome awesome-list deep-learning deep-learning-tutorial deep-neural-networks deeplearning list machine-learning machinelearning neural-network neural-networks": "\n# Machine Learning & Deep Learning Tutorials [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\n- This repository contains a topic-wise curated list of Machine Learning and Deep Learning tutorials, articles and other resources. Other awesome lists can be found in this [list](https://github.com/sindresorhus/awesome).\n\n- If you want to contribute to this list, please read [Contributing Guidelines](https://github.com/ujjwalkarn/Machine-Learning-Tutorials/blob/master/contributing.md).\n\n- [Curated list of R tutorials for Data Science, NLP and Machine Learning](https://github.com/ujjwalkarn/DataScienceR).\n\n- [Curated list of Python tutorials for Data Science, NLP and Machine Learning](https://github.com/ujjwalkarn/DataSciencePython).\n\n\n## Contents\n- [Introduction](#general)\n- [Interview Resources](#interview)\n- [Artificial Intelligence](#ai)\n- [Genetic Algorithms](#ga)\n- [Statistics](#stat)\n- [Useful Blogs](#blogs)\n- [Resources on Quora](#quora)\n- [Resources on Kaggle](#kaggle)\n- [Cheat Sheets](#cs)\n- [Classification](#classification)\n- [Linear Regression](#linear)\n- [Logistic Regression](#logistic)\n- [Model Validation using Resampling](#validation)\n    - [Cross Validation](#cross)\n    - [Bootstraping](#boot)\n- [Deep Learning](#deep)\n    - [Frameworks](#frame)\n    - [Feed Forward Networks](#feed)\n    - [Recurrent Neural Nets, LSTM, GRU](#rnn)\n    - [Restricted Boltzmann Machine, DBNs](#rbm)\n    - [Autoencoders](#auto)\n    - [Convolutional Neural Nets](#cnn)\n    - [Graph Representation Learning](#nrl)\n- [Natural Language Processing](#nlp)\n    - [Topic Modeling, LDA](#topic)\n    - [Word2Vec](#word2vec)\n- [Computer Vision](#vision)\n- [Support Vector Machine](#svm)\n- [Reinforcement Learning](#rl)\n- [Decision Trees](#dt)\n- [Random Forest / Bagging](#rf)\n- [Boosting](#gbm)\n- [Ensembles](#ensem)\n- [Stacking Models](#stack)\n- [VC Dimension](#vc)\n- [Bayesian Machine Learning](#bayes)\n- [Semi Supervised Learning](#semi)\n- [Optimizations](#opt)\n- [Other Useful Tutorials](#other)\n\n<a name=\"general\" />\n\n## Introduction\n\n- [Machine Learning Course by Andrew Ng (Stanford University)](https://www.coursera.org/learn/machine-learning)\n\n- [AI/ML YouTube Courses](https://github.com/dair-ai/ML-YouTube-Courses)\n\n- [Curated List of Machine Learning Resources](https://hackr.io/tutorials/learn-machine-learning-ml)\n\n- [In-depth introduction to machine learning in 15 hours of expert videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)\n\n- [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)\n\n- [List of Machine Learning University Courses](https://github.com/prakhar1989/awesome-courses#machine-learning)\n\n- [Machine Learning for Software Engineers](https://github.com/ZuzooVn/machine-learning-for-software-engineers)\n\n- [Dive into Machine Learning](https://github.com/hangtwenty/dive-into-machine-learning)\n\n- [A curated list of awesome Machine Learning frameworks, libraries and software](https://github.com/josephmisiti/awesome-machine-learning)\n\n- [A curated list of awesome data visualization libraries and resources.](https://github.com/fasouto/awesome-dataviz)\n\n- [An awesome Data Science repository to learn and apply for real world problems](https://github.com/okulbilisim/awesome-datascience)\n\n- [The Open Source Data Science Masters](http://datasciencemasters.org/)\n\n- [Machine Learning FAQs on Cross Validated](http://stats.stackexchange.com/questions/tagged/machine-learning)\n\n- [Machine Learning algorithms that you should always have a strong understanding of](https://www.quora.com/What-are-some-Machine-Learning-algorithms-that-you-should-always-have-a-strong-understanding-of-and-why)\n\n- [Difference between Linearly Independent, Orthogonal, and Uncorrelated Variables](http://terpconnect.umd.edu/~bmomen/BIOM621/LineardepCorrOrthogonal.pdf)\n\n- [List of Machine Learning Concepts](https://en.wikipedia.org/wiki/List_of_machine_learning_concepts)\n\n- [Slides on Several Machine Learning Topics](http://www.slideshare.net/pierluca.lanzi/presentations)\n\n- [MIT Machine Learning Lecture Slides](http://www.ai.mit.edu/courses/6.867-f04/lectures.html)\n\n- [Comparison Supervised Learning Algorithms](http://www.dataschool.io/comparing-supervised-learning-algorithms/)\n\n- [Learning Data Science Fundamentals](http://www.dataschool.io/learning-data-science-fundamentals/)\n\n- [Machine Learning mistakes to avoid](https://medium.com/@nomadic_mind/new-to-machine-learning-avoid-these-three-mistakes-73258b3848a4#.lih061l3l)\n\n- [Statistical Machine Learning Course](http://www.stat.cmu.edu/~larry/=sml/)\n\n- [TheAnalyticsEdge edX Notes and Codes](https://github.com/pedrosan/TheAnalyticsEdge)\n\n- [Have Fun With Machine Learning](https://github.com/humphd/have-fun-with-machine-learning)\n\n- [Twitter's Most Shared #machineLearning Content From The Past 7 Days](http://theherdlocker.com/tweet/popularity/machinelearning)\n\n- [Grokking Machine Learning](https://www.manning.com/books/grokking-machine-learning)\n\n<a name=\"interview\" />\n\n## Interview Resources\n\n- [41 Essential Machine Learning Interview Questions (with answers)](https://www.springboard.com/blog/machine-learning-interview-questions/)\n\n- [How can a computer science graduate student prepare himself for data scientist interviews?](https://www.quora.com/How-can-a-computer-science-graduate-student-prepare-himself-for-data-scientist-machine-learning-intern-interviews)\n\n- [How do I learn Machine Learning?](https://www.quora.com/How-do-I-learn-machine-learning-1)\n\n- [FAQs about Data Science Interviews](https://www.quora.com/topic/Data-Science-Interviews/faq)\n\n- [What are the key skills of a data scientist?](https://www.quora.com/What-are-the-key-skills-of-a-data-scientist)\n\n- [The Big List of DS/ML Interview Resources](https://towardsdatascience.com/the-big-list-of-ds-ml-interview-resources-2db4f651bd63)\n\n<a name=\"ai\" />\n\n## Artificial Intelligence\n\n- [Awesome Artificial Intelligence (GitHub Repo)](https://github.com/owainlewis/awesome-artificial-intelligence)\n\n- [UC Berkeley CS188 Intro to AI](http://ai.berkeley.edu/home.html), [Lecture Videos](http://ai.berkeley.edu/lecture_videos.html), [2](https://www.youtube.com/watch?v=W1S-HSakPTM)\n\n- [Programming Community Curated Resources for learning Artificial Intelligence](https://hackr.io/tutorials/learn-artificial-intelligence-ai) \n\n- [MIT 6.034 Artificial Intelligence Lecture Videos](https://www.youtube.com/playlist?list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi), [Complete Course](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/)\n\n- [edX course | Klein & Abbeel](https://courses.edx.org/courses/BerkeleyX/CS188x_1/1T2013/info)\n\n- [Udacity Course | Norvig & Thrun](https://www.udacity.com/course/intro-to-artificial-intelligence--cs271)\n\n- [TED talks on AI](http://www.ted.com/playlists/310/talks_on_artificial_intelligen)\n\n<a name=\"ga\" />\n\n## Genetic Algorithms\n\n- [Genetic Algorithms Wikipedia Page](https://en.wikipedia.org/wiki/Genetic_algorithm)\n\n- [Simple Implementation of Genetic Algorithms in Python (Part 1)](http://outlace.com/miniga.html), [Part 2](http://outlace.com/miniga_addendum.html)\n\n- [Genetic Algorithms vs Artificial Neural Networks](http://stackoverflow.com/questions/1402370/when-to-use-genetic-algorithms-vs-when-to-use-neural-networks)\n\n- [Genetic Algorithms Explained in Plain English](http://www.ai-junkie.com/ga/intro/gat1.html)\n\n- [Genetic Programming](https://en.wikipedia.org/wiki/Genetic_programming)\n\n    - [Genetic Programming in Python (GitHub)](https://github.com/trevorstephens/gplearn)\n    \n    - [Genetic Alogorithms vs Genetic Programming (Quora)](https://www.quora.com/Whats-the-difference-between-Genetic-Algorithms-and-Genetic-Programming), [StackOverflow](http://stackoverflow.com/questions/3819977/what-are-the-differences-between-genetic-algorithms-and-genetic-programming)\n\n<a name=\"stat\" />\n\n## Statistics\n\n- [Stat Trek Website](http://stattrek.com/) - A dedicated website to teach yourselves Statistics\n\n- [Learn Statistics Using Python](https://github.com/rouseguy/intro2stats) - Learn Statistics using an application-centric programming approach\n\n- [Statistics for Hackers | Slides | @jakevdp](https://speakerdeck.com/jakevdp/statistics-for-hackers) - Slides by Jake VanderPlas\n\n- [Online Statistics Book](http://onlinestatbook.com/2/index.html) - An Interactive Multimedia Course for Studying Statistics\n\n- [What is a Sampling Distribution?](http://stattrek.com/sampling/sampling-distribution.aspx)\n\n- Tutorials\n\n    - [AP Statistics Tutorial](http://stattrek.com/tutorials/ap-statistics-tutorial.aspx)\n    \n    - [Statistics and Probability Tutorial](http://stattrek.com/tutorials/statistics-tutorial.aspx)\n    \n    - [Matrix Algebra Tutorial](http://stattrek.com/tutorials/matrix-algebra-tutorial.aspx)\n    \n- [What is an Unbiased Estimator?](https://www.physicsforums.com/threads/what-is-an-unbiased-estimator.547728/)\n\n- [Goodness of Fit Explained](https://en.wikipedia.org/wiki/Goodness_of_fit)\n\n- [What are QQ Plots?](http://onlinestatbook.com/2/advanced_graphs/q-q_plots.html)\n\n- [OpenIntro Statistics](https://www.openintro.org/stat/textbook.php?stat_book=os) - Free PDF textbook\n\n<a name=\"blogs\" />\n\n## Useful Blogs\n\n- [Edwin Chen's Blog](http://blog.echen.me/) - A blog about Math, stats, ML, crowdsourcing, data science\n\n- [The Data School Blog](http://www.dataschool.io/) - Data science for beginners!\n\n- [ML Wave](http://mlwave.com/) - A blog for Learning Machine Learning\n\n- [Andrej Karpathy](http://karpathy.github.io/) - A blog about Deep Learning and Data Science in general\n\n- [Colah's Blog](http://colah.github.io/) - Awesome Neural Networks Blog\n\n- [Alex Minnaar's Blog](http://alexminnaar.com/) - A blog about Machine Learning and Software Engineering\n\n- [Statistically Significant](http://andland.github.io/) - Andrew Landgraf's Data Science Blog\n\n- [Simply Statistics](http://simplystatistics.org/) - A blog by three biostatistics professors\n\n- [Yanir Seroussi's Blog](https://yanirseroussi.com/) - A blog about Data Science and beyond\n\n- [fastML](http://fastml.com/) - Machine learning made easy\n\n- [Trevor Stephens Blog](http://trevorstephens.com/) - Trevor Stephens Personal Page\n\n- [no free hunch | kaggle](http://blog.kaggle.com/) - The Kaggle Blog about all things Data Science\n\n- [A Quantitative Journey | outlace](http://outlace.com/) -  learning quantitative applications\n\n- [r4stats](http://r4stats.com/) - analyze the world of data science, and to help people learn to use R\n\n- [Variance Explained](http://varianceexplained.org/) - David Robinson's Blog\n\n- [AI Junkie](http://www.ai-junkie.com/) - a blog about Artificial Intellingence\n\n- [Deep Learning Blog by Tim Dettmers](http://timdettmers.com/) - Making deep learning accessible\n\n- [J Alammar's Blog](http://jalammar.github.io/)- Blog posts about Machine Learning and Neural Nets\n\n- [Adam Geitgey](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471#.f7vwrtfne) - Easiest Introduction to machine learning\n\n- [Ethen's Notebook Collection](https://github.com/ethen8181/machine-learning) - Continuously updated machine learning documentations (mainly in Python3). Contents include educational implementation of machine learning algorithms from scratch and open-source library usage\n\n<a name=\"quora\" />\n\n## Resources on Quora\n\n- [Most Viewed Machine Learning writers](https://www.quora.com/topic/Machine-Learning/writers)\n\n- [Data Science Topic on Quora](https://www.quora.com/Data-Science)\n\n- [William Chen's Answers](https://www.quora.com/William-Chen-6/answers)\n\n- [Michael Hochster's Answers](https://www.quora.com/Michael-Hochster/answers)\n\n- [Ricardo Vladimiro's Answers](https://www.quora.com/Ricardo-Vladimiro-1/answers)\n\n- [Storytelling with Statistics](https://datastories.quora.com/)\n\n- [Data Science FAQs on Quora](https://www.quora.com/topic/Data-Science/faq)\n\n- [Machine Learning FAQs on Quora](https://www.quora.com/topic/Machine-Learning/faq)\n\n<a name=\"kaggle\" />\n\n## Kaggle Competitions WriteUp\n\n- [How to almost win Kaggle Competitions](https://yanirseroussi.com/2014/08/24/how-to-almost-win-kaggle-competitions/)\n\n- [Convolution Neural Networks for EEG detection](http://blog.kaggle.com/2015/10/05/grasp-and-lift-eeg-detection-winners-interview-3rd-place-team-hedj/)\n\n- [Facebook Recruiting III Explained](http://alexminnaar.com/tag/kaggle-competitions.html)\n\n- [Predicting CTR with Online ML](http://mlwave.com/predicting-click-through-rates-with-online-machine-learning/)\n\n- [How to Rank 10% in Your First Kaggle Competition](https://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/)\n\n<a name=\"cs\" />\n\n## Cheat Sheets\n\n- [Probability Cheat Sheet](http://static1.squarespace.com/static/54bf3241e4b0f0d81bf7ff36/t/55e9494fe4b011aed10e48e5/1441352015658/probability_cheatsheet.pdf),\n[Source](http://www.wzchen.com/probability-cheatsheet/)\n\n- [Machine Learning Cheat Sheet](https://github.com/soulmachine/machine-learning-cheat-sheet)\n\n- [ML Compiled](https://ml-compiled.readthedocs.io/en/latest/)\n\n<a name=\"classification\" />\n\n## Classification\n\n- [Does Balancing Classes Improve Classifier Performance?](http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance/)\n\n- [What is Deviance?](http://stats.stackexchange.com/questions/6581/what-is-deviance-specifically-in-cart-rpart)\n\n- [When to choose which machine learning classifier?](http://stackoverflow.com/questions/2595176/when-to-choose-which-machine-learning-classifier)\n\n- [What are the advantages of different classification algorithms?](https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms)\n\n- [ROC and AUC Explained](http://www.dataschool.io/roc-curves-and-auc-explained/) ([related video](https://youtu.be/OAl6eAyP-yo))\n\n- [An introduction to ROC analysis](https://ccrma.stanford.edu/workshops/mir2009/references/ROCintro.pdf)\n\n- [Simple guide to confusion matrix terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n\n\n<a name=\"linear\" />\n\n## Linear Regression\n\n- [General](#general-)\n\n    - [Assumptions of Linear Regression](http://pareonline.net/getvn.asp?n=2&v=8), [Stack Exchange](http://stats.stackexchange.com/questions/16381/what-is-a-complete-list-of-the-usual-assumptions-for-linear-regression)\n    \n    - [Linear Regression Comprehensive Resource](http://people.duke.edu/~rnau/regintro.htm)\n    \n    - [Applying and Interpreting Linear Regression](http://www.dataschool.io/applying-and-interpreting-linear-regression/)\n    \n    - [What does having constant variance in a linear regression model mean?](http://stats.stackexchange.com/questions/52089/what-does-having-constant-variance-in-a-linear-regression-model-mean/52107?stw=2#52107)\n    \n    - [Difference between linear regression on y with x and x with y](http://stats.stackexchange.com/questions/22718/what-is-the-difference-between-linear-regression-on-y-with-x-and-x-with-y?lq=1)\n    \n    - [Is linear regression valid when the dependant variable is not normally distributed?](https://www.researchgate.net/post/Is_linear_regression_valid_when_the_outcome_dependant_variable_not_normally_distributed)\n- Multicollinearity and VIF\n\n    - [Dummy Variable Trap | Multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity)\n    \n    - [Dealing with multicollinearity using VIFs](https://jonlefcheck.net/2012/12/28/dealing-with-multicollinearity-using-variance-inflation-factors/)\n\n- [Residual Analysis](#residuals-)\n\n    - [Interpreting plot.lm() in R](http://stats.stackexchange.com/questions/58141/interpreting-plot-lm)\n    \n    - [How to interpret a QQ plot?](http://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot?lq=1)\n    \n    - [Interpreting Residuals vs Fitted Plot](http://stats.stackexchange.com/questions/76226/interpreting-the-residuals-vs-fitted-values-plot-for-verifying-the-assumptions)\n\n- [Outliers](#outliers-)\n\n    - [How should outliers be dealt with?](http://stats.stackexchange.com/questions/175/how-should-outliers-be-dealt-with-in-linear-regression-analysis)\n\n- [Elastic Net](https://en.wikipedia.org/wiki/Elastic_net_regularization)\n    - [Regularization and Variable Selection via the\nElastic Net](https://web.stanford.edu/~hastie/Papers/elasticnet.pdf)\n\n<a name=\"logistic\" />\n\n## Logistic Regression\n\n- [Logistic Regression Wiki](https://en.wikipedia.org/wiki/Logistic_regression)\n\n- [Geometric Intuition of Logistic Regression](http://florianhartl.com/logistic-regression-geometric-intuition.html)\n\n- [Obtaining predicted categories (choosing threshold)](http://stats.stackexchange.com/questions/25389/obtaining-predicted-values-y-1-or-0-from-a-logistic-regression-model-fit)\n\n- [Residuals in logistic regression](http://stats.stackexchange.com/questions/1432/what-do-the-residuals-in-a-logistic-regression-mean)\n\n- [Difference between logit and probit models](http://stats.stackexchange.com/questions/20523/difference-between-logit-and-probit-models#30909), [Logistic Regression Wiki](https://en.wikipedia.org/wiki/Logistic_regression), [Probit Model Wiki](https://en.wikipedia.org/wiki/Probit_model)\n\n- [Pseudo R2 for Logistic Regression](http://stats.stackexchange.com/questions/3559/which-pseudo-r2-measure-is-the-one-to-report-for-logistic-regression-cox-s), [How to calculate](http://stats.stackexchange.com/questions/8511/how-to-calculate-pseudo-r2-from-rs-logistic-regression), [Other Details](http://www.ats.ucla.edu/stat/mult_pkg/faq/general/Psuedo_RSquareds.htm)\n\n- [Guide to an in-depth understanding of logistic regression](http://www.dataschool.io/guide-to-logistic-regression/)\n\n<a name=\"validation\" />\n\n## Model Validation using Resampling\n\n- [Resampling Explained](https://en.wikipedia.org/wiki/Resampling_(statistics))\n\n- [Partioning data set in R](http://stackoverflow.com/questions/13536537/partitioning-data-set-in-r-based-on-multiple-classes-of-observations)\n\n- [Implementing hold-out Validaion in R](http://stackoverflow.com/questions/22972854/how-to-implement-a-hold-out-validation-in-r), [2](http://www.gettinggeneticsdone.com/2011/02/split-data-frame-into-testing-and.html)\n\n<a name=\"cross\" />\n\n- [Cross Validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics))\n    - [How to use cross-validation in predictive modeling](http://stuartlacy.co.uk/2016/02/04/how-to-correctly-use-cross-validation-in-predictive-modelling/)\n    - [Training with Full dataset after CV?](http://stats.stackexchange.com/questions/11602/training-with-the-full-dataset-after-cross-validation)\n    \n    - [Which CV method is best?](http://stats.stackexchange.com/questions/103459/how-do-i-know-which-method-of-cross-validation-is-best)\n    \n    - [Variance Estimates in k-fold CV](http://stats.stackexchange.com/questions/31190/variance-estimates-in-k-fold-cross-validation)\n    \n    - [Is CV a subsitute for Validation Set?](http://stats.stackexchange.com/questions/18856/is-cross-validation-a-proper-substitute-for-validation-set)\n    \n    - [Choice of k in k-fold CV](http://stats.stackexchange.com/questions/27730/choice-of-k-in-k-fold-cross-validation)\n    \n    - [CV for ensemble learning](http://stats.stackexchange.com/questions/102631/k-fold-cross-validation-of-ensemble-learning)\n    \n    - [k-fold CV in R](http://stackoverflow.com/questions/22909197/creating-folds-for-k-fold-cv-in-r-using-caret)\n    \n    - [Good Resources](http://www.chioka.in/tag/cross-validation/)\n    \n    - Overfitting and Cross Validation\n    \n        - [Preventing Overfitting the Cross Validation Data | Andrew Ng](http://ai.stanford.edu/~ang/papers/cv-final.pdf)\n        \n        - [Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation](http://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf)\n\n        - [CV for detecting and preventing Overfitting](http://www.autonlab.org/tutorials/overfit10.pdf)\n        \n        - [How does CV overcome the Overfitting Problem](http://stats.stackexchange.com/questions/9053/how-does-cross-validation-overcome-the-overfitting-problem)\n\n\n<a name=\"boot\" />\n\n- [Bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))\n\n    - [Why Bootstrapping Works?](http://stats.stackexchange.com/questions/26088/explaining-to-laypeople-why-bootstrapping-works)\n    \n    - [Good Animation](https://www.stat.auckland.ac.nz/~wild/BootAnim/)\n    \n    - [Example of Bootstapping](http://statistics.about.com/od/Applications/a/Example-Of-Bootstrapping.htm)\n    \n    - [Understanding Bootstapping for Validation and Model Selection](http://stats.stackexchange.com/questions/14516/understanding-bootstrapping-for-validation-and-model-selection?rq=1)\n    \n    - [Cross Validation vs Bootstrap to estimate prediction error](http://stats.stackexchange.com/questions/18348/differences-between-cross-validation-and-bootstrapping-to-estimate-the-predictio), [Cross-validation vs .632 bootstrapping to evaluate classification performance](http://stats.stackexchange.com/questions/71184/cross-validation-or-bootstrapping-to-evaluate-classification-performance)\n\n\n<a name=\"deep\" />\n\n## Deep Learning\n\n- [fast.ai - Practical Deep Learning For Coders](http://course.fast.ai/)\n\n- [fast.ai - Cutting Edge Deep Learning For Coders](http://course.fast.ai/part2.html)\n\n- [A curated list of awesome Deep Learning tutorials, projects and communities](https://github.com/ChristosChristofidis/awesome-deep-learning)\n\n- **[Deep Learning Papers Reading Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md)**\n\n- [Lots of Deep Learning Resources](http://deeplearning4j.org/documentation.html)\n\n- [Interesting Deep Learning and NLP Projects (Stanford)](http://cs224d.stanford.edu/reports.html), [Website](http://cs224d.stanford.edu/)\n\n- [Core Concepts of Deep Learning](https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/)\n\n- [Understanding Natural Language with Deep Neural Networks Using Torch](https://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n\n- [Stanford Deep Learning Tutorial](http://ufldl.stanford.edu/tutorial/)\n\n- [Deep Learning FAQs on Quora](https://www.quora.com/topic/Deep-Learning/faq)\n\n- [Google+ Deep Learning Page](https://plus.google.com/communities/112866381580457264725)\n\n- [Recent Reddit AMAs related to Deep Learning](http://deeplearning.net/2014/11/22/recent-reddit-amas-about-deep-learning/), [Another AMA](https://www.reddit.com/r/IAmA/comments/3mdk9v/we_are_google_researchers_working_on_deep/)\n\n- [Where to Learn Deep Learning?](http://www.kdnuggets.com/2014/05/learn-deep-learning-courses-tutorials-overviews.html)\n\n- [Deep Learning nvidia concepts](http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/)\n\n- [Introduction to Deep Learning Using Python (GitHub)](https://github.com/rouseguy/intro2deeplearning), [Good Introduction Slides](https://speakerdeck.com/bargava/introduction-to-deep-learning)\n\n- [Video Lectures Oxford 2015](https://www.youtube.com/playlist?list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu), [Video Lectures Summer School Montreal](http://videolectures.net/deeplearning2015_montreal/)\n\n- [Deep Learning Software List](http://deeplearning.net/software_links/)\n\n- [Hacker's guide to Neural Nets](http://karpathy.github.io/neuralnets/)\n\n- [Top arxiv Deep Learning Papers explained](http://www.kdnuggets.com/2015/10/top-arxiv-deep-learning-papers-explained.html)\n\n- [Geoff Hinton Youtube Vidoes on Deep Learning](https://www.youtube.com/watch?v=IcOMKXAw5VA)\n\n- [Awesome Deep Learning Reading List](http://deeplearning.net/reading-list/)\n\n- [Deep Learning Comprehensive Website](http://deeplearning.net/), [Software](http://deeplearning.net/software_links/)\n\n- [deeplearning Tutorials](http://deeplearning4j.org/)\n\n- [AWESOME! Deep Learning Tutorial](https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks)\n\n- [Deep Learning Basics](http://alexminnaar.com/deep-learning-basics-neural-networks-backpropagation-and-stochastic-gradient-descent.html)\n\n- [Intuition Behind Backpropagation](https://medium.com/spidernitt/breaking-down-neural-networks-an-intuitive-approach-to-backpropagation-3b2ff958794c)\n\n- [Stanford Tutorials](http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/)\n\n- [Train, Validation & Test in Artificial Neural Networks](http://stackoverflow.com/questions/2976452/whats-is-the-difference-between-train-validation-and-test-set-in-neural-networ)\n\n- [Artificial Neural Networks Tutorials](http://stackoverflow.com/questions/478947/what-are-some-good-resources-for-learning-about-artificial-neural-networks)\n\n- [Neural Networks FAQs on Stack Overflow](http://stackoverflow.com/questions/tagged/neural-network?sort=votes&pageSize=50)\n\n- [Deep Learning Tutorials on deeplearning.net](http://deeplearning.net/tutorial/index.html)\n\n- [Neural Networks and Deep Learning Online Book](http://neuralnetworksanddeeplearning.com/)\n\n- Neural Machine Translation\n\n    - **[Machine Translation Reading List](https://github.com/THUNLP-MT/MT-Reading-List#machine-translation-reading-list)**\n\n    - [Introduction to Neural Machine Translation with GPUs (part 1)](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/), [Part 2](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/), [Part 3](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/)\n    \n    - [Deep Speech: Accurate Speech Recognition with GPU-Accelerated Deep Learning](https://devblogs.nvidia.com/parallelforall/deep-speech-accurate-speech-recognition-gpu-accelerated-deep-learning/)\n\n<a name=\"frame\" />\n\n- Deep Learning Frameworks\n\n    - [Torch vs. Theano](http://fastml.com/torch-vs-theano/)\n    \n    - [dl4j vs. torch7 vs. theano](http://deeplearning4j.org/compare-dl4j-torch7-pylearn.html)\n    \n    - [Deep Learning Libraries by Language](http://www.teglor.com/b/deep-learning-libraries-language-cm569/)\n    \n\n    - [Theano](https://en.wikipedia.org/wiki/Theano_(software))\n    \n        - [Website](http://deeplearning.net/software/theano/)\n        \n        - [Theano Introduction](http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/)\n        \n        - [Theano Tutorial](http://outlace.com/Beginner-Tutorial-Theano/)\n        \n        - [Good Theano Tutorial](http://deeplearning.net/software/theano/tutorial/)\n        \n        - [Logistic Regression using Theano for classifying digits](http://deeplearning.net/tutorial/logreg.html#logreg)\n        \n        - [MLP using Theano](http://deeplearning.net/tutorial/mlp.html#mlp)\n        \n        - [CNN using Theano](http://deeplearning.net/tutorial/lenet.html#lenet)\n        \n        - [RNNs using Theano](http://deeplearning.net/tutorial/rnnslu.html#rnnslu)\n        \n        - [LSTM for Sentiment Analysis in Theano](http://deeplearning.net/tutorial/lstm.html#lstm)\n        \n        - [RBM using Theano](http://deeplearning.net/tutorial/rbm.html#rbm)\n        \n        - [DBNs using Theano](http://deeplearning.net/tutorial/DBN.html#dbn)\n        \n        - [All Codes](https://github.com/lisa-lab/DeepLearningTutorials)\n        \n        - [Deep Learning Implementation Tutorials - Keras and Lasagne](https://github.com/vict0rsch/deep_learning/)\n\n    - [Torch](http://torch.ch/)\n    \n        - [Torch ML Tutorial](http://code.madbits.com/wiki/doku.php), [Code](https://github.com/torch/tutorials)\n        \n        - [Intro to Torch](http://ml.informatik.uni-freiburg.de/_media/teaching/ws1415/presentation_dl_lect3.pdf)\n        \n        - [Learning Torch GitHub Repo](https://github.com/chetannaik/learning_torch)\n        \n        - [Awesome-Torch (Repository on GitHub)](https://github.com/carpedm20/awesome-torch)\n        \n        - [Machine Learning using Torch Oxford Univ](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/), [Code](https://github.com/oxford-cs-ml-2015)\n        \n        - [Torch Internals Overview](https://apaszke.github.io/torch-internals.html)\n        \n        - [Torch Cheatsheet](https://github.com/torch/torch7/wiki/Cheatsheet)\n        \n        - [Understanding Natural Language with Deep Neural Networks Using Torch](http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n\n    - Caffe\n        - [Deep Learning for Computer Vision with Caffe and cuDNN](https://devblogs.nvidia.com/parallelforall/deep-learning-computer-vision-caffe-cudnn/)\n\n    - TensorFlow\n        - [Website](http://tensorflow.org/)\n        \n        - [TensorFlow Examples for Beginners](https://github.com/aymericdamien/TensorFlow-Examples)\n        \n        - [Stanford Tensorflow for Deep Learning Research Course](https://web.stanford.edu/class/cs20si/syllabus.html)\n        \n            - [GitHub Repo](https://github.com/chiphuyen/tf-stanford-tutorials)\n            \n        - [Simplified Scikit-learn Style Interface to TensorFlow](https://github.com/tensorflow/skflow)\n        \n        - [Learning TensorFlow GitHub Repo](https://github.com/chetannaik/learning_tensorflow)\n        \n        - [Benchmark TensorFlow GitHub](https://github.com/soumith/convnet-benchmarks/issues/66)\n        \n        - [Awesome TensorFlow List](https://github.com/jtoy/awesome-tensorflow)\n        \n        - [TensorFlow Book](https://github.com/BinRoot/TensorFlow-Book)\n        \n        - [Android TensorFlow Machine Learning Example](https://blog.mindorks.com/android-tensorflow-machine-learning-example-ff0e9b2654cc)\n        \n            - [GitHub Repo](https://github.com/MindorksOpenSource/AndroidTensorFlowMachineLearningExample)\n        - [Creating Custom Model For Android Using TensorFlow](https://blog.mindorks.com/creating-custom-model-for-android-using-tensorflow-3f963d270bfb)\n            - [GitHub Repo](https://github.com/MindorksOpenSource/AndroidTensorFlowMNISTExample)            \n\n<a name=\"feed\" />\n\n- Feed Forward Networks\n\n    - [A Quick Introduction to Neural Networks](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)\n    \n    - [Implementing a Neural Network from scratch](http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/), [Code](https://github.com/dennybritz/nn-from-scratch)\n    \n    - [Speeding up your Neural Network with Theano and the gpu](http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/), [Code](https://github.com/dennybritz/nn-theano)\n    \n    - [Basic ANN Theory](https://takinginitiative.wordpress.com/2008/04/03/basic-neural-network-tutorial-theory/)\n    \n    - [Role of Bias in Neural Networks](http://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks)\n    \n    - [Choosing number of hidden layers and nodes](http://stackoverflow.com/questions/3345079/estimating-the-number-of-neurons-and-number-of-layers-of-an-artificial-neural-ne),[2](http://stackoverflow.com/questions/10565868/multi-layer-perceptron-mlp-architecture-criteria-for-choosing-number-of-hidde?lq=1),[3](http://stackoverflow.com/questions/9436209/how-to-choose-number-of-hidden-layers-and-nodes-in-neural-network/2#)\n    \n    - [Backpropagation in Matrix Form](http://sudeepraja.github.io/Neural/)\n    \n    - [ANN implemented in C++ | AI Junkie](http://www.ai-junkie.com/ann/evolved/nnt6.html)\n    \n    - [Simple Implementation](http://stackoverflow.com/questions/15395835/simple-multi-layer-neural-network-implementation)\n    \n    - [NN for Beginners](http://www.codeproject.com/Articles/16419/AI-Neural-Network-for-beginners-Part-of)\n    \n    - [Regression and Classification with NNs (Slides)](http://www.autonlab.org/tutorials/neural13.pdf)\n    \n    - [Another Intro](http://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol4/cs11/report.html)\n\n<a name=\"rnn\" />\n\n- Recurrent and LSTM Networks\n    - [awesome-rnn: list of resources (GitHub Repo)](https://github.com/kjw0612/awesome-rnn)\n    \n    - [Recurrent Neural Net Tutorial Part 1](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/), [Part 2](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/), [Part 3](http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/), [Code](https://github.com/dennybritz/rnn-tutorial-rnnlm/)\n    \n    - [NLP RNN Representations](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)\n    \n    - [The Unreasonable effectiveness of RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), [Torch Code](https://github.com/karpathy/char-rnn), [Python Code](https://gist.github.com/karpathy/d4dee566867f8291f086)\n    \n    - [Intro to RNN](http://deeplearning4j.org/recurrentnetwork.html), [LSTM](http://deeplearning4j.org/lstm.html)\n    \n    - [An application of RNN](http://hackaday.com/2015/10/15/73-computer-scientists-created-a-neural-net-and-you-wont-believe-what-happened-next/)\n    \n    - [Optimizing RNN Performance](http://svail.github.io/)\n    \n    - [Simple RNN](http://outlace.com/Simple-Recurrent-Neural-Network/)\n    \n    - [Auto-Generating Clickbait with RNN](https://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/)\n    \n    - [Sequence Learning using RNN (Slides)](http://www.slideshare.net/indicods/general-sequence-learning-with-recurrent-neural-networks-for-next-ml)\n    \n    - [Machine Translation using RNN (Paper)](http://emnlp2014.org/papers/pdf/EMNLP2014179.pdf)\n    \n    - [Music generation using RNNs (Keras)](https://github.com/MattVitelli/GRUV)\n    \n    - [Using RNN to create on-the-fly dialogue (Keras)](http://neuralniche.com/post/tutorial/)\n    \n    - Long Short Term Memory (LSTM)\n    \n        - [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n        \n        - [LSTM explained](https://apaszke.github.io/lstm-explained.html)\n        \n        - [Beginner\u2019s Guide to LSTM](http://deeplearning4j.org/lstm.html)\n        \n        - [Implementing LSTM from scratch](http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/), [Python/Theano code](https://github.com/dennybritz/rnn-tutorial-gru-lstm)\n        \n        - [Torch Code for character-level language models using LSTM](https://github.com/karpathy/char-rnn)\n        \n        - [LSTM for Kaggle EEG Detection competition (Torch Code)](https://github.com/apaszke/kaggle-grasp-and-lift)\n        \n        - [LSTM for Sentiment Analysis in Theano](http://deeplearning.net/tutorial/lstm.html#lstm)\n        \n        - [Deep Learning for Visual Q&A | LSTM | CNN](http://avisingh599.github.io/deeplearning/visual-qa/), [Code](https://github.com/avisingh599/visual-qa)\n        \n        - [Computer Responds to email using LSTM | Google](http://googleresearch.blogspot.in/2015/11/computer-respond-to-this-email.html)\n        \n        - [LSTM dramatically improves Google Voice Search](http://googleresearch.blogspot.ch/2015/09/google-voice-search-faster-and-more.html), [Another Article](http://deeplearning.net/2015/09/30/long-short-term-memory-dramatically-improves-google-voice-etc-now-available-to-a-billion-users/)\n        \n        - [Understanding Natural Language with LSTM Using Torch](http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n        \n        - [Torch code for Visual Question Answering using a CNN+LSTM model](https://github.com/abhshkdz/neural-vqa)\n        \n        - [LSTM for Human Activity Recognition](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/)\n        \n    - Gated Recurrent Units (GRU)\n    \n        - [LSTM vs GRU](http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/)\n    \n    - [Time series forecasting with Sequence-to-Sequence (seq2seq) rnn models](https://github.com/guillaume-chevalier/seq2seq-signal-prediction)\n\n\n<a name=\"rnn2\" />\n\n- [Recursive Neural Network (not Recurrent)](https://en.wikipedia.org/wiki/Recursive_neural_network)\n\n    - [Recursive Neural Tensor Network (RNTN)](http://deeplearning4j.org/recursiveneuraltensornetwork.html)\n    \n    - [word2vec, DBN, RNTN for Sentiment Analysis ](http://deeplearning4j.org/zh-sentiment_analysis_word2vec.html)\n\n<a name=\"rbm\" />\n\n- Restricted Boltzmann Machine\n\n    - [Beginner's Guide about RBMs](http://deeplearning4j.org/restrictedboltzmannmachine.html)\n    \n    - [Another Good Tutorial](http://deeplearning.net/tutorial/rbm.html)\n    \n    - [Introduction to RBMs](http://blog.echen.me/2011/07/18/introduction-to-restricted-boltzmann-machines/)\n    \n    - [Hinton's Guide to Training RBMs](https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf)\n    \n    - [RBMs in R](https://github.com/zachmayer/rbm)\n    \n    - [Deep Belief Networks Tutorial](http://deeplearning4j.org/deepbeliefnetwork.html)\n    \n    - [word2vec, DBN, RNTN for Sentiment Analysis ](http://deeplearning4j.org/zh-sentiment_analysis_word2vec.html)\n\n<a name=\"auto\" />\n\n- Autoencoders: Unsupervised (applies BackProp after setting target = input)\n\n    - [Andrew Ng Sparse Autoencoders pdf](https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf)\n    \n    - [Deep Autoencoders Tutorial](http://deeplearning4j.org/deepautoencoder.html)\n    \n    - [Denoising Autoencoders](http://deeplearning.net/tutorial/dA.html), [Theano Code](http://deeplearning.net/tutorial/code/dA.py)\n    \n    - [Stacked Denoising Autoencoders](http://deeplearning.net/tutorial/SdA.html#sda)\n\n\n<a name=\"cnn\" />\n\n- Convolutional Neural Networks\n\n    - [An Intuitive Explanation of Convolutional Neural Networks](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)\n    \n    - [Awesome Deep Vision: List of Resources (GitHub)](https://github.com/kjw0612/awesome-deep-vision)\n    \n    - [Intro to CNNs](http://deeplearning4j.org/convolutionalnets.html)\n    \n    - [Understanding CNN for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)\n    \n    - [Stanford Notes](http://vision.stanford.edu/teaching/cs231n/), [Codes](http://cs231n.github.io/), [GitHub](https://github.com/cs231n/cs231n.github.io)\n    \n    - [JavaScript Library (Browser Based) for CNNs](http://cs.stanford.edu/people/karpathy/convnetjs/)\n    \n    - [Using CNNs to detect facial keypoints](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/)\n    \n    - [Deep learning to classify business photos at Yelp](http://engineeringblog.yelp.com/2015/10/how-we-use-deep-learning-to-classify-business-photos-at-yelp.html)\n    \n    - [Interview with Yann LeCun | Kaggle](http://blog.kaggle.com/2014/12/22/convolutional-nets-and-cifar-10-an-interview-with-yan-lecun/)\n    \n    - [Visualising and Understanding CNNs](https://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf)\n\n<a name=\"nrl\" />\n\n- Network Representation Learning\n\n    - [Awesome Graph Embedding](https://github.com/benedekrozemberczki/awesome-graph-embedding)\n    \n    - [Awesome Network Embedding](https://github.com/chihming/awesome-network-embedding)\n    \n    - [Network Representation Learning Papers](https://github.com/thunlp)\n    \n    - [Knowledge Representation Learning Papers](https://github.com/thunlp/KRLPapers)\n    \n    - [Graph Based Deep Learning Literature](https://github.com/naganandy/graph-based-deep-learning-literature)\n\n<a name=\"nlp\" />\n\n## Natural Language Processing\n\n- [A curated list of speech and natural language processing resources](https://github.com/edobashira/speech-language-processing)\n\n- [Understanding Natural Language with Deep Neural Networks Using Torch](http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n\n- [tf-idf explained](http://michaelerasm.us/post/tf-idf-in-10-minutes/)\n\n- [Interesting Deep Learning NLP Projects Stanford](http://cs224d.stanford.edu/reports.html), [Website](http://cs224d.stanford.edu/)\n\n- [The Stanford NLP Group](https://nlp.stanford.edu/)\n\n- [NLP from Scratch | Google Paper](https://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/35671.pdf)\n\n- [Graph Based Semi Supervised Learning for NLP](http://graph-ssl.wdfiles.com/local--files/blog%3A_start/graph_ssl_acl12_tutorial_slides_final.pdf)\n\n- [Bag of Words](https://en.wikipedia.org/wiki/Bag-of-words_model)\n\n    - [Classification text with Bag of Words](http://fastml.com/classifying-text-with-bag-of-words-a-tutorial/)\n    \n<a name=\"topic\" />\n\n- Topic Modeling\n    - [Topic Modeling Wikipedia](https://en.wikipedia.org/wiki/Topic_model) \n    - [**Probabilistic Topic Models Princeton PDF**](http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf)\n\n    - [LDA Wikipedia](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation), [LSA Wikipedia](https://en.wikipedia.org/wiki/Latent_semantic_analysis), [Probabilistic LSA Wikipedia](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis)\n    \n    - [What is a good explanation of Latent Dirichlet Allocation (LDA)?](https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation)\n    \n    - [**Introduction to LDA**](http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/), [Another good explanation](http://confusedlanguagetech.blogspot.in/2012/07/jordan-boyd-graber-and-philip-resnik.html)\n    \n    - [The LDA Buffet - Intuitive Explanation](http://www.matthewjockers.net/2011/09/29/the-lda-buffet-is-now-open-or-latent-dirichlet-allocation-for-english-majors/)\n    \n    - [Your Guide to Latent Dirichlet Allocation (LDA)](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)\n    \n    - [Difference between LSI and LDA](https://www.quora.com/Whats-the-difference-between-Latent-Semantic-Indexing-LSI-and-Latent-Dirichlet-Allocation-LDA)\n    \n    - [Original LDA Paper](https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf)\n    \n    - [alpha and beta in LDA](http://datascience.stackexchange.com/questions/199/what-does-the-alpha-and-beta-hyperparameters-contribute-to-in-latent-dirichlet-a)\n    \n    - [Intuitive explanation of the Dirichlet distribution](https://www.quora.com/What-is-an-intuitive-explanation-of-the-Dirichlet-distribution)\n    - [topicmodels: An R Package for Fitting Topic Models](https://cran.r-project.org/web/packages/topicmodels/vignettes/topicmodels.pdf)\n\n    - [Topic modeling made just simple enough](https://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/)\n    \n    - [Online LDA](http://alexminnaar.com/online-latent-dirichlet-allocation-the-best-option-for-topic-modeling-with-large-data-sets.html), [Online LDA with Spark](http://alexminnaar.com/distributed-online-latent-dirichlet-allocation-with-apache-spark.html)\n    \n    - [LDA in Scala](http://alexminnaar.com/latent-dirichlet-allocation-in-scala-part-i-the-theory.html), [Part 2](http://alexminnaar.com/latent-dirichlet-allocation-in-scala-part-ii-the-code.html)\n    \n    - [Segmentation of Twitter Timelines via Topic Modeling](https://alexisperrier.com/nlp/2015/09/16/segmentation_twitter_timelines_lda_vs_lsa.html)\n    \n    - [Topic Modeling of Twitter Followers](http://alexperrier.github.io/jekyll/update/2015/09/04/topic-modeling-of-twitter-followers.html)\n\n    - [Multilingual Latent Dirichlet Allocation (LDA)](https://github.com/ArtificiAI/Multilingual-Latent-Dirichlet-Allocation-LDA). ([Tutorial here](https://github.com/ArtificiAI/Multilingual-Latent-Dirichlet-Allocation-LDA/blob/master/Multilingual-LDA-Pipeline-Tutorial.ipynb))\n\n    - [Deep Belief Nets for Topic Modeling](https://github.com/larsmaaloee/deep-belief-nets-for-topic-modeling)\n    - [Gaussian LDA for Topic Models with Word Embeddings](http://www.cs.cmu.edu/~rajarshd/papers/acl2015.pdf)\n    - Python\n        - [Series of lecture notes for probabilistic topic models written in ipython notebook](https://github.com/arongdari/topic-model-lecture-note)\n        - [Implementation of various topic models in Python](https://github.com/arongdari/python-topic-model)\n           \n<a name=\"word2vec\" />\n\n- word2vec\n\n    - [Google word2vec](https://code.google.com/archive/p/word2vec)\n    \n    - [Bag of Words Model Wiki](https://en.wikipedia.org/wiki/Bag-of-words_model)\n    \n    - [word2vec Tutorial](https://rare-technologies.com/word2vec-tutorial/)\n    \n    - [A closer look at Skip Gram Modeling](http://homepages.inf.ed.ac.uk/ballison/pdf/lrec_skipgrams.pdf)\n    \n    - [Skip Gram Model Tutorial](http://alexminnaar.com/word2vec-tutorial-part-i-the-skip-gram-model.html), [CBoW Model](http://alexminnaar.com/word2vec-tutorial-part-ii-the-continuous-bag-of-words-model.html)\n    \n    - [Word Vectors Kaggle Tutorial Python](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors), [Part 2](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-3-more-fun-with-word-vectors)\n    \n    - [Making sense of word2vec](http://rare-technologies.com/making-sense-of-word2vec/)\n    \n    - [word2vec explained on deeplearning4j](http://deeplearning4j.org/word2vec.html)\n    \n    - [Quora word2vec](https://www.quora.com/How-does-word2vec-work)\n    \n    - [Other Quora Resources](https://www.quora.com/What-are-the-continuous-bag-of-words-and-skip-gram-architectures-in-laymans-terms), [2](https://www.quora.com/What-is-the-difference-between-the-Bag-of-Words-model-and-the-Continuous-Bag-of-Words-model), [3](https://www.quora.com/Is-skip-gram-negative-sampling-better-than-CBOW-NS-for-word2vec-If-so-why)\n    \n    - [word2vec, DBN, RNTN for Sentiment Analysis ](http://deeplearning4j.org/zh-sentiment_analysis_word2vec.html)\n\n- Text Clustering\n\n    - [How string clustering works](http://stackoverflow.com/questions/8196371/how-clustering-works-especially-string-clustering)\n    \n    - [Levenshtein distance for measuring the difference between two sequences](https://en.wikipedia.org/wiki/Levenshtein_distance)\n    \n    - [Text clustering with Levenshtein distances](http://stackoverflow.com/questions/21511801/text-clustering-with-levenshtein-distances)\n\n- Text Classification\n\n    - [Classification Text with Bag of Words](http://fastml.com/classifying-text-with-bag-of-words-a-tutorial/)\n\n- Named Entity Recognitation \n    \n     - [Stanford Named Entity Recognizer (NER)](https://nlp.stanford.edu/software/CRF-NER.shtml)\n\n     - [Named Entity Recognition: Applications and Use Cases- Towards Data Science](https://towardsdatascience.com/named-entity-recognition-applications-and-use-cases-acdbf57d595e)\n\t\n- [Language learning with NLP and reinforcement learning](http://blog.dennybritz.com/2015/09/11/reimagining-language-learning-with-nlp-and-reinforcement-learning/)\n\n- [Kaggle Tutorial Bag of Words and Word vectors](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words), [Part 2](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors), [Part 3](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-3-more-fun-with-word-vectors)\n\n- [What would Shakespeare say (NLP Tutorial)](https://gigadom.wordpress.com/2015/10/02/natural-language-processing-what-would-shakespeare-say/)\n\n- [A closer look at Skip Gram Modeling](http://homepages.inf.ed.ac.uk/ballison/pdf/lrec_skipgrams.pdf)\n\n<a name=\"vision\" />\n\n## Computer Vision\n- [Awesome computer vision (github)](https://github.com/jbhuang0604/awesome-computer-vision)\n\n- [Awesome deep vision (github)](https://github.com/kjw0612/awesome-deep-vision)\n\n\n<a name=\"svm\" />\n\n## Support Vector Machine\n\n- [Highest Voted Questions about SVMs on Cross Validated](http://stats.stackexchange.com/questions/tagged/svm)\n\n- [Help me Understand SVMs!](http://stats.stackexchange.com/questions/3947/help-me-understand-support-vector-machines)\n\n- [SVM in Layman's terms](https://www.quora.com/What-does-support-vector-machine-SVM-mean-in-laymans-terms)\n\n- [How does SVM Work | Comparisons](http://stats.stackexchange.com/questions/23391/how-does-a-support-vector-machine-svm-work)\n\n- [A tutorial on SVMs](http://alex.smola.org/papers/2003/SmoSch03b.pdf)\n\n- [Practical Guide to SVC](http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf), [Slides](http://www.csie.ntu.edu.tw/~cjlin/talks/freiburg.pdf)\n\n- [Introductory Overview of SVMs](http://www.statsoft.com/Textbook/Support-Vector-Machines)\n\n- Comparisons\n\n    - [SVMs > ANNs](http://stackoverflow.com/questions/6699222/support-vector-machines-better-than-artificial-neural-networks-in-which-learn?rq=1), [ANNs > SVMs](http://stackoverflow.com/questions/11632516/what-are-advantages-of-artificial-neural-networks-over-support-vector-machines), [Another Comparison](http://www.svms.org/anns.html)\n    \n    - [Trees > SVMs](http://stats.stackexchange.com/questions/57438/why-is-svm-not-so-good-as-decision-tree-on-the-same-data)\n    \n    - [Kernel Logistic Regression vs SVM](http://stats.stackexchange.com/questions/43996/kernel-logistic-regression-vs-svm)\n    \n    - [Logistic Regression vs SVM](http://stats.stackexchange.com/questions/58684/regularized-logistic-regression-and-support-vector-machine), [2](http://stats.stackexchange.com/questions/95340/svm-v-s-logistic-regression), [3](https://www.quora.com/Support-Vector-Machines/What-is-the-difference-between-Linear-SVMs-and-Logistic-Regression)\n    \n- [Optimization Algorithms in Support Vector Machines](http://pages.cs.wisc.edu/~swright/talks/sjw-complearning.pdf)\n\n- [Variable Importance from SVM](http://stats.stackexchange.com/questions/2179/variable-importance-from-svm)\n\n- Software\n\n    - [LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)\n    \n    - [Intro to SVM in R](http://cbio.ensmp.fr/~jvert/svn/tutorials/practical/svmbasic/svmbasic_notes.pdf)\n    \n- Kernels\n    - [What are Kernels in ML and SVM?](https://www.quora.com/What-are-Kernels-in-Machine-Learning-and-SVM)\n    \n    - [Intuition Behind Gaussian Kernel in SVMs?](https://www.quora.com/Support-Vector-Machines/What-is-the-intuition-behind-Gaussian-kernel-in-SVM)\n    \n- Probabilities post SVM\n\n    - [Platt's Probabilistic Outputs for SVM](http://www.csie.ntu.edu.tw/~htlin/paper/doc/plattprob.pdf)\n    \n    - [Platt Calibration Wiki](https://en.wikipedia.org/wiki/Platt_scaling)\n    \n    - [Why use Platts Scaling](http://stats.stackexchange.com/questions/5196/why-use-platts-scaling)\n    \n    - [Classifier Classification with Platt's Scaling](http://fastml.com/classifier-calibration-with-platts-scaling-and-isotonic-regression/)\n\n\n<a name=\"rl\" />\n\n## Reinforcement Learning\n\n- [Awesome Reinforcement Learning (GitHub)](https://github.com/aikorea/awesome-rl)\n\n- [RL Tutorial Part 1](http://outlace.com/Reinforcement-Learning-Part-1/), [Part 2](http://outlace.com/Reinforcement-Learning-Part-2/)\n\n<a name=\"dt\" />\n\n## Decision Trees\n\n- [Wikipedia Page - Lots of Good Info](https://en.wikipedia.org/wiki/Decision_tree_learning)\n\n- [FAQs about Decision Trees](http://stats.stackexchange.com/questions/tagged/cart)\n\n- [Brief Tour of Trees and Forests](https://statistical-research.com/index.php/2013/04/29/a-brief-tour-of-the-trees-and-forests/)\n\n- [Tree Based Models in R](http://www.statmethods.net/advstats/cart.html)\n\n- [How Decision Trees work?](http://www.aihorizon.com/essays/generalai/decision_trees.htm)\n\n- [Weak side of Decision Trees](http://stats.stackexchange.com/questions/1292/what-is-the-weak-side-of-decision-trees)\n\n- [Thorough Explanation and different algorithms](http://www.ise.bgu.ac.il/faculty/liorr/hbchap9.pdf)\n\n- [What is entropy and information gain in the context of building decision trees?](http://stackoverflow.com/questions/1859554/what-is-entropy-and-information-gain)\n\n- [Slides Related to Decision Trees](http://www.slideshare.net/pierluca.lanzi/machine-learning-and-data-mining-11-decision-trees)\n\n- [How do decision tree learning algorithms deal with missing values?](http://stats.stackexchange.com/questions/96025/how-do-decision-tree-learning-algorithms-deal-with-missing-values-under-the-hoo)\n\n- [Using Surrogates to Improve Datasets with Missing Values](https://www.salford-systems.com/videos/tutorials/tips-and-tricks/using-surrogates-to-improve-datasets-with-missing-values)\n\n- [Good Article](https://www.mindtools.com/dectree.html)\n\n- [Are decision trees almost always binary trees?](http://stats.stackexchange.com/questions/12187/are-decision-trees-almost-always-binary-trees)\n\n- [Pruning Decision Trees](https://en.wikipedia.org/wiki/Pruning_(decision_trees)), [Grafting of Decision Trees](https://en.wikipedia.org/wiki/Grafting_(decision_trees))\n\n- [What is Deviance in context of Decision Trees?](http://stats.stackexchange.com/questions/6581/what-is-deviance-specifically-in-cart-rpart)\n\n- [Discover structure behind data with decision trees](http://vooban.com/en/tips-articles-geek-stuff/discover-structure-behind-data-with-decision-trees/) - Grow and plot a decision tree to automatically figure out hidden rules in your data\n\n- Comparison of Different Algorithms\n\n    - [CART vs CTREE](http://stats.stackexchange.com/questions/12140/conditional-inference-trees-vs-traditional-decision-trees)\n    \n    - [Comparison of complexity or performance](https://stackoverflow.com/questions/9979461/different-decision-tree-algorithms-with-comparison-of-complexity-or-performance)\n    \n    - [CHAID vs CART](http://stats.stackexchange.com/questions/61230/chaid-vs-crt-or-cart) , [CART vs CHAID](http://www.bzst.com/2006/10/classification-trees-cart-vs-chaid.html)\n    \n    - [Good Article on comparison](http://www.ftpress.com/articles/article.aspx?p=2248639&seqNum=11)\n    \n- CART\n\n    - [Recursive Partitioning Wikipedia](https://en.wikipedia.org/wiki/Recursive_partitioning)\n    \n    - [CART Explained](http://documents.software.dell.com/Statistics/Textbook/Classification-and-Regression-Trees)\n    \n    - [How to measure/rank \u201cvariable importance\u201d when using CART?](http://stats.stackexchange.com/questions/6478/how-to-measure-rank-variable-importance-when-using-cart-specifically-using)\n    \n    - [Pruning a Tree in R](http://stackoverflow.com/questions/15318409/how-to-prune-a-tree-in-r)\n    \n    - [Does rpart use multivariate splits by default?](http://stats.stackexchange.com/questions/4356/does-rpart-use-multivariate-splits-by-default)\n    \n    - [FAQs about Recursive Partitioning](http://stats.stackexchange.com/questions/tagged/rpart)\n    \n- CTREE\n\n    - [party package in R](https://cran.r-project.org/web/packages/party/party.pdf)\n    \n    - [Show volumne in each node using ctree in R](http://stackoverflow.com/questions/13772715/show-volume-in-each-node-using-ctree-plot-in-r)\n    \n    - [How to extract tree structure from ctree function?](http://stackoverflow.com/questions/8675664/how-to-extract-tree-structure-from-ctree-function)\n    \n- CHAID\n\n    - [Wikipedia Artice on CHAID](https://en.wikipedia.org/wiki/CHAID)\n    \n    - [Basic Introduction to CHAID](https://smartdrill.com/Introduction-to-CHAID.html)\n    \n    - [Good Tutorial on CHAID](http://www.statsoft.com/Textbook/CHAID-Analysis)\n    \n- MARS\n\n    - [Wikipedia Article on MARS](https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines)\n    \n- Probabilistic Decision Trees\n\n    - [Bayesian Learning in Probabilistic Decision Trees](http://www.stats.org.uk/bayesian/Jordan.pdf)\n    \n    - [Probabilistic Trees Research Paper](http://people.stern.nyu.edu/adamodar/pdfiles/papers/probabilistic.pdf)\n\n<a name=\"rf\" />\n\n## Random Forest / Bagging\n\n- [Awesome Random Forest (GitHub)**](https://github.com/kjw0612/awesome-random-forest)\n\n- [How to tune RF parameters in practice?](https://www.kaggle.com/forums/f/15/kaggle-forum/t/4092/how-to-tune-rf-parameters-in-practice)\n\n- [Measures of variable importance in random forests](http://stats.stackexchange.com/questions/12605/measures-of-variable-importance-in-random-forests)\n\n- [Compare R-squared from two different Random Forest models](http://stats.stackexchange.com/questions/13869/compare-r-squared-from-two-different-random-forest-models)\n\n- [OOB Estimate Explained | RF vs LDA](https://stat.ethz.ch/education/semesters/ss2012/ams/slides/v10.2.pdf)\n\n- [Evaluating Random Forests for Survival Analysis Using Prediction Error Curve](https://www.jstatsoft.org/index.php/jss/article/view/v050i11)\n\n- [Why doesn't Random Forest handle missing values in predictors?](http://stats.stackexchange.com/questions/98953/why-doesnt-random-forest-handle-missing-values-in-predictors)\n\n- [How to build random forests in R with missing (NA) values?](http://stackoverflow.com/questions/8370455/how-to-build-random-forests-in-r-with-missing-na-values)\n\n- [FAQs about Random Forest](http://stats.stackexchange.com/questions/tagged/random-forest), [More FAQs](http://stackoverflow.com/questions/tagged/random-forest)\n\n- [Obtaining knowledge from a random forest](http://stats.stackexchange.com/questions/21152/obtaining-knowledge-from-a-random-forest)\n\n- [Some Questions for R implementation](http://stackoverflow.com/questions/20537186/getting-predictions-after-rfimpute), [2](http://stats.stackexchange.com/questions/81609/whether-preprocessing-is-needed-before-prediction-using-finalmodel-of-randomfore), [3](http://stackoverflow.com/questions/17059432/random-forest-package-in-r-shows-error-during-prediction-if-there-are-new-fact)\n\n<a name=\"gbm\" />\n\n## Boosting\n\n- [Boosting for Better Predictions](http://www.datasciencecentral.com/profiles/blogs/boosting-algorithms-for-better-predictions)\n\n- [Boosting Wikipedia Page](https://en.wikipedia.org/wiki/Boosting_(machine_learning))\n\n- [Introduction to Boosted Trees | Tianqi Chen](https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf)\n\n- Gradient Boosting Machine\n\n    - [Gradiet Boosting Wiki](https://en.wikipedia.org/wiki/Gradient_boosting)\n    \n    - [Guidelines for GBM parameters in R](http://stats.stackexchange.com/questions/25748/what-are-some-useful-guidelines-for-gbm-parameters), [Strategy to set parameters](http://stats.stackexchange.com/questions/35984/strategy-to-set-the-gbm-parameters)\n    \n    - [Meaning of Interaction Depth](http://stats.stackexchange.com/questions/16501/what-does-interaction-depth-mean-in-gbm), [2](http://stats.stackexchange.com/questions/16501/what-does-interaction-depth-mean-in-gbm)\n    \n    - [Role of n.minobsinnode parameter of GBM in R](http://stats.stackexchange.com/questions/30645/role-of-n-minobsinnode-parameter-of-gbm-in-r)\n    \n    - [GBM in R](http://www.slideshare.net/mark_landry/gbm-package-in-r)\n    \n    - [FAQs about GBM](http://stats.stackexchange.com/tags/gbm/hot)\n    \n    - [GBM vs xgboost](https://www.kaggle.com/c/higgs-boson/forums/t/9497/r-s-gbm-vs-python-s-xgboost)\n\n- xgboost\n\n    - [xgboost tuning kaggle](https://www.kaggle.com/khozzy/rossmann-store-sales/xgboost-parameter-tuning-template/log)\n    \n    - [xgboost vs gbm](https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/13012/question-to-experienced-kagglers-and-anyone-who-wants-to-take-a-shot/68296#post68296)\n    \n    - [xgboost survey](https://www.kaggle.com/c/higgs-boson/forums/t/10335/xgboost-post-competition-survey)\n    \n    - [Practical XGBoost in Python online course (free)](http://education.parrotprediction.teachable.com/courses/practical-xgboost-in-python)\n    \n- AdaBoost\n\n    - [AdaBoost Wiki](https://en.wikipedia.org/wiki/AdaBoost), [Python Code](https://gist.github.com/tristanwietsma/5486024)\n    \n    - [AdaBoost Sparse Input Support](http://hamzehal.blogspot.com/2014/06/adaboost-sparse-input-support.html)\n    \n    - [adaBag R package](https://cran.r-project.org/web/packages/adabag/adabag.pdf)\n    \n    - [Tutorial](http://math.mit.edu/~rothvoss/18.304.3PM/Presentations/1-Eric-Boosting304FinalRpdf.pdf)\n\n- CatBoost\n\n    - [CatBoost Documentation](https://catboost.ai/docs/)\n\n    - [Benchmarks](https://catboost.ai/#benchmark)\n\n    - [Tutorial](https://github.com/catboost/tutorials)\n\n    - [GitHub Project](https://github.com/catboost)\n\n    - [CatBoost vs. Light GBM vs. XGBoost](https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db)\n\n<a name=\"ensem\" />\n\n## Ensembles\n\n- [Wikipedia Article on Ensemble Learning](https://en.wikipedia.org/wiki/Ensemble_learning)\n\n- [Kaggle Ensembling Guide](http://mlwave.com/kaggle-ensembling-guide/)\n\n- [The Power of Simple Ensembles](http://www.overkillanalytics.net/more-is-always-better-the-power-of-simple-ensembles/)\n\n- [Ensemble Learning Intro](http://machine-learning.martinsewell.com/ensembles/)\n\n- [Ensemble Learning Paper](http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf)\n\n- [Ensembling models with R](http://amunategui.github.io/blending-models/), [Ensembling Regression Models in R](http://stats.stackexchange.com/questions/26790/ensembling-regression-models), [Intro to Ensembles in R](http://www.vikparuchuri.com/blog/intro-to-ensemble-learning-in-r/)\n\n- [Ensembling Models with caret](http://stats.stackexchange.com/questions/27361/stacking-ensembling-models-with-caret)\n\n- [Bagging vs Boosting vs Stacking](http://stats.stackexchange.com/questions/18891/bagging-boosting-and-stacking-in-machine-learning)\n\n- [Good Resources | Kaggle Africa Soil Property Prediction](https://www.kaggle.com/c/afsis-soil-properties/forums/t/10391/best-ensemble-references)\n\n- [Boosting vs Bagging](http://www.chioka.in/which-is-better-boosting-or-bagging/)\n\n- [Resources for learning how to implement ensemble methods](http://stats.stackexchange.com/questions/32703/resources-for-learning-how-to-implement-ensemble-methods)\n\n- [How are classifications merged in an ensemble classifier?](http://stats.stackexchange.com/questions/21502/how-are-classifications-merged-in-an-ensemble-classifier)\n\n<a name=\"stack\" />\n\n## Stacking Models\n\n- [Stacking, Blending and Stacked Generalization](http://www.chioka.in/stacking-blending-and-stacked-generalization/)\n\n- [Stacked Generalization (Stacking)](http://machine-learning.martinsewell.com/ensembles/stacking/)\n\n- [Stacked Generalization: when does it work?](http://www.ijcai.org/Proceedings/97-2/011.pdf)\n\n- [Stacked Generalization Paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1533&rep=rep1&type=pdf)\n\n<a name=\"vc\" />\n\n## Vapnik\u2013Chervonenkis Dimension\n\n- [Wikipedia article on VC Dimension](https://en.wikipedia.org/wiki/VC_dimension)\n\n- [Intuitive Explanantion of VC Dimension](https://www.quora.com/Explain-VC-dimension-and-shattering-in-lucid-Way)\n\n- [Video explaining VC Dimension](https://www.youtube.com/watch?v=puDzy2XmR5c)\n\n- [Introduction to VC Dimension](http://www.svms.org/vc-dimension/)\n\n- [FAQs about VC Dimension](http://stats.stackexchange.com/questions/tagged/vc-dimension)\n\n- [Do ensemble techniques increase VC-dimension?](http://stats.stackexchange.com/questions/78076/do-ensemble-techniques-increase-vc-dimension)\n\n\n<a name=\"bayes\" />\n\n## Bayesian Machine Learning\n\n- [Bayesian Methods for Hackers (using pyMC)](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)\n\n- [Should all Machine Learning be Bayesian?](http://videolectures.net/bark08_ghahramani_samlbb/)\n\n- [Tutorial on Bayesian Optimisation for Machine Learning](http://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf)\n\n- [Bayesian Reasoning and Deep Learning](http://blog.shakirm.com/2015/10/bayesian-reasoning-and-deep-learning/), [Slides](http://blog.shakirm.com/wp-content/uploads/2015/10/Bayes_Deep.pdf)\n\n- [Bayesian Statistics Made Simple](http://greenteapress.com/wp/think-bayes/)\n\n- [Kalman & Bayesian Filters in Python](https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python)\n\n- [Markov Chain Wikipedia Page](https://en.wikipedia.org/wiki/Markov_chain)\n\n\n<a name=\"semi\" />\n\n## Semi Supervised Learning\n\n- [Wikipedia article on Semi Supervised Learning](https://en.wikipedia.org/wiki/Semi-supervised_learning)\n\n- [Tutorial on Semi Supervised Learning](http://pages.cs.wisc.edu/~jerryzhu/pub/sslicml07.pdf)\n\n- [Graph Based Semi Supervised Learning for NLP](http://graph-ssl.wdfiles.com/local--files/blog%3A_start/graph_ssl_acl12_tutorial_slides_final.pdf)\n\n- [Taxonomy](http://is.tuebingen.mpg.de/fileadmin/user_upload/files/publications/taxo_[0].pdf)\n\n- [Video Tutorial Weka](https://www.youtube.com/watch?v=sWxcIjZFGNM)\n\n- [Unsupervised, Supervised and Semi Supervised learning](http://stats.stackexchange.com/questions/517/unsupervised-supervised-and-semi-supervised-learning)\n\n- [Research Papers 1](http://mlg.eng.cam.ac.uk/zoubin/papers/zglactive.pdf), [2](http://mlg.eng.cam.ac.uk/zoubin/papers/zgl.pdf), [3](http://icml.cc/2012/papers/616.pdf)\n\n\n<a name=\"opt\" />\n\n## Optimization\n\n- [Mean Variance Portfolio Optimization with R and Quadratic Programming](http://www.wdiam.com/2012/06/10/mean-variance-portfolio-optimization-with-r-and-quadratic-programming/?utm_content=buffer04c12&utm_medium=social&utm_source=linkedin.com&utm_campaign=buffer)\n\n- [Algorithms for Sparse Optimization and Machine Learning](http://www.ima.umn.edu/2011-2012/W3.26-30.12/activities/Wright-Steve/sjw-ima12)\n\n- [Optimization Algorithms in Machine Learning](http://pages.cs.wisc.edu/~swright/nips2010/sjw-nips10.pdf), [Video Lecture](http://videolectures.net/nips2010_wright_oaml/)\n\n- [Optimization Algorithms for Data Analysis](http://www.birs.ca/workshops/2011/11w2035/files/Wright.pdf)\n\n- [Video Lectures on Optimization](http://videolectures.net/stephen_j_wright/)\n\n- [Optimization Algorithms in Support Vector Machines](http://pages.cs.wisc.edu/~swright/talks/sjw-complearning.pdf)\n\n- [The Interplay of Optimization and Machine Learning Research](http://jmlr.org/papers/volume7/MLOPT-intro06a/MLOPT-intro06a.pdf)\n\n- [Hyperopt tutorial for Optimizing Neural Networks\u2019 Hyperparameters](http://vooban.com/en/tips-articles-geek-stuff/hyperopt-tutorial-for-optimizing-neural-networks-hyperparameters/)\n\n\n<a name=\"other\" />\n\n## Other Tutorials\n\n- For a collection of Data Science Tutorials using R, please refer to [this list](https://github.com/ujjwalkarn/DataScienceR).\n\n- For a collection of Data Science Tutorials using Python, please refer to [this list](https://github.com/ujjwalkarn/DataSciencePython).\n",
	"datasets deep-learning deep-neural-networks front-end-development graphical-user-interface": "# pix2code\n*Generating Code from a Graphical User Interface Screenshot*\n\n[![License](http://img.shields.io/badge/license-APACHE2-blue.svg)](LICENSE.txt)\n\n* A video demo of the system can be seen [here](https://youtu.be/pqKeXkhFA3I)\n* The paper is available at [https://arxiv.org/abs/1705.07962](https://arxiv.org/abs/1705.07962)\n* Official research page: [https://uizard.io/research#pix2code](https://uizard.io/research#pix2code)\n\n## Abstract\nTransforming a graphical user interface screenshot created by a designer into computer code is a typical task conducted by a developer in order to build customized software, websites, and mobile applications. In this paper, we show that deep learning methods can be leveraged to train a model end-to-end to automatically generate code from a single input image with over 77% of accuracy for three different platforms (i.e. iOS, Android and web-based technologies).\n\n## Citation\n\n```\n@article{beltramelli2017pix2code,\n  title={pix2code: Generating Code from a Graphical User Interface Screenshot},\n  author={Beltramelli, Tony},\n  journal={arXiv preprint arXiv:1705.07962},\n  year={2017}\n}\n```\n\n## Disclaimer\n\nThe following software is shared for educational purposes only. The author and its affiliated institution are not responsible in any manner whatsoever for any damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of the use or inability to use this software.\n\nThe project pix2code is a research project demonstrating an application of deep neural networks to generate code from visual inputs.\nThe current implementation is not, in any way, intended, nor able to generate code in a real-world context.\nWe could not emphasize enough that this project is experimental and shared for educational purposes only.\nBoth the source code and the datasets are provided to foster future research in machine intelligence and are not designed for end users.\n\n## Setup\n### Prerequisites\n\n- Python 2 or 3\n- pip\n\n### Install dependencies\n\n```sh\npip install -r  requirements.txt\n```\n\n## Usage\n\nPrepare the data:\n```sh\n# reassemble and unzip the data\ncd datasets\nzip -F pix2code_datasets.zip --out datasets.zip\nunzip datasets.zip\n\ncd ../model\n\n# split training set and evaluation set while ensuring no training example in the evaluation set\n# usage: build_datasets.py <input path> <distribution (default: 6)>\n./build_datasets.py ../datasets/ios/all_data\n./build_datasets.py ../datasets/android/all_data\n./build_datasets.py ../datasets/web/all_data\n\n# transform images (normalized pixel values and resized pictures) in training dataset to numpy arrays (smaller files if you need to upload the set to train your model in the cloud)\n# usage: convert_imgs_to_arrays.py <input path> <output path>\n./convert_imgs_to_arrays.py ../datasets/ios/training_set ../datasets/ios/training_features\n./convert_imgs_to_arrays.py ../datasets/android/training_set ../datasets/android/training_features\n./convert_imgs_to_arrays.py ../datasets/web/training_set ../datasets/web/training_features\n```\n\nTrain the model:\n```sh\nmkdir bin\ncd model\n\n# provide input path to training data and output path to save trained model and metadata\n# usage: train.py <input path> <output path> <is memory intensive (default: 0)> <pretrained weights (optional)>\n./train.py ../datasets/web/training_set ../bin\n\n# train on images pre-processed as arrays\n./train.py ../datasets/web/training_features ../bin\n\n# train with generator to avoid having to fit all the data in memory (RECOMMENDED)\n./train.py ../datasets/web/training_features ../bin 1\n\n# train on top of pretrained weights\n./train.py ../datasets/web/training_features ../bin 1 ../bin/pix2code.h5\n```\n\nGenerate code for batch of GUIs:\n```sh\nmkdir code\ncd model\n\n# generate DSL code (.gui file), the default search method is greedy\n# usage: generate.py <trained weights path> <trained model name> <input image> <output path> <search method (default: greedy)>\n./generate.py ../bin pix2code ../gui_screenshots ../code\n\n# equivalent to command above\n./generate.py ../bin pix2code ../gui_screenshots ../code greedy\n\n# generate DSL code with beam search and a beam width of size 3\n./generate.py ../bin pix2code ../gui_screenshots ../code 3\n```\n\nGenerate code for a single GUI image:\n```sh\nmkdir code\ncd model\n\n# generate DSL code (.gui file), the default search method is greedy\n# usage: sample.py <trained weights path> <trained model name> <input image> <output path> <search method (default: greedy)>\n./sample.py ../bin pix2code ../test_gui.png ../code\n\n# equivalent to command above\n./sample.py ../bin pix2code ../test_gui.png ../code greedy\n\n# generate DSL code with beam search and a beam width of size 3\n./sample.py ../bin pix2code ../test_gui.png ../code 3\n```\n\nCompile generated code to target language:\n```sh\ncd compiler\n\n# compile .gui file to Android XML UI\n./android-compiler.py <input file path>.gui\n\n# compile .gui file to iOS Storyboard\n./ios-compiler.py <input file path>.gui\n\n# compile .gui file to HTML/CSS (Bootstrap style)\n./web-compiler.py <input file path>.gui\n```\n\n## FAQ\n\n### Will pix2code supports other target platforms/languages?\nNo, pix2code is only a research project and will stay in the state described in the paper for consistency reasons.\nThis project is really just a toy example but you are of course more than welcome to fork the repo and experiment yourself with other target platforms/languages.\n\n### Will I be able to use pix2code for my own frontend projects?\nNo, pix2code is experimental and won't work for your specific use cases.\n\n### How is the model performance measured?\nThe accuracy/error reported in the paper is measured at the DSL level by comparing each generated token with each expected token.\nAny difference in length between the generated token sequence and the expected token sequence is also counted as error.\n\n### How long does it take to train the model?\nOn a Nvidia Tesla K80 GPU, it takes a little less than 5 hours to optimize the 109 * 10^6 parameters for one dataset; so expect around 15 hours if you want to train the model for the three target platforms.\n\n### I am a front-end developer, will I soon lose my job?\n*(I have genuinely been asked this question multiple times)*\n\n**TL;DR** Not anytime soon will AI replace front-end developers.\n\nEven assuming a mature version of pix2code able to generate GUI code with 100% accuracy for every platforms/languages in the universe, front-enders will still be needed to implement the logic, the interactive parts, the advanced graphics and animations, and all the features users love. The product we are building at [Uizard Technologies](https://uizard.io) is intended to bridge the gap between UI/UX designers and front-end developers, not replace any of them. We want to rethink the traditional workflow that too often results in more frustration than innovation. We want designers to be as creative as possible to better serve end users, and developers to dedicate their time programming the core functionality and forget about repetitive tasks such as UI implementation. We believe in a future where AI collaborate with humans, not replace humans.\n\n## Media coverage\n\n* [Wired UK](http://www.wired.co.uk/article/pix2code-ulzard-technologies)\n* [The Next Web](https://thenextweb.com/apps/2017/05/26/ai-raw-design-turn-source-code)\n* [Fast Company](https://www.fastcodesign.com/90127911/this-startup-uses-machine-learning-to-turn-ui-designs-into-raw-code)\n* [NVIDIA Developer News](https://news.developer.nvidia.com/ai-turns-ui-designs-into-code)\n* [Lifehacker Australia](https://www.lifehacker.com.au/2017/05/generating-user-interface-code-from-images-using-machine-learning/)\n* [Two Minute Papers](https://www.youtube.com/watch?v=Fevg4aowNyc) (web series)\n* [NLP Highlights](https://soundcloud.com/nlp-highlights/17a) (podcast)\n* [Data Skeptic](https://dataskeptic.com/blog/episodes/2017/pix2code) (podcast)\n* Read comments on [Hacker News](https://news.ycombinator.com/item?id=14416530)\n",
	"deep-learning deep-neural-networks deeplearning object-detection objectdetection": "# deep learning object detection\nA paper list of object detection using deep learning. I wrote this page with reference to [this survey paper](https://arxiv.org/pdf/1809.02165v1.pdf) and searching and searching.. \n\n*Last updated: 2020/09/22*\n\n#### Update log\n*2018/9/18* - update all of recent papers and make some diagram about history of object detection using deep learning. \n*2018/9/26* - update codes of papers. (official and unofficial)  \n*2018/october* - update 5 papers and performance table.  \n*2018/november* - update 9 papers.  \n*2018/december* - update 8 papers and and performance table and add new diagram(**2019 version!!**).  \n*2019/january* - update 4 papers and and add commonly used datasets.  \n*2019/february* - update 3 papers.  \n*2019/march* - update figure and code links.  \n*2019/april* - remove author's names and update ICLR 2019 & CVPR 2019 papers.  \n*2019/may* - update CVPR 2019 papers.  \n*2019/june* - update CVPR 2019 papers and dataset paper.  \n*2019/july* - update BMVC 2019 papers and some of ICCV 2019 papers.  \n*2019/september* - update NeurIPS 2019 papers and ICCV 2019 papers.  \n*2019/november* - update some of AAAI 2020 papers and other papers.  \n*2020/january* - update ICLR 2020 papers and other papers.  \n*2020/may* - update CVPR 2020 papers and other papers.  \n*2020/june* - update arxiv papers.  \n*2020/august* - update paper links.  \n\n\n##\n\n## Table of Contents\n- [Paper list from 2014 to now(2019)](https://github.com/hoya012/deep_learning_object_detection/blob/master/README.md#paper-list-from-2014-to-now2019)\n- [Performance table](https://github.com/hoya012/deep_learning_object_detection/blob/master/README.md#performance-table)\n- Papers\n  - [2014](https://github.com/hoya012/deep_learning_object_detection/blob/master/README.md#2014)\n  - [2015](https://github.com/hoya012/deep_learning_object_detection/blob/master/README.md#2015)\n  - [2016](https://github.com/hoya012/deep_learning_object_detection/blob/master/README.md#2016)\n  - [2017](https://github.com/hoya012/deep_learning_object_detection/blob/master/README.md#2017)\n  - [2018](https://github.com/hoya012/deep_learning_object_detection/blob/master/README.md#2018)\n  - [2019](https://github.com/hoya012/deep_learning_object_detection/blob/master/README.md#2019)\n  - [2020](https://github.com/hoya012/deep_learning_object_detection/blob/master/README.md#2020)\n- [Dataset Papers](https://github.com/hoya012/deep_learning_object_detection/blob/master/README.md#dataset-papers)\n\n##\n\n## Paper list from 2014 to now(2019)\nThe part highlighted with red characters means papers that i think \"must-read\".\nHowever, it is **my personal opinion** and other papers are important too, so I recommend to read them if you have time.\n\n<p align=\"center\">\n  <img width=\"1000\" src=\"/assets/deep_learning_object_detection_history.PNG\" \"Example of object detection.\">\n</p>\n\n##\n\n## Performance table\n\nFPS(Speed) index is related to the hardware spec(e.g. CPU, GPU, RAM, etc), so it is hard to make an equal comparison. The solution is to measure the performance of all models on hardware with equivalent specifications, but it is very difficult and time consuming. \n\n|   Detector   | VOC07 (mAP@IoU=0.5) | VOC12 (mAP@IoU=0.5) | COCO (mAP@IoU=0.5:0.95) | Published In |\n|:------------:|:-------------------:|:-------------------:|:----------:|:------------:| \n|     R-CNN    |         58.5        |          -          |      -     |    CVPR'14   |\n|    SPP-Net   |         59.2        |          -          |      -     |    ECCV'14   |\n|    MR-CNN    |     78.2 (07+12)    |     73.9 (07+12)    |      -     |    ICCV'15   |\n|  Fast R-CNN  |     70.0 (07+12)    |     68.4 (07++12)   |    19.7    |    ICCV'15   |\n| Faster R-CNN |     73.2 (07+12)    |     70.4 (07++12)   |    21.9    |    NIPS'15   |\n|    YOLO v1   |     66.4 (07+12)    |     57.9 (07++12)   |      -     |    CVPR'16   |\n|     G-CNN    |         66.8        |     66.4 (07+12)    |      -     |    CVPR'16   |\n|     AZNet    |         70.4        |          -          |    22.3    |    CVPR'16   |\n|      ION     |         80.1        |         77.9        |    33.1    |    CVPR'16   |\n|   HyperNet   |     76.3 (07+12)    |    71.4 (07++12)    |      -     |    CVPR'16   |\n|     OHEM     |     78.9 (07+12)    |    76.3 (07++12)    |    22.4    |    CVPR'16   |\n|      MPN     |           -         |          -          |    33.2    |    BMVC'16   |\n|      SSD     |     76.8 (07+12)    |    74.9 (07++12)    |    31.2    |    ECCV'16   |\n|    GBDNet    |     77.2 (07+12)    |          -          |    27.0    |    ECCV'16   |\n|      CPF     |     76.4 (07+12)    |    72.6 (07++12)    |      -     |    ECCV'16   |\n|     R-FCN    |     79.5 (07+12)    |    77.6 (07++12)    |    29.9    |    NIPS'16   |\n|  DeepID-Net  |         69.0        |          -          |      -     |    PAMI'16   |\n|      NoC     |     71.6 (07+12)    |    68.8 (07+12)     |    27.2    |   TPAMI'16   |\n|     DSSD     |     81.5 (07+12)    |    80.0 (07++12)    |    33.2    |   arXiv'17   |\n|      TDM     |          -          |          -          |    37.3    |    CVPR'17   |\n|      FPN     |          -          |          -          |    36.2    |    CVPR'17   |\n|    YOLO v2   |     78.6 (07+12)    |    73.4 (07++12)    |      -     |    CVPR'17   |\n|      RON     |     77.6 (07+12)    |    75.4 (07++12)    |    27.4    |    CVPR'17   |\n|     DeNet    |     77.1 (07+12)    |    73.9 (07++12)    |    33.8    |    ICCV'17   |\n|   CoupleNet  |     82.7 (07+12)    |    80.4 (07++12)    |    34.4    |    ICCV'17   |\n|   RetinaNet  |          -          |          -          |    39.1    |    ICCV'17   |\n|     DSOD     |     77.7 (07+12)    |    76.3 (07++12)    |      -     |    ICCV'17   |\n|      SMN     |         70.0        |          -          |      -     |    ICCV'17   |\n|Light-Head R-CNN|        -          |          -          |    41.5    |   arXiv'17   |\n|    YOLO v3   |          -          |          -          |    33.0    |   arXiv'18   |\n|      SIN     |     76.0 (07+12)    |    73.1 (07++12)    |    23.2    |    CVPR'18   |\n|     STDN     |     80.9 (07+12)    |          -          |      -     |    CVPR'18   |\n|   RefineDet  |     83.8 (07+12)    |    83.5 (07++12)    |    41.8    |    CVPR'18   |\n|     SNIP     |          -          |          -          |    45.7    |    CVPR'18   |\n|Relation-Network|        -          |          -          |     32.5   |    CVPR'18   |\n| Cascade R-CNN|          -          |          -          |     42.8   |    CVPR'18   |\n|     MLKP     |     80.6 (07+12)    |    77.2 (07++12)    |     28.6   |    CVPR'18   |\n|  Fitness-NMS |          -          |          -          |     41.8   |    CVPR'18   |\n|    RFBNet    |     82.2 (07+12)    |          -          |      -     |    ECCV'18   |\n|   CornerNet  |          -          |          -          |     42.1   |    ECCV'18   |\n|    PFPNet    |     84.1 (07+12)    |    83.7 (07++12)    |     39.4   |    ECCV'18   |\n|    Pelee     |     70.9 (07+12)    |          -          |      -     |    NIPS'18   |\n|     HKRM     |     78.8 (07+12)    |          -          |     37.8   |    NIPS'18   |\n|     M2Det    |          -          |          -          |     44.2   |    AAAI'19   |\n|     R-DAD    |     81.2 (07++12)   |    82.0 (07++12)    |     43.1   |    AAAI'19   |\n| ScratchDet   |   84.1 (07++12)     |    83.6 (07++12)    |     39.1   |    CVPR'19   |\n| Libra R-CNN  |          -          |          -          |     43.0   |    CVPR'19   |\n| Reasoning-RCNN  | 82.5 (07++12)    |          -          |     43.2   |    CVPR'19   |\n|      FSAF    |          -          |          -          |     44.6   |    CVPR'19   |\n| AmoebaNet + NAS-FPN |     -        |          -          |     47.0   |    CVPR'19   |\n| Cascade-RetinaNet |       -        |           -         |     41.1   |    CVPR'19   |\n|      HTC     |          -          |          -          |     47.2   |    CVPR'19   |\n|   TridentNet |          -          |          -          |     48.4   |    ICCV'19   |\n|      DAFS    |   **85.3 (07+12)**  |    83.1 (07++12)    |     40.5   |    ICCV'19   |\n|   Auto-FPN   |     81.8 (07++12)   |          -          |     40.5   |    ICCV'19   |\n|     FCOS     |          -          |          -          |     44.7   |    ICCV'19   |\n|   FreeAnchor |          -          |          -          |     44.8   |  NeurIPS'19  |\n|    DetNAS    |     81.5 (07++12)   |          -          |     42.0   |  NeurIPS'19  |\n|     NATS     |          -          |          -          |     42.0   |  NeurIPS'19  |\n| AmoebaNet + NAS-FPN + AA |   -     |          -          |     50.7   |    arXiv'19  |\n|   SpineNet   |          -          |          -          |     52.1   |    arXiv'19  |\n|     CBNet    |          -          |          -          |     53.3   |    AAAI'20   |\n| EfficientDet |          -          |          -          |     52.6   |    CVPR'20   |\n|  DetectoRS   |          -          |          -          |     **54.7**   |    arXiv'20   |\n\n##\n\n## 2014\n\n- **[R-CNN]** Rich feature hierarchies for accurate object detection and semantic segmentation | **[CVPR' 14]** |[`[pdf]`](https://arxiv.org/pdf/1311.2524.pdf) [`[official code - caffe]`](https://github.com/rbgirshick/rcnn) \n\n- **[OverFeat]** OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks | **[ICLR' 14]** |[`[pdf]`](https://arxiv.org/pdf/1312.6229.pdf) [`[official code - torch]`](https://github.com/sermanet/OverFeat) \n\n- **[MultiBox]** Scalable Object Detection using Deep Neural Networks | **[CVPR' 14]** |[`[pdf]`](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Erhan_Scalable_Object_Detection_2014_CVPR_paper.pdf)\n\n- **[SPP-Net]** Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition | **[ECCV' 14]** |[`[pdf]`](https://arxiv.org/pdf/1406.4729.pdf) [`[official code - caffe]`](https://github.com/ShaoqingRen/SPP_net) [`[unofficial code - keras]`](https://github.com/yhenon/keras-spp) [`[unofficial code - tensorflow]`](https://github.com/peace195/sppnet)\n\n## 2015\n- Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction | **[CVPR' 15]** |[`[pdf]`](https://arxiv.org/pdf/1504.03293.pdf) [`[official code - matlab]`](https://github.com/YutingZhang/fgs-obj)\n\n- **[MR-CNN]** Object detection via a multi-region & semantic segmentation-aware CNN model | **[ICCV' 15]** |[`[pdf]`](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Gidaris_Object_Detection_via_ICCV_2015_paper.pdf) [`[official code - caffe]`](https://github.com/gidariss/mrcnn-object-detection)\n\n- **[DeepBox]** DeepBox: Learning Objectness with Convolutional Networks | **[ICCV' 15]** |[`[pdf]`](https://arxiv.org/pdf/1505.02146.pdf) [`[official code - caffe]`](https://github.com/weichengkuo/DeepBox)\n\n- **[AttentionNet]** AttentionNet: Aggregating Weak Directions for Accurate Object Detection | **[ICCV' 15]** |[`[pdf]`](https://arxiv.org/pdf/1506.07704.pdf) \n\n- **[Fast R-CNN]** Fast R-CNN | **[ICCV' 15]** |[`[pdf]`](https://arxiv.org/pdf/1504.08083.pdf) [`[official code - caffe]`](https://github.com/rbgirshick/fast-rcnn) \n\n- **[DeepProposal]** DeepProposal: Hunting Objects by Cascading Deep Convolutional Layers | **[ICCV' 15]** |[`[pdf]`](https://arxiv.org/pdf/1510.04445.pdf)  [`[official code - matconvnet]`](https://github.com/aghodrati/deepproposal)\n\n- **[Faster R-CNN, RPN]** Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks | **[NIPS' 15]** |[`[pdf]`](https://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf)  [`[official code - caffe]`](https://github.com/rbgirshick/py-faster-rcnn) [`[unofficial code - tensorflow]`](https://github.com/endernewton/tf-faster-rcnn)  [`[unofficial code - pytorch]`](https://github.com/jwyang/faster-rcnn.pytorch) \n\n## 2016\n\n- **[YOLO v1]** You Only Look Once: Unified, Real-Time Object Detection | **[CVPR' 16]** |[`[pdf]`](https://arxiv.org/pdf/1506.02640.pdf) [`[official code - c]`](https://pjreddie.com/darknet/yolo/) \n\n- **[G-CNN]** G-CNN: an Iterative Grid Based Object Detector | **[CVPR' 16]** |[`[pdf]`](https://arxiv.org/pdf/1512.07729.pdf)\n\n- **[AZNet]** Adaptive Object Detection Using Adjacency and Zoom Prediction | **[CVPR' 16]** |[`[pdf]`](https://arxiv.org/pdf/1512.07711.pdf)\n\n- **[ION]** Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks | **[CVPR' 16]** |[`[pdf]`](https://arxiv.org/pdf/1512.04143.pdf)\n\n- **[HyperNet]** HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection | **[CVPR' 16]** |[`[pdf]`](https://arxiv.org/pdf/1604.00600.pdf)\n\n- **[OHEM]** Training Region-based Object Detectors with Online Hard Example Mining | **[CVPR' 16]** |[`[pdf]`](https://arxiv.org/pdf/1604.03540.pdf) [`[official code - caffe]`](https://github.com/abhi2610/ohem) \n\n- **[CRAPF]** CRAFT Objects from Images | **[CVPR' 16]** |[`[pdf]`](https://arxiv.org/pdf/1604.03239.pdf) [`[official code - caffe]`](https://github.com/byangderek/CRAFT) \n\n- **[MPN]** A MultiPath Network for Object Detection | **[BMVC' 16]** |[`[pdf]`](https://arxiv.org/pdf/1604.02135.pdf) [`[official code - torch]`](https://github.com/facebookresearch/multipathnet) \n\n- **[SSD]** SSD: Single Shot MultiBox Detector | **[ECCV' 16]** |[`[pdf]`](https://arxiv.org/pdf/1512.02325.pdf) [`[official code - caffe]`](https://github.com/weiliu89/caffe/tree/ssd) [`[unofficial code - tensorflow]`](https://github.com/balancap/SSD-Tensorflow) [`[unofficial code - pytorch]`](https://github.com/amdegroot/ssd.pytorch) \n\n- **[GBDNet]** Crafting GBD-Net for Object Detection | **[ECCV' 16]** |[`[pdf]`](https://arxiv.org/pdf/1610.02579.pdf) [`[official code - caffe]`](https://github.com/craftGBD/craftGBD)\n\n- **[CPF]** Contextual Priming and Feedback for Faster R-CNN | **[ECCV' 16]** |[`[pdf]`](https://pdfs.semanticscholar.org/40e7/4473cb82231559cbaeaa44989e9bbfe7ec3f.pdf)\n\n- **[MS-CNN]** A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection | **[ECCV' 16]** |[`[pdf]`](https://arxiv.org/pdf/1607.07155.pdf) [`[official code - caffe]`](https://github.com/zhaoweicai/mscnn)\n\n- **[R-FCN]** R-FCN: Object Detection via Region-based Fully Convolutional Networks | **[NIPS' 16]** |[`[pdf]`](https://arxiv.org/pdf/1605.06409.pdf) [`[official code - caffe]`](https://github.com/daijifeng001/R-FCN) [`[unofficial code - caffe]`](https://github.com/YuwenXiong/py-R-FCN)\n\n- **[PVANET]** PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection | **[NIPSW' 16]** |[`[pdf]`](https://arxiv.org/pdf/1608.08021.pdf) [`[official code - caffe]`](https://github.com/sanghoon/pva-faster-rcnn)\n\n- **[DeepID-Net]** DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection | **[PAMI' 16]** |[`[pdf]`](https://arxiv.org/pdf/1412.5661.pdf)\n\n- **[NoC]** Object Detection Networks on Convolutional Feature Maps | **[TPAMI' 16]** |[`[pdf]`](https://arxiv.org/pdf/1504.06066.pdf)\n\n## 2017\n\n- **[DSSD]** DSSD : Deconvolutional Single Shot Detector | **[arXiv' 17]** |[`[pdf]`](https://arxiv.org/pdf/1701.06659.pdf) [`[official code - caffe]`](https://github.com/chengyangfu/caffe/tree/dssd)\n\n- **[TDM]** Beyond Skip Connections: Top-Down Modulation for Object Detection | **[CVPR' 17]** |[`[pdf]`](https://arxiv.org/pdf/1612.06851.pdf)\n\n- **[FPN]** Feature Pyramid Networks for Object Detection  | **[CVPR' 17]** |[`[pdf]`](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lin_Feature_Pyramid_Networks_CVPR_2017_paper.pdf) [`[unofficial code - caffe]`](https://github.com/unsky/FPN)\n\n- **[YOLO v2]** YOLO9000: Better, Faster, Stronger | **[CVPR' 17]** |[`[pdf]`](https://arxiv.org/pdf/1612.08242.pdf) [`[official code - c]`](https://pjreddie.com/darknet/yolo/) [`[unofficial code - caffe]`](https://github.com/quhezheng/caffe_yolo_v2) [`[unofficial code - tensorflow]`](https://github.com/nilboy/tensorflow-yolo) [`[unofficial code - tensorflow]`](https://github.com/sualab/object-detection-yolov2) [`[unofficial code - pytorch]`](https://github.com/longcw/yolo2-pytorch) \n\n- **[RON]** RON: Reverse Connection with Objectness Prior Networks for Object Detection | **[CVPR' 17]** |[`[pdf]`](https://arxiv.org/pdf/1707.01691.pdf) [`[official code - caffe]`](https://github.com/taokong/RON) [`[unofficial code - tensorflow]`](https://github.com/HiKapok/RON_Tensorflow)\n\n- **[RSA]** Recurrent Scale Approximation for Object Detection in CNN |  | **[ICCV' 17]** |[`[pdf]`](https://arxiv.org/pdf/1707.09531.pdf) [`[official code - caffe]`](https://github.com/sciencefans/RSA-for-object-detection)\n\n- **[DCN]** Deformable Convolutional Networks  | **[ICCV' 17]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2017/papers/Dai_Deformable_Convolutional_Networks_ICCV_2017_paper.pdf) [`[official code - mxnet]`](https://github.com/msracver/Deformable-ConvNets) [`[unofficial code - tensorflow]`](https://github.com/Zardinality/TF_Deformable_Net) [`[unofficial code - pytorch]`](https://github.com/oeway/pytorch-deform-conv)\n\n- **[DeNet]** DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling | **[ICCV' 17]** |[`[pdf]`](https://arxiv.org/pdf/1703.10295.pdf) [`[official code - theano]`](https://github.com/lachlants/denet)\n\n- **[CoupleNet]** CoupleNet: Coupling Global Structure with Local Parts for Object Detection | **[ICCV' 17]** |[`[pdf]`](https://arxiv.org/pdf/1708.02863.pdf) [`[official code - caffe]`](https://github.com/tshizys/CoupleNet)\n\n- **[RetinaNet]** Focal Loss for Dense Object Detection | **[ICCV' 17]** |[`[pdf]`](https://arxiv.org/pdf/1708.02002.pdf) [`[official code - keras]`](https://github.com/fizyr/keras-retinanet) [`[unofficial code - pytorch]`](https://github.com/kuangliu/pytorch-retinanet) [`[unofficial code - mxnet]`](https://github.com/unsky/RetinaNet) [`[unofficial code - tensorflow]`](https://github.com/tensorflow/tpu/tree/master/models/official/retinanet)\n\n- **[Mask R-CNN]** Mask R-CNN | **[ICCV' 17]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2017/papers/He_Mask_R-CNN_ICCV_2017_paper.pdf) [`[official code - caffe2]`](https://github.com/facebookresearch/Detectron) [`[unofficial code - tensorflow]`](https://github.com/matterport/Mask_RCNN) [`[unofficial code - tensorflow]`](https://github.com/CharlesShang/FastMaskRCNN) [`[unofficial code - pytorch]`](https://github.com/multimodallearning/pytorch-mask-rcnn)\n\n- **[DSOD]** DSOD: Learning Deeply Supervised Object Detectors from Scratch | **[ICCV' 17]** |[`[pdf]`](https://arxiv.org/pdf/1708.01241.pdf) [`[official code - caffe]`](https://github.com/szq0214/DSOD) [`[unofficial code - pytorch]`](https://github.com/uoip/SSD-variants) \n\n- **[SMN]** Spatial Memory for Context Reasoning in Object Detection | **[ICCV' 17]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2017/papers/Chen_Spatial_Memory_for_ICCV_2017_paper.pdf)\n\n- **[Light-Head R-CNN]** Light-Head R-CNN: In Defense of Two-Stage Object Detector | **[arXiv' 17]** |[`[pdf]`](https://arxiv.org/pdf/1711.07264.pdf) [`[official code - tensorflow]`](https://github.com/zengarden/light_head_rcnn)\n\n- **[Soft-NMS]** Improving Object Detection With One Line of Code | **[ICCV' 17]** |[`[pdf]`](https://arxiv.org/pdf/1704.04503.pdf) [`[official code - caffe]`](https://github.com/bharatsingh430/soft-nms)\n\n## 2018\n\n- **[YOLO v3]** YOLOv3: An Incremental Improvement | **[arXiv' 18]** |[`[pdf]`](https://pjreddie.com/media/files/papers/YOLOv3.pdf) [`[official code - c]`](https://pjreddie.com/darknet/yolo/) [`[unofficial code - pytorch]`](https://github.com/ayooshkathuria/pytorch-yolo-v3) [`[unofficial code - pytorch]`](https://github.com/eriklindernoren/PyTorch-YOLOv3) [`[unofficial code - keras]`](https://github.com/qqwweee/keras-yolo3) [`[unofficial code - tensorflow]`](https://github.com/mystic123/tensorflow-yolo-v3)\n\n- **[ZIP]** Zoom Out-and-In Network with Recursive Training for Object Proposal | **[IJCV' 18]** |[`[pdf]`](https://arxiv.org/pdf/1702.05711.pdf) [`[official code - caffe]`](https://github.com/hli2020/zoom_network)\n\n- **[SIN]** Structure Inference Net: Object Detection Using Scene-Level Context and Instance-Level Relationships | **[CVPR' 18]** |[`[pdf]`](http://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_Structure_Inference_Net_CVPR_2018_paper.pdf) [`[official code - tensorflow]`](https://github.com/choasup/SIN)\n\n- **[STDN]** Scale-Transferrable Object Detection | **[CVPR' 18]** |[`[pdf]`](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_Scale-Transferrable_Object_Detection_CVPR_2018_paper.pdf)\n\n- **[RefineDet]** Single-Shot Refinement Neural Network for Object Detection | **[CVPR' 18]** |[`[pdf]`](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Single-Shot_Refinement_Neural_CVPR_2018_paper.pdf) [`[official code - caffe]`](https://github.com/sfzhang15/RefineDet) [`[unofficial code - chainer]`](https://github.com/fukatani/RefineDet_chainer)  [`[unofficial code - pytorch]`](https://github.com/lzx1413/PytorchSSD)\n\n- **[MegDet]** MegDet: A Large Mini-Batch Object Detector | **[CVPR' 18]** |[`[pdf]`](http://openaccess.thecvf.com/content_cvpr_2018/papers/Peng_MegDet_A_Large_CVPR_2018_paper.pdf)\n\n- **[DA Faster R-CNN]** Domain Adaptive Faster R-CNN for Object Detection in the Wild | **[CVPR' 18]** |[`[pdf]`](http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Domain_Adaptive_Faster_CVPR_2018_paper.pdf) [`[official code - caffe]`](https://github.com/yuhuayc/da-faster-rcnn)\n\n- **[SNIP]** An Analysis of Scale Invariance in Object Detection \u2013 SNIP | **[CVPR' 18]** |[`[pdf]`](https://arxiv.org/pdf/1711.08189.pdf)\n\n- **[Relation-Network]** Relation Networks for Object Detection | **[CVPR' 18]** |[`[pdf]`](https://arxiv.org/pdf/1711.11575.pdf) [`[official code - mxnet]`](https://github.com/msracver/Relation-Networks-for-Object-Detection)\n\n- **[Cascade R-CNN]** Cascade R-CNN: Delving into High Quality Object Detection | **[CVPR' 18]** |[`[pdf]`](http://openaccess.thecvf.com/content_cvpr_2018/papers/Cai_Cascade_R-CNN_Delving_CVPR_2018_paper.pdf) [`[official code - caffe]`](https://github.com/zhaoweicai/cascade-rcnn)\n\n- Finding Tiny Faces in the Wild with Generative Adversarial Network | **[CVPR' 18]** |[`[pdf]`](https://ivul.kaust.edu.sa/Documents/Publications/2018/Finding%20Tiny%20Faces%20in%20the%20Wild%20with%20Generative%20Adversarial%20Network.pdf)\n\n- **[MLKP]** Multi-scale Location-aware Kernel Representation for Object Detection | **[CVPR' 18]** |[`[pdf]`](https://arxiv.org/pdf/1804.00428.pdf) [`[official code - caffe]`](https://github.com/Hwang64/MLKP)\n\n- Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation | **[CVPR' 18]** |[`[pdf]`](https://arxiv.org/pdf/1803.11365.pdf) [`[official code - chainer]`](https://github.com/naoto0804/cross-domain-detection)\n\n- **[Fitness NMS]** Improving Object Localization with Fitness NMS and Bounded IoU Loss | **[CVPR' 18]** |[`[pdf]`](http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0794.pdf) \n\n- **[STDnet]** STDnet: A ConvNet for Small Target Detection | **[BMVC' 18]** |[`[pdf]`](http://bmvc2018.org/contents/papers/0897.pdf)\n\n- **[RFBNet]** Receptive Field Block Net for Accurate and Fast Object Detection | **[ECCV' 18]** |[`[pdf]`](https://arxiv.org/pdf/1711.07767.pdf) [`[official code - pytorch]`](https://github.com/ruinmessi/RFBNet)\n\n- Zero-Annotation Object Detection with Web Knowledge Transfer | **[ECCV' 18]** |[`[pdf]`](http://openaccess.thecvf.com/content_ECCV_2018/papers/Qingyi_Tao_Zero-Annotation_Object_Detection_ECCV_2018_paper.pdf)\n\n- **[CornerNet]** CornerNet: Detecting Objects as Paired Keypoints | **[ECCV' 18]** |[`[pdf]`](https://arxiv.org/pdf/1808.01244.pdf) [`[official code - pytorch]`](https://github.com/princeton-vl/CornerNet)\n\n- **[PFPNet]** Parallel Feature Pyramid Network for Object Detection | **[ECCV' 18]** |[`[pdf]`](http://openaccess.thecvf.com/content_ECCV_2018/papers/Seung-Wook_Kim_Parallel_Feature_Pyramid_ECCV_2018_paper.pdf)\n\n- **[Softer-NMS]** Softer-NMS: Rethinking Bounding Box Regression for Accurate Object Detection | **[arXiv' 18]** |[`[pdf]`](https://arxiv.org/pdf/1809.08545.pdf)\n\n- **[ShapeShifter]** ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object Detector | **[ECML-PKDD' 18]** |[`[pdf]`](https://arxiv.org/pdf/1804.05810.pdf) [`[official code - tensorflow]`](https://github.com/shangtse/robust-physical-attack)\n\n- **[Pelee]** Pelee: A Real-Time Object Detection System on Mobile Devices | **[NIPS' 18]** |[`[pdf]`](http://papers.nips.cc/paper/7466-pelee-a-real-time-object-detection-system-on-mobile-devices.pdf) [`[official code - caffe]`](https://github.com/Robert-JunWang/Pelee)\n\n- **[HKRM]** Hybrid Knowledge Routed Modules for Large-scale Object Detection | **[NIPS' 18]** |[`[pdf]`](http://papers.nips.cc/paper/7428-hybrid-knowledge-routed-modules-for-large-scale-object-detection.pdf) \n\n- **[MetaAnchor]** MetaAnchor: Learning to Detect Objects with Customized Anchors | **[NIPS' 18]** |[`[pdf]`](http://papers.nips.cc/paper/7315-metaanchor-learning-to-detect-objects-with-customized-anchors.pdf) \n\n- **[SNIPER]** SNIPER: Efficient Multi-Scale Training | **[NIPS' 18]** |[`[pdf]`](http://papers.nips.cc/paper/8143-sniper-efficient-multi-scale-training.pdf) \n\n## 2019\n- **[M2Det]** M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network | **[AAAI' 19]** |[`[pdf]`](https://arxiv.org/pdf/1811.04533.pdf) [`[official code - pytorch]`](https://github.com/qijiezhao/M2Det)\n\n- **[R-DAD]** Object Detection based on Region Decomposition and Assembly | **[AAAI' 19]** |[`[pdf]`](https://arxiv.org/pdf/1901.08225v1.pdf) \n\n- **[CAMOU]** CAMOU: Learning Physical Vehicle Camouflages to Adversarially Attack Detectors in the Wild | **[ICLR' 19]** |[`[pdf]`](https://openreview.net/pdf?id=SJgEl3A5tm) \n\n- Feature Intertwiner for Object Detection | **[ICLR' 19]** |[`[pdf]`](https://openreview.net/pdf?id=SyxZJn05YX) \n\n- **[GIoU]** Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1902.09630.pdf) \n\n- Automatic adaptation of object detectors to new domains using self-training | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.07305.pdf) \n\n- **[Libra R-CNN]** Libra R-CNN: Balanced Learning for Object Detection | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.02701.pdf) \n\n- **[FSAF]** Feature Selective Anchor-Free Module for Single-Shot Object Detection | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1903.00621.pdf) \n\n- **[ExtremeNet]** Bottom-up Object Detection by Grouping Extreme and Center Points | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1901.08043.pdf) | [`[official code - pytorch]`](https://github.com/xingyizhou/ExtremeNet)\n\n- **[C-MIL]** C-MIL: Continuation Multiple Instance Learning for Weakly Supervised Object Detection\n | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.05647.pdf) | [`[official code - torch]`](https://github.com/AnonymousIDs/C-MIL)\n\n- **[ScratchDet]** ScratchDet: Training Single-Shot Object Detectors from Scratch | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1810.08425.pdf) \n\n- Bounding Box Regression with Uncertainty for Accurate Object Detection | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1809.08545.pdf) | [`[official code - caffe2]`](https://github.com/yihui-he/KL-Loss)\n\n- Activity Driven Weakly Supervised Object Detection | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.01665.pdf) \n\n- Towards Accurate One-Stage Object Detection with AP-Loss | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.06373.pdf) \n\n- Strong-Weak Distribution Alignment for Adaptive Object Detection | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1812.04798.pdf) | [`[official code - pytorch]`](https://github.com/VisionLearningGroup/DA_Detection) \n\n- **[NAS-FPN]** NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.07392.pdf) \n\n- **[Adaptive NMS]** Adaptive NMS: Refining Pedestrian Detection in a Crowd | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.03629.pdf) \n\n- Point in, Box out: Beyond Counting Persons in Crowds | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.01333.pdf) \n\n- Locating Objects Without Bounding Boxes | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1806.07564.pdf) \n\n- Sampling Techniques for Large-Scale Object Detection from Sparsely Annotated Objects | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1811.10862.pdf) \n\n- Towards Universal Object Detection by Domain Attention | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.04402.pdf) \n\n- Exploring the Bounds of the Utility of Context for Object Detection | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1711.05471.pdf) \n\n- What Object Should I Use? - Task Driven Object Detection | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.03000.pdf) \n\n- Dissimilarity Coefficient based Weakly Supervised Object Detection | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1811.10016) \n\n- Adapting Object Detectors via Selective Cross-Domain Alignment | **[CVPR' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Adapting_Object_Detectors_via_Selective_Cross-Domain_Alignment_CVPR_2019_paper.pdf) \n\n- Fully Quantized Network for Object Detection | **[CVPR' 19]** |[`[pdf]`](https://yan-junjie.github.io/publication/dblp-confcvprlilqwfy-19/dblp-confcvprlilqwfy-19.pdf)\n\n- Distilling Object Detectors with Fine-grained Feature Imitation | **[CVPR' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Distilling_Object_Detectors_With_Fine-Grained_Feature_Imitation_CVPR_2019_paper.pdf)\n\n- Multi-task Self-Supervised Object Detection via Recycling of Bounding Box Annotations | **[CVPR' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_CVPR_2019/papers/Lee_Multi-Task_Self-Supervised_Object_Detection_via_Recycling_of_Bounding_Box_Annotations_CVPR_2019_paper.pdf)\n\n- **[Reasoning-RCNN]** Reasoning-RCNN: Unifying Adaptive Global Reasoning into Large-scale Object Detection | **[CVPR' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Reasoning-RCNN_Unifying_Adaptive_Global_Reasoning_Into_Large-Scale_Object_Detection_CVPR_2019_paper.pdf)\n\n- Arbitrary Shape Scene Text Detection with Adaptive Text Region Representation | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1905.05980.pdf)\n\n- Assisted Excitation of Activations: A Learning Technique to Improve Object Detectors | **[CVPR' 19]** |[`[pdf]`](https://pdfs.semanticscholar.org/ec96/b6ae95e1ebbe4f7c0252301ede26dfc79467.pdf)\n\n- Spatial-aware Graph Relation Network for Large-scale Object Detection | **[CVPR' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Spatial-Aware_Graph_Relation_Network_for_Large-Scale_Object_Detection_CVPR_2019_paper.pdf)\n\n- **[MaxpoolNMS]** MaxpoolNMS: Getting Rid of NMS Bottlenecks in Two-Stage Object Detectors | **[CVPR' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_CVPR_2019/papers/Cai_MaxpoolNMS_Getting_Rid_of_NMS_Bottlenecks_in_Two-Stage_Object_Detectors_CVPR_2019_paper.pdf)\n\n- You reap what you sow: Generating High Precision Object Proposals for Weakly-supervised Object Detection | **[CVPR' 19]** |[`[pdf]`](https://web.cs.ucdavis.edu/~yjlee/projects/cvpr2019-youreapwhatyousow.pdf)\n\n- Object detection with location-aware deformable convolution and backward attention filtering | **[CVPR' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Object_Detection_With_Location-Aware_Deformable_Convolution_and_Backward_Attention_Filtering_CVPR_2019_paper.pdf)\n\n- Diversify and Match: A Domain Adaptive Representation Learning Paradigm for Object Detection | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1905.05396.pdf)\n\n- Hybrid Task Cascade for Instance Segmentation | **[CVPR' 19]** |[`[pdf]`](https://arxiv.org/pdf/1901.07518.pdf)\n\n- **[GFR]** Improving Object Detection from Scratch via Gated Feature Reuse | **[BMVC' 19]** |[`[pdf]`](https://arxiv.org/pdf/1712.00886v2.pdf) | [`[official code - pytorch]`](https://github.com/szq0214/GFR-DSOD)\n\n- **[Cascade RetinaNet]** Cascade RetinaNet: Maintaining Consistency for Single-Stage Object Detection | **[BMVC' 19]** |[`[pdf]`](https://arxiv.org/pdf/1907.06881v1.pdf)\n\n- Soft Sampling for Robust Object Detection | **[BMVC' 19]** |[`[pdf]`](https://arxiv.org/pdf/1806.06986v2.pdf)\n\n- Multi-adversarial Faster-RCNN for Unrestricted Object Detection | **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1907.10343v1.pdf)\n\n- Towards Adversarially Robust Object Detection | **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1907.10310v1.pdf)\n\n- A Robust Learning Approach to Domain Adaptive Object Detection | **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.02361.pdf)\n\n- A Delay Metric for Video Object Detection: What Average Precision Fails to Tell\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1908.06368.pdf)\n\n- Delving Into Robust Object Detection From Unmanned Aerial Vehicles: A Deep Nuisance Disentanglement Approach | **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1908.03856.pdf)\n\n- Employing Deep Part-Object Relationships for Salient Object Detection\t| **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Employing_Deep_Part-Object_Relationships_for_Salient_Object_Detection_ICCV_2019_paper.pdf)\n\n- Learning Rich Features at High-Speed for Single-Shot Object Detection\t| **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Learning_Rich_Features_at_High-Speed_for_Single-Shot_Object_Detection_ICCV_2019_paper.pdf)\n\n- Structured Modeling of Joint Deep Feature and Prediction Refinement for Salient Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1909.04366.pdf)\n\n- Selectivity or Invariance: Boundary-Aware Salient Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1812.10066.pdf)\n\n- Progressive Sparse Local Attention for Video Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1903.09126.pdf)\n\n- Minimum Delay Object Detection From Video\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1908.11092.pdf)\n\n- Towards Interpretable Object Detection by Unfolding Latent Structures\t | **[ICCV' 19]**  |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wu_Towards_Interpretable_Object_Detection_by_Unfolding_Latent_Structures_ICCV_2019_paper.pdf)\n\n- Scaling Object Detection by Transferring Classification Weights\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1909.06804.pdf)\n\n- **[TridentNet]** Scale-Aware Trident Networks for Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1901.01892.pdf)\n\n- Generative Modeling for Small-Data Object Detection\t| **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Generative_Modeling_for_Small-Data_Object_Detection_ICCV_2019_paper.pdf)\n\n- Transductive Learning for Zero-Shot Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://salman-h-khan.github.io/papers/ICCV19-2.pdf)\n\n- Self-Training and Adversarial Background Regularization for Unsupervised Domain Adaptive One-Stage Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1909.00597.pdf)\n\n-  **[CenterNet]** CenterNet: Keypoint Triplets for Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.08189.pdf)\n\n- **[DAFS]** Dynamic Anchor Feature Selection for Single-Shot Object Detection\t| **[ICCV' 19]** |[`[pdf]`](http://www4.comp.polyu.edu.hk/~cslzhang/paper/ICCV-DAFS.pdf)\n\n- **[Auto-FPN]** Auto-FPN: Automatic Network Architecture Adaptation for Object Detection Beyond Classification\t| **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Auto-FPN_Automatic_Network_Architecture_Adaptation_for_Object_Detection_Beyond_Classification_ICCV_2019_paper.pdf)\n\n- Multi-Adversarial Faster-RCNN for Unrestricted Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1907.10343.pdf)\n\n- Object Guided External Memory Network for Video Object Detection | **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Deng_Object_Guided_External_Memory_Network_for_Video_Object_Detection_ICCV_2019_paper.pdf)\n\n- **[ThunderNet]** ThunderNet: Towards Real-Time Generic Object Detection on Mobile Devices\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1903.11752.pdf)\n\n- **[RDN]** Relation Distillation Networks for Video Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1908.09511.pdf)\n\n- **[MMNet]** Fast Object Detection in Compressed Video\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1811.11057.pdf)\n\n- Towards High-Resolution Salient Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1908.07274.pdf)\n\n- **[SCAN]** Stacked Cross Refinement Network for Edge-Aware Salient Object Detection\t| **[ICCV' 19]** |[`[official code]`](https://github.com/wuzhe71/SCAN) |[`[pdf]`]()\n\n- Motion Guided Attention for Video Salient Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1909.07061.pdf)\n\n- Semi-Supervised Video Salient Object Detection Using Pseudo-Labels\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1908.04051.pdf)\n\n- Learning to Rank Proposals for Object Detection\t| **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Tan_Learning_to_Rank_Proposals_for_Object_Detection_ICCV_2019_paper.pdf)\n\n- **[WSOD2]** WSOD2: Learning Bottom-Up and Top-Down Objectness Distillation for Weakly-Supervised Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1909.04972.pdf)\n\n- **[ClusDet]** Clustered Object Detection in Aerial Images\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.08008.pdf)\n\n- Towards Precise End-to-End Weakly Supervised Object Detection Network\t| **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_Towards_Precise_End-to-End_Weakly_Supervised_Object_Detection_Network_ICCV_2019_paper.pdf)\n\n- Few-Shot Object Detection via Feature Reweighting\t | **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1812.01866.pdf)\n\n- **[Objects365]** Objects365: A Large-Scale, High-Quality Dataset for Object Detection\t| **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shao_Objects365_A_Large-Scale_High-Quality_Dataset_for_Object_Detection_ICCV_2019_paper.pdf)\n\n- **[EGNet]** EGNet: Edge Guidance Network for Salient Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1908.08297.pdf)\n\n- Optimizing the F-Measure for Threshold-Free Salient Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1805.07567.pdf)\n\n- Sequence Level Semantics Aggregation for Video Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1907.06390.pdf)\n\n- **[NOTE-RCNN]** NOTE-RCNN: NOise Tolerant Ensemble RCNN for Semi-Supervised Object Detection | **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1812.00124.pdf)\t\n\n- Enriched Feature Guided Refinement Network for Object Detection\t| **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Nie_Enriched_Feature_Guided_Refinement_Network_for_Object_Detection_ICCV_2019_paper.pdf)\n\n- **[POD]** POD: Practical Object Detection With Scale-Sensitive Network\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1909.02225.pdf)\t\n\n- **[FCOS]** FCOS: Fully Convolutional One-Stage Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.01355.pdf)\t\n\n- **[RepPoints]** RepPoints: Point Set Representation for Object Detection\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.11490.pdf)\t\n\n- Better to Follow, Follow to Be Better: Towards Precise Supervision of Feature Super-Resolution for Small Object Detection\t| **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Noh_Better_to_Follow_Follow_to_Be_Better_Towards_Precise_Supervision_ICCV_2019_paper.pdf)\n\n- Weakly Supervised Object Detection With Segmentation Collaboration\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.00551.pdf)\t\n\n- Leveraging Long-Range Temporal Relationships Between Proposals for Video Object Detection\t| **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shvets_Leveraging_Long-Range_Temporal_Relationships_Between_Proposals_for_Video_Object_Detection_ICCV_2019_paper.pdf)\n\n- Detecting 11K Classes: Large Scale Object Detection Without Fine-Grained Bounding Boxes\t| **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1908.05217.pdf)\t\n\n- **[C-MIDN]** C-MIDN: Coupled Multiple Instance Detection Network With Segmentation Guidance for Weakly Supervised Object Detection\t| **[ICCV' 19]** |[`[pdf]`]()\n\n- Meta-Learning to Detect Rare Objects\t| **[ICCV' 19]** |[`[pdf]`](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Meta-Learning_to_Detect_Rare_Objects_ICCV_2019_paper.pdf)\n\n- **[Cap2Det]** Cap2Det: Learning to Amplify Weak Caption Supervision for Object Detection | **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1907.10164v1.pdf)\n\n- **[Gaussian YOLOv3]** Gaussian YOLOv3: An Accurate and Fast Object Detector using Localization Uncertainty for Autonomous Driving | **[ICCV' 19]** |[`[pdf]`](https://arxiv.org/pdf/1904.04620.pdf) [`[official code - c]`](https://github.com/jwchoi384/Gaussian_YOLOv3)\n\n- **[FreeAnchor]** FreeAnchor: Learning to Match Anchors for Visual Object Detection | **[NeurIPS' 19]** |[`[pdf]`](https://arxiv.org/pdf/1909.02466v1.pdf)\n\n- Memory-oriented Decoder for Light Field Salient Object Detection | **[NeurIPS' 19]** |[`[pdf]`](http://papers.nips.cc/paper/8376-memory-oriented-decoder-for-light-field-salient-object-detection.pdf)\n\n- One-Shot Object Detection with Co-Attention and Co-Excitation | **[NeurIPS' 19]** |[`[pdf]`](http://papers.nips.cc/paper/8540-one-shot-object-detection-with-co-attention-and-co-excitation.pdf)\n\n- **[DetNAS]** DetNAS: Backbone Search for Object Detection | **[NeurIPS' 19]** |[`[pdf]`](https://arxiv.org/pdf/1903.10979v4.pdf)\n\n- Consistency-based Semi-supervised Learning for Object detection | **[NeurIPS' 19]** |[`[pdf]`](https://papers.nips.cc/paper/9259-consistency-based-semi-supervised-learning-for-object-detection.pdf)\n\n- **[NATS]** Efficient Neural Architecture Transformation Searchin Channel-Level for Object Detection | **[NeurIPS' 19]** |[`[pdf]`](https://arxiv.org/pdf/1909.02293.pdf)\n\n- **[AA]** Learning Data Augmentation Strategies for Object Detection | **[arXiv' 19]** |[`[pdf]`](https://arxiv.org/pdf/1906.11172.pdf)\n\n- **[Spinenet]** Spinenet: Learning scale-permuted backbone for recognition and localization | **[arXiv' 19]** |[`[pdf]`](https://arxiv.org/pdf/1912.05027.pdf)\n\n- Object Detection in 20 Years: A Survey | **[arXiv' 19]** |[`[pdf]`](https://arxiv.org/pdf/1905.05055.pdf)\n\n## 2020\n- **[Spiking-YOLO]** Spiking-YOLO: Spiking Neural Network for Real-time Object Detection | **[AAAI' 20]** |[`[pdf]`](https://arxiv.org/pdf/1903.06530.pdf)\n\n- Tell Me What They're Holding: Weakly-supervised Object Detection with Transferable Knowledge from Human-object Interaction | **[AAAI' 20]** |[`[pdf]`](https://arxiv.org/pdf/1911.08141v1.pdf)\n\n- **[CBnet]** Cbnet: A novel composite backbone network architecture for object detection | **[AAAI' 20]** |[`[pdf]`](https://arxiv.org/pdf/1909.03625.pdf)\n\n- **[Distance-IoU Loss]** Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression | **[AAAI' 20]** |[`[pdf]`](https://arxiv.org/pdf/1911.08287v1.pdf)\n\n- Computation Reallocation for Object Detection | **[ICLR' 20]** |[`[pdf]`](https://openreview.net/pdf?id=SkxLFaNKwB)\n\n- **[YOLOv4]** YOLOv4: Optimal Speed and Accuracy of Object Detection | **[arXiv' 20]** |[`[pdf]`](https://arxiv.org/pdf/2004.10934.pdf)\n\n- Few-Shot Object Detection With Attention-RPN and Multi-Relation Detector | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1908.01998.pdf)\n\n- Large-Scale Object Detection in the Wild From Imbalanced Multi-Labels | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2005.08455.pdf)\n\n- Bridging the Gap Between Anchor-Based and Anchor-Free Detection via Adaptive Training Sample Selection | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.02424.pdf)\n\n- Rethinking Classification and Localization for Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1904.06493.pdf)\n\n- Multiple Anchor Learning for Visual Object Detection | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.02252.pdf)\n\n- **[CentripetalNet]** CentripetalNet: Pursuing High-Quality Keypoint Pairs for Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.09119.pdf)\n\n- Learning From Noisy Anchors for One-Stage Object Detection | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.05086.pdf)\n\n- **[EfficientDet]** EfficientDet: Scalable and Efficient Object Detection | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1911.09070.pdf)\n\n- Overcoming Classifier Imbalance for Long-Tail Object Detection With Balanced Group Softmax | **[CVPR' 20]** |[`[pdf]`](https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Overcoming_Classifier_Imbalance_for_Long-Tail_Object_Detection_With_Balanced_Group_CVPR_2020_paper.pdf)\n\n- Dynamic Refinement Network for Oriented and Densely Packed Object Detection | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2005.09973.pdf)\n\n- Noise-Aware Fully Webly Supervised Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://openaccess.thecvf.com/content_CVPR_2020/papers/Shen_Noise-Aware_Fully_Webly_Supervised_Object_Detection_CVPR_2020_paper.pdf)\n\n- **[Hit-Detector]** Hit-Detector: Hierarchical Trinity Architecture Search for Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.11818.pdf)\n\n- **[D2Det]** D2Det: Towards High Quality Object Detection and Instance Segmentation | **[CVPR' 20]** |[`[pdf]`](https://openaccess.thecvf.com/content_CVPR_2020/papers/Cao_D2Det_Towards_High_Quality_Object_Detection_and_Instance_Segmentation_CVPR_2020_paper.pdf)\n\n- Prime Sample Attention in Object Detection | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1904.04821.pdf)\n\n- Don\u2019t Even Look Once: Synthesizing Features for Zero-Shot Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1911.07933.pdf)\n\n- Exploring Categorical Regularization for Domain Adaptive Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.09152.pdf)\n\n- **[SP-NAS]** SP-NAS: Serial-to-Parallel Backbone Search for Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://openaccess.thecvf.com/content_CVPR_2020/papers/Jiang_SP-NAS_Serial-to-Parallel_Backbone_Search_for_Object_Detection_CVPR_2020_paper.pdf)\n\n- **[NAS-FCOS]** NAS-FCOS: Fast Neural Architecture Search for Object Detection | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1906.04423.pdf)\n\n- **[DR Loss]** DR Loss: Improving Object Detection by Distributional Ranking\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1907.10156.pdf)\n\n- Detection in Crowded Scenes: One Proposal, Multiple Predictions\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.09163.pdf)\n\n- **[AugFPN]** AugFPN: Improving Multi-Scale Feature Learning for Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.05384.pdf)\n\n- Robust Object Detection Under Occlusion With Context-Aware CompositionalNets\t | **[CVPR' 20]** |[`[pdf]`](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Robust_Object_Detection_Under_Occlusion_With_Context-Aware_CompositionalNets_CVPR_2020_paper.pdf)\n\n- Cross-Domain Document Object Detection: Benchmark Suite and Method | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.13197.pdf)\n\n- Exploring Bottom-Up and Top-Down Cues With Attentive Learning for Webly Supervised Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.09790.pdf)\n\n- **[SLV]** SLV: Spatial Likelihood Voting for Weakly Supervised Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_SLV_Spatial_Likelihood_Voting_for_Weakly_Supervised_Object_Detection_CVPR_2020_paper.pdf)\n\n- **[HAMBox]** HAMBox: Delving Into Mining High-Quality Anchors on Face Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.09231.pdf)\n\n- **[Context R-CNN]** Context R-CNN: Long Term Temporal Context for Per-Camera Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.03538.pdf)\n\n- Mixture Dense Regression for Object Detection and Human Pose Estimation\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.00821.pdf)\n\n- Offset Bin Classification Network for Accurate Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://openaccess.thecvf.com/content_CVPR_2020/papers/Qiu_Offset_Bin_Classification_Network_for_Accurate_Object_Detection_CVPR_2020_paper.pdf)\n\n- **[NETNet]** NETNet: Neighbor Erasing and Transferring Network for Better Single Shot Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2001.06690.pdf)\n\n- Scale-Equalizing Pyramid Convolution for Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2005.03101.pdf)\n\n- Temporal-Context Enhanced Detection of Heavily Occluded Pedestrians\t | **[CVPR' 20]** |[`[pdf]`](https://cse.buffalo.edu/~jsyuan/papers/2020/TFAN.pdf)\n\n- **[MnasFPN]** MnasFPN: Learning Latency-Aware Pyramid Architecture for Object Detection on Mobile Devices\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.01106.pdf)\n\n- Physically Realizable Adversarial Examples for LiDAR Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2004.00543.pdf)\n\n- Cross-domain Object Detection through Coarse-to-Fine Feature Adaptation\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.10275.pdf)\n\n- Incremental Few-Shot Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.04668.pdf)\n\n- Where, What, Whether: Multi-Modal Learning Meets Pedestrian Detection\t | **[CVPR' 20]** |[`[pdf]`](https://openaccess.thecvf.com/content_CVPR_2020/papers/Luo_Where_What_Whether_Multi-Modal_Learning_Meets_Pedestrian_Detection_CVPR_2020_paper.pdf)\n\n- Cylindrical Convolutional Networks for Joint Object Detection and Viewpoint Estimation\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.11303.pdf)\n\n- Learning a Unified Sample Weighting Network for Object Detection\t | **[CVPR' 20]** |[`[pdf]`](https://openaccess.thecvf.com/content_CVPR_2020/papers/Cai_Learning_a_Unified_Sample_Weighting_Network_for_Object_Detection_CVPR_2020_paper.pdf)\n\n- Seeing without Looking: Contextual Rescoring of Object Detections for AP Maximization\t | **[CVPR' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.12290.pdf)\n\n- DetectoRS: Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution\t | **[arXiv' 20]** |[`[pdf]`](https://arxiv.org/pdf/2006.02334v1.pdf)\n\n- **[DETR]** End-to-End Object Detection with Transformers\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2005.12872.pdf)\n\n- Suppress and Balance: A Simple Gated Network for Salient Object Detection\t| **[ECCV' 20]** |[`[code]`](https://github.com/Xiaoqi-Zhao-DLUT/GateNet-RGB-Saliency)\n\n- **[BorderDet]** BorderDet: Border Feature for Dense Object Detection | **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.11056.pdf)\n\n- Corner Proposal Network for Anchor-free, Two-stage Object Detection\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.13816.pdf)\n\n- A General Toolbox for Understanding Errors in Object Detection\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2008.08115v1.pdf)\n\n- **[Chained-Tracker]** Chained-Tracker: Chaining Paired Attentive Regression Results for End-to-End Joint Multiple-Object Detection and Tracking\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.14557.pdf)\n\n- Side-Aware Boundary Localization for More Precise Object Detection\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.04260.pdf)\n\n- **[PIoU]** PIoU Loss: Towards Accurate Oriented Object Detection in Complex Environments\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.09584.pdf)\n\n- **[AABO]** AABO: Adaptive Anchor Box Optimization for Object Detection via Bayesian Sub-sampling\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.09336.pdf)\n\n- Highly Efficient Salient Object Detection with 100K Parameters | **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.05643.pdf)\n\n- **[GeoGraph]** GeoGraph: Learning graph-based multi-view object detection with geometric cues end-to-end\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.10151.pdf)\n\n- Many-shot from Low-shot: Learning to Annotate using Mixed Supervision for Object Detection| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2008.09694.pdf)\n\n- Cheaper Pre-training Lunch: An Efficient Paradigm for Object Detection\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2004.12178.pdf)\n\n- Arbitrary-Oriented Object Detection with Circular Smooth Label\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.05597.pdf)\n\n- Soft Anchor-Point Object Detection\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/1911.12448.pdf)\n\n- Object Detection with a Unified Label Space from Multiple Datasets\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2008.06614.pdf)\n\n- **[MimicDet]** MimicDet: Bridging the Gap Between One-Stage and Two-Stage Object Detection | **[ECCV' 20]** |[`[pdf]`](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590528.pdf)\n\n- Prior-based Domain Adaptive Object Detection for Hazy and Rainy Conditions\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.00070.pdf)\n\n- **[Dynamic R-CNN]** Dynamic R-CNN: Towards High Quality Object Detection via Dynamic Training\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2004.06002.pdf)\n\n- **[OS2D]** OS2D: One-Stage One-Shot Object Detection by Matching Anchor Features\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.06800.pdf)\n\n- Multi-Scale Positive Sample Refinement for Few-Shot Object Detection\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.09384.pdf)\n\n- Few-Shot Object Detection and Viewpoint Estimation for Objects in the Wild\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.12107.pdf)\n\n- Collaborative Training between Region Proposal Localization and Classification for Domain Adaptive Object Detection\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2009.08119.pdf)\n\n- Two-Stream Active Query Suggestion for Large-Scale Object Detection in Connectomics\t\t| **[ECCV' 20]** |[`[pdf]`](https://donglaiw.github.io/paper/2020_eccv_twostream.pdf)\n\n- **[FDTS]** FDTS: Fast Diverse-Transformation Search for Object Detection and Beyond\t\t| **[ECCV' 20]** \n\n- Dual refinement underwater object detection network\t\t| **[ECCV' 20]** |[`[pdf]`](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650273.pdf)\n\n- **[APRICOT]** APRICOT: A Dataset of Physical Adversarial Attacks on Object Detection\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/1912.08166.pdf)\n\n- Large Batch Optimization for Object Detection: Training COCO in 12 Minutes\t\t| **[ECCV' 20]** |[`[pdf]`](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660477.pdf)\n\n- Hierarchical Context Embedding for Region-based Object Detection\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2008.01338.pdf)\n\n- Pillar-based Object Detection for Autonomous Driving\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.10323.pdf)\n\n- Dive Deeper Into Box for Object Detection\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.14350.pdf)\n\n- Domain Adaptive Object Detection via Asymmetric Tri-way Faster-RCNN\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.01571.pdf)\n\n- Probabilistic Anchor Assignment with IoU Prediction for Object Detection\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.08103.pdf)\n\n- **[HoughNet]** HoughNet: Integrating near and long-range evidence for bottom-up object detection\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.02355.pdf)\n\n- **[LabelEnc]** LabelEnc: A New Intermediate Supervision Method for Object Detection\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.03282.pdf)\n\n- Boosting Weakly Supervised Object Detection with Progressive Knowledge Transfer\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.07986.pdf)\n\n- On the Importance of Data Augmentation for Object Detection\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/abs/1906.11172)\n\n- Adaptive Object Detection with Dual Multi-Label Prediction\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2003.12943.pdf)\n\n- Quantum-soft QUBO Suppression for Accurate Object Detection\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.13992.pdf)\n\n- Improving Object Detection with Selective Self-supervised Self-training\t\t| **[ECCV' 20]** |[`[pdf]`](https://arxiv.org/pdf/2007.09162.pdf)\n\n\n##\n\n## Dataset Papers\nStatistics of commonly used object detection datasets. The Table came from [this survey paper](https://arxiv.org/pdf/1809.02165v1.pdf).\n\n<table>\n<thead>\n  <tr>\n    <th rowspan=2>Challenge</th>\n    <th rowspan=2 width=80>Object Classes</th>\n    <th colspan=3>Number of Images</th>\n    <th colspan=2>Number of Annotated Images</th>\n  </tr>\n  <tr>\n    <th>Train</th>\n    <th>Val</th>\n    <th>Test</th>\n    <th>Train</th>\n    <th>Val</th>\n  </tr>\n</thead>\n<tbody>\n\n<!-- PASCAL VOC Object Detection Challenge -->\n<tr><th colspan=7>PASCAL VOC Object Detection Challenge</th></tr>\n<tr><td> VOC07 </td><td> 20 </td><td> 2,501 </td><td> 2,510 </td><td>  4,952 </td><td>   6,301 (7,844) </td><td>   6,307 (7,818) </td></tr>\n<tr><td> VOC08 </td><td> 20 </td><td> 2,111 </td><td> 2,221 </td><td>  4,133 </td><td>   5,082 (6,337) </td><td>   5,281 (6,347) </td></tr>\n<tr><td> VOC09 </td><td> 20 </td><td> 3,473 </td><td> 3,581 </td><td>  6,650 </td><td>   8,505 (9,760) </td><td>   8,713 (9,779) </td></tr>\n<tr><td> VOC10 </td><td> 20 </td><td> 4,998 </td><td> 5,105 </td><td>  9,637 </td><td> 11,577 (13,339) </td><td> 11,797 (13,352) </td></tr>\n<tr><td> VOC11 </td><td> 20 </td><td> 5,717 </td><td> 5,823 </td><td> 10,994 </td><td> 13,609 (15,774) </td><td> 13,841 (15,787) </td></tr>\n<tr><td> VOC12 </td><td> 20 </td><td> 5,717 </td><td> 5,823 </td><td> 10,991 </td><td> 13,609 (15,774) </td><td> 13,841 (15,787) </td></tr>\n\n<!-- ILSVRC Object Detection Challenge -->\n<tr><th colspan=7>ILSVRC Object Detection Challenge</th></tr>\n<tr><td> ILSVRC13 </td><td> 200 </td><td> 395,909 </td><td> 20,121 </td><td> 40,152 </td><td> 345,854 </td><td> 55,502 </td></tr>\n<tr><td> ILSVRC14 </td><td> 200 </td><td> 456,567 </td><td> 20,121 </td><td> 40,152 </td><td> 478,807 </td><td> 55,502 </td></tr>\n<tr><td> ILSVRC15 </td><td> 200 </td><td> 456,567 </td><td> 20,121 </td><td> 51,294 </td><td> 478,807 </td><td> 55,502 </td></tr>\n<tr><td> ILSVRC16 </td><td> 200 </td><td> 456,567 </td><td> 20,121 </td><td> 60,000 </td><td> 478,807 </td><td> 55,502 </td></tr>\n<tr><td> ILSVRC17 </td><td> 200 </td><td> 456,567 </td><td> 20,121 </td><td> 65,500 </td><td> 478,807 </td><td> 55,502 </td></tr>\n\n<!-- MS COCO Object Detection Challenge -->\n<tr><th colspan=7>MS COCO Object Detection Challenge</th></tr>\n<tr><td> MS COCO15 </td><td> 80 </td><td>  82,783 </td><td> 40,504 </td><td> 81,434 </td><td> 604,907 </td><td> 291,875 </td></tr>\n<tr><td> MS COCO16 </td><td> 80 </td><td>  82,783 </td><td> 40,504 </td><td> 81,434 </td><td> 604,907 </td><td> 291,875 </td></tr>\n<tr><td> MS COCO17 </td><td> 80 </td><td> 118,287 </td><td>  5,000 </td><td> 40,670 </td><td> 860,001 </td><td>  36,781 </td></tr>\n<tr><td> MS COCO18 </td><td> 80 </td><td> 118,287 </td><td>  5,000 </td><td> 40,670 </td><td> 860,001 </td><td>  36,781 </td></tr>\n\n<!-- Open Images Object Detection Challenge -->\n<tr><th colspan=7>Open Images Object Detection Challenge</th></tr>\n<tr><td> OID18 </td><td> 500 </td><td> 1,743,042 </td><td> 41,620 </td><td> 125,436 </td><td> 12,195,144 </td><td> \u2015 </td></tr>\n\n  </tbody>\n</table>\n\nThe papers related to datasets used mainly in Object Detection are as follows.\n\n- **[PASCAL VOC]** The PASCAL Visual Object Classes (VOC) Challenge | **[IJCV' 10]** | [`[pdf]`](http://host.robots.ox.ac.uk/pascal/VOC/pubs/everingham10.pdf)\n\n- **[PASCAL VOC]** The PASCAL Visual Object Classes Challenge: A Retrospective | **[IJCV' 15]** | [`[pdf]`](http://host.robots.ox.ac.uk/pascal/VOC/pubs/everingham15.pdf) | [`[link]`](http://host.robots.ox.ac.uk/pascal/VOC/)\n\n- **[ImageNet]** ImageNet: A Large-Scale Hierarchical Image Database| **[CVPR' 09]** | [`[pdf]`](http://www.image-net.org/papers/imagenet_cvpr09.pdf)\n\n- **[ImageNet]** ImageNet Large Scale Visual Recognition Challenge | **[IJCV' 15]** | [`[pdf]`](https://arxiv.org/pdf/1409.0575.pdf) | [`[link]`](http://www.image-net.org/challenges/LSVRC/)\n\n- **[COCO]** Microsoft COCO: Common Objects in Context | **[ECCV' 14]** | [`[pdf]`](https://arxiv.org/pdf/1405.0312.pdf) | [`[link]`](http://cocodataset.org/)\n\n- **[Open Images]** The Open Images Dataset V4: Unified image classification, object detection, and visual relationship detection at scale | **[arXiv' 18]** | [`[pdf]`](https://arxiv.org/pdf/1811.00982v1.pdf) | [`[link]`](https://storage.googleapis.com/openimages/web/index.html)\n\n- **[DOTA]** DOTA: A Large-scale Dataset for Object Detection in Aerial Images | **[CVPR' 18]** | [`[pdf]`](https://arxiv.org/pdf/1711.10398v3.pdf) | [`[link]`](https://captain-whu.github.io/DOTA/)\n\n- **[Objects365]** Objects365: A Large-Scale, High-Quality Dataset for Object Detection\t| **[ICCV' 19]** | [`[link]`](https://www.biendata.com/competition/objects365/)\n\n##\n\n## Contact & Feedback\n\nIf you have any suggestions about papers, feel free to mail me :)\n\n- [e-mail](mailto:Hoseong.Lee@cognex.com)\n- [blog](https://hoya012.github.io/)\n- [pull request](https://github.com/hoya012/deep_learning_object_detection/pulls)\n",
	"artificial-intelligence-algorithms artificial-neural-networks bayesian-statistics computer-vision deep-learning deep-neural-networks deep-reinforcement-learning explainable-ai geometric-deep-learning graph-neural-networks machine-learning medical-imaging natural-language-processing optimization pattern-recognition probabilistic-graphical-models probability reinforcement-learning speech-recognition visual-recognition": "# :balloon: :tada: Deep Learning Drizzle :confetti_ball: :balloon:\n\n:books: [**\"Read enough so you start developing intuitions and then trust your intuitions and go for it!\"** ](https://www.deeplearning.ai/hodl-geoffrey-hinton/) :books:  \u200b<br/>  Prof. Geoffrey Hinton, University of Toronto\n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n### Contents\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n|                                                              |                                                              |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| **Deep Learning (Deep Neural Networks)**  [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#tada-deep-learning-deep-neural-networks-confetti_ball-balloon) | **Probabilistic Graphical Models**  [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#loudspeaker-probabilistic-graphical-models-sparkles) |\n|                                                              |                                                              |\n| **Machine Learning Fundamentals**  [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#cupid-machine-learning-fundamentals-cyclone-boom) | **Natural Language Processing**  [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#hibiscus-natural-language-processing-cherry_blossom-sparkling_heart) |\n|                                                              |                                                              |\n| **Optimization for Machine Learning**  [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#cupid-optimization-for-machine-learning-cyclone-boom) | **Automatic Speech Recognition** [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#speaking_head-automatic-speech-recognition-speech_balloon-thought_balloon) |\n|                                                              |                                                              |\n| **General Machine Learning**  [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#cupid-general-machine-learning-cyclone-boom) | **Modern Computer Vision** [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#fire-modern-computer-vision-camera_flash-movie_camera) |\n|                                                              |                                                              |\n| **Reinforcement Learning**  [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#balloon-reinforcement-learning-hotsprings-video_game) | **Boot Camps or Summer Schools** [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#star2-boot-camps-or-summer-schools-maple_leaf) |\n|                                                              |                                                              |\n| **Bayesian Deep Learning** [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#game_die-bayesian-deep-learning-spades-gem) | **Medical Imaging** [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#movie_camera-medical-imaging-camera-video_camera) |\n|                                                              |                                                              |\n| **Graph Neural Networks** [:arrow_heading_down: ](https://github.com/kmario23/deep-learning-drizzle#tada-graph-neural-networks-geometric-dl-confetti_ball-balloon) | **Bird's-eye view of Artificial Intelligence** [:arrow_heading_down:](https://github.com/kmario23/deep-learning-drizzle#bird-birds-eye-view-of-agi-eagle) |\n|                                                              |                                                              |\n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n## :tada: Deep Learning (Deep Neural Networks) :confetti_ball: :balloon: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                           | University/Instructor(s)                       | Course WebPage                                               | Lecture Videos                                               | Year            |\n| ---- | ----------------------------------------------------- | ---------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------------- |\n| 1.   | **Neural Networks for Machine Learning**              | Geoffrey Hinton, University of Toronto         | [Lecture-Slides](http://www.cs.toronto.edu/~hinton/coursera_slides.html) <br/> [CSC321-tijmen](https://www.cs.toronto.edu/~tijmen/csc321/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9) <br/> [UofT-mirror](https://www.cs.toronto.edu/~hinton/coursera_lectures.html) | 2012 <br/> 2014 |\n| 2.   | **Neural Networks Demystified**                       | Stephen Welch, Welch Labs                      | [Suppl. Code](https://github.com/stephencwelch/Neural-Networks-Demystified) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU) | 2014            |\n| 3.   | **Deep Learning at Oxford**                           | Nando de Freitas, Oxford University            | [Oxford-ML](http://www.cs.ox.ac.uk/teaching/courses/2014-2015/ml/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu) | 2015            |\n| 4.   | **Deep Learning for Perception**                      | Dhruv Batra, Virginia Tech                     | [ECE-6504](https://computing.ece.vt.edu/~f15ece6504/)        | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL-fZD610i7yAsfH2eLBiRDa90kL2ML0f7) | 2015            |\n| 5.   | **Deep Learning**                                     | Ali Ghodsi, University of Waterloo             | [STAT-946](https://uwaterloo.ca/data-analytics/deep-learning) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLehuLRPyt1Hyi78UOkMPWCGRxGcA9NVOE) | F2015           |\n| 6.   | **CS231n: CNNs for Visual Recognition**               | Andrej Karpathy, Stanford University           | [CS231n](http://cs231n.stanford.edu/2015/)                   | `None`                                                       | 2015            |\n| 7.   | **CS224d: Deep Learning for NLP**                     | Richard Socher, Stanford University            | [CS224d](http://cs224d.stanford.edu)                         | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLmImxx8Char8dxWB9LRqdpCTmewaml96q) | 2015            |\n| 8.   | **Bay Area Deep Learning**                            | Many legends, Stanford                         | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLrAXtmErZgOfMuxkACrYnD2fTgbzk2THW) | 2016            |\n| 9.   | **CS231n: CNNs for Visual Recognition**               | Andrej Karpathy, Stanford University           | [CS231n](http://cs231n.stanford.edu/2016/)                   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC) <br/>[(Academic Torrent)](https://academictorrents.com/details/46c5af9e2075d9af06f280b55b65cf9b44eb9fe7) | 2016            |\n| 10.  | **Neural Networks**                                   | Hugo Larochelle, Universit\u00e9 de Sherbrooke      | [Neural-Networks](http://info.usherbrooke.ca/hlarochelle/neural_networks/content.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH) <br/> [(Academic Torrent)](https://academictorrents.com/details/e046bca3bc837053d1609ef33d623ee5c5af7300) | 2016            |\n|      |                                                       |                                                |                                                              |                                                              |                 |\n| 11.  | **CS224d: Deep Learning for NLP**                     | Richard Socher, Stanford University            | [CS224d](http://cs224d.stanford.edu)                         | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLlJy-eBtNFt4CSVWYqscHDdP58M3zFHIG) <br/>[(Academic Torrent)](https://academictorrents.com/details/dd9b74b50a1292b4b154094b7338ec1d66e8894d) | 2016            |\n| 12.  | **CS224n: NLP with Deep Learning**                    | Richard Socher, Stanford University            | [CS224n](http://web.stanford.edu/class/cs224n/)              | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6) | 2017            |\n| 13.  | **CS231n: CNNs for Visual Recognition**               | Justin Johnson, Stanford University            | [CS231n](http://cs231n.stanford.edu/2017/)                   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv) <br/> [(Academic Torrent)](https://academictorrents.com/details/ed8a16ebb346e14119a03371665306609e485f13) | 2017            |\n| 14.  | **Topics in Deep Learning**                           | Ruslan Salakhutdinov, CMU                      | [10707](https://deeplearning-cmu-10707.github.io/)           | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLpIxOj-HnDsOSL__Buy7_UEVQkyfhHapa) | F2017           |\n| 15.  | **Deep Learning Crash Course**                        | Leo Isikdogan, UT Austin                       | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLWKotBjTDoLj3rXBL-nEIPRN9V3a9Cx07) | 2017            |\n| 16.  | **Deep Learning and its Applications**                | Fran\u00e7ois Piti\u00e9, Trinity College Dublin         | [EE4C16](https://github.com/frcs/4C16-2017)                  | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLIo1iEzl5iB9NkulNR0X5vXN8AaEKglWT) | 2017            |\n| 17.  | **Deep Learning**                                     | Andrew Ng, Stanford University                 | [CS230](http://cs230.stanford.edu/)                          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb) | 2018            |\n| 18.  | **UvA Deep Learning**                                 | Efstratios Gavves, University of Amsterdam     | [UvA-DLC](https://uvadlc.github.io/)                         | [Lecture-Videos](https://uvadlc.github.io/lectures-sep2018.html) | 2018            |\n| 19.  | **Advanced Deep Learning and Reinforcement Learning** | Many legends, DeepMind                         | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs) | 2018            |\n| 20.  | **Machine Learning**                                  | Peter Bloem, Vrije Universiteit Amsterdam      | [MLVU](https://mlvu.github.io/)                              | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLCof9EqayQgsORO3pFzeYZFz6cszYO0VJ) | 2018            |\n|      |                                                       |                                                |                                                              |                                                              |                 |\n| 21.  | **Deep Learning**                                     | Francois Fleuret, EPFL                         | [EE-59](https://fleuret.org/ee559-2018/dlc)                  | [Video-Lectures](https://fleuret.org/ee559-2018/dlc/#materials) | 2018            |\n| 22.  | **Introduction to Deep Learning**                     | Alexander Amini, Harini Suresh and others, MIT | [6.S191](http://introtodeeplearning.com/)                    | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI) <br/> [2017-version](https://www.youtube.com/playlist?list=PLkkuNyzb8LmxFutYuPA7B4oiMn6cjD6Rs) | 2017- 2021     |\n| 23.  | **Deep Learning for Self-Driving Cars**               | Lex Fridman, MIT                               | [6.S094](https://selfdrivingcars.mit.edu/)                   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf) | 2017-2018       |\n| 24.  | **Introduction to Deep Learning**                     | Bhiksha Raj and many others, CMU               | [11-485/785](http://deeplearning.cs.cmu.edu/)                | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLp-0K3kfddPwJBJ4Q8We-0yNQEG0fZrSa) | S2018           |\n| 25.  | **Introduction to Deep Learning**                     | Bhiksha Raj and many others, CMU               | [11-485/785](http://deeplearning.cs.cmu.edu/)                | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLp-0K3kfddPyH44FP0dl0CbYprvTcfgOI)   [Recitation-Inclusive](https://www.youtube.com/playlist?list=PLLR0_ZOlbfD6KDBq93G8-guHI-J1ICeFm) | F2018           |\n| 26.  | **Deep Learning Specialization**                      | Andrew Ng, Stanford                            | [DL.AI](https://www.deeplearning.ai/deep-learning-specialization/) | [YouTube-Lectures](https://www.youtube.com/channel/UCcIXc5mJsHVYTZR1maL5l9w/playlists) | 2017-2018       |\n| 27.  | **Deep Learning**                                     | Ali Ghodsi, University of Waterloo             | [STAT-946](https://uwaterloo.ca/data-analytics/teaching/deep-learning-2017) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLehuLRPyt1HxTolYUWeyyIoxDabDmaOSB) | F2017           |\n| 28.  | **Deep Learning**                                     | Mitesh Khapra, IIT-Madras                      | [CS7015](https://www.cse.iitm.ac.in/~miteshk/CS7015.html)    | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLyqSpQzTE6M9gCgajvQbc68Hk_JKGBAYT) | 2018            |\n| 29.  | **Deep Learning for AI**                              | UPC Barcelona                                  | [DLAI-2017](https://telecombcn-dl.github.io/2017-dlai/) <br/> [DLAI-2018](https://telecombcn-dl.github.io/2018-dlai/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL-5eMc3HQTBagIUjKefjcTbnXC0wXC_vd) | 2017-2018       |\n| 30.  | **Deep Learning**                                     | Alex Bronstein and Avi Mendelson, Technion     | [CS236605](https://vistalab-technion.github.io/cs236605/info/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLM0a6Z788YAZuqg2Ip-_dPLzEd33lZvP2) | 2018            |\n|      |                                                       |                                                |                                                              |                                                              |                 |\n| 31.  | **MIT Deep Learning**                                 | Many Researchers,  Lex Fridman, MIT            | [6.S094, 6.S091, 6.S093](https://deeplearning.mit.edu/)      | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf) | 2019            |\n| 32.  | **Deep Learning Book** companion videos               | Ian Goodfellow and others                      | [DL-book slides](https://www.deeplearningbook.org/lecture_slides.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLsXu9MHQGs8df5A4PzQGw-kfviylC-R9b) | 2017            |\n| 33.  | **Theories of Deep Learning**                         | Many Legends, Stanford                         | [Stats-385](https://stats385.github.io/)                     | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLwUqqMt5en7fFLwSDa9V3JIkDam-WWgqy) <br/> (first 10 lectures) | F2017           |\n| 34.  | **Neural Networks**                                   | Grant Sanderson                                | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) | 2017-2018       |\n| 35.  | **CS230: Deep Learning**                              | Andrew Ng, Kian Katanforoosh, Stanford         | [CS230](http://cs230.stanford.edu/)                          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb) | A2018           |\n| 36.  | **Theory of Deep Learning**                           | Lots of Legends, Canary Islands                | [DALI'18](http://dalimeeting.org/dali2018/workshopTheoryDL.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLeCNfJWZKqxtWBnV8gefGqmmPgz9YF4LR) | 2018            |\n| 37.  | **Introduction to Deep Learning**                     | Alex Smola, UC Berkeley                        | [Stat-157](http://courses.d2l.ai/berkeley-stat-157/index.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLZSO_6-bSqHQHBCoGaObUljoXAyyqhpFW) | S2019           |\n| 38.  | **Deep Unsupervised Learning**                        | Pieter Abbeel, UC Berkeley                     | [CS294-158](https://sites.google.com/view/berkeley-cs294-158-sp19/home) | [YouTube-Lectures](https://www.youtube.com/channel/UCf4SX8kAZM_oGcZjMREsU9w/videos) | S2019           |\n| 39.  | **Machine Learning**                                  | Peter Bloem, Vrije Universiteit Amsterdam      | [MLVU](https://mlvu.github.io/)                              | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLCof9EqayQgupldnTvqNy_BThTcME5r93) | 2019            |\n| 40.  | **Deep Learning on Computational Accelerators**       | Alex Bronstein and Avi Mendelson, Technion     | [CS236605](https://vistalab-technion.github.io/cs236605/lectures/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLM0a6Z788YAa_WCy_V-q9NrGm5qQegZR5) | S2019           |\n|      |                                                       |                                                |                                                              |                                                              |                 |\n| 41.  | **Introduction to Deep Learning**                     | Bhiksha Raj and many others, CMU               | [11-785](http://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Spring.2019/www) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLp-0K3kfddPzNdZPX4p0lVi6AcDXBofuf) | S2019           |\n| 42.  | **Introduction to Deep Learning**                     | Bhiksha Raj and many others, CMU               | [11-785](https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2019/www) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLp-0K3kfddPwz13VqV1PaMXF6V6dYdEsj) <br> [Recitations](https://www.youtube.com/playlist?list=PLp-0K3kfddPxf4T59JEQKv5UanLPVsxzz) | F2019           |\n| 43.  | **UvA Deep Learning**                                 | Efstratios Gavves, University of Amsterdam     | [UvA-DLC](https://uvadlc.github.io/)                         | [Lecture-Videos](https://uvadlc.github.io/lectures-apr2019.html) | S2019           |\n| 44. | **Deep Learning** | Prabir Kumar Biswas, IIT Kgp | `None` | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLbRMhDVUMngc7NM-gDwcBzIYZNFSK2N1a) | 2019 |\n| 45. | **Deep Learning and its Applications** | Aditya Nigam, IIT Mandi | [CS-671](http://faculty.iitmandi.ac.in/~aditya/cs671/index.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLKvX2d3IUq586Ic9gIhZj6ubpWV-OJfl4) | 2019 |\n| 46. | **Neural Networks**                                   | Neil Rhodes, Harvey Mudd College               | [CS-152](https://www.cs.hmc.edu/~rhodes/cs152/schedule.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgEuVSRbAI9UIQSHGy4l01laA_12YOqEj) | F2019           |\n| 47. | **Deep Learning**                                     | Thomas Hofmann, ETH Z\u00fcrich                     | [DAL-DL](http://www.da.inf.ethz.ch/teaching/2019/DeepLearning) | [Lecture-Videos](https://video.ethz.ch/lectures/d-infk/2019/autumn/263-3210-00L.html) | F2019           |\n| 48. | **Deep Learning**                                     | Milan Straka, Charles University               | [NPFL114](https://ufal.mff.cuni.cz/courses/npfl114) | [Lecture-Videos](https://ufal.mff.cuni.cz/courses/npfl114/1718-summer) | S2019 |\n| 49. | **UvA Deep Learning** | Efstratios Gavves, University of Amsterdam | [UvA-DLC-19](https://uvadlc.github.io/#lectures) | [Lecture-Videos](https://uvadlc.github.io/#lectures) | F2019 |\n| 50. | **Artificial Intelligence: Principles and Techniques** | Percy Liang and Dorsa Sadigh, Stanford University | [CS221](https://stanford-cs221.github.io/autumn2019/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rO1NB9TD4iUZ3qghGEGtqNX) | F2019 |\n|  |  |  |  |  |  |\n| 51. | **Analyses of Deep Learning** | Lots of Legends, Stanford University | [STATS-385](https://stats385.github.io/) | [YouTube-Lectures](https://stats385.github.io/lecture_videos) | 2017-2019 |\n| 52. | **Deep Learning Foundations and Applications** | Debdoot Sheet and Sudeshna Sarkar, IIT-Kgp | [AI61002](http://www.facweb.iitkgp.ac.in/~debdoot/courses/AI61002/Spr2020) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL_AdDfjIMo6pZfwjZ0rJlkE_MIsmRW7Mh) | S2020 |\n| 53. | **Designing, Visualizing, and Understanding Deep Neural Networks** | John Canny, UC Berkeley | [CS 182/282A](https://bcourses.berkeley.edu/courses/1487769/pages/cs-l-w-182-slash-282a-designing-visualizing-and-understanding-deep-neural-networks-spring-2020) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLkFD6_40KJIwaO6Eca8kzsEFBob0nFvwm) | S2020 |\n| 54. | **Deep Learning** | Yann LeCun and Alfredo Canziani, NYU | [DS-GA 1008](https://atcold.github.io/pytorch-Deep-Learning/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq) | S2020 |\n| 55. | **Introduction to Deep Learning** | Bhiksha Raj, CMU | [11-785](https://deeplearning.cs.cmu.edu/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLp-0K3kfddPzCnS4CqKphh-zT3aDwybDe) | S2020 |\n| 56. | **Deep Unsupervised Learning** | Pieter Abbeel, UC Berkeley | [CS294-158](https://sites.google.com/view/berkeley-cs294-158-sp20) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP) | S2020 |\n| 57. | **Machine Learning** | Peter Bloem, Vrije Universiteit Amsterdam | [VUML](https://mlvu.github.io/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLCof9EqayQgthR7IViXkAkUwel_rhxGYM) | S2020 |\n| 58. | **Deep Learning (with PyTorch)** | Alfredo Canziani and Yann LeCun, NYU | [DS-GA 1008](https://atcold.github.io/pytorch-Deep-Learning/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq) | S2020 |\n| 59. | **Introduction to Deep Learning and Generative Models** | Sebastian Raschka, UW-Madison | [Stat453](http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLTKMiZHVd_2JkR6QtQEnml7swCnFBtq4P) | S2020 |\n| 60. | **Deep Learning** | Andreas Maier, FAU Erlangen-N\u00fcrnberg | [DL-2020](https://www.video.uni-erlangen.de/course/id/925) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj) <br/>[Lecture-Videos](https://www.video.uni-erlangen.de/course/id/925) | SS2020 |\n|  |  |  |  |  |  |\n| 61. | **Introduction to Deep Learning** | Laura Leal-Taix\u00e9 and Matthias Niessner, TU-M\u00fcnchen | [I2DL-IN2346](https://dvl.in.tum.de/teaching/i2dl-ss20/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLQ8Y4kIIbzy_OaXv86lfbQwPHSomk2o2e) | SS2020 |\n| 62. | **Deep Learning** | Sargur Srihari, SUNY-Buffalo | [CSE676](https://cedar.buffalo.edu/~srihari/CSE676/) | [YouTube-Lectures-P1](https://www.youtube.com/playlist?list=PLmx4utxjUQD70k_NzeiSIXf30m54T_e1h) <br/>[YouTube-Lectures-P2](https://www.youtube.com/channel/UCUm7yUmVJyAbYh_0ppJ4H-g/videos) | 2020 |\n| 63. | **Deep Learning Lecture Series** | Lots of Legends, DeepMind x UCL, London | [DLLS-20](https://deepmind.com/learning-resources/deep-learning-lecture-series-2020) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF) | 2020 |\n| 64. | **MultiModal Machine Learning** | Louis-Philippe Morency & others, Carnegie Mellon University | [11-777 MMML-20](https://cmu-multicomp-lab.github.io/mmml-course/fall2020) | [YouTube-Lectures](https://www.youtube.com/channel/UCqlHIJTGYhiwQpNuPU5e2gg/videos) | F2020 |\n| 65. | **Reliable and Interpretable Artificial Intelligence** | Martin Vechev, ETH Z\u00fcrich | [RIAI-20](https://www.sri.inf.ethz.ch/teaching/riai2020) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLWjm4hHpaNg6c-W7JjNYDEC_kJK9oSp0Y) | F2020 |\n| 66. | **Fundamentals of Deep Learning** | David McAllester, Toyota Technological Institute, Chicago | [TTIC-31230](https://mcallester.github.io/ttic-31230/Fall2020) | [YouTube-Lectures](https://www.youtube.com/channel/UCciVrtrRR3bQdaGbti9-hVQ/videos) | F2020 |\n| 67. | **Foundations of Deep Learning** | Soheil Feize, University of Maryland, College Park | [CMSC 828W](http://www.cs.umd.edu/class/fall2020/cmsc828W) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLHgjs9ncvHi80UCSlSvQe-TK_uOyDv_Jf) | F2020 |\n| 68. | **Deep Learning** | Andreas Geiger, Universit\u00e4t T\u00fcbingen | [DL-UT](https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/autonomous-vision/teaching/lecture-deep-learning/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL05umP7R6ij3NTWIdtMbfvX7Z-4WEXRqD) | W20/21 |\n| 69. | **Deep Learning** | Andreas Maier, FAU Erlangen-N\u00fcrnberg | [DL-FAU](https://www.fau.tv/course/id/1599) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLpOGQvPCDQzvJEPFUQ3mJz72GJ95jyZTh) | W20/21 |\n| 70. | **Fundamentals of Deep Learning** | Terence Parr and Yannet Interian, University of San Francisco | [DL-Fundamentals](https://github.com/parrt/fundamentals-of-deep-learning) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLFCc_Fc116ikeol9CZcWWKqmrJljxhE4N) | S2021 |\n|  |  |  |  |  |  |\n| 71. | **Full Stack Deep Learning** | Pieter Abbeel, Sergey Karayev, UC Berkeley | [FS-DL](https://fullstackdeeplearning.com/spring2021) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL1T8fO7ArWlcWg04OgNiJy91PywMKT2lv) | S2021 |\n| 72. | **Deep Learning: Designing, Visualizing, and Understanding DNNs** | Sergey Levine, UC Berkeley | [CS 182](https://cs182sp21.github.io) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A) | S2021 |\n| 73. | **Deep Learning in the Life Sciences** | Manolis Kellis, MIT | [6.874](https://mit6874.github.io) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLypiXJdtIca5sxV7aE3-PS9fYX3vUdIOX) | S2021 |\n| 74. | **Introduction to Deep Learning and Generative Models** | Sebastian Raschka, University of Wisconsin-Madison | [Stat 453](http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2021) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLTKMiZHVd_2KJtIXOW0zFhFfBaJJilH51) | S2021 |\n| 75. | **Deep Learning** | Alfredo Canziani and Yann LeCun, NYU | [NYU-DLSP21](https://atcold.github.io/NYU-DLSP21) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI) | S2021 |\n| 76. | **Applied Deep Learning** | Alexander Pacha, TU Wien | `None` | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLNsFwZQ_pkE8xNYTEyorbaWPN7nvbWyk1) | 2020-2021 |\n| 77. | **Machine Learning** | Hung-yi Lee, National Taiwan University | [ML'21](https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLJV_el3uVTsNxV_IGauQZBHjBKZ26JHjd) | S2021 |\n| 78. | **Mathematics of Deep Learning** | Lots of legends, FAU | [MoDL](https://www.fau.tv/course/id/878) | [Lecture-Videos](https://www.fau.tv/course/id/878) | 2019-21 |\n| 79. | **Deep Learning** | Peter Bloem, Michael Cochez, and Jakub Tomczak, VU-Amsterdam | [DL](https://dlvu.github.io/) | [YouTube-Lectures](https://www.youtube.com/channel/UCYh1zKnwzrSjrO2Ae-akfTg/playlists) | 2020-21 |\n| 80. | **Applied Deep Learning** | Maziar Raissi, UC Boulder | [ADL'21](https://github.com/maziarraissi/Applied-Deep-Learning) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoEMreTa9CNmuxQeIKWaz7AVFd_ZeAcy4) | 2021 |\n| | | | | | |\n| 81. | **An Introduction to Group Equivariant Deep Learning** | Erik J. Bekkers, Universiteit van Amsterdam | [UvAGEDL](https://uvagedl.github.io) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd) | 2022 |\n| | | | | | |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents) \n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n### :cupid: Machine Learning Fundamentals :cyclone: :boom: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                                  | University/Instructor(s)                                | Course Webpage                                               | Video Lectures                                               | Year       |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------- |\n| 1.   | **Linear Algebra**                                           | Gilbert Strang, MIT                                     | [18.06 SC](http://ocw.mit.edu/18-06SCF11)                    | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL221E2BBF13BECF6C) | 2011       |\n| 2.   | **Probability Primer**                                       | Jeffrey Miller, Brown University                        | `mathematical monk`                                          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL17567A1A3F5DB5E4) | 2011       |\n| 3.   | **Information Theory, Pattern Recognition, and Neural Networks** | David Mackay, University of Cambridge                   | [ITPRNN](http://www.inference.org.uk/mackay/itprnn)          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLruBu5BI5n4aFpG32iMbdWoRVAA-Vcso6) | 2012       |\n| 4.   | **Linear Algebra Review**                                    | Zico Kolter, CMU                                        | [LinAlg](http://www.cs.cmu.edu/~zkolter/course/linalg/index.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLM4Pv4KYYzGzL5ay6dmpyzRnbzQ__8v_t) | 2013       |\n| 5.   | **Probability and Statistics**                               | Michel van Biezen                                       | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLX2gX-ftPVXUWwTzAkOhBdhplvz0fByqV) | 2015       |\n| 6.   | **Linear Algebra: An in-depth Introduction**                 | Pavel Grinfeld                                          | `None`                                                       | [Part-1](https://www.youtube.com/playlist?list=PLlXfTHzgMRUKXD88IdzS14F4NxAZudSmv) <br/> [Part-2](https://www.youtube.com/playlist?list=PLlXfTHzgMRULWJYthculb2QWEiZOkwTSU)  <br/> [Part-3](https://www.youtube.com/playlist?list=PLlXfTHzgMRUIqYrutsFXCOmiqKUgOgGJ5) <br/> [Part-4](https://www.youtube.com/playlist?list=PLlXfTHzgMRULZfrNCrrJ7xDcTjGr633mm) | 2015- 2017 |\n| 7.   | **Multivariable Calculus**                                   | Grant Sanderson, Khan Academy                           | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLSQl0a2vh4HC5feHa6Rc5c0wbRTx56nF7) | 2016       |\n| 8.   | **Essence of Linear Algebra**                                | Grant Sanderson                                         | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) | 2016       |\n| 9.   | **Essence of Calculus**                                      | Grant Sanderson                                         | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) | 2017-2018  |\n| 10.  | **Math Background for Machine Learning**                     | Geoff Gordon, CMU                                       | [10-606](https://canvas.cmu.edu/courses/603/assignments/syllabus), [10-607](https://piazza.com/cmu/fall2017/1060610607/home) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL7y-1rk2cCsAqRtWoZ95z-GMcecVG5mzA) | F2017      |\n|      |                                                              |                                                         |                                                              |                                                              |            |\n| 11.  | **Mathematics for Machine Learning** (Linear Algebra, Calculus) | David Dye, Samuel Cooper, and Freddie Page, IC-London   | [MML](https://www.coursera.org/learn/linear-algebra-machine-learning) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLmAuaUS7wSOP-iTNDivR0ANKuTUhEzMe4) | 2018       |\n| 12.  | **Multivariable Calculus**                                   | S.K. Gupta and Sanjeev Kumar, IIT-Roorkee               | [MVC](https://nptel.ac.in/syllabus/111107108/)               | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLq-Gm0yRYwTiQtK374NzhFOcQkWmJ71vx) | 2018       |\n| 13.  | **Engineering Probability**                                  | Rich Radke, Rensselaer Polytechnic Institute            | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLuh62Q4Sv7BU1dN2G6ncyiMbML7OXh_Jx) | 2018       |\n| 14.  | **Matrix Methods in Data Analysis, Signal Processing, and Machine Learning** | Gilbert Strang, MIT                                     | [18.065](https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLUl4u3cNGP63oMNUHXqIUcrkS2PivhN3k) | S2018      |\n| 15.  | **Information Theory**                                       | Himanshu Tyagi, IISC, Bengaluru                         | [E2 201](https://ece.iisc.ac.in/~htyagi/course-E2201-2020.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgMDNELGJ1CYS-8dlMGPIaowVfeda4nUj) | 2018-20    |\n| 16.  | **Math Camp**                                                | Mark Walker, University of Arizona                      | [UAMathCamp / Econ-519](http://www.u.arizona.edu/~mwalker/MathCamp2019.htm) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLcjqUUQt__ZGLhwUacPm7_RKs2eJNFwco) | 2019       |\n| 17.  | **A 2020 Vision of Linear Algebra**                          | Gilbert Strang, MIT                                     | [VoLA](https://ocw.mit.edu/resources/res-18-010-a-2020-vision-of-linear-algebra-spring-2020/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLUl4u3cNGP61iQEFiWLE21EJCxwmWvvek) | S2020      |\n| 18.  | **Mathematics for Numerical Computing and Machine Learning** | Szymon Rusinkiewicz, Princeton University               | [COS-302](https://www.cs.princeton.edu/courses/archive/fall20/cos302/outline.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL88aSuXxl_dSjC5pIG8bGkC5wsUPyW_Hh) | F2020      |\n| 19.  | **Essential Statistics for Neuroscientists**                 | Philipp Berens, Universit\u00e4t Klinikum T\u00fcbingen           | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL05umP7R6ij0Gw5SLIrOA1dMYScCx4oXT) | 2020       |\n| 20.  | **Mathematics for Machine Learning**                         | Ulrike von Luxburg, Eberhard Karls Universit\u00e4t T\u00fcbingen | [Math4ML](https://www.tml.cs.uni-tuebingen.de/teaching/2020_maths_for_ml) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL05umP7R6ij1a6KdEy8PVE9zoCv6SlHRS) | W2020      |\n| 21.  | **Introduction to Causal Inference**                         | Brady Neal, Mila, Montr\u00e9al                              | [CausalInf](https://www.bradyneal.com/causal-inference-course) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0) | F2020      |\n| 22.  | **Applied Linear Algebra**                                   | Andrew Thangaraj, IIT Madras                            | [EE5120](http://www.ee.iitm.ac.in/~andrew/EE5120)            | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLyqSpQzTE6M-CHZU5RGfamcXOnuFyTOpm) | 2021       |\n| 23.  | **Mathematical Tools for Data Science**                      | Carlos Fernandez-Granda, New York University            | [DS-GA 1013/Math-GA 2824](https://cds.nyu.edu/math-tools)    | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLBEf5mJtE6KtU6YlXFZD6lyYcHhW5pIlc) | 2021       |\n| 24.  | **Mathematics for Numerical Computing and Machine Learning** | Ryan Adams, Princeton University                        | [COS 302 / SML 305](https://www.cs.princeton.edu/courses/archive/spring21/cos302) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLCO4cUaBLHFEHo42HVIVWaSOvbAiH30uc) | 2021       |\n|      |                                                              |                                                         |                                                              |                                                              |            |\n|      |                                                              |                                                         |                                                              |                                                              |            |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents) \n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n### :cupid: Optimization for Machine Learning :cyclone: :boom: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                                  | University/Instructor(s)                                     | Course Webpage                                               | Video Lectures                                               | Year       |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------- |\n| 1.   | **Convex Optimization**                                      | Stephen Boyd, Stanford University                            | [ee364a](http://web.stanford.edu/class/ee364a/lectures.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL3940DD956CDF0622) | 2008       |\n| 2.   | **Introduction to Optimization**                             | Michael Zibulevsky, Technion                                 | [CS-236330](https://sites.google.com/site/michaelzibulevsky/optimization-course) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLDFB2EEF4DDAFE30B) | 2009       |\n| 3.   | **Optimization for Machine Learning**                        | S V N Vishwanathan, Purdue University                        | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL09B0E8AFC69BE108) | 2011       |\n| 4.   | **Optimization**                                             | Geoff Gordon & Ryan Tibshirani, CMU                          | [10-725](https://www.cs.cmu.edu/~ggordon/10725-F12/)         | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL7y-1rk2cCsDOv91McLOnV4kExFfTB7dU) | 2012       |\n| 5.   | **Convex Optimization**                                      | Joydeep Dutta, IIT-Kanpur                                    | [cvx-nptel](https://nptel.ac.in/courses/111/104/111104068)   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLbMVogVj5nJQHFqfiSdgaLCCWvDcm1W4l) | 2013       |\n| 6.   | **Foundations of Optimization**                              | Joydeep Dutta, IIT-Kanpur                                    | [fop-nptel](https://nptel.ac.in/courses/111/104/111104071)   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLbMVogVj5nJRRbofh3Qm3P6_NVyevDGD_) | 2014       |\n| 7.   | **Algorithmic Aspects of Machine Learning**                  | Ankur Moitra, MIT                                            | [18.409-AAML](http://people.csail.mit.edu/moitra/409.html)   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLB3sDpSRdrOvI1hYXNsa6Lety7K8FhPpx) | S2015      |\n| 8.   | **Numerical Optimization**                                   | Shirish K. Shevade, IISC                                     | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL6EA0722B99332589) | 2015       |\n| 9.   | **Convex Optimization**                                      | Ryan Tibshirani, CMU                                         | [10-725](https://www.stat.cmu.edu/~ryantibs/convexopt-S15/)  | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLjbUi5mgii6BZBhJ9nW7eydgycyCOYeZ6) | S2015      |\n| 10.  | **Convex Optimization**                                      | Ryan Tibshirani, CMU                                         | [10-725](http://stat.cmu.edu/~ryantibs/convexopt-F15/)       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLjbUi5mgii6AGJW3La3BpEXe27n8v3biT) | F2015      |\n| 11.  | **Advanced Algorithms**                                      | Ankur Moitra, MIT                                            | [6.854-AA](http://people.csail.mit.edu/moitra/854.html)      | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL6ogFv-ieghdoGKGg2Bik3Gl1glBTEu8c) | S2016      |\n| 12.  | **Introduction to Optimization**                             | Michael Zibulevsky, Technion                                 | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLBD31626529B0AC2A) | 2016       |\n| 13.  | **Convex Optimization**                                      | Javier Pe\u00f1a & Ryan Tibshirani                                | [10-725/36-725](https://www.stat.cmu.edu/~ryantibs/convexopt-F16) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLjbUi5mgii6AVdvImLB9-Hako68p9MpIC) | F2016      |\n| 14.  | **Convex Optimization**                                      | Ryan Tibshirani, CMU                                         | [10-725](https://www.stat.cmu.edu/~ryantibs/convexopt-F18/)  | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLpIxOj-HnDsMM7BCNGC3hPFU3DfCWfVIw) <br/> [Lecture-Videos](https://www.stat.cmu.edu/~ryantibs/convexopt-F18/) | F2018      |\n| 15.  | **Modern Algorithmic Optimization**                          | Yurii Nesterov, UCLouvain                                    | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLEqoHzpnmTfAoUDqnmMly-KgyJ6ZM_axf) | 2018       |\n| 16.  | **Optimization, Foundations of Optimization**                | Mark Walker, University of Arizona                           | [MathCamp-20](http://www.u.arizona.edu/~mwalker/MathCamp2020/MathCamp2020LectureNotes.htm) | [YouTube-Lectures-Found.](https://www.youtube.com/playlist?list=PLcjqUUQt__ZE6wp_c4-FcRdmzBvx8VN7O) <br/> [YouTube-Lectures-Opt](https://www.youtube.com/playlist?list=PLcjqUUQt__ZE0ZSTNRyBIgLJ5obPHdmxC) | 2019 - now |\n| 17.  | **Optimization: Principles and Algorithms**                  | Michel Bierlaire, \u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL) | [opt-algo](https://transp-or.epfl.ch/books/optimization/html/about_book.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLM4Pv4KYYzGzOpWwsaV6GgllT6njsi1G-) | 2019       |\n| 18.  | **Optimization and Simulation**                              | Michel Bierlaire, \u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL) | [opt-sim](https://transp-or.epfl.ch/courses/OptSim2019/slides.php) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL10NOnsbP5Q5NlJ-Y6Eiup6RTSfkuj1TR) | S2019      |\n| 19.  | **Brazilian Workshop on Continuous Optimization**            | Lots of Legends, Instituto Nacional de Matem\u00e1tica Pura e Aplicada, Rio de Janeiro | [cont. opt.](https://impa.br/eventos-do-impa/eventos-2019/xiii-brazilian-workshop-on-continuous-optimization) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLo4jXE-LdDTQVZhnLPq2W31vJ1fq1VSp6) | 2019       |\n| 20.  | **One World Optimization Seminar**                           | Lots of Legends, Universit\u00e4t Wien                            | [1W-OPT](https://owos.univie.ac.at)                          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLBQo-yZOMzLWEcAptzTYOnwXo9hhXrAa2) | 2020-      |\n|      |                                                              |                                                              |                                                              |                                                              |            |\n| 21.  | **Convex Optimization II**                                   | Constantine Caramanis, UT Austin                             | [CVX-Optim-II](http://users.ece.utexas.edu/~cmcaram/constantine_caramanis/Announcements.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLXsmhnDvpjORzPelSDs0LSDrfJcqyLlZc) | S2020      |\n| 22.  | **Combinatorial Optimization**                               | Constantine Caramanis, UT Austin                             | [comb-op](https://caramanis.github.io/teaching/)             | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLXsmhnDvpjORcTRFMVF3aUgyYlHsxfhNL) | F2020      |\n| 23.  | **Optimization Methods for Machine Learning and Engineering** | Julius Pfrommer, J\u00fcrgen Beyerer, Karlsruher Institut f\u00fcr Technologie (KIT) | [Optim-MLE](https://ies.anthropomatik.kit.edu/lehre_1487.php), [slides](https://drive.google.com/drive/folders/1WWVWV4vDBIOkjZc6uFY3nfXvpaOUHcfb) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLdkTDauaUnQpzuOCZyUUZc0lxf4-PXNR5) | W2020-21   |\n|      |                                                              |                                                              |                                                              |                                                              |            |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents) \n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n### :cupid: General Machine Learning :cyclone: :boom: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                                  | University/Instructor(s)                                     | Course Webpage                                               | Video Lectures                                               | Year      |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- |\n| 1.   | **CS229: Machine Learning**                                  | Andrew Ng, Stanford University                               | [CS229-old](https://see.stanford.edu/Course/CS229/) <br/> [CS229-new](http://cs229.stanford.edu/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599) | 2007      |\n| 2.   | **Machine Learning**                                         | Jeffrey Miller, Brown University                             | `mathematical monk`                                          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA) | 2011      |\n| 3.   | **Machine Learning**                                         | Tom Mitchell, CMU                                            | [10-701](http://www.cs.cmu.edu/~tom/10701_sp11/)             | [Lecture-Videos](http://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml) | 2011      |\n| 4.   | **Machine Learning and Data Mining**                         | Nando de Freitas, University of British Columbia             | [CPSC-340](https://www.cs.ubc.ca/~nando/340-2012/index.php)  | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLE6Wd9FR--Ecf_5nCbnSQMHqORpiChfJf) | 2012      |\n| 5.   | **Learning from Data**                                       | Yaser Abu-Mostafa, CalTech                                   | [CS156](http://work.caltech.edu/telecourse.html)             | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLD63A284B7615313A) | 2012      |\n| 6.   | **Machine Learning**                                         | Rudolph Triebel, Technische Universit\u00e4t M\u00fcnchen              | [Machine Learning](https://vision.in.tum.de/teaching/ws2013/ml_ws13) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLTBdjV_4f-EIiongKlS9OKrBEp8QR47Wl) | 2013      |\n| 7.   | **Introduction to Machine Learning**                         | Alex Smola, CMU                                              | [10-701](http://alex.smola.org/teaching/cmu2013-10-701/)     | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLZSO_6-bSqHQmMKwWVvYwKreGu4b4kMU9) | 2013      |\n| 8.   | **Introduction to Machine Learning**                         | Alex Smola and Geoffrey Gordon, CMU                          | [10-701x](http://alex.smola.org/teaching/cmu2013-10-701x/)   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLZSO_6-bSqHR7NPk4k0zqdm2dPdraQZ_B) | 2013      |\n| 9.   | **Pattern Recognition**                                      | Sukhendu Das, IIT-M and C.A. Murthy, ISI-Calcutta            | [PR-NPTEL](https://nptel.ac.in/syllabus/106106046/)          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLbMVogVj5nJQJMLb2CYw9rry0d5s0TQRp) | 2014      |\n| 10.  | **An Introduction to Statistical Learning with Applications in R** | Trevor Hastie and Robert Tibshirani, Stanford                | [stat-learn](https://lagunita.stanford.edu/courses/HumanitiesandScience/StatLearning/Winter2015/about) <br/> [R-bloggers](https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLOg0ngHtcqbPTlZzRHA2ocQZqB1D_qZ5V) | 2014      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 11.  | **Introduction to Machine Learning**                         | Katie Malone, Sebastian Thrun, Udacity                       | [ML-Udacity](https://www.udacity.com/course/ud120)           | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLAwxTw4SYaPkQXg8TkVdIvYv4HfLG7SiH) | 2015      |\n| 12.  | **Introduction to Machine Learning**                         | Dhruv Batra, Virginia Tech                                   | [ECE-5984](https://filebox.ece.vt.edu/~s15ece5984/)          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL-fZD610i7yDUiNTFy-tEOxkTwg4mHZHu) | 2015      |\n| 13.  | **Statistical Learning - Classification**                    | Ali Ghodsi, University of Waterloo                           | [STAT-441](https://uwaterloo.ca/data-analytics/statistical-learning-classification) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLehuLRPyt1Hy-4ObWBK4Ab0xk97s6imfC) | 2015      |\n| 14.  | **Machine Learning Theory**                                  | Shai Ben-David, University of Waterloo                       | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLPW2keNyw-usgvmR7FTQ3ZRjfLs5jT4BO) | 2015      |\n| 15.  | **Introduction to Machine Learning**                         | Alex Smola, CMU                                              | [10-701](http://alex.smola.org/teaching/10-701-15/)          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLZSO_6-bSqHTTV7w9u7grTXBHMH-mw3qn) | S2015     |\n| 16.  | **Statistical Machine Learning**                             | Larry Wasserman, CMU                                         | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLjbUi5mgii6BWEUZf7He6nowWvGne_Y8r) | S2015     |\n| 17.  | **ML: Supervised Learning**                                  | Michael Littman, Charles Isbell, Pushkar Kolhe, GaTech       | [ML-Udacity](https://eu.udacity.com/course/machine-learning--ud262) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLAwxTw4SYaPl0N6-e1GvyLp5-MUMUjOKo) | 2015      |\n| 18.  | **ML: Unsupervised Learning**                                | Michael Littman, Charles Isbell, Pushkar Kolhe, GaTech       | [ML-Udacity](https://eu.udacity.com/course/machine-learning-unsupervised-learning--ud741) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLAwxTw4SYaPmaHhu-Lz3mhLSj-YH-JnG7) | 2015      |\n| 19.  | **Advanced Introduction to Machine Learning**                | Barnabas Poczos and Alex Smola                               | [10-715](https://www.cs.cmu.edu/~bapoczos/Classes/ML10715_2015Fall/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL4YhK0pT0ZhWBzSBkMGzpnPw6sf6Ma0IX) | F2015     |\n| 20.  | **Machine Learning**                                         | Pedro Domingos, UWashington                                  | [CSEP-546](https://courses.cs.washington.edu/courses/csep546/16sp/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLTPQEx-31JXgtDaC6-3HxWcp7fq4N8YGr) | S2016     |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 21.  | **Statistical Machine Learning**                             | Larry Wasserman, CMU                                         | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLTB9VQq8WiaCBK2XrtYn5t9uuPdsNm7YE) | S2016     |\n| 22.  | **Machine Learning with Large Datasets**                     | William Cohen, CMU                                           | [10-605](http://curtis.ml.cmu.edu/w/courses/index.php/Machine_Learning_with_Large_Datasets_10-605_in_Fall_2016) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLnfBqXRW5MRhPtfkadfwQ0VcuSi2IwEcW) | F2016     |\n| 23.  | **Math Background for Machine Learning**                     | Geoffrey Gordon, CMU                                         | `10-600`                                                     | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL7y-1rk2cCsA339crwXMWUaBRuLBvPBCg) | F2016     |\n| 24.  | **Statistical Learning - Classification**                    | Ali Ghodsi, University of Waterloo                           | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLehuLRPyt1HzXDemu7K4ETcF0Ld_B5adG) | 2017      |\n| 25.  | **Machine Learning**                                         | Andrew Ng, Stanford University                               | [Coursera-ML](https://www.coursera.org/learn/machine-learning) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN) | 2017      |\n| 26.  | **Machine Learning**                                         | Roni Rosenfield, CMU                                         | [10-601](http://www.cs.cmu.edu/~roni/10601-f17/)             | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL7k0r4t5c10-g7CWCnHfZOAxLaiNinChk) | 2017      |\n| 27.  | **Statistical Machine Learning**                             | Ryan Tibshirani, Larry Wasserman, CMU                        | [10-702](http://www.stat.cmu.edu/~ryantibs/statml/)          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLjbUi5mgii6B7A0nM74zHTOVQtTC9DaCv) | S2017     |\n| 28.  | **Machine Learning for Computer Vision**                     | Fred Hamprecht, Heidelberg University                        | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLuRaSnb3n4kSQFyt8VBldsQ9pO9Xtu8rY) | F2017     |\n| 29.  | **Math Background for Machine Learning**                     | Geoffrey Gordon, CMU                                         | [10-606 / 10-607](https://canvas.cmu.edu/courses/603/assignments/syllabus) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL7y-1rk2cCsAqRtWoZ95z-GMcecVG5mzA) | F2017     |\n| 30.  | **Data Visualization**                                       | Ali Ghodsi, University of Waterloo                           | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLehuLRPyt1HzQoXEhtNuYTmd0aNQvtyAK) | 2017      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 31.  | **Machine Learning for Physicists**                          | Florian Marquardt, Uni Erlangen-N\u00fcrnberg                     | [ML4Phy-17](http://www.thp2.nat.uni-erlangen.de/index.php/2017_Machine_Learning_for_Physicists,_by_Florian_Marquardt) | [Lecture-Videos](https://www.video.uni-erlangen.de/course/id/574) | 2017      |\n| 32.  | **Machine Learning for Intelligent Systems**                 | Kilian Weinberger, Cornell University                        | [CS4780](http://www.cs.cornell.edu/courses/cs4780/2018fa/)   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS) | F2018     |\n| 33.  | **Statistical Learning Theory and Applications**             | Tomaso Poggio, Lorenzo Rosasco, Sasha Rakhlin                | [9.520/6.860](https://cbmm.mit.edu/lh-9-520)                 | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLyGKBDfnk-iAtLO6oLW4swMiQGz4f2OPY) | F2018     |\n| 34.  | **Machine Learning and Data Mining**                         | Mike Gelbart, University of British Columbia                 | [CPSC-340](https://ubc-cs.github.io/cpsc340/)                | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLWmXHcz_53Q02ZLeAxigki1JZFfCO6M-b) | 2018      |\n| 35.  | **Foundations of Machine Learning**                          | David Rosenberg, Bloomberg                                   | [FOML](https://bloomberg.github.io/foml/#home)               | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLnZuxOufsXnvftwTB1HL6mel1V32w0ThI) | 2018      |\n| 36.  | **Introduction to Machine Learning**                         | Andreas Krause, ETH Z\u00fcrich                                   | [IntroML](https://las.inf.ethz.ch/teaching/introml-s18)      | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLzn6LN6WhlN273tsqyfdrBUsA-o5nUESV) | 2018      |\n| 37.  | **Machine Learning Fundamentals**                            | Sanjoy Dasgupta, UC-San Diego                                | [MLF-slides](https://drive.google.com/drive/folders/1l1rwv-jMihLZIpW0zTgGN9-snWOsA3M9) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL_onPhFCkVQhUzcTVgQiC8W2ShZKWlm0s) | 2018      |\n| 38.  | **Machine Learning**                                         | Jordan Boyd-Graber, University of Maryland                   | [CMSC-726](http://users.umiacs.umd.edu/~jbg/teaching/CMSC_726/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLegWUnz91WfsELyRcZ7d1GwAVifDaZmgo) | 2015-2018 |\n| 39.  | **Machine Learning**                                         | Andrew Ng, Stanford University                               | [CS229](http://cs229.stanford.edu/syllabus-autumn2018.html)  | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU) | 2018      |\n| 40.  | **Machine Intelligence**                                     | H.R.Tizhoosh, UWaterloo                                      | [SYDE-522](https://kimialab.uwaterloo.ca/kimia/index.php/teaching/syde-522-machine-intelligence-2) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL4upCU5bnihwCX93Gv6AQnKmVMwx4AZoT) | 2019      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 41.  | **Introduction to Machine Learning**                         | Pascal Poupart, University of Waterloo                       | [CS480/680](https://cs.uwaterloo.ca/~ppoupart/teaching/cs480-spring19) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLdAoL1zKcqTW-uzoSVBNEecKHsnug_M0k) | S2019     |\n| 42.  | **Advanced Machine Learning**                                | Thorsten Joachims, Cornell University                        | [CS-6780](https://www.cs.cornell.edu/courses/cs6780/2019sp)  | [Lecture-Videos](https://cornell.mediasite.com/Mediasite/Catalog/Full/f5d1cd3323f746cca80b2468bf97efd421) | S2019     |\n| 43.  | **Machine Learning for Structured Data**                     | Matt Gormley, Carnegie Mellon University                     | [10-418/10-618](http://www.cs.cmu.edu/~mgormley/courses/10418/schedule.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL4CxkUJbvNVihRKP4bXufvRLIWzeS-ieP) | F2019     |\n| 44.  | **Advanced Machine Learning**                                | Joachim Buhmann, ETH Z\u00fcrich                                  | [ML2-AML](https://ml2.inf.ethz.ch/courses/aml/)              | [Lecture-Videos](https://video.ethz.ch/lectures/d-infk/2019/autumn/252-0535-00L.html) | F2019     |\n| 45.  | **Machine Learning for Signal Processing**                   | Vipul Arora, IIT-Kanpur                                      | [MLSP](http://home.iitk.ac.in/~vipular/stuff/2019_MLSP.html) | [Lecture-Videos](https://iitk-my.sharepoint.com/:f:/g/personal/vipular_iitk_ac_in/Enf97NZfsoVBiyclC6yHfe4BlUv6CA4U8LPQQ4vtsDo_Xg) | F2019     |\n| 46.  | **Foundations of Machine Learning**                          | Animashree Anandkumar, CalTech                               | [CMS-165](http://tensorlab.cms.caltech.edu/users/anima/cms165-2019.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLVNifWxslHCA5GUh0o92neMiWiQiGVFqp) | 2019      |\n| 47.  | **Machine Learning for Physicists**                          | Florian Marquardt, Uni Erlangen-N\u00fcrnberg                     | `None`                                                       | [Lecture-Videos](https://www.video.uni-erlangen.de/course/id/778) | 2019      |\n| 48.  | **Applied Machine Learning**                                 | Andreas M\u00fcller, Columbia University                          | [COMS-W4995](https://www.cs.columbia.edu/~amueller/comsw4995s19/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL_pVmAaAnxIQGzQS2oI3OWEPT-dpmwTfA) | 2019      |\n| 49.  | **Fundamentals of Machine Learning over Networks**           | Hossein Shokri-Ghadikolaei, KTH, Sweden                      | [MLoNs](https://sites.google.com/view/mlons/course-materials) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLWoZTd81WFCEBFrxDfNUrDnt3ABdLfg80) | 2019      |\n| 50.  | **Foundations of Machine Learning and Statistical Inference** | Animashree Anandkumar, CalTech                               | [CMS-165](http://tensorlab.cms.caltech.edu/users/anima/cms165-2020.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLVNifWxslHCDlbyitaLLYBOAEPbmF1AHg) | 2020      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 51.  | **Machine Learning**                                         | Rebecca Willett and Yuxin Chen, University of Chicago        | [STAT 37710 / CMSC 35400](https://voices.uchicago.edu/willett/teaching/stats37710-cmsc35400-s20) | [Lecture-Videos](https://voices.uchicago.edu/willett/teaching/stats37710-cmsc35400-s20) | S2020     |\n| 52.  | **Introduction to Machine Learning**                         | Sanjay Lall and Stephen Boyd, Stanford University            | [EE104/CME107](http://ee104.stanford.edu)                    | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rN_Uy7_wmS051_q1d6akXmK) | S2020     |\n| 53.  | **Applied Machine Learning**                                 | Andreas M\u00fcller, Columbia University                          | [COMS-W4995](https://www.cs.columbia.edu/~amueller/comsw4995s20/schedule/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL_pVmAaAnxIRnSw6wiCpSvshFyCREZmlM) | S2020     |\n| 54.  | **Statistical Machine Learning**                             | Ulrike von Luxburg, Eberhard Karls Universit\u00e4t T\u00fcbingen      | [Stat-ML](https://www.tml.cs.uni-tuebingen.de/teaching/2020_statistical_learning/index.php) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL05umP7R6ij2XCvrRzLokX6EoHWaGA2cC) | SS2020    |\n| 55.  | **Probabilistic Machine Learning**                           | Philipp Hennig, Eberhard Karls Universit\u00e4t T\u00fcbingen          | [Prob-ML](https://uni-tuebingen.de/en/180804)                | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL05umP7R6ij1tHaOFY96m5uX3J21a6yNd) | SS2020    |\n| 56.  | **Machine Learning**                                         | Sarath Chandar, PolyMTL, UdeM, Mila                          | [INF8953CE](http://sarathchandar.in/teaching/ml/fall2020)    | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLImtCgowF_ET0mi-AmmqQ0SIJUpWYaIOr) | F2020     |\n| 57.  | **Machine Learning**                                         | Erik Bekkers, Universiteit van Amsterdam                     | [UvA-ML](https://uvaml1.github.io/)                          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL8FnQMH2k7jzhtVYbKmvrMyXDYMmgjj_n) | F2020     |\n| 58.  | **Neural Networks for Signal Processing**                    | Shayan Srinivasa Garani, Indian Institute of Science         | [NN4SP](https://labs.dese.iisc.ac.in/pnsil/neural-networks-and-learning-systems-i-fall-2020/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgMDNELGJ1CZn1399dV7_U4VBNJflRsua) | F2020     |\n| 59.  | **Introduction to Machine Learning**                         | Dmitry Kobak, Universit\u00e4t Klinikum T\u00fcbingen                  | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL05umP7R6ij35ShKLDqccJSDntugY4FQT) | 2020      |\n| 60.  | **Machine Learning (PRML)**                                  | Erik J. Bekkers, Universiteit van Amsterdam                  | [UvAML-1](https://uvaml1.github.io)                          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL8FnQMH2k7jzhtVYbKmvrMyXDYMmgjj_n) | 2020      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n| 61.  | **Machine Learning with Kernel Methods**                     | Julien Mairal and Jean-Philippe Vert, Inria/ENS Paris-Saclay, Google | [ML-Kernels](http://members.cbio.mines-paristech.fr/~jvert/svn/kernelcourse/course/2021mva/index.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLD93kGj6_EdrkNj27AZMecbRlQ1SMkp_o) | S2021     |\n| 62.  | **Continual Learning**                                       | Vincenzo Lomonaco, Universit\u00e0 di Pisa                        | [ContLearn'21](https://course.continualai.org/background/details) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLm6QXeaB-XkBfM5RgQP6wCR7Jegdg51Px) | 2021      |\n| 63.  | **Causality**                                                | Christina Heinze-Deml, ETH Zurich                            | [Causal'21](https://stat.ethz.ch/lectures/ss21/causality.php#course_materials) | [YouTube-Lectures](https://stat.ethz.ch/lectures/ss21/causality.php#course_materials) | 2021      |\n|      |                                                              |                                                              |                                                              |                                                              |           |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents) \n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n### :balloon: Reinforcement Learning :hotsprings: :video_game: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                              | University/Instructor(s)                                     | Course Webpage                                               | Video Lectures                                               | Year   |\n| ---- | -------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------ |\n| 1.   | **A Short Course on Reinforcement Learning**             | Satinder Singh, UMichigan                                    | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLM4Pv4KYYzGy4cIFQ5C36-1jMNLab80Ky) | 2011   |\n| 2.   | **Approximate Dynamic Programming**                      | Dimitri P. Bertsekas, MIT                                    | [Lecture-Slides](http://adpthu2014.weebly.com/slides--materials.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLiCLbsFQNFAxOmVeqPhI5er1LGf2-L9I4) | 2014   |\n| 3.   | **Introduction to Reinforcement Learning**               | David Silver, DeepMind                                       | [UCL-RL](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ) | 2015   |\n| 4.   | **Reinforcement Learning**                               | Charles Isbell, Chris Pryby, GaTech; Michael Littman, Brown  | [RL-Udacity](https://eu.udacity.com/course/reinforcement-learning--ud600) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLAwxTw4SYaPnidDwo9e2c7ixIsu_pdSNp) | 2015   |\n| 5.   | **Reinforcement Learning**                               | Balaraman Ravindran, IIT Madras                              | [RL-IITM](https://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLNdWVHi37UggQIVcaZcmtGGEQHY9W7d9D) | 2016   |\n| 6.   | **Deep Reinforcement Learning**                          | Sergey Levine, UC Berkeley                                   | [CS-294](http://rail.eecs.berkeley.edu/deeprlcoursesp17/)    | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLkFD6_40KJIwTmSbCv9OVJB3YaO4sFwkX) | S2017  |\n| 7.   | **Deep Reinforcement Learning**                          | Sergey Levine, UC Berkeley                                   | [CS-294](http://rail.eecs.berkeley.edu/deeprlcourse-fa17/)   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLkFD6_40KJIznC9CDbVTjAF2oyt8_VAe3) | F2017  |\n| 8.   | **Deep RL Bootcamp**                                     | Many legends, UC Berkeley                                    | [Deep-RL](https://sites.google.com/view/deep-rl-bootcamp/lectures) | [YouTube-Lectures](https://www.youtube.com/channel/UCTgM-VlXKuylPrZ_YGAJHOw/videos) | 2017   |\n| 9    | **Data Efficient Reinforcement Learning**                | Lots of Legends, Canary Islands                              | [DERL-17](http://dalimeeting.org/dali2017/data-efficient-reinforcement-learning.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL-tWvTpyd1VAvDpxukup6w-SuZQQ7e8K8) | 2017   |\n| 10.  | **Deep Reinforcement Learning**                          | Sergey Levine, UC Berkeley                                   | [CS-294-112](http://rail.eecs.berkeley.edu/deeprlcourse-fa18/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLkFD6_40KJIxJMR-j5A1mkxK26gh_qg37) | 2018   |\n|      |                                                          |                                                              |                                                              |                                                              |        |\n| 11.  | **Reinforcement Learning**                               | Pascal Poupart, University of Waterloo                       | [CS-885](https://cs.uwaterloo.ca/~ppoupart/teaching/cs885-spring18/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLdAoL1zKcqTXFJniO3Tqqn6xMBBL07EDc) | 2018   |\n| 12.  | **Deep Reinforcement Learning and Control**              | Katerina Fragkiadaki and Tom Mitchell, CMU                   | [10-703](http://www.andrew.cmu.edu/course/10-703/)           | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLpIxOj-HnDsNfvOwRKLsUobmnF2J1l5oV) | 2018   |\n| 13.  | **Reinforcement Learning and Optimal Control**           | Dimitri Bertsekas, Arizona State University                  | [RLOC](http://web.mit.edu/dimitrib/www/RLbook.html)          | [Lecture-Videos](http://web.mit.edu/dimitrib/www/RLbook.html) | 2019   |\n| 14.  | **Reinforcement Learning**                               | Emma Brunskill, Stanford University                          | [CS 234](http://web.stanford.edu/class/cs234/index.html)     | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u) | 2019   |\n| 15.  | **Reinforcement Learning Day**                           | Lots of Legends, Microsoft Research, New York                | [RLD-19](https://www.microsoft.com/en-us/research/event/reinforcement-learning-day-2019/#!agenda) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLD7HFcN7LXRe9nWEX3Up-RiCDi6-0mqVC) | 2019   |\n| 16.  | **New Directions in Reinforcement Learning and Control** | Lots of Legends, IAS, Princeton University                   | [NDRLC-19](https://www.math.ias.edu/ndrlc)                   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLdDZb3TwJPZ61sGqd6cbWCmTc275NrKu3) | 2019   |\n| 17.  | **Deep Reinforcement Learning**                          | Sergey Levine, UC Berkeley                                   | [CS 285](http://rail.eecs.berkeley.edu/deeprlcourse-fa19)    | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLkFD6_40KJIwhWJpGazJ9VSj9CFMkb79A) | F2019  |\n| 18.  | **Deep Multi-Task and Meta Learning**                    | Chelsea Finn, Stanford University                            | [CS 330](https://cs330.stanford.edu/)                        | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5) | F2019  |\n| 19.  | **RL-Theory Seminars**                                   | Lots of Legends, Earth                                       | [RL-theory-sem](https://sites.google.com/view/rltheoryseminars/past-seminars) | [YouTube-Lectures](https://www.youtube.com/channel/UCfBFutC9RbKK6p--B4R9ebA/videos) | 2020 - |\n| 20.  | **Deep Reinforcement Learning**                          | Sergey Levine, UC Berkeley                                   | [CS 285](http://rail.eecs.berkeley.edu/deeprlcourse-fa20)    | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc) | F2020  |\n|      |                                                          |                                                              |                                                              |                                                              |        |\n| 21.  | **Introduction to Reinforcement Learning**               | Amir-massoud Farahmand, Vector Institute, University of Toronto | [RL-intro](https://amfarahmand.github.io/IntroRL)            | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLCveiXxL2xNbiDq51a8iJwPRq2aO0ykrq) | S2021  |\n| 22.  | **Reinforcement Learning**                               | Antonio Celani and Emanuele Panizon, International Centre for Theoretical Physics | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLp0hSY2uBeP8q2G3mfHGVGvQFEMX0QRWM) | 2021   |\n| 23.  | **Computational Sensorimotor Learning**                  | Pulkit Agrawal, MIT-CSAIL                                    | [6.884-CSL](https://pulkitag.github.io/6.884/lectures)       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLwNwxAG-kBxPMTIs2fKWSsf7HqL2TcC78) | S2021  |\n| 24.  | **Reinforcement Learning**                               | Dimitri P. Bertsekas, ASU/MIT                                | [RL-21](http://web.mit.edu/dimitrib/www/RLbook.html)         | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLmH30BG15SIp79JRJ-MVF12uvB1qPtPzn) | S2021  |\n| 25.  | **Reinforcement Learning**                               | Sarath Chandar,  \u00c9cole Polytechnique de Montr\u00e9al             | [INF8953DE](https://chandar-lab.github.io/INF8953DE)         | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLImtCgowF_ES_JdF_UcM60EXTcGZg67Ua) | F2021  |\n| 26.  | **Deep Reinforcement Learning**                          | Sergey Levine, UC Berkeley                                   | [CS 285](http://rail.eecs.berkeley.edu/deeprlcourse)         | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL_iWQOsE6TfXxKgI1GgyV1B_Xa0DxE5eH) | F2021  |\n| 27.  | **Reinforcement Learning Lecture Series**                | Lots of Legends, DeepMind & UC London                        | [RL-series](https://deepmind.com/learning-resources/reinforcement-learning-series-2021) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLqYmG7hTraZDVH599EItlEWsUOsJbAodm) | 2021   |\n| 28.  | **Reinforcement Learning**                               | Dimitri P. Bertsekas, ASU/MIT                                | [RL-22](http://web.mit.edu/dimitrib/www/RLbook.html)         | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLmH30BG15SIoXhxLldoio0BhsIY84YMDj) | S2022  |\n|      |                                                          |                                                              |                                                              |                                                              |        |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents) \n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n### :loudspeaker: Probabilistic Graphical Models :sparkles: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                                  | University/Instructor(s)                            | Course WebPage                                               | Lecture Videos                                               | Year    |\n| ---- | ------------------------------------------------------------ | --------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------- |\n| 1.   | **Probabilistic Graphical Models**                           | Many Legends, MPI-IS                                | [MLSS-Tuebingen](http://mlss.tuebingen.mpg.de/2013/2013/speakers.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLL0GjJzXhAWTRiW_ynFswMaiLSa0hjCZ3) | 2013    |\n| 2.   | **Probabilistic Modeling and Machine Learning**              | Zoubin Ghahramani, University of Cambridge          | [WUST-Wroclaw](https://www.ii.pwr.edu.pl/~gonczarek/zoubin.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLwUOK5j_XOsdfVAGKErx9HqnrVZIuRbZ2) | 2013    |\n| 3.   | **Probabilistic Graphical Models**                           | Eric Xing, CMU                                      | [10-708](http://www.cs.cmu.edu/~epxing/Class/10708/lecture.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLI3nIOD-p5aoXrOzTd1P6CcLavu9rNtC-) | 2014    |\n| 4.   | **Learning with Structured Data: An Introduction to Probabilistic Graphical Models** | Christoph Lampert, IST Austria                      | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLEqoHzpnmTfA0wc1JxjoVVOrJlx8W0rGf) | 2016    |\n| 5.   | **Probabilistic Graphical Models**                           | Nicholas Zabaras, University of Notre Dame          | [PGM](https://www.zabaras.com/probabilistic-graphical-models) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLd-PuDzW85AcV4bgdu7wHPL37hm60W4RM) | 2018    |\n| 6.   | **Probabilistic Graphical Models**                           | Eric Xing, CMU                                      | [10-708](https://sailinglab.github.io/pgm-spring-2019/)      | [Lecture-Videos](https://sailinglab.github.io/pgm-spring-2019/lectures) <br> [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoZgVqqHOumTY2CAQHL45tQp6kmDnDcqn) | S2019   |\n| 7.   | **Probabilistic Graphical Models**                           | Eric Xing, CMU                                      | [10-708](https://www.cs.cmu.edu/~epxing/Class/10708-20/index.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoZgVqqHOumTqxIhcdcpOAJOOimrRCGZn) | S2020   |\n| 8.   | **Uncertainty Modeling in AI**                               | Gim Hee Lee, National University of Singapura (NUS) | [CS 5340 - CH](https://www.coursehero.com/sitemap/schools/2652-National-University-of-Singapore/courses/7821096-CS5340/), [CS 5340-NB](https://github.com/clear-nus/CS5340-notebooks) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLxg0CGqViygOb9Eyc8IXM27doxjp2SK0H) | 2020-21 |\n|      |                                                              |                                                     |                                                              |                                                              |         |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents)\n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n## :game_die: Bayesian Deep Learning :spades: :gem: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                         | University/Instructor(s)          | Course WebPage                                           | Lecture Videos                                               | Year     |\n| ---- | --------------------------------------------------- | --------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ | -------- |\n| 1.   | **Bayesian Neural Networks, Variational Inference** | Lots of Legends                   | `None`                                                   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLM4Pv4KYYzGwUB4bFy183hwGhpL9ytvA1) | 2014-now |\n| 2.   | **Variational Inference**                           | Chieh Wu, Northeastern University | `None`                                                   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLdk2fd27CQzSd1sQ3kBYL4vtv6GjXvPsE) | 2015     |\n| 3.   | **Deep Learning and Bayesian Methods**              | Lots of Legends, HSE Moscow       | [DLBM-SS](http://deepbayes.ru/2018)                      | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLe5rNUydzV9Q01vWCP9BV7NhJG3j7mz62) | 2018     |\n| 4.   | **Deep Learning and Bayesian Methods**              | Lots of Legends, HSE Moscow       | [DLBM-SS](http://deepbayes.ru/)                          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLe5rNUydzV9QHe8VDStpU0o8Yp63OecdW) | 2019     |\n| 5.   | **Nordic Probabilistic AI**                         | Lots of Legends, NTNU, Trondheim  | [ProbAI](https://github.com/probabilisticai/probai-2019) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLRy-VW__9hV8s--JkHXZvnd26KgjRP2ik) | 2019     |\n|      |                                                     |                                   |                                                          |                                                              |          |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents)\n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n## :movie_camera: Medical Imaging :camera: :video_camera: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                                  | University/Instructor(s)                    | Course WebPage                                               | Lecture Videos                                               | Year  |\n| ---- | ------------------------------------------------------------ | ------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----- |\n| 1.   | **Medical Imaging Summer School**                            | Lots of Legends, Sicily                     | [MISS-14](http://iplab.dmi.unict.it/miss14/programme.html)   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL_VeUGLULXQtvcCdAgmvKoJ1k0Ajhz-Qu) | 2014  |\n| 2.   | **Biomedical Image Analysis Summer School**                  | Lots of Legends, Paris                      | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgSHH6boFf5uJAUT4ZRiAZc_ofXolkAGK) | 2015  |\n| 3.   | **Medical Imaging Summer School**                            | Lots of Legends, Sicily                     | [MISS-16](http://iplab.dmi.unict.it/miss16/programme.html)   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLTRCr47yTx5iXIYSneX3LKf16upaw59wa) | 2016  |\n| 4.   | **OPtical and UltraSound imaging - OPUS**                    | Lots of Legends, Universit\u00e9 de Lyon, France | [OPUS'16](https://opus2016lyon.sciencesconf.org/resource/page/id/2) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL95ayoVLX8GdUKbxu-R9WqRWwzdWcKjti) | 2016  |\n| 5.   | **Medical Imaging Summer School**                            | Lots of Legends, Sicily                     | [MISS-18](http://iplab.dmi.unict.it/miss/programme.htm)      | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL_VeUGLULXQux1dV4iA3XuMX6AueJmGGa) | 2018  |\n| 6.   | **Seminar on AI in Healthcare**                              | Lots of Legends, Stanford                   | [CS 522](http://cs522.stanford.edu/2018/index.html)          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLYn-ZmPR1DtNQJ-ot-L2V2EgUEH6OH_7w) | 2018  |\n| 7.   | **Machine Learning for Healthcare**                          | David Sontag, Peter Szolovits, CSAIL MIT    | [MLHC-19](https://mlhc19mit.github.io/) <br/>[MIT 6.S897](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-s897-machine-learning-for-healthcare-spring-2019/lecture-notes/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLUl4u3cNGP60B0PQXVQyGNdCyCTDU1Q5j) | S2019 |\n| 8.   | **Deep Learning and Medical Applications**                   | Lots of Legends, IPAM, UCLA                 | [DLM-20](https://www.ipam.ucla.edu/programs/workshops/deep-learning-and-medical-applications/?tab=schedule) | [Lecture-Videos](https://www.ipam.ucla.edu/programs/workshops/deep-learning-and-medical-applications/?tab=schedule) | 2020  |\n| 9.   | **Stanford Symposium on Artificial Intelligence in Medicine and Imaging** | Lots of Legends, Stanford AIMI              | [AIMI-20](https://aimi.stanford.edu/news-events/aimi-symposium/agenda) | [YouTube-Lectures](https://www.youtube.com/watch?v=tR2ObiL4il8&list=PLe6zdIMe5B7IR0oDOobXBDBlYY1eqLYPx) | 2020  |\n|      |                                                              |                                             |                                                              |                                                              |       |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents)\n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n## :tada: Graph Neural Networks (Geometric DL) :confetti_ball: :balloon: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                                  | University/Instructor(s)                                | Course WebPage                                               | Lecture Videos                                               | Year  |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----- |\n| 1.   | **Deep learning on graphs and manifolds**                    | Michael Bronstein, Technion                             | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLH39kM3nuavcVOUIIBraBNHjv-CwEd1uV) | 2017  |\n| 2.   | **Geometric Deep Learning on Graphs and Manifolds**          | Michael Bronstein, Technische Universit\u00e4t M\u00fcnchen       | `None`                                                       | [Lec-part1](https://streams.tum.de/Mediasite/Play/1f3b894e78f6400daa7885c886b936fb1d),  <br/>[Lec-part2](https://streams.tum.de/Mediasite/Play/6039c846b2f84e7a806024c06e3f5c5c1d) | 2017  |\n| 3.   | **Eurographics Symposium on Geometry Processing - Graduate School** | Lots of Legends, SIGGRAPH, London                       | [SGP-2017](http://geometry.cs.ucl.ac.uk/SGP2017/?p=gradschool) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLOp-ngXvomHArqntgLVNzuJNdzNx3rDjZ) | 2017  |\n| 4.   | **Eurographics Symposium on Geometry Processing - Graduate School** | Lots of Legends, SIGGRAPH, Paris                        | [SGP-2018](https://sgp2018.sciencesconf.org/resource/page/id/7) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLvcoRb-DvAmgpp8LYw7dUvLxh-1Vrrm-v) | 2018  |\n| 5.   | **Analysis of Networks: Mining and Learning with Graphs**    | Jure Leskovec, Stanford University                      | [CS224W](http://snap.stanford.edu/class/cs224w-2018/)        | [Lecture-Videos](http://snap.stanford.edu/class/cs224w-2018/) | 2018  |\n| 6.   | **Machine Learning with Graphs**                             | Jure Leskovec, Stanford University                      | [CS224W](http://snap.stanford.edu/class/cs224w-2019/)        | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL-Y8zK4dwCrQyASidb2mjj_itW2-YYx6-) | 2019  |\n| 7.   | Geometry and Learning from Data in 3D and Beyond -**Geometry and Learning from Data Tutorials** | Lots of Legends, IPAM UCLA                              | [GLDT](http://www.ipam.ucla.edu/programs/workshops/geometry-and-learning-from-data-tutorials) | [Lecture-Videos](http://www.ipam.ucla.edu/programs/workshops/geometry-and-learning-from-data-tutorials/?tab=schedule) | 2019  |\n| 8.   | Geometry and Learning from Data in 3D and Beyond - **Geometric Processing** | Lots of Legends, IPAM UCLA                              | [GeoPro](http://www.ipam.ucla.edu/programs/workshops/workshop-i-geometric-processing/) | [Lecture-Videos](http://www.ipam.ucla.edu/programs/workshops/workshop-i-geometric-processing/?tab=schedule) | 2019  |\n| 9.   | Geometry and Learning from Data in 3D and Beyond - **Shape Analysis** | Lots of Legends, IPAM UCLA                              | [Shape-Analysis](http://www.ipam.ucla.edu/programs/workshops/workshop-ii-shape-analysis/) | [Lecture-Videos](http://www.ipam.ucla.edu/programs/workshops/workshop-ii-shape-analysis/?tab=schedule) | 2019  |\n| 10.  | Geometry and Learning from Data in 3D and Beyond - **Geometry of Big Data** | Lots of Legends, IPAM UCLA                              | [Geo-BData](http://www.ipam.ucla.edu/programs/workshops/workshop-iii-geometry-of-big-data) | [Lecture-Videos](http://www.ipam.ucla.edu/programs/workshops/workshop-iii-geometry-of-big-data/?tab=schedule) | 2019  |\n|      |                                                              |                                                         |                                                              |                                                              |       |\n| 11.  | Geometry and Learning from Data in 3D and Beyond - **Deep Geometric Learning of Big Data and Applications** | Lots of Legends, IPAM UCLA                              | [DGL-BData](http://www.ipam.ucla.edu/programs/workshops/workshop-iv-deep-geometric-learning-of-big-data-and-applications) | [Lecture-Videos](http://www.ipam.ucla.edu/programs/workshops/workshop-iv-deep-geometric-learning-of-big-data-and-applications/?tab=schedule) | 2019  |\n| 12.  | **Israeli Geometric Deep Learning**                          | Lots of Legends, Israel                                 | [iGDL-20](https://gdl-israel.github.io/schedule.html)        | [Lecture-Videos](https://www.youtube.com/watch?v=c8_32IVn-sg) | 2020  |\n| 13.  | **Machine Learning for Graphs and Sequential Data**          | Stephan G\u00fcnnemann, Technische Universit\u00e4t M\u00fcnchen (TUM) | [MLGS-20](https://www.in.tum.de/en/daml/teaching/summer-term-2020/machine-learning-for-graphs-and-sequential-data/) | [Lecture-Videos](https://www.in.tum.de/daml/teaching/mlgs/)  | S2020 |\n| 14.  | **Machine Learning with Graphs**                             | Jure Leskovec, Stanford                                 | [CS224W](http://web.stanford.edu/class/cs224w)               | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn) | W2021 |\n| 15.  | **Geometric Deep Learning** - AMMI                           | Lots of Legends, Virtual                                | [GDL-AMMI](https://geometricdeeplearning.com/lectures)       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLn2-dEmQeTfQ8YVuHBOvAhUlnIPYxkeu3) | 2021  |\n| 16.  | **Summer School on Geometric Deep Learning** -               | Lots of Legends, DTU, DIKU & AAU                        | [GDL- DTU, DIKU & AAU](https://geometric-deep-learning.compute.dtu.dk) | [Lecture-Videos](https://geometric-deep-learning.compute.dtu.dk/talks-and-materials) | 2021  |\n| 17.  | **Graph Neural Networks**                                    | Alejandro Ribeiro, University of Pennsylvania           | [ESE 514](https://gnn.seas.upenn.edu)                        | [YouTube-Lectures](https://www.youtube.com/channel/UC_YPrqpiEqkeGOG1TCt0giQ/playlists) | F2021 |\n|      |                                                              |                                                         |                                                              |                                                              |       |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents)\n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n### :hibiscus: Natural Language Processing :cherry_blossom: :sparkling_heart: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                         | University/Instructor(s)                                     | Course WebPage                                               | Lecture Videos                                               | Year      |\n| ---- | --------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- |\n| 1.   | **Computational Linguistics I**                     | Jordan Boyd-Graber, University of Maryland                   | [CMS-723](http://users.umiacs.umd.edu/~jbg/teaching/CMSC_723/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLegWUnz91WfuPebLI97-WueAP90JO-15i) | 2013-2018 |\n| 2.   | **Deep Learning for Natural Language Processing**   | Nils Reimers, TU Darmstadt                                   | [DL4NLP](https://github.com/UKPLab/deeplearning4nlp-tutorial) | [YouTube-Lectures](https://www.youtube.com/channel/UC1zCuTrfpjT6Sv2kJk-JkvA/videos) | 2015-2017 |\n| 3.   | **Deep Learning for Natural Language Processing**   | Many Legends, DeepMind-Oxford                                | [DL-NLP](http://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm) | 2017      |\n| 4.   | **Deep Learning for Speech & Language**             | UPC Barcelona                                                | [DL-SL](https://telecombcn-dl.github.io/2017-dlsl/)          | [Lecture-Videos](https://telecombcn-dl.github.io/2017-dlsl/) | 2017      |\n| 5.   | **Neural Networks for Natural Language Processing** | Graham Neubig, CMU                                           | [NN4NLP](http://www.phontron.com/class/nn4nlp2017/)   [Code](https://github.com/neubig/nn4nlp-code) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT) | 2017      |\n| 6.   | **Neural Networks for Natural Language Processing** | Graham Neubig, CMU                                           | [NN4-NLP](http://www.phontron.com/class/nn4nlp2018/)         | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL8PYTP1V4I8Ba7-rY4FoB4-jfuJ7VDKEE) | 2018      |\n| 7.   | **Deep Learning for NLP**                           | Min-Yen Kan, NUS                                             | [CS-6101](https://www.comp.nus.edu.sg/~kanmy/courses/6101_1810/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLllwxvcS7ca5eD44KTCiT7Rmu_hFAafXB) | 2018      |\n| 8.   | **Neural Networks for Natural Language Processing** | Graham Neubig, CMU                                           | [NN4NLP](http://www.phontron.com/class/nn4nlp2019/)          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL8PYTP1V4I8Ajj7sY6sdtmjgkt7eo2VMs) | 2019      |\n| 9.   | **Natural Language Processing with Deep Learning**  | Abigail See, Chris Manning, Richard Socher, Stanford University | [CS224n](http://web.stanford.edu/class/cs224n/)              | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z) | 2019      |\n| 10.  | **Natural Language Understanding**                  | Bill MacCartney and Christopher Potts                        | [CS224U](https://web.stanford.edu/class/cs224u)              | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20) | S2019     |\n|      |                                                     |                                                              |                                                              |                                                              |           |\n| 11.  | **Neural Networks for Natural Language Processing** | Graham Neubig, Carnegie Mellon University                    | [CS 11-747](http://www.phontron.com/class/nn4nlp2020/schedule.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL8PYTP1V4I8CJ7nMxMC8aXv8WqKYwj-aJ) | S2020     |\n| 12.  | **Advanced Natural Language Processing**            | Mohit Iyyer, UMass Amherst                                   | [CS 685](https://people.cs.umass.edu/~miyyer/cs685)          | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLWnsVgP6CzadmQX6qevbar3_vDBioWHJL) | F2020     |\n| 13.  | **Machine Translation**                             | Philipp Koehn, Johns Hopkins University                      | [EN 601.468/668](http://mt-class.org/jhu/syllabus.html)      | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLQrCiUDqDLG0lQX54o9jB4phJ-SLI6ZBQ) | F2020     |\n| 14.  | **Neural Networks for NLP**                         | Graham Neubig, Carnegie Mellon University                    | [CS 11-747](http://www.phontron.com/class/nn4nlp2021)        | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL8PYTP1V4I8AkaHEJ7lOOrlex-pcxS-XV) | 2021      |\n| 15.  | **Deep Learning for Natural Language Processing**   | Kyunghyun Cho, New York University                           | [DS-GA 1011](https://drive.google.com/drive/folders/1ykXBtophaY_65VHK_8yDzZQJwfJDD5Ve) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLdH9u0f1XKW_s-c8EcgJpn_HJz5Jj1IRf) | F2021     |\n| 16.  | **Natural Language Processing with Deep Learning**  | Chris Manning, Stanford University                           | [CS224n](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ) | 2021      |\n|      |                                                     |                                                              |                                                              |                                                              |           |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents) \n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n###  :speaking_head: Automatic Speech Recognition :speech_balloon: :thought_balloon:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                              | University/Instructor(s)       | Course WebPage                                      | Lecture Videos                                               | Year      |\n| ---- | ---------------------------------------- | ------------------------------ | --------------------------------------------------- | ------------------------------------------------------------ | --------- |\n| 1.   | **Deep Learning for Speech & Language**  | UPC Barcelona                  | [DL-SL](https://telecombcn-dl.github.io/2017-dlsl/) | [Lecture-Videos](https://telecombcn-dl.github.io/2017-dlsl/) <br/> [YouTube-Videos](https://www.youtube.com/playlist?list=PL-5DCZHuHZkWeF9ljIjoC_X5gHRLNtIkU) | 2017      |\n| 2.   | **Speech and Audio in the Northeast**    | Many Legends, Google NYC       | [SANE-15](http://www.saneworkshop.org/sane2015/)    | [YouTube-Videos](https://www.youtube.com/playlist?list=PLBJWRPcgwk7sZOB4UTVilWWnRg84L9o5i) | 2015      |\n| 3.   | **Automatic Speech Recognition**         | Samudra Vijaya K, TIFR         | `None`                                              | [YouTube-Videos](https://www.youtube.com/channel/UCHk6uq1Cr9J3k5KNmIsYUNw/videos) | 2016      |\n| 4.   | **Speech and Audio in the Northeast**    | Many Legends, Google NYC       | [SANE-17](http://www.saneworkshop.org/sane2017/)    | [YouTube-Videos](https://www.youtube.com/playlist?list=PLBJWRPcgwk7tNLaBVu_S90ZQSblO3bwjg) | 2017      |\n| 5.   | **Speech and Audio in the Northeast**    | Many Legends, Google Cambridge | [SANE-18](http://www.saneworkshop.org/sane2018/)    | [YouTube-Videos](https://www.youtube.com/playlist?list=PLBJWRPcgwk7sjMANn8jqosyHIMe6DJhmn) | 2018      |\n|      |                                          |                                |                                                     |                                                              |           |\n| -1.  | **Deep Learning for Speech Recognition** | Many Legends, AoE              | `None`                                              | [YouTube-Videos](https://www.youtube.com/playlist?list=PLM4Pv4KYYzGyFYCXV6YPWAKVOR2gmHnQd) | 2015-2018 |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents) \n\n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n### :fire: Modern Computer Vision :camera_flash: :movie_camera: \n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                                  | University/Instructor(s)                               | Course WebPage                                               | Lecture Videos                                               | Year       |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------- |\n| 1.   | **Microsoft Computer Vision Summer School** - (classical)    | Lots of Legends, Lomonosov Moscow State University     | `None`                                                       | [YouTube-Videos](https://www.youtube.com/playlist?list=PLbwKcm5vdiSYU54xFUG1zoxQTulqvIcJu) <br> [Russian-mirror](https://www.youtube.com/playlist?list=PL-_cKNuVAYAUp0eCL7KO8QY4ETY3tIDFH) | 2011       |\n| 2.   | **Computer Vision** - (classical)                            | Mubarak Shah, UCF                                      | [CAP-5415](http://crcv.ucf.edu/courses/CAP5415/Fall2012/index.php) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLd3hlSJsX_Imk_BPmB_H3AQjFKZS9XgZm) | 2012       |\n| 3.   | **Image and Multidimensional Signal Processing** - (classical) | William Hoff, Colorado School of Mines                 | [CSCI 510/EENG 510](http://inside.mines.edu/~whoff/courses/EENG510) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLyED3W677ALNv8Htn0f9Xh-AHe1aZPftv) | 2012       |\n| 4.   | **Computer Vision** - (classical)                            | William Hoff, Colorado School of Mines                 | [CSCI 512/EENG 512](http://inside.mines.edu/~whoff/courses/EENG512/index.htm) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL4B3F8D4A5CAD8DA3) | 2012       |\n| 5.   | **Image and Video Processing: From Mars to Hollywood with a Stop at the Hospital** | Guillermo Sapiro, Duke University                      | `None`                                                       | [YouTube-Videos](https://www.youtube.com/playlist?list=PLZ9qNFMHZ-A79y1StvUUqgyL-O0fZh2rs) | 2013       |\n| 6.   | **Multiple View Geometry** (classical)                       | Daniel Cremers, Technische Universit\u00e4t M\u00fcnchen         | [mvg](https://vision.in.tum.de/teaching/ss2014/mvg2014)      | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLTBdjV_4f-EJn6udZ34tht9EVIW7lbeo4) | 2013       |\n| 7.   | **Mathematical Methods for Robotics, Vision, and Graphics**  | Justin Solomon, Stanford University                    | [CS-205A](http://graphics.stanford.edu/courses/cs205a/)      | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLQ3UicqQtfNvQ_VzflHYKhAqZiTxOkSwi) | 2013       |\n| 8.   | **Computer Vision** - (classical)                            | Mubarak Shah, UCF                                      | [CAP-5415](http://crcv.ucf.edu/courses/CAP5415/Fall2014/index.php) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLd3hlSJsX_ImKP68wfKZJVIPTd8Ie5u-9) | 2014       |\n| 9.   | **Computer Vision for Visual Effects** (classical)           | Rich Radke, Rensselaer Polytechnic Institute           | [ECSE-6969](https://www.ecse.rpi.edu/~rjradke/cvfxcourse.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLuh62Q4Sv7BUJlKlt84HFqSWfW36MDd5a) | S2014      |\n| 10.  | **Autonomous Navigation for Flying Robots**                  | Juergen Sturm, Technische Universit\u00e4t M\u00fcnchen          | [Autonavx](https://jsturm.de/wp/teaching/autonavx-slides/)   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLTBdjV_4f-EKBCUs1HmMtsnXv4JUoFrzg) | 2014       |\n|      |                                                              |                                                        |                                                              |                                                              |            |\n| 11.  | **SLAM - Mobile Robotics**                                   | Cyrill Stachniss, Universitaet Freiburg                | [RobotMapping](http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQrZ4O5QzbIHgl3b1JHimN_) | 2014       |\n| 12.  | **Computational Photography**                                | Irfan Essa, David Joyner, Arpan Chakraborty            | [CP-Udacity](https://eu.udacity.com/course/computational-photography--ud955) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLAwxTw4SYaPn-unAWtRMleY4peSe4OzIY) | 2015       |\n| 13.  | **Introduction to Digital Image Processing**                 | Rich Radke, Rensselaer Polytechnic Institute           | [ECSE-4540](https://www.ecse.rpi.edu/~rjradke/improccourse.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLuh62Q4Sv7BUf60vkjePfcOQc8sHxmnDX) | S2015      |\n| 14.  | **Lectures on Digital Photography**                          | Marc Levoy, Stanford/Google Research                   | [LoDP](https://sites.google.com/site/marclevoylectures/)     | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL7ddpXYvFXspUN0N-gObF1GXoCA-DA-7i) | 2016       |\n| 15.  | **Introduction to Computer Vision** (foundation)             | Aaron Bobick, Irfan Essa, Arpan Chakraborty            | [CV-Udacity](https://eu.udacity.com/course/introduction-to-computer-vision--ud810) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLAwxTw4SYaPnbDacyrK_kB_RUkuxQBlCm) | 2016       |\n| 16.  | **Computer Vision**                                          | Syed Afaq Ali Shah, University of Western Australia    | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLvqB6_mDBCdlnT84LK_NvbOqcXLlOTR8j) | 2016       |\n| 17.  | **Photogrammetry I & II**                                    | Cyrill Stachniss, University of Bonn                   | [PG-I&II](https://www.ipb.uni-bonn.de/photogrammetry-i-ii/)  | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgnQpQtFTOGRsi5vzy9PiQpNWHjq-bKN1) | 2016       |\n| 18.  | **Deep Learning for Computer Vision**                        | UPC Barcelona                                          | [DLCV-16](http://imatge-upc.github.io/telecombcn-2016-dlcv/) <br/> [DLCV-17](https://telecombcn-dl.github.io/2017-dlcv/) <br/> [DLCV-18](https://telecombcn-dl.github.io/2018-dlcv/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL-5eMc3HQTBbuaTFP4wsfD2Y2VqEfQcaP) | 2016-2018  |\n| 19.  | **Convolutional Neural Networks**                            | Andrew Ng, Stanford University                         | [DeepLearning.AI](https://www.deeplearning.ai/deep-learning-specialization/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF) | 2017       |\n| 20.  | **Variational Methods for Computer Vision**                  | Daniel Cremers, Technische Universit\u00e4t M\u00fcnchen         | [VMCV](https://vision.in.tum.de/teaching/ws2016/vmcv2016)    | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLTBdjV_4f-EJ7A2iIH5L5ztqqrWYjP2RI) | 2017       |\n|      |                                                              |                                                        |                                                              |                                                              |            |\n| 21.  | **Winter School on Computer Vision**                         | Lots of Legends, Israel Institute for Advanced Studies | [WS-CV](http://www.as.huji.ac.il/cse)                        | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLTn74Qx5mPsSniA5tt6W-o0OGYEeKScug) | 2017       |\n| 22.  | **Deep Learning for Visual Computing**                       | Debdoot Sheet, IIT-Kgp                                 | [Nptel](https://onlinecourses.nptel.ac.in/noc18_ee08/preview)  [Notebooks](https://github.com/iitkliv/dlvcnptel) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLuv3GM6-gsE1Biyakccxb3FAn4wBLyfWf) | 2018       |\n| 23.  | **The Ancient Secrets of Computer Vision**                   | Joseph Redmon, Ali Farhadi                             | [TASCV](https://pjreddie.com/courses/computer-vision/) ; [TASCV-UW](https://courses.cs.washington.edu/courses/cse455/18sp/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLjMXczUzEYcHvw5YYSU92WrY8IwhTuq7p) | 2018       |\n| 24.  | **Modern Robotics**                                          | Kevin Lynch, Northwestern Robotics                     | [modern-robot](http://hades.mech.northwestern.edu/index.php/Modern_Robotics) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLggLP4f-rq02vX0OQQ5vrCxbJrzamYDfx) | 2018       |\n| 25.  | **Digial Image Processing**                                  | Alex Bronstein, Technion                               | [CS236860](https://vistalab-technion.github.io/cs236860/info/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLM0a6Z788YAZOxUyWda9y3N_i2upIj1Ep) | 2018       |\n| 26.  | **Mathematics of Imaging** - Variational Methods and Optimization in Imaging | Lots of Legends, Institut Henri Poincar\u00e9               | [Workshop-1](http://www.ihp.fr/sites/default/files/conf1-04_au_08_fevr-imaging2019.pdf) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL9kd4mpdvWcAzD5Aq-P1TrLLiYckrloxw) | 2019       |\n| 27.  | **Deep Learning for Video**                                  | Xavier Gir\u00f3, UPC Barcelona                             | [deepvideo](https://mcv-m6-video.github.io/deepvideo-2019/)  | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL-5eMc3HQTBbPY-627Gornj09pZrNQgPD) | 2019       |\n| 28.  | **Statistical modeling for shapes and imaging**              | Lots of Legends, Institut Henri Poincar\u00e9, Paris        | [workshop-2](https://imaging-in-paris.github.io/semester2019/workshop2prog) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL9kd4mpdvWcAzD5Aq-P1TrLLiYckrloxw) | 2019       |\n| 29.  | **Imaging and machine learning**                             | Lots of Legends, Institut Henri Poincar\u00e9, Paris        | [workshop-3](https://imaging-in-paris.github.io/semester2019/workshop3prog) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL9kd4mpdvWcAzD5Aq-P1TrLLiYckrloxw) | 2019       |\n| 30.  | **Computer Vision**                                          | Jayanta Mukhopadhyay, IIT Kgp                          | [CV-nptel](https://nptel.ac.in/courses/106/105/106105216/)   | [YouTube-Lectures](https://nptel.ac.in/courses/106/105/106105216/) | 2019       |\n|      |                                                              |                                                        |                                                              |                                                              |            |\n| 31.  | **Deep Learning for Computer Vision**                        | Justin Johnson, UMichigan                              | [EECS 498-007](https://web.eecs.umich.edu/~justincj/teaching/eecs498/) | [Lecture-Videos](http://leccap.engin.umich.edu/leccap/site/jhygcph151x25gjj1f0) <br/> [YouTube-Lectures](https://www.youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r) | 2019       |\n| 32.  | **Sensors and State Estimation 2**                           | Cyrill Stachniss, University of Bonn                   | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQh_J16IMwDlji18SWQ2PZ6) | S2020      |\n| 33.  | **Computer Vision III: Detection, Segmentation and Tracking** | Laura Leal-Taix\u00e9, TU M\u00fcnchen                           | [CV3DST](https://dvl.in.tum.de/teaching/cv3dst-ss20/)        | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLog3nOPCjKBneGyffEktlXXMfv1OtKmCs) | S2020      |\n| 34.  | **Advanced Deep Learning for Computer Vision**               | Laura Leal-Taix\u00e9 and Matthias Nie\u00dfner, TU M\u00fcnchen      | [ADL4CV](https://dvl.in.tum.de/teaching/adl4cv-ss20)         | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39) | S2020      |\n| 35.  | **Computer Vision: Foundations**                             | Fred Hamprecht, Universit\u00e4t Heidelberg                 | [CVF](https://hci.iwr.uni-heidelberg.de/ial/cvf)             | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLuRaSnb3n4kRAbnmiyGd77hyoGzO9wPde) | SS2020     |\n| 36.  | **MIT Vision Seminar**                                       | Lots of Legends, MIT                                   | [MIT-Vision](https://sites.google.com/view/visionseminar/past-talks) | [YouTube-Lectures](https://www.youtube.com/channel/UCLMiFkFyfcNnZs6iwYLPI9g/videos) | 2015-now   |\n| 37.  | **TUM AI Guest Lectures**                                    | Lots of Legends, Technische Universit\u00e4t M\u00fcnchen        | [TUM-AI](https://niessner.github.io/TUM-AI-Lecture-Series)   | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLQ8Y4kIIbzy8kMlz7cRqz-BjbdyWsfLXt) | 2020 - now |\n| 38.  | **Seminar on 3D Geometry & Vision**                          | Lots of Legends, Virtual                               | [3DGV seminar](https://3dgv.github.io)                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLZk0jtN0g8e-xVTfsiV67q8Iz1cZO_FpV) | 2020 - now |\n| 39.  | **Event-based Robot Vision**                                 | Guillermo Gallego, Technische Universit\u00e4t Berlin       | [EVIS-SS20](https://sites.google.com/view/guillermogallego/teaching/event-based-robot-vision) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL03Gm3nZjVgUFYUh3v5x8jVonjrGfcal8) | 2020 - now |\n| 40.  | **Deep Learning for Computer Vision**                        | Vineeth Balasubramanian, IIT Hyderabad                 | [DL-CV'20](https://onlinecourses.nptel.ac.in/noc20_cs88/preview) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLyqSpQzTE6M_PI-rIz4O1jEgffhJU9GgG) | 2020       |\n|      |                                                              |                                                        |                                                              |                                                              |            |\n| 41.  | **Deep Learning for Visual Computing**                       | Peter Wonka, KAUST, SA                                 | `NOne`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLMpQLEui13s2DHbw6kTTxwQma8rehlfZE) | 2020       |\n| 42.  | **Computer Vision**                                          | Yogesh Rawat, University of Central Florida            | [CAP5415-CV](https://www.crcv.ucf.edu/courses/cap5415-fall-2020/schedule/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLd3hlSJsX_Ikm5il1HgmDB_z62BeoikFX) | F2020      |\n| 43.  | **Multimedia Signal Processing**                             | Mark Hasegawa-Johnson, UIUC                            | [ECE-417 MSP](https://courses.engr.illinois.edu/ece417/fa2020/) | [Lecture Videos](https://mediaspace.illinois.edu/channel/ECE%20417/26816181) | F2020      |\n| 44.  | **Computer Vision**                                          | Andreas Geiger, Universit\u00e4t T\u00fcbingen                   | [Comp.Vis](https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/autonomous-vision/lectures/computer-vision/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL05umP7R6ij35L2MHGzis8AEHz7mg381_) | S2021      |\n| 45.  | **3D Computer Vision**                                       | Lee Gim Hee, National Univeristy of Singapura          | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLxg0CGqViygP47ERvqHw_v7FVnUovJeaz) | 2021       |\n| 46.  | **Deep Learning for Computer Vision: Fundamentals and Applications** | T. Dekel et al., Weizmann Institute of Science         | [DL4CV](https://dl4cv.github.io/schedule.html)               | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL_Z2_U9MIJdNgFM7-f2fZ9ZxjVRP_jhJv) | S2021      |\n| 47.  | **Current Topics in ML Methods in 3D and Geometric Deep Learning** | Animesh Garg  & others, University of Toronto          | [CSC 2547](http://www.pair.toronto.edu/csc2547-w21)          | [YouTube-Lectures](https://www.youtube.com/channel/UCrsmAXnwu6sgccWevW12Dfg/videos) | 2021       |\n| 48.  | **First Principles of Computer Vision**                      | Shree K. Nayar, Columbia University                    | [FPCV](https://fpcv.cs.columbia.edu)                         | [YouTube-Lectures](https://www.youtube.com/channel/UCf0WB91t8Ky6AuYcQV0CcLw/videos) | 2021       |\n| 49.  | **Self-Driving Cars**                                        | Andreas Geiger, Universit\u00e4t T\u00fcbingen                   | [SDC'21](https://uni-tuebingen.de/de/123611)                 | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL05umP7R6ij321zzKXK6XCQXAaaYjQbzr) | W2021      |\n|      |                                                              |                                                        |                                                              |                                                              |            |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents) \n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n### :star2: Boot Camps or Summer Schools :maple_leaf:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                                             | University/Instructor(s)                                 | Course WebPage                                               | Lecture Videos                                               | Year      |\n| ---- | ------------------------------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- |\n| 1.   | **Deep Learning, Feature Learning**                     | Lots of Legends, IPAM UCLA                               | [GSS-2012](https://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-deep-learning-feature-learning/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLHyI3Fbmv0SdzMHAy0aN59oYnLy5vyyTA) | 2012      |\n| 2.   | **Big Data Boot Camp**                                  | Lots of Legends, Simons Institute                    | [Big Data](https://simons.berkeley.edu/workshops/schedule/316) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgKuh-lKre13RmUC2AybRvVAxO5DEMIBH) | 2013      |\n| 3. | **Machine Learning Summer School** | Lots of Legends, MPI-IS T\u00fcbingen | [MLSS-13](http://mlss.tuebingen.mpg.de/2013/2013/index.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLqJm7Rc5-EXFv6RXaPZzzlzo93Hl0v91E) | 2013 |\n| 4 | **Graduate Summer School: Computer Vision** | Lots of Legends, IPAM-UCLA | [GSS-CV](http://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-computer-vision/) | [Video-Lectures](http://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-computer-vision/?tab=schedule) | 2013 |\n| 5. | **Machine Learning Summer School** | Lots of Legends, Reykjavik University | [MLSS-14](http://mlss2014.hiit.fi/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLqdbxUnkqOw2nKn7VxYqIrKWcqRkQYOsF) | 2014 |\n| 6. | **Machine Learning Summer School** | Lots of Legends, Pittsburgh | [MLSS-14](http://www.mlss2014.com) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLZSO_6-bSqHQCIYxE3ycGLXHMjK3XV7Iz) | 2014 |\n| 7. | **Deep Learning Summer School** | Lots of Legends, Universit\u00e9 de Montr\u00e9al | [DLSS-15](https://sites.google.com/site/deeplearningsummerschool/home) | [YouTube-Lectures](http://videolectures.net/deeplearning2015_montreal/) | 2015 |\n| 8. | **Biomedical Image Analysis Summer School** | Lots of Legends, CentraleSupelec, Paris | `None` | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgSHH6boFf5uJAUT4ZRiAZc_ofXolkAGK) | 2015 |\n| 9. | **Mathematics of Signal Processing**                    | Lots of Legends, Hausdorff Institute for Mathematics | [SigProc](http://www.him.uni-bonn.de/signal-processing-2016/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLul8LCT3AJqSQo3lr5RbwxJ92RsgRuDtx) | 2016      |\n| 10. | **Microsoft Research - Machine Learning Course**        | S V N Vishwanathan and Prateek Jain MS-Research          | `None`                                                       | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL34iyE0uXtxo7vPXGFkmm6KbgZQwjf9Kf) | 2016      |\n|  |  |  |  |  |  |\n| 11. | **Deep Learning Summer School**                         | Lots of Legends, Universit\u00e9 de Montr\u00e9al                  | [DL-SS-16](https://sites.google.com/site/deeplearningsummerschool2016/home) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL5bqIc6XopCbb-FvnHmD1neVlQKwGzQyR) | 2016      |\n| 12. | **Lisbon Machine Learning School** | Lots of Legends, Instituto Superior T\u00e9cnico, Portugal | [LxMLS-16](http://lxmls.it.pt/2016/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLToLj8M4ao-fymxXBIOU6sF1NGFLb5EiX) | 2016 |\n| 13. | **Machine Learning Advances and Applications Seminar**  | Lots of Legends, Fields Institute, University of Toronto | [MLAAS-16](http://www.fields.utoronto.ca/activities/16-17/machine-learning) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLfsVAYSMwskuQcRkuDApP40lX_i08d0QK) <br/> [Video-Lectures](http://www.fields.utoronto.ca/video-archive/event/2267) | 2016-2017 |\n| 14. | **Machine Learning Advances and Applications Seminar**  | Lots of Legends, Fields Institute, University of Toronto | [MLAAS-17](http://www.fields.utoronto.ca/activities/17-18/machine-learning) | [Video Lectures](http://www.fields.utoronto.ca/video-archive/event/2487) | 2017-2018 |\n| 15. | **Machine Learning Summer School** | Lots of Legends, MPI-IS T\u00fcbingen | [MLSS-17](http://mlss.tuebingen.mpg.de/2017/index.html) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLqJm7Rc5-EXFUOvoYCdKikfck8YeUCnl9) | 2017 |\n| 16. | **Representation Learning**                             | Lots of Legends, Simons Institute                    | [RepLearn](https://simons.berkeley.edu/workshops/abstracts/3750) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgKuh-lKre13UNV4ztsWUXciUZ7x_ZDHz) | 2017      |\n| 17. | **Foundations of Machine Learning**                     | Lots of Legends, Simons Institute                  | [ML-BootCamp](https://simons.berkeley.edu/workshops/abstracts/3748) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgKuh-lKre11GbZWneln-VZDLHyejO7YD) | 2017      |\n| 18. | **Optimization, Statistics, and Uncertainty**           | Lots of Legends, Simons Institute                    | [Optim-Stats](https://simons.berkeley.edu/workshops/abstracts/4795) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgKuh-lKre13ACD44z2FH-IVP1e8ip5JO) | 2017      |\n| 19. | **Deep Learning: Theory, Algorithms, and Applications** | Lots of Legends, TU-Berlin                         | [DL: TAA](http://doc.ml.tu-berlin.de/dlworkshop2017/)        | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLJOzdkh8T5kqCNV_v1w2tapvtJDZYiohW) | 2017      |\n| 20. | **Deep Learning and Reinforcement Learning Summer School** | Lots of Legends, Universit\u00e9 de Montr\u00e9al                                   | [DLRL-2017](https://mila.quebec/en/cours/deep-learning-summer-school-2017/)   | [Lecture-videos](http://videolectures.net/deeplearning2017_montreal/)          | 2017 |\n|  |  |  |  |  |  |\n| 21. | **Statistical Physics Methods in Machine Learning** | Lots of Legends, International Centre for Theoretical Sciences, TIFR | [SPMML](https://www.icts.res.in/discussion-meeting/SPMML2017) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL04QVxpjcnjhtL3IIVyFRMOgdhWtPn7YJ) | 2017 |\n| 22. | **Lisbon Machine Learning School** | Lots of Legends, Instituto Superior T\u00e9cnico, Portugal | [LxMLS-17](http://lxmls.it.pt/2017/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLToLj8M4ao-fuRfnzEJCCnvuW2_FeJ73N) | 2017 |\n| 23. | **Interactive Learning** | Lots of Legends, Simons Institute, Berkeley | [IL-2017](https://simons.berkeley.edu/workshops/schedule/3749) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgKuh-lKre10T2POF-WzXh0ckdpyvANUx) | 2017 |\n| 24. | **Computational Challenges in Machine Learning** | Lots of Legends, Simons Institute, Berkeley | [CCML-17](https://simons.berkeley.edu/workshops/schedule/3751) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgKuh-lKre12eXz4dnvc8oervo2_Af4iU) | 2017 |\n| 25. | **Foundations of Data Science**                         | Lots of Legends, Simons Institute                   | [DS-BootCamp](https://simons.berkeley.edu/workshops/abstracts/6680) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgKuh-lKre13r1Qrnrejj3f498-NurSf3) | 2018      |\n| 26. | **Deep Learning and Bayesian Methods**           | Lots of Legends, HSE Moscow                          | [DLBM-SS](http://deepbayes.ru/2018/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLe5rNUydzV9Q01vWCP9BV7NhJG3j7mz62) | 2018      |\n| 27. | **New Deep Learning Techniques**                        | Lots of Legends, IPAM UCLA                           | [IPAM-Workshop](https://www.ipam.ucla.edu/programs/workshops/new-deep-learning-techniques/?tab=schedule) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLHyI3Fbmv0SdM0zXj31HWjG9t9Q0v2xYN) | 2018      |\n| 28. | **Deep Learning and Reinforcement Learning Summer School** | Lots of Legends, University of Toronto | [DLRL-2018](https://dlrlsummerschool.ca/2018-event/) | [Lecture-videos](http://videolectures.net/DLRLsummerschool2018_toronto/) | 2018 |\n| 29. | **Machine Learning Summer School** | Lots of Legends, Universidad Aut\u00f3noma de Madrid, Spain | [MLSS-18](http://mlss.ii.uam.es/mlss2018/index.html) | [YouTube-Lectures](https://www.youtube.com/channel/UCbPJHr__eIor_7jFH3HmVHQ/videos) <br/> [Course-videos](http://mlss.ii.uam.es/mlss2018/speakers.html) | 2018 |\n| 30. | **Theoretical Basis of Machine Learning** | Lots of Legends, International Centre for Theoretical Sciences, TIFR | [TBML-18](https://www.icts.res.in/discussion-meeting/tbml2018) | [Lecture-Videos](https://www.icts.res.in/discussion-meeting/tbml2018/talks) <br/> [YouTube-Videos](https://www.youtube.com/playlist?list=PL04QVxpjcnjj1DgnXxFBo2fkSju4r-ggr) | 2018 |\n|  |  |  |  |  |  |\n| 31. | **Polish View on Machine Learning** | Lots of Legends, Warsaw | [PLinML-18](https://plinml.mimuw.edu.pl/) | [YouTube-Videos](https://www.youtube.com/playlist?list=PLoaWrlj9TDhPcA6N9dZQ6GPXboYuumDRp) | 2018 |\n| 32. | **Big Data Analysis in Astronomy** | Lots of Legends, Tenerife | [BDAA-18](http://research.iac.es/winterschool/2018/pages/book-ws2018.php) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLM4Pv4KYYzGx42W5pSp3Itetp0u-PENtI) | 2018 |\n| 33. | **Machine Learning Advances and Applications Seminar**  | Lots of Legends, Fields Institute, University of Toronto | [MLASS](http://www.fields.utoronto.ca/activities/18-19/machine-learning) | [Video Lectures](http://www.fields.utoronto.ca/video-archive/event/2681) | 2018-2019 |\n| 34. | **MIFODS- ML, Stats, ToC seminar**                      | Lots of Legends, MIT                                     | [MIFODS-seminar](http://mifods.mit.edu/seminar.php)          | [Lecture-videos](http://mifods.mit.edu/seminar.php)          | 2018-2019 |\n| 35. | **Learning Machines Seminar Series** | Lots of Legends, Cornell Tech | [LMSS](https://lmss.tech.cornell.edu/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLycW2Yy79JuxbQZ9uHEu_NS3cGNomhL2A) | 2018-now |\n| 36. | **Machine Learning Summer School** | Lots of Legends, South Africa | [MLSS'19](https://mlssafrica.com/programme-schedule/) | [YouTube-Lectures](https://www.youtube.com/channel/UC722CmQVgcLtxt_jXr3RyWg/videos) | 2019 |\n| 37. | **Deep Learning Boot Camp** | Lots of Legends, Simons Institute, Berkeley | [DLBC-19](https://simons.berkeley.edu/workshops/schedule/10624) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgKuh-lKre12c2Il9mNX0Cmp9Z4oFNrQh) | 2019 |\n| 38. | **Frontiers of Deep Learning** | Lots of Legends, Simons Institute, Berkeley | [FoDL-19](https://simons.berkeley.edu/workshops/schedule/10627) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgKuh-lKre11ekU7g-Z_qsvjDD8cT-hi9) | 2019 |\n| 39. | **Mathematics of data: Structured representations for sensing, approximation and learning** | Lots of Legends, The Alan Turing Institute, London | [MoD-19](https://www.turing.ac.uk/sites/default/files/2019-05/agenda_9_3.pdf) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLuD_SqLtxSdX_w1Ztexpzl_EJgFQSkWez) | 2019 |\n| 40. | **Deep Learning and Bayesian Methods** | Lots of Legends, HSE Moscow | [DLBM-SS](http://deepbayes.ru/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLe5rNUydzV9QHe8VDStpU0o8Yp63OecdW) | 2019 |\n|  |  |  |  |  |  |\n| 41. | **The Mathematics of Deep Learning and Data Science** | Lots of Legends, Isaac Newton Institute, Cambridge | [MoDL-DS](https://gateway.newton.ac.uk/event/ofbw46) | [Lecture-Videos](https://gateway.newton.ac.uk/event/ofbw46/programme) | 2019 |\n| 42. | **Geometry of Deep Learning** | Lots of Legends, MSR Redmond | [GoDL](https://www.microsoft.com/en-us/research/event/ai-institute-2019) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLD7HFcN7LXRe30qq36It2XCljxc340O_d) | 2019 |\n| 43. | **Deep Learning for Science School** | Many folks, LBNL, Berkeley | [DLfSS](https://dl4sci-school.lbl.gov/agenda) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL20S5EeApOSvfvEyhCPOUzU7zkBcR5-eL) | 2019 |\n| 44. | **Emerging Challenges in Deep Learning** | Lots of Legends, Simons Institute, Berkeley | [ECDL](https://simons.berkeley.edu/workshops/schedule/10629) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLgKuh-lKre10BpafDrv0fg2VNUweWXWVd) | 2019 |\n| 45. | **Full Stack Deep Learning** | Pieter Abbeel and many others, UC Berkeley | [FSDL-M19](https://fullstackdeeplearning.com/march2019) | [YouTube-Lectures-Day-1](https://www.youtube.com/playlist?list=PL1T8fO7ArWlcf3Hc4VMEVBlH8HZm_NbeB) <br/> [Day-2](https://www.youtube.com/playlist?list=PL1T8fO7ArWlf6TWwdstb-PcwlubnlrKrm) | 2019 |\n| 46. | **Algorithmic and Theoretical aspects of Machine Learning** | Lots of legends, IIIT-Bengaluru | [ACM-ML](https://india.acm.org/education/machine-learning) <br/> [nptel](https://nptel.ac.in/courses/128/106/128106011/) | [YouTube-Lectures](https://nptel.ac.in/courses/128/106/128106011) | 2019 |\n| 47. | **Deep Learning and Reinforcement Learning Summer School** | Lots of Legends, AMII, Edmonton, Canada | [DLRL-2019](https://dlrlsummerschool.ca/past-years) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLKlhhkvvU8-aXmPQZNYG_e-2nTd0tJE8v) | 2019 |\n| 48. | **Mathematics of Machine Learning** - Summer Graduate School | Lots of Legends, University of Washington | [MoML-SGS](http://www.msri.org/summer_schools/866#schedule), [MoML-SS](http://mathofml.cs.washington.edu/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLTPQEx-31JXhguCush5J7OGnEORofoCW9) | 2019 |\n| 49. | **Workshop on Theory of Deep Learning: Where next?** | Lots of Legends, IAS, Princeton University | [WTDL](https://www.math.ias.edu/wtdl) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLdDZb3TwJPZ5dqqg_S-rgJqSFeH4DQqFQ) | 2019 |\n| 50. | **Computational Vision Summer School** | Lots of Legends, Black Forest, Germany | [CVSS-2019](http://orga.cvss.cc/program-cvss-2019/) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLeCNfJWZKqxsvidOlVLtWq9s7sIsX1QTC) | 2019 |\n| | | | | | |\n| 51. | **Learning under complex structure** | Lots of Legends, MIT | [LUCS](https://mifods.mit.edu/complex.php) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLM4Pv4KYYzGwhIHcaY6zYR7M9hhFO4Vud) | 2020 |\n| 52. | **Machine Learning Summer School** | Lots of Legends, MPI-IS T\u00fcbingen (virtual) | [MLSS](http://mlss.tuebingen.mpg.de/2020/schedule.html) | [YouTube-Lectures](https://www.youtube.com/channel/UCBOgpkDhQuYeVVjuzS5Wtxw/videos) | SS2020 |\n| 53. | **Eastern European Machine Learning Summer School** | Lots of Legends, Krak\u00f3w, Poland (virtual) | [EEML](https://www.eeml.eu/program) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLaKY4p4V3gE1j01FOY2FeglV4jRntQj84) | S2020 |\n| 54. | **Lisbon Machine Learning Summer School** | Lots of Legends, Lisbon, Portugal (virtual) | [LxMLS](http://lxmls.it.pt/2020/?page_id=19) | [YouTube-Lectures](https://www.youtube.com/channel/UCkVFZWgT1jR75UvSLGP9_mw) | S2020 |\n| 55. | **Workshop on New Directions in Optimization, Statistics and Machine Learning** | Lots of Legends,  Institute of Advanced Study, Princeton | [ML-Opt new dir.](https://www.ias.edu/video/workshop/2020/0415-16) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLdDZb3TwJPZ4Ri6i0MIdesIEpYK4lx17Q) | 2020 |\n| 56. | **Mediterranean Machine Learning School** | Lots of Legends, Italy (virtual) | [M2L-school](https://www.m2lschool.org/talks) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLF-wkqRv4u1YRbfnwN8cXXyrmXld-sked) | 2021 |\n| 57. | **Mathematics of Machine Learning - One World Seminar** | Lots of Legends, Virtual | [1W-ML](https://sites.google.com/view/oneworldml/past-events) | [YouTube-Lectures](https://www.youtube.com/channel/UCz7WlgXs20CzugkfxhFCNFg/videos) | 2020 - now |\n| 58. | **Deep Learning Theory Summer School** | Lots of Legends, Princeton University (virtual) | [DLT'21](https://deep-learning-summer-school.princeton.edu) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PL2mB9GGlueJj_FNjJ8RWgz4Nc_hCSXfMU) | 2021 |\n| | | | | | |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents)\n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n### :bird: Bird's Eye view of A(G)I :eagle:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n| S.No | Course Name                            | University/Instructor(s)                                 | Course WebPage                                               | Lecture Videos                                               | Year      |\n| ---- | -------------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- |\n| 1.   | **Artificial General Intelligence**    | Lots of Legends, MIT                                     | [6.S099-AGI](https://agi.mit.edu/)                           | [Lecture-Videos](https://agi.mit.edu/)                       | 2018-2019 |\n| 2.   | **AI Podcast**                         | Lots of Legends, MIT                                     | [AI-Pod](https://lexfridman.com/ai/)                         | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLrAXtmErZgOdP_8GztsuKi9nrraNbKKp4) | 2018-2019 |\n| 3.   | **NYU - AI Seminars**                  | Lots of Legends, NYU                                     | [modern-AI](https://engineering.nyu.edu/academics/departments/electrical-and-computer-engineering/ece-seminar-series/modern-artificial) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLhwo5ntex8iY9xhpSwWas451NgVuqBE7U) | 2017-now  |\n| 4.   | **Deep Learning: Alchemy or Science?** | Lots of Legends, Institute for Advanced Study, Princeton | [DLAS](https://video.ias.edu/deeplearning/2019/0222) <br/> [Agenda](https://www.math.ias.edu/tml/dlasagenda) | [YouTube-Lectures](https://www.youtube.com/playlist?list=PLdDZb3TwJPZ7aAxhIHALBoh8l6-UxmMNP) | 2019      |\n|      |                                        |                                                          |                                                              |                                                              |           |\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents)\n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n### To-Do :running:\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n:white_large_square: Optimization courses which form the foundation for ML, DL, RL\n\n:white_large_square: Computer Vision courses which are DL & ML heavy\n\n:white_large_square: Speech recognition courses which are DL heavy\n\n:white_large_square: Structured Courses on Geometric, Graph Neural Networks\n\n:white_large_square: Section on Autonomous Vehicles\n\n:white_large_square: Section on Computer Graphics with ML/DL focus\n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n[Go to Contents :arrow_heading_up:](https://github.com/kmario23/deep-learning-drizzle#contents) \n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n\n### Around the Web :earth_asia:\n\n - [Montreal.AI](http://www.montreal.ai/ai4all.pdf)\n - [UPC-DLAI-2018](https://telecombcn-dl.github.io/2018-dlai/)\n - [UPC-DLAI-2019](https://telecombcn-dl.github.io/dlai-2019/)\n - [www.hashtagtechgeek.com](https://www.hashtagtechgeek.com/2019/10/250-machine-learning-deep-learning-videos-courseware.html)\n - [UPC-Barcelona, IDL-2020](https://telecombcn-dl.github.io/idl-2020/) \n - [UPC-DLAI-2020](https://telecombcn-dl.github.io/dlai-2020) \n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n\n### Contributions :pray:\n\nIf you find a course that fits in any of the above categories (i.e. DL, ML, RL, CV, NLP), **and** the course has lecture videos (with slides being optional), then please raise an issue or send a PR by updating the course according to the above format.\n\n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n\n### Support :moneybag:\n\n**Optional:** If you're a kind Samaritan and want to support me, please do so if possible, for which I would eternally be thankful and, most importantly, your contribution imbues me with greater motivation to work, particularly in hard times :pray:\n\n[![](https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=NT3EATS5N35WU)\n\n\nVielen lieben Dank! :blue_heart: \n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n###  :gift_heart: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board::mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board::mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :mortar_board: :gift_heart: \n\n:heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign::heavy_minus_sign:\n\n",
	"deep-learning deep-learning-library deep-learning-tutorial deep-neural-networks python pytorch": "<p align=\"center\"><img width=\"40%\" src=\"the_incredible_pytorch.png\" /></p>\n\n--------------------------------------------------------------------------------\n<p align=\"center\">\n\t<img src=\"https://img.shields.io/badge/stars-9000+-blue.svg\"/>\n\t<img src=\"https://img.shields.io/badge/forks-1800+-blue.svg\"/>\n\t<img src=\"https://img.shields.io/badge/license-MIT-blue.svg\"/>\n</p>\n\nThis is a curated list of tutorials, projects, libraries, videos, papers, books and anything related to the incredible [PyTorch](http://pytorch.org/). Feel free to make a pull request to contribute to this list.\n\n\n# Table Of Contents\n<!-- vscode-markdown-toc -->\n* [Tabular Data](#TabularData)\n* [Tutorials](#Tutorials)\n* [Visualization](#Visualization)\n* [Explainability](#Explainability)\n* [Object Detection](#ObjectDetection)\n* [Long-Tailed / Out-of-Distribution Recognition](#Long-TailedOut-of-DistributionRecognition)\n* [Activation Functions](#ActivationFunctions)\n* [Energy-Based Learning](#Energy-BasedLearning)\n* [Missing Data](#MissingData)\n* [Architecture Search](#ArchitectureSearch)\n* [Optimization](#Optimization)\n* [Quantization](#Quantization)\n* [Quantum Machine Learning](#QuantumMachineLearning)\n* [Neural Network Compression](#NeuralNetworkCompression)\n* [Facial, Action and Pose Recognition](#FacialActionandPoseRecognition)\n* [Super resolution](#Superresolution)\n* [Synthetesizing Views](#SynthetesizingViews)\n* [Voice](#Voice)\n* [Medical](#Medical)\n* [3D Segmentation, Classification and Regression](#DSegmentationClassificationandRegression)\n* [Video Recognition](#VideoRecognition)\n* [Recurrent Neural Networks (RNNs)](#RecurrentNeuralNetworksRNNs)\n* [Convolutional Neural Networks (CNNs)](#ConvolutionalNeuralNetworksCNNs)\n* [Segmentation](#Segmentation)\n* [Geometric Deep Learning: Graph & Irregular Structures](#GeometricDeepLearning:GraphIrregularStructures)\n* [Sorting](#Sorting)\n* [Ordinary Differential Equations Networks](#OrdinaryDifferentialEquationsNetworks)\n* [Multi-task Learning](#Multi-taskLearning)\n* [GANs, VAEs, and AEs](#GANsVAEsandAEs)\n* [Unsupervised Learning](#UnsupervisedLearning)\n* [Adversarial Attacks](#AdversarialAttacks)\n* [Style Transfer](#StyleTransfer)\n* [Image Captioning](#ImageCaptioning)\n* [Transformers](#Transformers)\n* [Similarity Networks and Functions](#SimilarityNetworksandFunctions)\n* [Reasoning](#Reasoning)\n* [General NLP](#GeneralNLP)\n* [Question and Answering](#QuestionandAnswering)\n* [Speech Generation and Recognition](#SpeechGenerationandRecognition)\n* [Document and Text Classification](#DocumentandTextClassification)\n* [Text Generation](#TextGeneration)\n* [Translation](#Translation)\n* [Sentiment Analysis](#SentimentAnalysis)\n* [Deep Reinforcement Learning](#DeepReinforcementLearning)\n* [Deep Bayesian Learning and Probabilistic Programmming](#DeepBayesianLearningandProbabilisticProgrammming)\n* [Spiking Neural Networks](#SpikingNeuralNetworks)\n* [Anomaly Detection](#AnomalyDetection)\n* [Regression Types](#RegressionTypes)\n* [Time Series](#TimeSeries)\n* [Synthetic Datasets](#SyntheticDatasets)\n* [Neural Network General Improvements](#NeuralNetworkGeneralImprovements)\n* [DNN Applications in Chemistry and Physics](#DNNApplicationsinChemistryandPhysics)\n* [New Thinking on General Neural Network Architecture](#NewThinkingonGeneralNeuralNetworkArchitecture)\n* [Linear Algebra](#LinearAlgebra)\n* [API Abstraction](#APIAbstraction)\n* [Low Level Utilities](#LowLevelUtilities)\n* [PyTorch Utilities](#PyTorchUtilities)\n* [PyTorch Video Tutorials](#PyTorchVideoTutorials)\n* [Datasets](#Datasets)\n* [Community](#Community)\n* [Links to This Repository](#LinkstoThisRepository)\n* [To be Classified](#TobeClassified)\n* [Contributions](#Contributions)\n\n<!-- vscode-markdown-toc-config\n\tnumbering=false\n\tautoSave=true\n\t/vscode-markdown-toc-config -->\n<!-- /vscode-markdown-toc -->\n\n## <a name='TabularData'></a>Tabular Data\n- [PyTorch-TabNet: Attentive Interpretable Tabular Learning](https://github.com/dreamquark-ai/tabnet)\n- [carefree-learn: A minimal Automatic Machine Learning (AutoML) solution for tabular datasets based on PyTorch](https://github.com/carefree0910/carefree-learn)\n\n## <a name='Tutorials'></a>Tutorials\n- [Official PyTorch Tutorials](https://github.com/pytorch/tutorials)\n- [Official PyTorch Examples](https://github.com/pytorch/examples)\n- [Dive Into Deep Learning with PyTorch](https://github.com/d2l-ai/d2l-en)\n- [Minicourse in Deep Learning with PyTorch (Multi-language)](https://github.com/Atcold/pytorch-Deep-Learning-Minicourse)\n- [Practical Deep Learning with PyTorch](https://github.com/ritchieng/deep-learning-wizard)\n- [Deep Learning Models](https://github.com/rasbt/deeplearning-models)\n- [C++ Implementation of PyTorch Tutorial](https://github.com/prabhuomkar/pytorch-cpp)\n- [Simple Examples to Introduce PyTorch](https://github.com/jcjohnson/pytorch-examples)\n- [Mini Tutorials in PyTorch](https://github.com/vinhkhuc/PyTorch-Mini-Tutorials)\n- [Deep Learning for NLP](https://github.com/rguthrie3/DeepLearningForNLPInPytorch)\n- [Deep Learning Tutorial for Researchers](https://github.com/yunjey/pytorch-tutorial)\n- [Fully Convolutional Networks implemented with PyTorch](https://github.com/wkentaro/pytorch-fcn)\n- [Simple PyTorch Tutorials Zero to ALL](https://github.com/hunkim/PyTorchZeroToAll)\n- [DeepNLP-models-Pytorch](https://github.com/DSKSD/DeepNLP-models-Pytorch)\n- [MILA PyTorch Welcome Tutorials](https://github.com/mila-udem/welcome_tutorials)\n- [Effective PyTorch, Optimizing Runtime with TorchScript and Numerical Stability Optimization](https://github.com/vahidk/EffectivePyTorch)\n- [Practical PyTorch](https://github.com/spro/practical-pytorch)\n- [PyTorch Project Template](https://github.com/moemen95/PyTorch-Project-Template)\n- [Semantic Search with PyTorch](https://github.com/kuutsav/information-retrieval)\n\n## <a name='Visualization'></a>Visualization\n- [Loss Visualization](https://github.com/tomgoldstein/loss-landscape)\n- [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://github.com/jacobgil/pytorch-grad-cam)\n- [Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps](https://github.com/utkuozbulak/pytorch-cnn-visualizations)\n- [SmoothGrad: removing noise by adding noise](https://github.com/utkuozbulak/pytorch-cnn-visualizations)\n- [DeepDream: dream-like hallucinogenic visuals](https://github.com/ProGamerGov/neural-dream)\n- [FlashTorch: Visualization toolkit for neural networks in PyTorch](https://github.com/MisaOgura/flashtorch)\n- [Lucent: Lucid adapted for PyTorch](https://github.com/greentfrapp/lucent)\n- [DreamCreator: Training GoogleNet models for DeepDream with custom datasets made simple](https://github.com/ProGamerGov/dream-creator)\n- [CNN Feature Map Visualisation](https://github.com/lewis-morris/mapextrackt)\n\n## <a name='Explainability'></a>Explainability\n- [Neural-Backed Decision Trees](https://github.com/alvinwan/neural-backed-decision-trees)\n- [Efficient Covariance Estimation from Temporal Data](https://github.com/hrayrhar/T-CorEx)\n- [Hierarchical interpretations for neural network predictions](https://github.com/csinva/hierarchical-dnn-interpretations)\n- [Shap, a unified approach to explain the output of any machine learning model](https://github.com/slundberg/shap)\n- [VIsualizing PyTorch saved .pth deep learning models with netron](https://github.com/lutzroeder/netron)\n- [Distilling a Neural Network Into a Soft Decision Tree](https://github.com/kimhc6028/soft-decision-tree)\n- [Captum, A unified model interpretability library for PyTorch](https://github.com/pytorch/captum)\n\n## <a name='ObjectDetection'></a>Object Detection\n- [MMDetection Object Detection Toolbox](https://github.com/open-mmlab/mmdetection)\n- [Mask R-CNN Benchmark: Faster R-CNN and Mask R-CNN in PyTorch 1.0](https://github.com/facebookresearch/maskrcnn-benchmark)\n- [YOLOS](https://github.com/hustvl/YOLOS)\n- [YOLOF](https://github.com/megvii-model/YOLOF)\n- [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)\n- [Yolov7](https://github.com/WongKinYiu/yolov7)\n- [YOLOv6](https://github.com/meituan/YOLOv6)\n- [Yolov5](https://github.com/ultralytics/yolov5)\n- [Yolov4](https://github.com/AlexeyAB/darknet)\n- [YOLOv3](https://github.com/ultralytics/yolov3)\n- [YOLOv2: Real-Time Object Detection](https://github.com/longcw/yolo2-pytorch)\n- [SSD: Single Shot MultiBox Detector](https://github.com/amdegroot/ssd.pytorch)\n- [Detectron models for Object Detection](https://github.com/ignacio-rocco/detectorch)\n- [Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks](https://github.com/potterhsu/SVHNClassifier-PyTorch)\n- [Whale Detector](https://github.com/TarinZ/whale-detector)\n- [Catalyst.Detection](https://github.com/catalyst-team/detection)\n\n## <a name='Long-TailedOut-of-DistributionRecognition'></a>Long-Tailed / Out-of-Distribution Recognition\n- [Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization](https://github.com/kohpangwei/group_DRO)\n- [Invariant Risk Minimization](https://github.com/facebookresearch/InvariantRiskMinimization)\n- [Training Confidence-Calibrated Classifier for Detecting Out-of-Distribution Samples](https://github.com/alinlab/Confident_classifier)\n- [Deep Anomaly Detection with Outlier Exposure](https://github.com/hendrycks/outlier-exposure)\n- [Large-Scale Long-Tailed Recognition in an Open World](https://github.com/zhmiao/OpenLongTailRecognition-OLTR)\n- [Principled Detection of Out-of-Distribution Examples in Neural Networks](https://github.com/ShiyuLiang/odin-pytorch)\n- [Learning Confidence for Out-of-Distribution Detection in Neural Networks](https://github.com/uoguelph-mlrg/confidence_estimation)\n- [PyTorch Imbalanced Class Sampler](https://github.com/ufoym/imbalanced-dataset-sampler)\n\n## <a name='ActivationFunctions'></a>Activation Functions\n- [Rational Activations - Learnable Rational Activation Functions](https://github.com/ml-research/rational_activations)\n\n## <a name='Energy-BasedLearning'></a>Energy-Based Learning\n- [EBGAN, Energy-Based GANs](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/ebgan/ebgan.py)\n- [Maximum Entropy Generators for Energy-based Models](https://github.com/ritheshkumar95/energy_based_generative_models)\n\n## <a name='MissingData'></a>Missing Data\n - [BRITS: Bidirectional Recurrent Imputation for Time Series](http://papers.nips.cc/paper/7911-brits-bidirectional-recurrent-imputation-for-time-series)\n\n## <a name='ArchitectureSearch'></a>Architecture Search\n- [EfficientNetV2](https://github.com/lukemelas/EfficientNet-PyTorch)\n- [DenseNAS](https://github.com/JaminFong/DenseNAS)\n- [DARTS: Differentiable Architecture Search](https://github.com/quark0/darts)\n- [Efficient Neural Architecture Search (ENAS)](https://github.com/carpedm20/ENAS-pytorch)\n- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://github.com/zsef123/EfficientNets-PyTorch)\n\n## <a name='Optimization'></a>Optimization\n- [AccSGD, AdaBound, AdaMod, DiffGrad, Lamb, NovoGrad, RAdam, SGDW, Yogi and more](https://github.com/jettify/pytorch-optimizer)\n- [Lookahead Optimizer: k steps forward, 1 step back](https://github.com/alphadl/lookahead.pytorch)\n- [RAdam, On the Variance of the Adaptive Learning Rate and Beyond](https://github.com/LiyuanLucasLiu/RAdam)\n- [Over9000, Comparison of RAdam, Lookahead, Novograd, and combinations](https://github.com/mgrankin/over9000)\n- [AdaBound, Train As Fast as Adam As Good as SGD](https://github.com/Luolc/AdaBound)\n- [Riemannian Adaptive Optimization Methods](https://github.com/ferrine/geoopt)\n- [L-BFGS](https://github.com/hjmshi/PyTorch-LBFGS)\n- [OptNet: Differentiable Optimization as a Layer in Neural Networks](https://github.com/locuslab/optnet)\n- [Learning to learn by gradient descent by gradient descent](https://github.com/ikostrikov/pytorch-meta-optimizer)\n- [Surrogate Gradient Learning in Spiking Neural Networks](https://github.com/fzenke/spytorch)\n\n## <a name='Quantization'></a>Quantization\n- [Additive Power-of-Two Quantization: An Efficient Non-uniform Discretization For Neural Networks](https://github.com/yhhhli/APoT_Quantization)\n\n## <a name='QuantumMachineLearning'></a>Quantum Machine Learning\n- [Tor10, generic tensor-network library for quantum simulation in PyTorch](https://github.com/kaihsin/Tor10)\n- [PennyLane, cross-platform Python library for quantum machine learning with PyTorch interface](https://github.com/XanaduAI/pennylane)\n\n## <a name='NeuralNetworkCompression'></a>Neural Network Compression\n- [Bayesian Compression for Deep Learning](https://github.com/KarenUllrich/Tutorial_BayesianCompressionForDL)\n- [Neural Network Distiller by Intel AI Lab: a Python package for neural network compression research](https://github.com/NervanaSystems/distiller)\n- [Learning Sparse Neural Networks through L0 regularization](https://github.com/AMLab-Amsterdam/L0_regularization)\n- [Energy-constrained Compression for Deep Neural Networks via Weighted Sparse Projection and Layer Input Masking](https://github.com/hyang1990/model_based_energy_constrained_compression)\n- [EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis](https://github.com/alecwangcq/EigenDamage-Pytorch)\n- [Pruning Convolutional Neural Networks for Resource Efficient Inference](https://github.com/jacobgil/pytorch-pruning)\n- [Pruning neural networks: is it time to nip it in the bud? (showing reduced networks work better)](https://github.com/BayesWatch/pytorch-prunes)\n\n## <a name='FacialActionandPoseRecognition'></a>Facial, Action and Pose Recognition\n- [Facenet: Pretrained Pytorch face detection and recognition models](https://github.com/timesler/facenet-pytorch)\n- [DGC-Net: Dense Geometric Correspondence Network](https://github.com/AaltoVision/DGC-Net)\n- [High performance facial recognition library on PyTorch](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch)\n- [FaceBoxes, a CPU real-time face detector with high accuracy](https://github.com/zisianw/FaceBoxes.PyTorch)\n- [How far are we from solving the 2D & 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)](https://github.com/1adrianb/face-alignment)\n- [Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition](https://github.com/kenshohara/3D-ResNets-PyTorch)\n- [PyTorch Realtime Multi-Person Pose Estimation](https://github.com/DavexPro/pytorch-pose-estimation)\n- [SphereFace: Deep Hypersphere Embedding for Face Recognition](https://github.com/clcarwin/sphereface_pytorch)\n- [GANimation: Anatomically-aware Facial Animation from a Single Image](https://github.com/albertpumarola/GANimation)\n- [Shufflenet V2 by Face++ with better results than paper](https://github.com/ericsun99/Shufflenet-v2-Pytorch)\n- [Towards 3D Human Pose Estimation in the Wild: a Weakly-supervised Approach](https://github.com/xingyizhou/pytorch-pose-hg-3d)\n- [Unsupervised Learning of Depth and Ego-Motion from Video](https://github.com/ClementPinard/SfmLearner-Pytorch)\n- [FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks](https://github.com/NVIDIA/flownet2-pytorch)\n- [FlowNet: Learning Optical Flow with Convolutional Networks](https://github.com/ClementPinard/FlowNetPytorch)\n- [Optical Flow Estimation using a Spatial Pyramid Network](https://github.com/sniklaus/pytorch-spynet)\n- [OpenFace in PyTorch](https://github.com/thnkim/OpenFacePytorch)\n- [Deep Face Recognition in PyTorch](https://github.com/grib0ed0v/face_recognition.pytorch)\n\n## <a name='Superresolution'></a>Super resolution\n- [Enhanced Deep Residual Networks for Single Image Super-Resolution](https://github.com/thstkdgus35/EDSR-PyTorch)\n- [Superresolution using an efficient sub-pixel convolutional neural network](https://github.com/pytorch/examples/tree/master/super_resolution)\n- [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://github.com/bengxy/FastNeuralStyle)\n\n## <a name='SynthetesizingViews'></a>Synthetesizing Views\n- [NeRF, Neural Radian Fields, Synthesizing Novels Views of Complex Scenes](https://github.com/yenchenlin/nerf-pytorch)\n\n## <a name='Voice'></a>Voice\n- [Google AI VoiceFilter: Targeted Voice Separatation by Speaker-Conditioned Spectrogram Masking](https://github.com/mindslab-ai/voicefilter)\n\n## <a name='Medical'></a>Medical\n- [Medical Zoo, 3D multi-modal medical image segmentation library in PyTorch]( https://github.com/black0017/MedicalZooPytorch)\n- [U-Net for FLAIR Abnormality Segmentation in Brain MRI](https://github.com/mateuszbuda/brain-segmentation-pytorch)\n- [Genomic Classification via ULMFiT](https://github.com/kheyer/Genomic-ULMFiT)\n- [Deep Neural Networks Improve Radiologists' Performance in Breast Cancer Screening](https://github.com/nyukat/breast_cancer_classifier)\n- [Delira, lightweight framework for medical imaging prototyping](https://github.com/justusschock/delira)\n- [V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation](https://github.com/mattmacy/vnet.pytorch)\n- [Medical Torch, medical imaging framework for PyTorch](https://github.com/perone/medicaltorch)\n- [TorchXRayVision - A library for chest X-ray datasets and models. Including pre-trainined models.](https://github.com/mlmed/torchxrayvision)\n\n## <a name='DSegmentationClassificationandRegression'></a>3D Segmentation, Classification and Regression\n- [Kaolin, Library for Accelerating 3D Deep Learning Research](https://github.com/NVIDIAGameWorks/kaolin)\n- [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://github.com/fxia22/pointnet.pytorch)\n- [3D segmentation with MONAI and Catalyst](https://colab.research.google.com/drive/15wJus5WZPYxTYE51yBhIBNhk9Tj4k3BT?usp=sharing)\n\n## <a name='VideoRecognition'></a>Video Recognition\n- [Dancing to Music](https://github.com/NVlabs/Dancing2Music)\n- [Devil Is in the Edges: Learning Semantic Boundaries from Noisy Annotations](https://github.com/nv-tlabs/STEAL)\n- [Deep Video Analytics](https://github.com/AKSHAYUBHAT/DeepVideoAnalytics)\n- [PredRNN: Recurrent Neural Networks for Predictive Learning using Spatiotemporal LSTMs](https://github.com/thuml/predrnn-pytorch)\n\n## <a name='RecurrentNeuralNetworksRNNs'></a>Recurrent Neural Networks (RNNs)\n- [SRU: training RNNs as fast as CNNs](https://github.com/asappresearch/sru)\n- [Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks](https://github.com/yikangshen/Ordered-Neurons)\n- [Averaged Stochastic Gradient Descent with Weight Dropped LSTM](https://github.com/salesforce/awd-lstm-lm)\n- [Training RNNs as Fast as CNNs](https://github.com/taolei87/sru)\n- [Quasi-Recurrent Neural Network (QRNN)](https://github.com/salesforce/pytorch-qrnn)\n- [ReSeg: A Recurrent Neural Network-based Model for Semantic Segmentation](https://github.com/Wizaron/reseg-pytorch)\n- [A Recurrent Latent Variable Model for Sequential Data (VRNN)](https://github.com/emited/VariationalRecurrentNeuralNetwork)\n- [Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks](https://github.com/dasguptar/treelstm.pytorch)\n- [Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling](https://github.com/DSKSD/RNN-for-Joint-NLU)\n- [Attentive Recurrent Comparators](https://github.com/sanyam5/arc-pytorch)\n- [Collection of Sequence to Sequence Models with PyTorch](https://github.com/MaximumEntropy/Seq2Seq-PyTorch)\n\t1. Vanilla Sequence to Sequence models\n\t2. Attention based Sequence to Sequence models\n\t3. Faster attention mechanisms using dot products between the final encoder and decoder hidden states\n\n## <a name='ConvolutionalNeuralNetworksCNNs'></a>Convolutional Neural Networks (CNNs)\n- [LegoNet: Efficient Convolutional Neural Networks with Lego Filters](https://github.com/huawei-noah/LegoNet)\n- [MeshCNN, a convolutional neural network designed specifically for triangular meshes](https://github.com/ranahanocka/MeshCNN)\n- [Octave Convolution](https://github.com/d-li14/octconv.pytorch)\n- [PyTorch Image Models, ResNet/ResNeXT, DPN, MobileNet-V3/V2/V1, MNASNet, Single-Path NAS, FBNet](https://github.com/rwightman/pytorch-image-models)\n- [Deep Neural Networks with Box Convolutions](https://github.com/shrubb/box-convolutions)\n- [Invertible Residual Networks](https://github.com/jarrelscy/iResnet)\n- [Stochastic Downsampling for Cost-Adjustable Inference and Improved Regularization in Convolutional Networks ](https://github.com/xternalz/SDPoint)\n- [Faster Faster R-CNN Implementation](https://github.com/jwyang/faster-rcnn.pytorch)\n\t- [Faster R-CNN Another Implementation](https://github.com/longcw/faster_rcnn_pytorch)\n- [Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer](https://github.com/szagoruyko/attention-transfer)\n- [Wide ResNet model in PyTorch](https://github.com/szagoruyko/functional-zoo)\n\t-[DiracNets: Training Very Deep Neural Networks Without Skip-Connections](https://github.com/szagoruyko/diracnets)\n- [An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition](https://github.com/bgshih/crnn)\n- [Efficient Densenet](https://github.com/gpleiss/efficient_densenet_pytorch)\n- [Video Frame Interpolation via Adaptive Separable Convolution](https://github.com/sniklaus/pytorch-sepconv)\n- [Learning local feature descriptors with triplets and shallow convolutional neural networks](https://github.com/edgarriba/examples/tree/master/triplet)\n- [Densely Connected Convolutional Networks](https://github.com/bamos/densenet.pytorch)\n- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://github.com/jcjohnson/pytorch-vgg)\n- [SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and \\<0.5MB model size](https://github.com/gsp-27/pytorch_Squeezenet)\n- [Deep Residual Learning for Image Recognition](https://github.com/szagoruyko/functional-zoo)\n- [Training Wide ResNets for CIFAR-10 and CIFAR-100 in PyTorch](https://github.com/xternalz/WideResNet-pytorch)\n- [Deformable Convolutional Network](https://github.com/oeway/pytorch-deform-conv)\n- [Convolutional Neural Fabrics](https://github.com/vabh/convolutional-neural-fabrics)\n- [Deformable Convolutional Networks in PyTorch](https://github.com/1zb/deformable-convolution-pytorch)\n- [Dilated ResNet combination with Dilated Convolutions](https://github.com/fyu/drn)\n- [Striving for Simplicity: The All Convolutional Net](https://github.com/utkuozbulak/pytorch-cnn-visualizations)\n- [Convolutional LSTM Network](https://github.com/automan000/Convolution_LSTM_pytorch)\n- [Big collection of pretrained classification models](https://github.com/osmr/imgclsmob)\n- [PyTorch Image Classification with Kaggle Dogs vs Cats Dataset](https://github.com/rdcolema/pytorch-image-classification)\n- [CIFAR-10 on Pytorch with VGG, ResNet and DenseNet](https://github.com/kuangliu/pytorch-cifar)\n- [Base pretrained models and datasets in pytorch (MNIST, SVHN, CIFAR10, CIFAR100, STL10, AlexNet, VGG16, VGG19, ResNet, Inception, SqueezeNet)](https://github.com/aaron-xichen/pytorch-playground)\n- [NVIDIA/unsupervised-video-interpolation](https://github.com/NVIDIA/unsupervised-video-interpolation)\n\n## <a name='Segmentation'></a>Segmentation\n- [Detectron2 by FAIR](https://github.com/facebookresearch/detectron2)\n- [Pixel-wise Segmentation on VOC2012 Dataset using PyTorch](https://github.com/bodokaiser/piwise)\n- [Pywick - High-level batteries-included neural network training library for Pytorch](https://github.com/achaiah/pywick)\n- [Improving Semantic Segmentation via Video Propagation and Label Relaxation](https://github.com/NVIDIA/semantic-segmentation)\n- [Super-BPD: Super Boundary-to-Pixel Direction for Fast Image Segmentation](https://github.com/JianqiangWan/Super-BPD)\n- [Catalyst.Segmentation](https://github.com/catalyst-team/segmentation)\n- [Segmentation models with pretrained backbones](https://github.com/qubvel/segmentation_models.pytorch)\n\n## <a name='GeometricDeepLearning:GraphIrregularStructures'></a>Geometric Deep Learning: Graph & Irregular Structures\n- [PyTorch Geometric, Deep Learning Extension](https://github.com/rusty1s/pytorch_geometric)\n- [PyTorch Geometric Temporal: A Temporal Extension Library for PyTorch Geometric](https://github.com/benedekrozemberczki/pytorch_geometric_temporal)\n- [PyTorch Geometric Signed Directed: A Signed & Directed Extension Library for PyTorch Geometric](https://github.com/SherylHYX/pytorch_geometric_signed_directed)\n- [ChemicalX: A PyTorch Based Deep Learning Library for Drug Pair Scoring](https://github.com/AstraZeneca/chemicalx)\n- [Self-Attention Graph Pooling](https://github.com/inyeoplee77/SAGPool)\n- [Position-aware Graph Neural Networks](https://github.com/JiaxuanYou/P-GNN)\n- [Signed Graph Convolutional Neural Network](https://github.com/benedekrozemberczki/SGCN)\n- [Graph U-Nets](https://github.com/HongyangGao/gunet)\n- [Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks](https://github.com/benedekrozemberczki/ClusterGCN)\n- [MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing](https://github.com/benedekrozemberczki/MixHop-and-N-GCN)\n- [Semi-Supervised Graph Classification: A Hierarchical Graph Perspective](https://github.com/benedekrozemberczki/SEAL-CI)\n- [PyTorch BigGraph by FAIR for Generating Embeddings From Large-scale Graph Data](https://github.com/facebookresearch/PyTorch-BigGraph)\n- [Capsule Graph Neural Network](https://github.com/benedekrozemberczki/CapsGNN)\n- [Splitter: Learning Node Representations that Capture Multiple Social Contexts](https://github.com/benedekrozemberczki/Splitter)\n- [A Higher-Order Graph Convolutional Layer](https://github.com/benedekrozemberczki/MixHop-and-N-GCN)\n- [Predict then Propagate: Graph Neural Networks meet Personalized PageRank](https://github.com/benedekrozemberczki/APPNP)\n- [Lorentz Embeddings: Learn Continuous Hierarchies in Hyperbolic Space](https://github.com/theSage21/lorentz-embeddings)\n- [Graph Wavelet Neural Network](https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork)\n- [Watch Your Step: Learning Node Embeddings via Graph Attention](https://github.com/benedekrozemberczki/AttentionWalk)\n- [Signed Graph Convolutional Network](https://github.com/benedekrozemberczki/SGCN)\n- [Graph Classification Using Structural Attention](https://github.com/benedekrozemberczki/GAM)\n- [SimGNN: A Neural Network Approach to Fast Graph Similarity Computation](https://github.com/benedekrozemberczki/SimGNN)\n- [SINE: Scalable Incomplete Network Embedding](https://github.com/benedekrozemberczki/SINE)\n- [HypER: Hypernetwork Knowledge Graph Embeddings](https://github.com/ibalazevic/HypER)\n- [TuckER: Tensor Factorization for Knowledge Graph Completion](https://github.com/ibalazevic/TuckER)\n- [PyKEEN: A Python library for learning and evaluating knowledge graph embeddings](https://github.com/pykeen/pykeen/)\n- [Pathfinder Discovery Networks for Neural Message Passing](https://github.com/benedekrozemberczki/PDN)\n- [SSSNET: Semi-Supervised Signed Network Clustering](https://github.com/SherylHYX/SSSNET_Signed_Clustering)\n- [MagNet: A Neural Network for Directed Graphs](https://github.com/matthew-hirn/magnet)\n\n## <a name='Sorting'></a>Sorting\n- [Stochastic Optimization of Sorting Networks via Continuous Relaxations](https://github.com/ermongroup/neuralsort)\n\n## <a name='OrdinaryDifferentialEquationsNetworks'></a>Ordinary Differential Equations Networks\n- [Latent ODEs for Irregularly-Sampled Time Series](https://github.com/YuliaRubanova/latent_ode)\n- [GRU-ODE-Bayes: continuous modelling of sporadically-observed time series](https://github.com/edebrouwer/gru_ode_bayes)\n\n## <a name='Multi-taskLearning'></a>Multi-task Learning\n- [Hierarchical Multi-Task Learning Model](https://github.com/huggingface/hmtl)\n- [Task-based End-to-end Model Learning](https://github.com/locuslab/e2e-model-learning)\n\n## <a name='GANsVAEsandAEs'></a>GANs, VAEs, and AEs\n- [Stable Diffusion](https://github.com/CompVis/stable-diffusion)\n- [BigGAN: Large Scale GAN Training for High Fidelity Natural Image Synthesis](https://github.com/ajbrock/BigGAN-PyTorch)\n- [High Fidelity Performance Metrics for Generative Models in PyTorch](https://github.com/toshas/torch-fidelity)\n- [Mimicry, PyTorch Library for Reproducibility of GAN Research](https://github.com/kwotsin/mimicry)\n- [Clean Readable CycleGAN](https://github.com/aitorzip/PyTorch-CycleGAN)\n- [StarGAN](https://github.com/yunjey/stargan)\n- [Block Neural Autoregressive Flow](https://github.com/nicola-decao/BNAF)\n- [High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs](https://github.com/NVIDIA/pix2pixHD)\n- [A Style-Based Generator Architecture for Generative Adversarial Networks](https://github.com/rosinality/style-based-gan-pytorch)\n- [GANDissect, PyTorch Tool for Visualizing Neurons in GANs](https://github.com/CSAILVision/gandissect)\n- [Learning deep representations by mutual information estimation and maximization](https://github.com/DuaneNielsen/DeepInfomaxPytorch)\n- [Variational Laplace Autoencoders](https://github.com/yookoon/VLAE)\n- [VeGANS, library for easily training GANs](https://github.com/unit8co/vegans)\n- [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://github.com/github-pengge/PyTorch-progressive_growing_of_gans)\n- [Conditional GAN](https://github.com/kmualim/CGAN-Pytorch/)\n- [Wasserstein GAN](https://github.com/martinarjovsky/WassersteinGAN)\n- [Adversarial Generator-Encoder Network](https://github.com/DmitryUlyanov/AGE)\n- [Image-to-Image Translation with Conditional Adversarial Networks](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)\n- [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)\n- [On the Effects of Batch and Weight Normalization in Generative Adversarial Networks](https://github.com/stormraiser/GAN-weight-norm)\n- [Improved Training of Wasserstein GANs](https://github.com/jalola/improved-wgan-pytorch)\n- [Collection of Generative Models with PyTorch](https://github.com/wiseodd/generative-models)\n\t- Generative Adversarial Nets (GAN)\n\t\t1. [Vanilla GAN](https://arxiv.org/abs/1406.2661)\n\t\t2. [Conditional GAN](https://arxiv.org/abs/1411.1784)\n\t\t3. [InfoGAN](https://arxiv.org/abs/1606.03657)\n\t\t4. [Wasserstein GAN](https://arxiv.org/abs/1701.07875)\n\t\t5. [Mode Regularized GAN](https://arxiv.org/abs/1612.02136)\n\t- Variational Autoencoder (VAE)\n\t\t1. [Vanilla VAE](https://arxiv.org/abs/1312.6114)\n\t\t2. [Conditional VAE](https://arxiv.org/abs/1406.5298)\n\t\t3. [Denoising VAE](https://arxiv.org/abs/1511.06406)\n\t\t4. [Adversarial Autoencoder](https://arxiv.org/abs/1511.05644)\n\t\t5. [Adversarial Variational Bayes](https://arxiv.org/abs/1701.04722)\n- [Improved Training of Wasserstein GANs](https://github.com/caogang/wgan-gp)\n- [CycleGAN and Semi-Supervised GAN](https://github.com/yunjey/mnist-svhn-transfer)\n- [Improving Variational Auto-Encoders using Householder Flow and using convex combination linear Inverse Autoregressive Flow](https://github.com/jmtomczak/vae_vpflows)\n- [PyTorch GAN Collection](https://github.com/znxlwm/pytorch-generative-model-collections)\n- [Generative Adversarial Networks, focusing on anime face drawing](https://github.com/jayleicn/animeGAN)\n- [Simple Generative Adversarial Networks](https://github.com/mailmahee/pytorch-generative-adversarial-networks)\n- [Adversarial Auto-encoders](https://github.com/fducau/AAE_pytorch)\n- [torchgan: Framework for modelling Generative Adversarial Networks in Pytorch](https://github.com/torchgan/torchgan)\n- [Evaluating Lossy Compression Rates of Deep Generative Models](https://github.com/huangsicong/rate_distortion)\n- [Catalyst.GAN](https://github.com/catalyst-team/gan)\n    1. [Vanilla GAN](https://arxiv.org/abs/1406.2661)\n    2. [Conditional GAN](https://arxiv.org/abs/1411.1784)\n    3. [Wasserstein GAN](https://arxiv.org/abs/1701.07875)\n    4. [Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028)\n\n## <a name='UnsupervisedLearning'></a>Unsupervised Learning\n- [Unsupervised Embedding Learning via Invariant and Spreading Instance Feature](https://github.com/mangye16/Unsupervised_Embedding_Learning)\n- [AND: Anchor Neighbourhood Discovery](https://github.com/Raymond-sci/AND)\n\n## <a name='AdversarialAttacks'></a>Adversarial Attacks\n- [Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images](https://github.com/utkuozbulak/pytorch-cnn-adversarial-attacks)\n- [Explaining and Harnessing Adversarial Examples](https://github.com/utkuozbulak/pytorch-cnn-adversarial-attacks)\n- [AdverTorch - A Toolbox for Adversarial Robustness Research](https://github.com/BorealisAI/advertorch)\n\n## <a name='StyleTransfer'></a>Style Transfer\n- [Pystiche: Framework for Neural Style Transfer](https://github.com/pystiche/pystiche)\n- [Detecting Adversarial Examples via Neural Fingerprinting](https://github.com/StephanZheng/neural-fingerprinting)\n- [A Neural Algorithm of Artistic Style](https://github.com/alexis-jacq/Pytorch-Tutorials)\n- [Multi-style Generative Network for Real-time Transfer](https://github.com/zhanghang1989/PyTorch-Style-Transfer)\n- [DeOldify, Coloring Old Images](https://github.com/jantic/DeOldify)\n- [Neural Style Transfer](https://github.com/ProGamerGov/neural-style-pt)\n- [Fast Neural Style Transfer](https://github.com/darkstar112358/fast-neural-style)\n- [Draw like Bob Ross](https://github.com/kendricktan/drawlikebobross)\n\n## <a name='ImageCaptioning'></a>Image Captioning\n- [CLIP (Contrastive Language-Image Pre-Training)](https://github.com/openai/CLIP)\n- [Neuraltalk 2, Image Captioning Model, in PyTorch](https://github.com/ruotianluo/neuraltalk2.pytorch)\n- [Generate captions from an image with PyTorch](https://github.com/eladhoffer/captionGen)\n- [DenseCap: Fully Convolutional Localization Networks for Dense Captioning](https://github.com/jcjohnson/densecap)\n\n## <a name='Transformers'></a>Transformers\n- [Attention is all you need](https://github.com/jadore801120/attention-is-all-you-need-pytorch)\n- [Spatial Transformer Networks](https://github.com/fxia22/stn.pytorch)\n\n## <a name='SimilarityNetworksandFunctions'></a>Similarity Networks and Functions\n- [Conditional Similarity Networks](https://github.com/andreasveit/conditional-similarity-networks)\n\n## <a name='Reasoning'></a>Reasoning\n- [Inferring and Executing Programs for Visual Reasoning](https://github.com/facebookresearch/clevr-iep)\n\n## <a name='GeneralNLP'></a>General NLP\n- [Espresso, Module Neural Automatic Speech Recognition Toolkit](https://github.com/freewym/espresso)\n- [Label-aware Document Representation via Hybrid Attention for Extreme Multi-Label Text Classification](https://github.com/HX-idiot/Hybrid_Attention_XML)\n- [XLNet](https://github.com/graykode/xlnet-Pytorch)\n- [Conversing by Reading: Contentful Neural Conversation with On-demand Machine Reading](https://github.com/qkaren/converse_reading_cmr)\n- [Cross-lingual Language Model Pretraining](https://github.com/facebookresearch/XLM)\n- [Libre Office Translate via PyTorch NMT](https://github.com/lernapparat/lotranslate)\n- [BERT](https://github.com/huggingface/pytorch-pretrained-BERT)\n- [VSE++: Improved Visual-Semantic Embeddings](https://github.com/fartashf/vsepp)\n- [A Structured Self-Attentive Sentence Embedding](https://github.com/ExplorerFreda/Structured-Self-Attentive-Sentence-Embedding)\n- [Neural Sequence labeling model](https://github.com/jiesutd/PyTorchSeqLabel)\n- [Skip-Thought Vectors](https://github.com/sanyam5/skip-thoughts)\n- [Complete Suite for Training Seq2Seq Models in PyTorch](https://github.com/eladhoffer/seq2seq.pytorch)\n- [MUSE: Multilingual Unsupervised and Supervised Embeddings](https://github.com/facebookresearch/MUSE)\n- [TorchMoji: PyTorch Implementation of DeepMoji to under Language used to Express Emotions](https://github.com/huggingface/torchMoji)\n\n## <a name='QuestionandAnswering'></a>Question and Answering\n- [Visual Question Answering in Pytorch](https://github.com/Cadene/vqa.pytorch)\n- [Reading Wikipedia to Answer Open-Domain Questions](https://github.com/facebookresearch/DrQA)\n- [Deal or No Deal? End-to-End Learning for Negotiation Dialogues](https://github.com/facebookresearch/end-to-end-negotiator)\n- [Interpretable Counting for Visual Question Answering](https://github.com/sanyam5/irlc-vqa)\n- [Open Source Chatbot with PyTorch](https://github.com/jinfagang/pytorch_chatbot)\n\n## <a name='SpeechGenerationandRecognition'></a>Speech Generation and Recognition\n- [PyTorch-Kaldi Speech Recognition Toolkit](https://github.com/mravanelli/pytorch-kaldi)\n- [WaveGlow: A Flow-based Generative Network for Speech Synthesis](https://github.com/NVIDIA/waveglow)\n- [OpenNMT](https://github.com/OpenNMT/OpenNMT-py)\n- [Deep Speech 2: End-to-End Speech Recognition in English and Mandarin](https://github.com/SeanNaren/deepspeech.pytorch)\n- [WeNet: Production First and Production Ready End-to-End Speech Recognition Toolkit](https://github.com/mobvoi/wenet)\n\n## <a name='DocumentandTextClassification'></a>Document and Text Classification\n- [Hierarchical Attention Network for Document Classification](https://github.com/cedias/HAN-pytorch)\n- [Hierarchical Attention Networks for Document Classification](https://github.com/EdGENetworks/attention-networks-for-classification)\n- [CNN Based Text Classification](https://github.com/xiayandi/Pytorch_text_classification)\n\n## <a name='TextGeneration'></a>Text Generation\n- [Pytorch Poetry Generation](https://github.com/jhave/pytorch-poetry-generation)\n\n## <a name='Translation'></a>Translation\n- [Open-source (MIT) Neural Machine Translation (NMT) System](https://github.com/OpenNMT/OpenNMT-py)\n\n## <a name='SentimentAnalysis'></a>Sentiment Analysis\n- [Recurrent Neural Networks for Sentiment Analysis (Aspect-Based) on SemEval 2014](https://github.com/vanzytay/pytorch_sentiment_rnn)\n- [Seq2Seq Intent Parsing](https://github.com/spro/pytorch-seq2seq-intent-parsing)\n- [Finetuning BERT for Sentiment Analysis](https://github.com/barissayil/SentimentAnalysis)\n\n## <a name='DeepReinforcementLearning'></a>Deep Reinforcement Learning\n- [Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels](https://github.com/denisyarats/drq)\n- [Exploration by Random Network Distillation](https://github.com/openai/random-network-distillation)\n- [EGG: Emergence of lanGuage in Games, quickly implement multi-agent games with discrete channel communication](https://github.com/facebookresearch/EGG)\n- [Temporal Difference VAE](https://openreview.net/pdf?id=S1x4ghC9tQ)\n- [High-performance Atari A3C Agent in 180 Lines PyTorch](https://github.com/greydanus/baby-a3c)\n- [Learning when to communicate at scale in multiagent cooperative and competitive tasks](https://github.com/IC3Net/IC3Net)\n- [Actor-Attention-Critic for Multi-Agent Reinforcement Learning](https://github.com/shariqiqbal2810/MAAC)\n- [PPO in PyTorch C++](https://github.com/mhubii/ppo_pytorch_cpp)\n- [Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback](https://github.com/khanhptnk/bandit-nmt)\n- [Asynchronous Methods for Deep Reinforcement Learning](https://github.com/ikostrikov/pytorch-a3c)\n- [Continuous Deep Q-Learning with Model-based Acceleration](https://github.com/ikostrikov/pytorch-naf)\n- [Asynchronous Methods for Deep Reinforcement Learning for Atari 2600](https://github.com/dgriff777/rl_a3c_pytorch)\n- [Trust Region Policy Optimization](https://github.com/mjacar/pytorch-trpo)\n- [Neural Combinatorial Optimization with Reinforcement Learning](https://github.com/pemami4911/neural-combinatorial-rl-pytorch)\n- [Noisy Networks for Exploration](https://github.com/Kaixhin/NoisyNet-A3C)\n- [Distributed Proximal Policy Optimization](https://github.com/alexis-jacq/Pytorch-DPPO)\n- [Reinforcement learning models in ViZDoom environment with PyTorch](https://github.com/akolishchak/doom-net-pytorch)\n- [Reinforcement learning models using Gym and Pytorch](https://github.com/jingweiz/pytorch-rl)\n- [SLM-Lab: Modular Deep Reinforcement Learning framework in PyTorch](https://github.com/kengz/SLM-Lab)\n- [Catalyst.RL](https://github.com/catalyst-team/catalyst-rl)\n\n## <a name='DeepBayesianLearningandProbabilisticProgrammming'></a>Deep Bayesian Learning and Probabilistic Programmming\n- [BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning](https://github.com/BlackHC/BatchBALD)\n- [Subspace Inference for Bayesian Deep Learning](https://github.com/wjmaddox/drbayes)\n- [Bayesian Deep Learning with Variational Inference Package](https://github.com/ctallec/pyvarinf)\n- [Probabilistic Programming and Statistical Inference in PyTorch](https://github.com/stepelu/ptstat)\n- [Bayesian CNN with Variational Inferece in PyTorch](https://github.com/kumar-shridhar/PyTorch-BayesianCNN)\n\n## <a name='SpikingNeuralNetworks'></a>Spiking Neural Networks\n- [Norse, Library for Deep Learning with Spiking Neural Networks](https://github.com/norse/norse)\n\n## <a name='AnomalyDetection'></a>Anomaly Detection\n- [Detection of Accounting Anomalies using Deep Autoencoder Neural Networks](https://github.com/GitiHubi/deepAI)\n\n## <a name='RegressionTypes'></a>Regression Types\n- [Quantile Regression DQN](https://github.com/ars-ashuha/quantile-regression-dqn-pytorch)\n\n## <a name='TimeSeries'></a>Time Series\n- [Dual Self-Attention Network for Multivariate Time Series Forecasting](https://github.com/bighuang624/DSANet)\n- [DILATE: DIstortion Loss with shApe and tImE](https://github.com/vincent-leguen/DILATE)\n- [Variational Recurrent Autoencoder for Timeseries Clustering](https://github.com/tejaslodaya/timeseries-clustering-vae)\n- [Spatio-Temporal Neural Networks for Space-Time Series Modeling and Relations Discovery](https://github.com/edouardelasalles/stnn)\n- [Flow Forecast: A deep learning for time series forecasting framework built in PyTorch](https://github.com/AIStream-Peelout/flow-forecast)\n\n## <a name='SyntheticDatasets'></a>Synthetic Datasets\n- [Meta-Sim: Learning to Generate Synthetic Datasets](https://github.com/nv-tlabs/meta-sim)\n\n## <a name='NeuralNetworkGeneralImprovements'></a>Neural Network General Improvements\n- [In-Place Activated BatchNorm for Memory-Optimized Training of DNNs](https://github.com/mapillary/inplace_abn)\n- [Train longer, generalize better: closing the generalization gap in large batch training of neural networks](https://github.com/eladhoffer/bigBatch)\n- [FreezeOut: Accelerate Training by Progressively Freezing Layers](https://github.com/ajbrock/FreezeOut)\n- [Binary Stochastic Neurons](https://github.com/Wizaron/binary-stochastic-neurons)\n- [Compact Bilinear Pooling](https://github.com/DeepInsight-PCALab/CompactBilinearPooling-Pytorch)\n- [Mixed Precision Training in PyTorch](https://github.com/suvojit-0x55aa/mixed-precision-pytorch)\n\n## <a name='DNNApplicationsinChemistryandPhysics'></a>DNN Applications in Chemistry and Physics\n- [Wave Physics as an Analog Recurrent Neural Network](https://github.com/fancompute/wavetorch)\n- [Neural Message Passing for Quantum Chemistry](https://github.com/priba/nmp_qc)\n- [Automatic chemical design using a data-driven continuous representation of molecules](https://github.com/cxhernandez/molencoder)\n- [Deep Learning for Physical Processes: Integrating Prior Scientific Knowledge](https://github.com/emited/flow)\n- [Differentiable Molecular Simulation for Learning and Control](https://github.com/wwang2/torchmd)\n\n## <a name='NewThinkingonGeneralNeuralNetworkArchitecture'></a>New Thinking on General Neural Network Architecture\n- [Complement Objective Training](https://github.com/henry8527/COT)\n- [Decoupled Neural Interfaces using Synthetic Gradients](https://github.com/andrewliao11/dni.pytorch)\n\n## <a name='LinearAlgebra'></a>Linear Algebra\n- [Eigenvectors from Eigenvalues](https://github.com/ritchieng/eigenvectors-from-eigenvalues)\n\n## <a name='APIAbstraction'></a>API Abstraction\n- [Torch Layers, Shape inference for PyTorch, SOTA Layers](https://github.com/szymonmaszke/torchlayers)\n- [Hummingbird, run trained scikit-learn models on GPU with PyTorch](https://github.com/microsoft/hummingbird)\n\n## <a name='LowLevelUtilities'></a>Low Level Utilities\n- [TorchSharp, .NET API with access to underlying library powering PyTorch](https://github.com/interesaaat/TorchSharp)\n\n## <a name='PyTorchUtilities'></a>PyTorch Utilities\n- [Functorch: prototype of JAX-like composable Function transformers for PyTorch](https://github.com/zou3519/functorch)\n- [Poutyne: Simplified Framework for Training Neural Networks](https://github.com/GRAAL-Research/poutyne)\n- [PyTorch Metric Learning](https://github.com/KevinMusgrave/pytorch-metric-learning)\n- [Kornia: an Open Source Differentiable Computer Vision Library for PyTorch](https://kornia.org/)\n- [BackPACK to easily Extract Variance, Diagonal of Gauss-Newton, and KFAC](https://f-dangel.github.io/backpack/)\n- [PyHessian for Computing Hessian Eigenvalues, trace of matrix, and ESD](https://github.com/amirgholami/PyHessian)\n- [Hessian in PyTorch](https://github.com/mariogeiger/hessian)\n- [Differentiable Convex Layers](https://github.com/cvxgrp/cvxpylayers)\n- [Albumentations: Fast Image Augmentation Library](https://github.com/albu/albumentations)\n- [Higher, obtain higher order gradients over losses spanning training loops](https://github.com/facebookresearch/higher)\n- [Neural Pipeline, Training Pipeline for PyTorch](https://github.com/toodef/neural-pipeline)\n- [Layer-by-layer PyTorch Model Profiler for Checking Model Time Consumption](https://github.com/awwong1/torchprof)\n- [Sparse Distributions](https://github.com/probabll/sparse-distributions)\n- [Diffdist, Adds Support for Differentiable Communication allowing distributed model parallelism](https://github.com/ag14774/diffdist)\n- [HessianFlow, Library for Hessian Based Algorithms](https://github.com/amirgholami/HessianFlow)\n- [Texar, PyTorch Toolkit for Text Generation](https://github.com/asyml/texar-pytorch)\n- [PyTorch FLOPs counter](https://github.com/Lyken17/pytorch-OpCounter)\n- [PyTorch Inference on C++ in Windows](https://github.com/zccyman/pytorch-inference)\n- [EuclidesDB, Multi-Model Machine Learning Feature Database](https://github.com/perone/euclidesdb)\n- [Data Augmentation and Sampling for Pytorch](https://github.com/ncullen93/torchsample)\n- [PyText, deep learning based NLP modelling framework officially maintained by FAIR](https://github.com/facebookresearch/pytext)\n- [Torchstat for Statistics on PyTorch Models](https://github.com/Swall0w/torchstat)\n- [Load Audio files directly into PyTorch Tensors](https://github.com/pytorch/audio)\n- [Weight Initializations](https://github.com/pytorch/pytorch/blob/master/torch/nn/init.py)\n- [Spatial transformer implemented in PyTorch](https://github.com/fxia22/stn.pytorch)\n- [PyTorch AWS AMI, run PyTorch with GPU support in less than 5 minutes](https://github.com/ritchieng/dlami)\n- [Use tensorboard with PyTorch](https://github.com/lanpa/tensorboard-pytorch)\n- [Simple Fit Module in PyTorch, similar to Keras](https://github.com/henryre/pytorch-fitmodule)\n- [torchbearer: A model fitting library for PyTorch](https://github.com/ecs-vlc/torchbearer)\n- [PyTorch to Keras model converter](https://github.com/nerox8664/pytorch2keras)\n- [Gluon to PyTorch model converter with code generation](https://github.com/nerox8664/gluon2pytorch)\n- [Catalyst: High-level utils for PyTorch DL & RL research](https://github.com/catalyst-team/catalyst)\n- [PyTorch Lightning: Scalable and lightweight deep learning research framework](https://github.com/PyTorchLightning/pytorch-lightning)\n- [Determined: Scalable deep learning platform with PyTorch support](https://github.com/determined-ai/determined)\n- [PyTorch-Ignite: High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently](https://github.com/pytorch/ignite)\n- [torchvision: A package consisting of popular datasets, model architectures, and common image transformations for computer vision.](https://github.com/pytorch/vision)\n- [Poutyne: A Keras-like framework for PyTorch and handles much of the boilerplating code needed to train neural networks.](https://github.com/GRAAL-Research/poutyne)\n- [torchensemble: Scikit-Learn like ensemble methods in PyTorch](https://github.com/AaronX121/Ensemble-Pytorch)\n\n## <a name='PyTorchVideoTutorials'></a>PyTorch Video Tutorials\n- [PyTorch Zero to All Lectures](http://bit.ly/PyTorchVideo)\n- [PyTorch For Deep Learning Full Course](https://www.youtube.com/watch?v=GIsg-ZUy0MY)\n- [PyTorch Lightning 101 with Alfredo Canziani and William Falcon](https://www.you\ntube.com/playlist?list=PLaMu-SDt_RB5NUm67hU2pdE75j6KaIOv2)\n- [Practical Deep Learning with PyTorch](https://www.udemy.com/practical-deep-learning-with-pytorch)\n\n## <a name='Datasets'></a>Datasets\n- [Worldbank Data](https://github.com/mwouts/world_bank_data)\n\n## <a name='Community'></a>Community\n- [PyTorch Discussion Forum](https://discuss.pytorch.org/)\n- [StackOverflow PyTorch Tags](http://stackoverflow.com/questions/tagged/pytorch)\n- [Catalyst.Slack](https://join.slack.com/t/catalyst-team-core/shared_invite/zt-d9miirnn-z86oKDzFMKlMG4fgFdZafw)\n\n## <a name='LinkstoThisRepository'></a>Links to This Repository\n- [Github Repository](https://github.com/ritchieng/the-incredible-pytorch)\n- [Website](https://www.ritchieng.com/the-incredible-pytorch/)\n\n## <a name='TobeClassified'></a>To be Classified\n- [Perturbative Neural Networks](https://github.com/michaelklachko/pnn.pytorch)\n- [Accurate Neural Network Potential](https://github.com/aiqm/torchani)\n- [Scaling the Scattering Transform: Deep Hybrid Networks](https://github.com/edouardoyallon/pyscatwave)\n- [CortexNet: a Generic Network Family for Robust Visual Temporal Representations](https://github.com/e-lab/pytorch-CortexNet)\n- [Oriented Response Networks](https://github.com/ZhouYanzhao/ORN)\n- [Associative Compression Networks](https://github.com/jalexvig/associative_compression_networks)\n- [Clarinet](https://github.com/ksw0306/ClariNet)\n- [Continuous Wavelet Transforms](https://github.com/tomrunia/PyTorchWavelets)\n- [mixup: Beyond Empirical Risk Minimization](https://github.com/leehomyc/mixup_pytorch)\n- [Network In Network](https://github.com/szagoruyko/functional-zoo)\n- [Highway Networks](https://github.com/c0nn3r/pytorch_highway_networks)\n- [Hybrid computing using a neural network with dynamic external memory](https://github.com/ypxie/pytorch-NeuCom)\n- [Value Iteration Networks](https://github.com/onlytailei/PyTorch-value-iteration-networks)\n- [Differentiable Neural Computer](https://github.com/jingweiz/pytorch-dnc)\n- [A Neural Representation of Sketch Drawings](https://github.com/alexis-jacq/Pytorch-Sketch-RNN)\n- [Understanding Deep Image Representations by Inverting Them](https://github.com/utkuozbulak/pytorch-cnn-visualizations)\n- [NIMA: Neural Image Assessment](https://github.com/truskovskiyk/nima.pytorch)\n- [NASNet-A-Mobile. Ported weights](https://github.com/veronikayurchuk/pretrained-models.pytorch)\n- [Graphics code generating model using Processing](https://github.com/jtoy/sketchnet)\n\n## <a name='Contributions'></a>Contributions\nDo feel free to contribute!\n\nYou can raise an issue or submit a pull request, whichever is more convenient for you. The guideline is simple: just follow the format of the previous bullet point or create a new section if it's a new category.\n",
	"deep-learning deep-neural-networks gpu-acceleration javascript machine-learning neural-network typescript webgl": "# This repository has been archived in favor of tensorflow/tfjs.\n\nThis repo will remain around for some time to keep history but all future PRs should be sent to [tensorflow/tfjs](https://github.com/tensorflow/tfjs) inside the tfjs-core folder.\n\nAll history and contributions have been preserved in the monorepo.",
	"ai artificial-intelligence caffe2 deep-learning deep-neural-networks machine-learning ml": "# [Source code now lives in the PyTorch repository](https://github.com/pytorch/pytorch/).\n\n## Caffe2\n\nCaffe2 is a lightweight, modular, and scalable deep learning framework. Building on the original [Caffe](http://caffe.berkeleyvision.org), Caffe2 is designed with expression, speed, and modularity in mind.\n\nLearn more about Caffe2 on the [caffe2.ai website](http://caffe2.ai/)\n",
	"arm convolution deep-learning deep-neural-networks embedded-devices machine-learning ml mnn vulkan winograd-algorithm": "![MNN](doc/banner.png)\n\n[\u4e2d\u6587\u7248\u672c](README_CN.md)\n\n[MNN Homepage](http://www.mnn.zone)\n\n## Intro\nMNN is a highly efficient and lightweight deep learning framework. It supports inference and training of deep learning models, and has industry leading performance for inference and training on-device. At present, MNN has been integrated in more than 30 apps of Alibaba Inc, such as Taobao, Tmall, Youku, Dingtalk, Xianyu and etc., covering more than 70 usage scenarios such as live broadcast, short video capture, search recommendation, product searching by image, interactive marketing, equity distribution, security risk control. In addition, MNN is also used on embedded devices, such as IoT.\n\n![architecture](doc/architecture.png)\n\nInside Alibaba, [MNN](https://mp.weixin.qq.com/s/5I1ISpx8lQqvCS8tGd6EJw) works as the basic module of the compute container in the [Walle](https://mp.weixin.qq.com/s/qpeCETty0BqqNJV9CMJafA) System, the first end-to-end, general-purpose, and large-scale production system for device-cloud collaborative machine learning, which has been published in the top system conference OSDI\u201922. The key design principles of MNN and the extensive benchmark testing results (vs. TensorFlow, TensorFlow Lite, PyTorch, PyTorch Mobile, TVM) can be found in the OSDI paper. The scripts and instructions for benchmark testing are put in the path \u201c/benchmark\u201d. If MNN or the design of Walle helps your research or production use, please cite our OSDI paper as follows:\n\n    @inproceedings {proc:osdi22:walle,\n        author = {Chengfei Lv and Chaoyue Niu and Renjie Gu and Xiaotang Jiang and Zhaode Wang and Bin Liu and Ziqi Wu and Qiulin Yao and Congyu Huang and Panos Huang and Tao Huang and Hui Shu and Jinde Song and Bin Zou and Peng Lan and Guohuan Xu and Fei Wu and Shaojie Tang and Fan Wu and Guihai Chen},\n        title = {Walle: An {End-to-End}, {General-Purpose}, and {Large-Scale} Production System for {Device-Cloud} Collaborative Machine Learning},\n        booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},\n        year = {2022},\n        isbn = {978-1-939133-28-1},\n        address = {Carlsbad, CA},\n        pages = {249--265},\n        url = {https://www.usenix.org/conference/osdi22/presentation/lv},\n        publisher = {USENIX Association},\n        month = jul,\n    }\n\n\n## Documentation and Workbench\nMNN's docs are in placed in [Yuque docs here](https://www.yuque.com/mnn/en) and [Read the docs](https://mnn-docs.readthedocs.io/en/latest).\n\nMNN Workbench could be downloaded from [MNN's homepage](http://www.mnn.zone), which provides pretrained models, visualized training tools, and one-click deployment of models to devices.\n\n## Key Features\n### Lightweight\n- Optimized for devices, no dependencies, can be easily deployed to mobile devices and a variety of embedded devices.\n- iOS platform: static library size will full option for armv7+arm64 platforms is about 12MB, size increase of linked executables is about 2M.\n- Android platform: core so size is about 800KB (armv7a - c++_shared).\n- Use MNN_BUILD_MINI can reduce package size about 25% , with limit of fix model input size\n- Support FP16 / Int8 qunatize, can reduce model size 50%-70%\n\n### Versatility\n- Supports `Tensorflow`, `Caffe`, `ONNX`,`Torchscripts` and supports common neural networks such as `CNN`, `RNN`, `GAN`, `Transformork`.\n- Supports AI model with multi-inputs or multi-outputs, every kind of dimenstion format, dynamic inputs, controlflow.\n- MNN supports approximate full OPs used for AI Model. The converter supports 178 `Tensorflow` OPs, 52 `Caffe` OPs, 163 `Torchscripts` OPs, 158 `ONNX` OPs.\n- Supports iOS 8.0+, Android 4.3+ and embedded devices with POSIX interface.\n- Supports hybrid computing on multiple devices. Currently supports CPU and GPU.\n\n\n### High performance\n- Implements core computing with lots of optimized assembly code to make full use of the ARM / x64 CPU.\n- Use Metal / OpenCL / Vulkan to support GPU inference on mobile.\n- Use CUDA and tensorcore to support NVIDIA GPU for better performance\n- Convolution and transposition convolution algorithms are efficient and stable. The Winograd convolution algorithm is widely used to better symmetric convolutions such as 3x3,4x4,5x5,6x6,7x7.\n- Twice speed increase for the new architecture ARM v8.2 with FP16 half-precision calculation support. 2.5 faster to use sdot for ARM v8.2 and VNNI.\n\n### Ease of use\n- Support use MNN's OP to do numerical calculating like numpy.\n- Support lightweight image process module like OpenCV, which is only 100k.\n- Support build model and train it on PC / mobile.\n- MNN Python API helps ML engineers to easily use MNN to inference, train, process image, without dipping their toes in C++ code.\n\nThe Architecture / Precision MNN supported is shown below:\n\n- S \uff1aSupport and work well, deeply optimized, recommend to use\n- A \uff1aSupport and work well, can use\n- B \uff1aSupport but has bug or not optimized, no recommend to use\n- C \uff1aNot Support\n\n| Architecture / Precision |  | Normal | FP16 | BF16 | Int8 |\n| --- | --- | --- | --- | --- | --- |\n| CPU | Native | B | C | B | B |\n|  | x86/x64-SSE4.1 | A | B | B | A |\n|  | x86/x64-AVX2 | S | B | B | A |\n|  | x86/x64-AVX512 | S | B | B | S |\n|  | ARMv7a | S | S (ARMv8.2) | S | S |\n|  | ARMv8 | S | S (ARMv8.2) | S(ARMv8.6) | S |\n| GPU | OpenCL | A | S | C | C |\n|  | Vulkan | A | A | C | C |\n|  | Metal | A | S | C | C |\n|  | CUDA | A | S | C | C |\n| NPU | CoreML | B | B | C | C |\n|  | HIAI | B | C | C | B |\n|  | NNAPI | B | B | C | C |\n\n\n\n## Tools\n\nBase on MNN (Tensor compute engine), we provided a series of tools for inference, train and general computation.\n\n- MNN-Converter: Convert other model to MNN model for inference, such as Tensorflow(lite), Caffe, ONNX, Torchscripts. And do graph optimization to reduce computation.\n- MNN-Compress: Compress model to reduce size and increase performance / speed\n- MNN-Express: Support model with controlflow, use MNN's OP to do general-purpose compute.\n- MNN-CV: An OpenCV liked library, but based on MNN and then much more lightweight.\n- MNN-Train: Support train MNN model.\n\n## How to Discuss and Get Help From MNN Community\n\nThe group discussions are predominantly Chinese. But we welcome and will help English speakers.\n\nDingtalk discussion groups:\n\nGroup #1 (Full): 23329087\n\nGroup #2 (Full): 23350225\n\nGroup #3: https://h5.dingtalk.com/circle/healthCheckin.html?dtaction=os&corpId=ding8989a1d6ae6ef130b177420cc0e366ea&f0c81=1b93a&cbdbhh=qwertyuiop\n\n## Historical Paper\n\nThe preliminary version of MNN, as mobile inference engine and with the focus on manual optimization, has also been published in MLSys 2020. Please cite the paper, if MNN previously helped your research:\n\n\n    @inproceedings{alibaba2020mnn,\n      author = {Jiang, Xiaotang and Wang, Huan and Chen, Yiliu and Wu, Ziqi and Wang, Lichuan and Zou, Bin and Yang, Yafeng and Cui, Zongyang and Cai, Yu and Yu, Tianhang and Lv, Chengfei and Wu, Zhihua},\n      title = {MNN: A Universal and Efficient Inference Engine},\n      booktitle = {MLSys},\n      year = {2020}\n    }\n\n\n## License\nApache 2.0\n\n## Acknowledgement\nMNN participants: Taobao Technology Department, Search Engineering Team, DAMO Team, Youku and other Alibaba Group employees.\n\nMNN refers to the following projects:\n- [Caffe](https://github.com/BVLC/caffe)\n- [flatbuffer](https://github.com/google/flatbuffers)\n- [gemmlowp](https://github.com/google/gemmlowp)\n- [Google Vulkan demo](http://www.github.com/googlesamples/android-vulkan-tutorials)\n- [Halide](https://github.com/halide/Halide)\n- [Mace](https://github.com/XiaoMi/mace)\n- [ONNX](https://github.com/onnx/onnx)\n- [protobuffer](https://github.com/protocolbuffers/protobuf)\n- [skia](https://github.com/google/skia)\n- [Tensorflow](https://github.com/tensorflow/tensorflow)\n- [ncnn](https://github.com/Tencent/ncnn)\n- [paddle-mobile](https://github.com/PaddlePaddle/paddle-mobile)\n- [stb](https://github.com/nothings/stb)\n- [rapidjson](https://github.com/Tencent/rapidjson)\n- [pybind11](https://github.com/pybind/pybind11)\n- [pytorch](https://github.com/pytorch/pytorch)\n- [bolt](https://github.com/huawei-noah/bolt)\n- [libyuv](https://chromium.googlesource.com/libyuv/libyuv)\n- [libjpeg](https://github.com/libjpeg-turbo/libjpeg-turbo)\n- [opencv](https://github.com/opencv/opencv)\n",
	"convolutional-networks convolutional-neural-networks darknet deep-learning deep-neural-networks graph image-processing machine-learning mobile-development object-detection real-time tensorflow": "## Intro\n\n[![Build Status](https://travis-ci.org/thtrieu/darkflow.svg?branch=master)](https://travis-ci.org/thtrieu/darkflow) [![codecov](https://codecov.io/gh/thtrieu/darkflow/branch/master/graph/badge.svg)](https://codecov.io/gh/thtrieu/darkflow)\n\nReal-time object detection and classification. Paper: [version 1](https://arxiv.org/pdf/1506.02640.pdf), [version 2](https://arxiv.org/pdf/1612.08242.pdf).\n\nRead more about YOLO (in darknet) and download weight files [here](http://pjreddie.com/darknet/yolo/). In case the weight file cannot be found, I uploaded some of mine [here](https://drive.google.com/drive/folders/0B1tW_VtY7onidEwyQ2FtQVplWEU), which include `yolo-full` and `yolo-tiny` of v1.0, `tiny-yolo-v1.1` of v1.1 and `yolo`, `tiny-yolo-voc` of v2.\n\n\nSee demo below or see on [this imgur](http://i.imgur.com/EyZZKAA.gif)\n\n<p align=\"center\"> <img src=\"demo.gif\"/> </p>\n\n## Dependencies\n\nPython3, tensorflow 1.0, numpy, opencv 3.\n\n## Citation\n\n```\n@article{trieu2018darkflow,\n  title={Darkflow},\n  author={Trieu, Trinh Hoang},\n  journal={GitHub Repository. Available online: https://github. com/thtrieu/darkflow (accessed on 14 February 2019)},\n  year={2018}\n}\n```\n\n### Getting started\n\nYou can choose _one_ of the following three ways to get started with darkflow.\n\n1. Just build the Cython extensions in place. NOTE: If installing this way you will have to use `./flow` in the cloned darkflow directory instead of `flow` as darkflow is not installed globally.\n    ```\n    python3 setup.py build_ext --inplace\n    ```\n\n2. Let pip install darkflow globally in dev mode (still globally accessible, but changes to the code immediately take effect)\n    ```\n    pip install -e .\n    ```\n\n3. Install with pip globally\n    ```\n    pip install .\n    ```\n\n## Update\n\n**Android demo on Tensorflow's** [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorFlowYoloDetector.java)\n\n**I am looking for help:**\n - `help wanted` labels in issue track\n\n## Parsing the annotations\n\nSkip this if you are not training or fine-tuning anything (you simply want to forward flow a trained net)\n\nFor example, if you want to work with only 3 classes `tvmonitor`, `person`, `pottedplant`; edit `labels.txt` as follows\n\n```\ntvmonitor\nperson\npottedplant\n```\n\nAnd that's it. `darkflow` will take care of the rest. You can also set darkflow to load from a custom labels file with the `--labels` flag (i.e. `--labels myOtherLabelsFile.txt`). This can be helpful when working with multiple models with different sets of output labels. When this flag is not set, darkflow will load from `labels.txt` by default (unless you are using one of the recognized `.cfg` files designed for the COCO or VOC dataset - then the labels file will be ignored and the COCO or VOC labels will be loaded).\n\n## Design the net\n\nSkip this if you are working with one of the original configurations since they are already there. Otherwise, see the following example:\n\n```python\n...\n\n[convolutional]\nbatch_normalize = 1\nsize = 3\nstride = 1\npad = 1\nactivation = leaky\n\n[maxpool]\n\n[connected]\noutput = 4096\nactivation = linear\n\n...\n```\n\n## Flowing the graph using `flow`\n\n```bash\n# Have a look at its options\nflow --h\n```\n\nFirst, let's take a closer look at one of a very useful option `--load`\n\n```bash\n# 1. Load tiny-yolo.weights\nflow --model cfg/tiny-yolo.cfg --load bin/tiny-yolo.weights\n\n# 2. To completely initialize a model, leave the --load option\nflow --model cfg/yolo-new.cfg\n\n# 3. It is useful to reuse the first identical layers of tiny for `yolo-new`\nflow --model cfg/yolo-new.cfg --load bin/tiny-yolo.weights\n# this will print out which layers are reused, which are initialized\n```\n\nAll input images from default folder `sample_img/` are flowed through the net and predictions are put in `sample_img/out/`. We can always specify more parameters for such forward passes, such as detection threshold, batch size, images folder, etc.\n\n```bash\n# Forward all images in sample_img/ using tiny yolo and 100% GPU usage\nflow --imgdir sample_img/ --model cfg/tiny-yolo.cfg --load bin/tiny-yolo.weights --gpu 1.0\n```\njson output can be generated with descriptions of the pixel location of each bounding box and the pixel location. Each prediction is stored in the `sample_img/out` folder by default. An example json array is shown below.\n```bash\n# Forward all images in sample_img/ using tiny yolo and JSON output.\nflow --imgdir sample_img/ --model cfg/tiny-yolo.cfg --load bin/tiny-yolo.weights --json\n```\nJSON output:\n```json\n[{\"label\":\"person\", \"confidence\": 0.56, \"topleft\": {\"x\": 184, \"y\": 101}, \"bottomright\": {\"x\": 274, \"y\": 382}},\n{\"label\": \"dog\", \"confidence\": 0.32, \"topleft\": {\"x\": 71, \"y\": 263}, \"bottomright\": {\"x\": 193, \"y\": 353}},\n{\"label\": \"horse\", \"confidence\": 0.76, \"topleft\": {\"x\": 412, \"y\": 109}, \"bottomright\": {\"x\": 592,\"y\": 337}}]\n```\n - label: self explanatory\n - confidence: somewhere between 0 and 1 (how confident yolo is about that detection)\n - topleft: pixel coordinate of top left corner of box.\n - bottomright: pixel coordinate of bottom right corner of box.\n\n## Training new model\n\nTraining is simple as you only have to add option `--train`. Training set and annotation will be parsed if this is the first time a new configuration is trained. To point to training set and annotations, use option `--dataset` and `--annotation`. A few examples:\n\n```bash\n# Initialize yolo-new from yolo-tiny, then train the net on 100% GPU:\nflow --model cfg/yolo-new.cfg --load bin/tiny-yolo.weights --train --gpu 1.0\n\n# Completely initialize yolo-new and train it with ADAM optimizer\nflow --model cfg/yolo-new.cfg --train --trainer adam\n```\n\nDuring training, the script will occasionally save intermediate results into Tensorflow checkpoints, stored in `ckpt/`. To resume to any checkpoint before performing training/testing, use `--load [checkpoint_num]` option, if `checkpoint_num < 0`, `darkflow` will load the most recent save by parsing `ckpt/checkpoint`.\n\n```bash\n# Resume the most recent checkpoint for training\nflow --train --model cfg/yolo-new.cfg --load -1\n\n# Test with checkpoint at step 1500\nflow --model cfg/yolo-new.cfg --load 1500\n\n# Fine tuning yolo-tiny from the original one\nflow --train --model cfg/tiny-yolo.cfg --load bin/tiny-yolo.weights\n```\n\nExample of training on Pascal VOC 2007:\n```bash\n# Download the Pascal VOC dataset:\ncurl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\ntar xf VOCtest_06-Nov-2007.tar\n\n# An example of the Pascal VOC annotation format:\nvim VOCdevkit/VOC2007/Annotations/000001.xml\n\n# Train the net on the Pascal dataset:\nflow --model cfg/yolo-new.cfg --train --dataset \"~/VOCdevkit/VOC2007/JPEGImages\" --annotation \"~/VOCdevkit/VOC2007/Annotations\"\n```\n\n### Training on your own dataset\n\n*The steps below assume we want to use tiny YOLO and our dataset has 3 classes*\n\n1. Create a copy of the configuration file `tiny-yolo-voc.cfg` and rename it according to your preference `tiny-yolo-voc-3c.cfg` (It is crucial that you leave the original `tiny-yolo-voc.cfg` file unchanged, see below for explanation).\n\n2. In `tiny-yolo-voc-3c.cfg`, change classes in the [region] layer (the last layer) to the number of classes you are going to train for. In our case, classes are set to 3.\n    \n    ```python\n    ...\n\n    [region]\n    anchors = 1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52\n    bias_match=1\n    classes=3\n    coords=4\n    num=5\n    softmax=1\n    \n    ...\n    ```\n\n3. In `tiny-yolo-voc-3c.cfg`, change filters in the [convolutional] layer (the second to last layer) to num * (classes + 5). In our case, num is 5 and classes are 3 so 5 * (3 + 5) = 40 therefore filters are set to 40.\n    \n    ```python\n    ...\n\n    [convolutional]\n    size=1\n    stride=1\n    pad=1\n    filters=40\n    activation=linear\n\n    [region]\n    anchors = 1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52\n    \n    ...\n    ```\n\n4. Change `labels.txt` to include the label(s) you want to train on (number of labels should be the same as the number of classes you set in `tiny-yolo-voc-3c.cfg` file). In our case, `labels.txt` will contain 3 labels.\n\n    ```\n    label1\n    label2\n    label3\n    ```\n5. Reference the `tiny-yolo-voc-3c.cfg` model when you train.\n\n    `flow --model cfg/tiny-yolo-voc-3c.cfg --load bin/tiny-yolo-voc.weights --train --annotation train/Annotations --dataset train/Images`\n\n\n* Why should I leave the original `tiny-yolo-voc.cfg` file unchanged?\n    \n    When darkflow sees you are loading `tiny-yolo-voc.weights` it will look for `tiny-yolo-voc.cfg` in your cfg/ folder and compare that configuration file to the new one you have set with `--model cfg/tiny-yolo-voc-3c.cfg`. In this case, every layer will have the same exact number of weights except for the last two, so it will load the weights into all layers up to the last two because they now contain different number of weights.\n\n\n## Camera/video file demo\n\nFor a demo that entirely runs on the CPU:\n\n```bash\nflow --model cfg/yolo-new.cfg --load bin/yolo-new.weights --demo videofile.avi\n```\n\nFor a demo that runs 100% on the GPU:\n\n```bash\nflow --model cfg/yolo-new.cfg --load bin/yolo-new.weights --demo videofile.avi --gpu 1.0\n```\n\nTo use your webcam/camera, simply replace `videofile.avi` with keyword `camera`.\n\nTo save a video with predicted bounding box, add `--saveVideo` option.\n\n## Using darkflow from another python application\n\nPlease note that `return_predict(img)` must take an `numpy.ndarray`. Your image must be loaded beforehand and passed to `return_predict(img)`. Passing the file path won't work.\n\nResult from `return_predict(img)` will be a list of dictionaries representing each detected object's values in the same format as the JSON output listed above.\n\n```python\nfrom darkflow.net.build import TFNet\nimport cv2\n\noptions = {\"model\": \"cfg/yolo.cfg\", \"load\": \"bin/yolo.weights\", \"threshold\": 0.1}\n\ntfnet = TFNet(options)\n\nimgcv = cv2.imread(\"./sample_img/sample_dog.jpg\")\nresult = tfnet.return_predict(imgcv)\nprint(result)\n```\n\n\n## Save the built graph to a protobuf file (`.pb`)\n\n```bash\n## Saving the lastest checkpoint to protobuf file\nflow --model cfg/yolo-new.cfg --load -1 --savepb\n\n## Saving graph and weights to protobuf file\nflow --model cfg/yolo.cfg --load bin/yolo.weights --savepb\n```\nWhen saving the `.pb` file, a `.meta` file will also be generated alongside it. This `.meta` file is a JSON dump of everything in the `meta` dictionary that contains information nessecary for post-processing such as `anchors` and `labels`. This way, everything you need to make predictions from the graph and do post processing is contained in those two files - no need to have the `.cfg` or any labels file tagging along.\n\nThe created `.pb` file can be used to migrate the graph to mobile devices (JAVA / C++ / Objective-C++). The name of input tensor and output tensor are respectively `'input'` and `'output'`. For further usage of this protobuf file, please refer to the official documentation of `Tensorflow` on C++ API [_here_](https://www.tensorflow.org/versions/r0.9/api_docs/cc/index.html). To run it on, say, iOS application, simply add the file to Bundle Resources and update the path to this file inside source code.\n\nAlso, darkflow supports loading from a `.pb` and `.meta` file for generating predictions (instead of loading from a `.cfg` and checkpoint or `.weights`).\n```bash\n## Forward images in sample_img for predictions based on protobuf file\nflow --pbLoad built_graph/yolo.pb --metaLoad built_graph/yolo.meta --imgdir sample_img/\n```\nIf you'd like to load a `.pb` and `.meta` file when using `return_predict()` you can set the `\"pbLoad\"` and `\"metaLoad\"` options in place of the `\"model\"` and `\"load\"` options you would normally set.\n\nThat's all.\n",
	"computer-graphics computer-vision deep-learning deep-neural-networks gan generative-adversarial-network image-to-image-translation pix2pix pytorch": "<img src='imgs/teaser_720.gif' align=\"right\" width=360>\r\n\r\n<br><br><br><br>\r\n\r\n# pix2pixHD\r\n### [Project](https://tcwang0509.github.io/pix2pixHD/) | [Youtube](https://youtu.be/3AIpPlzM_qs) | [Paper](https://arxiv.org/pdf/1711.11585.pdf) <br>\r\nPytorch implementation of our method for high-resolution (e.g. 2048x1024) photorealistic image-to-image translation. It can be used for turning semantic label maps into photo-realistic images or synthesizing portraits from face label maps. <br><br>\r\n[High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs](https://tcwang0509.github.io/pix2pixHD/)  \r\n [Ting-Chun Wang](https://tcwang0509.github.io/)<sup>1</sup>, [Ming-Yu Liu](http://mingyuliu.net/)<sup>1</sup>, [Jun-Yan Zhu](http://people.eecs.berkeley.edu/~junyanz/)<sup>2</sup>, Andrew Tao<sup>1</sup>, [Jan Kautz](http://jankautz.com/)<sup>1</sup>, [Bryan Catanzaro](http://catanzaro.name/)<sup>1</sup>  \r\n <sup>1</sup>NVIDIA Corporation, <sup>2</sup>UC Berkeley  \r\n In CVPR 2018.  \r\n\r\n## Image-to-image translation at 2k/1k resolution\r\n- Our label-to-streetview results\r\n<p align='center'>  \r\n  <img src='imgs/teaser_label.png' width='400'/>\r\n  <img src='imgs/teaser_ours.jpg' width='400'/>\r\n</p>\r\n- Interactive editing results\r\n<p align='center'>  \r\n  <img src='imgs/teaser_style.gif' width='400'/>\r\n  <img src='imgs/teaser_label.gif' width='400'/>\r\n</p>\r\n- Additional streetview results\r\n<p align='center'>\r\n  <img src='imgs/cityscapes_1.jpg' width='400'/>\r\n  <img src='imgs/cityscapes_2.jpg' width='400'/>\r\n</p>\r\n<p align='center'>\r\n  <img src='imgs/cityscapes_3.jpg' width='400'/>\r\n  <img src='imgs/cityscapes_4.jpg' width='400'/>\r\n</p>\r\n\r\n- Label-to-face and interactive editing results\r\n<p align='center'>\r\n  <img src='imgs/face1_1.jpg' width='250'/>\r\n  <img src='imgs/face1_2.jpg' width='250'/>\r\n  <img src='imgs/face1_3.jpg' width='250'/>\r\n</p>\r\n<p align='center'>\r\n  <img src='imgs/face2_1.jpg' width='250'/>\r\n  <img src='imgs/face2_2.jpg' width='250'/>\r\n  <img src='imgs/face2_3.jpg' width='250'/>\r\n</p>\r\n\r\n- Our editing interface\r\n<p align='center'>\r\n  <img src='imgs/city_short.gif' width='330'/>\r\n  <img src='imgs/face_short.gif' width='450'/>\r\n</p>\r\n\r\n## Prerequisites\r\n- Linux or macOS\r\n- Python 2 or 3\r\n- NVIDIA GPU (11G memory or larger) + CUDA cuDNN\r\n\r\n## Getting Started\r\n### Installation\r\n- Install PyTorch and dependencies from http://pytorch.org\r\n- Install python libraries [dominate](https://github.com/Knio/dominate).\r\n```bash\r\npip install dominate\r\n```\r\n- Clone this repo:\r\n```bash\r\ngit clone https://github.com/NVIDIA/pix2pixHD\r\ncd pix2pixHD\r\n```\r\n\r\n\r\n### Testing\r\n- A few example Cityscapes test images are included in the `datasets` folder.\r\n- Please download the pre-trained Cityscapes model from [here](https://drive.google.com/file/d/1h9SykUnuZul7J3Nbms2QGH1wa85nbN2-/view?usp=sharing) (google drive link), and put it under `./checkpoints/label2city_1024p/`\r\n- Test the model (`bash ./scripts/test_1024p.sh`):\r\n```bash\r\n#!./scripts/test_1024p.sh\r\npython test.py --name label2city_1024p --netG local --ngf 32 --resize_or_crop none\r\n```\r\nThe test results will be saved to a html file here: `./results/label2city_1024p/test_latest/index.html`.\r\n\r\nMore example scripts can be found in the `scripts` directory.\r\n\r\n\r\n### Dataset\r\n- We use the Cityscapes dataset. To train a model on the full dataset, please download it from the [official website](https://www.cityscapes-dataset.com/) (registration required).\r\nAfter downloading, please put it under the `datasets` folder in the same way the example images are provided.\r\n\r\n\r\n### Training\r\n- Train a model at 1024 x 512 resolution (`bash ./scripts/train_512p.sh`):\r\n```bash\r\n#!./scripts/train_512p.sh\r\npython train.py --name label2city_512p\r\n```\r\n- To view training results, please checkout intermediate results in `./checkpoints/label2city_512p/web/index.html`.\r\nIf you have tensorflow installed, you can see tensorboard logs in `./checkpoints/label2city_512p/logs` by adding `--tf_log` to the training scripts.\r\n\r\n### Multi-GPU training\r\n- Train a model using multiple GPUs (`bash ./scripts/train_512p_multigpu.sh`):\r\n```bash\r\n#!./scripts/train_512p_multigpu.sh\r\npython train.py --name label2city_512p --batchSize 8 --gpu_ids 0,1,2,3,4,5,6,7\r\n```\r\nNote: this is not tested and we trained our model using single GPU only. Please use at your own discretion.\r\n\r\n### Training with Automatic Mixed Precision (AMP) for faster speed\r\n- To train with mixed precision support, please first install apex from: https://github.com/NVIDIA/apex\r\n- You can then train the model by adding `--fp16`. For example,\r\n```bash\r\n#!./scripts/train_512p_fp16.sh\r\npython -m torch.distributed.launch train.py --name label2city_512p --fp16\r\n```\r\nIn our test case, it trains about 80% faster with AMP on a Volta machine.\r\n\r\n### Training at full resolution\r\n- To train the images at full resolution (2048 x 1024) requires a GPU with 24G memory (`bash ./scripts/train_1024p_24G.sh`), or 16G memory if using mixed precision (AMP).\r\n- If only GPUs with 12G memory are available, please use the 12G script (`bash ./scripts/train_1024p_12G.sh`), which will crop the images during training. Performance is not guaranteed using this script.\r\n\r\n### Training with your own dataset\r\n- If you want to train with your own dataset, please generate label maps which are one-channel whose pixel values correspond to the object labels (i.e. 0,1,...,N-1, where N is the number of labels). This is because we need to generate one-hot vectors from the label maps. Please also specity `--label_nc N` during both training and testing.\r\n- If your input is not a label map, please just specify `--label_nc 0` which will directly use the RGB colors as input. The folders should then be named `train_A`, `train_B` instead of `train_label`, `train_img`, where the goal is to translate images from A to B.\r\n- If you don't have instance maps or don't want to use them, please specify `--no_instance`.\r\n- The default setting for preprocessing is `scale_width`, which will scale the width of all training images to `opt.loadSize` (1024) while keeping the aspect ratio. If you want a different setting, please change it by using the `--resize_or_crop` option. For example, `scale_width_and_crop` first resizes the image to have width `opt.loadSize` and then does random cropping of size `(opt.fineSize, opt.fineSize)`. `crop` skips the resizing step and only performs random cropping. If you don't want any preprocessing, please specify `none`, which will do nothing other than making sure the image is divisible by 32.\r\n\r\n## More Training/Test Details\r\n- Flags: see `options/train_options.py` and `options/base_options.py` for all the training flags; see `options/test_options.py` and `options/base_options.py` for all the test flags.\r\n- Instance map: we take in both label maps and instance maps as input. If you don't want to use instance maps, please specify the flag `--no_instance`.\r\n\r\n\r\n## Citation\r\n\r\nIf you find this useful for your research, please use the following.\r\n\r\n```\r\n@inproceedings{wang2018pix2pixHD,\r\n  title={High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs},\r\n  author={Ting-Chun Wang and Ming-Yu Liu and Jun-Yan Zhu and Andrew Tao and Jan Kautz and Bryan Catanzaro},  \r\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\r\n  year={2018}\r\n}\r\n```\r\n\r\n## Acknowledgments\r\nThis code borrows heavily from [pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix).\r\n",
	"c-plus-plus computer-vision deep-learning image-processing opencv": "## OpenCV: Open Source Computer Vision Library\n\n### Resources\n\n* Homepage: <https://opencv.org>\n  * Courses: <https://opencv.org/courses>\n* Docs: <https://docs.opencv.org/4.x/>\n* Q&A forum: <https://forum.opencv.org>\n  * previous forum (read only): <http://answers.opencv.org>\n* Issue tracking: <https://github.com/opencv/opencv/issues>\n* Additional OpenCV functionality: <https://github.com/opencv/opencv_contrib> \n\n\n### Contributing\n\nPlease read the [contribution guidelines](https://github.com/opencv/opencv/wiki/How_to_contribute) before starting work on a pull request.\n\n#### Summary of the guidelines:\n\n* One pull request per issue;\n* Choose the right base branch;\n* Include tests and documentation;\n* Clean up \"oops\" commits before submitting;\n* Follow the [coding style guide](https://github.com/opencv/opencv/wiki/Coding_Style_Guide).\n",
	"deep-learning python pytorch tensorflow tts voice-cloning": "# Real-Time Voice Cloning\nThis repository is an implementation of [Transfer Learning from Speaker Verification to\nMultispeaker Text-To-Speech Synthesis](https://arxiv.org/pdf/1806.04558.pdf) (SV2TTS) with a vocoder that works in real-time. This was my [master's thesis](https://matheo.uliege.be/handle/2268.2/6801).\n\nSV2TTS is a deep learning framework in three stages. In the first stage, one creates a digital representation of a voice from a few seconds of audio. In the second and third stages, this representation is used as reference to generate speech given arbitrary text.\n\n**Video demonstration** (click the picture):\n\n[![Toolbox demo](https://i.imgur.com/8lFUlgz.png)](https://www.youtube.com/watch?v=-O_hYhToKoA)\n\n\n\n### Papers implemented  \n| URL | Designation | Title | Implementation source |\n| --- | ----------- | ----- | --------------------- |\n|[**1806.04558**](https://arxiv.org/pdf/1806.04558.pdf) | **SV2TTS** | **Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis** | This repo |\n|[1802.08435](https://arxiv.org/pdf/1802.08435.pdf) | WaveRNN (vocoder) | Efficient Neural Audio Synthesis | [fatchord/WaveRNN](https://github.com/fatchord/WaveRNN) |\n|[1703.10135](https://arxiv.org/pdf/1703.10135.pdf) | Tacotron (synthesizer) | Tacotron: Towards End-to-End Speech Synthesis | [fatchord/WaveRNN](https://github.com/fatchord/WaveRNN)\n|[1710.10467](https://arxiv.org/pdf/1710.10467.pdf) | GE2E (encoder)| Generalized End-To-End Loss for Speaker Verification | This repo |\n\n## News\n**08/09/22**: Our team at Resemble.AI is releasing a voice conversion model (closed source), check out my demo [here](https://www.youtube.com/watch?v=f075EOzYKog). \n\n**10/01/22**: I recommend checking out [CoquiTTS](https://github.com/coqui-ai/tts). It's a good and up-to-date TTS repository targeted for the ML community. It can also do voice cloning and more, such as cross-language cloning or voice conversion.\n\n**28/12/21**: I've done a [major maintenance update](https://github.com/CorentinJ/Real-Time-Voice-Cloning/pull/961). Mostly, I've worked on making setup easier. Find new instructions in the section below.\n\n**14/02/21**: This repo now runs on PyTorch instead of Tensorflow, thanks to the help of @bluefish.\n\n**13/11/19**: I'm now working full time and I will rarely maintain this repo anymore. To anyone who reads this:\n- **If you just want to clone your voice (and not someone else's):** I recommend our free plan on [Resemble.AI](https://www.resemble.ai/). You will get a better voice quality and less prosody errors.\n- **If this is not your case:** proceed with this repository, but you might end up being disappointed by the results. If you're planning to work on a serious project, my strong advice: find another TTS repo. Go [here](https://github.com/CorentinJ/Real-Time-Voice-Cloning/issues/364) for more info.\n\n**20/08/19:** I'm working on [resemblyzer](https://github.com/resemble-ai/Resemblyzer), an independent package for the voice encoder (inference only). You can use your trained encoder models from this repo with it.\n\n\n## Setup\n\n### 1. Install Requirements\n1. Both Windows and Linux are supported. A GPU is recommended for training and for inference speed, but is not mandatory.\n2. Python 3.7 is recommended. Python 3.5 or greater should work, but you'll probably have to tweak the dependencies' versions. I recommend setting up a virtual environment using `venv`, but this is optional.\n3. Install [ffmpeg](https://ffmpeg.org/download.html#get-packages). This is necessary for reading audio files.\n4. Install [PyTorch](https://pytorch.org/get-started/locally/). Pick the latest stable version, your operating system, your package manager (pip by default) and finally pick any of the proposed CUDA versions if you have a GPU, otherwise pick CPU. Run the given command.\n5. Install the remaining requirements with `pip install -r requirements.txt`\n\n### 2. (Optional) Download Pretrained Models\nPretrained models are now downloaded automatically. If this doesn't work for you, you can manually download them [here](https://github.com/CorentinJ/Real-Time-Voice-Cloning/wiki/Pretrained-models).\n\n### 3. (Optional) Test Configuration\nBefore you download any dataset, you can begin by testing your configuration with:\n\n`python demo_cli.py`\n\nIf all tests pass, you're good to go.\n\n### 4. (Optional) Download Datasets\nFor playing with the toolbox alone, I only recommend downloading [`LibriSpeech/train-clean-100`](https://www.openslr.org/resources/12/train-clean-100.tar.gz). Extract the contents as `<datasets_root>/LibriSpeech/train-clean-100` where `<datasets_root>` is a directory of your choosing. Other datasets are supported in the toolbox, see [here](https://github.com/CorentinJ/Real-Time-Voice-Cloning/wiki/Training#datasets). You're free not to download any dataset, but then you will need your own data as audio files or you will have to record it with the toolbox.\n\n### 5. Launch the Toolbox\nYou can then try the toolbox:\n\n`python demo_toolbox.py -d <datasets_root>`  \nor  \n`python demo_toolbox.py`  \n\ndepending on whether you downloaded any datasets. If you are running an X-server or if you have the error `Aborted (core dumped)`, see [this issue](https://github.com/CorentinJ/Real-Time-Voice-Cloning/issues/11#issuecomment-504733590).\n",
	"deep-learning": "# Deep Learning Papers Reading Roadmap\n\n>If you are a newcomer to the Deep Learning area, the first question you may have is \"Which paper should I start reading from?\"\n\n>Here is a reading roadmap of Deep Learning papers!\n\nThe roadmap is constructed in accordance with the following four guidelines:\n\n- From outline to detail\n- From old to state-of-the-art\n- from generic to specific areas\n- focus on state-of-the-art\n\nYou will find many papers that are quite new but really worth reading.\n\nI would continue adding papers to this roadmap.\n\n\n---------------------------------------\n\n# 1 Deep Learning History and Basics\n\n## 1.0 Book\n\n**[0]** Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. \"**Deep learning**.\" An MIT Press book. (2015). [[html]](http://www.deeplearningbook.org/) **(Deep Learning Bible, you can read this book while reading following papers.)** :star::star::star::star::star:\n\n## 1.1 Survey\n\n**[1]** LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. \"**Deep learning**.\" Nature 521.7553 (2015): 436-444. [[pdf]](http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf) **(Three Giants' Survey)** :star::star::star::star::star:\n\n## 1.2 Deep Belief Network(DBN)(Milestone of Deep Learning Eve)\n\n**[2]** Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. \"**A fast learning algorithm for deep belief nets**.\" Neural computation 18.7 (2006): 1527-1554. [[pdf]](http://www.cs.toronto.edu/~hinton/absps/ncfast.pdf)**(Deep Learning Eve)** :star::star::star:\n\n**[3]** Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. \"**Reducing the dimensionality of data with neural networks**.\" Science 313.5786 (2006): 504-507. [[pdf]](http://www.cs.toronto.edu/~hinton/science.pdf) **(Milestone, Show the promise of deep learning)** :star::star::star:\n\n## 1.3 ImageNet Evolution\uff08Deep Learning broke out from here\uff09\n\n**[4]** Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \"**Imagenet classification with deep convolutional neural networks**.\" Advances in neural information processing systems. 2012. [[pdf]](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) **(AlexNet, Deep Learning Breakthrough)** :star::star::star::star::star:\n\n**[5]** Simonyan, Karen, and Andrew Zisserman. \"**Very deep convolutional networks for large-scale image recognition**.\" arXiv preprint arXiv:1409.1556 (2014). [[pdf]](https://arxiv.org/pdf/1409.1556.pdf) **(VGGNet,Neural Networks become very deep!)** :star::star::star:\n\n**[6]** Szegedy, Christian, et al. \"**Going deeper with convolutions**.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf) **(GoogLeNet)** :star::star::star:\n\n**[7]** He, Kaiming, et al. \"**Deep residual learning for image recognition**.\" arXiv preprint arXiv:1512.03385 (2015). [[pdf]](https://arxiv.org/pdf/1512.03385.pdf) **(ResNet,Very very deep networks, CVPR best paper)** :star::star::star::star::star:\n\n## 1.4 Speech Recognition Evolution\n\n**[8]** Hinton, Geoffrey, et al. \"**Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups**.\" IEEE Signal Processing Magazine 29.6 (2012): 82-97. [[pdf]](http://cs224d.stanford.edu/papers/maas_paper.pdf) **(Breakthrough in speech recognition)**:star::star::star::star:\n\n**[9]** Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. \"**Speech recognition with deep recurrent neural networks**.\" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [[pdf]](http://arxiv.org/pdf/1303.5778.pdf) **(RNN)**:star::star::star:\n\n**[10]** Graves, Alex, and Navdeep Jaitly. \"**Towards End-To-End Speech Recognition with Recurrent Neural Networks**.\" ICML. Vol. 14. 2014. [[pdf]](http://www.jmlr.org/proceedings/papers/v32/graves14.pdf):star::star::star:\n\n**[11]** Sak, Ha\u015fim, et al. \"**Fast and accurate recurrent neural network acoustic models for speech recognition**.\" arXiv preprint arXiv:1507.06947 (2015). [[pdf]](http://arxiv.org/pdf/1507.06947) **(Google Speech Recognition System)** :star::star::star:\n\n**[12]** Amodei, Dario, et al. \"**Deep speech 2: End-to-end speech recognition in english and mandarin**.\" arXiv preprint arXiv:1512.02595 (2015). [[pdf]](https://arxiv.org/pdf/1512.02595.pdf) **(Baidu Speech Recognition System)** :star::star::star::star:\n\n**[13]** W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig \"**Achieving Human Parity in Conversational Speech Recognition**.\" arXiv preprint arXiv:1610.05256 (2016). [[pdf]](https://arxiv.org/pdf/1610.05256v1) **(State-of-the-art in speech recognition, Microsoft)** :star::star::star::star:\n\n>After reading above papers, you will have a basic understanding of the Deep Learning history, the basic architectures of Deep Learning model(including CNN, RNN, LSTM) and how deep learning can be applied to image and speech recognition issues. The following papers will take you in-depth understanding of the Deep Learning method, Deep Learning in different areas of application and the frontiers. I suggest that you can choose the following papers based on your interests and research direction.\n\n#2 Deep Learning Method\n\n## 2.1 Model\n\n**[14]** Hinton, Geoffrey E., et al. \"**Improving neural networks by preventing co-adaptation of feature detectors**.\" arXiv preprint arXiv:1207.0580 (2012). [[pdf]](https://arxiv.org/pdf/1207.0580.pdf) **(Dropout)** :star::star::star:\n\n**[15]** Srivastava, Nitish, et al. \"**Dropout: a simple way to prevent neural networks from overfitting**.\" Journal of Machine Learning Research 15.1 (2014): 1929-1958. [[pdf]](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) :star::star::star:\n\n**[16]** Ioffe, Sergey, and Christian Szegedy. \"**Batch normalization: Accelerating deep network training by reducing internal covariate shift**.\" arXiv preprint arXiv:1502.03167 (2015). [[pdf]](http://arxiv.org/pdf/1502.03167) **(An outstanding Work in 2015)** :star::star::star::star:\n\n**[17]** Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \"**Layer normalization**.\" arXiv preprint arXiv:1607.06450 (2016). [[pdf]](https://arxiv.org/pdf/1607.06450.pdf?utm_source=sciontist.com&utm_medium=refer&utm_campaign=promote) **(Update of Batch Normalization)** :star::star::star::star:\n\n**[18]** Courbariaux, Matthieu, et al. \"**Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or\u22121**.\" [[pdf]](https://pdfs.semanticscholar.org/f832/b16cb367802609d91d400085eb87d630212a.pdf) **(New Model,Fast)**  :star::star::star:\n\n**[19]** Jaderberg, Max, et al. \"**Decoupled neural interfaces using synthetic gradients**.\" arXiv preprint arXiv:1608.05343 (2016). [[pdf]](https://arxiv.org/pdf/1608.05343) **(Innovation of Training Method,Amazing Work)** :star::star::star::star::star:\n\n**[20]** Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. \"Net2net: Accelerating learning via knowledge transfer.\" arXiv preprint arXiv:1511.05641 (2015). [[pdf]](https://arxiv.org/abs/1511.05641) **(Modify previously trained network to reduce training epochs)** :star::star::star:\n\n**[21]** Wei, Tao, et al. \"Network Morphism.\" arXiv preprint arXiv:1603.01670 (2016). [[pdf]](https://arxiv.org/abs/1603.01670) **(Modify previously trained network to reduce training epochs)** :star::star::star:\n\n## 2.2 Optimization\n\n**[22]** Sutskever, Ilya, et al. \"**On the importance of initialization and momentum in deep learning**.\" ICML (3) 28 (2013): 1139-1147. [[pdf]](http://www.jmlr.org/proceedings/papers/v28/sutskever13.pdf) **(Momentum optimizer)** :star::star:\n\n**[23]** Kingma, Diederik, and Jimmy Ba. \"**Adam: A method for stochastic optimization**.\" arXiv preprint arXiv:1412.6980 (2014). [[pdf]](http://arxiv.org/pdf/1412.6980) **(Maybe used most often currently)** :star::star::star:\n\n**[24]** Andrychowicz, Marcin, et al. \"**Learning to learn by gradient descent by gradient descent**.\" arXiv preprint arXiv:1606.04474 (2016). [[pdf]](https://arxiv.org/pdf/1606.04474) **(Neural Optimizer,Amazing Work)** :star::star::star::star::star:\n\n**[25]** Han, Song, Huizi Mao, and William J. Dally. \"**Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding**.\" CoRR, abs/1510.00149 2 (2015). [[pdf]](https://pdfs.semanticscholar.org/5b6c/9dda1d88095fa4aac1507348e498a1f2e863.pdf) **(ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup)** :star::star::star::star::star:\n\n**[26]** Iandola, Forrest N., et al. \"**SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size**.\" arXiv preprint arXiv:1602.07360 (2016). [[pdf]](http://arxiv.org/pdf/1602.07360) **(Also a new direction to optimize NN,DeePhi Tech Startup)** :star::star::star::star:\n\n**[27]** Glorat Xavier, Bengio Yoshua, et al. \"**Understanding the difficulty of training deep forward neural networks**.\" Proceedings of the thirteenth International Conference on Artificial Intelligence and Statistics, PMLR 9:249-256,2010. [[pdf]](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) :star::star::star::star:\n\n## 2.3 Unsupervised Learning / Deep Generative Model\n\n**[28]** Le, Quoc V. \"**Building high-level features using large scale unsupervised learning**.\" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [[pdf]](http://arxiv.org/pdf/1112.6209.pdf&embed) **(Milestone, Andrew Ng, Google Brain Project, Cat)** :star::star::star::star:\n\n\n**[29]** Kingma, Diederik P., and Max Welling. \"**Auto-encoding variational bayes**.\" arXiv preprint arXiv:1312.6114 (2013). [[pdf]](http://arxiv.org/pdf/1312.6114) **(VAE)** :star::star::star::star:\n\n**[30]** Goodfellow, Ian, et al. \"**Generative adversarial nets**.\" Advances in Neural Information Processing Systems. 2014. [[pdf]](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf) **(GAN,super cool idea)** :star::star::star::star::star:\n\n**[31]** Radford, Alec, Luke Metz, and Soumith Chintala. \"**Unsupervised representation learning with deep convolutional generative adversarial networks**.\" arXiv preprint arXiv:1511.06434 (2015). [[pdf]](http://arxiv.org/pdf/1511.06434) **(DCGAN)** :star::star::star::star:\n\n**[32]** Gregor, Karol, et al. \"**DRAW: A recurrent neural network for image generation**.\" arXiv preprint arXiv:1502.04623 (2015). [[pdf]](http://jmlr.org/proceedings/papers/v37/gregor15.pdf) **(VAE with attention, outstanding work)** :star::star::star::star::star:\n\n**[33]** Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. \"**Pixel recurrent neural networks**.\" arXiv preprint arXiv:1601.06759 (2016). [[pdf]](http://arxiv.org/pdf/1601.06759) **(PixelRNN)** :star::star::star::star:\n\n**[34]** Oord, Aaron van den, et al. \"Conditional image generation with PixelCNN decoders.\" arXiv preprint arXiv:1606.05328 (2016). [[pdf]](https://arxiv.org/pdf/1606.05328) **(PixelCNN)** :star::star::star::star:\n\n**[34]** S. Mehri et al., \"**SampleRNN: An Unconditional End-to-End Neural Audio Generation Model**.\" arXiv preprint \tarXiv:1612.07837 (2016). [[pdf]](https://arxiv.org/pdf/1612.07837.pdf) :star::star::star::star::star:\n\n## 2.4 RNN / Sequence-to-Sequence Model\n\n**[35]** Graves, Alex. \"**Generating sequences with recurrent neural networks**.\" arXiv preprint arXiv:1308.0850 (2013). [[pdf]](http://arxiv.org/pdf/1308.0850) **(LSTM, very nice generating result, show the power of RNN)** :star::star::star::star:\n\n**[36]** Cho, Kyunghyun, et al. \"**Learning phrase representations using RNN encoder-decoder for statistical machine translation**.\" arXiv preprint arXiv:1406.1078 (2014). [[pdf]](http://arxiv.org/pdf/1406.1078) **(First Seq-to-Seq Paper)** :star::star::star::star:\n\n**[37]** Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \"**Sequence to sequence learning with neural networks**.\" Advances in neural information processing systems. 2014. [[pdf]](https://arxiv.org/pdf/1409.3215.pdf) **(Outstanding Work)** :star::star::star::star::star:\n\n**[38]** Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. \"**Neural Machine Translation by Jointly Learning to Align and Translate**.\" arXiv preprint arXiv:1409.0473 (2014). [[pdf]](https://arxiv.org/pdf/1409.0473v7.pdf) :star::star::star::star:\n\n**[39]** Vinyals, Oriol, and Quoc Le. \"**A neural conversational model**.\" arXiv preprint arXiv:1506.05869 (2015). [[pdf]](http://arxiv.org/pdf/1506.05869.pdf%20(http://arxiv.org/pdf/1506.05869.pdf)) **(Seq-to-Seq on Chatbot)** :star::star::star:\n\n## 2.5 Neural Turing Machine\n\n**[40]** Graves, Alex, Greg Wayne, and Ivo Danihelka. \"**Neural turing machines**.\" arXiv preprint arXiv:1410.5401 (2014). [[pdf]](http://arxiv.org/pdf/1410.5401.pdf) **(Basic Prototype of Future Computer)** :star::star::star::star::star:\n\n**[41]** Zaremba, Wojciech, and Ilya Sutskever. \"**Reinforcement learning neural Turing machines**.\" arXiv preprint arXiv:1505.00521 362 (2015). [[pdf]](https://pdfs.semanticscholar.org/f10e/071292d593fef939e6ef4a59baf0bb3a6c2b.pdf) :star::star::star:\n\n**[42]** Weston, Jason, Sumit Chopra, and Antoine Bordes. \"**Memory networks**.\" arXiv preprint arXiv:1410.3916 (2014). [[pdf]](http://arxiv.org/pdf/1410.3916) :star::star::star:\n\n\n**[43]** Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. \"**End-to-end memory networks**.\" Advances in neural information processing systems. 2015. [[pdf]](http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf) :star::star::star::star:\n\n**[44]** Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. \"**Pointer networks**.\" Advances in Neural Information Processing Systems. 2015. [[pdf]](http://papers.nips.cc/paper/5866-pointer-networks.pdf) :star::star::star::star:\n\n**[45]** Graves, Alex, et al. \"**Hybrid computing using a neural network with dynamic external memory**.\" Nature (2016). [[pdf]](https://www.dropbox.com/s/0a40xi702grx3dq/2016-graves.pdf) **(Milestone,combine above papers' ideas)** :star::star::star::star::star:\n\n## 2.6 Deep Reinforcement Learning\n\n**[46]** Mnih, Volodymyr, et al. \"**Playing atari with deep reinforcement learning**.\" arXiv preprint arXiv:1312.5602 (2013). [[pdf]](http://arxiv.org/pdf/1312.5602.pdf)) **(First Paper named deep reinforcement learning)** :star::star::star::star:\n\n**[47]** Mnih, Volodymyr, et al. \"**Human-level control through deep reinforcement learning**.\" Nature 518.7540 (2015): 529-533. [[pdf]](https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf) **(Milestone)** :star::star::star::star::star:\n\n**[48]** Wang, Ziyu, Nando de Freitas, and Marc Lanctot. \"**Dueling network architectures for deep reinforcement learning**.\" arXiv preprint arXiv:1511.06581 (2015). [[pdf]](http://arxiv.org/pdf/1511.06581) **(ICLR best paper,great idea)**  :star::star::star::star:\n\n**[49]** Mnih, Volodymyr, et al. \"**Asynchronous methods for deep reinforcement learning**.\" arXiv preprint arXiv:1602.01783 (2016). [[pdf]](http://arxiv.org/pdf/1602.01783) **(State-of-the-art method)** :star::star::star::star::star:\n\n**[50]** Lillicrap, Timothy P., et al. \"**Continuous control with deep reinforcement learning**.\" arXiv preprint arXiv:1509.02971 (2015). [[pdf]](http://arxiv.org/pdf/1509.02971) **(DDPG)** :star::star::star::star:\n\n**[51]** Gu, Shixiang, et al. \"**Continuous Deep Q-Learning with Model-based Acceleration**.\" arXiv preprint arXiv:1603.00748 (2016). [[pdf]](http://arxiv.org/pdf/1603.00748) **(NAF)** :star::star::star::star:\n\n**[52]** Schulman, John, et al. \"**Trust region policy optimization**.\" CoRR, abs/1502.05477 (2015). [[pdf]](http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf) **(TRPO)** :star::star::star::star:\n\n**[53]** Silver, David, et al. \"**Mastering the game of Go with deep neural networks and tree search**.\" Nature 529.7587 (2016): 484-489. [[pdf]](http://willamette.edu/~levenick/cs448/goNature.pdf) **(AlphaGo)** :star::star::star::star::star:\n\n## 2.7 Deep Transfer Learning / Lifelong Learning / especially for RL\n\n**[54]** Bengio, Yoshua. \"**Deep Learning of Representations for Unsupervised and Transfer Learning**.\" ICML Unsupervised and Transfer Learning 27 (2012): 17-36. [[pdf]](http://www.jmlr.org/proceedings/papers/v27/bengio12a/bengio12a.pdf) **(A Tutorial)** :star::star::star:\n\n**[55]** Silver, Daniel L., Qiang Yang, and Lianghao Li. \"**Lifelong Machine Learning Systems: Beyond Learning Algorithms**.\" AAAI Spring Symposium: Lifelong Machine Learning. 2013. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.696.7800&rep=rep1&type=pdf) **(A brief discussion about lifelong learning)**  :star::star::star:\n\n**[56]** Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. \"**Distilling the knowledge in a neural network**.\" arXiv preprint arXiv:1503.02531 (2015). [[pdf]](http://arxiv.org/pdf/1503.02531) **(Godfather's Work)** :star::star::star::star:\n\n**[57]** Rusu, Andrei A., et al. \"**Policy distillation**.\" arXiv preprint arXiv:1511.06295 (2015). [[pdf]](http://arxiv.org/pdf/1511.06295) **(RL domain)** :star::star::star:\n\n**[58]** Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. \"**Actor-mimic: Deep multitask and transfer reinforcement learning**.\" arXiv preprint arXiv:1511.06342 (2015). [[pdf]](http://arxiv.org/pdf/1511.06342) **(RL domain)** :star::star::star:\n\n**[59]** Rusu, Andrei A., et al. \"**Progressive neural networks**.\" arXiv preprint arXiv:1606.04671 (2016). [[pdf]](https://arxiv.org/pdf/1606.04671) **(Outstanding Work, A novel idea)** :star::star::star::star::star:\n\n\n## 2.8 One Shot Deep Learning\n\n**[60]** Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. \"**Human-level concept learning through probabilistic program induction**.\" Science 350.6266 (2015): 1332-1338. [[pdf]](http://clm.utexas.edu/compjclub/wp-content/uploads/2016/02/lake2015.pdf) **(No Deep Learning,but worth reading)** :star::star::star::star::star:\n\n**[61]** Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. \"**Siamese Neural Networks for One-shot Image Recognition**.\"(2015) [[pdf]](http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf) :star::star::star:\n\n**[62]** Santoro, Adam, et al. \"**One-shot Learning with Memory-Augmented Neural Networks**.\" arXiv preprint arXiv:1605.06065 (2016). [[pdf]](http://arxiv.org/pdf/1605.06065) **(A basic step to one shot learning)** :star::star::star::star:\n\n**[63]** Vinyals, Oriol, et al. \"**Matching Networks for One Shot Learning**.\" arXiv preprint arXiv:1606.04080 (2016). [[pdf]](https://arxiv.org/pdf/1606.04080) :star::star::star:\n\n**[64]** Hariharan, Bharath, and Ross Girshick. \"**Low-shot visual object recognition**.\" arXiv preprint arXiv:1606.02819 (2016). [[pdf]](http://arxiv.org/pdf/1606.02819) **(A step to large data)** :star::star::star::star:\n\n\n# 3 Applications\n\n## 3.1 NLP(Natural Language Processing)\n\n**[1]** Antoine Bordes, et al. \"**Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing**.\" AISTATS(2012) [[pdf]](https://www.hds.utc.fr/~bordesan/dokuwiki/lib/exe/fetch.php?id=en%3Apubli&cache=cache&media=en:bordes12aistats.pdf) :star::star::star::star:\n\n**[2]** Mikolov, et al. \"**Distributed representations of words and phrases and their compositionality**.\" ANIPS(2013): 3111-3119 [[pdf]](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) **(word2vec)** :star::star::star:\n\n**[3]** Sutskever, et al. \"**\u201cSequence to sequence learning with neural networks**.\" ANIPS(2014) [[pdf]](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf) :star::star::star:\n\n**[4]** Ankit Kumar, et al. \"**\u201cAsk Me Anything: Dynamic Memory Networks for Natural Language Processing**.\" arXiv preprint arXiv:1506.07285(2015) [[pdf]](https://arxiv.org/abs/1506.07285) :star::star::star::star:\n\n**[5]** Yoon Kim, et al. \"**Character-Aware Neural Language Models**.\" NIPS(2015) arXiv preprint arXiv:1508.06615(2015) [[pdf]](https://arxiv.org/abs/1508.06615) :star::star::star::star:\n\n**[6]** Jason Weston, et al. \"**Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks**.\" arXiv preprint arXiv:1502.05698(2015) [[pdf]](https://arxiv.org/abs/1502.05698) **(bAbI tasks)** :star::star::star:\n\n**[7]** Karl Moritz Hermann, et al. \"**Teaching Machines to Read and Comprehend**.\" arXiv preprint arXiv:1506.03340(2015) [[pdf]](https://arxiv.org/abs/1506.03340) **(CNN/DailyMail cloze style questions)** :star::star:\n\n**[8]** Alexis Conneau, et al. \"**Very Deep Convolutional Networks for Natural Language Processing**.\" arXiv preprint arXiv:1606.01781(2016) [[pdf]](https://arxiv.org/abs/1606.01781) **(state-of-the-art in text classification)** :star::star::star:\n\n**[9]** Armand Joulin, et al. \"**Bag of Tricks for Efficient Text Classification**.\" arXiv preprint arXiv:1607.01759(2016) [[pdf]](https://arxiv.org/abs/1607.01759) **(slightly worse than state-of-the-art, but a lot faster)** :star::star::star:\n\n## 3.2 Object Detection\n\n**[1]** Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. \"**Deep neural networks for object detection**.\" Advances in Neural Information Processing Systems. 2013. [[pdf]](http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf) :star::star::star:\n\n**[2]** Girshick, Ross, et al. \"**Rich feature hierarchies for accurate object detection and semantic segmentation**.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf) **(RCNN)** :star::star::star::star::star:\n\n**[3]** He, Kaiming, et al. \"**Spatial pyramid pooling in deep convolutional networks for visual recognition**.\" European Conference on Computer Vision. Springer International Publishing, 2014. [[pdf]](http://arxiv.org/pdf/1406.4729) **(SPPNet)** :star::star::star::star:\n\n**[4]** Girshick, Ross. \"**Fast r-cnn**.\" Proceedings of the IEEE International Conference on Computer Vision. 2015. [[pdf]](https://pdfs.semanticscholar.org/8f67/64a59f0d17081f2a2a9d06f4ed1cdea1a0ad.pdf) :star::star::star::star:\n\n**[5]** Ren, Shaoqing, et al. \"**Faster R-CNN: Towards real-time object detection with region proposal networks**.\" Advances in neural information processing systems. 2015. [[pdf]](https://arxiv.org/pdf/1506.01497.pdf) :star::star::star::star:\n\n**[6]** Redmon, Joseph, et al. \"**You only look once: Unified, real-time object detection**.\" arXiv preprint arXiv:1506.02640 (2015). [[pdf]](http://homes.cs.washington.edu/~ali/papers/YOLO.pdf) **(YOLO,Oustanding Work, really practical)** :star::star::star::star::star:\n\n**[7]** Liu, Wei, et al. \"**SSD: Single Shot MultiBox Detector**.\" arXiv preprint arXiv:1512.02325 (2015). [[pdf]](http://arxiv.org/pdf/1512.02325) :star::star::star:\n\n**[8]** Dai, Jifeng, et al. \"**R-FCN: Object Detection via\nRegion-based Fully Convolutional Networks**.\" arXiv preprint arXiv:1605.06409 (2016). [[pdf]](https://arxiv.org/abs/1605.06409) :star::star::star::star:\n\n**[9]** He, Gkioxari, et al. \"**Mask R-CNN**\" arXiv preprint arXiv:1703.06870 (2017). [[pdf]](https://arxiv.org/abs/1703.06870) :star::star::star::star:\n\n**[10]** Bochkovskiy, Alexey, et al. \"**YOLOv4: Optimal Speed and Accuracy of Object Detection.**\"  arXiv preprint arXiv:2004.10934 (2020). [[pdf]](https://arxiv.org/pdf/2004.10934) :star::star::star::star:\n\n\n**[11]** Tan, Mingxing, et al. \u201c**EfficientDet: Scalable and Efficient Object Detection.**\" arXiv preprint arXiv:1911.09070 (2019). [[pdf]](https://arxiv.org/pdf/1911.09070) :star::star::star::star::star:\n\n\n## 3.3 Visual Tracking\n\n**[1]** Wang, Naiyan, and Dit-Yan Yeung. \"**Learning a deep compact image representation for visual tracking**.\" Advances in neural information processing systems. 2013. [[pdf]](http://papers.nips.cc/paper/5192-learning-a-deep-compact-image-representation-for-visual-tracking.pdf) **(First Paper to do visual tracking using Deep Learning,DLT Tracker)** :star::star::star:\n\n**[2]** Wang, Naiyan, et al. \"**Transferring rich feature hierarchies for robust visual tracking**.\" arXiv preprint arXiv:1501.04587 (2015). [[pdf]](http://arxiv.org/pdf/1501.04587) **(SO-DLT)** :star::star::star::star:\n\n**[3]** Wang, Lijun, et al. \"**Visual tracking with fully convolutional networks**.\" Proceedings of the IEEE International Conference on Computer Vision. 2015. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Wang_Visual_Tracking_With_ICCV_2015_paper.pdf) **(FCNT)** :star::star::star::star:\n\n**[4]** Held, David, Sebastian Thrun, and Silvio Savarese. \"**Learning to Track at 100 FPS with Deep Regression Networks**.\" arXiv preprint arXiv:1604.01802 (2016). [[pdf]](http://arxiv.org/pdf/1604.01802) **(GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods)** :star::star::star::star:\n\n**[5]** Bertinetto, Luca, et al. \"**Fully-Convolutional Siamese Networks for Object Tracking**.\" arXiv preprint arXiv:1606.09549 (2016). [[pdf]](https://arxiv.org/pdf/1606.09549) **(SiameseFC,New state-of-the-art for real-time object tracking)** :star::star::star::star:\n\n**[6]** Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. \"**Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking**.\" ECCV (2016) [[pdf]](http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/C-COT_ECCV16.pdf) **(C-COT)** :star::star::star::star:\n\n**[7]** Nam, Hyeonseob, Mooyeol Baek, and Bohyung Han. \"**Modeling and Propagating CNNs in a Tree Structure for Visual Tracking**.\" arXiv preprint arXiv:1608.07242 (2016). [[pdf]](https://arxiv.org/pdf/1608.07242) **(VOT2016 Winner,TCNN)** :star::star::star::star:\n\n## 3.4 Image Caption\n**[1]** Farhadi,Ali,etal. \"**Every picture tells a story: Generating sentences from images**\". In Computer VisionECCV 2010. Springer Berlin Heidelberg:15-29, 2010. [[pdf]](https://www.cs.cmu.edu/~afarhadi/papers/sentence.pdf) :star::star::star:\n\n**[2]** Kulkarni, Girish, et al. \"**Baby talk: Understanding and generating image descriptions**\". In Proceedings of the 24th CVPR, 2011. [[pdf]](http://tamaraberg.com/papers/generation_cvpr11.pdf):star::star::star::star:\n\n**[3]** Vinyals, Oriol, et al. \"**Show and tell: A neural image caption generator**\". In arXiv preprint arXiv:1411.4555, 2014. [[pdf]](https://arxiv.org/pdf/1411.4555.pdf):star::star::star:\n\n**[4]** Donahue, Jeff, et al. \"**Long-term recurrent convolutional networks for visual recognition and description**\". In arXiv preprint arXiv:1411.4389 ,2014. [[pdf]](https://arxiv.org/pdf/1411.4389.pdf)\n\n**[5]** Karpathy, Andrej, and Li Fei-Fei. \"**Deep visual-semantic alignments for generating image descriptions**\". In arXiv preprint arXiv:1412.2306, 2014. [[pdf]](https://cs.stanford.edu/people/karpathy/cvpr2015.pdf):star::star::star::star::star:\n\n**[6]** Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. \"**Deep fragment embeddings for bidirectional image sentence mapping**\". In Advances in neural information processing systems, 2014. [[pdf]](https://arxiv.org/pdf/1406.5679v1.pdf):star::star::star::star:\n\n**[7]** Fang, Hao, et al. \"**From captions to visual concepts and back**\". In arXiv preprint arXiv:1411.4952, 2014. [[pdf]](https://arxiv.org/pdf/1411.4952v3.pdf):star::star::star::star::star:\n\n**[8]** Chen, Xinlei, and C. Lawrence Zitnick. \"**Learning a recurrent visual representation for image caption generation**\". In arXiv preprint arXiv:1411.5654, 2014. [[pdf]](https://arxiv.org/pdf/1411.5654v1.pdf):star::star::star::star:\n\n**[9]** Mao, Junhua, et al. \"**Deep captioning with multimodal recurrent neural networks (m-rnn)**\". In arXiv preprint arXiv:1412.6632, 2014. [[pdf]](https://arxiv.org/pdf/1412.6632v5.pdf):star::star::star:\n\n**[10]** Xu, Kelvin, et al. \"**Show, attend and tell: Neural image caption generation with visual attention**\". In arXiv preprint arXiv:1502.03044, 2015. [[pdf]](https://arxiv.org/pdf/1502.03044v3.pdf):star::star::star::star::star:\n\n## 3.5 Machine Translation\n\n> Some milestone papers are listed in RNN / Seq-to-Seq topic.\n\n**[1]** Luong, Minh-Thang, et al. \"**Addressing the rare word problem in neural machine translation**.\" arXiv preprint arXiv:1410.8206 (2014). [[pdf]](http://arxiv.org/pdf/1410.8206) :star::star::star::star:\n\n\n**[2]** Sennrich, et al. \"**Neural Machine Translation of Rare Words with Subword Units**\". In arXiv preprint arXiv:1508.07909, 2015. [[pdf]](https://arxiv.org/pdf/1508.07909.pdf):star::star::star:\n\n**[3]** Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. \"**Effective approaches to attention-based neural machine translation**.\" arXiv preprint arXiv:1508.04025 (2015). [[pdf]](http://arxiv.org/pdf/1508.04025) :star::star::star::star:\n\n**[4]** Chung, et al. \"**A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation**\". In arXiv preprint arXiv:1603.06147, 2016. [[pdf]](https://arxiv.org/pdf/1603.06147.pdf):star::star:\n\n**[5]** Lee, et al. \"**Fully Character-Level Neural Machine Translation without Explicit Segmentation**\". In arXiv preprint arXiv:1610.03017, 2016. [[pdf]](https://arxiv.org/pdf/1610.03017.pdf):star::star::star::star::star:\n\n**[6]** Wu, Schuster, Chen, Le, et al. \"**Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation**\". In arXiv preprint arXiv:1609.08144v2, 2016. [[pdf]](https://arxiv.org/pdf/1609.08144v2.pdf) **(Milestone)** :star::star::star::star:\n\n## 3.6 Robotics\n\n**[1]** Koutn\u00edk, Jan, et al. \"**Evolving large-scale neural networks for vision-based reinforcement learning**.\" Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. [[pdf]](http://repository.supsi.ch/4550/1/koutnik2013gecco.pdf) :star::star::star:\n\n**[2]** Levine, Sergey, et al. \"**End-to-end training of deep visuomotor policies**.\" Journal of Machine Learning Research 17.39 (2016): 1-40. [[pdf]](http://www.jmlr.org/papers/volume17/15-522/15-522.pdf) :star::star::star::star::star:\n\n**[3]** Pinto, Lerrel, and Abhinav Gupta. \"**Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours**.\" arXiv preprint arXiv:1509.06825 (2015). [[pdf]](http://arxiv.org/pdf/1509.06825) :star::star::star:\n\n**[4]** Levine, Sergey, et al. \"**Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection**.\" arXiv preprint arXiv:1603.02199 (2016). [[pdf]](http://arxiv.org/pdf/1603.02199) :star::star::star::star:\n\n**[5]** Zhu, Yuke, et al. \"**Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning**.\" arXiv preprint arXiv:1609.05143 (2016). [[pdf]](https://arxiv.org/pdf/1609.05143) :star::star::star::star:\n\n**[6]** Yahya, Ali, et al. \"**Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search**.\" arXiv preprint arXiv:1610.00673 (2016). [[pdf]](https://arxiv.org/pdf/1610.00673) :star::star::star::star:\n\n**[7]** Gu, Shixiang, et al. \"**Deep Reinforcement Learning for Robotic Manipulation**.\" arXiv preprint arXiv:1610.00633 (2016). [[pdf]](https://arxiv.org/pdf/1610.00633) :star::star::star::star:\n\n**[8]** A Rusu, M Vecerik, Thomas Roth\u00f6rl, N Heess, R Pascanu, R Hadsell.\"**Sim-to-Real Robot Learning from Pixels with Progressive Nets**.\" arXiv preprint arXiv:1610.04286 (2016). [[pdf]](https://arxiv.org/pdf/1610.04286.pdf) :star::star::star::star:\n\n**[9]** Mirowski, Piotr, et al. \"**Learning to navigate in complex environments**.\" arXiv preprint arXiv:1611.03673 (2016). [[pdf]](https://arxiv.org/pdf/1611.03673) :star::star::star::star:\n\n## 3.7 Art\n\n**[1]** Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). \"**Inceptionism: Going Deeper into Neural Networks**\". Google Research. [[html]](https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html) **(Deep Dream)**\n:star::star::star::star:\n\n**[2]** Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. \"**A neural algorithm of artistic style**.\" arXiv preprint arXiv:1508.06576 (2015). [[pdf]](http://arxiv.org/pdf/1508.06576) **(Outstanding Work, most successful method currently)** :star::star::star::star::star:\n\n**[3]** Zhu, Jun-Yan, et al. \"**Generative Visual Manipulation on the Natural Image Manifold**.\" European Conference on Computer Vision. Springer International Publishing, 2016. [[pdf]](https://arxiv.org/pdf/1609.03552) **(iGAN)** :star::star::star::star:\n\n**[4]** Champandard, Alex J. \"**Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks**.\" arXiv preprint arXiv:1603.01768 (2016). [[pdf]](http://arxiv.org/pdf/1603.01768) **(Neural Doodle)** :star::star::star::star:\n\n**[5]** Zhang, Richard, Phillip Isola, and Alexei A. Efros. \"**Colorful Image Colorization**.\" arXiv preprint arXiv:1603.08511 (2016). [[pdf]](http://arxiv.org/pdf/1603.08511) :star::star::star::star:\n\n**[6]** Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. \"**Perceptual losses for real-time style transfer and super-resolution**.\" arXiv preprint arXiv:1603.08155 (2016). [[pdf]](https://arxiv.org/pdf/1603.08155.pdf) :star::star::star::star:\n\n**[7]** Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. \"**A learned representation for artistic style**.\" arXiv preprint arXiv:1610.07629 (2016). [[pdf]](https://arxiv.org/pdf/1610.07629v1.pdf) :star::star::star::star:\n\n**[8]** Gatys, Leon and Ecker, et al.\"**Controlling Perceptual Factors in Neural Style Transfer**.\" arXiv preprint arXiv:1611.07865 (2016). [[pdf]](https://arxiv.org/pdf/1611.07865.pdf) **(control style transfer over spatial location,colour information and across spatial scale)**:star::star::star::star:\n\n**[9]** Ulyanov, Dmitry and Lebedev, Vadim, et al. \"**Texture Networks: Feed-forward Synthesis of Textures and Stylized Images**.\" arXiv preprint arXiv:1603.03417(2016). [[pdf]](http://arxiv.org/abs/1603.03417) **(texture generation and style transfer)** :star::star::star::star:\n\n**[10]** Yijun Li, Ming-Yu Liu ,Xueting Li, Ming-Hsuan Yang,Jan Kautz (NVIDIA). \"**A Closed-form Solution to Photorealistic Image Stylization**.\" arXiv preprint arXiv:1802.06474(2018). [[pdf]](https://arxiv.org/pdf/1802.06474.pdf) **(Very fast and ultra realistic style transfer)** :star::star::star::star:\n\n## 3.8 Object Segmentation\n\n**[1]** J. Long, E. Shelhamer, and T. Darrell, \u201c**Fully convolutional networks for semantic segmentation**.\u201d in CVPR, 2015. [[pdf]](https://arxiv.org/pdf/1411.4038v2.pdf) :star::star::star::star::star:\n\n**[2]** L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. \"**Semantic image segmentation with deep convolutional nets and fully connected crfs**.\" In ICLR, 2015. [[pdf]](https://arxiv.org/pdf/1606.00915v1.pdf) :star::star::star::star::star:\n\n**[3]** Pinheiro, P.O., Collobert, R., Dollar, P. \"**Learning to segment object candidates.**\" In: NIPS. 2015. [[pdf]](https://arxiv.org/pdf/1506.06204v2.pdf) :star::star::star::star:\n\n**[4]** Dai, J., He, K., Sun, J. \"**Instance-aware semantic segmentation via multi-task network cascades**.\" in CVPR. 2016 [[pdf]](https://arxiv.org/pdf/1512.04412v1.pdf) :star::star::star:\n\n**[5]** Dai, J., He, K., Sun, J. \"**Instance-sensitive Fully Convolutional Networks**.\" arXiv preprint arXiv:1603.08678 (2016). [[pdf]](https://arxiv.org/pdf/1603.08678v1.pdf) :star::star::star:\n\n\n",
	"deep-learning javascript ocr tesseract webassembly": "<p align=\"center\">\n<a href=\"https://tesseract.projectnaptha.com/\"><img width=\"256px\" height=\"256px\" alt=\"Tesseract.js\" src=\"./docs/images/tesseract.png\"></a>\n</p>\n\n![Lint & Test](https://github.com/naptha/tesseract.js/workflows/Node.js%20CI/badge.svg)\n![CodeQL](https://github.com/naptha/tesseract.js/workflows/CodeQL/badge.svg)\n[![Gitpod Ready-to-Code](https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod)](https://github.com/naptha/tesseract.js) \n[![Financial Contributors on Open Collective](https://opencollective.com/tesseractjs/all/badge.svg?label=financial+contributors)](https://opencollective.com/tesseractjs) [![npm version](https://badge.fury.io/js/tesseract.js.svg)](https://badge.fury.io/js/tesseract.js)\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/naptha/tesseract.js/graphs/commit-activity)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![Code Style](https://badgen.net/badge/code%20style/airbnb/ff5a5f?icon=airbnb)](https://github.com/airbnb/javascript)\n[![Downloads Total](https://img.shields.io/npm/dt/tesseract.js.svg)](https://www.npmjs.com/package/tesseract.js)\n[![Downloads Month](https://img.shields.io/npm/dm/tesseract.js.svg)](https://www.npmjs.com/package/tesseract.js)\n\nTesseract.js is a javascript library that gets words in [almost any language](./docs/tesseract_lang_list.md) out of images. ([Demo](http://tesseract.projectnaptha.com/))\n\nImage Recognition\n\n[![fancy demo gif](./docs/images/demo.gif)](http://tesseract.projectnaptha.com)\n\nVideo Real-time Recognition\n\n<p align=\"center\">\n  <a href=\"https://github.com/jeromewu/tesseract.js-video\"><img alt=\"Tesseract.js Video\" src=\"./docs/images/video-demo.gif\"></a>\n</p>\n\n\nTesseract.js wraps an [emscripten](https://github.com/kripken/emscripten) [port](https://github.com/naptha/tesseract.js-core) of the [Tesseract](https://github.com/tesseract-ocr/tesseract) [OCR](https://en.wikipedia.org/wiki/Optical_character_recognition) Engine.\nIt works in the browser using [webpack](https://webpack.js.org/) or plain script tags with a [CDN](#CDN) and on the server with [Node.js](https://nodejs.org/en/).\nAfter you [install it](#installation), using it is as simple as:\n\n```javascript\nimport Tesseract from 'tesseract.js';\n\nTesseract.recognize(\n  'https://tesseract.projectnaptha.com/img/eng_bw.png',\n  'eng',\n  { logger: m => console.log(m) }\n).then(({ data: { text } }) => {\n  console.log(text);\n})\n```\n\nOr more imperative\n\n```javascript\nimport { createWorker } from 'tesseract.js';\n\nconst worker = await createWorker({\n  logger: m => console.log(m)\n});\n\n(async () => {\n  await worker.loadLanguage('eng');\n  await worker.initialize('eng');\n  const { data: { text } } = await worker.recognize('https://tesseract.projectnaptha.com/img/eng_bw.png');\n  console.log(text);\n  await worker.terminate();\n})();\n```\n\n[Check out the docs](#documentation) for a full explanation of the API.\n\n## Major changes in v4\nVersion 4 includes many new features and bug fixes--see [this issue](https://github.com/naptha/tesseract.js/issues/662) for a full list.  Several highlights are below. \n\n- Added rotation preprocessing options (including auto-rotate) for significantly better accuracy\n- Processed images (rotated, grayscale, binary) can now be retrieved\n- Improved support for parallel processing (schedulers)\n- Breaking changes:\n  - `createWorker` is now async\n  - `getPDF` function replaced by `pdf` recognize option\n\n## Major changes in v3\n- Significantly faster performance\n   - Runtime reduction of 84% for Browser and 96% for Node.js when recognizing the [example images](./examples/data)\n- Upgrade to Tesseract v5.1.0 (using emscripten 3.1.18)\n- Added SIMD-enabled build for supported devices\n- Added support:\n   - Node.js version 18\n- Removed support:\n   - ASM.js version, any other old versions of Tesseract.js-core (<3.0.0) \n   - Node.js versions 10 and 12\n\n## Major changes in v2\n- Upgrade to tesseract v4.1.1 (using emscripten 1.39.10 upstream)\n- Support multiple languages at the same time, eg: eng+chi\\_tra for English and Traditional Chinese\n- Supported image formats: png, jpg, bmp, pbm\n- Support WebAssembly (fallback to ASM.js when browser doesn't support)\n- Support Typescript\n\nRead a story about v2: <a href=\"https://jeromewu.github.io/why-i-refactor-tesseract.js-v2/\">Why I refactor tesseract.js v2?</a><br>\n  Check the <a href=\"https://github.com/naptha/tesseract.js/tree/support/1.x\">support/1.x</a> branch for version 1\n## Installation\nTesseract.js works with a `<script>` tag via local copy or CDN, with webpack via `npm` and on Node.js with `npm/yarn`.\n\n\n### CDN\n```html\n<!-- v4 -->\n<script src='https://unpkg.com/tesseract.js@4.0.0/dist/tesseract.min.js'></script>\n```\nAfter including the script the `Tesseract` variable will be globally available.\n\n\n### Node.js\n\n**Requires Node.js v14 or higher**\n\n```shell\n# For latest version\nnpm install tesseract.js\nyarn add tesseract.js\n\n# For old versions\nnpm install tesseract.js@3.0.3\nyarn add tesseract.js@3.0.3\n```\n\n\n## Documentation\n\n* [Examples](./docs/examples.md)\n* [Image Format](./docs/image-format.md)\n* [API](./docs/api.md)\n* [Local Installation](./docs/local-installation.md)\n* [FAQ](./docs/faq.md)\n\n## Use tesseract.js the way you like!\n\n- Offline Version: https://github.com/jeromewu/tesseract.js-offline\n- Electron Version: https://github.com/jeromewu/tesseract.js-electron\n- Custom Traineddata: https://github.com/jeromewu/tesseract.js-custom-traineddata\n- Chrome Extension #1: https://github.com/jeromewu/tesseract.js-chrome-extension\n- Chrome Extension #2: https://github.com/fxnoob/image-to-text\n- Firefox Extension: https://github.com/gnonio/korporize\n- With Vue: https://github.com/jeromewu/tesseract.js-vue-app\n- With Angular: https://github.com/jeromewu/tesseract.js-angular-app\n- With React: https://github.com/jeromewu/tesseract.js-react-app\n- Typescript: https://github.com/jeromewu/tesseract.js-typescript\n- Video Real-time Recognition: https://github.com/jeromewu/tesseract.js-video\n\n## Contributing\n\n### Development\nTo run a development copy of Tesseract.js do the following:\n```shell\n# First we clone the repository\ngit clone https://github.com/naptha/tesseract.js.git\ncd tesseract.js\n\n# Then we install the dependencies\nnpm install\n\n# And finally we start the development server\nnpm start\n```\n\nThe development server will be available at http://localhost:3000/examples/browser/demo.html in your favorite browser.\nIt will automatically rebuild `tesseract.dev.js` and `worker.dev.js` when you change files in the **src** folder.\n\n### Online Setup with a single Click\n\nYou can use Gitpod(A free online VS Code like IDE) for contributing. With a single click it will launch a ready to code workspace with the build & start scripts already in process and within a few seconds it will spin up the dev server so that you can start contributing straight away without wasting any time. \n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/naptha/tesseract.js/blob/master/examples/browser/demo.html)\n\n### Building Static Files\nTo build the compiled static files just execute the following:\n```shell\nnpm run build\n```\nThis will output the files into the `dist` directory.\n\n## Contributors\n\n### Code Contributors\n\nThis project exists thanks to all the people who contribute. [[Contribute](CONTRIBUTING.md)].\n<a href=\"https://github.com/naptha/tesseract.js/graphs/contributors\"><img src=\"https://opencollective.com/tesseractjs/contributors.svg?width=890&button=false\" /></a>\n\n### Financial Contributors\n\nBecome a financial contributor and help us sustain our community. [[Contribute](https://opencollective.com/tesseractjs/contribute)]\n\n#### Individuals\n\n<a href=\"https://opencollective.com/tesseractjs\"><img src=\"https://opencollective.com/tesseractjs/individuals.svg?width=890\"></a>\n\n#### Organizations\n\nSupport this project with your organization. Your logo will show up here with a link to your website. [[Contribute](https://opencollective.com/tesseractjs/contribute)]\n\n<a href=\"https://opencollective.com/tesseractjs/organization/0/website\"><img src=\"https://opencollective.com/tesseractjs/organization/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/tesseractjs/organization/1/website\"><img src=\"https://opencollective.com/tesseractjs/organization/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/tesseractjs/organization/2/website\"><img src=\"https://opencollective.com/tesseractjs/organization/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/tesseractjs/organization/3/website\"><img src=\"https://opencollective.com/tesseractjs/organization/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/tesseractjs/organization/4/website\"><img src=\"https://opencollective.com/tesseractjs/organization/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/tesseractjs/organization/5/website\"><img src=\"https://opencollective.com/tesseractjs/organization/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/tesseractjs/organization/6/website\"><img src=\"https://opencollective.com/tesseractjs/organization/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/tesseractjs/organization/7/website\"><img src=\"https://opencollective.com/tesseractjs/organization/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/tesseractjs/organization/8/website\"><img src=\"https://opencollective.com/tesseractjs/organization/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/tesseractjs/organization/9/website\"><img src=\"https://opencollective.com/tesseractjs/organization/9/avatar.svg\"></a>\n",
	"artificial-intelligence deep-learning machine-learning machine-learning-algorithms software-engineer": "# Top-down learning path: Machine Learning for Software Engineers\n\n<p align=\"center\">\n  <a href=\"https://github.com/ZuzooVn/machine-learning-for-software-engineers\">\n    <img alt=\"Top-down learning path: Machine Learning for Software Engineers\" src=\"https://img.shields.io/badge/Machine%20Learning-Software%20Engineers-blue.svg\">\n  </a>\n  <a href=\"https://github.com/ZuzooVn/machine-learning-for-software-engineers/stargazers\">\n    <img alt=\"GitHub stars\" src=\"https://img.shields.io/github/stars/ZuzooVn/machine-learning-for-software-engineers.svg\">\n  </a>\n  <a href=\"https://github.com/ZuzooVn/machine-learning-for-software-engineers/network\">\n    <img alt=\"GitHub forks\" src=\"https://img.shields.io/github/forks/ZuzooVn/machine-learning-for-software-engineers.svg\">\n  </a>\n</p>\n\nInspired by [Coding Interview University](https://github.com/jwasham/coding-interview-university).\n\nTranslations: [Brazilian Portuguese](https://github.com/ZuzooVn/machine-learning-for-software-engineers/blob/master/README-pt-BR.md) | [\u4e2d\u6587\u7248\u672c](https://github.com/ZuzooVn/machine-learning-for-software-engineers/blob/master/README-zh-CN.md) | [Fran\u00e7ais](https://github.com/ZuzooVn/machine-learning-for-software-engineers/blob/master/README-fr-FR.md) | [\u81fa\u7063\u83ef\u8a9e\u7248\u672c](https://github.com/ZuzooVn/machine-learning-for-software-engineers/blob/master/README-zh-TW.md)\n\n[How I (Nam Vu) plan to become a machine learning engineer](https://www.codementor.io/zuzoovn/how-i-plan-to-become-a-machine-learning-engineer-a4metbcuk)\n\n## What is it?\n\nThis is my multi-month study plan for going from mobile developer (self-taught, no CS degree) to machine learning engineer.\n\nMy main goal was to find an approach to studying Machine Learning that is mainly hands-on and abstracts most of the Math for the beginner.\nThis approach is unconventional because it\u2019s the top-down and results-first approach designed for software engineers.\n\nPlease, feel free to make any contributions you feel will make it better.\n\n---\n\n## Table of Contents\n\n- [What is it?](#what-is-it)\n- [Why use it?](#why-use-it)\n- [How to use it](#how-to-use-it)\n- [Follow me](#follow-me)\n- [Don't feel you aren't smart enough](#dont-feel-you-arent-smart-enough)\n- [About Video Resources](#about-video-resources)\n- [Prerequisite Knowledge](#prerequisite-knowledge)\n- [The Daily Plan](#the-daily-plan)\n- [Motivation](#motivation)\n- [Machine learning overview](#machine-learning-overview)\n- [Machine learning mastery](#machine-learning-mastery)\n- [Machine learning is fun](#machine-learning-is-fun)\n- [Inky Machine Learning](#inky-machine-learning)\n- [Machine Learning: An In-Depth Guide](#machine-learning-an-in-depth-guide)\n- [Stories and experiences](#stories-and-experiences)\n- [Machine Learning Algorithms](#machine-learning-algorithms)\n- [Beginner Books](#beginner-books)\n- [Practical Books](#practical-books)\n- [Kaggle knowledge competitions](#kaggle-knowledge-competitions)\n- [Video Series](#video-series)\n- [MOOC](#mooc)\n- [Resources](#resources)\n- [Becoming an Open Source Contributor](#becoming-an-open-source-contributor)\n- [Games](#games)\n- [Podcasts](#podcasts)\n- [Communities](#communities)\n- [Conferences](#conferences)\n- [Interview Questions](#interview-questions)\n- [My admired companies](#my-admired-companies)\n\n---\n\n## Why use it?\n\nI'm following this plan to prepare for my near-future job: Machine learning engineer. I've been building native mobile applications (Android/iOS/Blackberry) since 2011. I have a Software Engineering degree, not a Computer Science degree. I have an itty-bitty amount of basic knowledge about: Calculus, Linear Algebra, Discrete Mathematics, Probability & Statistics from university.\nThink about my interest in machine learning:\n- [Can I learn and get a job in Machine Learning without studying CS Master and PhD?](https://www.quora.com/Can-I-learn-and-get-a-job-in-Machine-Learning-without-studying-CS-Master-and-PhD)\n    - *\"You can, but it is far more difficult than when I got into the field.\"* [Drac Smith](https://www.quora.com/Can-I-learn-and-get-a-job-in-Machine-Learning-without-studying-CS-Master-and-PhD/answer/Drac-Smith?srid=oT0p)\n- [How do I get a job in Machine Learning as a software programmer who self-studies Machine Learning, but  never has a chance to use it at work?](https://www.quora.com/How-do-I-get-a-job-in-Machine-Learning-as-a-software-programmer-who-self-studies-Machine-Learning-but-never-has-a-chance-to-use-it-at-work)\n    - *\"I'm hiring machine learning experts for my team and your MOOC will not get you the job (there is better news below). In fact, many people with a master's in machine learning will not get the job because they (and most who have taken MOOCs) do not have a deep understanding that will help me solve my problems.\"* [Ross C. Taylor](https://www.quora.com/How-do-I-get-a-job-in-Machine-Learning-as-a-software-programmer-who-self-studies-Machine-Learning-but-never-has-a-chance-to-use-it-at-work/answer/Ross-C-Taylor?srid=oT0p)\n- [What skills are needed for machine learning jobs?](http://programmers.stackexchange.com/questions/79476/what-skills-are-needed-for-machine-learning-jobs)\n    - *\"First, you need to have a decent CS/Math background. ML is an advanced topic so most textbooks assume that you have that background. Second, machine learning is a very general topic with many sub-specialties requiring unique skills. You may want to browse the curriculum of an MS program in Machine Learning to see the course, curriculum and textbook.\"* [Uri](http://softwareengineering.stackexchange.com/a/79717)\n    - *\"Probability, distributed computing, and Statistics.\"* [Hydrangea](http://softwareengineering.stackexchange.com/a/79575)\n\nI find myself in times of trouble.\n\nAFAIK, [There are two sides to machine learning](http://machinelearningmastery.com/programmers-can-get-into-machine-learning/):\n- Practical Machine Learning: This is about querying databases, cleaning data, writing scripts to transform data and gluing algorithm and libraries together and writing custom code to squeeze reliable answers from data to satisfy difficult and ill-defined questions. It\u2019s the mess of reality.\n- Theoretical Machine Learning: This is about math and abstraction and idealized scenarios and limits and beauty and informing what is possible. It is a whole lot neater and cleaner and removed from the mess of reality.\n\nI think the best way for practice-focused methodology is something like ['practice \u2014 learning \u2014 practice'](http://machinelearningmastery.com/machine-learning-for-programmers/#comment-358985), that means where students first come with some existing projects with problems and solutions (practice) to get familiar with traditional methods in the area and perhaps also with their methodology. After practicing with some elementary experiences, they can go into the books and study the underlying theory, which serves to guide their future advanced practice and will enhance their toolbox of solving practical problems. Studying theory also further improves their understanding on the elementary experiences, and will help them acquire advanced experiences more quickly.\n\n It's a long plan. It's going to take me years. If you are familiar with a lot of this already it will take you a lot less time.\n\n## How to use it\nEverything below is an outline, and you should tackle the items in order from top to bottom.\n\nI'm using Github's special markdown flavor, including tasks lists to check progress.\n\n- [x] Create a new branch so you can check items like this, just put an x in the brackets: [x]\n\n[More about Github-flavored markdown](https://guides.github.com/features/mastering-markdown/#GitHub-flavored-markdown)\n\n## Follow me\nI'm a Vietnamese Software Engineer who is really passionate and wants to work in the USA.\n\nHow much did I work during this plan? Roughly 4 hours/night after a long, hard day at work.\n\nI'm on the journey.\n\n- Twitter: [@Nam Vu](https://twitter.com/zuzoovn)\n\n| ![Nam Vu - Top-down learning path: machine learning for software engineers](http://sv1.upsieutoc.com/2016/10/08/331f241c8da44d0c43e9324d55440db6.md.jpg)|\n|:---:|\n| USA as heck |\n\n## Don't feel you aren't smart enough\nI get discouraged from books and courses that tell me as soon as I open them that multivariate calculus, inferential statistics and linear algebra are prerequisites. I still don\u2019t know how to get started\u2026\n\n- [What if I\u2019m Not Good at Mathematics](http://machinelearningmastery.com/what-if-im-not-good-at-mathematics/)\n- [5 Techniques To Understand Machine Learning Algorithms Without the Background in Mathematics](http://machinelearningmastery.com/techniques-to-understand-machine-learning-algorithms-without-the-background-in-mathematics/)\n- [How do I learn machine learning?](https://www.quora.com/Machine-Learning/How-do-I-learn-machine-learning-1)\n\n## About Video Resources\n\nSome videos are available only by enrolling in a Coursera or EdX class. It is free to do so, but sometimes the classes\nare no longer in session so you have to wait a couple of months, so you have no access. I'm going to be adding more videos\nfrom public sources and replacing the online course videos over time. I like using university lectures.\n\n## Prerequisite Knowledge\n\nThis short section consists of prerequisites/interesting info I wanted to learn before getting started on the daily plan.\n\n- [ ] [What is the difference between Data Analytics, Data Analysis, Data Mining, Data Science, Machine Learning, and Big Data?](https://www.quora.com/What-is-the-difference-between-Data-Analytics-Data-Analysis-Data-Mining-Data-Science-Machine-Learning-and-Big-Data-1)\n- [ ] [Learning How to Learn](https://www.coursera.org/learn/learning-how-to-learn)\n- [ ] [Don\u2019t Break The Chain](http://lifehacker.com/281626/jerry-seinfelds-productivity-secret)\n- [ ] [How to learn on your own](https://metacademy.org/roadmaps/rgrosse/learn_on_your_own)\n\n## The Daily Plan\n\nEach subject does not require a whole day to be able to understand it fully, and you can do multiple of these in a day.\n\nEach day I take one subject from the list below, read it cover to cover, take notes, do the exercises and write an implementation in Python or R.\n\n# Motivation\n- [ ] [Dream](https://www.youtube.com/watch?v=g-jwWYX7Jlo)\n\n## Machine learning overview\n- [ ] [A Visual Introduction to Machine Learning](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n- [ ] [Gentle Guide to Machine Learning](https://blog.monkeylearn.com/gentle-guide-to-machine-learning/)\n- [ ] [Introduction to Machine Learning for Developers](http://blog.algorithmia.com/introduction-machine-learning-developers/)\n- [ ] [Machine Learning basics for a newbie](https://www.analyticsvidhya.com/blog/2015/06/machine-learning-basics/)\n- [ ] [How do you explain Machine Learning and Data Mining to non Computer Science people?](https://www.quora.com/How-do-you-explain-Machine-Learning-and-Data-Mining-to-non-Computer-Science-people)\n- [ ] [Machine Learning: Under the hood. Blog post explains the principles of machine learning in layman terms. Simple and clear](https://georgemdallas.wordpress.com/2013/06/11/big-data-data-mining-and-machine-learning-under-the-hood/)\n- [ ] [What is machine learning, and how does it work?](https://www.youtube.com/watch?v=elojMnjn4kk&list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&index=1)\n- ~~[] [Deep Learning - A Non-Technical Introduction](http://www.slideshare.net/AlfredPong1/deep-learning-a-nontechnical-introduction-69385936)~~[removed]\n\n## Machine learning mastery\n- [ ] [The Machine Learning Mastery Method](http://machinelearningmastery.com/machine-learning-mastery-method/)\n- [ ] [Machine Learning for Programmers](http://machinelearningmastery.com/machine-learning-for-programmers/)\n- [ ] [Applied Machine Learning with Machine Learning Mastery](http://machinelearningmastery.com/start-here/)\n- [ ] [Python Machine Learning Mini-Course](http://machinelearningmastery.com/python-machine-learning-mini-course/)\n- [ ] [Machine Learning Algorithms Mini-Course](http://machinelearningmastery.com/machine-learning-algorithms-mini-course/)\n\n## Machine learning is fun\n- [ ] [Machine Learning is Fun!](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471#.37ue6caww)\n- [ ] [Part 2: Using Machine Learning to generate Super Mario Maker levels](https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.kh7qgvp1b)\n- [ ] [Part 3: Deep Learning and Convolutional Neural Networks](https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.44rhxy637)\n- [ ] [Part 4: Modern Face Recognition with Deep Learning](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78#.3rwmq0ddc)\n- [ ] [Part 5: Language Translation with Deep Learning and the Magic of Sequences](https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa#.wyfthap4c)\n- [ ] [Part 6: How to do Speech Recognition with Deep Learning](https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a#.lhr1nnpcy)\n- [ ] [Part 7: Abusing Generative Adversarial Networks to Make 8-bit Pixel Art](https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7)\n- [ ] [Part 8: How to Intentionally Trick Neural Networks](https://medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196)\n\n## [Inky Machine Learning](https://triskell.github.io/2016/11/15/Inky-Machine-Learning.html)\n- [ ] [Part 1: What is Machine Learning ?](https://triskell.github.io/2016/10/23/What-is-Machine-Learning.html)\n- [ ] [Part 2: Supervised Learning and Unsupervised Learning](https://triskell.github.io/2016/11/13/Supervised-Learning-and-Unsupervised-Learning.html)\n\n## Machine Learning: An In-Depth Guide\n- [ ] [Overview, goals, learning types, and algorithms](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide/)\n- [ ] [Data selection, preparation, and modeling](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide-part-2/)\n- [ ] [Model evaluation, validation, complexity, and improvement](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide-part-3/)\n- [ ] [Model performance and error analysis](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide-part-4/)\n- [ ] [Unsupervised learning, related fields, and machine learning in practice](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide-part-5/)\n\n## Stories and experiences\n- [ ] [Machine Learning in a Week](https://medium.com/learning-new-stuff/machine-learning-in-a-week-a0da25d59850#.tk6ft2kcg)\n- [ ] [Machine Learning in a Year](https://medium.com/learning-new-stuff/machine-learning-in-a-year-cdb0b0ebd29c#.hhcb9fxk1)\n- [ ] [How I wrote my first Machine Learning program in 3 days](http://blog.adnansiddiqi.me/how-i-wrote-my-first-machine-learning-program-in-3-days/)\n- [ ] [Learning Path : Your mentor to become a machine learning expert](https://www.analyticsvidhya.com/learning-path-learn-machine-learning/)\n- [ ] [You Too Can Become a Machine Learning Rock Star! No PhD](https://backchannel.com/you-too-can-become-a-machine-learning-rock-star-no-phd-necessary-107a1624d96b#.g9p16ldp7)\n- [ ] How to become a Data Scientist in 6 months: A hacker\u2019s approach to career planning\n    - [Video](https://www.youtube.com/watch?v=rIofV14c0tc)\n    - [Slide](http://www.slideshare.net/TetianaIvanova2/how-to-become-a-data-scientist-in-6-months)\n- [ ] [5 Skills You Need to Become a Machine Learning Engineer](http://blog.udacity.com/2016/04/5-skills-you-need-to-become-a-machine-learning-engineer.html)\n- [ ] [Are you a self-taught machine learning engineer? If yes, how did you do it & how long did it take you?](https://www.quora.com/Are-you-a-self-taught-machine-learning-engineer-If-yes-how-did-you-do-it-how-long-did-it-take-you)\n- [ ] [How can one become a good machine learning engineer?](https://www.quora.com/How-can-one-become-a-good-machine-learning-engineer)\n- [ ] [A Learning Sabbatical focused on Machine Learning](http://karlrosaen.com/ml/)\n\n## Machine Learning Algorithms\n- [ ] [10 Machine Learning Algorithms Explained to an \u2018Army Soldier\u2019](https://www.analyticsvidhya.com/blog/2015/12/10-machine-learning-algorithms-explained-army-soldier/)\n- [ ] [Top 10 data mining algorithms in plain English](https://rayli.net/blog/data/top-10-data-mining-algorithms-in-plain-english/)\n- [ ] [10 Machine Learning Terms Explained in Simple English](http://blog.aylien.com/10-machine-learning-terms-explained-in-simple/)\n- [ ] [A Tour of Machine Learning Algorithms](http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)\n- [ ] [The 10 Algorithms Machine Learning Engineers Need to Know](https://gab41.lab41.org/the-10-algorithms-machine-learning-engineers-need-to-know-f4bb63f5b2fa#.ofc7t2965)\n- [ ] [Comparing supervised learning algorithms](http://www.dataschool.io/comparing-supervised-learning-algorithms/)\n- [ ] [Machine Learning Algorithms: A collection of minimal and clean implementations of machine learning algorithms](https://github.com/rushter/MLAlgorithms)\n- [ ] [KNN Algorithm in Machine Learning](https://www.scaler.com/topics/what-is-knn-algorithm-in-machine-learning/)\n\n## Beginner Books\n- [ ] [Data Smart: Using Data Science to Transform Information into Insight 1st Edition](https://www.amazon.com/Data-Smart-Science-Transform-Information/dp/111866146X)\n- [ ] [Data Science for Business: What you need to know about data mining and data\u00ad analytic-thinking](https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/1449361323/)\n- [ ] [Predictive Analytics: The Power to Predict Who Will Click, Buy, Lie, or Die](https://www.amazon.com/Predictive-Analytics-Power-Predict-Click/dp/1118356853)\n\n## Practical Books\n- [ ] [Machine Learning for Hackers](https://www.amazon.com/Machine-Learning-Hackers-Drew-Conway/dp/1449303714)\n    - [GitHub repository(R)](https://github.com/johnmyleswhite/ML_for_Hackers)\n    - [GitHub repository(Python)](https://github.com/carljv/Will_it_Python)\n- [ ] [Python Machine Learning](https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka-ebook/dp/B00YSILNL0)\n    - [GitHub repository](https://github.com/rasbt/python-machine-learning-book)\n- [ ] [Programming Collective Intelligence: Building Smart Web 2.0 Applications](https://www.amazon.com/Programming-Collective-Intelligence-Building-Applications-ebook/dp/B00F8QDZWG)\n- [ ] [Machine Learning: An Algorithmic Perspective, Second Edition](https://www.amazon.com/Machine-Learning-Algorithmic-Perspective-Recognition/dp/1466583282)\n    - [GitHub repository](https://github.com/alexsosn/MarslandMLAlgo)\n    - [Resource repository](http://seat.massey.ac.nz/personal/s.r.marsland/MLbook.html)\n- [ ] [Introduction to Machine Learning with Python: A Guide for Data Scientists](http://shop.oreilly.com/product/0636920030515.do)\n    - [GitHub repository](https://github.com/amueller/introduction_to_ml_with_python)\n- [ ] [Data Mining: Practical Machine Learning Tools and Techniques, Third Edition](https://www.amazon.com/Data-Mining-Practical-Techniques-Management/dp/0123748569)\n    - Teaching material\n        - [Slides for Chapters 1-5 (zip)](http://www.cs.waikato.ac.nz/ml/weka/Slides3rdEd_Ch1-5.zip)\n        - [Slides for Chapters 6-8 (zip)](http://www.cs.waikato.ac.nz/ml/weka/Slides3rdEd_Ch6-8.zip)\n- [ ] [Machine Learning in Action](https://www.amazon.com/Machine-Learning-Action-Peter-Harrington/dp/1617290181/)\n    - [GitHub repository](https://github.com/pbharrin/machinelearninginaction)\n- [ ] [Reactive Machine Learning Systems(MEAP)](https://www.manning.com/books/reactive-machine-learning-systems)\n    - [GitHub repository](https://github.com/jeffreyksmithjr/reactive-machine-learning-systems)\n- [ ] [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)\n    - [GitHub repository(R)](http://www-bcf.usc.edu/~gareth/ISL/code.html)\n    - [GitHub repository(Python)](https://github.com/JWarmenhoven/ISLR-python)\n    - [Videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)\n- [ ] [Building Machine Learning Systems with Python](https://www.packtpub.com/big-data-and-business-intelligence/building-machine-learning-systems-python)\n    - [GitHub repository](https://github.com/luispedro/BuildingMachineLearningSystemsWithPython)\n- [ ] [Learning scikit-learn: Machine Learning in Python](https://www.packtpub.com/big-data-and-business-intelligence/learning-scikit-learn-machine-learning-python)\n    - [GitHub repository](https://github.com/gmonce/scikit-learn-book)\n- [ ] [Probabilistic Programming & Bayesian Methods for Hackers](https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)\n- [ ] [Probabilistic Graphical Models: Principles and Techniques](https://www.amazon.com/Probabilistic-Graphical-Models-Principles-Computation/dp/0262013193)\n- [ ] [Machine Learning: Hands-On for Developers and Technical Professionals](https://www.amazon.com/Machine-Learning-Hands-Developers-Professionals/dp/1118889061)\n    - [Machine Learning Hands-On for Developers and Technical Professionals review](https://blogs.msdn.microsoft.com/querysimon/2015/01/01/book-review-machine-learning-hands-on-for-developers-and-technical-professionals/)\n    - [GitHub repository](https://github.com/jasebell/mlbook)\n- [ ] [Learning from Data](https://www.amazon.com/Learning-Data-Yaser-S-Abu-Mostafa/dp/1600490069)\n    - [Online tutorials](https://work.caltech.edu/telecourse.html)\n- [ ] [Reinforcement Learning: An Introduction (2nd Edition)](https://webdocs.cs.ualberta.ca/~sutton/book/the-book-2nd.html)\n    - [GitHub repository](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction)\n- [ ] [Machine Learning with TensorFlow(MEAP)](https://www.manning.com/books/machine-learning-with-tensorflow)\n    - [GitHub repository](https://github.com/BinRoot/TensorFlow-Book)\n- [ ] [How Machine Learning Works (MEAP)](https://www.manning.com/books/how-machine-learning-works)\n    - [GitHub repository](https://github.com/Mostafa-Samir/How-Machine-Learning-Works)\n- [ ] [Succeeding with AI](https://www.manning.com/books/succeeding-with-ai)\n\n## Kaggle knowledge competitions\n- [ ] [Kaggle Competitions: How and where to begin?](https://www.analyticsvidhya.com/blog/2015/06/start-journey-kaggle/)\n- [ ] [How a Beginner Used Small Projects To Get Started in Machine Learning and Compete on Kaggle](http://machinelearningmastery.com/how-a-beginner-used-small-projects-to-get-started-in-machine-learning-and-compete-on-kaggle)\n- [ ] [Master Kaggle By Competing Consistently](http://machinelearningmastery.com/master-kaggle-by-competing-consistently/)\n\n## Video Series\n- [ ] [Machine Learning for Hackers](https://www.youtube.com/playlist?list=PL2-dafEMk2A4ut2pyv0fSIXqOzXtBGkLj)\n- [ ] [Fresh Machine Learning](https://www.youtube.com/playlist?list=PL2-dafEMk2A6Kc7pV6gHH-apBFxwFjKeY)\n- [ ] [Machine Learning Recipes with Josh Gordon](https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal)\n- [ ] [Everything You Need to know about Machine Learning in 30 Minutes or Less](https://vimeo.com/43547079)\n- [ ] [A Friendly Introduction to Machine Learning](https://www.youtube.com/watch?v=IpGxLWOIZy4)\n- [ ] [Nuts and Bolts of Applying Deep Learning - Andrew Ng](https://www.youtube.com/watch?v=F1ka6a13S9I)\n- [ ] BigML Webinar\n    - [Video](https://www.youtube.com/watch?list=PL1bKyu9GtNYHcjGa6ulrvRVcm1lAB8he3&v=W62ehrnOVqo)\n    - [Resources](https://bigml.com/releases)\n- [ ] [mathematicalmonk's Machine Learning tutorials](https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA)\n- [ ] [Machine learning in Python with scikit-learn](https://www.youtube.com/playlist?list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A)\n    - [GitHub repository](https://github.com/justmarkham/scikit-learn-videos)\n    - [Blog](http://blog.kaggle.com/author/kevin-markham/)\n- [ ] [My playlist \u2013 Top YouTube Videos on Machine Learning, Neural Network & Deep Learning](https://www.analyticsvidhya.com/blog/2015/07/top-youtube-videos-machine-learning-neural-network-deep-learning/)\n- [ ] [16 New Must Watch Tutorials, Courses on Machine Learning](https://www.analyticsvidhya.com/blog/2016/10/16-new-must-watch-tutorials-courses-on-machine-learning/)\n- [ ] [DeepLearning.TV](https://www.youtube.com/channel/UC9OeZkIwhzfv-_Cb7fCikLQ)\n- [ ] [Learning To See](https://www.youtube.com/playlist?list=PLiaHhY2iBX9ihLasvE8BKnS2Xg8AhY6iV)\n- [ ] [Neural networks class - Universit\u00e9 de Sherbrooke](https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH)\n- [ ] [21 Deep Learning Videos, Tutorials & Courses on Youtube from 2016](https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/)\n- [ ] [30 Top Videos, Tutorials & Courses on Machine Learning & Artificial Intelligence from 2016](https://www.analyticsvidhya.com/blog/2016/12/30-top-videos-tutorials-courses-on-machine-learning-artificial-intelligence-from-2016/)\n- [ ] [Practical Deep Learning For Coders](http://course.fast.ai/index.html)\n- [ ]  [Practical Deep Learning For Coders Version 2 (PyTorch)](http://forums.fast.ai/t/welcome-to-part-1-v2/5787)\n\n## MOOC\n- [ ] [Coursera\u2019s AI For Everyone](https://www.coursera.org/learn/ai-for-everyone)\n- [ ] [edX's Introduction to Artificial Intelligence (AI)](https://www.edx.org/course/introduction-artificial-intelligence-ai-microsoft-dat263x)\n- [ ] [Udacity\u2019s Intro to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120)\n    - [Udacity Intro to Machine Learning Review](http://hamelg.blogspot.com/2014/12/udacity-intro-to-machine-learning-review.html)\n- [ ] [Udacity\u2019s Supervised, Unsupervised & Reinforcement](https://www.udacity.com/course/machine-learning--ud262)\n- [ ] [Machine Learning Foundations: A Case Study Approach](https://www.coursera.org/learn/ml-foundations)\n- [ ] [Machine Learning & AI Foundations: Value Estimations](https://www.lynda.com/Data-Science-tutorials/Machine-Learning-Essential-Training-Value-Estimations/548594-2.html)\n- [ ] [Kaggle's Hands-On Data Science Education](https://www.kaggle.com/learn/overview)\n- [ ] [Microsoft Professional Program for Artificial Intelligence](https://academy.microsoft.com/en-us/professional-program/tracks/artificial-intelligence/)\n- [ ] [Coursera\u2019s Machine Learning](https://www.coursera.org/learn/machine-learning)\n    - [Video only](https://www.youtube.com/playlist?list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW)\n    - [Coursera Machine Learning review](https://rayli.net/blog/data/coursera-machine-learning-review/)\n    - [Coursera: Machine Learning Roadmap](https://metacademy.org/roadmaps/cjrd/coursera_ml_supplement)\n- [ ] [Machine Learning Distilled](https://code.tutsplus.com/courses/machine-learning-distilled)\n- [ ] [BigML training](https://bigml.com/training)\n- [ ] [Coursera\u2019s Neural Networks for Machine Learning](https://www.coursera.org/learn/neural-networks)\n    - Taught by Geoffrey Hinton, a pioneer in the field of neural networks\n- [ ] [Machine Learning\u200a-\u200aCS\u200a-\u200aOxford University](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/)\n- [ ] [Creative Applications of Deep Learning with TensorFlow](https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow/info)\n- [ ] [Intro to Descriptive Statistics](https://www.udacity.com/course/intro-to-descriptive-statistics--ud827)\n- [ ] [Intro to Inferential Statistics](https://www.udacity.com/course/intro-to-inferential-statistics--ud201)\n- [ ] [6.S094: Deep Learning for Self-Driving Cars](http://selfdrivingcars.mit.edu/)\n- [ ] [6.S191: Introduction to Deep Learning](http://introtodeeplearning.com/index.html)\n- [ ] [Coursera\u2019s Deep Learning](https://www.coursera.org/specializations/deep-learning)\n\n## Resources\n- [ ] [Absolute Beginning into Machine Learning](https://hackernoon.com/absolute-beginning-into-machine-learning-e90ceda5a4bc)\n- [ ] [Learn Machine Learning in a Single Month](https://elitedatascience.com/machine-learning-masterclass)\n- [ ] [The Non-Technical Guide to Machine Learning & Artificial Intelligence](https://medium.com/@samdebrule/a-humans-guide-to-machine-learning-e179f43b67a0#.cpzf3a5c0)\n- [ ] [Programming Community Curated Resources for learning Machine Learning](https://hackr.io/tutorials/learn-machine-learning-ml)\n- [ ] [Best practices rule book for Machine Learning engineering from Google](http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf)\n- [ ] [Machine Learning for Software Engineers on Hacker News](https://news.ycombinator.com/item?id=12898718)\n- [ ] [Machine Learning for Developers](https://xyclade.github.io/MachineLearning/)\n- [ ] [Machine Learning for Humans\ud83e\udd16\ud83d\udc76](https://medium.com/machine-learning-for-humans/why-machine-learning-matters-6164faf1df12)\n- [ ] [Machine Learning Advice for Developers](https://dev.to/thealexlavin/machine-learning-advice-for-developers)\n- [ ] [Machine Learning For Complete Beginners](http://pythonforengineers.com/machine-learning-for-complete-beginners/)\n- [ ] [Getting Started with Machine Learning: For absolute beginners and fifth graders](https://medium.com/@suffiyanz/getting-started-with-machine-learning-f15df1c283ea#.yjtiy7ei9)\n- [ ] [How to Learn Machine Learning: The Self-Starter Way](https://elitedatascience.com/learn-machine-learning)\n- [ ] [Machine Learning Self-study Resources](https://ragle.sanukcode.net/articles/machine-learning-self-study-resources/)\n- [ ] [Level-Up Your Machine Learning](https://metacademy.org/roadmaps/cjrd/level-up-your-ml)\n- [ ] [An Honest Guide to Machine Learning](https://medium.com/axiomzenteam/an-honest-guide-to-machine-learning-2f6d7a6df60e#.ib12a1yw5)\n- [ ] Enough Machine Learning to Make Hacker News Readable Again\n    - [Video](https://www.youtube.com/watch?v=O7IezJT9uSI)\n    - [Slide](https://speakerdeck.com/pycon2014/enough-machine-learning-to-make-hacker-news-readable-again-by-ned-jackson-lovely)\n- [ ] [Dive into Machine Learning](https://github.com/hangtwenty/dive-into-machine-learning)\n- [ ] [{Machine, Deep} Learning for software engineers](https://speakerdeck.com/pmigdal/machine-deep-learning-for-software-engineers)\n- [ ] [Deep Learning For Beginners](https://deeplearning4j.org/deeplearningforbeginners.html)\n- [ ] [Foundations for deep learning](https://github.com/pauli-space/foundations_for_deep_learning)\n- [ ] [Machine Learning Mindmap / Cheatsheet](https://github.com/dformoso/machine-learning-mindmap)\n- Machine Learning courses in Universities\n    - [ ] [Stanford](http://ai.stanford.edu/courses/)\n    - [ ] [Machine Learning Summer Schools](http://mlss.cc/)\n    - [ ] [Oxford](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/)\n    - [ ] [Cambridge](http://mlg.eng.cam.ac.uk/)\n- Flipboard Topics\n    - [Machine learning](https://flipboard.com/topic/machinelearning)\n    - [Deep learning](https://flipboard.com/topic/deeplearning)\n    - [Artificial Intelligence](https://flipboard.com/topic/artificialintelligence)\n- Medium Topics\n    - [Machine learning](https://medium.com/tag/machine-learning/latest)\n    - [Deep learning](https://medium.com/tag/deep-learning)\n    - [Artificial Intelligence](https://medium.com/tag/artificial-intelligence)\n- Monthly top 10 articles\n    - [Machine Learning](https://medium.mybridge.co/search?q=%22Machine%20Learning%22)\n    - [Algorithms](https://medium.mybridge.co/search?q=Algorithms)\n- [Comprehensive list of data science resources](http://www.datasciencecentral.com/group/resources/forum/topics/comprehensive-list-of-data-science-resources)\n- [DigitalMind's Artificial Intelligence resources](http://blog.digitalmind.io/post/artificial-intelligence-resources)\n- [Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning)\n- [Awesome Graph Classification](https://github.com/benedekrozemberczki/awesome-graph-classification)\n- [Awesome Community Detection](https://github.com/benedekrozemberczki/awesome-community-detection)\n- [CreativeAi's Machine Learning](http://www.creativeai.net/?cat%5B0%5D=machine-learning)\n- [Machine Learning Online Courses](https://classpert.com/machine-learning)\n\n## Games\n- [Halite: A.I. Coding Game](https://halite.io/)\n- [Vindinium: A.I. Programming Challenge](http://vindinium.org/)\n- [General Video Game AI Competition](http://www.gvgai.net/)\n- [Angry Birds AI Competition](https://aibirds.org/)\n- [The AI Games](http://theaigames.com/)\n- [Fighting Game AI Competition](http://www.ice.ci.ritsumei.ac.jp/~ftgaic/)\n- [CodeCup](http://www.codecup.nl/intro.php)\n- [Student StarCraft AI Tournament](http://sscaitournament.com/)\n- [AIIDE StarCraft AI Competition](http://www.cs.mun.ca/~dchurchill/starcraftaicomp/)\n- [CIG StarCraft AI Competition](https://sites.google.com/site/starcraftaic/)\n- [CodinGame - AI Bot Games](https://www.codingame.com/training/machine-learning)\n\n## Becoming an Open Source Contributor\n- [ ] [tensorflow/magenta: Magenta: Music and Art Generation with Machine Intelligence](https://github.com/tensorflow/magenta)\n- [ ] [tensorflow/tensorflow: Computation using data flow graphs for scalable machine learning](https://github.com/tensorflow/tensorflow)\n- [ ] [cmusatyalab/openface: Face recognition with deep neural networks.](https://github.com/cmusatyalab/openface)\n- [ ] [tensorflow/models/syntaxnet: Neural Models of Syntax.](https://github.com/tensorflow/models/tree/master/syntaxnet)\n\n## Podcasts\n- ### Podcasts for Beginners:\n    - [Talking Machines](http://www.thetalkingmachines.com/)\n    - [Linear Digressions](http://lineardigressions.com/)\n    - [Data Skeptic](http://dataskeptic.com/)\n    - [This Week in Machine Learning & AI](https://twimlai.com/)\n    - [Machine Learning Guide](http://ocdevel.com/podcasts/machine-learning)\n    \n- ### Interviews with ML Practitioners, Researchers and Kagglers about their Joureny\n    - [Chai Time Data Science](https://www.youtube.com/playlist?list=PLLvvXm0q8zUbiNdoIazGzlENMXvZ9bd3x), [Audio](http://anchor.fm/chaitimedatascience), [Writeups](https://sanyambhutani.com/tag/chaitimedatascience/)\n    - [Machine Learning for Beginners - Interviews](https://www.youtube.com/channel/UCdZ0GX-F3ULMKfxtyzSFbaw), [Audio](https://jayshah.buzzsprout.com/)\n\n- ### \"More\" advanced podcasts\n    - [Partially Derivative](http://partiallyderivative.com/)\n    - [O\u2019Reilly Data Show](http://radar.oreilly.com/tag/oreilly-data-show-podcast)\n    - [Not So Standard Deviation](https://soundcloud.com/nssd-podcast)\n\n- ### Podcasts to think outside the box:\n    - [Data Stories](http://datastori.es/)\n    \n## Communities\n- Quora\n    - [Machine Learning](https://www.quora.com/topic/Machine-Learning)\n    - [Statistics](https://www.quora.com/topic/Statistics-academic-discipline)\n    - [Data Mining](https://www.quora.com/topic/Data-Mining)\n\n- Reddit\n    - [Machine Learning](https://www.reddit.com/r/machinelearning)\n    - [Computer Vision](https://www.reddit.com/r/computervision)\n    - [Natural Language](https://www.reddit.com/r/languagetechnology)\n    - [Data Science](https://www.reddit.com/r/datascience)\n    - [Big Data](https://www.reddit.com/r/bigdata)\n    - [Statistics](https://www.reddit.com/r/statistics)\n\n- [Data Tau](http://www.datatau.com/)\n\n- [Deep Learning News](http://news.startup.ml/)\n\n- [KDnuggets](http://www.kdnuggets.com/)\n\n## Conferences\n- Neural Information Processing Systems ([NIPS](https://nips.cc/))\n- International Conference on Learning Representations ([ICLR](http://www.iclr.cc/doku.php?id=ICLR2017:main&redirect=1))\n- Association for the Advancement of Artificial Intelligence ([AAAI](http://www.aaai.org/Conferences/AAAI/aaai17.php))\n- IEEE Conference on Computational Intelligence and Games ([CIG](http://www.ieee-cig.org/))\n- IEEE International Conference on Machine Learning and Applications ([ICMLA](http://www.icmla-conference.org/))\n- International Conference on Machine Learning ([ICML](https://2017.icml.cc/))\n- International Joint Conferences on Artificial Intelligence ([IJCAI](http://www.ijcai.org/))\n- Association for Computational Linguistics ([ACL](http://acl2017.org/))\n\n## Interview Questions\n- [ ] [How To Prepare For A Machine Learning Interview](http://blog.udacity.com/2016/05/prepare-machine-learning-interview.html)\n- [ ] [40 Interview Questions asked at Startups in Machine Learning / Data Science](https://www.analyticsvidhya.com/blog/2016/09/40-interview-questions-asked-at-startups-in-machine-learning-data-science)\n- [ ] [21 Must-Know Data Science Interview Questions and Answers](http://www.kdnuggets.com/2016/02/21-data-science-interview-questions-answers.html)\n- [ ] [Top 50 Machine learning Interview questions & Answers](http://career.guru99.com/top-50-interview-questions-on-machine-learning/)\n- [ ] [Machine Learning Engineer interview questions](https://resources.workable.com/machine-learning-engineer-interview-questions)\n- [ ] [Popular Machine Learning Interview Questions](http://www.learn4master.com/machine-learning/popular-machine-learning-interview-questions)\n- [ ] [What are some common Machine Learning interview questions?](https://www.quora.com/What-are-some-common-Machine-Learning-interview-questions)\n- [ ] [What are the best interview questions to evaluate a machine learning researcher?](https://www.quora.com/What-are-the-best-interview-questions-to-evaluate-a-machine-learning-researcher)\n- [ ] [Collection of Machine Learning Interview Questions](http://analyticscosm.com/machine-learning-interview-questions-for-data-scientist-interview/)\n- [ ] [121 Essential Machine Learning Questions & Answers](https://elitedatascience.com/mlqa-reading-list)\n- [ ] [Minimum Viable Study Plan for Machine Learning Interviews](https://github.com/khangich/machine-learning-interview)\n\n## My admired companies\n- [ ] [ELSA - Your virtual pronunciation coach](https://www.elsanow.io/home)\n",
	"caffe computer-vision cpp cvpr-2017 deep-learning face foot-estimation hand-estimation human-behavior-understanding human-pose human-pose-estimation keypoint-detection keypoints machine-learning multi-person opencv openpose pose pose-estimation real-time": "<div align=\"center\">\n    <img src=\".github/Logo_main_black.png\" width=\"300\">\n</div>\n\n-----------------\n\n| **Build Type**   |`Linux`           |`MacOS`           |`Windows`         |\n| :---:            | :---:            | :---:            | :---:            |\n| **Build Status** | [![Status](https://github.com/CMU-Perceptual-Computing-Lab/openpose/workflows/CI/badge.svg)](https://github.com/CMU-Perceptual-Computing-Lab/openpose/actions) | [![Status](https://github.com/CMU-Perceptual-Computing-Lab/openpose/workflows/CI/badge.svg)](https://github.com/CMU-Perceptual-Computing-Lab/openpose/actions) | [![Status](https://ci.appveyor.com/api/projects/status/5leescxxdwen77kg/branch/master?svg=true)](https://ci.appveyor.com/project/gineshidalgo99/openpose/branch/master) |\n\n[**OpenPose**](https://github.com/CMU-Perceptual-Computing-Lab/openpose) has represented the **first real-time multi-person system to jointly detect human body, hand, facial, and foot keypoints (in total 135 keypoints) on single images**.\n\nIt is **authored by** [**Gin\u00e9s Hidalgo**](https://www.gineshidalgo.com), [**Zhe Cao**](https://people.eecs.berkeley.edu/~zhecao), [**Tomas Simon**](http://www.cs.cmu.edu/~tsimon), [**Shih-En Wei**](https://scholar.google.com/citations?user=sFQD3k4AAAAJ&hl=en), [**Yaadhav Raaj**](https://www.raaj.tech), [**Hanbyul Joo**](https://jhugestar.github.io), **and** [**Yaser Sheikh**](http://www.cs.cmu.edu/~yaser). It is **maintained by** [**Gin\u00e9s Hidalgo**](https://www.gineshidalgo.com) **and** [**Yaadhav Raaj**](https://www.raaj.tech). OpenPose would not be possible without the [**CMU Panoptic Studio dataset**](http://domedb.perception.cs.cmu.edu). We would also like to thank all the people who [has helped OpenPose in any way](doc/09_authors_and_contributors.md).\n\n\n\n<p align=\"center\">\n    <img src=\".github/media/pose_face_hands.gif\" width=\"480\">\n    <br>\n    <sup>Authors <a href=\"https://www.gineshidalgo.com\" target=\"_blank\">Gin\u00e9s Hidalgo</a> (left) and <a href=\"https://jhugestar.github.io\" target=\"_blank\">Hanbyul Joo</a> (right) in front of the <a href=\"http://domedb.perception.cs.cmu.edu\" target=\"_blank\">CMU Panoptic Studio</a></sup>\n</p>\n\n\n\n## Contents\n1. [Results](#results)\n2. [Features](#features)\n3. [Related Work](#related-work)\n4. [Installation](#installation)\n5. [Quick Start Overview](#quick-start-overview)\n6. [Send Us Feedback!](#send-us-feedback)\n7. [Citation](#citation)\n8. [License](#license)\n\n\n\n## Results\n### Whole-body (Body, Foot, Face, and Hands) 2D Pose Estimation\n<p align=\"center\">\n    <img src=\".github/media/dance_foot.gif\" width=\"300\">\n    <img src=\".github/media/pose_face.gif\" width=\"300\">\n    <img src=\".github/media/pose_hands.gif\" width=\"300\">\n    <br>\n    <sup>Testing OpenPose: (Left) <a href=\"https://www.youtube.com/watch?v=2DiQUX11YaY\" target=\"_blank\"><i>Crazy Uptown Funk flashmob in Sydney</i></a> video sequence. (Center and right) Authors <a href=\"https://www.gineshidalgo.com\" target=\"_blank\">Gin\u00e9s Hidalgo</a> and <a href=\"http://www.cs.cmu.edu/~tsimon\" target=\"_blank\">Tomas Simon</a> testing face and hands</sup>\n</p>\n\n### Whole-body 3D Pose Reconstruction and Estimation\n<p align=\"center\">\n    <img src=\".github/media/openpose3d.gif\" width=\"360\">\n    <br>\n    <sup><a href=\"https://ziutinyat.github.io/\" target=\"_blank\">Tianyi Zhao</a> testing the OpenPose 3D Module</a></sup>\n</p>\n\n### Unity Plugin\n<p align=\"center\">\n    <img src=\".github/media/unity_main.png\" width=\"300\">\n    <img src=\".github/media/unity_body_foot.png\" width=\"300\">\n    <img src=\".github/media/unity_hand_face.png\" width=\"300\">\n    <br>\n    <sup><a href=\"https://ziutinyat.github.io/\" target=\"_blank\">Tianyi Zhao</a> and <a href=\"https://www.gineshidalgo.com\" target=\"_blank\">Gin\u00e9s Hidalgo</a> testing the <a href=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose_unity_plugin\" target=\"_blank\">OpenPose Unity Plugin</a></sup>\n</p>\n\n### Runtime Analysis\nWe show an inference time comparison between the 3 available pose estimation libraries (same hardware and conditions): OpenPose, Alpha-Pose (fast Pytorch version), and Mask R-CNN. The OpenPose runtime is constant, while the runtime of Alpha-Pose and Mask R-CNN grow linearly with the number of people. More details [**here**](https://arxiv.org/abs/1812.08008).\n\n<p align=\"center\">\n    <img src=\".github/media/openpose_vs_competition.png\" width=\"360\">\n</p>\n\n\n\n## Features\n**Main Functionality**:\n- **2D real-time multi-person keypoint detection**:\n    - 15, 18 or **25-keypoint body/foot keypoint estimation**, including **6 foot keypoints**. **Runtime invariant to number of detected people**.\n    - **2x21-keypoint hand keypoint estimation**. **Runtime depends on number of detected people**. See [**OpenPose Training**](https://github.com/CMU-Perceptual-Computing-Lab/openpose_train) for a runtime invariant alternative.\n    - **70-keypoint face keypoint estimation**. **Runtime depends on number of detected people**. See [**OpenPose Training**](https://github.com/CMU-Perceptual-Computing-Lab/openpose_train) for a runtime invariant alternative.\n- [**3D real-time single-person keypoint detection**](doc/advanced/3d_reconstruction_module.md):\n    - 3D triangulation from multiple single views.\n    - Synchronization of Flir cameras handled.\n    - Compatible with Flir/Point Grey cameras.\n- [**Calibration toolbox**](doc/advanced/calibration_module.md): Estimation of distortion, intrinsic, and extrinsic camera parameters.\n- **Single-person tracking** for further speedup or visual smoothing.\n\n**Input**: Image, video, webcam, Flir/Point Grey, IP camera, and support to add your own custom input source (e.g., depth camera).\n\n**Output**: Basic image + keypoint display/saving (PNG, JPG, AVI, ...), keypoint saving (JSON, XML, YML, ...), keypoints as array class, and support to add your own custom output code (e.g., some fancy UI).\n\n**OS**: Ubuntu (20, 18, 16, 14), Windows (10, 8), Mac OSX, Nvidia TX2.\n\n**Hardware compatibility**: CUDA (Nvidia GPU), OpenCL (AMD GPU), and non-GPU (CPU-only) versions.\n\n**Usage Alternatives**:\n- [**Command-line demo**](doc/01_demo.md) for built-in functionality.\n- [**C++ API**](doc/04_cpp_api.md/) and [**Python API**](doc/03_python_api.md) for custom functionality. E.g., adding your custom inputs, pre-processing, post-posprocessing, and output steps.\n\nFor further details, check the [major released features](doc/07_major_released_features.md) and [release notes](doc/08_release_notes.md) docs.\n\n\n\n## Related Work\n- [**OpenPose training code**](https://github.com/CMU-Perceptual-Computing-Lab/openpose_train)\n- [**OpenPose foot dataset**](https://cmu-perceptual-computing-lab.github.io/foot_keypoint_dataset/)\n- [**OpenPose Unity Plugin**](https://github.com/CMU-Perceptual-Computing-Lab/openpose_unity_plugin)\n- OpenPose papers published in **IEEE TPAMI and CVPR**. Cite them in your publications if OpenPose helps your research! (Links and more details in the [Citation](#citation) section below).\n\n\n\n## Installation\nIf you want to use OpenPose without installing or writing any code, simply [download and use the latest Windows portable version of OpenPose](doc/installation/0_index.md#windows-portable-demo)!\n\nOtherwise, you could [build OpenPose from source](doc/installation/0_index.md#compiling-and-running-openpose-from-source). See the [installation doc](doc/installation/0_index.md) for all the alternatives.\n\n\n\n## Quick Start Overview\nSimply use the OpenPose Demo from your favorite command-line tool (e.g., Windows PowerShell or Ubuntu Terminal). E.g., this example runs OpenPose on your webcam and displays the body keypoints:\n```\n# Ubuntu\n./build/examples/openpose/openpose.bin\n```\n```\n:: Windows - Portable Demo\nbin\\OpenPoseDemo.exe --video examples\\media\\video.avi\n```\n\nYou can also add any of the available flags in any order. E.g., the following example runs on a video (`--video {PATH}`), enables face (`--face`) and hands (`--hand`), and saves the output keypoints on JSON files on disk (`--write_json {PATH}`).\n```\n# Ubuntu\n./build/examples/openpose/openpose.bin --video examples/media/video.avi --face --hand --write_json output_json_folder/\n```\n```\n:: Windows - Portable Demo\nbin\\OpenPoseDemo.exe --video examples\\media\\video.avi --face --hand --write_json output_json_folder/\n```\n\nOptionally, you can also extend OpenPose's functionality from its Python and C++ APIs. After [installing](doc/installation/0_index.md) OpenPose, check its [official doc](doc/00_index.md) for a quick overview of all the alternatives and tutorials.\n\n\n\n## Send Us Feedback!\nOur library is open source for research purposes, and we want to improve it! So let us know (create a new GitHub issue or pull request, email us, etc.) if you...\n1. Find/fix any bug (in functionality or speed) or know how to speed up or improve any part of OpenPose.\n2. Want to add/show some cool functionality/demo/project made on top of OpenPose. We can add your project link to our [Community-based Projects](doc/10_community_projects.md) section or even integrate it with OpenPose!\n\n\n\n## Citation\nPlease cite these papers in your publications if OpenPose helps your research. All of OpenPose is based on [OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](https://arxiv.org/abs/1812.08008), while the hand and face detectors also use [Hand Keypoint Detection in Single Images using Multiview Bootstrapping](https://arxiv.org/abs/1704.07809) (the face detector was trained using the same procedure than the hand detector).\n\n    @article{8765346,\n      author = {Z. {Cao} and G. {Hidalgo Martinez} and T. {Simon} and S. {Wei} and Y. A. {Sheikh}},\n      journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n      title = {OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},\n      year = {2019}\n    }\n\n    @inproceedings{simon2017hand,\n      author = {Tomas Simon and Hanbyul Joo and Iain Matthews and Yaser Sheikh},\n      booktitle = {CVPR},\n      title = {Hand Keypoint Detection in Single Images using Multiview Bootstrapping},\n      year = {2017}\n    }\n\n    @inproceedings{cao2017realtime,\n      author = {Zhe Cao and Tomas Simon and Shih-En Wei and Yaser Sheikh},\n      booktitle = {CVPR},\n      title = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},\n      year = {2017}\n    }\n\n    @inproceedings{wei2016cpm,\n      author = {Shih-En Wei and Varun Ramakrishna and Takeo Kanade and Yaser Sheikh},\n      booktitle = {CVPR},\n      title = {Convolutional pose machines},\n      year = {2016}\n    }\n\nPaper links:\n- OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields:\n    - [IEEE TPAMI](https://ieeexplore.ieee.org/document/8765346)\n    - [ArXiv](https://arxiv.org/abs/1812.08008)\n- [Hand Keypoint Detection in Single Images using Multiview Bootstrapping](https://arxiv.org/abs/1704.07809)\n- [Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](https://arxiv.org/abs/1611.08050)\n- [Convolutional Pose Machines](https://arxiv.org/abs/1602.00134)\n\n\n\n## License\nOpenPose is freely available for free non-commercial use, and may be redistributed under these conditions. Please, see the [license](./LICENSE) for further details. Interested in a commercial license? Check this [FlintBox link](https://cmu.flintbox.com/#technologies/b820c21d-8443-4aa2-a49f-8919d93a8740). For commercial queries, use the `Contact` section from the [FlintBox link](https://cmu.flintbox.com/#technologies/b820c21d-8443-4aa2-a49f-8919d93a8740) and also send a copy of that message to [Yaser Sheikh](mailto:yaser@cs.cmu.edu).\n",
	"deep-learning neural-networks pytorch pytorch-tutorial": "<p align=\"center\"><img width=\"40%\" src=\"logo/pytorch_logo_2018.svg\" /></p>\n\n--------------------------------------------------------------------------------\n\nThis repository provides tutorial code for deep learning researchers to learn [PyTorch](https://github.com/pytorch/pytorch). In the tutorial, most of the models were implemented with less than 30 lines of code. Before starting this tutorial, it is recommended to finish [Official Pytorch Tutorial](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).\n\n\n<br/>\n\n## Table of Contents\n\n#### 1. Basics\n* [PyTorch Basics](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/pytorch_basics/main.py)\n* [Linear Regression](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/linear_regression/main.py#L22-L23)\n* [Logistic Regression](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/logistic_regression/main.py#L33-L34)\n* [Feedforward Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/01-basics/feedforward_neural_network/main.py#L37-L49)\n\n#### 2. Intermediate\n* [Convolutional Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/convolutional_neural_network/main.py#L35-L56)\n* [Deep Residual Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/deep_residual_network/main.py#L76-L113)\n* [Recurrent Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/recurrent_neural_network/main.py#L39-L58)\n* [Bidirectional Recurrent Neural Network](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/bidirectional_recurrent_neural_network/main.py#L39-L58)\n* [Language Model (RNN-LM)](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/02-intermediate/language_model/main.py#L30-L50)\n\n#### 3. Advanced\n* [Generative Adversarial Networks](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/generative_adversarial_network/main.py#L41-L57)\n* [Variational Auto-Encoder](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py#L38-L65)\n* [Neural Style Transfer](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/neural_style_transfer)\n* [Image Captioning (CNN-RNN)](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/image_captioning)\n\n#### 4. Utilities\n* [TensorBoard in PyTorch](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/04-utils/tensorboard)\n\n\n<br/>\n\n## Getting Started\n```bash\n$ git clone https://github.com/yunjey/pytorch-tutorial.git\n$ cd pytorch-tutorial/tutorials/PATH_TO_PROJECT\n$ python main.py\n```\n\n<br/>\n\n## Dependencies\n* [Python 2.7 or 3.5+](https://www.continuum.io/downloads)\n* [PyTorch 0.4.0+](http://pytorch.org/)\n\n\n\n\n",
	"ai deep-learning pytorch speech": "![mockingbird](https://user-images.githubusercontent.com/12797292/131216767-6eb251d6-14fc-4951-8324-2722f0cd4c63.jpg)\n\n\n[![MIT License](https://img.shields.io/badge/license-MIT-blue.svg?style=flat)](http://choosealicense.com/licenses/mit/)\n\n> English | [\u4e2d\u6587](README-CN.md)\n\n## Features\n\ud83c\udf0d **Chinese** supported mandarin and tested with multiple datasets: aidatatang_200zh, magicdata, aishell3, data_aishell, and etc.\n\n\ud83e\udd29 **PyTorch** worked for pytorch, tested in version of 1.9.0(latest in August 2021), with GPU Tesla T4 and GTX 2060\n\n\ud83c\udf0d **Windows + Linux** run in both Windows OS and linux OS (even in M1 MACOS)\n\n\ud83e\udd29 **Easy & Awesome** effect with only newly-trained synthesizer, by reusing the pretrained encoder/vocoder\n\n\ud83c\udf0d **Webserver Ready** to serve your result with remote calling\n\n### [DEMO VIDEO](https://www.bilibili.com/video/BV17Q4y1B7mY/)\n\n### Ongoing Works(Helps Needed)\n* Major upgrade on GUI/Client and unifying web and toolbox\n[X] Init framework `./mkgui` and [tech design](https://vaj2fgg8yn.feishu.cn/docs/doccnvotLWylBub8VJIjKzoEaee)\n[X] Add demo part of Voice Cloning and Conversion\n[X] Add preprocessing and training for Voice Conversion\n[ ] Add preprocessing and training for Encoder/Synthesizer/Vocoder\n* Major upgrade on model backend based on ESPnet2(not yet started)\n\n## Quick Start\n\n### 1. Install Requirements\n> Follow the original repo to test if you got all environment ready.\n**Python 3.7 or higher ** is needed to run the toolbox.\n\n* Install [PyTorch](https://pytorch.org/get-started/locally/).\n> If you get an `ERROR: Could not find a version that satisfies the requirement torch==1.9.0+cu102 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2 )` This error is probably due to a low version of python, try using 3.9 and it will install successfully\n* Install [ffmpeg](https://ffmpeg.org/download.html#get-packages).\n* Run `pip install -r requirements.txt` to install the remaining necessary packages.\n* Install webrtcvad `pip install webrtcvad-wheels`(If you need)\n> Note that we are using the pretrained encoder/vocoder but synthesizer since the original model is incompatible with the Chinese symbols. It means the demo_cli is not working at this moment.\n### 2. Prepare your models\nYou can either train your models or use existing ones:\n\n#### 2.1 Train encoder with your dataset (Optional)\n\n* Preprocess with the audios and the mel spectrograms:\n`python encoder_preprocess.py <datasets_root>` Allowing parameter `--dataset {dataset}` to support the datasets you want to preprocess. Only the train set of these datasets will be used. Possible names: librispeech_other, voxceleb1, voxceleb2. Use comma to sperate multiple datasets.\n\n* Train the encoder: `python encoder_train.py my_run <datasets_root>/SV2TTS/encoder`\n> For training, the encoder uses visdom. You can disable it with `--no_visdom`, but it's nice to have. Run \"visdom\" in a separate CLI/process to start your visdom server.\n\n#### 2.2 Train synthesizer with your dataset\n* Download dataset and unzip: make sure you can access all .wav in folder\n* Preprocess with the audios and the mel spectrograms:\n`python pre.py <datasets_root>`\nAllowing parameter `--dataset {dataset}` to support aidatatang_200zh, magicdata, aishell3, data_aishell, etc.If this parameter is not passed, the default dataset will be aidatatang_200zh.\n\n* Train the synthesizer:\n`python synthesizer_train.py mandarin <datasets_root>/SV2TTS/synthesizer`\n\n* Go to next step when you see attention line show and loss meet your need in training folder *synthesizer/saved_models/*.\n\n#### 2.3 Use pretrained model of synthesizer\n> Thanks to the community, some models will be shared:\n\n| author | Download link | Preview Video | Info |\n| --- | ----------- | ----- |----- |\n| @author | https://pan.baidu.com/s/1iONvRxmkI-t1nHqxKytY3g  [Baidu](https://pan.baidu.com/s/1iONvRxmkI-t1nHqxKytY3g) 4j5d  |  | 75k steps trained by multiple datasets\n| @author | https://pan.baidu.com/s/1fMh9IlgKJlL2PIiRTYDUvw  [Baidu](https://pan.baidu.com/s/1fMh9IlgKJlL2PIiRTYDUvw) code\uff1aom7f  |  | 25k steps trained by multiple datasets, only works under version 0.0.1\n|@FawenYo | https://drive.google.com/file/d/1H-YGOUHpmqKxJ9FRc6vAjPuqQki24UbC/view?usp=sharing https://u.teknik.io/AYxWf.pt  | [input](https://github.com/babysor/MockingBird/wiki/audio/self_test.mp3) [output](https://github.com/babysor/MockingBird/wiki/audio/export.wav) | 200k steps with local accent of Taiwan, only works under version 0.0.1\n|@miven| https://pan.baidu.com/s/1PI-hM3sn5wbeChRryX-RCQ code: 2021 https://www.aliyundrive.com/s/AwPsbo8mcSP code: z2m0 | https://www.bilibili.com/video/BV1uh411B7AD/ | only works under version 0.0.1\n\n#### 2.4 Train vocoder (Optional)\n> note: vocoder has little difference in effect, so you may not need to train a new one.\n* Preprocess the data:\n`python vocoder_preprocess.py <datasets_root> -m <synthesizer_model_path>`\n> `<datasets_root>` replace with your dataset root\uff0c`<synthesizer_model_path>`replace with directory of your best trained models of sythensizer, e.g. *sythensizer\\saved_mode\\xxx*\n\n* Train the wavernn vocoder:\n`python vocoder_train.py mandarin <datasets_root>`\n\n* Train the hifigan vocoder\n`python vocoder_train.py mandarin <datasets_root> hifigan`\n\n### 3. Launch\n#### 3.1 Using the web server\nYou can then try to run:`python web.py` and open it in browser, default as `http://localhost:8080`\n\n#### 3.2 Using the Toolbox\nYou can then try the toolbox:\n`python demo_toolbox.py -d <datasets_root>`\n\n#### 3.3 Using the command line\nYou can then try the command:\n`python gen_voice.py <text_file.txt> your_wav_file.wav`\nyou may need to install cn2an by \"pip install cn2an\" for better digital number result.\n\n## Reference\n> This repository is forked from [Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning) which only support English.\n\n| URL | Designation | Title | Implementation source |\n| --- | ----------- | ----- | --------------------- |\n| [1803.09017](https://arxiv.org/abs/1803.09017) | GlobalStyleToken (synthesizer)| Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis | This repo |\n| [2010.05646](https://arxiv.org/abs/2010.05646) | HiFi-GAN (vocoder)| Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis | This repo |\n| [2106.02297](https://arxiv.org/abs/2106.02297) | Fre-GAN (vocoder)| Fre-GAN: Adversarial Frequency-consistent Audio Synthesis | This repo |\n|[**1806.04558**](https://arxiv.org/pdf/1806.04558.pdf) | **SV2TTS** | **Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis** | This repo |\n|[1802.08435](https://arxiv.org/pdf/1802.08435.pdf) | WaveRNN (vocoder) | Efficient Neural Audio Synthesis | [fatchord/WaveRNN](https://github.com/fatchord/WaveRNN) |\n|[1703.10135](https://arxiv.org/pdf/1703.10135.pdf) | Tacotron (synthesizer) | Tacotron: Towards End-to-End Speech Synthesis | [fatchord/WaveRNN](https://github.com/fatchord/WaveRNN)\n|[1710.10467](https://arxiv.org/pdf/1710.10467.pdf) | GE2E (encoder)| Generalized End-To-End Loss for Speaker Verification | This repo |\n\n## F Q&A\n#### 1.Where can I download the dataset?\n| Dataset | Original Source | Alternative Sources |\n| --- | ----------- | ---------------|\n| aidatatang_200zh | [OpenSLR](http://www.openslr.org/62/) | [Google Drive](https://drive.google.com/file/d/110A11KZoVe7vy6kXlLb6zVPLb_J91I_t/view?usp=sharing) |\n| magicdata | [OpenSLR](http://www.openslr.org/68/) | [Google Drive (Dev set)](https://drive.google.com/file/d/1g5bWRUSNH68ycC6eNvtwh07nX3QhOOlo/view?usp=sharing) |\n| aishell3 | [OpenSLR](https://www.openslr.org/93/) | [Google Drive](https://drive.google.com/file/d/1shYp_o4Z0X0cZSKQDtFirct2luFUwKzZ/view?usp=sharing) |\n| data_aishell | [OpenSLR](https://www.openslr.org/33/) |  |\n> After unzip aidatatang_200zh, you need to unzip all the files under `aidatatang_200zh\\corpus\\train`\n\n#### 2.What is`<datasets_root>`?\nIf the dataset path is `D:\\data\\aidatatang_200zh`,then `<datasets_root>` is`D:\\data`\n\n#### 3.Not enough VRAM\nTrain the synthesizer\uff1aadjust the batch_size in `synthesizer/hparams.py`\n```\n//Before\ntts_schedule = [(2,  1e-3,  20_000,  12),   # Progressive training schedule\n                (2,  5e-4,  40_000,  12),   # (r, lr, step, batch_size)\n                (2,  2e-4,  80_000,  12),   #\n                (2,  1e-4, 160_000,  12),   # r = reduction factor (# of mel frames\n                (2,  3e-5, 320_000,  12),   #     synthesized for each decoder iteration)\n                (2,  1e-5, 640_000,  12)],  # lr = learning rate\n//After\ntts_schedule = [(2,  1e-3,  20_000,  8),   # Progressive training schedule\n                (2,  5e-4,  40_000,  8),   # (r, lr, step, batch_size)\n                (2,  2e-4,  80_000,  8),   #\n                (2,  1e-4, 160_000,  8),   # r = reduction factor (# of mel frames\n                (2,  3e-5, 320_000,  8),   #     synthesized for each decoder iteration)\n                (2,  1e-5, 640_000,  8)],  # lr = learning rate\n```\n\nTrain Vocoder-Preprocess the data\uff1aadjust the batch_size in `synthesizer/hparams.py`\n```\n//Before\n### Data Preprocessing\n        max_mel_frames = 900,\n        rescale = True,\n        rescaling_max = 0.9,\n        synthesis_batch_size = 16,                  # For vocoder preprocessing and inference.\n//After\n### Data Preprocessing\n        max_mel_frames = 900,\n        rescale = True,\n        rescaling_max = 0.9,\n        synthesis_batch_size = 8,                  # For vocoder preprocessing and inference.\n```\n\nTrain Vocoder-Train the vocoder\uff1aadjust the batch_size in `vocoder/wavernn/hparams.py`\n```\n//Before\n# Training\nvoc_batch_size = 100\nvoc_lr = 1e-4\nvoc_gen_at_checkpoint = 5\nvoc_pad = 2\n\n//After\n# Training\nvoc_batch_size = 6\nvoc_lr = 1e-4\nvoc_gen_at_checkpoint = 5\nvoc_pad =2\n```\n\n#### 4.If it happens `RuntimeError: Error(s) in loading state_dict for Tacotron: size mismatch for encoder.embedding.weight: copying a param with shape torch.Size([70, 512]) from checkpoint, the shape in current model is torch.Size([75, 512]).`\nPlease refer to issue [#37](https://github.com/babysor/MockingBird/issues/37)\n\n#### 5. How to improve CPU and GPU occupancy rate?\nAdjust the batch_size as appropriate to improve\n\n\n#### 6. What if it happens `the page file is too small to complete the operation`\nPlease refer to this [video](https://www.youtube.com/watch?v=Oh6dga-Oy10&ab_channel=CodeProf) and change the virtual memory to 100G (102400), for example : When the file is placed in the D disk, the virtual memory of the D disk is changed.\n\n#### 7. When should I stop during training?\nFYI, my attention came after 18k steps and loss became lower than 0.4 after 50k steps.\n![attention_step_20500_sample_1](https://user-images.githubusercontent.com/7423248/128587252-f669f05a-f411-4811-8784-222156ea5e9d.png)\n![step-135500-mel-spectrogram_sample_1](https://user-images.githubusercontent.com/7423248/128587255-4945faa0-5517-46ea-b173-928eff999330.png)\n",
	"deep-learning deprecated distributed jupyter-notebook machine-learning ml neural-network python scikit-learn tensorflow": "Machine Learning Notebooks\n==========================\n\n# \u26a0 THE <a href=\"https://github.com/ageron/handson-ml3\">THIRD EDITION OF MY BOOK</a> IS NOW AVAILABLE.\n\nThis project is for the first edition, which is now outdated.\n\n<details>\n\nThis project aims at teaching you the fundamentals of Machine Learning in\npython. It contains the example code and solutions to the exercises in my O'Reilly book [Hands-on Machine Learning with Scikit-Learn and TensorFlow](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781491962282/):\n\n[![book](http://akamaicovers.oreilly.com/images/9781491962282/cat.gif)](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781491962282/)\n\n\n## Quick Start\n\n### Want to play with these notebooks online without having to install anything?\nUse any of the following services.\n\n**WARNING**: Please be aware that these services provide temporary environments: anything you do will be deleted after a while, so make sure you download any data you care about.\n\n* **Recommended**: open this repository in [Colaboratory](https://colab.research.google.com/github/ageron/handson-ml/blob/master/):\n<a href=\"https://colab.research.google.com/github/ageron/handson-ml/blob/master/\"><img src=\"https://colab.research.google.com/img/colab_favicon.ico\" width=\"90\" /></a>\n\n* Or open it in [Binder](https://mybinder.org/v2/gh/ageron/handson-ml/master):\n<a href=\"https://mybinder.org/v2/gh/ageron/handson-ml/master\"><img src=\"https://matthiasbussonnier.com/posts/img/binder_logo_128x128.png\" width=\"90\" /></a>\n\n  * _Note_: Most of the time, Binder starts up quickly and works great, but when handson-ml is updated, Binder creates a new environment from scratch, and this can take quite some time.\n\n* Or open it in [Deepnote](https://beta.deepnote.com/launch?template=data-science&url=https%3A//github.com/ageron/handson-ml/blob/master/index.ipynb):\n<a href=\"https://beta.deepnote.com/launch?template=data-science&url=https%3A//github.com/ageron/handson-ml/blob/master/index.ipynb\"><img src=\"https://www.deepnote.com/static/illustration.png\" width=\"150\" /></a>\n\n### Just want to quickly look at some notebooks, without executing any code?\n\nBrowse this repository using [jupyter.org's notebook viewer](https://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/index.ipynb):\n<a href=\"https://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/index.ipynb\"><img src=\"https://jupyter.org/assets/logos/rectanglelogo-greytext-orangebody-greymoons.svg\" width=\"150\" /></a>\n\n_Note_: [github.com's notebook viewer](index.ipynb) also works but it is slower and the math equations are not always displayed correctly.\n\n### Want to run this project using a Docker image?\nRead the [Docker instructions](https://github.com/ageron/handson-ml/tree/master/docker).\n\n### Want to install this project on your own machine?\n\nStart by installing [Anaconda](https://www.anaconda.com/distribution/) (or [Miniconda](https://docs.conda.io/en/latest/miniconda.html)), [git](https://git-scm.com/downloads), and if you have a TensorFlow-compatible GPU, install the [GPU driver](https://www.nvidia.com/Download/index.aspx), as well as the appropriate version of CUDA and cuDNN (see TensorFlow's documentation for more details).\n\nNext, clone this project by opening a terminal and typing the following commands (do not type the first `$` signs on each line, they just indicate that these are terminal commands):\n\n    $ git clone https://github.com/ageron/handson-ml.git\n    $ cd handson-ml\n\nNext, run the following commands:\n\n    $ conda env create -f environment.yml\n    $ conda activate tf1\n    $ python -m ipykernel install --user --name=python3\n\nFinally, start Jupyter:\n\n    $ jupyter notebook\n\nIf you need further instructions, read the [detailed installation instructions](INSTALL.md).\n\n# FAQ\n\n**Which Python version should I use?**\n\nI recommend Python 3.7. If you follow the installation instructions above, that's the version you will get. Most code will work with other versions of Python 3, but some libraries do not support Python 3.8 or 3.9 yet, which is why I recommend Python 3.7.\n\n**I'm getting an error when I call `load_housing_data()`**\n\nMake sure you call `fetch_housing_data()` *before* you call `load_housing_data()`. If you're getting an HTTP error, make sure you're running the exact same code as in the notebook (copy/paste it if needed). If the problem persists, please check your network configuration.\n\n**I'm getting an SSL error on MacOSX**\n\nYou probably need to install the SSL certificates (see this [StackOverflow question](https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error)). If you downloaded Python from the official website, then run `/Applications/Python\\ 3.7/Install\\ Certificates.command` in a terminal (change `3.7` to whatever version you installed). If you installed Python using MacPorts, run `sudo port install curl-ca-bundle` in a terminal.\n\n**I've installed this project locally. How do I update it to the latest version?**\n\nSee [INSTALL.md](INSTALL.md)\n\n**How do I update my Python libraries to the latest versions, when using Anaconda?**\n\nSee [INSTALL.md](INSTALL.md)\n\n## Contributors\nI would like to thank everyone [who contributed to this project](https://github.com/ageron/handson-ml/graphs/contributors), either by providing useful feedback, filing issues or submitting Pull Requests. Special thanks go to Haesun Park and Ian Beauregard who reviewed every notebook and submitted many PRs, including help on some of the exercise solutions. Thanks as well to Steven Bunkley and Ziembla who created the `docker` directory, and to github user SuperYorio who helped on some exercise solutions.\n\n</details>\n",
	"ai caffe caffe2 coreml darknet deep-learning deeplearning keras machine-learning machinelearning ml mxnet neural-network onnx paddle pytorch tensorflow tensorflow-lite torch visualizer": "<div align=\"center\">\n<img width=\"400px\" height=\"100px\" src=\"https://github.com/lutzroeder/netron/raw/main/.github/logo-light.svg#gh-light-mode-only\">\n<img width=\"400px\" height=\"100px\" src=\"https://github.com/lutzroeder/netron/raw/main/.github/logo-dark.svg#gh-dark-mode-only\">\n</div>\n\nNetron is a viewer for neural network, deep learning and machine learning models. \n\nNetron supports ONNX, TensorFlow Lite, Caffe, Keras, Darknet, PaddlePaddle, ncnn, MNN, Core ML, RKNN, MXNet, MindSpore Lite, TNN, Barracuda, Tengine, CNTK, TensorFlow.js, Caffe2 and UFF.\n\nNetron has experimental support for PyTorch, TensorFlow, TorchScript, OpenVINO, Torch, Vitis AI, kmodel, Arm NN, BigDL, Chainer, Deeplearning4j, MediaPipe, MegEngine, ML.NET and scikit-learn.\n\n<p align='center'><a href='https://www.lutzroeder.com/ai'><img src='.github/screenshot.png' width='800'></a></p>\n\n## Install\n\n**macOS**: [**Download**](https://github.com/lutzroeder/netron/releases/latest) the `.dmg` file or run `brew install --cask netron`\n\n**Linux**: [**Download**](https://github.com/lutzroeder/netron/releases/latest) the `.AppImage` file or run `snap install netron`\n\n**Windows**: [**Download**](https://github.com/lutzroeder/netron/releases/latest) the `.exe` installer or run `winget install -s winget netron`\n\n**Browser**: [**Start**](https://netron.app) the browser version.\n\n**Python Server**: Run `pip install netron` and `netron [FILE]` or `netron.start('[FILE]')`.\n\n## Models\n\nSample model files to download or open using the browser version:\n\n * **ONNX**: [squeezenet](https://media.githubusercontent.com/media/onnx/models/main/vision/classification/squeezenet/model/squeezenet1.0-3.onnx) [[open](https://netron.app?url=https://media.githubusercontent.com/media/onnx/models/main/vision/classification/squeezenet/model/squeezenet1.0-3.onnx)]\n * **TensorFlow Lite**: [yamnet](https://huggingface.co/thelou1s/yamnet/resolve/main/lite-model_yamnet_tflite_1.tflite) [[open](https://netron.app?url=https://huggingface.co/thelou1s/yamnet/resolve/main/lite-model_yamnet_tflite_1.tflite)]\n * **TensorFlow**: [chessbot](https://raw.githubusercontent.com/srom/chessbot/master/model/chessbot.pb) [[open](https://netron.app?url=https://raw.githubusercontent.com/srom/chessbot/master/model/chessbot.pb)]\n * **Keras**: [mobilenet](https://raw.githubusercontent.com/aio-libs/aiohttp-demos/master/demos/imagetagger/tests/data/mobilenet.h5) [[open](https://netron.app?url=https://raw.githubusercontent.com/aio-libs/aiohttp-demos/master/demos/imagetagger/tests/data/mobilenet.h5)]\n * **TorchScript**: [traced_online_pred_layer](https://raw.githubusercontent.com/ApolloAuto/apollo/master/modules/prediction/data/traced_online_pred_layer.pt) [[open](https://netron.app?url=https://raw.githubusercontent.com/ApolloAuto/apollo/master/modules/prediction/data/traced_online_pred_layer.pt)]\n * **Core ML**: [exermote](https://raw.githubusercontent.com/Lausbert/Exermote/master/ExermoteInference/ExermoteCoreML/ExermoteCoreML/Model/Exermote.mlmodel) [[open](https://netron.app?url=https://raw.githubusercontent.com/Lausbert/Exermote/master/ExermoteInference/ExermoteCoreML/ExermoteCoreML/Model/Exermote.mlmodel)]\n * **Darknet**: [yolo](https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolo.cfg) [[open](https://netron.app?url=https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolo.cfg)]\n",
	"google-kubernetes-engine jupyter kubeflow kubernetes machine-learning minikube ml notebook tensorflow": "<img src=\"https://www.kubeflow.org/images/logo.svg\" width=\"100\">\nKubeflow the cloud-native platform for machine learning operations - pipelines, training and deployment.\n\n---\n\n## Documentation\nPlease refer to the official docs at [kubeflow.org](http://kubeflow.org).\n\n## Working Groups\nThe Kubeflow community is organized into working groups (WGs) with associated repositories, that focus on specific pieces of the ML platform. \n\n* [AutoML](https://github.com/kubeflow/community/tree/master/wg-automl)\n* [Deployment](https://github.com/kubeflow/community/tree/master/wg-deployment)\n* [Manifests](https://github.com/kubeflow/community/tree/master/wg-manifests)\n* [Notebooks](https://github.com/kubeflow/community/tree/master/wg-notebooks)\n* [Pipelines](https://github.com/kubeflow/community/tree/master/wg-pipelines)\n* [Serving](https://github.com/kubeflow/community/tree/master/wg-serving)\n* [Training](https://github.com/kubeflow/community/tree/master/wg-training)\n\n## Quick Links\n* [Prow jobs dashboard](http://prow.kubeflow-testing.com)\n* [PR Dashboard](https://k8s-gubernator.appspot.com/pr)\n* [Argo UI for E2E tests](https://argo.kubeflow-testing.com)\n\n## Get Involved\nPlease refer to the [Community](https://www.kubeflow.org/docs/about/community/) page.\n\n",
	"ai google ml rl tensorflow": "# Dopamine\n[Getting Started](#getting-started) |\n[Docs][docs] |\n[Baseline Results][baselines] |\n[Changelist](https://google.github.io/dopamine/docs/changelist)\n\n<div align=\"center\">\n  <img src=\"https://google.github.io/dopamine/images/dopamine_logo.png\"><br><br>\n</div>\n\nDopamine is a research framework for fast prototyping of reinforcement learning\nalgorithms. It aims to fill the need for a small, easily grokked codebase in\nwhich users can freely experiment with wild ideas (speculative research).\n\nOur design principles are:\n\n* _Easy experimentation_: Make it easy for new users to run benchmark\n                          experiments.\n* _Flexible development_: Make it easy for new users to try out research ideas.\n* _Compact and reliable_: Provide implementations for a few, battle-tested\n                          algorithms.\n* _Reproducible_: Facilitate reproducibility in results. In particular, our\n                  setup follows the recommendations given by\n                  [Machado et al. (2018)][machado].\n\nDopamine supports the following agents, implemented with jax:\n\n* DQN ([Mnih et al., 2015][dqn])\n* C51 ([Bellemare et al., 2017][c51])\n* Rainbow ([Hessel et al., 2018][rainbow])\n* IQN ([Dabney et al., 2018][iqn])\n* SAC ([Haarnoja et al., 2018][sac])\n\nFor more information on the available agents, see the [docs](https://google.github.io/dopamine/docs).\n\nMany of these agents also have a tensorflow (legacy) implementation, though\nnewly added agents are likely to be jax-only.\n\nThis is not an official Google product.\n\n## Getting Started\n\n\nWe provide docker containers for using Dopamine.\nInstructions can be found [here](https://google.github.io/dopamine/docker/).\n\nAlternatively, Dopamine can be installed from source (preferred) or installed\nwith pip. For either of these methods, continue reading at prerequisites.\n\n### Prerequisites\n\nDopamine supports Atari environments and Mujoco environments. Install the\nenvironments you intend to use before you install Dopamine:\n\n**Atari**\n\n1. Install the atari roms following the instructions from\n[atari-py](https://github.com/openai/atari-py#roms).\n2. `pip install ale-py` (we recommend using a [virtual environment](virtualenv)):\n3. `unzip $ROM_DIR/ROMS.zip -d $ROM_DIR && ale-import-roms $ROM_DIR/ROMS`\n(replace $ROM_DIR with the directory you extracted the ROMs to).\n\n**Mujoco**\n\n1. Install Mujoco and get a license\n[here](https://github.com/openai/mujoco-py#install-mujoco).\n2. Run `pip install mujoco-py` (we recommend using a\n[virtual environment](virtualenv)).\n\n### Installing from Source\n\n\nThe most common way to use Dopamine is to install it from source and modify\nthe source code directly:\n\n```\ngit clone https://github.com/google/dopamine\n```\n\nAfter cloning, install dependencies:\n\n```\npip install -r dopamine/requirements.txt\n```\n\nDopamine supports tensorflow (legacy) and jax (actively maintained) agents.\nView the [Tensorflow documentation](https://www.tensorflow.org/install) for\nmore information on installing tensorflow.\n\nNote: We recommend using a [virtual environment](virtualenv) when working with Dopamine.\n\n### Installing with Pip\n\nNote: We strongly recommend installing from source for most users.\n\nInstalling with pip is simple, but Dopamine is designed to be modified\ndirectly. We recommend installing from source for writing your own experiments.\n\n```\npip install dopamine-rl\n```\n\n### Running tests\n\nYou can test whether the installation was successful by running the following\nfrom the dopamine root directory.\n\n```\nexport PYTHONPATH=$PYTHONPATH:$PWD\npython -m tests.dopamine.atari_init_test\n```\n\n## Next Steps\n\nView the [docs][docs] for more information on training agents.\n\nWe supply [baselines][baselines] for each Dopamine agent.\n\nWe also provide a set of [Colaboratory notebooks](https://github.com/google/dopamine/tree/master/dopamine/colab)\nwhich demonstrate how to use Dopamine.\n\n## References\n\n[Bellemare et al., *The Arcade Learning Environment: An evaluation platform for\ngeneral agents*. Journal of Artificial Intelligence Research, 2013.][ale]\n\n[Machado et al., *Revisiting the Arcade Learning Environment: Evaluation\nProtocols and Open Problems for General Agents*, Journal of Artificial\nIntelligence Research, 2018.][machado]\n\n[Hessel et al., *Rainbow: Combining Improvements in Deep Reinforcement Learning*.\nProceedings of the AAAI Conference on Artificial Intelligence, 2018.][rainbow]\n\n[Mnih et al., *Human-level Control through Deep Reinforcement Learning*. Nature,\n2015.][dqn]\n\n[Schaul et al., *Prioritized Experience Replay*. Proceedings of the International\nConference on Learning Representations, 2016.][prioritized_replay]\n\n[Haarnoja et al., *Soft Actor-Critic Algorithms and Applications*,\narXiv preprint arXiv:1812.05905, 2018.][sac]\n\n## Giving credit\n\nIf you use Dopamine in your work, we ask that you cite our\n[white paper][dopamine_paper]. Here is an example BibTeX entry:\n\n```\n@article{castro18dopamine,\n  author    = {Pablo Samuel Castro and\n               Subhodeep Moitra and\n               Carles Gelada and\n               Saurabh Kumar and\n               Marc G. Bellemare},\n  title     = {Dopamine: {A} {R}esearch {F}ramework for {D}eep {R}einforcement {L}earning},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1812.06110},\n  archivePrefix = {arXiv}\n}\n```\n\n\n\n[docs]: https://google.github.io/dopamine/docs/\n[baselines]: https://google.github.io/dopamine/baselines\n[machado]: https://jair.org/index.php/jair/article/view/11182\n[ale]: https://jair.org/index.php/jair/article/view/10819\n[dqn]: https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf\n[a3c]: http://proceedings.mlr.press/v48/mniha16.html\n[prioritized_replay]: https://arxiv.org/abs/1511.05952\n[c51]: http://proceedings.mlr.press/v70/bellemare17a.html\n[rainbow]: https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/17204/16680\n[iqn]: https://arxiv.org/abs/1806.06923\n[sac]: https://arxiv.org/abs/1812.05905\n[dopamine_paper]: https://arxiv.org/abs/1812.06110\n[vitualenv]: https://docs.python.org/3/library/venv.html#creating-virtual-environments\n",
	"ai data-science devops engineering federated-learning machine-learning ml mlops software-engineering": "# Awesome MLOps [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) [![Made With Love](https://img.shields.io/badge/Made%20With-Love-orange.svg)](https://github.com/chetanraj/awesome-github-badges) \n\n![MLOps. You Desing It. Your Train It. You Run It.](awesome-mlops-intro.png)\n\n*An awesome list of references for MLOps - Machine Learning Operations :point_right: [ml-ops.org](https://ml-ops.org/)*\n\n\n![Twitter Follow](https://img.shields.io/twitter/follow/visenger?style=social)\n\n\n# Table of Content\n| <!-- -->                         | <!-- -->                         |\n| -------------------------------- | -------------------------------- |\n| [MLOps Core](#core-mlops) | [MLOps Communities](#mlops-communities) |\n| [MLOps Books](#mlops-books) | [MLOps Articles](#mlops-articles) |\n| [MLOps Workflow Management](#wfl-management)| [MLOps: Feature Stores](#feature-stores) | \n|[MLOps: Data Engineering (DataOps)](#dataops) | [MLOps: Model Deployment and Serving](#deployment) |\n| [MLOps: Testing, Monitoring and Maintenance](#testing-monintoring)| [MLOps: Infrastructure](#mlops-infra)| \n|[MLOps Papers](#mlops-papers) | [Talks About MLOps](#talks-about-mlops) | \n| [Existing ML Systems](#existing-ml-systems) | [Machine Learning](#machine-learning)|\n| [Software Engineering](#software-engineering) | [Product Management for ML/AI](#product-management-for-mlai) | \n| [The Economics of ML/AI](#the-economics-of-mlai) | [Model Governance, Ethics, Responsible AI](#ml-governance) | \n| [MLOps: People & Processes](#teams)|[Newsletters About MLOps, Machine Learning, Data Science and Co.](#newsletters)| \n\n\n<a name=\"core-mlops\"></a>\n# MLOps Core\n<details>\n<summary>Click to expand!</summary>\n \n1. [Machine Learning Operations: You Design It, You Train It, You Run It!](https://ml-ops.org/)\n1. [MLOps SIG Specification](https://github.com/tdcox/mlops-roadmap/blob/master/MLOpsRoadmap2020.md)\n1. [ML in Production](http://mlinproduction.com/)\n1. [Awesome production machine learning: State of MLOps Tools and Frameworks](https://github.com/EthicalML/awesome-production-machine-learning)\n1. [Udemy \u201cDeployment of ML Models\u201d](https://www.udemy.com/course/deployment-of-machine-learning-models/)\n1. [Full Stack Deep Learning](https://course.fullstackdeeplearning.com/)\n1. [Engineering best practices for Machine Learning](https://se-ml.github.io/practices/)\n1. [:rocket: Putting ML in Production](https://madewithml.com/courses/putting-ml-in-production/)\n1. [Stanford MLSys Seminar Series](https://mlsys.stanford.edu/)\n1. [IBM ML Operationalization Starter Kit](https://github.com/ibm-cloud-architecture/refarch-ml-ops)\n1. [Productize ML. A self-study guide for Developers and Product Managers building Machine Learning products.](https://productizeml.gitbook.io/productize-ml/)\n1. [MLOps (Machine Learning Operations) Fundamentals on GCP](https://www.coursera.org/learn/mlops-fundamentals)\n1. [ML full Stack preparation](https://www.confetti.ai/)\n1. [MLOps Guide: Theory and Implementation](https://mlops-guide.github.io/)\n1. [Practitioners guide to MLOps: A framework for continuous delivery and automation of machine learning.](https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf)\n</details>\n\n\n<a name=\"mlops-communities\"></a>\n# MLOps Communities\n<details>\n<summary>Click to expand!</summary>\n\n1. [MLOps.community](https://mlops.community/)\n1. [CDF Special Interest Group - MLOps](https://github.com/cdfoundation/sig-mlops)\n1. [RsqrdAI - Robust and Responsible AI](https://www.rsqrdai.org)\n1. [DataTalks.Club](https://datatalks.club/)\n1. [Synthetic Data Community](https://syntheticdata.community/)\n1. [MLOps World Community](https://www.mlopsworld.com)\n</details>\n\n<a name=\"mlops-courses\"></a>\n# MLOps Courses\n\n1. [MLOps Zoomcamp (free)](https://github.com/DataTalksClub/mlops-zoomcamp)\n2. [Coursera's Machine Learning Engineering for Production (MLOps) Specialization](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops)\n\n\n<a name=\"mlops-books\"></a>\n# MLOps Books\n\n<details>\n<summary>Click to expand!</summary>\n \n1. [\u201cMachine Learning Engineering\u201d by Andriy Burkov, 2020](http://www.mlebook.com/wiki/doku.php?id=start)\n1. [\"ML Ops: Operationalizing Data Science\" by David Sweenor, Steven Hillion, Dan Rope, Dev Kannabiran, Thomas Hill, Michael O'Connell](https://learning.oreilly.com/library/view/ml-ops-operationalizing/9781492074663/)\n1. [\"Building Machine Learning Powered Applications\" by Emmanuel Ameisen](https://learning.oreilly.com/library/view/building-machine-learning/9781492045106/)\n1. [\"Building Machine Learning Pipelines\" by Hannes Hapke, Catherine Nelson, 2020, O\u2019Reilly](https://learning.oreilly.com/library/view/building-machine-learning/9781492053187/) \n1. [\"Managing Data Science\" by Kirill Dubovikov](https://www.packtpub.com/eu/data/managing-data-science)\n1. [\"Accelerated DevOps with AI, ML & RPA: Non-Programmer's Guide to AIOPS & MLOPS\" by Stephen Fleming](https://www.amazon.com/Accelerated-DevOps-AI-RPA-Non-Programmers-ebook/dp/B07ZMJCJRS)\n1. [\"Evaluating Machine Learning Models\" by Alice Zheng](https://learning.oreilly.com/library/view/evaluating-machine-learning/9781492048756/)\n1. [Agile AI. 2020. By Carlo Appugliese, Paco Nathan, William S. Roberts. O'Reilly Media, Inc.](https://learning.oreilly.com/library/view/agile-ai/9781492074984/)\n1. [\"Machine Learning Logistics\". 2017. By T. Dunning et al. O'Reilly Media Inc.](https://mapr.com/ebook/machine-learning-logistics/)\n1. [\"Machine Learning Design Patterns\" by Valliappa Lakshmanan, Sara Robinson, Michael Munn. O'Reilly 2020](https://learning.oreilly.com/library/view/machine-learning-design/9781098115777/)\n1. [\"Serving Machine Learning Models: A Guide to Architecture, Stream Processing Engines, and Frameworks\" by Boris Lublinsky, O'Reilly Media, Inc. 2017](https://www.lightbend.com/ebooks/machine-learning-guide-architecture-stream-processing-frameworks-oreilly)\n1. [\"Kubeflow for Machine Learning\" by Holden Karau, Trevor Grant, Ilan Filonenko, Richard Liu, Boris Lublinsky](https://learning.oreilly.com/library/view/kubeflow-for-machine/9781492050117/)\n1. [\"Clean Machine Learning Code\" by Moussa Taifi. Leanpub. 2020](https://leanpub.com/cleanmachinelearningcode)\n1. [E-Book \"Practical MLOps. How to Get Ready for Production Models\"](https://valohai.com/mlops-ebook/)\n1. [\"Introducing MLOps\" by Mark Treveil, et al. O'Reilly Media, Inc. 2020](https://learning.oreilly.com/library/view/introducing-mlops/9781492083283/)\n1. [\"Machine Learning for Data Streams with Practical Examples in MOA\", Bifet, Albert and Gavald\\`a, Ricard and Holmes, Geoff and Pfahringer, Bernhard, MIT Press, 2018](https://moa.cms.waikato.ac.nz/book/)\n1. [\"Machine Learning Product Manual\" by Laszlo Sragner, Chris Kelly](https://machinelearningproductmanual.com/)\n1. [\"Data Science Bootstrap Notes\" by Eric J. Ma](https://ericmjl.github.io/data-science-bootstrap-notes/)\n1. [\"Data Teams\" by Jesse Anderson, 2020](https://www.datateams.io/)\n1. [\"Data Science on AWS\" by Chris Fregly, Antje Barth, 2021](https://learning.oreilly.com/library/view/data-science-on/9781492079385/)\n1. [\u201cEngineering MLOps\u201d by Emmanuel Raj, 2021](https://www.packtpub.com/product/engineering-mlops/9781800562882)\n1. [Machine Learning Engineering in Action](https://www.manning.com/books/machine-learning-engineering-in-action)\n1. [Practical MLOps](https://learning.oreilly.com/library/view/practical-mlops/9781098103002/)\n1. [\"Effective Data Science Infrastructure\" by Ville Tuulos, 2021](https://www.manning.com/books/effective-data-science-infrastructure)\n1. [AI and Machine Learning for On-Device Development, 2021, By Laurence Moroney. O'Reilly](https://learning.oreilly.com/library/view/ai-and-machine/9781098101732/)\n1. [Designing Machine Learning Systems ,2022 by Chip Huyen , O'Reilly ](https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/)\n1. [Reliable Machine Learning. 2022. By Cathy Chen, Niall Richard Murphy, Kranti Parisa, D. Sculley, Todd Underwood. O'Reilly](https://learning.oreilly.com/library/view/reliable-machine-learning/9781098106218/)\n</details>\n\n<a name=\"mlops-articles\"></a>\n# MLOps Articles\n\n<details>\n<summary>Click to expand!</summary>\n \n1. [Continuous Delivery for Machine Learning (by Thoughtworks)](https://martinfowler.com/articles/cd4ml.html)\n1. [What is MLOps? NVIDIA Blog](https://blogs.nvidia.com/blog/2020/09/03/what-is-mlops/)\n1. [MLSpec: A project to standardize the intercomponent schemas for a multi-stage ML Pipeline.](https://github.com/visenger/MLSpec)\n1. [The 2021 State of Enterprise Machine Learning](https://info.algorithmia.com/tt-state-of-ml-2021) | State of Enterprise ML 2020: [PDF](https://info.algorithmia.com/hubfs/2019/Whitepapers/The-State-of-Enterprise-ML-2020/Algorithmia_2020_State_of_Enterprise_ML.pdf) and [Interactive](https://algorithmia.com/state-of-ml)\n1. [Organizing machine learning projects: project management guidelines.](https://www.jeremyjordan.me/ml-projects-guide/)\n1. [Rules for ML Project (Best practices)](http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf)\n1. [ML Pipeline Template](https://www.agilestacks.com/tutorials/ml-pipelines)\n1. [Data Science Project Structure](https://drivendata.github.io/cookiecutter-data-science/#directory-structure)\n1. [Reproducible ML](https://github.com/cmawer/reproducible-model)\n1. [ML project template facilitating both research and production phases.](https://github.com/visenger/ml-project-template)\n1. [Machine learning requires a fundamentally different deployment approach. As organizations embrace machine learning, the need for new deployment tools and strategies grows.](https://www.oreilly.com/radar/machine-learning-requires-a-fundamentally-different-deployment-approach/)\n1. [Introducting Flyte: A Cloud Native Machine Learning and Data Processing Platform](https://eng.lyft.com/introducing-flyte-cloud-native-machine-learning-and-data-processing-platform-fb2bb3046a59)\n1. [Why is DevOps for Machine Learning so Different?](https://hackernoon.com/why-is-devops-for-machine-learning-so-different-384z32f1)\n1. [Lessons learned turning machine learning models into real products and services \u2013 O\u2019Reilly](https://www.oreilly.com/radar/lessons-learned-turning-machine-learning-models-into-real-products-and-services/)\n1. [MLOps: Model management, deployment and monitoring with Azure Machine Learning](https://docs.microsoft.com/en-gb/azure/machine-learning/concept-model-management-and-deployment)\n1. [Guide to File Formats for Machine Learning: Columnar, Training, Inferencing, and the Feature Store](https://towardsdatascience.com/guide-to-file-formats-for-machine-learning-columnar-training-inferencing-and-the-feature-store-2e0c3d18d4f9)\n1. [Architecting a Machine Learning Pipeline How to build scalable Machine Learning systems](https://towardsdatascience.com/architecting-a-machine-learning-pipeline-a847f094d1c7)\n1. [Why Machine Learning Models Degrade In Production](https://towardsdatascience.com/why-machine-learning-models-degrade-in-production-d0f2108e9214)\n1. [Concept Drift and Model Decay in Machine Learning](http://xplordat.com/2019/04/25/concept-drift-and-model-decay-in-machine-learning/?source=post_page---------------------------)\n1. [Machine Learning in Production: Why You Should Care About Data and Concept Drift](https://towardsdatascience.com/machine-learning-in-production-why-you-should-care-about-data-and-concept-drift-d96d0bc907fb)\n1. [Bringing ML to Production](https://www.slideshare.net/mikiobraun/bringing-ml-to-production-what-is-missing-amld-2020)\n1. [A Tour of End-to-End Machine Learning Platforms](https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/)\n1. [MLOps: Continuous delivery and automation pipelines in machine learning](https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)\n1. [AI meets operations](https://www.oreilly.com/radar/ai-meets-operations/)\n1. [What would machine learning look like if you mixed in DevOps? Wonder no more, we lift the lid on MLOps](https://www.theregister.co.uk/2020/03/07/devops_machine_learning_mlops/)\n1. [Forbes: The Emergence Of ML Ops](https://www.forbes.com/sites/cognitiveworld/2020/03/08/the-emergence-of-ml-ops/#72f04ed04698)\n1. [Cognilytica Report \"ML Model Management and Operations 2020 (MLOps)\"](https://www.cognilytica.com/2020/03/03/ml-model-management-and-operations-2020-mlops/) \n1. [Introducing Cloud AI Platform Pipelines](https://cloud.google.com/blog/products/ai-machine-learning/introducing-cloud-ai-platform-pipelines)\n1. [A Guide to Production Level Deep Learning ](https://github.com/alirezadir/Production-Level-Deep-Learning/blob/master/README.md)\n1. [The 5 Components Towards Building Production-Ready Machine Learning Systems](https://medium.com/cracking-the-data-science-interview/the-5-components-towards-building-production-ready-machine-learning-system-a4d5237ec04e)\n1. [Deep Learning in Production (references about deploying deep learning-based models in production)](https://github.com/ahkarami/Deep-Learning-in-Production)\n1. [Machine Learning Experiment Tracking](https://towardsdatascience.com/machine-learning-experiment-tracking-93b796e501b0)\n1. [The Team Data Science Process (TDSP)](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview)\n1. [MLOps Solutions (Azure based)](https://github.com/visenger/MLOps)\n1. [Monitoring ML pipelines](https://intothedepthsofdataengineering.wordpress.com/2020/02/13/monitoring-ml-pipelines/)\n1. [Deployment & Explainability of Machine Learning COVID-19 Solutions at Scale with Seldon Core and Alibi](https://github.com/axsaucedo/seldon-core/tree/corona_research_exploration/examples/models/research_paper_classification)\n1. [Demystifying AI Infrastructure](https://www.intel.com/content/www/us/en/intel-capital/news/story.html?id=a0F1I00000BNTXPUA5#/type=All/page=0/term=/tags=)\n1. [Organizing machine learning projects: project management guidelines.](https://www.jeremyjordan.me/ml-projects-guide/)\n1. [The Checklist for Machine Learning Projects (from Aur\u00e9lien G\u00e9ron,\"Hands-On Machine Learning with Scikit-Learn and TensorFlow\")](https://github.com/visenger/handson-ml/blob/master/ml-project-checklist.md)\n1. [Data Project Checklist by Jeremy Howard](https://www.fast.ai/2020/01/07/data-questionnaire/)\n1. [MLOps: not as Boring as it Sounds](https://itnext.io/mlops-not-as-boring-as-it-sounds-eaebe73e3533)\n1. [10 Steps to Making Machine Learning Operational. Cloudera White Paper](https://www.cloudera.com/content/dam/www/marketing/resources/whitepapers/10-steps-to-making-ml-operational.pdf)\n1. [MLOps is Not Enough. The Need for an End-to-End Data Science Lifecycle Process.](https://techcommunity.microsoft.com/t5/azure-ai/mlops-is-not-enough/ba-p/1386789)\n1. [Data Science Lifecycle Repository Template](https://github.com/dslp/dslp-repo-template)\n1. [Template: code and pipeline definition for a machine learning project demonstrating how to automate an end to end ML/AI workflow. ](https://github.com/aronchick/MLOps-pipeline)\n1. [Nitpicking Machine Learning Technical Debt](https://matthewmcateer.me/blog/machine-learning-technical-debt/)\n1. [The Best Tools, Libraries, Frameworks and Methodologies that Machine Learning Teams Actually Use \u2013 Things We Learned from 41 ML Startups](https://neptune.ai/blog/tools-libraries-frameworks-methodologies-ml-startups-roundup)\n1. [Software Engineering for AI/ML - An Annotated Bibliography](https://github.com/ckaestne/seaibib)\n1. [Intelligent System. Machine Learning in Practice](https://intelligentsystem.io/)\n1. [CMU 17-445/645: Software Engineering for AI-Enabled Systems (SE4AI)](https://github.com/ckaestne/seai/)\n1. [Machine Learning is Requirements Engineering](https://link.medium.com/l7akzjR826)\n1. [Machine Learning Reproducibility Checklist](https://www.cs.mcgill.ca/~jpineau/ReproducibilityChecklist.pdf)\n1. [Machine Learning Ops. A collection of resources on how to facilitate Machine Learning Ops with GitHub.](http://mlops-github.com/)\n1. [Task Cheatsheet for Almost Every Machine Learning Project A checklist of tasks for building End-to-End ML projects](https://towardsdatascience.com/task-cheatsheet-for-almost-every-machine-learning-project-d0946861c6d0)\n1. [Web services vs. streaming for real-time machine learning endpoints](https://towardsdatascience.com/web-services-vs-streaming-for-real-time-machine-learning-endpoints-c08054e2b18e)\n1. [How PyTorch Lightning became the first ML framework to run continuous integration on TPUs](https://medium.com/pytorch/how-pytorch-lightning-became-the-first-ml-framework-to-runs-continuous-integration-on-tpus-a47a882b2c95)\n1. [The ultimate guide to building maintainable Machine Learning pipelines using DVC](https://towardsdatascience.com/the-ultimate-guide-to-building-maintainable-machine-learning-pipelines-using-dvc-a976907b2a1b)\n1. [Continuous Machine Learning (CML) is CI/CD for Machine Learning Projects (DVC)](https://cml.dev/)\n1. [What I learned from looking at 200 machine learning tools](https://huyenchip.com/2020/06/22/mlops.html) | Update: [MLOps Tooling Landscape v2 (+84 new tools) - Dec '20](https://docs.google.com/spreadsheets/d/10pPQYmyNnYb6zshOKxBjJ704E0XUj2vJ9HCDfoZxAoA/edit#gid=1651929178)\n1. [Big Data & AI Landscape](http://mattturck.com/wp-content/uploads/2018/07/Matt_Turck_FirstMark_Big_Data_Landscape_2018_Final.png)\n1. [Deploying Machine Learning Models as Data, not Code \u2014 A better match?](https://towardsdatascience.com/deploying-machine-learning-models-as-data-not-code-omega-ml-8825a0ae530a)\n1. [\u201cThou shalt always scale\u201d \u2014 10 commandments of MLOps](https://towardsdatascience.com/mlops-thou-shalt-always-scale-10-commandments-of-mlops-152c11e711a5)\n1. [Three Risks in Building Machine Learning Systems](https://insights.sei.cmu.edu/sei_blog/2020/05/three-risks-in-building-machine-learning-systems.html)\n1. [Blog about ML in production (by maiot.io)](https://blog.maiot.io/)\n1. Back to the Machine Learning fundamentals: How to write code for Model deployment. [Part 1](https://medium.com/@ivannardini/back-to-the-machine-learning-fundamentals-how-to-write-code-for-model-deployment-part-1-3-4b05deda1cd1), [Part 2](https://medium.com/@ivannardini/back-to-the-machine-learning-fundamentals-how-to-write-code-for-model-deployment-part-2-3-9632d5a43f98), [Part 3](https://medium.com/@ivannardini/back-to-the-machine-learning-fundamentals-how-to-write-code-for-model-deployment-part-3-3-fb85102bebb2)\n1. [MLOps: Machine Learning as an Engineering Discipline](https://towardsdatascience.com/ml-ops-machine-learning-as-an-engineering-discipline-b86ca4874a3f)\n1. [ML Engineering on Google Cloud Platform (hands-on labs and code samples)](https://github.com/GoogleCloudPlatform/mlops-on-gcp)\n1. [Deep Reinforcement Learning in Production. The use of Reinforcement Learning to Personalize User Experience at Zynga](https://towardsdatascience.com/deep-reinforcement-learning-in-production-7e1e63471e2)\n1. [What is Data Observability?](https://towardsdatascience.com/what-is-data-observability-40b337971e3e)\n1. [A Practical Guide to Maintaining Machine Learning in Production](https://eugeneyan.com/writing/practical-guide-to-maintaining-machine-learning/)\n1. Continuous Machine Learning. [Part 1](https://mribeirodantas.xyz/blog/index.php/2020/08/10/continuous-machine-learning/), [Part 2](https://mribeirodantas.xyz/blog/index.php/2020/08/18/continuous-machine-learning-part-ii/). Part 3 is coming soon.\n1. [The Agile approach in data science explained by an ML expert](https://www.iunera.com/kraken/big-data-science-strategy/the-agile-approach-in-data-science-explained-by-an-ml-expert/)\n1. [Here is what you need to look for in a model server to build ML-powered services](https://anyscale.com/blog/heres-what-you-need-to-look-for-in-a-model-server-to-build-ml-powered-services/)\n1. [The problem with AI developer tools for enterprises (and what IKEA has to do with it)](https://towardsdatascience.com/the-problem-with-ai-developer-tools-for-enterprises-and-what-ikea-has-to-do-with-it-b26277841661)\n1. [Streaming Machine Learning with Tiered Storage](https://www.confluent.io/blog/streaming-machine-learning-with-tiered-storage/)\n1. [Best practices for performance and cost optimization for machine learning (Google Cloud)](https://cloud.google.com/solutions/machine-learning/best-practices-for-ml-performance-cost)\n1. [Lean Data and Machine Learning Operations](https://databaseline.tech/lean-dml-operations/)\n1. [A Brief Guide to Running ML Systems in Production Best Practices for Site Reliability Engineers](https://www.oreilly.com/content/a-brief-guide-to-running-ml-systems-in-production/)\n1. [AI engineering practices in the wild - SIG | Getting software right for a healthier digital world](https://www.softwareimprovementgroup.com/resources/ai-engineering-practices-in-the-wild/)\n1. [SE-ML | The 2020 State of Engineering Practices for Machine Learning](https://se-ml.github.io/report2020)\n1. [Awesome Software Engineering for Machine Learning (GitHub repository)](https://github.com/SE-ML/awesome-seml)\n1. [Sampling isn\u2019t enough, profile your ML data instead](https://towardsdatascience.com/sampling-isnt-enough-profile-your-ml-data-instead-6a28fcfb2bd4?source=friends_link&sk=5af46143562d348b182c449265ed54fb)\n1. [Reproducibility in ML: why it matters and how to achieve it](https://determined.ai/blog/reproducibility-in-ml/)\n1. [12 Factors of reproducible Machine Learning in production](https://blog.maiot.io/12-factors-of-ml-in-production/)\n1. [MLOps: More Than Automation](https://devops.com/mlop-more-than-automation/)\n1. [Lean Data Science](https://locallyoptimistic.com/post/lean-data-science/)\n1. [Engineering Skills for Data Scientists](https://mark.douthwaite.io/tag/engineering-skills-for-data-scientists/)\n1. [DAGsHub Blog. Read about data science and machine learning workflows, MLOps, and open source data science](https://dagshub.com/blog/)\n1. [Data Science Project Flow for Startups](https://towardsdatascience.com/data-science-project-flow-for-startups-282a93d4508d)\n1. [Data Science Engineering at Shopify](https://shopify.engineering/topics/data-science-engineering)\n1. [Building state-of-the-art machine learning technology with efficient execution for the crypto economy](https://blog.coinbase.com/building-state-of-the-art-machine-learning-technology-with-efficient-execution-for-the-crypto-ad10896a48a)\n1. [Completing the Machine Learning Loop](https://jimmymwhitaker.medium.com/completing-the-machine-learning-loop-e03c784eaab4)\n1. [Deploying Machine Learning Models: A Checklist](https://twolodzko.github.io/ml-checklist) \n1. [Global MLOps and ML tools landscape (by MLReef)](https://about.mlreef.com/blog/global-mlops-and-ml-tools-landscape)\n1. [Why all Data Science teams need to get serious about MLOps](https://towardsdatascience.com/why-data-science-teams-needs-to-get-serious-about-mlops-56c98e255e20)  \n1. [MLOps Values (by Bart Grasza)](https://gist.github.com/bartgras/4ab9c716167b5d9aee6a222f7301ac60)\n1. [Machine Learning Systems Design (by Chip Huyen)](https://huyenchip.com/machine-learning-systems-design/toc.html)\n1. [Designing an ML system (Stanford | CS 329 | Chip Huyen)](https://docs.google.com/presentation/d/13a5B2HeK9Id59zy3oNJDv5_ksDvzbGmNLx4zumkimZM/edit?usp=sharing)\n1. [How COVID-19 Has Infected AI Models (about the data drift or model drift concept)](https://www.dominodatalab.com/blog/how-covid-19-has-infected-ai-models/)\n1. [Microkernel Architecture for Machine Learning Library. An Example of Microkernel Architecture with Python Metaclass](https://towardsdatascience.com/microkernel-architecture-for-machine-learning-library-c04b797e0d5f)\n1. [Machine Learning in production: the Booking.com approach](https://booking.ai/https-booking-ai-machine-learning-production-3ee8fe943c70)\n1. [What I Learned From Attending TWIMLcon 2021 (by James Le)](https://jameskle.com/writes/twiml2021)\n1. [Designing ML Orchestration Systems for Startups. A case study in building a lightweight production-grade ML orchestration system](https://towardsdatascience.com/designing-ml-orchestration-systems-for-startups-202e527d7897)\n1. [Towards MLOps: Technical capabilities of a Machine Learning platform | Prosus AI Tech Blog](https://medium.com/prosus-ai-tech-blog/towards-mlops-technical-capabilities-of-a-machine-learning-platform-61f504e3e281)\n1. [Get started with MLOps A comprehensive MLOps tutorial with open source tools](https://towardsdatascience.com/get-started-with-mlops-fd7062cab018)\n1. [From DevOps to MLOPS: Integrate Machine Learning Models using Jenkins and Docker](https://towardsdatascience.com/from-devops-to-mlops-integrate-machine-learning-models-using-jenkins-and-docker-79034dbedf1)\n1. [Example code for a basic ML Platform based on Pulumi, FastAPI, DVC, MLFlow and more](https://github.com/aporia-ai/mlplatform-workshop)\n1. [Software Engineering for Machine Learning: Characterizing and Detecting Mismatch in Machine-Learning Systems](https://insights.sei.cmu.edu/blog/software-engineering-for-machine-learning-characterizing-and-detecting-mismatch-in-machine-learning-systems/)\n1. [TWIML Solutions Guide](https://twimlai.com/solutions/introducing-twiml-ml-ai-solutions-guide/)\n1. [How Well Do You Leverage Machine Learning at Scale? Six Questions to Ask](https://medium.com/cognizantai/how-well-do-you-leverage-machine-learning-at-scale-six-questions-to-ask-7e6acda15ea5)\n1. [Getting started with MLOps: Selecting the right capabilities for your use case](https://cloud.google.com/blog/products/ai-machine-learning/select-the-right-mlops-capabilities-for-your-ml-use-case)\n1. [The Latest Work from the SEI: Artificial Intelligence, DevSecOps, and Security Incident Response](https://insights.sei.cmu.edu/blog/the-latest-work-from-the-sei-artificial-intelligence-devsecops-and-security-incident-response/)\n1. [MLOps: The Ultimate Guide. A handbook on MLOps and how to think about it](https://towardsdatascience.com/mlops-the-ultimate-guide-9d902c752fd1)\n1. [Enterprise Readiness of Cloud MLOps](https://gigaom.com/report/enterprise-readiness-of-cloud-mlops/)\n1. [Should I Train a Model for Each Customer or Use One Model for All of My Customers?](https://towardsdatascience.com/should-i-train-a-model-for-each-customer-or-use-one-model-for-all-of-my-customers-f9e8734d991)\n1. [MLOps-Basics (GitHub repo)](https://github.com/graviraja/MLOps-Basics) by [raviraja](https://github.com/graviraja)\n1. [Another tool won\u2019t fix your MLOps problems](https://dshersh.medium.com/too-many-mlops-tools-c590430ba81b)\n1. [Best MLOps Tools: What to Look for and How to Evaluate Them](https://nimblebox.ai/blog/mlops-tools)\n1. [MLOps vs. DevOps: A Detailed Comparison](https://nimblebox.ai/blog/mlops-vs-devops)\n1. [A Guide To Setting Up Your MLOps Team](https://nimblebox.ai/blog/mlops-team-structure)\n</details>\n\n\n\n<a name=\"wfl-management\"></a>\n# MLOps: Workflow Management\n\n1. [Open-source Workflow Management Tools: A Survey by Ploomber](https://ploomber.io/posts/survey/)\n1. [How to Compare ML Experiment Tracking Tools to Fit Your Data Science Workflow (by dagshub)](https://dagshub.com/blog/how-to-compare-ml-experiment-tracking-tools-to-fit-your-data-science-workflow/)\n1. [15 Best Tools for Tracking Machine Learning Experiments](https://medium.com/neptune-ai/15-best-tools-for-tracking-machine-learning-experiments-64c6eff16808)\n\n<a name=\"feature-stores\"></a>\n# MLOps: Feature Stores\n\n<details>\n<summary>Click to expand!</summary>\n \n1. [Feature Stores for Machine Learning Medium Blog](https://medium.com/data-for-ai)\n1. [MLOps with a Feature Store](https://www.logicalclocks.com/blog/mlops-with-a-feature-store)\n1. [Feature Stores for ML](http://featurestore.org/)\n1. [Hopsworks: Data-Intensive AI with a Feature Store](https://github.com/logicalclocks/hopsworks)\n1. [Feast: An open-source Feature Store for Machine Learning](https://github.com/feast-dev/feast)\n1. [What is a Feature Store?](https://www.tecton.ai/blog/what-is-a-feature-store/)\n1. [ML Feature Stores: A Casual Tour](https://medium.com/@farmi/ml-feature-stores-a-casual-tour-fc45a25b446a)\n1. [Comprehensive List of Feature Store Architectures for Data Scientists and Big Data Professionals](https://hackernoon.com/the-essential-architectures-for-every-data-scientist-and-big-data-engineer-f21u3e5c)\n1. [ML Engineer Guide: Feature Store vs Data Warehouse (vendor blog)](https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse)\n1. [Building a Gigascale ML Feature Store with Redis, Binary Serialization, String Hashing, and Compression (DoorDash blog)](https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/)\n1. [Feature Stores: Variety of benefits for Enterprise AI.](https://insidebigdata.com/2020/12/29/how-feature-stores-will-revolutionize-enterprise-ai/)\n1. [Feature Store as a Foundation for Machine Learning](https://towardsdatascience.com/feature-store-as-a-foundation-for-machine-learning-d010fc6eb2f3)\n1. [ML Feature Serving Infrastructure at Lyft](https://eng.lyft.com/ml-feature-serving-infrastructure-at-lyft-d30bf2d3c32a)\n1. [Feature Stores for Self-Service Machine Learning](https://www.ethanrosenthal.com/2021/02/03/feature-stores-self-service/)\n1. [The Architecture Used at LinkedIn to Improve Feature Management in Machine Learning Models.](https://jrodthoughts.medium.com/the-architecture-used-at-linkedin-to-improve-feature-management-in-machine-learning-models-c7bd6ae54db)\n1. [Is There a Feature Store Over the Rainbow? How to select the right feature store for your use case](https://towardsdatascience.com/is-there-a-feature-store-over-the-rainbow-291cab94e8a5)\n</details>\n \n<a name=\"dataops\"></a>\n# MLOps: Data Engineering (DataOps)\n\n<details>\n<summary>Click to expand!</summary>\n \n1. [The state of data quality in 2020 \u2013 O\u2019Reilly](https://www.oreilly.com/radar/the-state-of-data-quality-in-2020/)\n1. [Why We Need DevOps for ML Data](https://tecton.ai/blog/devops-ml-data/) \n1. [Data Preparation for Machine Learning (7-Day Mini-Course)](https://machinelearningmastery.com/data-preparation-for-machine-learning-7-day-mini-course/)\n1. [Best practices in data cleaning: A Complete Guide to Everything You Need to Do Before and After Collecting Your Data.](https://www.researchgate.net/publication/266714997_Best_practices_in_data_cleaning_A_Complete_Guide_to_Everything_You_Need_to_Do_Before_and_After_Collecting_Your_Data)\n1. [17 Strategies for Dealing with Data, Big Data, and Even Bigger Data](https://towardsdatascience.com/17-strategies-for-dealing-with-data-big-data-and-even-bigger-data-283426c7d260)\n1. [DataOps Data Architecture](https://blog.datakitchen.io/blog/dataops-data-architecture)\n1. [Data Orchestration \u2014 A Primer](https://medium.com/memory-leak/data-orchestration-a-primer-56f3ddbb1700)\n1. [4 Data Trends to Watch in 2020](https://medium.com/memory-leak/4-data-trends-to-watch-in-2020-491707902c09)\n1. [CSE 291D / 234: Data Systems for Machine Learning](http://cseweb.ucsd.edu/classes/fa20/cse291-d/index.html)\n1. [A complete picture of the modern data engineering landscape](https://github.com/datastacktv/data-engineer-roadmap)\n1. [Continuous Integration for your data with GitHub Actions and Great Expectations. One step closer to CI/CD for your data pipelines](https://greatexpectations.io/blog/github-actions/)\n1. [Emerging Architectures for Modern Data Infrastructure](https://a16z.com/2020/10/15/the-emerging-architectures-for-modern-data-infrastructure/)\n1. [Awesome Data Engineering. Learning path and resources to become a data engineer](https://awesomedataengineering.com/)\n1. Data Quality at Airbnb [Part 1](https://medium.com/airbnb-engineering/data-quality-at-airbnb-e582465f3ef7) | [Part 2](https://medium.com/airbnb-engineering/data-quality-at-airbnb-870d03080469)\n1. [DataHub: Popular metadata architectures explained](https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained)\n1. [Financial Times Data Platform: From zero to hero. An in-depth walkthrough of the evolution of our Data Platform](https://medium.com/ft-product-technology/financial-times-data-platform-from-zero-to-hero-143156bffb1d)\n1. [Alki, or how we learned to stop worrying and love cold metadata (Dropbox)](https://dropbox.tech/infrastructure/alki--or-how-we-learned-to-stop-worrying-and-love-cold-metadata)\n1. [A Beginner's Guide to Clean Data. Practical advice to spot and avoid data quality problems (by Benjamin Greve)](https://b-greve.gitbook.io/beginners-guide-to-clean-data/)\n1. [ML Lake: Building Salesforce\u2019s Data Platform for Machine Learning](https://engineering.salesforce.com/ml-lake-building-salesforces-data-platform-for-machine-learning-228c30e21f16)\n1. [Data Catalog 3.0: Modern Metadata for the Modern Data Stack](https://towardsdatascience.com/data-catalog-3-0-modern-metadata-for-the-modern-data-stack-ec621f593dcf)\n1. [Metadata Management Systems](https://gradientflow.com/the-growing-importance-of-metadata-management-systems/)\n1. [Essential resources for data engineers (a curated recommended read and watch list for scalable data processing)](https://www.scling.com/reading-list/)\n1. [Comprehensive and Comprehensible Data Catalogs: The What, Who, Where, When, Why, and How of Metadata Management (Paper)](https://arxiv.org/pdf/2103.07532.pdf)\n1. [What I Learned From Attending DataOps Unleashed 2021 (byJames Le)](https://jameskle.com/writes/dataops-unleashed2021)\n1. [Uber's Journey Toward Better Data Culture From First Principles](https://ubr.to/3lo9GU8)\n1. [Cerberus - lightweight and extensible data validation library for Python](https://docs.python-cerberus.org/en/stable/)\n1. [Design a data mesh architecture using AWS Lake Formation and AWS Glue. AWS Big Data Blog](https://aws.amazon.com/blogs/big-data/design-a-data-mesh-architecture-using-aws-lake-formation-and-aws-glue/)\n1. [Data Management Challenges in Production Machine Learning (slides)](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46178.pdf)\n1. [The Missing Piece of Data Discovery and Observability Platforms: Open Standard for Metadata](https://towardsdatascience.com/the-missing-piece-of-data-discovery-and-observability-platforms-open-standard-for-metadata-37dac2d0503)\n1. [Automating Data Protection at Scale](https://medium.com/airbnb-engineering/automating-data-protection-at-scale-part-1-c74909328e08)\n1. [A curated list of awesome pipeline toolkits](https://github.com/pditommaso/awesome-pipeline)\n1. [Data Mesh Archtitecture](https://www.datamesh-architecture.com/)\n1. [The Essential Guide to Data Exploration in Machine Learning](https://nimblebox.ai/blog/data-exploration)\n</details>\n\n\n\n<a name=\"deployment\"></a> \n# MLOps: Model Deployment and Serving\n<details>\n<summary>Click to expand!</summary>\n \n1. [AI Infrastructure for Everyone: DeterminedAI](https://determined.ai/)\n1. [Deploying R Models with MLflow and Docker](https://mdneuzerling.com/post/deploying-r-models-with-mlflow-and-docker/)\n1. [What Does it Mean to Deploy a Machine Learning Model?](https://mlinproduction.com/what-does-it-mean-to-deploy-a-machine-learning-model-deployment-series-01/)\n1. [Software Interfaces for Machine Learning Deployment](https://mlinproduction.com/software-interfaces-for-machine-learning-deployment-deployment-series-02/)\n1. [Batch Inference for Machine Learning Deployment](https://mlinproduction.com/batch-inference-for-machine-learning-deployment-deployment-series-03/)\n1. [AWS Cost Optimization for ML Infrastructure - EC2 spend](https://blog.floydhub.com/aws-cost-optimization-for-ml-infra-ec2/)\n1. [CI/CD for Machine Learning & AI](https://blog.paperspace.com/ci-cd-for-machine-learning-ai/)\n1. [Ita\u00fa Unibanco: How we built a CI/CD Pipeline for machine learning with ***online training*** in Kubeflow](https://cloud.google.com/blog/products/ai-machine-learning/itau-unibanco-how-we-built-a-cicd-pipeline-for-machine-learning-with-online-training-in-kubeflow)\n1. [101 For Serving ML Models](https://pakodas.substack.com/p/101-for-serving-ml-models-10217c9f0764)\n1. [Deploying Machine Learning models to production \u2014 **Inference service architecture patterns**](https://medium.com/data-for-ai/deploying-machine-learning-models-to-production-inference-service-architecture-patterns-bc8051f70080)\n1. [Serverless ML: Deploying Lightweight Models at Scale](https://mark.douthwaite.io/serverless-machine-learning/)\n1. ML Model Rollout To Production. [Part 1](https://www.superwise.ai/resources-old/safely-rolling-out-ml-models-to-production) | [Part 2](https://www.superwise.ai/blog/part-ii-safely-rolling-out-models-to-production)\n1. [Deploying Python ML Models with Flask, Docker and Kubernetes](https://alexioannides.com/2019/01/10/deploying-python-ml-models-with-flask-docker-and-kubernetes/)\n1. [Deploying Python ML Models with Bodywork](https://alexioannides.com/2020/12/01/deploying-python-ml-models-with-bodywork/)\n1. [Framework for a successful Continuous Training Strategy. When should the model be retrained? What data should be used? What should be retrained? A data-driven approach](https://towardsdatascience.com/framework-for-a-successful-continuous-training-strategy-8c83d17bb9dc)\n1. [Efficient Machine Learning Inference. The benefits of multi-model serving where latency matters](https://www.oreilly.com/content/efficient-machine-learning-inference/)\n</details>\n\n \n<a name=\"testing-monintoring\"></a> \n# MLOps: Testing, Monitoring and Maintenance\n<details>\n<summary>Click to expand!</summary>\n \n1. [Building dashboards for operational visibility (AWS)](https://aws.amazon.com/builders-library/building-dashboards-for-operational-visibility/)\n1. [Monitoring Machine Learning Models in Production](https://christophergs.com/machine%20learning/2020/03/14/how-to-monitor-machine-learning-models/)\n1. [Effective testing for machine learning systems](https://www.jeremyjordan.me/testing-ml/)\n1. [Unit Testing Data: What is it and how do you do it?](https://winderresearch.com/unit-testing-data-what-is-it-and-how-do-you-do-it/)\n1. [How to Test Machine Learning Code and Systems](https://eugeneyan.com/writing/testing-ml/) ([Accompanying code](https://github.com/eugeneyan/testing-ml))\n1. [Wu, T., Dong, Y., Dong, Z., Singa, A., Chen, X. and Zhang, Y., 2020. Testing Artificial Intelligence System Towards Safety and Robustness: State of the Art. IAENG International Journal of Computer Science, 47(3).](http://www.iaeng.org/IJCS/issues_v47/issue_3/IJCS_47_3_13.pdf)\n1. [Multi-Armed Bandits and the Stitch Fix Experimentation Platform](https://multithreaded.stitchfix.com/blog/2020/08/05/bandits/)\n1. [A/B Testing Machine Learning Models](https://mlinproduction.com/ab-test-ml-models-deployment-series-08/)\n1. [Data validation for machine learning. Polyzotis, N., Zinkevich, M., Roy, S., Breck, E. and Whang, S., 2019. Proceedings of Machine Learning and Systems](https://mlsys.org/Conferences/2019/doc/2019/167.pdf)\n1. [Testing machine learning based systems: a systematic mapping](https://link.springer.com/content/pdf/10.1007/s10664-020-09881-0.pdf)\n1. [Explainable Monitoring: Stop flying blind and monitor your AI](https://blog.fiddler.ai/2020/04/explainable-monitoring-stop-flying-blind-and-monitor-your-ai/)\n1. [WhyLogs: Embrace Data Logging Across Your ML Systems](https://medium.com/whylabs/whylogs-embrace-data-logging-a9449cd121d)\n1. [Evidently AI. Insights on doing machine learning in production. (Vendor blog.)](https://evidentlyai.com/blog)\n1. [The definitive guide to comprehensively monitoring your AI](https://www.monalabs.io/mona-blog/definitiveguidetomonitorai)\n1. [Introduction to Unit Testing for Machine Learning](https://themlrebellion.com/blog/Introduction-To-Unit-Testing-Machine-Learning/)\n1. [Production Machine Learning Monitoring: Outliers, Drift, Explainers & Statistical Performance](https://towardsdatascience.com/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158)\n1. Test-Driven Development in MLOps [Part 1](https://medium.com/mlops-community/test-driven-development-in-mlops-part-1-8894575f4dec)\n1. [Domain-Specific Machine Learning Monitoring](https://medium.com/mlops-community/domain-specific-machine-learning-monitoring-88bc0dd8a212)\n1. [Introducing ML Model Performance Management (Blog by fiddler)](https://blog.fiddler.ai/2021/03/introducing-ml-model-performance-management/)\n1. [What is ML Observability? (Arize AI)](https://arize.com/what-is-ml-observability/)\n1. [Beyond Monitoring: The Rise of Observability (Arize AI & Monte Carlo Data)](https://arize.com/beyond-monitoring-the-rise-of-observability/)\n1. [Model Failure Modes (Arize AI)](https://arize.com/ml-model-failure-modes/)\n1. [Quick Start to Data Quality Monitoring for ML (Arize AI)](https://arize.com/data-quality-monitoring/)\n1. [Playbook to Monitoring Model Performance in Production (Arize AI)](https://arize.com/monitor-your-model-in-production/)\n1. [Robust ML by Property Based Domain Coverage Testing (Blog by Efemarai)](https://towardsdatascience.com/why-dont-we-test-machine-learning-as-we-test-software-43f5720903d)\n1. [Monitoring and explainability of models in production](https://arxiv.org/pdf/2007.06299.pdf)\n1. [Beyond Monitoring: The Rise of Observability](https://aparnadhinak.medium.com/beyond-monitoring-the-rise-of-observability-c53bdc1d2e0b)\n1. [ML Model Monitoring \u2013 9 Tips From the Trenches. (by NU bank)](https://building.nubank.com.br/ml-model-monitoring-9-tips-from-the-trenches/)\n1. [Model health assurance at LinkedIn. By LinkedIn Engineering](https://engineering.linkedin.com/blog/2021/model-health-assurance-at-linkedin)\n1. [How to Trust Your Deep Learning Code](https://krokotsch.eu/cleancode/2020/08/11/Unit-Tests-for-Deep-Learning.html) ([Accompanying code](https://github.com/tilman151/unittest_dl))\n1. [Estimating Performance of Regression Models Without Ground-Truth](https://bit.ly/medium-estimating-performance-regression) (Using [NannyML](https://bit.ly/ml-ops-nannyml))\n1. [How Hyperparameter Tuning in Machine Learning Works](https://nimblebox.ai/blog/hyperparameter-tuning-machine-learning)\n</details>\n\n<a name=\"mlops-infra\"></a>\n# MLOps: Infrastructure & Tooling\n<details>\n<summary>Click to expand!</summary>\n \n1. [MLOps Infrastructure Stack Canvas](https://miro.com/app/board/o9J_lfoc4Hg=/)\n1. [Rise of the Canonical Stack in Machine Learning. How a Dominant New Software Stack Will Unlock the Next Generation of Cutting Edge AI Apps](https://towardsdatascience.com/rise-of-the-canonical-stack-in-machine-learning-724e7d2faa75)\n1. [AI Infrastructure Alliance. Building the canonical stack for AI/ML](https://ai-infrastructure.org/)\n1. [Linux Foundation AI Foundation](https://wiki.lfai.foundation/)\n1. ML Infrastructure Tools for Production | [Part 1 \u2014 Production ML \u2014 The Final Stage of the Model Workflow](https://towardsdatascience.com/ml-infrastructure-tools-for-production-1b1871eecafb) | [Part 2 \u2014 Model Deployment and Serving](https://towardsdatascience.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving-fcfc75c4a362)\n1. [The MLOps Stack Template (by valohai)](https://valohai.com/blog/the-mlops-stack/)\n1. [Navigating the MLOps tooling landscape](https://ljvmiranda921.github.io/notebook/2021/05/10/navigating-the-mlops-landscape/)\n1. [MLOps.toys curated list of MLOps projects (by Aporia)](https://mlops.toys/)\n1. [Comparing Cloud MLOps platforms, From a former AWS SageMaker PM](https://towardsdatascience.com/comparing-cloud-mlops-platform-from-a-former-aws-sagemaker-pm-115ced28239b)\n1. [Machine Learning Ecosystem 101 (whitepaper by Arize AI)](https://arize.com/wp-content/uploads/2021/04/Arize-AI-Ecosystem-White-Paper.pdf)\n1. [Selecting your optimal MLOps stack: advantages and challenges. By Intellerts](https://intellerts.com/selecting-your-optimal-mlops-stack-advantages-and-challenges/)\n1. [Infrastructure Design for Real-time Machine Learning Inference. The Databricks Blog](https://databricks.com/blog/2021/09/01/infrastructure-design-for-real-time-machine-learning-inference.html)\n1. [The 2021 State of AI Infrastructure Survey](https://pages.run.ai/hubfs/PDFs/2021-State-of-AI-Infrastructure-Survey.pdf)\n1. [AI infrastructure Maturity matrix](https://pages.run.ai/hubfs/PDFs/AI-Infrastructure-Maturity-Benchmarking-Model.pdf)\n1. [A Curated Collection of the Best Open-source MLOps Tools. By Censius](https://censius.ai/mlops-tools)\n1. [Best MLOps Tools to Manage the ML Lifecycle](https://nimblebox.ai/blog/mlops-tools)\n</details>\n\n\n<a name=\"mlops-papers\"></a>\n# MLOps Papers\n\nA list of scientific and industrial papers and resources about Machine Learning operalization since 2015. [See more.](papers.md)\n\n\n<a name=\"talks-about-mlops\"></a>\n# Talks About MLOps\n<details>\n<summary>Click to expand!</summary>\n \n1. [\"MLOps: Automated Machine Learning\" by Emmanuel Raj](https://www.youtube.com/watch?v=m32k9jcY4pY)\n1. [DeliveryConf 2020. \"Continuous Delivery For Machine Learning: Patterns And Pains\" by Emily Gorcenski](https://youtu.be/bFW5mZmj0nQ)\n1. [MLOps Conference: Talks from 2019](https://www.mlopsconf.com?wix-vod-comp-id=comp-k1ry4afh)\n1. [Kubecon 2019: Flyte: Cloud Native Machine Learning and Data Processing Platform](https://www.youtube.com/watch?v=KdUJGSP1h9U)\n1. [Kubecon 2019: Running LargeScale Stateful workloads on Kubernetes at Lyft](https://www.youtube.com/watch?v=ECeVQoble0g)\n1. [A CI/CD Framework for Production Machine Learning at Massive Scale (using Jenkins X and Seldon Core)](https://youtu.be/68_Phxwaj-k)\n1. [MLOps Virtual Event (Databricks)](https://youtu.be/9Ehh7Vl7ByM)\n1. [MLOps NY conference 2019](https://www.iguazio.com/mlops-nyc-sessions/)\n1. [MLOps.community YouTube Channel](https://www.youtube.com/channel/UCG6qpjVnBTTT8wLGBygANOQ)\n1. [MLinProduction YouTube Channel](https://www.youtube.com/channel/UC3B_Z9FTeu4i8xtxDjGaZxw)\n1. [Introducing MLflow for End-to-End Machine Learning on Databricks. Spark+AI Summit 2020. Sean Owen](https://youtu.be/nx3yFzx_nHI)\n1. [MLOps Tutorial #1: Intro to Continuous Integration for ML](https://youtu.be/9BgIDqAzfuA)\n1. [Machine Learning At Speed: Operationalizing ML For Real-Time Data Streams (2019)](https://youtu.be/46l_C7ibpuo)\n1. [Damian Brady - The emerging field of MLops](https://humansofai.podbean.com/e/damian-brady-the-emerging-field-of-mlops/)\n1. [MLOps - Entwurf, Entwicklung, Betrieb (INNOQ Podcast in German)](https://www.innoq.com/en/podcast/076-mlops/)\n1. [Instrumentation, Observability & Monitoring of Machine Learning Models](https://www.infoq.com/presentations/instrumentation-observability-monitoring-ml/)\n1. [Efficient ML engineering: Tools and best practices](https://learning.oreilly.com/videos/oreilly-strata-data/9781492050681/9781492050681-video327465?autoplay=false)\n1. [Beyond the jupyter notebook: how to build data science products](https://towardsdatascience.com/beyond-the-jupyter-notebook-how-to-build-data-science-products-50d942fc25d8)\n1. [An introduction to MLOps on Google Cloud](https://www.youtube.com/watch?v=6gdrwFMaEZ0#action=share) (First 19 min are vendor-, language-, and framework-agnostic. @visenger)\n1. [How ML Breaks: A Decade of Outages for One Large ML Pipeline](https://youtu.be/hBMHohkRgAA)\n1. [Clean Machine Learning Code: Practical Software Engineering](https://youtu.be/PEjTAJHxYPM)\n1. [Machine Learning Engineering: 10 Fundamentale Praktiken](https://www.youtube.com/watch?v=VYlXNWxqJ2A)\n1. [Architecture of machine learning systems (3-part series)](https://www.youtube.com/playlist?list=PLx8omXiw3n9y26FKZLV5ScyS52D_c29QN)\n1. [Machine Learning Design Patterns](https://youtu.be/udXjlvCFusc)\n1. [The laylist that covers techniques and approaches for model deployment on to production](https://youtube.com/playlist?list=PL3N9eeOlCrP5PlN1jwOB3jVZE6nYTVswk)\n1. [ML Observability: A Critical Piece in Ensuring Responsible AI (Arize AI at Re-Work)](https://www.youtube.com/watch?v=2FE1sg749V[o)\n1. [ML Engineering vs. Data Science (Arize AI Un/Summit)](https://www.youtube.com/watch?v=lP_4lT2k7Kg&t=2s)\n1. [SRE for ML: The First 10 Years and the Next 10 ](https://www.usenix.org/conference/srecon21/presentation/underwood-sre-ml)\n1. [Demystifying Machine Learning in Production: Reasoning about a Large-Scale ML Platform](https://www.usenix.org/conference/srecon21/presentation/mcglohon)\n1. [Apply Conf 2022](https://www.applyconf.com/apply-conf-may-2022/)\n1. [Databricks' Data + AI Summit 2022](https://databricks.com/dataaisummit/north-america-2022)\n1. [RE\u2022WORK MLOps Summit 2022](https://www.re-work.co/events/mlops-summit-2022)\n1. [Annual MLOps World Conference](https://mlopsworld.com/)\n</details>\n\n<a name=\"existing-ml-systems\"></a>\n# Existing ML Systems\n<details>\n<summary>Click to expand!</summary>\n \n1. [Introducing FBLearner Flow: Facebook\u2019s AI backbone](https://engineering.fb.com/ml-applications/introducing-fblearner-flow-facebook-s-ai-backbone/)\n1. [TFX: A TensorFlow-Based Production-Scale Machine Learning Platform](https://dl.acm.org/doi/pdf/10.1145/3097983.3098021?download=true)\n1. [Accelerate your ML and Data workflows to production: Flyte](https://flyte.org/)\n1. [Getting started with Kubeflow Pipelines](https://cloud.google.com/blog/products/ai-machine-learning/getting-started-kubeflow-pipelines)\n1. [Meet Michelangelo: Uber\u2019s Machine Learning Platform](https://eng.uber.com/michelangelo/)\n1. [Meson: Workflow Orchestration for Netflix Recommendations](https://netflixtechblog.com/meson-workflow-orchestration-for-netflix-recommendations-fc932625c1d9)\n1. [What are Azure Machine Learning pipelines?](https://docs.microsoft.com/en-gb/azure/machine-learning/concept-ml-pipelines)\n1. [Uber ATG\u2019s Machine Learning Infrastructure for Self-Driving Vehicles](https://eng.uber.com/machine-learning-model-life-cycle-version-control/)\n1. [An overview of ML development platforms](https://www.linkedin.com/pulse/overview-ml-development-platforms-louis-dorard/)\n1. [Snorkel AI: Putting Data First in ML Development](https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html)\n1. [A Tour of End-to-End Machine Learning Platforms](https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/)\n1. [Introducing WhyLabs, a Leap Forward in AI Reliability](https://medium.com/whylabs/introducing-whylabs-5a3b4f37b998)\n1. [Project: Ease.ml (ETH Z\u00fcrich)](https://ds3lab.inf.ethz.ch/easeml.html)\n1. [Bodywork: model-training and deployment automation](https://bodywork.readthedocs.io/en/latest/)\n1. [Lessons on ML Platforms \u2014 from Netflix, DoorDash, Spotify, and more](https://towardsdatascience.com/lessons-on-ml-platforms-from-netflix-doordash-spotify-and-more-f455400115c7)\n1. [Papers & tech blogs by companies sharing their work on data science & machine learning in production. By Eugen Yan](https://github.com/eugeneyan/applied-ml)\n1. [How do different tech companies approach building internal ML platforms? (tweet)](https://twitter.com/EvidentlyAI/status/1420328878585913344)\n1. [Declarative Machine Learning Systems](https://dl.acm.org/doi/pdf/10.1145/3475965.3479315)\n1. [StreamING Machine Learning Models: How ING Adds Fraud Detection Models at Runtime with Apache Flink](https://www.ververica.com/blog/real-time-fraud-detection-ing-bank-apache-flink)\n</details>\n\n<a name=\"machine-learning\"></a>\n# Machine Learning \n<details>\n<summary>Click to expand!</summary>\n \n1. Book, Aur\u00e9lien G\u00e9ron,\"Hands-On Machine Learning with Scikit-Learn and TensorFlow\"\n1. [Foundations of Machine Learning](https://bloomberg.github.io/foml/)\n1. [Best Resources to Learn Machine Learning](http://www.trainindatablog.com/best-resources-to-learn-machine-learning/)\n1. [Awesome TensorFlow](https://github.com/jtoy/awesome-tensorflow)\n1. [\"Papers with Code\" - Browse the State-of-the-Art in Machine Learning](https://paperswithcode.com/sota)\n1. [Zhi-Hua Zhou. 2012. Ensemble Methods: Foundations and Algorithms. Chapman & Hall/CRC.](https://www.amazon.com/exec/obidos/ASIN/1439830037/acmorg-20)\n1. [Feature Engineering for Machine Learning. Principles and Techniques for Data Scientists. By Alice Zheng, Amanda Casari](https://www.amazon.com/Feature-Engineering-Machine-Learning-Principles-ebook/dp/B07BNX4MWC)\n1. [Google Research: Looking Back at 2019, and Forward to 2020 and Beyond](https://ai.googleblog.com/2020/01/google-research-looking-back-at-2019.html)\n1. [O\u2019Reilly: The road to Software 2.0](https://www.oreilly.com/radar/the-road-to-software-2-0/)\n1. [Machine Learning and Data Science Applications in Industry](https://github.com/firmai/industry-machine-learning)\n1. [Deep Learning for Anomaly Detection](https://ff12.fastforwardlabs.com/)\n1. [Federated Learning for Mobile Keyboard Prediction](https://arxiv.org/pdf/1811.03604.pdf)\n1. [Federated Learning. Building better products with on-device data and privacy on default](https://federated.withgoogle.com/)\n1. [Federated Learning: Collaborative Machine Learning without Centralized Training Data](https://ai.googleblog.com/2017/04/federated-learning-collaborative.html) \n1. [Yang, Q., Liu, Y., Cheng, Y., Kang, Y., Chen, T. and Yu, H., 2019. Federated learning. Synthesis Lectures on Artificial Intelligence and Machine Learning, 13(3). Chapters 1 and 2.](https://www.morganclaypoolpublishers.com/catalog_Orig/samples/9781681736983_sample.pdf)\n1. [Federated Learning by FastForward](https://federated.fastforwardlabs.com/)\n1. [THE FEDERATED & DISTRIBUTED MACHINE LEARNING CONFERENCE](https://www.federatedlearningconference.com/)\n1. [Federated Learning: Challenges, Methods, and Future Directions](https://blog.ml.cmu.edu/2019/11/12/federated-learning-challenges-methods-and-future-directions/)\n1. [Book: Molnar, Christoph. \"Interpretable machine learning. A Guide for Making Black Box Models Explainable\", 2019](https://christophm.github.io/interpretable-ml-book/)\n1. [Book: Hutter, Frank, Lars Kotthoff, and Joaquin Vanschoren. \"Automated Machine Learning\". Springer,2019.](https://originalstatic.aminer.cn/misc/pdf/Hutter-AutoML_Book_compressed.pdf)\n1. [ML resources by topic, curated by the community. ](https://madewithml.com/topics/)\n1. [An Introduction to Machine Learning Interpretability, by Patrick Hall, Navdeep Gill, 2nd Edition. O'Reilly 2019](https://learning.oreilly.com/library/view/an-introduction-to/9781098115487/)\n1. [Examples of techniques for training interpretable machine learning (ML) models, explaining ML models, and debugging ML models for accuracy, discrimination, and security.](https://github.com/jphall663/interpretable_machine_learning_with_python)\n1. [Paper: \"Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence\", by Sebastian Raschka, Joshua Patterson, and Corey Nolet. 2020](https://arxiv.org/pdf/2002.04803.pdf)\n1. [Distill: Machine Learning Research](https://distill.pub/)\n1. [AtHomeWithAI: Curated Resource List by DeepMind](https://storage.googleapis.com/deepmind-media/research/New_AtHomeWithAI%20resources.pdf)\n1. [Awesome Data Science](https://github.com/academic/awesome-datascience)\n1. [Intro to probabilistic programming. A use case using Tensorflow-Probability (TFP)](https://towardsdatascience.com/intro-to-probabilistic-programming-b47c4e926ec5)\n1. [Dive into Snorkel: Weak-Superversion on German Texts. inovex Blog](https://www.inovex.de/blog/snorkel-weak-superversion-german-texts/)\n1. [Dive into Deep Learning. An interactive deep learning book with code, math, and discussions. Provides NumPy/MXNet, PyTorch, and TensorFlow implementations](http://d2l.ai/)\n1. [Data Science Collected Resources (GitHub repository)](https://github.com/tirthajyoti/Data-science-best-resources)\n1. [Set of illustrated Machine Learning cheatsheets](https://stanford.edu/~shervine/teaching/cs-229/)\n1. [\"Machine Learning Bookcamp\" by Alexey Grigorev](https://www.manning.com/books/machine-learning-bookcamp)\n1. [130 Machine Learning Projects Solved and Explained](https://medium.com/the-innovation/130-machine-learning-projects-solved-and-explained-605d188fb392)\n1. [Machine learning cheat sheet](https://github.com/soulmachine/machine-learning-cheat-sheet)\n1. [Stateoftheart AI. An open-data and free platform built by the research community to facilitate the collaborative development of AI](https://www.stateoftheart.ai/)\n1. [Online Machine Learning Courses: 2020 Edition](https://www.blog.confetti.ai/post/best-online-machine-learning-courses-2020-edition)\n1. [End-to-End Machine Learning Library](https://e2eml.school/blog.html)\n1. [Machine Learning Toolbox (by Amit Chaudhary)](https://amitness.com/toolbox/)\n1. [Causality for Machine Learning](https://ff13.fastforwardlabs.com/FF13-Causality_for_Machine_Learning-Cloudera_Fast_Forward.pdf)\n1. [Causal Inference for the Brave and True](https://matheusfacure.github.io/python-causality-handbook/landing-page.html)\n1. [Causal Inference](https://mixtape.scunning.com/index.html)\n1. [A resource list for causality in statistics, data science and physics](https://github.com/msuzen/looper/blob/master/looper.md)\n1. [Learning from data. Caltech](http://work.caltech.edu/lectures.html)\n1. [Machine Learning Glossary](https://ml-cheatsheet.readthedocs.io/en/latest/#)\n1. [Book: \"Distributed Machine Learning Patterns\". 2022. By Yuan Tang. Manning](https://www.manning.com/books/distributed-machine-learning-patterns)\n1. [Machine Learning for Beginners - A Curriculum](https://github.com/microsoft/ML-For-Beginners)\n1. [Making Friends with Machine Learning. By Cassie Kozyrkov]()\n1. [Machine Learning Workflow - A Complete Guide](https://nimblebox.ai/blog/machine-learning-workflow)\n1. [Performance Metrics to Monitor in Machine Learning Projects](https://nimblebox.ai/blog/machine-learning-performance-metrics)\n \n</details>\n\n\n\n\n\n<a name=\"software-engineering\"></a>\n# Software Engineering\n<details>\n<summary>Click to expand!</summary>\n \n1. [The Twelve Factors](https://12factor.net/)\n1. [Book \"Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations\", 2018 by Nicole Forsgren et.al](https://www.amazon.com/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339)\n1. [Book \"The DevOps Handbook\" by Gene Kim, et al. 2016](https://itrevolution.com/book/the-devops-handbook/)\n1. [State of DevOps 2019](https://research.google/pubs/pub48455/)\n1. [Clean Code concepts adapted for machine learning and data science.](https://github.com/davified/clean-code-ml)\n1. [School of SRE](https://linkedin.github.io/school-of-sre/)\n1. [10 Laws of Software Engineering That People Ignore](https://www.indiehackers.com/post/10-laws-of-software-engineering-that-people-ignore-e3439176dd)\n1. [The Patterns of Scalable, Reliable, and Performant Large-Scale Systems](http://awesome-scalability.com/)\n1. [The Book of Secret Knowledge](https://github.com/trimstray/the-book-of-secret-knowledge)\n1. [SHADES OF CONWAY'S LAW](https://thinkinglabs.io/articles/2021/05/07/shades-of-conways-law.html)\n1. [Engineering Practices for Data Scientists](https://valohai.com/engineering-practices-ebook/)\n</details>\n\n\n<a name=\"product-management-for-mlai\"></a>\n# Product Management for ML/AI\n<details>\n<summary>Click to expand!</summary>\n \n1. [What you need to know about product management for AI. A product manager for AI does everything a traditional PM does, and much more.](https://www.oreilly.com/radar/what-you-need-to-know-about-product-management-for-ai/)\n1. [Bringing an AI Product to Market. Previous articles have gone through the basics of AI product management. Here we get to the meat: how do you bring a product to market?](https://www.oreilly.com/radar/bringing-an-ai-product-to-market/)\n1. [The People + AI Guidebook](https://pair.withgoogle.com/guidebook/)\n1. [User Needs + Defining Success](https://pair.withgoogle.com/chapter/user-needs/)\n1. [Building machine learning products: a problem well-defined is a problem half-solved.](https://www.jeremyjordan.me/ml-requirements/)\n1. [Talk: Designing Great ML Experiences (Apple)](https://developer.apple.com/videos/play/wwdc2019/803/) \n1. [Machine Learning for Product Managers](http://nlathia.github.io/2017/03/Machine-Learning-for-Product-Managers.html)\n1. [Understanding the Data Landscape and Strategic Play Through Wardley Mapping](https://ergestx.com/data-landscape-wardley-mapping/)\n1. [Techniques for prototyping machine learning systems across products and features](https://design.google/library/simulating-intelligence/)\n1. [Machine Learning and User Experience: A Few Resources](https://medium.com/ml-ux/machine-learning-and-user-experience-a-few-resources-e7872f1d34ee)\n1. [AI ideation canvas](https://idalab.de/wp-content/uploads/2021/02/idalab-AI-ideation-canvas-Feb21.pdf)\n1. [Ideation in AI](https://idalab.de/ideation-in-ai-five-ways-to-make-the-workshops-work/)\n1. [5 Steps for Building Machine Learning Models for Business. By shopify engineering](https://shopify.engineering/building-business-machine-learning-models)\n1. [Metric Design for Data Scientists and Business Leaders](https://towardsdatascience.com/metric-design-for-data-scientists-and-business-leaders-b8adaf46c00)\n</details>\n\n\n<a name=\"the-economics-of-mlai\"></a>\n# The Economics of ML/AI\n<details>\n<summary>Click to expand!</summary>\n \n1. [Book: \"Prediction Machines: The Simple Economics of Artificial Intelligence\"](https://www.predictionmachines.ai/)\n1. [Book: \"The AI Organization\" by David Carmona](https://learning.oreilly.com/library/view/the-ai-organization/9781492057369/)\n1. [Book: \"Succeeding with AI\". 2020. By Veljko Krunic. Manning Publications](https://learning.oreilly.com/library/view/succeeding-with-ai/9781617296932/)\n1. [A list of articles about AI and the economy](https://www.predictionmachines.ai/articles)\n1. [Gartner AI Trends 2019](https://blogs.gartner.com/smarterwithgartner/files/2019/08/CTMKT_736691_Hype_Cycle_for_AI_2019.png)\n1. [Global AI Survey: AI proves its worth, but few scale impact](https://www.mckinsey.com/featured-insights/artificial-intelligence/global-ai-survey-ai-proves-its-worth-but-few-scale-impact)\n1. [Getting started with AI? Start here! Everything you need to know to dive into your project](https://medium.com/hackernoon/the-decision-makers-guide-to-starting-ai-72ee0d7044df)\n1. [11 questions to ask before starting a successful Machine Learning project](https://tryolabs.com/blog/2019/02/13/11-questions-to-ask-before-starting-a-successful-machine-learning-project/)\n1. [What AI still can\u2019t do](https://www.technologyreview.com/s/615189/what-ai-still-cant-do/)\n1. [Demystifying AI Part 4: What is an AI Canvas and how do you use it?](https://www.wearebrain.com/blog/ai-data-science/what-is-an-ai-canvas/)\n1. [A Data Science Workflow Canvas to Kickstart Your Projects](https://towardsdatascience.com/a-data-science-workflow-canvas-to-kickstart-your-projects-db62556be4d0)\n1. [Is your AI project a nonstarter? Here\u2019s a reality check(list) to help you avoid the pain of learning the hard way](https://medium.com/hackernoon/ai-reality-checklist-be34e2fdab9)\n1. [What is THE main reason most ML projects fail?](https://towardsdatascience.com/what-is-the-main-reason-most-ml-projects-fail-515d409a161f)\n1. [Designing great data products. The Drivetrain Approach: A four-step process for building data products.](https://www.oreilly.com/radar/drivetrain-approach-data-products/)\n1. [The New Business of AI (and How It\u2019s Different From Traditional Software)](https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software/)\n1. [The idea maze for AI startups](https://cdixon.org/2015/02/01/the-ai-startup-idea-maze)\n1. [The Enterprise AI Challenge: Common Misconceptions](https://www.forbes.com/sites/forbestechcouncil/2020/01/15/the-enterprise-ai-challenge-common-misconceptions/#37ca1e5c5696)\n1. [Misconception 1 (of 5): Enterprise AI Is Primarily About The Technology](https://www.forbes.com/sites/forbestechcouncil/2020/01/31/misconception-1-of-5-enterprise-ai-is-primarily-about-the-technology/#151e6711180e)\n1. [Misconception 2 (of 5): Automated Machine Learning Will Unlock Enterprise AI](https://www.forbes.com/sites/forbestechcouncil/2020/02/27/misconception-2-of-5-automated-machine-learning-will-unlock-enterprise-ai/#7f618ff97ace)\n1. [Three Principles for Designing ML-Powered Products](https://spotify.design/articles/2019-12-10/three-principles-for-designing-ml-powered-products/)\n1. [A Step-by-Step Guide to Machine Learning Problem Framing](https://medium.com/thelaunchpad/a-step-by-step-guide-to-machine-learning-problem-framing-6fc17126b981)\n1. [AI adoption in the enterprise 2020](https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2020/)\n1. [How Adopting MLOps can Help Companies With ML Culture?](https://www.analyticsinsight.net/adopting-mlops-can-help-companies-ml-culture/)\n1. [Weaving AI into Your Organization](https://medium.com/firmai/weaving-ai-into-your-organization-2d9643da50e1)\n1. [What to Do When AI Fails](https://www.oreilly.com/radar/what-to-do-when-ai-fails/)\n1. [Introduction to Machine Learning Problem Framing](https://developers.google.com/machine-learning/problem-framing)\n1. [Structured Approach for Identifying AI Use Cases](https://towardsdatascience.com/proven-structured-approach-for-identifying-ai-use-cases-b876d8d00e5)\n1. [Book: \"Machine Learning for Business\" by Doug Hudgeon, Richard Nichol, O'reilly](https://learning.oreilly.com/library/view/machine-learning-for/9781617295836/)\n1. [Why Commercial Artificial Intelligence Products Do Not Scale (FemTech)](https://www.presagen.com/why-commercial-artificial-intelligence-products-do-not-scale)\n1. [Google Cloud\u2019s AI Adoption Framework (White Paper)](https://services.google.com/fh/files/misc/ai_adoption_framework_whitepaper.pdf)\n1. [Data Science Project Management](http://www.datascience-pm.com/)\n1. [Book: \"Competing in the Age of AI\" by Marco Iansiti, Karim R. Lakhani. Harvard Business Review Press. 2020](https://learning.oreilly.com/library/view/competing-in-the/9781633697638/)\n1. [The Three Questions about AI that Startups Need to Ask. The first is: Are you sure you need AI?](https://towardsdatascience.com/google-expert-tips-for-artificial-intelligence-startups-three-questions-about-ai-that-startups-need-to-ask-308924cb5324)\n1. [Taming the Tail: Adventures in Improving AI Economics](https://a16z.com/2020/08/12/taming-the-tail-adventures-in-improving-ai-economics/)\n1. [Managing the Risks of Adopting AI Engineering](https://insights.sei.cmu.edu/sei_blog/2020/08/managing-the-risks-of-adopting-ai-engineering.html)\n1. [Get rid of AI Saviorism](https://www.shreya-shankar.com/ai-saviorism/)\n1. [Collection of articles listing reasons why data science projects fail](https://github.com/xLaszlo/datascience-fails)\n1. [How to Choose Your First AI Project by Andrew Ng](https://hbr.org/2019/02/how-to-choose-your-first-ai-project)\n1. [How to Set AI Goals](https://www.oreilly.com/radar/how-to-set-ai-goals/)\n1. [Expanding AI's Impact With Organizational Learning](https://sloanreview.mit.edu/projects/expanding-ais-impact-with-organizational-learning/)\n1. [Potemkin Data Science](https://mcorrell.medium.com/potemkin-data-science-fba2b5ba5cc6)\n1. [When Should You Not Invest in AI?](https://www.entrepreneur.com/article/359803)\n1. [Why 90% of machine learning models never hit the market. Most companies lack leadership support, effective communication between teams, and accessible data](https://thenextweb.com/news/why-most-machine-learning-models-never-hit-market-syndication)\n</details>\n\n\n\n<a name=\"ml-governance\"></a>\n# Model Governance, Ethics, Responsible AI\n\nThis topic is extracted into our new [Awesome ML Model Governace repository](https://github.com/visenger/Awesome-ML-Model-Governance)\n\n\n<a name=\"teams\"></a>\n# MLOps: People & Processes\n<details>\n<summary>Click to expand!</summary>\n \n1. [Scaling An ML Team (0\u201310 People)](https://medium.com/aquarium-learning/scaling-an-ml-team-0-10-people-ae024f3a89f3)\n1. [The Knowledge Repo project is focused on facilitating the sharing of knowledge between data scientists and other technical roles.](https://github.com/airbnb/knowledge-repo) \n1. [Scaling Knowledge at Airbnb](https://medium.com/airbnb-engineering/scaling-knowledge-at-airbnb-875d73eff091)\n1. [Models for integrating data science teams within companies A comparative analysis](https://djpardis.medium.com/models-for-integrating-data-science-teams-within-organizations-7c5afa032ebd)\n1. [How to Write Better with The Why, What, How Framework. How to write design documents for data science/machine learning projects? (by Eugene Yan)](https://eugeneyan.com/writing/writing-docs-why-what-how/)\n1. [Technical Writing Courses](https://developers.google.com/tech-writing)\n1. [Building a data team at a mid-stage startup: a short story. By Erik Bernhardsson](https://erikbern.com/2021/07/07/the-data-team-a-short-story.html)\n1. [The Cultural Benefits of Artificial Intelligence in the Enterprise. by Sam Ransbotham, Fran\u00e7ois Candelon, David Kiron, Burt LaFountain, and Shervin Khodabandeh](https://web-assets.bcg.com/2a/d0/ebfb860a4e05aa9e4729b083da4b/the-cultural-benefits-of-artificial-intelligence-in-the-enterprise.pdf)\n</details>\n\n\n<a name=\"newsletters\"></a>\n# Newsletters About MLOps, Machine Learning, Data Science and Co.\n<details>\n<summary>Click to expand!</summary>\n \n1. [ML in Production newsletter](https://mlinproduction.com/machine-learning-newsletter/)\n1. [MLOps.community](https://mlops.community/)\n1. [Andriy Burkov newsletter](https://www.linkedin.com/pulse/artificial-intelligence-33-andriy-burkov/)\n1. [Decision Intelligence by Cassie Kozyrkov](https://decision.substack.com/)\n1. [Laszlo's Newsletter about Data Science](https://laszlo.substack.com/)\n1. [Data Elixir newsletter for a weekly dose of the top data science picks from around the web. Covering machine learning, data visualization, analytics, and strategy.](https://dataelixir.com/)\n1. [The Data Science Roundup by Tristan Handy](http://roundup.fishtownanalytics.com/)\n1. [Vicki Boykis Newsletter about Data Science](https://vicki.substack.com/)\n1. [KDnuggets News](https://www.kdnuggets.com/)\n1. [Analytics Vidhya, Any questions on business analytics, data science, big data, data visualizations tools and techniques](https://www.analyticsvidhya.com/blog/)\n1. [Data Science Weekly Newsletter: A free weekly newsletter featuring curated news, articles and jobs related to Data Science](https://www.datascienceweekly.org/)\n1. [The Machine Learning Engineer Newsletter](https://ethical.institute/mle.html)\n1. [Gradient Flow helps you stay ahead of the latest technology trends and tools with in-depth coverage, analysis and insights. See the latest on data, technology and business, with a focus on machine learning and AI](https://gradientflow.wpcomstaging.com/)\n1. [Your guide to AI by Nathan Benaich. Monthly analysis of AI technology, geopolitics, research, and startups.](http://newsletter.airstreet.com/)\n1. [O'Reilly Data & AI Newsletter](https://www.oreilly.com/emails/newsletters/)\n1. [deeplearning.ai\u2019s newsletter by Andrew Ng](https://www.deeplearning.ai/)\n1. [Deep Learning Weekly](https://www.deeplearningweekly.com/)\n1. [Import AI is a weekly newsletter about artificial intelligence, read by more than ten thousand experts. By Jack Clark.](https://jack-clark.net/)\n1. [AI Ethics Weekly](https://lighthouse3.com/newsletter/)\n1. [Announcing Projects To Know, a weekly machine intelligence and data science newsletter](https://blog.amplifypartners.com/announcing-projects-to-know/)\n1. [TWIML: This Week in Machine Learning and AI newsletter](https://twimlai.com/newsletter/)\n1. [featurestore.org: Monthly Newsletter on Feature Stores for ML](https://www.featurestore.org/)\n1. [DataTalks.Club Community: Slack, Newsletter, Podcast, Weeekly Events](https://datatalks.club/)\n1. [Machine Learning Ops Roundup](https://mlopsroundup.substack.com/)\n1. [Data Science Programming Newsletter by Eric Ma](https://dspn.substack.com/)\n1. [Marginally Interesting by Mikio L. Braun](https://www.getrevue.co/profile/mikiobraun) \n1. [Synced](https://syncedreview.com/)\n1. [The Ground Truth: Newsletter for Computer Vision Practitioners](https://info.superb-ai.com/ground-truth-newsletter-subscribe)\n1. [SwirlAI: Data Engineering, MLOps and overall Data focused Newsletter by Aurimas Grici\u016bnas](https://swirlai.substack.com/)\n</details>\n \n![Twitter Follow](https://img.shields.io/twitter/follow/visenger?style=social)\n",
	"computer-vision data-centric data-science datascience deep deep-learning deeplearning learning machine machine-learning machinelearning ml natural-language natural-language-processing neural-network python pytorch": "![Ludwig logo](https://github.com/ludwig-ai/ludwig-docs/raw/master/docs/images/ludwig_hero.png \"Ludwig logo\")\n\n<div align=\"center\">\n\n[![PyPI version](https://badge.fury.io/py/ludwig.svg)](https://badge.fury.io/py/ludwig)\n[![Commit Activity](https://img.shields.io/github/commit-activity/m/ludwig-ai/ludwig)](https://img.shields.io/github/commit-activity/m/ludwig-ai/ludwig)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/4210/badge)](https://bestpractices.coreinfrastructure.org/projects/4210)\n[![Slack](https://img.shields.io/badge/slack-chat-green.svg?logo=slack)](https://join.slack.com/t/ludwig-ai/shared_invite/zt-mrxo87w6-DlX5~73T2B4v_g6jj0pJcQ)\n\n[![DockerHub](https://img.shields.io/docker/pulls/ludwigai/ludwig.svg)](https://hub.docker.com/r/ludwigai)\n[![Downloads](https://pepy.tech/badge/ludwig)](https://pepy.tech/project/ludwig)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/ludwig-ai/ludwig/blob/master/LICENSE)\n[![Twitter](https://img.shields.io/twitter/follow/ludwig_ai.svg?style=social&logo=twitter)](https://twitter.com/ludwig_ai)\n\nFull Documentation: [ludwig.ai](https://ludwig.ai)\n\n</div>\n\n# What is Ludwig?\n\nLudwig is a [declarative machine learning framework](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/what_is_ludwig/#why-declarative-machine-learning-systems)\nthat makes it easy to define machine learning pipelines using a simple and\nflexible data-driven configuration system. Ludwig is suitable for a wide variety\nof AI tasks, and is hosted by the\n[Linux Foundation AI & Data](https://lfaidata.foundation/).\n\nThe configuration declares the input and output features, with their respective\ndata types. Users can also specify additional parameters to preprocess, encode,\nand decode features, load from pre-trained models, compose the internal model\narchitecture, set training parameters, or run hyperparameter optimization.\n\n![img](https://raw.githubusercontent.com/ludwig-ai/ludwig-docs/master/docs/images/ludwig_legos_unanimated.gif)\n\nLudwig will build an end-to-end machine learning pipeline automatically, using\nwhatever is explicitly specified in the configuration, while falling back to\nsmart defaults for any parameters that are not.\n\n# Declarative Machine Learning\n\nLudwig\u2019s declarative approach to machine learning empowers you to have full\ncontrol of the components of the machine learning pipeline that you care about,\nwhile leaving it up to Ludwig to make reasonable decisions for the rest.\n\n![img](images/why_declarative.png)\n\nAnalysts, scientists, engineers, and researchers use Ludwig to explore\nstate-of-the-art model architectures, run hyperparameter search, scale up to\nlarger than available memory datasets and multi-node clusters, and finally\nserve the best model in production.\n\nFinally, the use of abstract interfaces throughout the codebase makes it easy\nfor users to extend Ludwig by adding new models, metrics, losses, and\npreprocessing functions that can be registered to make them immediately useable\nin the same unified configuration system.\n\n# Main Features\n\n- **[Data-Driven configuration system](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/how_ludwig_works)**\n\n  A config YAML file that describes the schema of your data (input features,\n  output features, and their types) is all you need to start training deep\n  learning models. Ludwig uses declared features to compose a deep learning\n  model accordingly.\n\n  ```yaml\n  input_features:\n      - name: data_column_1\n        type: number\n      - name: data_column_2\n        type: category\n      - name: data_column_3\n        type: text\n      - name: data_column_4\n        type: image\n      ...\n\n  output_features:\n      - name: data_column_5\n        type: number\n      - name: data_column_6\n        type: category\n      ...\n  ```\n\n- **[Training, prediction, and evaluation from the command line](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/command_line_interface)**\n\n  Simple commands can be used to train models and predict new data.\n\n  ```shell\n  ludwig train --config config.yaml --dataset data.csv\n  ludwig predict --model_path results/experiment_run/model --dataset test.csv\n  ludwig eval --model_path results/experiment_run/model --dataset test.csv\n  ```\n\n- **[Programmatic API](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/api/LudwigModel)**\n\n  Ludwig also provides a simple programmatic API for all of the functionality\n  described above and more.\n\n  ```python\n  from ludwig.api import LudwigModel\n\n  # train a model\n  config = {\n      \"input_features\": [...],\n      \"output_features\": [...],\n  }\n  model = LudwigModel(config)\n  data = pd.read_csv(\"data.csv\")\n  train_stats, _, model_dir = model.train(data)\n\n  # or load a model\n  model = LudwigModel.load(model_dir)\n\n  # obtain predictions\n  predictions = model.predict(data)\n  ```\n\n- **[Distributed training](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/distributed_training)**\n\n  Train models in a distributed setting using [Horovod](https://github.com/horovod/horovod),\n  which allows training on a single machine with multiple GPUs or multiple\n  machines with multiple GPUs.\n\n- **[Serving](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/serving)**\n\n  Serve models using FastAPI.\n\n  ```shell\n  ludwig serve --model_path ./results/experiment_run/model\n  curl http://0.0.0.0:8000/predict -X POST -F \"movie_title=Friends With Money\" -F \"content_rating=R\" -F \"genres=Art House & International, Comedy, Drama\" -F \"runtime=88.0\" -F \"top_critic=TRUE\" -F \"review_content=The cast is terrific, the movie isn't.\"\n  ```\n\n- **[Hyperparameter optimization](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/hyperopt)**\n\n  Run hyperparameter optimization locally or using [Ray Tune](https://docs.ray.io/en/latest/tune/index.html).\n\n  ```shell\n  ludwig hyperopt --config config.yaml --dataset data.csv\n  ```\n\n- **[AutoML](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/automl)**\n\n  Ludwig AutoML takes a dataset, the target column, and a time budget, and\n  returns a trained Ludwig model.\n\n- **[Third-Party integrations](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/integrations)**\n\n  Ludwig provides an extendable interface to integrate with third-party\n  systems for tracking experiments. Third-party integrations exist for Comet\n  ML, Weights & Biases, WhyLabs, and MLFlow.\n\n- **[Extensibility](https://ludwig-ai.github.io/ludwig-docs/latest/developer_guide)**\n\n  Ludwig is built from the ground up with extensibility in mind. It is easy to\n  add new data types by implementing clear, well-documented abstract classes\n  that define functions to preprocess, encode, and decode data.\n\n  Furthermore, new `torch nn.Module` models can be easily added by them to a\n  registry. This encourages reuse and sharing new models with the community.\n  Refer to the [Developer Guide](https://ludwig-ai.github.io/ludwig-docs/latest/developer_guide)\n  for further details.\n\n# Quick Start\n\nFor a full tutorial, check out the official [getting started guide](https://ludwig-ai.github.io/ludwig-docs/latest/getting_started/),\nor take a look at end-to-end [Examples](https://ludwig-ai.github.io/ludwig-docs/latest/examples).\n\n## Step 1: Install\n\nInstall from PyPi. Be aware that Ludwig requires Python 3.7+.\n\n```shell\npip install ludwig\n```\n\n## Step 2: Define a configuration\n\nCreate a config that describes the schema of your data.\n\nAssume we have a text classification task, with data containing a sentence and class column like the following.\n\n|               sentence               |  class   |\n| :----------------------------------: | :------: |\n|  Former president Barack Obama ...   | politics |\n| Juventus hired Cristiano Ronaldo ... |  sport   |\n|  LeBron James joins the Lakers ...   |  sport   |\n|                 ...                  |   ...    |\n\nA configuration will look like this.\n\n```yaml\ninput_features:\n- name: sentence\n  type: text\n\noutput_features:\n- name: class\n  type: category\n```\n\nStarting from a simple config like the one above, any and all aspects of the model architecture, training loop,\nhyperparameter search, and backend infrastructure can be modified as additional fields in the declarative configuration\nto customize the pipeline to meet your requirements.\n\n```yaml\ninput_features:\n- name: sentence\n  type: text\n  encoder: transformer\n  layers: 6\n  embedding_size: 512\n\noutput_features:\n- name: class\n  type: category\n  loss: cross_entropy\n\ntrainer:\n  epochs: 50\n  batch_size: 64\n  optimizer:\n    type: adamw\n    beat1: 0.9\n  learning_rate: 0.001\n\nbackend:\n  type: ray\n  cache_format: parquet\n  processor:\n    type: dask\n  trainer:\n    use_gpu: true\n    num_workers: 4\n    resources_per_worker:\n      CPU: 4\n      GPU: 1\n\nhyperopt:\n  metric: f1\n  sampler: random\n  parameters:\n    title.num_layers:\n      lower: 1\n      upper: 5\n    trainer.learning_rate:\n      values: [0.01, 0.003, 0.001]\n```\n\nFor details on what can be configured, check out [Ludwig Configuration](https://ludwig-ai.github.io/ludwig-docs/latest/configuration/)\ndocs.\n\n## Step 3: Train a model\n\nSimple commands can be used to train models and predict new data.\n\n```shell\nludwig train --config config.yaml --dataset data.csv\n```\n\n## Step 4: Predict and evaluate\n\nThe training process will produce a model that can be used for evaluating on and obtaining predictions for new data.\n\n```shell\nludwig predict --model path/to/trained/model --dataset heldout.csv\nludwig evaluate --model path/to/trained/model --dataset heldout.csv\n```\n\n## Step 5: Visualize\n\nLudwig provides a suite of visualization tools allows you to analyze models' training and test performance and to\ncompare them.\n\n```shell\nludwig visualize --visualization compare_performance --test_statistics path/to/test_statistics_model_1.json path/to/test_statistics_model_2.json\n```\n\nFor the full set of visualization see the [Visualization Guide](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/visualizations).\n\n## Step 6: Happy modeling\n\nTry applying Ludwig to your data. [Reach out](https://join.slack.com/t/ludwig-ai/shared_invite/zt-mrxo87w6-DlX5~73T2B4v_g6jj0pJcQ)\nif you have any questions.\n\n# Advantages\n\n- **Minimal machine learning boilerplate**\n\n  Ludwig takes care of the engineering complexity of machine learning out of\n  the box, enabling research scientists to focus on building models at the\n  highest level of abstraction. Data preprocessing, hyperparameter\n  optimization, device management, and distributed training for\n  `torch.nn.Module` models come completely free.\n\n- **Easily build your benchmarks**\n\n  Creating a state-of-the-art baseline and comparing it with a new model is a\n  simple config change.\n\n- **Easily apply new architectures to multiple problems and datasets**\n\n  Apply new models across the extensive set of tasks and datasets that Ludwig\n  supports. Ludwig includes a\n  [full benchmarking toolkit](https://arxiv.org/abs/2111.04260) accessible to\n  any user, for running experiments with multiple models across multiple\n  datasets with just a simple configuration.\n\n- **Highly configurable data preprocessing, modeling, and metrics**\n\n  Any and all aspects of the model architecture, training loop, hyperparameter\n  search, and backend infrastructure can be modified as additional fields in\n  the declarative configuration to customize the pipeline to meet your\n  requirements. For details on what can be configured, check out\n  [Ludwig Configuration](https://ludwig-ai.github.io/ludwig-docs/latest/configuration/)\n  docs.\n\n- **Multi-modal, multi-task learning out-of-the-box**\n\n  Mix and match tabular data, text, images, and even audio into complex model\n  configurations without writing code.\n\n- **Rich model exporting and tracking**\n\n  Automatically track all trials and metrics with tools like Tensorboard,\n  Comet ML, Weights & Biases, MLFlow, and Aim Stack.\n\n- **Automatically scale training to multi-GPU, multi-node clusters**\n\n  Go from training on your local machine to the cloud without code changes.\n\n- **Low-code interface for state-of-the-art models, including pre-trained Huggingface Transformers**\n\n  Ludwig also natively integrates with pre-trained models, such as the ones\n  available in [Huggingface Transformers](https://huggingface.co/docs/transformers/index).\n  Users can choose from a vast collection of state-of-the-art pre-trained\n  PyTorch models to use without needing to write any code at all. For example,\n  training a BERT-based sentiment analysis model with Ludwig is as simple as:\n\n  ```shell\n  ludwig train --dataset sst5 --config_str \u201c{input_features: [{name: sentence, type: text, encoder: bert}], output_features: [{name: label, type: category}]}\u201d\n  ```\n\n- **Low-code interface for AutoML**\n\n  [Ludwig AutoML](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/automl/)\n  allows users to obtain trained models by providing just a dataset, the\n  target column, and a time budget.\n\n  ```python\n  auto_train_results = ludwig.automl.auto_train(dataset=my_dataset_df, target=target_column_name, time_limit_s=7200)\n  ```\n\n- **Easy productionisation**\n\n  Ludwig makes it easy to serve deep learning models, including on GPUs.\n  Launch a REST API for your trained Ludwig model.\n\n  ```shell\n  ludwig serve --model_path=/path/to/model\n  ```\n\n  Ludwig supports exporting models to efficient Torschscript bundles.\n\n  ```shell\n  ludwig export_torchscript -\u2013model_path=/path/to/model\n  ```\n\n# Tutorials\n\n- [Text Classification](https://ludwig-ai.github.io/ludwig-docs/latest/examples/text_classification)\n- [Tabular Data Classification](https://ludwig-ai.github.io/ludwig-docs/latest/examples/adult_census_income)\n- [Image Classification](https://ludwig-ai.github.io/ludwig-docs/latest/examples/mnist)\n- [Multimodal Classification](https://ludwig-ai.github.io/ludwig-docs/latest/examples/multimodal_classification)\n\n# Example Use Cases\n\n- [Named Entity Recognition Tagging](https://ludwig-ai.github.io/ludwig-docs/latest/examples/ner_tagging)\n- [Natural Language Understanding](https://ludwig-ai.github.io/ludwig-docs/latest/examples/nlu)\n- [Machine Translation](https://ludwig-ai.github.io/ludwig-docs/latest/examples/machine_translation)\n- [Chit-Chat Dialogue Modeling through seq2seq](https://ludwig-ai.github.io/ludwig-docs/latest/examples/seq2seq)\n- [Sentiment Analysis](https://ludwig-ai.github.io/ludwig-docs/latest/examples/sentiment_analysis)\n- [One-shot Learning with Siamese Networks](https://ludwig-ai.github.io/ludwig-docs/latest/examples/oneshot)\n- [Visual Question Answering](https://ludwig-ai.github.io/ludwig-docs/latest/examples/visual_qa)\n- [Spoken Digit Speech Recognition](https://ludwig-ai.github.io/ludwig-docs/latest/examples/speech_recognition)\n- [Speaker Verification](https://ludwig-ai.github.io/ludwig-docs/latest/examples/speaker_verification)\n- [Binary Classification (Titanic)](https://ludwig-ai.github.io/ludwig-docs/latest/examples/titanic)\n- [Timeseries forecasting](https://ludwig-ai.github.io/ludwig-docs/latest/examples/forecasting)\n- [Timeseries forecasting (Weather)](https://ludwig-ai.github.io/ludwig-docs/latest/examples/weather)\n- [Movie rating prediction](https://ludwig-ai.github.io/ludwig-docs/latest/examples/movie_ratings)\n- [Multi-label classification](https://ludwig-ai.github.io/ludwig-docs/latest/examples/multi_label)\n- [Multi-Task Learning](https://ludwig-ai.github.io/ludwig-docs/latest/examples/multi_task)\n- [Simple Regression: Fuel Efficiency Prediction](https://ludwig-ai.github.io/ludwig-docs/latest/examples/fuel_efficiency)\n- [Fraud Detection](https://ludwig-ai.github.io/ludwig-docs/latest/examples/fraud)\n\n# More Information\n\nRead our publications on [Ludwig](https://arxiv.org/pdf/1909.07930.pdf), [declarative ML](https://arxiv.org/pdf/2107.08148.pdf), and [Ludwig\u2019s SoTA benchmarks](https://openreview.net/pdf?id=hwjnu6qW7E4).\n\nLearn more about [how Ludwig works](https://ludwig-ai.github.io/ludwig-docs/latest/user_guide/how_ludwig_works/), [how to get started](https://ludwig-ai.github.io/ludwig-docs/latest/getting_started/), and work through more [examples](https://ludwig-ai.github.io/ludwig-docs/latest/examples).\n\nIf you are interested in contributing, have questions, comments, or thoughts to share, or if you just want to be in the\nknow, please consider [joining the Ludwig Slack](https://join.slack.com/t/ludwig-ai/shared_invite/zt-mrxo87w6-DlX5~73T2B4v_g6jj0pJcQ) and follow us on [Twitter](https://twitter.com/ludwig_ai)!\n\n# Getting Involved\n\n- [Slack](https://join.slack.com/t/ludwig-ai/shared_invite/zt-mrxo87w6-DlX5~73T2B4v_g6jj0pJcQ)\n- [Twitter](https://twitter.com/ludwig_ai)\n- [Medium](https://medium.com/ludwig-ai)\n- [GitHub Issues](https://github.com/ludwig-ai/ludwig/issues)\n",
	"algorithms dotnet machine-learning ml": "# Machine Learning for .NET\n\n[ML.NET](https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet) is a cross-platform open-source machine learning (ML) framework for .NET.\n\nML.NET allows developers to easily build, train, deploy, and consume custom models in their .NET applications without requiring prior expertise in developing machine learning models or experience with other programming languages like Python or R. The framework provides data loading from files and databases, enables data transformations, and includes many ML algorithms.\n\nWith ML.NET, you can train models for a [variety of scenarios](https://docs.microsoft.com/dotnet/machine-learning/resources/tasks), like classification, forecasting, and anomaly detection.\n\nYou can also consume both TensorFlow and ONNX models within ML.NET which makes the framework more extensible and expands the number of supported scenarios.\n\n## Getting started with machine learning and ML.NET\n\n- Learn more about the [basics of ML.NET](https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet).\n- Build your first ML.NET model by following our [ML.NET Getting Started tutorial](https://dotnet.microsoft.com/learn/ml-dotnet/get-started-tutorial/intro).\n- Check out our [documentation and tutorials](https://docs.microsoft.com/dotnet/machine-learning/).\n- See the [API Reference documentation](https://docs.microsoft.com/dotnet/api/?view=ml-dotnet).\n- Clone our [ML.NET Samples GitHub repo](https://github.com/dotnet/machinelearning-samples) and run some sample apps.\n- Take a look at some [ML.NET Community Samples](https://github.com/dotnet/machinelearning-samples/blob/main/docs/COMMUNITY-SAMPLES.md).\n- Watch some videos on the [ML.NET videos YouTube playlist](https://aka.ms/mlnetyoutube).\n\n## Roadmap\n\nTake a look at ML.NET's [Roadmap](ROADMAP.md) to see what the team plans to work on in the next year.\n\n## Operating systems and processor architectures supported by ML.NET\n\nML.NET runs on Windows, Linux, and macOS using .NET Core, or Windows using .NET Framework.\n\nML.NET also runs on ARM64, Apple M1, and Blazor Web Assembly. However, there are some [limitations](docs/project-docs/platform-limitations.md).\n\n64-bit is supported on all platforms. 32-bit is supported on Windows, except for TensorFlow and LightGBM related functionality.\n\n## ML.NET NuGet packages status\n\n[![NuGet Status](https://img.shields.io/nuget/vpre/Microsoft.ML.svg?style=flat)](https://www.nuget.org/packages/Microsoft.ML/)\n\n## Release notes\n\nCheck out the [release notes](docs/release-notes) to see what's new. You can also read the [blog posts](https://devblogs.microsoft.com/dotnet/category/ml-net/) for more details about each release.\n\n## Using ML.NET packages\n\nFirst, ensure you have installed [.NET Core 2.1](https://www.microsoft.com/net/learn/get-started) or later. ML.NET also works on the .NET Framework 4.6.1 or later, but 4.7.2 or later is recommended.\n\nOnce you have an app, you can install the ML.NET NuGet package from the .NET Core CLI using:\n```\ndotnet add package Microsoft.ML\n```\n\nor from the NuGet Package Manager:\n```\nInstall-Package Microsoft.ML\n```\n\nAlternatively, you can add the Microsoft.ML package from within Visual Studio's NuGet package manager or via [Paket](https://github.com/fsprojects/Paket).\n\nDaily NuGet builds of the project are also available in our Azure DevOps feed:\n\n> [https://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet-libraries/nuget/v3/index.json](https://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet-libraries/nuget/v3/index.json)\n\n## Building ML.NET (For contributors building ML.NET open source code)\n\nTo build ML.NET from source please visit our [developer guide](docs/project-docs/developer-guide.md).\n\n[![codecov](https://codecov.io/gh/dotnet/machinelearning/branch/main/graph/badge.svg?flag=production)](https://codecov.io/gh/dotnet/machinelearning)\n\n|    | Debug | Release |\n|:---|----------------:|------------------:|\n|**CentOS**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Centos_x64_Net60&configuration=Centos_x64_Net60%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Centos_x64_Net60&configuration=Centos_x64_Net60%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|\n|**Ubuntu**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Ubuntu_x64_Net60&configuration=Ubuntu_x64_Net60%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Ubuntu_x64_Net60&configuration=Ubuntu_x64_Net60%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|\n|**macOS**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=MacOS_x64_Net60&configuration=MacOS_x64_Net60%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=MacOS_x64_Net60&configuration=MacOS_x64_Net60%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|\n|**Windows x64**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Windows_x64_Net60&configuration=Windows_x64_Net60%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Windows_x64_Net60&configuration=Windows_x64_Net60%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|\n|**Windows FullFramework**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Windows_x64_NetFx461&configuration=Windows_x64_NetFx461%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Windows_x64_NetFx461&configuration=Windows_x64_NetFx461%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|\n|**Windows x86**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Windows_x86_Net60&configuration=Windows_x86_Net60%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Windows_x86_Net60&configuration=Windows_x86_Net60%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|\n|**Windows NetCore3.1**|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Windows_x64_Net60&configuration=Windows_x64_Net60%20Debug_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|[![Build Status](https://dev.azure.com/dnceng/public/_apis/build/status/dotnet/machinelearning/MachineLearning-CI?branchName=main&jobName=Windows_x64_Net60&configuration=Windows_x64_Net60%20Release_Build)](https://dev.azure.com/dnceng/public/_build/latest?definitionId=104&branchName=main)|\n\n## Release process and versioning\n\nMajor releases of ML.NET are shipped once a year with the major .NET releases, starting with ML.NET 1.7 in November 2021 with .NET 6, then ML.NET 2.0 with .NET 7, etc. We will maintain release branches to optionally service ML.NET with bug fixes and/or minor features on the same cadence as .NET servicing.\n\nCheck out the [Release Notes](docs/release-notes) to see all of the past ML.NET releases.\n\n## Contributing\n\nWe welcome contributions! Please review our [contribution guide](CONTRIBUTING.md).\n\n## Community\n\n- Join our community on [Discord](https://aka.ms/dotnet-discord).\n- Tune into the [.NET Machine Learning Community Standup](https://dotnet.microsoft.com/live/community-standup) every other Wednesday at 10AM Pacific Time.\n\nThis project has adopted the code of conduct defined by the [Contributor Covenant](https://contributor-covenant.org/) to clarify expected behavior in our community.\nFor more information, see the [.NET Foundation Code of Conduct](https://dotnetfoundation.org/code-of-conduct).\n\n## Code examples\n\nHere is a code snippet for training a model to predict sentiment from text samples. You can find complete samples in the [samples repo](https://github.com/dotnet/machinelearning-samples).\n\n```C#\nvar dataPath = \"sentiment.csv\";\nvar mlContext = new MLContext();\nvar loader = mlContext.Data.CreateTextLoader(new[]\n    {\n        new TextLoader.Column(\"SentimentText\", DataKind.String, 1),\n        new TextLoader.Column(\"Label\", DataKind.Boolean, 0),\n    },\n    hasHeader: true,\n    separatorChar: ',');\nvar data = loader.Load(dataPath);\nvar learningPipeline = mlContext.Transforms.Text.FeaturizeText(\"Features\", \"SentimentText\")\n        .Append(mlContext.BinaryClassification.Trainers.FastTree());\nvar model = learningPipeline.Fit(data);\n```\n\nNow from the model we can make inferences (predictions):\n\n```C#\nvar predictionEngine = mlContext.Model.CreatePredictionEngine<SentimentData, SentimentPrediction>(model);\nvar prediction = predictionEngine.Predict(new SentimentData\n{\n    SentimentText = \"Today is a great day!\"\n});\nConsole.WriteLine(\"prediction: \" + prediction.Prediction);\n```\n\n## License\n\nML.NET is licensed under the [MIT license](LICENSE), and it is free to use commercially.\n\n## .NET Foundation\n\nML.NET is a part of the [.NET Foundation](https://www.dotnetfoundation.org/projects).\n",
	"anomaly-detection citizen-data-scientists classification clustering data-science gpu machine-learning ml nlp pycaret python regression time-series": "<div align=\"center\">\n  \n<img src=\"docs/images/logo.png\" alt=\"drawing\" width=\"200\"/>\n\n**An open-source, low-code machine learning library in Python** </br>\n:rocket: **PyCaret 3.0-rc is now out. `pip install --pre pycaret`**\n  \n<p align=\"center\">\n  <a href=\"https://www.pycaret.org\">Official</a> \u2022\n  <a href=\"https://pycaret.gitbook.io/\">Docs</a> \u2022\n  <a href=\"https://pycaret.gitbook.io/docs/get-started/installation\">Install</a> \u2022\n  <a href=\"https://pycaret.gitbook.io/docs/get-started/tutorials\">Tutorials</a> \u2022\n  <a href=\"https://pycaret.gitbook.io/docs/learn-pycaret/faqs\">FAQs</a> \u2022\n  <a href=\"https://pycaret.gitbook.io/docs/learn-pycaret/cheat-sheet\">Cheat sheet</a> \u2022\n  <a href=\"https://github.com/pycaret/pycaret/discussions\">Discussions</a> \u2022\n  <a href=\"https://pycaret.readthedocs.io/en/latest/contribute.html\">Contribute</a> \u2022\n  <a href=\"https://github.com/pycaret/pycaret/tree/master/resources\">Resources</a> \u2022\n  <a href=\"https://pycaret.gitbook.io/docs/learn-pycaret/official-blog\">Blog</a> \u2022\n  <a href=\"https://www.linkedin.com/company/pycaret/\">LinkedIn</a> \u2022 \n  <a href=\"https://www.youtube.com/channel/UCxA1YTYJ9BEeo50lxyI_B3g\">YouTube</a> \u2022 \n  <a href=\"https://join.slack.com/t/pycaret/shared_invite/zt-row9phbm-BoJdEVPYnGf7_NxNBP307w\">Slack</a>\n\n</p>\n\n[![Python](https://img.shields.io/badge/Python-3.7%20%7C%203.8%20%7C%203.9-blue)](https://badge.fury.io/py/pycaret) \n![pytest on push](https://github.com/pycaret/pycaret/workflows/pytest%20on%20push/badge.svg) \n[![Documentation Status](https://readthedocs.org/projects/pip/badge/?version=stable)](http://pip.pypa.io/en/stable/?badge=stable) \n[![PyPI version](https://badge.fury.io/py/pycaret.svg)](https://badge.fury.io/py/pycaret) \n[![License](https://img.shields.io/pypi/l/ansicolortags.svg)](https://img.shields.io/pypi/l/ansicolortags.svg) \n<!-- [![Git count](http://hits.dwyl.com/pycaret/pycaret/pycaret.svg)](http://hits.dwyl.com/pycaret/pycaret/pycaret) -->\n[![Slack](https://img.shields.io/badge/slack-chat-green.svg?logo=slack)](https://join.slack.com/t/pycaret/shared_invite/zt-row9phbm-BoJdEVPYnGf7_NxNBP307w)\n\n![alt text](docs/images/quick_start.gif)\n\n<div align=\"left\">\n  \n# Welcome to PyCaret\nPyCaret is an open-source, low-code machine learning library in Python that automates machine learning workflows. It is an end-to-end machine learning and model management tool that speeds up the experiment cycle exponentially and makes you more productive.\n\nIn comparison with the other open-source machine learning libraries, PyCaret is an alternate low-code library that can be used to replace hundreds of lines of code with few lines only. This makes experiments exponentially fast and efficient. PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as scikit-learn, XGBoost, LightGBM, CatBoost, spaCy, Optuna, Hyperopt, Ray, and few more.\n\nThe design and simplicity of PyCaret are inspired by the emerging role of citizen data scientists, a term first used by Gartner. Citizen Data Scientists are power users who can perform both simple and moderately sophisticated analytical tasks that would previously have required more technical expertise.\n\n| Important Links              |                                                                |\n| -------------------------- | -------------------------------------------------------------- |\n| :star: **[Tutorials]**        | New to PyCaret? Checkout our official notebooks!            |\n| :clipboard: **[Example Notebooks]** | Example notebooks created by community.               |\n| :orange_book: **[Official Blog]** | Tutorials and articles by contributors.                      |\n| :books: **[Documentation]**      | The detailed API docs of PyCaret                         |\n| :tv: **[Video Tutorials]**            | Our video tutorial from various events.             |\n| \u2708\ufe0f **[Cheat sheet]**            | Cheat sheet for all functions across modules.             |\n| :loudspeaker: **[Discussions]**        | Have questions? Engage with community and contributors.|\n| :hammer_and_wrench: **[Changelog]**          | Changes and version history.                 |\n| :deciduous_tree: **[Roadmap]**          | PyCaret's software and community development plan.|\n  \n[tutorials]: https://pycaret.gitbook.io/docs/get-started/tutorials\n[Example notebooks]: https://github.com/pycaret/pycaret/tree/master/examples\n[Official Blog]: https://pycaret.gitbook.io/docs/learn-pycaret/official-blog\n[Documentation]: https://pycaret.gitbook.io\n[video tutorials]: https://pycaret.gitbook.io/docs/learn-pycaret/videos\n[Cheat sheet]: https://pycaret.gitbook.io/docs/learn-pycaret/cheat-sheet\n[Discussions]: https://github.com/pycaret/pycaret/discussions\n[changelog]: https://pycaret.gitbook.io/docs/get-started/release-notes\n[roadmap]: https://github.com/pycaret/pycaret/issues/1756\n \n# Installation\n\nPyCaret's default installation only installs hard dependencies as listed in the [requirements.txt](requirements.txt) file. \n\n```python\npip install pycaret\n```\nTo install the full version:\n\n```python\npip install pycaret[full]\n```\n\n<div align=\"center\">\n\n# Supervised Workflow\n  \n  Classification           |  Regression\n:-------------------------:|:-------------------------:\n![](docs/images/pycaret_classification.png)  | ![](docs/images/pycaret_regression.png)\n\n # Unsupervised Workflow\n  \n  Clustering               |  Anomaly Detection\n:-------------------------:|:-------------------------:\n![](docs/images/pycaret_clustering.png)  |  ![](docs/images/pycaret_anomaly.png)  \n  \n<div align=\"left\">\n\n# \u26a1 PyCaret Time Series Module\n  \nPyCaret time series module is now available with the main pycaret installation. Staying true to simplicity of PyCaret, it is consistent with our existing API and fully loaded with functionalities. Statistical testing, model training and selection (30+ algorithms), model analysis, automated hyperparameter tuning, experiment logging, deployment on cloud, and more. All of this with only few lines of code (just like the other modules of pycaret). \n  \n| Important Links              |                                                                |\n| -------------------------- | -------------------------------------------------------------- |\n| :star: **[Time Series Quickstart]**        | Get started with Time Series Analysis         |\n| :books: **[Time Series Notebooks]**        | New to Time Series? Checkout our official (detailed) notebooks!            |\n| :tv: **[Time Series Video Tutorials]**            | Our video tutorial from various events.             |\n| :question: **[Time Series FAQs]**        |   Have questions? Queck out the FAQ's     |\n| :hammer_and_wrench: **[Time Series API Interface]**        |   The detailed API interface for the Time Series Module          |\n| :deciduous_tree: **[Time Series Features and Roadmap]**          | PyCaret's software and community development plan.|\n\n[Time Series Quickstart]: https://pycaret.gitbook.io/docs/get-started/quickstart#time-series\n[Time Series Notebooks]: https://pycaret.gitbook.io/docs/get-started/tutorials\n[Time Series Video Tutorials]: https://pycaret.gitbook.io/docs/learn-pycaret/videos#pycaret-time-series-module\n[Time Series FAQs]: https://github.com/pycaret/pycaret/discussions/categories/faqs?discussions_q=category%3AFAQs+label%3Atime_series\n[Time Series API Interface]: https://pycaret.readthedocs.io/en/latest/api/time_series.html\n[Time Series Features and Roadmap]: https://github.com/pycaret/pycaret/issues/1648\n  \n# Installation\n  \n ```\n pip install --pre pycaret\n ```  \n\n![alt text](docs/images/pycaret_ts_quickdemo.gif)  \n\n# Who should use PyCaret?\nPyCaret is an open source library that anybody can use. In our view the ideal target audience of PyCaret is: <br />\n\n- Experienced Data Scientists who want to increase productivity.\n- Citizen Data Scientists who prefer a low code machine learning solution.\n- Data Science Professionals who want to build rapid prototypes.\n- Data Science and Machine Learning students and enthusiasts.\n  \n# PyCaret GPU support\nWith PyCaret >= 2.2, you can train models on GPU and speed up your workflow by 10x. To train models on GPU simply pass `use_gpu = True` in the setup function. There is no change in the use of the API, however, in some cases, additional libraries have to be installed as they are not installed with the default version or the full version. As of the latest release, the following models can be trained on GPU:\n\n- Extreme Gradient Boosting (requires no further installation)\n- CatBoost (requires no further installation)\n- Light Gradient Boosting Machine requires [GPU installation](https://lightgbm.readthedocs.io/en/latest/GPU-Tutorial.html)\n- Logistic Regression, Ridge Classifier, Random Forest, K Neighbors Classifier, K Neighbors Regressor, Support Vector Machine, Linear Regression, Ridge Regression, Lasso Regression requires [cuML >= 0.15](https://github.com/rapidsai/cuml)\n\n# PyCaret Intel sklearnex support\nYou can apply [Intel optimizations](https://github.com/intel/scikit-learn-intelex) for machine learning algorithms and speed up your workflow. To train models with Intel optimizations use `sklearnex` engine. There is no change in the use of the API, however, installation of Intel sklearnex is required:\n\n```pip install scikit-learn-intelex```\n\n# License\nPyCaret is completely free and open-source and licensed under the [MIT](https://github.com/pycaret/pycaret/blob/master/LICENSE) license. \n\n# Contributors\n<a href=\"https://github.com/pycaret/pycaret/graphs/contributors\">\n  <img src=\"https://contributors-img.web.app/image?repo=pycaret/pycaret\" width = 500/>\n</a>\n",
	"ai cli data-science datascience high-performance-computing kubernetes machine-learning ml ml-infrastructure ml-platform mlops model-management productivity python r r-package reproducible-research rstats": "![Metaflow_Logo_Horizontal_FullColor_Ribbon_Dark_RGB](https://user-images.githubusercontent.com/763451/89453116-96a57e00-d713-11ea-9fa6-82b29d4d6eff.png)\n\n# Metaflow\n\nMetaflow is a human-friendly Python/R library that helps scientists and engineers build and manage real-life data science projects. Metaflow was originally developed at Netflix to boost productivity of data scientists who work on a wide variety of projects from classical statistics to state-of-the-art deep learning.\n\nFor more information, see [Metaflow's website](https://metaflow.org) and [documentation](https://docs.metaflow.org).\n\n## Getting Started\n\nGetting up and running with Metaflow is easy. \n\n### Python\nInstall metaflow from [pypi](https://pypi.org/project/metaflow/):\n\n```sh\npip install metaflow\n```\n\nand access tutorials by typing:\n\n```sh\nmetaflow tutorials pull\n```\n\n### R\n\nInstall Metaflow from [github](https://github.com/Netflix/metaflow/tree/master/R):\n\n```R\ndevtools::install_github(\"Netflix/metaflow\", subdir=\"R\")\nmetaflow::install()\n```\n\nand access tutorials by typing:\n\n```R\nmetaflow::pull_tutorials()\n```\n\n## Get in Touch\nThere are several ways to get in touch with us:\n\n* Open an issue at: https://github.com/Netflix/metaflow \n* Email us at: help@metaflow.org\n* Chat with us on: http://chat.metaflow.org \n\n## Contributing\n\nWe welcome contributions to Metaflow. Please see our [contribution guide](https://docs.metaflow.org/introduction/contributing-to-metaflow) for more details.\n\n### Code style\n\nWe use [black](https://black.readthedocs.io/en/stable/) as a code formatter. The easiest way to ensure your commits are always formatted with the correct version of `black` it is to use [pre-commit](https://pre-commit.com/): install it and then run `pre-commit install` once in your local copy of the repo.\n\n",
	"cpp deep-learning deep-neural-networks machine-learning ml neural-network python serving tensorflow": "# TensorFlow Serving\n\n[![Ubuntu Build Status](https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/ubuntu.svg)](https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/ubuntu.html)\n[![Ubuntu Build Status at TF HEAD](https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/ubuntu-tf-head.svg)](https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/ubuntu-tf-head.html)\n![Docker CPU Nightly Build Status](https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/docker-cpu-nightly.svg)\n![Docker GPU Nightly Build Status](https://storage.googleapis.com/tensorflow-serving-kokoro-build-badges-bucket/docker-gpu-nightly.svg)\n\n----\nTensorFlow Serving is a flexible, high-performance serving system for\nmachine learning models, designed for production environments. It deals with\nthe *inference* aspect of machine learning, taking models after *training* and\nmanaging their lifetimes, providing clients with versioned access via\na high-performance, reference-counted lookup table.\nTensorFlow Serving provides out-of-the-box integration with TensorFlow models,\nbut can be easily extended to serve other types of models and data.\n\nTo note a few features:\n\n-   Can serve multiple models, or multiple versions of the same model\n    simultaneously\n-   Exposes both gRPC as well as HTTP inference endpoints\n-   Allows deployment of new model versions without changing any client code\n-   Supports canarying new versions and A/B testing experimental models\n-   Adds minimal latency to inference time due to efficient, low-overhead\n    implementation\n-   Features a scheduler that groups individual inference requests into batches\n    for joint execution on GPU, with configurable latency controls\n-   Supports many *servables*: Tensorflow models, embeddings, vocabularies,\n    feature transformations and even non-Tensorflow-based machine learning\n    models\n\n## Serve a Tensorflow model in 60 seconds\n```bash\n# Download the TensorFlow Serving Docker image and repo\ndocker pull tensorflow/serving\n\ngit clone https://github.com/tensorflow/serving\n# Location of demo models\nTESTDATA=\"$(pwd)/serving/tensorflow_serving/servables/tensorflow/testdata\"\n\n# Start TensorFlow Serving container and open the REST API port\ndocker run -t --rm -p 8501:8501 \\\n    -v \"$TESTDATA/saved_model_half_plus_two_cpu:/models/half_plus_two\" \\\n    -e MODEL_NAME=half_plus_two \\\n    tensorflow/serving &\n\n# Query the model using the predict API\ncurl -d '{\"instances\": [1.0, 2.0, 5.0]}' \\\n    -X POST http://localhost:8501/v1/models/half_plus_two:predict\n\n# Returns => { \"predictions\": [2.5, 3.0, 4.5] }\n```\n\n## End-to-End Training & Serving Tutorial\n\nRefer to the official Tensorflow documentations site for [a complete tutorial to train and serve a Tensorflow Model](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple).\n\n\n## Documentation\n\n### Set up\n\nThe easiest and most straight-forward way of using TensorFlow Serving is with\nDocker images. We highly recommend this route unless you have specific needs\nthat are not addressed by running in a container.\n\n*   [Install Tensorflow Serving using Docker](tensorflow_serving/g3doc/docker.md)\n    *(Recommended)*\n*   [Install Tensorflow Serving without Docker](tensorflow_serving/g3doc/setup.md)\n    *(Not Recommended)*\n*   [Build Tensorflow Serving from Source with Docker](tensorflow_serving/g3doc/building_with_docker.md)\n*   [Deploy Tensorflow Serving on Kubernetes](tensorflow_serving/g3doc/serving_kubernetes.md)\n\n### Use\n\n#### Export your Tensorflow model\n\nIn order to serve a Tensorflow model, simply export a SavedModel from your\nTensorflow program.\n[SavedModel](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md)\nis a language-neutral, recoverable, hermetic serialization format that enables\nhigher-level systems and tools to produce, consume, and transform TensorFlow\nmodels.\n\nPlease refer to [Tensorflow documentation](https://www.tensorflow.org/guide/saved_model#save_and_restore_models)\nfor detailed instructions on how to export SavedModels.\n\n#### Configure and Use Tensorflow Serving\n\n* [Follow a tutorial on Serving Tensorflow models](tensorflow_serving/g3doc/serving_basic.md)\n* [Configure Tensorflow Serving to make it fit your serving use case](tensorflow_serving/g3doc/serving_config.md)\n* Read the [Performance Guide](tensorflow_serving/g3doc/performance.md)\nand learn how to [use TensorBoard to profile and optimize inference requests](tensorflow_serving/g3doc/tensorboard.md)\n* Read the [REST API Guide](tensorflow_serving/g3doc/api_rest.md)\nor [gRPC API definition](https://github.com/tensorflow/serving/tree/master/tensorflow_serving/apis)\n* [Use SavedModel Warmup if initial inference requests are slow due to lazy initialization of graph](tensorflow_serving/g3doc/saved_model_warmup.md)\n* [If encountering issues regarding model signatures, please read the SignatureDef documentation](tensorflow_serving/g3doc/signature_defs.md)\n* If using a model with custom ops, [learn how to serve models with custom ops](tensorflow_serving/g3doc/custom_op.md)\n\n### Extend\n\nTensorflow Serving's architecture is highly modular. You can use some parts\nindividually (e.g. batch scheduling) and/or extend it to serve new use cases.\n\n* [Ensure you are familiar with building Tensorflow Serving](tensorflow_serving/g3doc/building_with_docker.md)\n* [Learn about Tensorflow Serving's architecture](tensorflow_serving/g3doc/architecture.md)\n* [Explore the Tensorflow Serving C++ API reference](https://www.tensorflow.org/tfx/serving/api_docs/cc/)\n* [Create a new type of Servable](tensorflow_serving/g3doc/custom_servable.md)\n* [Create a custom Source of Servable versions](tensorflow_serving/g3doc/custom_source.md)\n\n## Contribute\n\n\n**If you'd like to contribute to TensorFlow Serving, be sure to review the\n[contribution guidelines](CONTRIBUTING.md).**\n\n\n## For more information\n\nPlease refer to the official [TensorFlow website](http://tensorflow.org) for\nmore information.\n",
	"analytics charts google-analytics statistics web-analytics": "# umami\n\nUmami is a simple, fast, privacy-focused alternative to Google Analytics.\n\n## Getting started\n\nA detailed getting started guide can be found at [https://umami.is/docs/](https://umami.is/docs/)\n\n## Installing from source\n\n### Requirements\n\n- A server with Node.js version 12 or newer\n- A database. Umami supports [MySQL](https://www.mysql.com/) and [Postgresql](https://www.postgresql.org/) databases.\n\n### Install Yarn\n\n```\nnpm install -g yarn\n```\n\n### Get the source code and install packages\n\n```\ngit clone https://github.com/umami-software/umami.git\ncd umami\nyarn install\n```\n\n### Configure umami\n\nCreate an `.env` file with the following\n\n```\nDATABASE_URL=connection-url\n```\n\nThe connection url is in the following format:\n```\npostgresql://username:mypassword@localhost:5432/mydb\n\nmysql://username:mypassword@localhost:3306/mydb\n```\n\n### Build the application\n\n```bash\nyarn build\n```\n\nThe build step will also create tables in your database if you ae installing for the first time. It will also create a login account with username **admin** and password **umami**.\n\n### Start the application\n\n```bash\nyarn start\n```\n\nBy default this will launch the application on `http://localhost:3000`. You will need to either\n[proxy](https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/) requests from your web server\nor change the [port](https://nextjs.org/docs/api-reference/cli#production) to serve the application directly.\n\n## Installing with Docker\n\nTo build the umami container and start up a Postgres database, run:\n\n```bash\ndocker compose up\n```\n\nAlternatively, to pull just the Umami Docker image with PostgreSQL support:\n```bash\ndocker pull docker.umami.dev/umami-software/umami:postgresql-latest\n```\n\nOr with MySQL support:\n```bash\ndocker pull docker.umami.dev/umami-software/umami:mysql-latest\n```\n\n## Getting updates\n\nTo get the latest features, simply do a pull, install any new dependencies, and rebuild:\n\n```bash\ngit pull\nyarn install\nyarn build\n```\n\nTo update the Docker image, simply pull the new images and rebuild:\n\n```bash\ndocker compose pull\ndocker compose up --force-recreate\n```\n\n## License\n\nMIT\n",
	"analytics data-science ecma-376 excel excelize formula go golang microsoft office ole ooxml openoffice openxml spreadsheet statistics visualization xlsm xlsx": "<p align=\"center\"><img width=\"650\" src=\"./excelize.svg\" alt=\"Excelize logo\"></p>\n\n<p align=\"center\">\n    <a href=\"https://github.com/xuri/excelize/actions/workflows/go.yml\"><img src=\"https://github.com/xuri/excelize/actions/workflows/go.yml/badge.svg\" alt=\"Build Status\"></a>\n    <a href=\"https://codecov.io/gh/qax-os/excelize\"><img src=\"https://codecov.io/gh/qax-os/excelize/branch/master/graph/badge.svg\" alt=\"Code Coverage\"></a>\n    <a href=\"https://goreportcard.com/report/github.com/xuri/excelize/v2\"><img src=\"https://goreportcard.com/badge/github.com/xuri/excelize/v2\" alt=\"Go Report Card\"></a>\n    <a href=\"https://pkg.go.dev/github.com/xuri/excelize/v2\"><img src=\"https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white\" alt=\"go.dev\"></a>\n    <a href=\"https://opensource.org/licenses/BSD-3-Clause\"><img src=\"https://img.shields.io/badge/license-bsd-orange.svg\" alt=\"Licenses\"></a>\n    <a href=\"https://www.paypal.com/paypalme/xuri\"><img src=\"https://img.shields.io/badge/Donate-PayPal-green.svg\" alt=\"Donate\"></a>\n</p>\n\n# Excelize\n\n## Introduction\n\nExcelize is a library written in pure Go providing a set of functions that allow you to write to and read from XLAM / XLSM / XLSX / XLTM / XLTX files. Supports reading and writing spreadsheet documents generated by Microsoft Excel&trade; 2007 and later. Supports complex components by high compatibility, and provided streaming API for generating or reading data from a worksheet with huge amounts of data. This library needs Go version 1.16 or later. The full docs can be seen using go's built-in documentation tool, or online at [go.dev](https://pkg.go.dev/github.com/xuri/excelize/v2) and [docs reference](https://xuri.me/excelize/).\n\n## Basic Usage\n\n### Installation\n\n```bash\ngo get github.com/xuri/excelize\n```\n\n- If your packages are managed using [Go Modules](https://go.dev/blog/using-go-modules), please install with following command.\n\n```bash\ngo get github.com/xuri/excelize/v2\n```\n\n### Create spreadsheet\n\nHere is a minimal example usage that will create spreadsheet file.\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n\n    \"github.com/xuri/excelize/v2\"\n)\n\nfunc main() {\n    f := excelize.NewFile()\n    // Create a new sheet.\n    index := f.NewSheet(\"Sheet2\")\n    // Set value of a cell.\n    f.SetCellValue(\"Sheet2\", \"A2\", \"Hello world.\")\n    f.SetCellValue(\"Sheet1\", \"B2\", 100)\n    // Set active sheet of the workbook.\n    f.SetActiveSheet(index)\n    // Save spreadsheet by the given path.\n    if err := f.SaveAs(\"Book1.xlsx\"); err != nil {\n        fmt.Println(err)\n    }\n}\n```\n\n### Reading spreadsheet\n\nThe following constitutes the bare to read a spreadsheet document.\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n\n    \"github.com/xuri/excelize/v2\"\n)\n\nfunc main() {\n    f, err := excelize.OpenFile(\"Book1.xlsx\")\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    defer func() {\n        // Close the spreadsheet.\n        if err := f.Close(); err != nil {\n            fmt.Println(err)\n        }\n    }()\n    // Get value from cell by given worksheet name and cell reference.\n    cell, err := f.GetCellValue(\"Sheet1\", \"B2\")\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    fmt.Println(cell)\n    // Get all the rows in the Sheet1.\n    rows, err := f.GetRows(\"Sheet1\")\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    for _, row := range rows {\n        for _, colCell := range row {\n            fmt.Print(colCell, \"\\t\")\n        }\n        fmt.Println()\n    }\n}\n```\n\n### Add chart to spreadsheet file\n\nWith Excelize chart generation and management is as easy as a few lines of code. You can build charts based on data in your worksheet or generate charts without any data in your worksheet at all.\n\n<p align=\"center\"><img width=\"650\" src=\"./test/images/chart.png\" alt=\"Excelize\"></p>\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n\n    \"github.com/xuri/excelize/v2\"\n)\n\nfunc main() {\n    categories := map[string]string{\n        \"A2\": \"Small\", \"A3\": \"Normal\", \"A4\": \"Large\",\n        \"B1\": \"Apple\", \"C1\": \"Orange\", \"D1\": \"Pear\"}\n    values := map[string]int{\n        \"B2\": 2, \"C2\": 3, \"D2\": 3, \"B3\": 5, \"C3\": 2, \"D3\": 4, \"B4\": 6, \"C4\": 7, \"D4\": 8}\n    f := excelize.NewFile()\n    for k, v := range categories {\n        f.SetCellValue(\"Sheet1\", k, v)\n    }\n    for k, v := range values {\n        f.SetCellValue(\"Sheet1\", k, v)\n    }\n    if err := f.AddChart(\"Sheet1\", \"E1\", `{\n        \"type\": \"col3DClustered\",\n        \"series\": [\n        {\n            \"name\": \"Sheet1!$A$2\",\n            \"categories\": \"Sheet1!$B$1:$D$1\",\n            \"values\": \"Sheet1!$B$2:$D$2\"\n        },\n        {\n            \"name\": \"Sheet1!$A$3\",\n            \"categories\": \"Sheet1!$B$1:$D$1\",\n            \"values\": \"Sheet1!$B$3:$D$3\"\n        },\n        {\n            \"name\": \"Sheet1!$A$4\",\n            \"categories\": \"Sheet1!$B$1:$D$1\",\n            \"values\": \"Sheet1!$B$4:$D$4\"\n        }],\n        \"title\":\n        {\n            \"name\": \"Fruit 3D Clustered Column Chart\"\n        }\n    }`); err != nil {\n        fmt.Println(err)\n        return\n    }\n    // Save spreadsheet by the given path.\n    if err := f.SaveAs(\"Book1.xlsx\"); err != nil {\n        fmt.Println(err)\n    }\n}\n```\n\n### Add picture to spreadsheet file\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    _ \"image/gif\"\n    _ \"image/jpeg\"\n    _ \"image/png\"\n\n    \"github.com/xuri/excelize/v2\"\n)\n\nfunc main() {\n    f, err := excelize.OpenFile(\"Book1.xlsx\")\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    defer func() {\n        // Close the spreadsheet.\n        if err := f.Close(); err != nil {\n            fmt.Println(err)\n        }\n    }()\n    // Insert a picture.\n    if err := f.AddPicture(\"Sheet1\", \"A2\", \"image.png\", \"\"); err != nil {\n        fmt.Println(err)\n    }\n    // Insert a picture to worksheet with scaling.\n    if err := f.AddPicture(\"Sheet1\", \"D2\", \"image.jpg\",\n        `{\"x_scale\": 0.5, \"y_scale\": 0.5}`); err != nil {\n        fmt.Println(err)\n    }\n    // Insert a picture offset in the cell with printing support.\n    if err := f.AddPicture(\"Sheet1\", \"H2\", \"image.gif\", `{\n        \"x_offset\": 15,\n        \"y_offset\": 10,\n        \"print_obj\": true,\n        \"lock_aspect_ratio\": false,\n        \"locked\": false\n    }`); err != nil {\n        fmt.Println(err)\n    }\n    // Save the spreadsheet with the origin path.\n    if err = f.Save(); err != nil {\n        fmt.Println(err)\n    }\n}\n```\n\n## Contributing\n\nContributions are welcome! Open a pull request to fix a bug, or open an issue to discuss a new feature or change. XML is compliant with [part 1 of the 5th edition of the ECMA-376 Standard for Office Open XML](https://www.ecma-international.org/publications-and-standards/standards/ecma-376/).\n\n## Licenses\n\nThis program is under the terms of the BSD 3-Clause License. See [https://opensource.org/licenses/BSD-3-Clause](https://opensource.org/licenses/BSD-3-Clause).\n\nThe Excel logo is a trademark of [Microsoft Corporation](https://aka.ms/trademarks-usage). This artwork is an adaptation.\n\ngopher.{ai,svg,png} was created by [Takuya Ueda](https://twitter.com/tenntenn). Licensed under the [Creative Commons 3.0 Attributions license](http://creativecommons.org/licenses/by/3.0/).\n",
	"analytics charts clickhouse cloud elixir google-analytics marketing metrics phoenix plausible-analytics postgresql privacy statistics tailwindcss web-analytics website website-analytics website-stats": "# Plausible Analytics\n\n<p align=\"center\">\n  <a href=\"https://plausible.io/\">\n    <img src=\"https://raw.githubusercontent.com/plausible/docs/master/static/img/plausible-analytics-icon-top.png\" width=\"140px\" alt=\"Plausible Analytics\" />\n  </a>\n</p>\n<p align=\"center\">\n    <a href=\"https://plausible.io/simple-web-analytics\">Simple Metrics</a> |\n    <a href=\"https://plausible.io/lightweight-web-analytics\">Lightweight Script</a> |\n    <a href=\"https://plausible.io/privacy-focused-web-analytics\">Privacy Focused</a> |\n    <a href=\"https://plausible.io/open-source-website-analytics\">Open Source</a> |\n    <a href=\"https://plausible.io/docs\">Docs</a> |\n    <a href=\"https://github.com/plausible/analytics/blob/master/CONTRIBUTING.md\">Contributing</a>\n    <br /><br />\n</p>\n\n[Plausible Analytics](https://plausible.io/) is a simple, lightweight (< 1 KB), open source and privacy-friendly alternative to Google Analytics. It doesn\u2019t use cookies and is fully compliant with GDPR, CCPA and PECR. You can self-host or have us run Plausible for you in the cloud. Here's [the live demo of our own website stats](https://plausible.io/plausible.io). Made and hosted in the EU \ud83c\uddea\ud83c\uddfa\n\nWe are dedicated to making web analytics more privacy-friendly. Our mission is to reduce corporate surveillance by providing an alternative web analytics tool which doesn\u2019t come from the AdTech world. We are completely independent and solely funded by our subscribers.\n\n![Plausible Analytics](https://plausible.io/docs/img/plausible-analytics.png)\n\n## Why Plausible?\n\nHere's what makes Plausible a great Google Analytics alternative and why we're trusted by thousands of paying subscribers to deliver their website and business insights:\n\n- **Clutter Free**: Plausible Analytics provides [simple web analytics](https://plausible.io/simple-web-analytics) and it cuts through the noise. No layers of menus, no need for custom reports. Get all the important insights on one single page. No training necessary.\n- **GDPR/CCPA/PECR compliant**: Measure traffic, not individuals. No personal data or IP addresses are ever stored in our database. We don't use cookies or any other persistent identifiers. [Read more about our data policy](https://plausible.io/data-policy)\n- **Lightweight**: Plausible Analytics works by loading a script on your website, like Google Analytics. Our script is [45x smaller](https://plausible.io/lightweight-web-analytics), making your website quicker to load.\n- **Email or Slack reports**: Keep an eye on your traffic with weekly and/or monthly email or Slack reports. You can also get traffic spike notifications.\n- **Open website stats**: You have the option to be transparent and open your web analytics to everyone. Your website stats are private by default but you can choose to make them public so anyone with your custom link can view them.\n- **Define key goals and track conversions**: Set custom events or page URLs as your goals and see how they convert over time to understand and identify the trends that matter. Includes easy ways to track outbound link clicks and 404 error pages.\n- **Search keywords**: Integrate your dashboard with Google Search Console to get the most accurate reporting on your search keywords.\n- **SPA support**: Plausible is built with modern web frameworks in mind and it works automatically with any pushState based router on the frontend. We also support frameworks that use the URL hash for routing. See [our documentation](https://plausible.io/docs/hash-based-routing).\n\nInterested to learn more? [Read more on our website](https://plausible.io), learn more about the team and the goals of the project on [our about page](https://plausible.io/about) or explore [the documentation](https://plausible.io/docs).\n\n## Why is Plausible Analytics Cloud not free like Google Analytics?\n\nPlausible Analytics is an independently owned and actively developed project. To keep the project development going, to stay in business, to continue putting effort into building a better product and to cover our costs, we need to charge a fee.\n\nGoogle Analytics is free because Google has built their company and their wealth by collecting and analyzing huge amounts of personal information from web users and using these personal and behavioral insights to sell advertisements.\n\nPlausible has no part in that business model. No personal data is being collected and analyzed either. With Plausible, you 100% own and control all of your website data. This data is not being shared with or sold to any third-parties.\n\nWe choose the subscription business model rather than the business model of surveillance capitalism. See reasons why we believe you should [stop using Google Analytics on your website](https://plausible.io/blog/remove-google-analytics).\n\n## Getting started with Plausible\n\nThe easiest way to get started with Plausible is with [our official managed service in the cloud](https://plausible.io/#pricing). It takes 2 minutes to start counting your stats with a worldwide CDN, high availability, backups, security and maintenance all done for you by us.\n\nIn order to be compliant with the GDPR and the Schrems II ruling, all visitor data for our managed service in the cloud is exclusively processed on servers and cloud infrastructure owned and operated by European providers. Your website data never leaves the EU.\n\nOur managed hosting can save a substantial amount of developer time and resources. For most sites this ends up being the best value option and the revenue goes to funding the maintenance and further development of Plausible. So you\u2019ll be supporting open source software and getting a great service!\n\n### Can Plausible Analytics be self-hosted?\n\nPlausible is fully [open source web analytics](https://plausible.io/open-source-website-analytics) and we have a free as in beer [Plausible Analytics Self-Hosted](https://plausible.io/self-hosted-web-analytics) solution. It\u2019s exactly the same product as our cloud solution with a less frequent release schedule (think of it as a long term support release).\n\nBug fixes and new features are released to the cloud version several times per week. Features are battle-tested in the cloud which allows us to fix any bugs before the general self-hosted release. Every six months or so we combine all the changes into a new self-hosted release.\n\nThe main difference between the two is that the self-hosted version you have to install, host and manage yourself on your own infrastructure while the cloud version we manage everything for your ease and convenience. Here's the overview of all the differences:\n\n|  | Plausible Cloud  | Self-Hosting |\n| ------------- | ------------- | ------------- |\n| Hosting | Easy and convenient. It takes 2 minutes to start counting your stats with a worldwide CDN, high availability, backups, security and maintenance all done for you by us. We manage everything so you don\u2019t have to worry about anything and can focus on your stats. | You do it all yourself. You need to get a server and you need to manage your infrastructure. You are responsible for installation, maintenance, upgrades, server capacity, uptime, backup, security, stability, consistency, loading time and so on. |\n| Storage | All visitor data is exclusively processed on EU-owned cloud infrastructure. We keep your site data on a secure, encrypted and green energy powered server in Germany. This ensures that your site data is protected by the strict European Union data privacy laws and ensures compliance with GDPR. Your website data never leaves the EU. | You have full control and can host your instance on any server in any country that you wish. Host it on a server in your basement or host it with any cloud provider wherever you want, even those that are not GDPR compliant. |\n| Releases | Continuously developed and improved with new features and updates multiple times per week. | [It's a long term release](https://plausible.io/blog/building-open-source) published approximately twice per year so latest features won't be immediately available. You can see all the [currently unreleased features in the changelog](https://github.com/plausible/analytics/blob/master/CHANGELOG.md).|\n| Raw data | You see all your site stats and metrics on our modern-looking, simple to use and fast loading dashboard. You can only see the stats aggregated in the dashboard. | Are you an analyst and want access to the raw data? Hosting Plausible yourself gives you that option. Take the data directly from the ClickHouse database and import it to a data analysis tool of your choice. |\n| Premium Support | Real support delivered by real human beings who build and maintain Plausible. | Premium support is not included. Self-hosting is community supported only. |\n| Costs | There's a cost associated with providing an analytics service so we charge a subscription fee. We choose the subscription business model rather than the business model of surveillance capitalism. Your money funds further developement of Plausible. | You need to pay for your server, CDN, backups and whatever other cost there is associated with running the infrastructure. You never have to pay any fees to us. Your money goes to 3rd party companies with no connection to us.|\n\nInterested in self-hosting Plausible on your server? Take a look at our [self-hosting installation instructions](https://plausible.io/docs/self-hosting).\n\nPlausible Self-Hosted is a community supported project and there are no guarantees that you will get support from the creators of Plausible to troubleshoot your self-hosting issues. There is a [community supported forum](https://github.com/plausible/analytics/discussions/categories/self-hosted-support) where you can ask for help.\n\nOur only source of funding is our premium, managed service for running Plausible in the cloud. If you're looking for an alternative way to support the project, we've put together some sponsorship packages. If you choose to self-host Plausible you can [become a sponsor](https://github.com/sponsors/plausible) which is a great way to give back to the community and to contribute to the long-term sustainability of the project.\n \n## Technology\n\nPlausible Analytics is a standard Elixir/Phoenix application backed by a PostgreSQL database for general data and a Clickhouse\ndatabase for stats. On the frontend we use [TailwindCSS](https://tailwindcss.com/) for styling and React to make the dashboard interactive.\n\n## Contributors\n\nFor anyone wishing to contribute to Plausible, we recommend taking a look at [our contributor guide](https://github.com/plausible/analytics/blob/master/CONTRIBUTING.md).\n\n<a href=\"https://github.com/plausible/analytics/graphs/contributors\"><img src=\"https://opencollective.com/plausible/contributors.svg?width=800&button=false\" /></a>\n\n## Feedback & Roadmap\n\nWe welcome feedback from our community. We have a public roadmap driven by the features suggested by the community members. Take a look at our [feedback board](https://plausible.io/feedback) directly here on GitHub. Please let us know if you have any requests and vote on open issues so we can better prioritize.\n\nTo stay up to date with all the latest news and product updates, make sure to follow us on [Twitter](https://twitter.com/plausiblehq), [LinkedIn](https://www.linkedin.com/company/plausible-analytics/) or [Mastodon](https://fosstodon.org/@plausible).\n\n## License\n\nPlausible is open-source under the GNU Affero General Public License Version 3 (AGPLv3) or any later version. You can [find it here](https://github.com/plausible/analytics/blob/master/LICENSE.md).\n\nThe only exception is our JavaScript tracker which gets included on your website. To avoid issues with AGPL virality, we've\nreleased the tracker under the MIT license. You can [find it here](https://github.com/plausible/analytics/blob/master/tracker/LICENSE.md).\n",
	"badge cli cloc code command-line-tool linux macos rust sloc statistics tokei windows": "# Tokei ([\u6642\u8a08](https://en.wiktionary.org/wiki/%E6%99%82%E8%A8%88))\r\n[![Mean Bean CI](https://github.com/XAMPPRocky/tokei/workflows/Mean%20Bean%20CI/badge.svg)](https://github.com/XAMPPRocky/tokei/actions?query=workflow%3A%22Mean+Bean+CI%22)\r\n[![Help Wanted](https://img.shields.io/github/issues/XAMPPRocky/tokei/help%20wanted?color=green)](https://github.com/XAMPPRocky/tokei/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22)\r\n[![Lines Of Code](https://tokei.rs/b1/github/XAMPPRocky/tokei?category=code)](https://github.com/XAMPPRocky/tokei)\r\n[![Documentation](https://docs.rs/tokei/badge.svg)](https://docs.rs/tokei/)\r\n![](https://img.shields.io/crates/d/tokei?label=downloads%20%28crates.io%29)\r\n![](https://img.shields.io/github/downloads/xampprocky/tokei/total?label=downloads%20%28GH%29)\r\n![](https://img.shields.io/homebrew/installs/dy/tokei?color=brightgreen&label=downloads%20%28brew%29)\r\n\r\nTokei is a program that displays statistics about your code. Tokei will show the number of files, total lines within those files and code, comments, and blanks grouped by language.\r\n\r\n### Translations\r\n- [\u4e2d\u6587](https://github.com/chinanf-boy/tokei-zh#\u652f\u6301\u7684\u8bed\u8a00)\r\n\r\n## Example\r\n```console\r\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\r\n Language            Files        Lines         Code     Comments       Blanks\r\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\r\n BASH                    4           49           30           10            9\r\n JSON                    1         1332         1332            0            0\r\n Shell                   1           49           38            1           10\r\n TOML                    2           77           64            4            9\r\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n Markdown                5         1355            0         1074          281\r\n |- JSON                 1           41           41            0            0\r\n |- Rust                 2           53           42            6            5\r\n |- Shell                1           22           18            0            4\r\n (Total)                           1471          101         1080          290\r\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n Rust                   19         3416         2840          116          460\r\n |- Markdown            12          351            5          295           51\r\n (Total)                           3767         2845          411          511\r\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\r\n Total                  32         6745         4410         1506          829\r\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\r\n```\r\n\r\n## [API Documentation](https://docs.rs/tokei)\r\n\r\n## Table of Contents\r\n\r\n- [Features](#features)\r\n- [Installation](#installation)\r\n    - [Package Managers](#package-managers)\r\n    - [Manual](#manual)\r\n- [Configuration](#configuration)\r\n- [How to use Tokei](#how-to-use-tokei)\r\n- [Options](#options)\r\n- [Badges](#badges)\r\n- [Supported Languages](#supported-languages)\r\n- [Changelog](CHANGELOG.md)\r\n- [Common Issues](#common-issues)\r\n- [Canonical Source](#canonical-source)\r\n- [Copyright and License](#copyright-and-license)\r\n\r\n## Features\r\n\r\n- Tokei is **very fast**, and is able to count millions of lines of code in seconds.\r\n  Check out the [12.0.0 release](https://github.com/XAMPPRocky/tokei/releases/v12.0.0)\r\n  to see how Tokei's speed compares to others.\r\n\r\n- Tokei is **accurate**, Tokei correctly handles multi line comments,\r\n  nested comments, and not counting comments that are in strings. Providing an\r\n  accurate code statistics.\r\n\r\n- Tokei has huge range of languages, supporting over **150** languages, and\r\n  their various extensions.\r\n\r\n- Tokei can output in multiple formats(**CBOR**, **JSON**, **YAML**)\r\n  allowing Tokei's output to be easily stored, and reused. These can also be\r\n  reused in tokei combining a previous run's statistics with another set.\r\n\r\n- Tokei is available on **Mac**, **Linux**, and **Windows**. See [installation\r\n  instructions](#installation) for how to get Tokei on your platform.\r\n\r\n- Tokei is also a **library** allowing you to easily integrate it with other\r\n  projects.\r\n\r\n- Tokei comes with and without color. Set the env variable NO_COLOR to 1, and\r\n  it'll be black and white.\r\n\r\n## Installation\r\n\r\n### Package Managers\r\n\r\n#### Unix\r\n```console\r\n# Alpine Linux (since 3.13)\r\napk add tokei\r\n# Arch Linux\r\npacman -S tokei\r\n# Cargo\r\ncargo install tokei\r\n# Conda\r\nconda install -c conda-forge tokei\r\n# Fedora\r\nsudo dnf install tokei\r\n# FreeBSD\r\npkg install tokei\r\n# NetBSD\r\npkgin install tokei\r\n# Nix/NixOS\r\nnix-env -i tokei\r\n# OpenSUSE\r\nsudo zypper install tokei\r\n```\r\n\r\n#### macOS\r\n```console\r\n# Homebrew\r\nbrew install tokei\r\n# MacPorts\r\nsudo port selfupdate\r\nsudo port install tokei\r\n```\r\n\r\n#### Windows\r\n```console\r\nscoop install tokei\r\n```\r\n\r\n### Manual\r\n\r\n#### Downloading\r\nYou can download prebuilt binaries in the\r\n[releases section](https://github.com/XAMPPRocky/tokei/releases).\r\n\r\n#### Building\r\nYou can also build and install from source (requires the latest stable [Rust] compiler.)\r\n```console\r\ncargo install --git https://github.com/XAMPPRocky/tokei.git tokei\r\n```\r\n\r\n[rust]: https://www.rust-lang.org\r\n\r\n\r\n## Configuration\r\n\r\nTokei has a [configuration] file that allows you to change default behaviour.\r\nThe file can be named `tokei.toml` or `.tokeirc`. Currently tokei looks for\r\nthis file in three different places. The current directory, your home directory,\r\nand your configuration directory.\r\n\r\n## How to use Tokei\r\n\r\n#### Basic usage\r\n\r\nThis is the basic way to use tokei. Which will report on the code in `./foo`\r\nand all subfolders.\r\n\r\n```shell\r\n$ tokei ./foo\r\n```\r\n\r\n[configuration]: ./tokei.example.toml\r\n\r\n#### Multiple folders\r\nTo have tokei report on multiple folders in the same call simply add a comma,\r\nor a space followed by another path.\r\n\r\n```shell\r\n$ tokei ./foo ./bar ./baz\r\n```\r\n```shell\r\n$ tokei ./foo, ./bar, ./baz\r\n```\r\n\r\n#### Excluding folders\r\nTokei will respect all `.gitignore` and `.ignore` files, and you can use\r\nthe `--exclude` option to exclude any additional files. The `--exclude` flag has\r\nthe same semantics as `.gitignore`.\r\n\r\n```shell\r\n$ tokei ./foo --exclude *.rs\r\n```\r\n\r\nPaths to exclude can also be listed in a `.tokeignore` file, using the same\r\n[syntax](https://git-scm.com/docs/gitignore) as .gitignore files.\r\n\r\n#### Sorting output\r\nBy default tokei sorts alphabetically by language name, however using `--sort`\r\ntokei can also sort by any of the columns.\r\n\r\n`blanks, code, comments, lines`\r\n\r\n```shell\r\n$ tokei ./foo --sort code\r\n```\r\n\r\n#### Outputting file statistics\r\nBy default tokei only outputs the total of the languages, and using `--files`\r\nflag tokei can also output individual file statistics.\r\n\r\n```shell\r\n$ tokei ./foo --files\r\n```\r\n\r\n#### Outputting into different formats\r\nTokei normally outputs into a nice human readable format designed for terminals.\r\nThere is also using the `--output` option various other formats that are more\r\nuseful for bringing the data into another program.\r\n\r\n**Note:** This version of tokei was compiled without any serialization formats, to enable serialization, reinstall\r\ntokei with the features flag.\r\n\r\n```shell\r\n  ALL:\r\n  cargo install tokei --features all\r\n\r\n  CBOR:\r\n  cargo install tokei --features cbor\r\n\r\n  YAML:\r\n  cargo install tokei --features yaml\r\n```\r\n\r\n**Currently supported formats**\r\n- JSON `--output json`\r\n- YAML `--output yaml`\r\n- CBOR `--output cbor`\r\n\r\n```shell\r\n$ tokei ./foo --output json\r\n```\r\n\r\n#### Reading in stored formats\r\nTokei can also take in the outputted formats added in the previous results to its\r\ncurrent run. Tokei can take either a path to a file, the format passed in as a\r\nvalue to the option, or from stdin.\r\n\r\n```shell\r\n$ tokei ./foo --input ./stats.json\r\n```\r\n\r\n## Options\r\n\r\n```\r\nUSAGE:\r\n    tokei [FLAGS] [OPTIONS] [--] [input]...\r\n\r\nFLAGS:\r\n    -f, --files               Will print out statistics on individual files.\r\n    -h, --help                Prints help information\r\n        --hidden              Count hidden files.\r\n    -l, --languages           Prints out supported languages and their extensions.\r\n        --no-ignore           Don't respect ignore files (.gitignore, .ignore, etc.). This implies --no-ignore-parent,\r\n                              --no-ignore-dot, and --no-ignore-vcs.\r\n        --no-ignore-dot       Don't respect .ignore and .tokeignore files, including those in parent directories.\r\n        --no-ignore-parent    Don't respect ignore files (.gitignore, .ignore, etc.) in parent directories.\r\n        --no-ignore-vcs       Don't respect VCS ignore files (.gitignore, .hgignore, etc.), including those in parent\r\n                              directories.\r\n    -V, --version             Prints version information\r\n    -v, --verbose             Set log output level:\r\n                                          1: to show unknown file extensions,\r\n                                          2: reserved for future debugging,\r\n                                          3: enable file level trace. Not recommended on multiple files\r\n\r\nOPTIONS:\r\n    -c, --columns <columns>       Sets a strict column width of the output, only available for terminal output.\r\n    -e, --exclude <exclude>...    Ignore all files & directories matching the pattern.\r\n    -i, --input <file_input>      Gives statistics from a previous tokei run. Can be given a file path, or \"stdin\" to\r\n                                  read from stdin.\r\n    -o, --output <output>         Outputs Tokei in a specific format. Compile with additional features for more format\r\n                                  support. [possible values: cbor, json, yaml]\r\n    -s, --sort <sort>             Sort languages based on column [possible values: files, lines, blanks, code, comments]\r\n    -t, --type <types>            Filters output by language type, separated by a comma. i.e. -t=Rust,Markdown\r\n\r\nARGS:\r\n    <input>...    The path(s) to the file or directory to be counted.\r\n```\r\n\r\n## Badges\r\nTokei has support for badges. For example\r\n[![](https://tokei.rs/b1/github/XAMPPRocky/tokei)](https://github.com/XAMPPRocky/tokei).\r\n\r\n```\r\n[![](https://tokei.rs/b1/github/XAMPPRocky/tokei)](https://github.com/XAMPPRocky/tokei).\r\n```\r\n\r\nTokei's URL scheme is as follows.\r\n\r\n```\r\nhttps://tokei.rs/b1/{host: values: github|gitlab}/{Repo Owner eg: XAMPPRocky}/{Repo name eg: tokei}\r\n```\r\n\r\nBy default the badge will show the repo's LoC(_Lines of Code_), you can also\r\nspecify for it to show a different category, by using the `?category=` query\r\nstring. It can be either `code`, `blanks`, `files`, `lines`, `comments`,\r\nExample show total lines:\r\n\r\n```\r\n[![](https://tokei.rs/b1/github/XAMPPRocky/tokei?category=lines)](https://github.com/XAMPPRocky/tokei).\r\n```\r\n\r\nThe server code hosted on tokei.rs is in [XAMPPRocky/tokei_rs](https://github.com/XAMPPRocky/tokei_rs)\r\n\r\n## Supported Languages\r\n\r\nIf there is a language that you would to add to tokei feel free to make a pull\r\nrequest. Languages are defined in [`languages.json`](./languages.json), and you can\r\nread how to add and test your language in our [CONTRIBUTING.md](./CONTRIBUTING.md).\r\n\r\n```\r\nAbap\r\nActionScript\r\nAda\r\nAgda\r\nAlex\r\nAlloy\r\nAsn1\r\nAsp\r\nAspNet\r\nAssembly\r\nAssemblyGAS\r\nATS\r\nAutoconf\r\nAutoHotKey\r\nAutomake\r\nAWK\r\nBash\r\nBatch\r\nBrightScript\r\nC\r\nCabal\r\nCassius\r\nCeylon\r\nCHeader\r\nClojure\r\nClojureC\r\nClojureScript\r\nCMake\r\nCobol\r\nCoffeeScript\r\nCogent\r\nColdFusion\r\nColdFusionScript\r\nCoq\r\nCpp\r\nCppHeader\r\nCrystal\r\nCSharp\r\nCShell\r\nCss\r\nCuda\r\nCython\r\nD\r\nDAML\r\nDart\r\nDeviceTree\r\nDhall\r\nDockerfile\r\nDotNetResource\r\nDreamMaker\r\nDust\r\nEdn\r\nElisp\r\nElixir\r\nElm\r\nElvish\r\nEmacsDevEnv\r\nEmojicode\r\nErlang\r\nFactor\r\nFEN\r\nFish\r\nFlatBuffers\r\nForgeConfig\r\nForth\r\nFortranLegacy\r\nFortranModern\r\nFreeMarker\r\nFSharp\r\nFstar\r\nGDB\r\nGdScript\r\nGherkin\r\nGleam\r\nGlsl\r\nGo\r\nGraphql\r\nGroovy\r\nGwion\r\nHamlet\r\nHandlebars\r\nHappy\r\nHaskell\r\nHaxe\r\nHcl\r\nHex\r\nHlsl\r\nHolyC\r\nHtml\r\nIdris\r\nIni\r\nIntelHex\r\nIsabelle\r\nJai\r\nJava\r\nJavaScript\r\nJson\r\nJsx\r\nJulia\r\nJulius\r\nKakouneScript\r\nKotlin\r\nLean\r\nLess\r\nLinkerScript\r\nLiquid\r\nLisp\r\nLLVM\r\nLogtalk\r\nLua\r\nLucius\r\nMadlang\r\nMakefile\r\nMarkdown\r\nMeson\r\nMint\r\nMlatu\r\nModuleDef\r\nMoonScript\r\nMsBuild\r\nMustache\r\nNim\r\nNix\r\nNotQuitePerl\r\nObjectiveC\r\nObjectiveCpp\r\nOCaml\r\nOdin\r\nOrg\r\nOz\r\nPascal\r\nPerl\r\nPerl6\r\nPest\r\nPhp\r\nPoke\r\nPolly\r\nPony\r\nPostCss\r\nPowerShell\r\nProcessing\r\nProlog\r\nProtobuf\r\nPSL\r\nPureScript\r\nPython\r\nQcl\r\nQml\r\nR\r\nRacket\r\nRakefile\r\nRazor\r\nRenpy\r\nReStructuredText\r\nRON\r\nRPMSpecfile\r\nRuby\r\nRubyHtml\r\nRust\r\nSass\r\nScala\r\nScheme\r\nScons\r\nSh\r\nShaderLab\r\nSml\r\nSolidity\r\nSpecmanE\r\nSpice\r\nSql\r\nSRecode\r\nStratego\r\nSvelte\r\nSvg\r\nSwift\r\nSwig\r\nSystemVerilog\r\nTcl\r\nTex\r\nText\r\nThrift\r\nToml\r\nTsx\r\nTwig\r\nTypeScript\r\nUMPL\r\nUnrealDeveloperMarkdown\r\nUnrealPlugin\r\nUnrealProject\r\nUnrealScript\r\nUnrealShader\r\nUnrealShaderHeader\r\nUrWeb\r\nUrWebProject\r\nVala\r\nVB6\r\nVBScript\r\nVelocity\r\nVerilog\r\nVerilogArgsFile\r\nVhdl\r\nVimScript\r\nVisualBasic\r\nVisualStudioProject\r\nVisualStudioSolution\r\nVue\r\nWebAssembly\r\nWolfram\r\nXaml\r\nXcodeConfig\r\nXml\r\nXSL\r\nXtend\r\nYaml\r\nZenCode\r\nZig\r\nZsh\r\n```\r\n\r\n## Common issues\r\n\r\n### Tokei says I have a lot of D code, but I know there is no D code!\r\nThis is likely due to `gcc` generating `.d` files. Until the D people decide on\r\na different file extension, you can always exclude `.d` files using the\r\n`-e --exclude` flag like so\r\n\r\n```\r\n$ tokei . -e *.d\r\n```\r\n\r\n## Canonical Source\r\nThe canonical source of this repo is hosted on\r\n[GitHub](https://github.com/XAMPPRocky/tokei). If you have a GitHub account,\r\nplease make your issues, and pull requests there.\r\n\r\n## Related Tools\r\n\r\n- [tokei-pie](https://github.com/laixintao/tokei-pie): Render tokei's output to\r\n  interactive sunburst chart.\r\n\r\n## Copyright and License\r\n(C) Copyright 2015 by XAMPPRocky and contributors\r\n\r\nSee [the graph](https://github.com/XAMPPRocky/tokei/graphs/contributors) for a full list of contributors.\r\n\r\nTokei is distributed under the terms of both the MIT license and the Apache License (Version 2.0).\r\n\r\nSee [LICENCE-APACHE](./LICENCE-APACHE), [LICENCE-MIT](./LICENCE-MIT) for more information.\r\n",
	"calendar contributions-calendar gitstats hacktoberfest statistics": "<!-- Please do not edit this file. Edit the `blah` field in the `package.json` instead. If in doubt, open an issue. -->\n\n\n\n\n\n\n\n\n[![git-stats](http://i.imgur.com/Q7TQYHx.png)](#)\n\n\n\n\n\n\n\n\n\n\n\n# `$ git-stats`\n\n [![Support me on Patreon][badge_patreon]][patreon] [![Buy me a book][badge_amazon]][amazon] [![PayPal][badge_paypal_donate]][paypal-donations] [![Ask me anything](https://img.shields.io/badge/ask%20me-anything-1abc9c.svg)](https://github.com/IonicaBizau/ama) [![Version](https://img.shields.io/npm/v/git-stats.svg)](https://www.npmjs.com/package/git-stats) [![Downloads](https://img.shields.io/npm/dt/git-stats.svg)](https://www.npmjs.com/package/git-stats) [![Get help on Codementor](https://cdn.codementor.io/badges/get_help_github.svg)](https://www.codementor.io/johnnyb?utm_source=github&utm_medium=button&utm_term=johnnyb&utm_campaign=github)\n\n<a href=\"https://www.buymeacoffee.com/H96WwChMy\" target=\"_blank\"><img src=\"https://www.buymeacoffee.com/assets/img/custom_images/yellow_img.png\" alt=\"Buy Me A Coffee\"></a>\n\n\n\n\n\n\n\n> Local git statistics including GitHub-like contributions calendars.\n\n\n\n\n\n\n\nI'd be curious to see your calendar with all your commits. Ping me on Twitter ([**@IonicaBizau**](https://twitter.com/IonicaBizau)). :smile: Until then, here's my calendar:\n\n![](http://i.imgur.com/PpM0i3v.png)\n\n## Contents\n\n\n - [Installation](#cloud-installation)\n - [Usage](#usage)\n\n     - [Importing and deleting commits](#importing-and-deleting-commits)\n     - [Importing all the commits from GitHub and BitBucket](#importing-all-the-commits-from-github-and-bitbucket)\n     - [What about the GitHub Contributions calendar?](#what-about-the-github-contributions-calendar)\n\n - [Documentation](#memo-documentation)\n - [How to contribute](#yum-how-to-contribute)\n\n\n\n\n\n\n\n\n\n\n\n\n\n## :cloud: Installation\n\nYou can install the package globally and use it as command line tool:\n\n\n```sh\n# Install the package globally\nnpm i -g git-stats\n\n# Initialize git hooks\n# This is for tracking the new commits\ncurl -s https://raw.githubusercontent.com/IonicaBizau/git-stats/master/scripts/init-git-post-commit | bash\n```\n\n\nThen, run `git-stats --help` and see what the CLI tool can do.\n\n\n```\n$ git-stats --help\nUsage: git-stats [options]\n\nLocal git statistics including GitHub-like contributions calendars.\n\nOptions:\n  -r, --raw              Outputs a dump of the raw JSON data.\n  -g, --global-activity  Shows global activity calendar in the current\n                         repository.\n  -d, --data <path>      Sets a custom data store file.\n  -l, --light            Enables the light theme.\n  -n, --disable-ansi     Forces the tool not to use ANSI styles.\n  -A, --author           Filter author related contributions in the current\n                         repository.\n  -a, --authors          Shows a pie chart with the author related\n                         contributions in the current repository.\n  -u, --until <date>     Optional end date.\n  -s, --since <date>     Optional start date.\n  --record <data>        Records a new commit. Don't use this unless you are\n                         a mad scientist. If you are a developer just use\n                         this option as part of the module.\n  -h, --help             Displays this help.\n  -v, --version          Displays version information.\n\nExamples:\n  $ git-stats # Default behavior (stats in the last year)\n  $ git-stats -l # Light mode\n  $ git-stats -s '1 January 2012' # All the commits from 1 January 2012 to now\n  $ git-stats -s '1 January 2012' -u '31 December 2012' # All the commits from 2012\n\nYour commit history is kept in ~/.git-stats by default. You can create\n~/.git-stats-config.js to specify different defaults.\n\nDocumentation can be found at https://github.com/IonicaBizau/git-stats.\n```\n\n\n\n\n\n\n\n## Usage\n\n### Importing and deleting commits\n\n\nI know it's not nice to start your git commit calendar from scratch. That's why I created [`git-stats-importer`](https://github.com/IonicaBizau/git-stats-importer)\u2013a tool which imports or deletes the commits from selected repositories.\n\nCheck it out here: https://github.com/IonicaBizau/git-stats-importer\n\nThe usage is simple:\n\n```sh\n# Install the importer tool\n$ npm install -g git-stats-importer\n\n# Go to the repository you want to import\n$ cd path/to/my-repository\n\n# Import the commits\n$ git-stats-importer\n\n# ...or delete them if that's a dummy repository\n$ git-stats-importer --delete\n```\n\n### Importing all the commits from GitHub and BitBucket\n\n\nYes, that's also possible. I [built a tool which downloads and then imports all the commits you have pushed to GitHub and BitBucket](https://github.com/IonicaBizau/repository-downloader)!\n\n```sh\n# Download the repository downloader\n$ git clone https://github.com/IonicaBizau/repository-downloader.git\n\n# Go to repository downloader\n$ cd repository-downloader\n\n# Install the dependencies\n$ npm install\n\n# Start downloading and importing\n$ ./start\n```\n\n### What about the GitHub Contributions calendar?\n\n\nIf you want to visualize the calendars that appear on GitHub profiles, you can do that using [`ghcal`](https://github.com/IonicaBizau/ghcal).\n\n```sh\n# Install ghcal\n$ npm install -g ghcal\n\n# Check out @alysonla's contributions\n$ ghcal -u alysonla\n```\n\n\nFor more detailed documentation, check out the repository: https://github.com/IonicaBizau/ghcal.\n\nIf want to get even more GitHub stats in your terminal, you may want to try [`github-stats`](https://github.com/IonicaBizau/github-stats)--this is like `git-stats` but with data taken from GitHub.\n\n## Using the configuration file\n\n\nYou can tweak the git-stats behavior using a configuration file in your home directory: `~/.git-stats-config.js`.\n\nThis file should export an object, like below (defaults are listed):\n\n```js\nmodule.exports = {\n    // \"DARK\", \"LIGHT\" or an object interpreted by IonicaBizau/node-git-stats-colors\n    \"theme\": \"DARK\"\n\n    // The file where the commit hashes will be stored\n  , \"path\": \"~/.git-stats\"\n\n    // First day of the week\n  , first_day: \"Sun\"\n\n    // This defaults to *one year ago*\n    // It can be any parsable date\n  , since: undefined\n\n    // This defaults to *now*\n    // It can be any parsable date\n  , until: undefined\n\n    // Don't show authors by default\n    // If true, this will enable the authors pie\n  , authors: false\n\n    // No global activity by default\n    // If true, this will enable the global activity calendar in the current project\n  , global_activity: false\n};\n```\n\n\nSince it's a js file, you can `require` any other modules there.\n\n## Saving the data as HTML and images\n\n\n`git-stats --raw` outputs raw JSON format which can be consumed by other tools to generate results such as HTML files or images.\n\n[`git-stats-html`](https://github.com/IonicaBizau/git-stats-html) interprets the JSON data and generates an HTML file. Example:\n\n```sh\n\n# Install git-stats-html\n\nnpm install -g git-stats-html\n\n\n\n# Export the data from the last year (generate out.html)\n\ngit-stats --raw | git-stats-html -o out.html\n\n\n\n# Export data since 2015 (save the results in out.html)\n\ngit-stats --since '1 January 2015' --raw | ./bin/git-stats-html -o out.html --big\n\n```\n\n\n\nAfter we have the HTML file, we can generate an image file using [`pageres`](https://github.com/sindresorhus/pageres) by [**@sindresorhus**](https://github.com/sindresorhus/):\n\n```sh\n\n# Install pageres\n\nnpm install -g pageres-cli\n\n\n\n# Generate the image from HTML\n\npageres out.html 775x250\n\n```\n\n\n\n## Cross-platform compatibility\n\n\n`git-stats` is working fine in terminal emulators supporting ANSI styles. It should work fine on Linux and OS X.\n\nIf you run `git-stats` to display graph on Windows, please use a terminal that can properly display ANSI colors.\n\nCygwin Terminal is known to work, while Windows Command Prompt and Git Bash do not. Improvements are more than welcome! :dizzy:\n\n\n\n\n\n\n\n\n## :clipboard: Example\n\n\n\nHere is an example how to use this package as library. To install it locally, as library, you can use `npm install git-stats` (or `yarn add git-stats`):\n\n\n\n```js\n// Dependencies\nvar GitStats = require(\"git-stats\");\n\n// Create the GitStats instance\nvar g1 = new GitStats();\n\n// Display the ansi calendar\ng1.ansiCalendar({\n    theme: \"DARK\"\n}, function (err, data) {\n    console.log(err || data);\n});\n```\n\n\n\n\n\n\n\n\n\n\n\n## :question: Get Help\n\nThere are few ways to get help:\n\n\n\n 1. Please [post questions on Stack Overflow](https://stackoverflow.com/questions/ask). You can open issues with questions, as long you add a link to your Stack Overflow question.\n 2. For bug reports and feature requests, open issues. :bug:\n 3. For direct and quick help, you can [use Codementor](https://www.codementor.io/johnnyb). :rocket:\n\n\n\n\n\n## :memo: Documentation\n\nFor full API reference, see the [DOCUMENTATION.md][docs] file.\n\n\n\n\n\n\n## :newspaper: Press Highlights\n\n - [*A GitHub-like contributions calendar, but locally, with all your git commits*, The Changelog](https://changelog.com/github-like-contributions-calendar-locally-git-commits/)\n\n\n\n\n\n\n\n\n## :yum: How to contribute\nHave an idea? Found a bug? See [how to contribute][contributing].\n\n\n## :sparkling_heart: Support my projects\nI open-source almost everything I can, and I try to reply to everyone needing help using these projects. Obviously,\nthis takes time. You can integrate and use these projects in your applications *for free*! You can even change the source code and redistribute (even resell it).\n\nHowever, if you get some profit from this or just want to encourage me to continue creating stuff, there are few ways you can do it:\n\n\n - Starring and sharing the projects you like :rocket:\n - [![Buy me a book][badge_amazon]][amazon]\u2014I love books! I will remember you after years if you buy me one. :grin: :book:\n - [![PayPal][badge_paypal]][paypal-donations]\u2014You can make one-time donations via PayPal. I'll probably buy a ~~coffee~~ tea. :tea:\n - [![Support me on Patreon][badge_patreon]][patreon]\u2014Set up a recurring monthly donation and you will get interesting news about what I'm doing (things that I don't share with everyone).\n - **Bitcoin**\u2014You can send me bitcoins at this address (or scanning the code below): `1P9BRsmazNQcuyTxEqveUsnf5CERdq35V6`\n\n    ![](https://i.imgur.com/z6OQI95.png)\n\n\nThanks! :heart:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## :dizzy: Where is this library used?\nIf you are using this library in one of your projects, add it in this list. :sparkles:\n\n - `git-stats-importer`\n - `git-stats-fcc-importer`\n\n\n\n\n\n\n\n\n\n\n\n## :scroll: License\n\n[MIT][license] \u00a9 [Ionic\u0103 Biz\u0103u][website]\n\n\n\n\n\n\n[license]: /LICENSE\n[website]: https://ionicabizau.net\n[contributing]: /CONTRIBUTING.md\n[docs]: /DOCUMENTATION.md\n[badge_patreon]: https://ionicabizau.github.io/badges/patreon.svg\n[badge_amazon]: https://ionicabizau.github.io/badges/amazon.svg\n[badge_paypal]: https://ionicabizau.github.io/badges/paypal.svg\n[badge_paypal_donate]: https://ionicabizau.github.io/badges/paypal_donate.svg\n[patreon]: https://www.patreon.com/ionicabizau\n[amazon]: http://amzn.eu/hRo9sIZ\n[paypal-donations]: https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=RVXDDLKKLQRJW\n",
	"cache data-science data-structures file json python queue recursive standard-library statistics utilities": "# Boltons\n\n*boltons should be builtins.*\n\n<a href=\"https://boltons.readthedocs.io/en/latest/\"><img src=\"https://img.shields.io/badge/docs-latest-brightgreen.svg?style=flat\"></a>\n<a href=\"https://pypi.python.org/pypi/boltons\"><img src=\"https://img.shields.io/pypi/v/boltons.svg\"></a>\n<a href=\"https://anaconda.org/conda-forge/boltons\"><img src=\"https://img.shields.io/conda/vn/conda-forge/boltons.svg\"></a>\n<a href=\"https://ports.macports.org/port/py-boltons/summary\"><img src=\"https://repology.org/badge/version-for-repo/macports/python:boltons.svg?header=\ud83c\udf4e MacPorts\"></a>\n<a href=\"https://pypi.python.org/pypi/boltons\"><img src=\"https://img.shields.io/pypi/pyversions/boltons.svg\"></a>\n<a href=\"http://calver.org\"><img src=\"https://img.shields.io/badge/calver-YY.MINOR.MICRO-22bfda.svg\"></a>\n\n**Boltons** is a set of over 230 BSD-licensed, pure-Python utilities\nin the same spirit as \u2014 and yet conspicuously missing from \u2014\n[the standard library][stdlib], including:\n\n  * [Atomic file saving][atomic], bolted on with [fileutils][fileutils]\n  * A highly-optimized [OrderedMultiDict][omd], in [dictutils][dictutils]\n  * *Two* types of [PriorityQueue][pq], in [queueutils][queueutils]\n  * [Chunked][chunked] and [windowed][windowed] iteration, in [iterutils][iterutils]\n  * Recursive data structure [iteration and merging][remap], with [iterutils.remap][iterutils.remap]\n  * Exponential backoff functionality, including jitter, through [iterutils.backoff][iterutils.backoff]\n  * A full-featured [TracebackInfo][tbinfo] type, for representing stack traces,\n    in [tbutils][tbutils]\n\n**[Full and extensive docs are available on Read The Docs.][rtd]** See\nwhat's new [by checking the CHANGELOG][changelog].\n\nBoltons is tested against Python 2.6, 2.7, 3.4, 3.5, 3.6, 3.7, 3.8 and 3.9, as well as CPython\n_nightly_ and PyPy/PyPy3.\n\n[stdlib]: https://docs.python.org/2.7/library/index.html\n[rtd]: https://boltons.readthedocs.org/en/latest/\n[changelog]: https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md\n\n[atomic]: https://boltons.readthedocs.org/en/latest/fileutils.html#boltons.fileutils.atomic_save\n[omd]: https://boltons.readthedocs.org/en/latest/dictutils.html#boltons.dictutils.OrderedMultiDict\n[pq]: https://boltons.readthedocs.org/en/latest/queueutils.html#boltons.queueutils.PriorityQueue\n[chunked]: https://boltons.readthedocs.org/en/latest/iterutils.html#boltons.iterutils.chunked\n[windowed]: https://boltons.readthedocs.org/en/latest/iterutils.html#boltons.iterutils.windowed\n[tbinfo]: https://boltons.readthedocs.org/en/latest/tbutils.html#boltons.tbutils.TracebackInfo\n\n[fileutils]: https://boltons.readthedocs.org/en/latest/fileutils.html#module-boltons.fileutils\n[ioutils]: https://boltons.readthedocs.org/en/latest/ioutils.html#module-boltons.ioutils\n[dictutils]: https://boltons.readthedocs.org/en/latest/dictutils.html#module-boltons.dictutils\n[queueutils]: https://boltons.readthedocs.org/en/latest/queueutils.html#module-boltons.queueutils\n[iterutils]: https://boltons.readthedocs.org/en/latest/iterutils.html#module-boltons.iterutils\n[iterutils.remap]: http://boltons.readthedocs.org/en/latest/iterutils.html#boltons.iterutils.remap\n[iterutils.backoff]: http://boltons.readthedocs.org/en/latest/iterutils.html#boltons.iterutils.backoff\n[tbutils]: https://boltons.readthedocs.org/en/latest/tbutils.html#module-boltons.tbutils\n\n[remap]: http://sedimental.org/remap.html\n\n## Installation\n\nBoltons can be added to a project in a few ways. There's the obvious one:\n\n```bash\npip install boltons\n```\nOn macOS, it can also be installed via [MacPorts](https://ports.macports.org/port/py-boltons/summary):\n\n```bash\nsudo port install py-boltons\n```\n\n\nThen, [thanks to PyPI][boltons_pypi], dozens of boltons are just an import away:\n\n```python\nfrom boltons.cacheutils import LRU\nmy_cache = LRU()\n```\n\nHowever, due to the nature of utilities, application developers might\nwant to consider other options, including vendorization of individual\nmodules into a project. Boltons is pure-Python and has no\ndependencies. If the whole project is too big, each module is\nindependent, and can be copied directly into a project. See the\n[Integration][integration] section of the docs for more details.\n\n[boltons_pypi]: https://pypi.python.org/pypi/boltons\n[integration]: https://boltons.readthedocs.org/en/latest/architecture.html#integration\n\n## Third-party packages\n\nThe majority of boltons strive to be \"good enough\" for a wide range of\nbasic uses, leaving advanced use cases to Python's [myriad specialized\n3rd-party libraries][pypi]. In many cases the respective ``boltons`` module\nwill describe 3rd-party alternatives worth investigating when use\ncases outgrow `boltons`. If you've found a natural \"next-step\"\nlibrary worth mentioning, see the next section!\n\n[pypi]: https://pypi.python.org/pypi\n\n## Gaps\n\nFound something missing in the standard library that should be in\n`boltons`? Found something missing in `boltons`? First, take a\nmoment to read the very brief [architecture statement][architecture] to make\nsure the functionality would be a good fit.\n\nThen, if you are very motivated, submit [a Pull Request][prs]. Otherwise,\nsubmit a short feature request on [the Issues page][issues], and we will\nfigure something out.\n\n[architecture]: https://boltons.readthedocs.org/en/latest/architecture.html\n[issues]: https://github.com/mahmoud/boltons/issues\n[prs]: https://github.com/mahmoud/boltons/pulls\n",
	"command-line command-line-tools csv csv-format data-cleaning data-processing data-reduction data-regression devops devops-tools json json-data miller statistical-analysis statistics streaming-algorithms streaming-data tabular-data tsv unix-toolkit": "# What is Miller?\n\n**Miller is like awk, sed, cut, join, and sort for data formats such as CSV, TSV, JSON, JSON Lines, and positionally-indexed.**\n\n# What can Miller do for me?\n\nWith Miller, you get to use named fields without needing to count positional\nindices, using familiar formats such as CSV, TSV, JSON, JSON Lines, and\npositionally-indexed.  Then, on the fly, you can add new fields which are\nfunctions of existing fields, drop fields, sort, aggregate statistically,\npretty-print, and more.\n\n![cover-art](./docs/src/coverart/cover-combined.png)\n\n* Miller operates on **key-value-pair data** while the familiar\nUnix tools operate on integer-indexed fields: if the natural data structure for\nthe latter is the array, then Miller's natural data structure is the\ninsertion-ordered hash map.\n\n* Miller handles a **variety of data formats**,\nincluding but not limited to the familiar **CSV**, **TSV**, and **JSON**/**JSON Lines**.\n(Miller can handle **positionally-indexed data** too!)\n\nIn the above image you can see how Miller embraces the common themes of\nkey-value-pair data in a variety of data formats.\n\n# Getting started\n\n* [Miller in 10 minutes](https://miller.readthedocs.io/en/latest/10min)\n* [A quick tutorial on Miller](https://www.ict4g.net/adolfo/notes/data-analysis/miller-quick-tutorial.html)\n* [Tools to manipulate CSV files from the Command Line](https://www.ict4g.net/adolfo/notes/data-analysis/tools-to-manipulate-csv.html)\n* [www.togaware.com/linux/survivor/CSV_Files.html](https://www.togaware.com/linux/survivor/CSV_Files.html)\n* [MLR for CSV manipulation](https://guillim.github.io/terminal/2018/06/19/MLR-for-CSV-manipulation.html)\n* [Linux Magazine: Process structured text files with Miller](https://www.linux-magazine.com/Issues/2016/187/Miller)\n* [Miller: Command Line CSV File Processing](https://onepointzero.app/posts/miller-command-line-csv-file-processing/)\n* [Miller - A Swiss Army Chainsaw for CSV Data, Data Science and Data Munging](https://fuzzyblog.io/blog/data_science/2022/05/13/miller-a-swiss-army-chainsaw-for-csv-data-data-science-and-data-munging.html)\n* [Pandas Killer: mlr, the Scientist](https://xvzftube.xyz/posts/pandas_killers/#mlr%3A-the-scientist)\n\n# More documentation links\n\n* [**Full documentation**](https://miller.readthedocs.io/)\n* [Miller's license is two-clause BSD](https://github.com/johnkerl/miller/blob/main/LICENSE.txt)\n* [Notes about issue-labeling in the Github repo](https://github.com/johnkerl/miller/wiki/Issue-labeling)\n* [Active issues](https://github.com/johnkerl/miller/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc)\n\n# Installing\n\nThere's a good chance you can get Miller pre-built for your system:\n\n[![Ubuntu](https://img.shields.io/badge/distros-ubuntu-db4923.svg)](https://launchpad.net/ubuntu/+source/miller)\n[![Ubuntu 16.04 LTS](https://img.shields.io/badge/distros-ubuntu1604lts-db4923.svg)](https://launchpad.net/ubuntu/xenial/+package/miller)\n[![Fedora](https://img.shields.io/badge/distros-fedora-173b70.svg)](https://apps.fedoraproject.org/packages/miller)\n[![Debian](https://img.shields.io/badge/distros-debian-c70036.svg)](https://packages.debian.org/stable/miller)\n[![Gentoo](https://img.shields.io/badge/distros-gentoo-4e4371.svg)](https://packages.gentoo.org/packages/sys-apps/miller)\n\n[![Pro-Linux](https://img.shields.io/badge/distros-prolinux-3a679d.svg)](http://www.pro-linux.de/cgi-bin/DBApp/check.cgi?ShowApp..20427.100)\n[![Arch Linux](https://img.shields.io/badge/distros-archlinux-1792d0.svg)](https://aur.archlinux.org/packages/miller-git)\n\n[![NetBSD](https://img.shields.io/badge/distros-netbsd-f26711.svg)](http://pkgsrc.se/textproc/miller)\n[![FreeBSD](https://img.shields.io/badge/distros-freebsd-8c0707.svg)](https://www.freshports.org/textproc/miller/)\n\n[![Anaconda](https://img.shields.io/badge/distros-anaconda-63ad41.svg)](https://anaconda.org/conda-forge/miller/)\n[![Homebrew/MacOSX](https://img.shields.io/badge/distros-homebrew-ba832b.svg)](https://formulae.brew.sh/formula/miller)\n[![MacPorts/MacOSX](https://img.shields.io/badge/distros-macports-1376ec.svg)](https://www.macports.org/ports.php?by=name&substr=miller)\n[![Chocolatey](https://img.shields.io/badge/distros-chocolatey-red.svg)](https://chocolatey.org/packages/miller)\n\n|OS|Installation command|\n|---|---|\n|Linux|`yum install miller`<br/> `apt-get install miller`|\n|Mac|`brew install miller`<br/>`port install miller`|\n|Windows|`choco install miller`|\n\nSee also [README-versions.md](./README-versions.md) for a full list of package versions. Note that long-term-support (LtS) releases will likely be on older versions.\n\nSee also [building from source](https://miller.readthedocs.io/en/latest/build.html).\n\n# Community\n\n[![GitHub stars](https://img.shields.io/github/stars/johnkerl/miller.svg?label=GitHub%20stars)](https://github.com/johnkerl/miller/stargazers)\n[![Homebrew downloads](https://badges.weareopensource.me:/homebrew/installs/dy/miller?label=Homebrew%20downloads)](https://formulae.brew.sh/formula/miller)\n[![Conda downloads](https://anaconda.org/conda-forge/miller/badges/downloads.svg?label=Conda%20downloads)](https://anaconda.org/conda-forge/miller)\n<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->\n[![All Contributors](https://img.shields.io/badge/all_contributors-41-orange.svg?style=flat-square)](#contributors-)\n<!-- ALL-CONTRIBUTORS-BADGE:END -->\n\n* Discussion forum: https://github.com/johnkerl/miller/discussions\n* Feature requests / bug reports: https://github.com/johnkerl/miller/issues\n* How to contribute: [https://miller.readthedocs.io/en/latest/contributing/](https://miller.readthedocs.io/en/latest/contributing/)\n\n# Build status\n\n[![Multi-platform build status](https://github.com/johnkerl/miller/actions/workflows/go.yml/badge.svg)](https://github.com/johnkerl/miller/actions/workflows/go.yml)\n[![CodeQL status](https://github.com/johnkerl/miller/actions/workflows/codeql-analysis.yml/badge.svg)](https://github.com/johnkerl/miller/actions/workflows/codeql-analysis.yml)\n[![Codespell status](https://github.com/johnkerl/miller/actions/workflows/codespell.yml/badge.svg)](https://github.com/johnkerl/miller/actions/workflows/codespell.yml)\n<!--\n[![Release status](https://github.com/johnkerl/miller/actions/workflows/release.yml/badge.svg)](https://github.com/johnkerl/miller/actions/workflows/release.yml)\n-->\n\n# Building from source\n\n* First:\n  * `cd /where/you/want/to/put/the/source`\n  * `git clone https://github.com/johnkerl/miller`\n  * `cd miller`\n* With `make`:\n  * To build: `make`. This takes just a few seconds and produces the Miller executable, which is `./mlr` (or `.\\mlr.exe` on Windows).\n  * To run tests: `make check`.\n  * To install: `make install`. This installs the executable `/usr/local/bin/mlr` and manual page `/usr/local/share/man/man1/mlr.1` (so you can do `man mlr`).\n  * You can do `./configure --prefix=/some/install/path` before `make install` if you want to install somewhere other than `/usr/local`.\n* Without `make`:\n  * To build: `go build github.com/johnkerl/miller/cmd/mlr`.\n  * To run tests: `go test github.com/johnkerl/miller/internal/pkg/...` and `mlr regtest`.\n  * To install: `go install github.com/johnkerl/miller/cmd/mlr` will install to _GOPATH_`/bin/mlr`.\n* See also the doc page on [building from source](https://miller.readthedocs.io/en/latest/build).\n* For more developer information please see [README-dev.md](./README-dev.md).\n\n# For developers\n\n* [README-dev.md](README-dev.md)\n* [How to contribute](https://miller.readthedocs.io/en/latest/contributing/)\n\n# License\n\n[License: BSD2](https://github.com/johnkerl/miller/blob/main/LICENSE.txt)\n\n# Features\n\n* Miller is **multi-purpose**: it's useful for **data cleaning**,\n**data reduction**, **statistical reporting**, **devops**, **system\nadministration**, **log-file processing**, **format conversion**, and\n**database-query post-processing**.\n\n* You can use Miller to snarf and munge **log-file data**, including selecting\nout relevant substreams, then produce CSV format and load that into\nall-in-memory/data-frame utilities for further statistical and/or graphical\nprocessing.\n\n* Miller complements **data-analysis tools** such as **R**, **pandas**, etc.:\nyou can use Miller to **clean** and **prepare** your data. While you can do\n**basic statistics** entirely in Miller, its streaming-data feature and\nsingle-pass algorithms enable you to **reduce very large data sets**.\n\n* Miller complements SQL **databases**: you can slice, dice, and reformat data\non the client side on its way into or out of a database. You can also reap some\nof the benefits of databases for quick, setup-free one-off tasks when you just\nneed to query some data in disk files in a hurry.\n\n* Miller also goes beyond the classic Unix tools by stepping fully into our\nmodern, **no-SQL** world: its essential record-heterogeneity property allows\nMiller to operate on data where records with different schema (field names) are\ninterleaved.\n\n* Miller is **streaming**: most operations need only a single record in\nmemory at a time, rather than ingesting all input before producing any output.\nFor those operations which require deeper retention (`sort`, `tac`, `stats1`),\nMiller retains only as much data as needed. This means that whenever\nfunctionally possible, you can operate on files which are larger than your\nsystem&rsquo;s available RAM, and you can use Miller in **tail -f** contexts.\n\n* Miller is **pipe-friendly** and interoperates with the Unix toolkit.\n\n* Miller's I/O formats include **tabular pretty-printing**, **positionally\n  indexed** (Unix-toolkit style), CSV, TSV, JSON, JSON Lines, and others.\n\n* Miller does **conversion** between formats.\n\n* Miller's **processing is format-aware**: e.g. CSV `sort` and `tac` keep header lines first.\n\n* Miller has high-throughput **performance** on par with the Unix toolkit.\n\n* Miller is written in portable, modern Go, with **zero runtime dependencies**.\nYou can download or compile a single binary, `scp` it to a faraway machine,\nand expect it to work.\n\n# What people are saying about Miller\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Today I discovered Miller\u2014it&#39;s like jq but for CSV: <a href=\"https://t.co/pn5Ni241KM\">https://t.co/pn5Ni241KM</a><br><br>Also, &quot;Miller complements data-analysis tools such as R, pandas, etc.: you can use Miller to clean and prepare your data.&quot; <a href=\"https://twitter.com/GreatBlueC?ref_src=twsrc%5Etfw\">@GreatBlueC</a> <a href=\"https://twitter.com/nfmcclure?ref_src=twsrc%5Etfw\">@nfmcclure</a></p>&mdash; Adrien Trouillaud (@adrienjt) <a href=\"https://twitter.com/adrienjt/status/1308963056592891904?ref_src=twsrc%5Etfw\">September 24, 2020</a></blockquote>\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Underappreciated swiss-army command-line chainsaw.<br><br>&quot;Miller is like awk, sed, cut, join, and sort for [...] CSV, TSV, and [...] JSON.&quot; <a href=\"https://t.co/TrQqSUK3KK\">https://t.co/TrQqSUK3KK</a></p>&mdash; Dirk Eddelbuettel (@eddelbuettel) <a href=\"https://twitter.com/eddelbuettel/status/836555980771061760?ref_src=twsrc%5Etfw\">February 28, 2017</a></blockquote>\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Miller looks like a great command line tool for working with CSV data. Sed, awk, cut, join all rolled into one: <a href=\"http://t.co/9BBb6VCZ6Y\">http://t.co/9BBb6VCZ6Y</a></p>&mdash; Mike Loukides (@mikeloukides) <a href=\"https://twitter.com/mikeloukides/status/632885317389950976?ref_src=twsrc%5Etfw\">August 16, 2015</a></blockquote>\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Miller is like sed, awk, cut, join, and sort for name-indexed data such as CSV: <a href=\"http://t.co/1zPbfg6B2W\">http://t.co/1zPbfg6B2W</a> - handy tool!</p>&mdash; Ilya Grigorik (@igrigorik) <a href=\"https://twitter.com/igrigorik/status/635134857283153920?ref_src=twsrc%5Etfw\">August 22, 2015</a></blockquote>\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Btw, I think Miller is the best CLI tool to deal with CSV. I used to use this when I need to preprocess too big CSVs to load into R (now we have vroom, so such cases might be rare, though...)<a href=\"https://t.co/kUjrSSGJoT\">https://t.co/kUjrSSGJoT</a></p>&mdash; Hiroaki Yutani (@yutannihilat_en) <a href=\"https://twitter.com/yutannihilat_en/status/1252392795676934144?ref_src=twsrc%5Etfw\">April 21, 2020</a></blockquote>\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Miller: a *format-aware* data munging tool By <a href=\"https://twitter.com/__jo_ker__?ref_src=twsrc%5Etfw\">@__jo_ker__</a> to overcome limitations with *line-aware* workshorses like awk, sed et al <a href=\"https://t.co/LCyPkhYvt9\">https://t.co/LCyPkhYvt9</a><br><br>The project website is a fantastic example of good software documentation!!</p>&mdash; Donny Daniel (@dnnydnl) <a href=\"https://twitter.com/dnnydnl/status/1038883999391932416?ref_src=twsrc%5Etfw\">September 9, 2018</a></blockquote>\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Holy holly data swiss army knife batman! How did no one suggest Miller <a href=\"https://t.co/JGQpmRAZLv\">https://t.co/JGQpmRAZLv</a> for solving database cleaning / ETL issues to me before <br><br>Congrats to <a href=\"https://twitter.com/__jo_ker__?ref_src=twsrc%5Etfw\">@__jo_ker__</a> for amazingly intuitive tool for critical data management tasks!<a href=\"https://twitter.com/hashtag/DataScienceandLaw?src=hash&amp;ref_src=twsrc%5Etfw\">#DataScienceandLaw</a> <a href=\"https://twitter.com/hashtag/ComputationalLaw?src=hash&amp;ref_src=twsrc%5Etfw\">#ComputationalLaw</a></p>&mdash; James Miller (@japanlawprof) <a href=\"https://twitter.com/japanlawprof/status/1006547451409518597?ref_src=twsrc%5Etfw\">June 12, 2018</a></blockquote>\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">\ud83e\udd2f<a href=\"https://twitter.com/__jo_ker__?ref_src=twsrc%5Etfw\">@__jo_ker__</a>&#39;s Miller easily reads, transforms, + writes all sorts of tabular data. It&#39;s standalone, fast, and built for streaming data (operating on one line at a time, so you can work on files larger than memory).<br><br>And the docs are dream. I&#39;ve been reading them all morning! <a href=\"https://t.co/Be2pGPZK6t\">https://t.co/Be2pGPZK6t</a></p>&mdash; Benjamin Wolfe (he/him) (@BenjaminWolfe) <a href=\"https://twitter.com/BenjaminWolfe/status/1435966268499128324?ref_src=twsrc%5Etfw\">September 9, 2021</a></blockquote>\n\n## Contributors \u2728\n\nThanks to all the fine people who help make Miller better ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/aborruso\"><img src=\"https://avatars.githubusercontent.com/u/30607?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Andrea Borruso</b></sub></a><br /><a href=\"#ideas-aborruso\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#design-aborruso\" title=\"Design\">\ud83c\udfa8</a></td>\n    <td align=\"center\"><a href=\"https://sjackman.ca/\"><img src=\"https://avatars.githubusercontent.com/u/291551?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Shaun Jackman</b></sub></a><br /><a href=\"#ideas-sjackman\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"http://www.fredtrotter.com/\"><img src=\"https://avatars.githubusercontent.com/u/83133?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Fred Trotter</b></sub></a><br /><a href=\"#ideas-ftrotter\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a> <a href=\"#design-ftrotter\" title=\"Design\">\ud83c\udfa8</a></td>\n    <td align=\"center\"><a href=\"https://github.com/Komosa\"><img src=\"https://avatars.githubusercontent.com/u/10688154?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>komosa</b></sub></a><br /><a href=\"#ideas-Komosa\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/jungle-boogie\"><img src=\"https://avatars.githubusercontent.com/u/1111743?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>jungle-boogie</b></sub></a><br /><a href=\"#ideas-jungle-boogie\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/0-wiz-0\"><img src=\"https://avatars.githubusercontent.com/u/2221844?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Thomas Klausner</b></sub></a><br /><a href=\"#infra-0-wiz-0\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n    <td align=\"center\"><a href=\"https://github.com/skitt\"><img src=\"https://avatars.githubusercontent.com/u/2128935?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Stephen Kitt</b></sub></a><br /><a href=\"#platform-skitt\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"http://leahneukirchen.org/\"><img src=\"https://avatars.githubusercontent.com/u/139?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Leah Neukirchen</b></sub></a><br /><a href=\"#ideas-leahneukirchen\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/lgbaldoni\"><img src=\"https://avatars.githubusercontent.com/u/1450716?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Luigi Baldoni</b></sub></a><br /><a href=\"#platform-lgbaldoni\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n    <td align=\"center\"><a href=\"https://yutani.rbind.io/\"><img src=\"https://avatars.githubusercontent.com/u/1978793?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Hiroaki Yutani</b></sub></a><br /><a href=\"#ideas-yutannihilation\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://3e.org/\"><img src=\"https://avatars.githubusercontent.com/u/41439?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Daniel M. Drucker</b></sub></a><br /><a href=\"#ideas-dmd\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/NikosAlexandris\"><img src=\"https://avatars.githubusercontent.com/u/7046639?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Nikos Alexandris</b></sub></a><br /><a href=\"#ideas-NikosAlexandris\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/kundeng\"><img src=\"https://avatars.githubusercontent.com/u/89032?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>kundeng</b></sub></a><br /><a href=\"#platform-kundeng\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n    <td align=\"center\"><a href=\"http://victorsergienko.com/\"><img src=\"https://avatars.githubusercontent.com/u/151199?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Victor Sergienko</b></sub></a><br /><a href=\"#platform-singalen\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/gromgit\"><img src=\"https://avatars.githubusercontent.com/u/215702?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Adrian Ho</b></sub></a><br /><a href=\"#design-gromgit\" title=\"Design\">\ud83c\udfa8</a></td>\n    <td align=\"center\"><a href=\"https://github.com/Zachp\"><img src=\"https://avatars.githubusercontent.com/u/1316442?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>zachp</b></sub></a><br /><a href=\"#platform-Zachp\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n    <td align=\"center\"><a href=\"https://dsel.net/\"><img src=\"https://avatars.githubusercontent.com/u/921669?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>David Selassie</b></sub></a><br /><a href=\"#ideas-davidselassie\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"http://www.joelparkerhenderson.com/\"><img src=\"https://avatars.githubusercontent.com/u/27145?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Joel Parker Henderson</b></sub></a><br /><a href=\"#ideas-joelparkerhenderson\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/divtiply\"><img src=\"https://avatars.githubusercontent.com/u/5359679?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Michel Ace</b></sub></a><br /><a href=\"#ideas-divtiply\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"http://fuco1.github.io/sitemap.html\"><img src=\"https://avatars.githubusercontent.com/u/2664959?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Matus Goljer</b></sub></a><br /><a href=\"#ideas-Fuco1\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/terorie\"><img src=\"https://avatars.githubusercontent.com/u/21371810?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Richard Patel</b></sub></a><br /><a href=\"#platform-terorie\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://blog.kub1x.org/\"><img src=\"https://avatars.githubusercontent.com/u/1833840?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Jakub Podlaha</b></sub></a><br /><a href=\"#design-kub1x\" title=\"Design\">\ud83c\udfa8</a></td>\n    <td align=\"center\"><a href=\"https://goo.gl/ZGZynx\"><img src=\"https://avatars.githubusercontent.com/u/85767?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Miodrag Mili\u0107</b></sub></a><br /><a href=\"#platform-majkinetor\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n    <td align=\"center\"><a href=\"https://github.com/derekmahar\"><img src=\"https://avatars.githubusercontent.com/u/6047?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Derek Mahar</b></sub></a><br /><a href=\"#ideas-derekmahar\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/spmundi\"><img src=\"https://avatars.githubusercontent.com/u/38196185?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>spmundi</b></sub></a><br /><a href=\"#ideas-spmundi\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/koernepr\"><img src=\"https://avatars.githubusercontent.com/u/24551942?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Peter K\u00f6rner</b></sub></a><br /><a href=\"#security-koernepr\" title=\"Security\">\ud83d\udee1\ufe0f</a></td>\n    <td align=\"center\"><a href=\"https://github.com/rubyFeedback\"><img src=\"https://avatars.githubusercontent.com/u/46686565?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>rubyFeedback</b></sub></a><br /><a href=\"#ideas-rubyFeedback\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/rbolsius\"><img src=\"https://avatars.githubusercontent.com/u/2106964?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>rbolsius</b></sub></a><br /><a href=\"#platform-rbolsius\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/awildturtok\"><img src=\"https://avatars.githubusercontent.com/u/1553491?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>awildturtok</b></sub></a><br /><a href=\"#ideas-awildturtok\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/agguser\"><img src=\"https://avatars.githubusercontent.com/u/1206106?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>agguser</b></sub></a><br /><a href=\"#ideas-agguser\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/jganong\"><img src=\"https://avatars.githubusercontent.com/u/2783890?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>jganong</b></sub></a><br /><a href=\"#ideas-jganong\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/fulvio-scapin\"><img src=\"https://avatars.githubusercontent.com/u/69568?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Fulvio Scapin</b></sub></a><br /><a href=\"#ideas-trantor\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/torbiak\"><img src=\"https://avatars.githubusercontent.com/u/109347?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Jordan Torbiak</b></sub></a><br /><a href=\"#ideas-torbiak\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/Andy1978\"><img src=\"https://avatars.githubusercontent.com/u/240064?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Andreas Weber</b></sub></a><br /><a href=\"#ideas-Andy1978\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/vapniks\"><img src=\"https://avatars.githubusercontent.com/u/174330?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>vapniks</b></sub></a><br /><a href=\"#platform-vapniks\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/89z\"><img src=\"https://avatars.githubusercontent.com/u/73562167?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Zombo</b></sub></a><br /><a href=\"#platform-89z\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n    <td align=\"center\"><a href=\"https://github.com/BEFH\"><img src=\"https://avatars.githubusercontent.com/u/3386600?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Brian Fulton-Howard</b></sub></a><br /><a href=\"#platform-BEFH\" title=\"Packaging/porting to new platform\">\ud83d\udce6</a></td>\n    <td align=\"center\"><a href=\"https://github.com/ChCyrill\"><img src=\"https://avatars.githubusercontent.com/u/2165604?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>ChCyrill</b></sub></a><br /><a href=\"#ideas-ChCyrill\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n    <td align=\"center\"><a href=\"https://github.com/jauderho\"><img src=\"https://avatars.githubusercontent.com/u/13562?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Jauder Ho</b></sub></a><br /><a href=\"https://github.com/johnkerl/miller/commits?author=jauderho\" title=\"Code\">\ud83d\udcbb</a></td>\n    <td align=\"center\"><a href=\"https://github.com/psacawa\"><img src=\"https://avatars.githubusercontent.com/u/21274063?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Pawe\u0142 Sacawa</b></sub></a><br /><a href=\"https://github.com/johnkerl/miller/issues?q=author%3Apsacawa\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    <td align=\"center\"><a href=\"https://github.com/schragge\"><img src=\"https://avatars.githubusercontent.com/u/4294278?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>schragge</b></sub></a><br /><a href=\"https://github.com/johnkerl/miller/commits?author=schragge\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    <td align=\"center\"><a href=\"https://github.com/Poshi\"><img src=\"https://avatars.githubusercontent.com/u/1780510?v=4?s=50\" width=\"50px;\" alt=\"\"/><br /><sub><b>Jordi</b></sub></a><br /><a href=\"https://github.com/johnkerl/miller/commits?author=Poshi\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#ideas-Poshi\" title=\"Ideas, Planning, & Feedback\">\ud83e\udd14</a></td>\n  </tr>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\n<a href=\"https://github.com/johnkerl/miller/graphs/contributors\">\n  <img src=\"https://contributors-img.web.app/image?repo=johnkerl/miller\" />\n</a>\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind are welcome!\n",
	"classification clustering computer-algebra-system data-science dataframe deep-learning genetic-algorithm graph interpolation linear-algebra machine-learning manifold-learning multidimensional-scaling nearest-neighbor-search nlp regression statistics visualization wavelet": "# Smile\n\n[![Join the chat at https://gitter.im/haifengl/smile](https://badges.gitter.im/haifengl/smile.svg)](https://gitter.im/haifengl/smile?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![Maven Central](https://maven-badges.herokuapp.com/maven-central/com.github.haifengl/smile-core/badge.svg)](https://maven-badges.herokuapp.com/maven-central/com.github.haifengl/smile-core)\n\n[Smile (Statistical Machine Intelligence and Learning Engine)](https://haifengl.github.io/)\nis a fast and comprehensive machine learning, NLP, linear algebra,\ngraph, interpolation, and visualization system in Java and Scala.\nWith advanced data structures and algorithms, Smile delivers\nstate-of-art performance. Smile is well documented and please\ncheck out the project [website](https://haifengl.github.io/)\nfor programming guides and more information.\n\nSmile covers every aspect of machine learning, including classification,\nregression, clustering, association rule mining, feature selection,\nmanifold learning, multidimensional scaling, genetic algorithms,\nmissing value imputation, efficient nearest neighbor search, etc.\n\nSmile implements the following major machine learning algorithms:\n\n- **Classification:**\nSupport Vector Machines, Decision Trees, AdaBoost, Gradient Boosting,\nRandom Forest, Logistic Regression, Neural Networks, RBF Networks,\nMaximum Entropy Classifier, KNN, Na\u00efve Bayesian,\nFisher/Linear/Quadratic/Regularized Discriminant Analysis.\n\n- **Regression:**\nSupport Vector Regression, Gaussian Process, Regression Trees,\nGradient Boosting, Random Forest, RBF Networks, OLS, LASSO, ElasticNet,\nRidge Regression.\n\n- **Feature Selection:**\nGenetic Algorithm based Feature Selection, Ensemble Learning based Feature\nSelection, TreeSHAP, Signal Noise ratio, Sum Squares ratio.\n\n- **Clustering:**\nBIRCH, CLARANS, DBSCAN, DENCLUE, Deterministic Annealing, K-Means,\nX-Means, G-Means, Neural Gas, Growing Neural Gas, Hierarchical\nClustering, Sequential Information Bottleneck, Self-Organizing Maps,\nSpectral Clustering, Minimum Entropy Clustering.\n\n- **Association Rule & Frequent Itemset Mining:**\nFP-growth mining algorithm.\n\n- **Manifold Learning:**\nIsoMap, LLE, Laplacian Eigenmap, t-SNE, UMAP, PCA, Kernel PCA,\nProbabilistic PCA, GHA, Random Projection, ICA.\n\n- **Multi-Dimensional Scaling:**\nClassical MDS, Isotonic MDS, Sammon Mapping.\n\n- **Nearest Neighbor Search:**\nBK-Tree, Cover Tree, KD-Tree, SimHash, LSH.\n\n- **Sequence Learning:**\nHidden Markov Model, Conditional Random Field.\n\n- **Natural Language Processing:**\nSentence Splitter and Tokenizer, Bigram Statistical Test, Phrase Extractor,\nKeyword Extractor, Stemmer, POS Tagging, Relevance Ranking\n\nYou can use the libraries through Maven central repository by adding the\nfollowing to your project pom.xml file.\n```\n    <dependency>\n      <groupId>com.github.haifengl</groupId>\n      <artifactId>smile-core</artifactId>\n      <version>2.6.0</version>\n    </dependency>\n```\n\nFor NLP, use the artifactId smile-nlp.\n\nFor Scala API, please use\n```\n    libraryDependencies += \"com.github.haifengl\" %% \"smile-scala\" % \"2.6.0\"\n```\n\nFor Kotlin API, add the below into the `dependencies` section\nof Gradle build script.\n```\n    implementation(\"com.github.haifengl:smile-kotlin:2.6.0\")\n```\n\nFor Clojure API, add the following dependency to your project or build file:\n```\n    [org.clojars.haifengl/smile \"2.6.0\"]\n```\n\nSome algorithms rely on BLAS and LAPACK (e.g. manifold learning,\nsome clustering algorithms, Gaussian Process regression, MLP, etc).\nTo use these algorithms, you should include OpenBLAS for optimized matrix\ncomputation:\n```\n    libraryDependencies ++= Seq(\n      \"org.bytedeco\" % \"javacpp\"   % \"1.5.4\"        classifier \"macosx-x86_64\" classifier \"windows-x86_64\" classifier \"linux-x86_64\" classifier \"linux-arm64\" classifier \"linux-ppc64le\" classifier \"android-arm64\" classifier \"ios-arm64\",\n      \"org.bytedeco\" % \"openblas\"  % \"0.3.10-1.5.4\" classifier \"macosx-x86_64\" classifier \"windows-x86_64\" classifier \"linux-x86_64\" classifier \"linux-arm64\" classifier \"linux-ppc64le\" classifier \"android-arm64\" classifier \"ios-arm64\",\n      \"org.bytedeco\" % \"arpack-ng\" % \"3.7.0-1.5.4\"  classifier \"macosx-x86_64\" classifier \"windows-x86_64\" classifier \"linux-x86_64\" classifier \"linux-arm64\" classifier \"linux-ppc64le\"\n    )\n```\nIn this example, we include all supported 64-bit platforms and filter out\n32-bit platforms. The user should include only the needed platforms to save\nspaces.\n\nIf you prefer other BLAS implementations, you can use any library found on\nthe \"java.library.path\" or on the class path, by specifying it with the\n\"org.bytedeco.openblas.load\" system property. For example, to use the BLAS\nlibrary from the Accelerate framework on Mac OS X, we can pass options such\nas `-Djava.library.path=/usr/lib/ -Dorg.bytedeco.openblas.load=blas`.\n\nFor a default installation of MKL that would be `-Dorg.bytedeco.openblas.load=mkl_rt`.\nOr you may simply include `smile-mkl` module in your project, which includes\nMKL binaries. With `smile-mkl` module in the class path, Smile will\nautomatically switch to MKL.\n```\n    libraryDependencies += \"com.github.haifengl\" %% \"smile-mkl\" % \"2.6.0\"\n```\n\n## Shell\nSmile comes with interactive shells for Java, Scala and Kotlin.\nDownload pre-packaged Smile from the\n[releases page](https://github.com/haifengl/smile/releases).\nIn the home directory of Smile, type\n```\n    ./bin/smile\n```\nto enter the Scala shell. You can run any valid Scala expressions\nin the shell. In the simplest case, you can use it as a calculator.\nBesides, all high-level Smile operators are predefined in the shell.\nBy default, the shell uses up to 75% memory. If you need more memory\nto handle large data, use the option `-J-Xmx` or `-XX:MaxRAMPercentage`.\nFor example,\n```\n    ./bin/smile -J-Xmx30G\n```\nYou can also modify the configuration file `./conf/smile.ini` for the\nmemory and other JVM settings.\n\nTo use Java's JShell, type\n```\n    ./bin/jshell.sh\n```\nwhich has Smile's jars in the classpath. Similarly, run\n```\n    ./bin/kotlin.sh\n```\nto enter Kotlin REPL.\n\n## Model Serialization\nMost models support the Java `Serializable` interface (all classifiers\ndo support `Serializable` interface) so that you can use them in Spark.\nFor reading/writing the models in non-Java code, we suggest [XStream]\n(https://github.com/x-stream/xstream) to serialize the trained models.\nXStream is a simple library to serialize objects to XML and back again.\nXStream is easy to use and doesn't require mappings (actually requires\nno modifications to objects). [Protostuff](http://code.google.com/p/protostuff/)\nis a nice alternative that supports forward-backward compatibility\n(schema evolution) and validation. Beyond XML, Protostuff supports many\nother formats such as JSON, YAML, protobuf, etc.\n\n## Visualization\nSmile provides a Swing-based data visualization library SmilePlot,\nwhich provides scatter plot, line plot, staircase plot, bar plot,\nbox plot, histogram, 3D histogram, dendrogram, heatmap, hexmap,\nQQ plot, contour plot, surface, and wireframe.\n\nTo use SmilePlot, add the following to dependencies\n```\n    <dependency>\n      <groupId>com.github.haifengl</groupId>\n      <artifactId>smile-plot</artifactId>\n      <version>2.6.0</version>\n    </dependency>\n```\n\nSmile also support data visualization in declarative approach.\nWith `smile.plot.vega package`, we can create a specification\nthat describes visualizations as mappings from data to properties\nof graphical marks (e.g., points or bars). The specification is\nbased on [Vega-Lite](https://vega.github.io/vega-lite/). The\nVega-Lite compiler automatically produces visualization components\nincluding axes, legends, and scales. It then determines properties\nof these components based on a set of carefully designed rules.\n\n## Gallery\n<table class=\"center\" width=\"100%\">\n    <tr>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-kpca.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-kpca-small.png\" alt=\"Kernel PCA\"></a>\n                <figcaption><h2>Kernel PCA</h2></figcaption>\n            </figure>\n        </td>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-isomap.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-isomap-small.png\" alt=\"IsoMap\"></a>\n                <figcaption><h2>IsoMap</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n    <tr>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-mds.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-mds-small.png\" alt=\"MDS\"></a>\n                <figcaption><h2>Multi-Dimensional Scaling</h2></figcaption>\n            </figure>\n        </td>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-som.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-som-small.png\" alt=\"SOM\"></a>\n                <figcaption><h2>SOM</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n    <tr>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-ann.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-ann-small.png\" alt=\"Neural Network\"></a>\n                <figcaption><h2>Neural Network</h2></figcaption>\n            </figure>\n        </td>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-svm.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-svm-small.png\" alt=\"SVM\"></a>\n                <figcaption><h2>SVM</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n    <tr>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-agglomerative-clustering.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-agglomerative-clustering-small.png\" alt=\"Agglomerative Clustering\"></a>\n                <figcaption><h2>Agglomerative Clustering</h2></figcaption>\n            </figure>\n        </td>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-xmeans.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-xmeans-small.png\" alt=\"X-Means\"></a>\n                <figcaption><h2>X-Means</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n    <tr>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-dbscan.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-dbscan-small.png\" alt=\"DBSCAN\"></a>\n                <figcaption><h2>DBSCAN</h2></figcaption>\n            </figure>\n        </td>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-neural-gas.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-neural-gas-small.png\" alt=\"Neural Gas\"></a>\n                <figcaption><h2>Neural Gas</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n    <tr>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-wavelet.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-wavelet-small.png\" alt=\"Wavelet\"></a>\n                <figcaption><h2>Wavelet</h2></figcaption>\n            </figure>\n        </td>\n        <td width=\"50%\">\n            <figure>\n                <a href=\"http://haifengl.github.io/gallery/smile-demo-mixture.png\"><img src=\"http://haifengl.github.io/gallery/smile-demo-mixture-small.png\" alt=\"Mixture\"></a>\n                <figcaption><h2>Exponential Family Mixture</h2></figcaption>\n            </figure>\n        </td>\n    </tr>\n</table>\n\n",
	"agile bash changelog commits contributors detailed git git-addons git-pathspec gitlog history meeting review reviewer shell shell-script statistical-analysis statistics stats suggestion": "\n# GIT quick statistics [![Backers on Open Collective](https://opencollective.com/git-quick-stats/backers/badge.svg)](#backers) [![Sponsors on Open Collective](https://opencollective.com/git-quick-stats/sponsors/badge.svg)](#sponsors) [![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=Simple%20and%20efficient%20way%20to%20access%20various%20statistics%20in%20git%20repository&url=https://github.com/arzzen/git-quick-stat&via=arzzen&hashtags=git,stats,tool,statistics,developers) [![Travis](https://api.travis-ci.org/arzzen/git-quick-stats.svg?branch=master)](https://travis-ci.org/arzzen/git-quick-stats) [![Homebrew package](https://repology.org/badge/version-for-repo/homebrew/git-quick-stats.svg)](https://formulae.brew.sh/formula/git-quick-stats#default) [![Linuxbrew package](https://repology.org/badge/version-for-repo/linuxbrew/git-quick-stats.svg)](https://repology.org/metapackage/git-quick-stats/packages)\n\n> `git-quick-stats` is a simple and efficient way to access various statistics in a git repository.\n>\n> Any git repository may contain tons of information about commits, contributors, and files. Extracting this information is not always trivial, mostly because there are a gadzillion options to a gadzillion git commands \u2013 I don\u2019t think there is a single person alive who knows them all. Probably not even [Linus Torvalds](https://github.com/torvalds) himself :).\n\n![mainMenuScreenshot](https://user-images.githubusercontent.com/8818630/154823670-f42a111b-45f4-47fc-aea7-80059827c8e6.png)\n\n\n## Table of Contents\n\n[**Screenshots**](#screenshots)\n\n[**Usage**](#usage)\n\n* [**Interactive**](#interactive)\n* [**Non-interactive**](#non-interactive)\n* [**Command-line arguments**](#command-line-arguments)\n* [**Git log since and until**](#git-log-since-and-until)\n* [**Git log limit**](#git-log-limit)\n* [**Git log options**](#git-log-options)\n* [**Git pathspec**](#git-pathspec)\n* [**Git merge view strategy**](#git-merge-view-strategy)\n* [**Color themes**](#color-themes)\n\n[**Installation**](#installation)\n\n* [**UNIX and Linux**](#unix-and-linux)\n* [**macOS**](#macos-homebrew)\n* [**Windows**](#windows)\n* [**Docker**](#docker)\n\n[**System requirements**](#system-requirements)\n\n* [**Dependencies**](#dependencies)\n\n[**FAQ**](#faq)\n\n[**Contribution**](#contribution)\n\n* [**Code reviews**](#code-reviews)\n* [**Some tips for good pull requests**](#some-tips-for-good-pull-requests)\n* [**Formatting**](#formatting)\n\n[**Tests**](#tests)\n\n[**Licensing**](#licensing)\n\n[**Contributors**](#contributors)\n\n* [**Backers**](#backers)\n* [**Sponsors**](#sponsors)\n\n## Screenshots\n\n![commitsByWeekdayScreenshot](https://user-images.githubusercontent.com/8818630/154823677-e34ca867-ae61-4755-bf89-c877f809c591.png)\n\n![commitsByHourScreenshot](https://user-images.githubusercontent.com/8818630/154823679-bdadc26c-c644-4a01-b625-85e330f85d41.png)\n\n## Usage\n\n### Interactive\n\n`git-quick-stats` has a built-in interactive menu that can be executed as such:\n\n```bash\ngit-quick-stats\n```\n\nOr\n\n```bash\ngit quick-stats\n```\n\n### Non-interactive\n\nFor those who prefer to utilize command-line options, `git-quick-stats` also has a non-interactive mode supporting both short and long options:\n\n```bash\ngit-quick-stats <optional-command-to-execute-directly>\n```\n\nOr\n\n```bash\ngit quick-stats <optional-command-to-execute-directly>\n```\n\n### Command-line arguments\n\nPossible arguments in short and long form:\n\n```bash\nGENERATE OPTIONS\n    -T, --detailed-git-stats\n        give a detailed list of git stats\n    -R, --git-stats-by-branch\n        see detailed list of git stats by branch\n    -c, --changelogs\n        see changelogs\n    -L, --changelogs-by-author\n        see changelogs by author\n    -S, --my-daily-stats\n        see your current daily stats\n    -V, --csv-output-by-branch\n        output daily stats by branch in CSV format\n    -j, --json-output\n        save git log as a JSON formatted file to a specified area\n\nLIST OPTIONS\n    -b, --branch-tree\n        show an ASCII graph of the git repo branch history\n    -D, --branches-by-date\n        show branches by date\n    -C, --contributors\n        see a list of everyone who contributed to the repo\n    -a, --commits-per-author\n        displays a list of commits per author\n    -d, --commits-per-day\n        displays a list of commits per day\n    -Y, --commits-by-year\n        displays a list of commits per year\n    -m, --commits-by-month\n        displays a list of commits per month\n    -w, --commits-by-weekday\n        displays a list of commits per weekday\n    -o, --commits-by-hour\n        displays a list of commits per hour\n    -A, --commits-by-author-by-hour\n        displays a list of commits per hour by author\n    -z, --commits-by-timezone\n        displays a list of commits per timezone\n    -Z, --commits-by-author-by-timezone\n        displays a list of commits per timezone by author\n\nSUGGEST OPTIONS\n    -r, --suggest-reviewers\n        show the best people to contact to review code\n    -h, -?, --help\n        display this help text in the terminal\n```\n\n### Git log since and until\n\nYou can set the variables `_GIT_SINCE` and/or `_GIT_UNTIL` before running `git-quick-stats` to limit the git log. These work similar to git's built-in `--since` and `--until` log options.\n\n```bash\nexport _GIT_SINCE=\"2017-01-20\"\nexport _GIT_UNTIL=\"2017-01-22\"\n```\n\nOnce set, run `git quick-stats` as normal. Note that this affects all stats that parse the git log history until unset.\n\n### Git log limit\n\nYou can set variable `_GIT_LIMIT` for limited output. It will affect the \"changelogs\" and \"branch tree\" options.\n\n```bash\nexport _GIT_LIMIT=20\n```\n\n### Git log options\n\nYou can set `_GIT_LOG_OPTIONS` for [git log options](https://git-scm.com/docs/git-log#_options):\n\n```bash\nexport _GIT_LOG_OPTIONS=\"--ignore-all-space --ignore-blank-lines\"\n```\n\n### Git pathspec\n\nYou can exclude a directory from the stats by using [pathspec](https://git-scm.com/docs/gitglossary#gitglossary-aiddefpathspecapathspec)\n\n```bash\nexport _GIT_PATHSPEC=':!directory'\n```\n\nYou can also exclude files from the stats. Note that it works with any alphanumeric, glob, or regex that git respects.\n\n```bash\nexport _GIT_PATHSPEC=':!package-lock.json'\n```\n\n### Git merge view strategy\n\nYou can set the variable `_GIT_MERGE_VIEW` to enable merge commits to be part of the stats by setting `_GIT_MERGE_VIEW` to `enable`. You can also choose to only show merge commits by setting `_GIT_MERGE_VIEW` to `exclusive`. Default is to not show merge commits. These work similar to git's built-in `--merges` and `--no-merges` log options.\n\n```bash\nexport _GIT_MERGE_VIEW=\"enable\"\nexport _GIT_MERGE_VIEW=\"exclusive\"\n```\n\n### Git branch\n\nYou can set the variable `_GIT_BRANCH` to set the branch of the stats. Works with commands `--git-stats-by-branch` and `--csv-output-by-branch`.\n\n```bash\nexport _GIT_BRANCH=\"master\"\n```\n\n### Color themes\n\nYou can change to the legacy color scheme by toggling the variable `_MENU_THEME` between `default` and `legacy`\n\n```bash\nexport _MENU_THEME=\"legacy\"\n```\n\n![legacyThemeScreenshot](https://user-images.githubusercontent.com/8818630/154823711-3dd0c268-f3cb-42e5-9094-0eb8e45d1761.png)\n\n## Installation\n\n### Debian and Ubuntu\n\nIf you are on at least Debian Bullseye or Ubuntu Focal you can use apt for installation:\n\n```bash\napt install git-quick-stats\n```\n\n### UNIX and Linux\n\n```bash\ngit clone https://github.com/arzzen/git-quick-stats.git && cd git-quick-stats\nsudo make install\n```\n\nFor uninstalling, open up the cloned directory and run\n\n```bash\nsudo make uninstall\n```\n\nFor update/reinstall\n\n```bash\nsudo make reinstall\n```\n\n### macOS (homebrew)\n\n```bash\nbrew install git-quick-stats\n```\n\nOr you can follow the UNIX and Linux instructions if you wish.\n\n### Windows\n\nIf you are installing with Cygwin, use these scripts:\n\n* [installer](https://gist.github.com/arzzen/35e09866dfdadf2108b2420045739245)\n* [uninstaller](https://gist.github.com/arzzen/21c660014d0663b6c5710014714779d6)\n\nIf you are wishing to use this with WSL, follow the UNIX and Linux instructions.\n\n### Docker\n\nYou can use the Docker image provided:\n\n* Build: `docker build -t arzzen/git-quick-stats .`\n* Run interactive menu: `docker run --rm -it -v $(pwd):/git arzzen/git-quick-stats`\n* Docker pull command: `docker pull arzzen/git-quick-stats` [docker repository](https://hub.docker.com/r/arzzen/git-quick-stats)\n\n## System requirements\n\n* An OS with a Bash shell\n* Tools we use:\n\n```bash\nawk\nbasename\ncat\ncolumn\necho\ngit\ngrep\nhead\nprintf\nseq\nsort\ntput\ntr\nuniq\n```\n\n### Dependencies\n\n* [`bsdmainutils`](https://packages.debian.org/sid/bsdmainutils) `apt install bsdmainutils`\n\n## FAQ\n\n*Q:* I get some errors after run git-quick-stats in cygwin like `/usr/local/bin/git-quick-stats: line 2: $'\\r': command not found`\n\n*A:* You can run the dos2unix app in cygwin as follows: `/bin/dos2unix.exe /usr/local/bin/git-quick-stats`. This will convert the script from the CR-LF convention that Microsoft uses to the LF convention that UNIX, OS X, and Linux use. You should then should be able to run it as normal.\n\n*Q:* How they could be used in a project with many git projects and statistics would show a summary of all git projects?\n\n*A:* If you want to include submodule logs, you can try using the following: `export _GIT_LOG_OPTIONS=\"-p --submodule=log\"`\n(more info about [git log --submodule](https://git-scm.com/docs/git-log#Documentation/git-log.txt---submoduleltformatgt))\n\n## Contribution\n\nWant to contribute? Great! First, read this page.\n\n### Code reviews\n\nAll submissions, including submissions by project members, require review.</br>\nWe use GitHub pull requests for this purpose.\n\n### Some tips for good pull requests\n\n* Use our code </br>\n  When in doubt, try to stay true to the existing code of the project.\n* Write a descriptive commit message. What problem are you solving and what\n  are the consequences? Where and what did you test? Some good tips:\n  [here](http://robots.thoughtbot.com/5-useful-tips-for-a-better-commit-message)\n  and [here](https://www.kernel.org/doc/Documentation/SubmittingPatches).\n* If your PR consists of multiple commits which are successive improvements /\n  fixes to your first commit, consider squashing them into a single commit\n  (`git rebase -i`) such that your PR is a single commit on top of the current\n  HEAD. This make reviewing the code so much easier, and our history more\n  readable.\n\n### Formatting\n\nThis documentation is written using standard [markdown syntax](https://help.github.com/articles/markdown-basics/). Please submit your changes using the same syntax.\n\n## Tests\n\n[![codecov](https://codecov.io/gh/arzzen/git-quick-stats/branch/master/graph/badge.svg)](https://codecov.io/gh/arzzen/git-quick-stats)\n\n```bash\nmake test\n```\n\n## Licensing\n\nMIT see [LICENSE][] for the full license text.\n\n   [read this page]: http://github.com/arzzen/git-quick-stats/blob/master/.github/CONTRIBUTING.md\n   [landing page]: http://arzzen.github.io/git-quick-stats\n   [LICENSE]: https://github.com/arzzen/git-quick-stats/blob/master/LICENSE\n\n## Contributors\n\nThis project exists thanks to all the people who contribute.\n\n[![contributors](https://opencollective.com/git-quick-stats/contributors.svg?width=890&button=false)](https://github.com/arzzen/git-quick-stats/graphs/contributors)\n\n### Backers\n\nThank you to all our backers! \ud83d\ude4f [[Become a backer](https://opencollective.com/git-quick-stats#backer)]\n\n[![backers](https://opencollective.com/git-quick-stats/backers.svg?width=890)](https://opencollective.com/git-quick-stats#backers)\n\n### Sponsors\n\nSupport this project by becoming a sponsor. Your logo will show up here with a link to your website. [[Become a sponsor](https://opencollective.com/git-quick-stats#sponsor)]\n\n[![sponsor0](https://opencollective.com/git-quick-stats/sponsor/0/avatar.svg?v=1)](https://opencollective.com/git-quick-stats/sponsor/0/website)\n[![sponsor1](https://opencollective.com/git-quick-stats/sponsor/1/avatar.svg)](https://opencollective.com/git-quick-stats/sponsor/1/website)\n[![sponsor2](https://opencollective.com/git-quick-stats/sponsor/2/avatar.svg)](https://opencollective.com/git-quick-stats/sponsor/2/website)\n[![sponsor3](https://opencollective.com/git-quick-stats/sponsor/3/avatar.svg)](https://opencollective.com/git-quick-stats/sponsor/3/website)\n[![sponsor4](https://opencollective.com/git-quick-stats/sponsor/4/avatar.svg)](https://opencollective.com/git-quick-stats/sponsor/4/website)\n[![sponsor5](https://opencollective.com/git-quick-stats/sponsor/5/avatar.svg)](https://opencollective.com/git-quick-stats/sponsor/5/website)\n[![sponsor6](https://opencollective.com/git-quick-stats/sponsor/6/avatar.svg)](https://opencollective.com/git-quick-stats/sponsor/6/website)\n[![sponsor7](https://opencollective.com/git-quick-stats/sponsor/7/avatar.svg)](https://opencollective.com/git-quick-stats/sponsor/7/website)\n[![sponsor8](https://opencollective.com/git-quick-stats/sponsor/8/avatar.svg)](https://opencollective.com/git-quick-stats/sponsor/8/website)\n[![sponsor9](https://opencollective.com/git-quick-stats/sponsor/9/avatar.svg)](https://opencollective.com/git-quick-stats/sponsor/9/website)\n\n[![61999966](https://user-images.githubusercontent.com/6382002/130024560-65bb49a6-c7e9-48f9-8427-a29d8ff2a3db.png)](https://quaestor.com/?utm_source=github&utm_category=sponsor)\n\n",
	"bayesian-methods data-science deep-learning machine-learning neural-networks probabilistic-programming statistics tensorflow": "[![edward](../master/docs/images/edward_200.png?raw=true)](http://edwardlib.org)\n\n[![Build Status](https://travis-ci.org/blei-lab/edward.svg?branch=master)](https://travis-ci.org/blei-lab/edward)\n[![Coverage Status](https://coveralls.io/repos/github/blei-lab/edward/badge.svg?branch=master&cacheBuster=1)](https://coveralls.io/github/blei-lab/edward?branch=master)\n[![Join the chat at https://gitter.im/blei-lab/edward](https://badges.gitter.im/blei-lab/edward.svg)](https://gitter.im/blei-lab/edward?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n[Edward](http://edwardlib.org) is a Python library for probabilistic modeling,\ninference, and criticism. It is a testbed for fast experimentation and research\nwith probabilistic models, ranging from classical hierarchical models on small\ndata sets to complex deep probabilistic models on large data sets. Edward fuses\nthree fields: Bayesian statistics and machine learning, deep learning, and\nprobabilistic programming.\n\nIt supports __modeling__ with\n\n+ Directed graphical models\n+ Neural networks (via libraries such as\n    [`tf.layers`](https://www.tensorflow.org/api_docs/python/tf/layers)\n    and\n    [Keras](http://keras.io))\n+ Implicit generative models\n+ Bayesian nonparametrics and probabilistic programs\n\nIt supports __inference__ with\n\n+ Variational inference\n  + Black box variational inference\n  + Stochastic variational inference\n  + Generative adversarial networks\n  + Maximum a posteriori estimation\n+ Monte Carlo\n  + Gibbs sampling\n  + Hamiltonian Monte Carlo\n  + Stochastic gradient Langevin dynamics\n+ Compositions of inference\n  + Expectation-Maximization\n  + Pseudo-marginal and ABC methods\n  + Message passing algorithms\n\nIt supports __criticism__ of the model and inference with\n\n+ Point-based evaluations\n+ Posterior predictive checks\n\nEdward is built on top of [TensorFlow](https://www.tensorflow.org).\nIt enables features such as computational graphs, distributed\ntraining, CPU/GPU integration, automatic differentiation, and\nvisualization with TensorBoard.\n\n## Resources\n\n+ [Edward website](http://edwardlib.org)\n+ [Edward Forum](http://discuss.edwardlib.org)\n+ [Edward Gitter channel](http://gitter.im/blei-lab/edward)\n+ [Edward releases](https://github.com/blei-lab/edward/releases)\n+ [Edward papers, posters, and slides](https://github.com/edwardlib/papers)\n\nSee [Getting Started](http://edwardlib.org/getting-started) for how to install Edward.\n",
	"analytics monitoring notifications plex plexpy python statistics stats tautulli": "# Tautulli\n\nA python based web application for monitoring, analytics and notifications for \n[Plex Media Server](https://plex.tv).\n\nThis project is based on code from [Headphones](https://github.com/rembo10/headphones)\nand [PlexWatchWeb](https://github.com/ecleese/plexWatchWeb).\n\n## Features\n\n-   Responsive web design viewable on desktop, tablet and mobile web browsers.\n-   Themed to complement Plex/Web.\n-   Easy configuration setup (no separate web server required).\n-   Monitor current Plex Media Server activity.\n-   Fully customizable notifications for stream activity and recently added media.\n-   Top statistics on home page with configurable duration and measurement metric.\n-   Global watching history with search/filtering & dynamic column sorting.\n-   Full user list with general information and comparison stats.\n-   Individual user information including devices IP addresses.\n-   Complete library statistics and media file information.\n-   Rich analytics presented using Highcharts graphing.\n-   Beautiful content information pages.\n-   Full sync list data on all users syncing items from your library.\n-   And many more!!\n\n## Preview\n\n[Full preview gallery available on our website][Tautulli]\n\n![Tautulli Homepage](https://tautulli.com/images/screenshots/activity-compressed.jpg?v=2)\n\n## Installation\n\n[![Python][badge-python]][Python]\n[![Docker Pulls][badge-docker-pulls]][DockerHub]\n[![Docker Stars][badge-docker-stars]][DockerHub]\n[![Downloads][badge-downloads]][Releases Latest]\n\n[badge-python]: https://img.shields.io/badge/python->=3.7-blue?style=flat-square\n[badge-docker-pulls]: https://img.shields.io/docker/pulls/tautulli/tautulli?style=flat-square\n[badge-docker-stars]: https://img.shields.io/docker/stars/tautulli/tautulli?style=flat-square\n[badge-downloads]: https://img.shields.io/github/downloads/Tautulli/Tautulli/total?style=flat-square\n\n| Status | Branch: `master` | Branch: `beta` | Branch: `nightly` |\n| --- | --- | --- | --- |\n| Release   | [![Release@master][badge-release-master]][Releases Latest] <br> [![Release Date@master][badge-release-master-date]][Releases Latest] | [![Release@beta][badge-release-beta]][Releases] <br> [![Commits@beta][badge-release-beta-commits]][Commits Beta] | [![Last Commits@nightly][badge-release-nightly-last-commit]][commits Nightly] <br> [![Commits@nightly][badge-release-nightly-commits]][Commits Nightly] |\n| Docker    | [![Docker@master][badge-docker-master]][DockerHub] <br> [![Docker Build@master][badge-docker-master-ci]][Publish Docker Master] | [![Docker@beta][badge-docker-beta]][DockerHub] <br> [![Docker Build@beta][badge-docker-beta-ci]][Publish Docker Beta] | [![Docker@nightly][badge-docker-nightly]][DockerHub] <br> [![Docker Build@nightly][badge-docker-nightly-ci]][Publish Docker Nightly] |\n| Snap      | [![Snap@master][badge-snap-master]][Snapcraft] <br> [![Snap Build@master][badge-snap-master-ci]][Publish Snap Master] | [![Snap@beta][badge-snap-beta]][Snapcraft] <br> [![Snap Build@beta][badge-snap-beta-ci]][Publish Snap Beta] | [![Snap@nightly][badge-snap-nightly]][Snapcraft] <br> [![Snap Build@nightly][badge-snap-nightly-ci]][Publish Snap Nightly] |\n| Installer | [![Windows@master][badge-installer-master-win]][Releases Latest] <br> [![MacOS@master][badge-installer-master-macos]][Releases Latest] <br> [![Installer Build@master][badge-installer-master-ci]][Publish Installer Master] | [![Windows@beta][badge-installer-beta-win]][Releases] <br> [![MacOS@beta][badge-installer-beta-macos]][Releases] <br> [![Installer Build@beta][badge-installer-beta-ci]][Publish Installer Beta] | [![Installer Build@nightly][badge-installer-nightly-ci]][Publish Installer Nightly] |\n\nRead the [Installation Guides][Installation] for instructions on how to install Tautulli.\n\n[badge-release-master]: https://img.shields.io/github/v/release/Tautulli/Tautulli?style=flat-square\n[badge-release-master-date]: https://img.shields.io/github/release-date/Tautulli/Tautulli?style=flat-square&color=blue\n[badge-release-beta]: https://img.shields.io/github/v/release/Tautulli/Tautulli?include_prereleases&style=flat-square\n[badge-release-beta-commits]: https://img.shields.io/github/commits-since/Tautulli/Tautulli/latest/beta?style=flat-square&color=blue\n[badge-release-nightly-last-commit]: https://img.shields.io/github/last-commit/Tautulli/Tautulli/nightly?style=flat-square&color=blue\n[badge-release-nightly-commits]: https://img.shields.io/github/commits-since/Tautulli/Tautulli/latest/nightly?style=flat-square&color=blue\n[badge-docker-master]: https://img.shields.io/badge/docker-latest-blue?style=flat-square\n[badge-docker-master-ci]: https://img.shields.io/github/workflow/status/Tautulli/Tautulli/Publish%20Docker/master?style=flat-square\n[badge-docker-beta]: https://img.shields.io/badge/docker-beta-blue?style=flat-square\n[badge-docker-beta-ci]: https://img.shields.io/github/workflow/status/Tautulli/Tautulli/Publish%20Docker/beta?style=flat-square\n[badge-docker-nightly]: https://img.shields.io/badge/docker-nightly-blue?style=flat-square\n[badge-docker-nightly-ci]: https://img.shields.io/github/workflow/status/Tautulli/Tautulli/Publish%20Docker/nightly?style=flat-square\n[badge-snap-master]: https://img.shields.io/badge/snap-stable-blue?style=flat-square\n[badge-snap-master-ci]: https://img.shields.io/github/workflow/status/Tautulli/Tautulli/Publish%20Snap/master?style=flat-square\n[badge-snap-beta]: https://img.shields.io/badge/snap-beta-blue?style=flat-square\n[badge-snap-beta-ci]: https://img.shields.io/github/workflow/status/Tautulli/Tautulli/Publish%20Snap/beta?style=flat-square\n[badge-snap-nightly]: https://img.shields.io/badge/snap-edge-blue?style=flat-square\n[badge-snap-nightly-ci]: https://img.shields.io/github/workflow/status/Tautulli/Tautulli/Publish%20Snap/nightly?style=flat-square\n[badge-installer-master-win]: https://img.shields.io/github/v/release/Tautulli/Tautulli?label=windows&style=flat-square\n[badge-installer-master-macos]: https://img.shields.io/github/v/release/Tautulli/Tautulli?label=macos&style=flat-square\n[badge-installer-master-ci]: https://img.shields.io/github/workflow/status/Tautulli/Tautulli/Publish%20Installers/master?style=flat-square\n[badge-installer-beta-win]: https://img.shields.io/github/v/release/Tautulli/Tautulli?label=windows&include_prereleases&style=flat-square\n[badge-installer-beta-macos]: https://img.shields.io/github/v/release/Tautulli/Tautulli?label=macos&include_prereleases&style=flat-square\n[badge-installer-beta-ci]: https://img.shields.io/github/workflow/status/Tautulli/Tautulli/Publish%20Installers/beta?style=flat-square\n[badge-installer-nightly-ci]: https://img.shields.io/github/workflow/status/Tautulli/Tautulli/Publish%20Installers/nightly?style=flat-square\n\n## Support\n\n[![Wiki][badge-wiki]][Wiki]\n[![Discord][badge-discord]][Discord]\n[![Reddit][badge-reddit]][Reddit]\n[![Plex Forums][badge-forums]][Plex Forums]\n[![Issues][badge-issues]][Issues]\n\n[badge-wiki]: https://img.shields.io/badge/github-wiki-black?style=flat-square\n[badge-discord]: https://img.shields.io/discord/183396325142822912?label=discord&style=flat-square&color=7289DA\n[badge-reddit]: https://img.shields.io/reddit/subreddit-subscribers/tautulli?label=reddit&style=flat-square&color=FF5700\n[badge-forums]: https://img.shields.io/badge/plex%20forums-discussion-E5A00D?style=flat-square\n[badge-issues]: https://img.shields.io/badge/github-issues-black?style=flat-square\n\nIf you think you've found a bug in Tautulli make sure you have read the [FAQ][]\nfirst to make sure it hasn't been covered by one of the questions there. If your\nproblem isn't answered in the FAQ try the following first:\n\n-   Update to the latest version of Tautulli.\n-   Turning your device off and on again.\n-   Analyzing your logs, you just might find the solution yourself!\n-   Using the **search** function to see if this issue has already been reported/solved.\n-   Checking the [Wiki][] for [Installation][] instructions and reading the [FAQs][FAQ].\n-   For basic questions try asking on [Discord][], [Reddit][], \n    or the [Plex Forums][] first before opening an issue.\n\n**If nothing has worked:**\n\n1.  Please check the [issues tracker][Issues] to see if someone else has already reported the bug.\n2.  If this is a new bug, open a [bug report][Issue New] on the issues tracker.\n3.  Provide a clear title to easily help identify your problem.\n4.  Use proper [Markdown syntax][] to structure your post (i.e. code/log in code blocks).\n5.  Make sure to fill out the required information on the issue template.\n6.  Close your issue when it's solved! If you found the solution yourself please\n    comment so that others benefit from it.\n\n## Feature Requests\n\n1.  Pleases check the [issues tracker][Issues] to see if someone else has already requested the feature.\n    If a similar idea has already been requested, _give it a thumbs up_. **Do not comment\n    with `+1` or something similar as it creates unnecessary spam.**\n2.  If this is a new feature request, open a [feature request][Issue New] on the issues tracker.\n\n## License\n\n[![License][badge-license]][License]\n\n[badge-license]: https://img.shields.io/github/license/Tautulli/Tautulli?style=flat-square\n\nThis is free software under the GPL v3 open source license. Feel free to do with it what you wish,\nbut any modification must be open sourced. A copy of the license is included.\n\nThis software includes Highsoft software libraries which you may freely distribute for \nnon-commercial use. Commerical users must licence this software, for more information visit\nhttps://shop.highsoft.com/faq/non-commercial#non-commercial-redistribution.\n\n\n[Python]: https://python.org/downloads\n[DockerHub]: https://hub.docker.com/r/tautulli/tautulli\n[Releases]: https://github.com/Tautulli/Tautulli/releases\n[Releases Latest]: https://github.com/Tautulli/Tautulli/releases/latest\n[License]: https://github.com/Tautulli/Tautulli/blob/master/LICENSE\n[FAQ]: https://github.com/Tautulli/Tautulli/wiki/Frequently-Asked-Questions\n[Installation]: https://github.com/Tautulli/Tautulli/wiki/Installation\n[Issues]: https://github.com/Tautulli/Tautulli/issues\n[Issue New]: https://github.com/Tautulli/Tautulli/issues/new/choose\n[Markdown syntax]: https://help.github.com/articles/github-flavored-markdown\n[Tautulli]: http://tautulli.com\n[Wiki]: https://github.com/Tautulli/Tautulli/wiki\n[Discord]: https://tautulli.com/discord\n[Reddit]: https://reddit.com/r/Tautulli\n[Plex Forums]: https://forums.plex.tv/t/tautulli-monitor-your-plex-media-server/225242\n[Snapcraft]: https://snapcraft.io/tautulli\n[Commits Beta]: https://github.com/Tautulli/Tautulli/commits/beta\n[Commits Nightly]: https://github.com/Tautulli/Tautulli/commits/nightly\n\n[Publish Docker Master]: https://github.com/Tautulli/Tautulli/actions?query=workflow%3A\"Publish+Docker\"+branch%3Amaster\n[Publish Docker Beta]: https://github.com/Tautulli/Tautulli/actions?query=workflow%3A\"Publish+Docker\"+branch%3Abeta\n[Publish Docker Nightly]: https://github.com/Tautulli/Tautulli/actions?query=workflow%3A\"Publish+Docker\"+branch%3Anightly\n[Publish Snap Master]: https://github.com/Tautulli/Tautulli/actions?query=workflow%3A\"Publish+Snap\"+branch%3Amaster\n[Publish Snap Beta]: https://github.com/Tautulli/Tautulli/actions?query=workflow%3A\"Publish+Snap\"+branch%3Abeta\n[Publish Snap Nightly]: https://github.com/Tautulli/Tautulli/actions?query=workflow%3A\"Publish+Snap\"+branch%3Anightly\n[Publish Installer Master]: https://github.com/Tautulli/Tautulli/actions?query=workflow%3A\"Publish+Installers\"+branch%3Amaster\n[Publish Installer Beta]: https://github.com/Tautulli/Tautulli/actions?query=workflow%3A\"Publish+Installers\"+branch%3Abeta\n[Publish Installer Nightly]: https://github.com/Tautulli/Tautulli/actions?query=workflow%3A\"Publish+Installers\"+branch%3Anightly\n",
	"c-sharp computer-vision ffmpeg framework image-processing machine-learning neural-network nuget statistics support-vector-machines unity3d visual-studio": "# Accord.NET Framework\r\n\r\n[![DOI](https://zenodo.org/badge/3964514.svg)](https://zenodo.org/badge/latestdoi/3964514)\r\n[![Build status](https://ci.appveyor.com/api/projects/status/ns9h9opjmu8iw3ep?svg=true)](https://ci.appveyor.com/project/cesarsouza/framework)\r\n[![Build Status](https://travis-ci.org/accord-net/framework.svg?branch=development)](https://travis-ci.org/accord-net/framework)\r\n[![Github All Releases](https://img.shields.io/github/downloads/accord-net/framework/total.svg)]()\r\n[![License](https://img.shields.io/badge/license-LGPL--2.1-blue.svg)](LICENSE)\r\n[![NuGet](https://img.shields.io/nuget/v/Accord.svg)]()\r\n[![NuGet Pre Release](https://img.shields.io/nuget/vpre/Accord.svg)]()\r\n<!--[![GitHub release](https://img.shields.io/github/release/accord-net/framework.svg?maxAge=2592000)]()-->\r\n\r\nThe Accord.NET project provides machine learning, statistics, artificial intelligence, computer vision and image processing methods to .NET. It can be used on Microsoft Windows, Xamarin, Unity3D, Windows Store applications, Linux or mobile.\r\n\r\nAfter merging with the AForge.NET project, the framework now offers a unified API for learning/training machine learning models that is both easy to use *and* extensible. It is based on the following pattern:\r\n\r\n- Choose a [learning algorithm](http://accord-framework.net/docs/html/N_Accord_MachineLearning.htm) that provides a Learn(x, y) or Learn(x) method;\r\n- [Use the Learn(x, y)](http://accord-framework.net/docs/html/M_Accord_MachineLearning_VectorMachines_Learning_SequentialMinimalOptimization_Learn.htm) to create a [machine learning model](http://accord-framework.net/docs/html/T_Accord_MachineLearning_VectorMachines_SupportVectorMachine.htm) learned from the data; \r\n- Use the model's [Transform](http://accord-framework.net/docs/html/M_Accord_MachineLearning_ClassifierBase_2_Transform.htm), [Decide](http://accord-framework.net/docs/html/M_Accord_MachineLearning_ClassifierBase_2_Decide_1.htm), [Scores](http://accord-framework.net/docs/html/M_Accord_MachineLearning_BinaryScoreClassifierBase_1_Scores_3.htm), [Probabilities](http://accord-framework.net/docs/html/M_Accord_MachineLearning_BinaryLikelihoodClassifierBase_1_Probabilities.htm) or [LogLikelihoods](http://accord-framework.net/docs/html/M_Accord_MachineLearning_VectorMachines_SupportVectorMachine_2_LogLikelihood.htm) methods.\r\n\r\nFor more information, please see the [getting started guide](https://github.com/accord-net/framework/wiki/Getting-started), and check [the classfication wiki](https://github.com/accord-net/framework/wiki/Classification). *Please do not hesitate to edit the wiki if you would like!*\r\n\r\n\r\n# Installing\r\n\r\nTo install the framework in your application, please use NuGet. If you are on Visual Studio, right-click on the \"References\" item in your solution folder, and select \"Manage NuGet Packages.\" Search for Accord.MachineLearning ([or equivalently, Accord.Math, Accord.Statistics or Accord.Imaging depending on your initial goal](https://www.nuget.org/packages?q=accord.net)) and select \"Install.\"\r\n\r\nIf you would like to install the framework on [Unity3D applications](https://unity3d.com), download the \"libsonly\" compressed archive from the [framework releases page](https://github.com/accord-net/framework/releases). Navigate to the Releases/Mono folder, and copy the .dll files to the Plugins folder in your Unity project. Finally, find and add the System.ComponentModel.DataAnnotations.dll assembly that should be available from your system to the Plugin folders as well.\r\n\r\n## Sample applications\r\n\r\nThe framework comes with a wide range of sample applications to help get you started quickly. If you downloaded the framework sources or cloned the repository, open the *Samples.sln* solution file in the Samples folder.\r\n\r\n\r\n# Building\r\n\r\n#### With Visual Studio 2015\r\n\r\nPlease download and install the following dependencies:\r\n\r\n- [T4 Toolbox for Visual Studio 2015](https://visualstudiogallery.msdn.microsoft.com/34b6d489-afbc-4d7b-82c3-dded2b726dbc)\r\n- [Sandcastle Help File Builder (with VS2015 extension)](https://github.com/EWSoftware/SHFB/releases)\r\n- [NUnit 3 Test Adapter](https://marketplace.visualstudio.com/items?itemName=NUnitDevelopers.NUnit3TestAdapter)\r\n\r\nThen navigate to the Sources directory, and open the *Accord.NET.sln* solution file. Note: the solution includes F# unit test projects that can be disabled/unloaded from the solution in case you do not have support for F# tools in your version of Visual Studio.\r\n\r\n\r\n#### With Visual Studio 2017\r\n\r\nPlease download and install the following dependencies:\r\n\r\n- [T4 Toolbox for Visual Studio 2017](https://github.com/hagronnestad/T4Toolbox/releases/tag/vs2017-b1)\r\n- [Sandcastle Help File Builder (with VS2017 extension)](https://github.com/EWSoftware/SHFB/releases)\r\n- [NUnit 3 Test Adapter](https://marketplace.visualstudio.com/items?itemName=NUnitDevelopers.NUnit3TestAdapter)\r\n- [Visual C++ Redistributable for Visual Studio 2015](https://www.microsoft.com/en-us/download/details.aspx?id=48145&751be11f-ede8-5a0c-058c-2ee190a24fa6) (both x64 and x86)\r\n\r\nThen navigate to the Sources directory, and open the *Accord.NET.sln* solution file. Note: the solution includes F# unit test projects that can be disabled/unloaded from the solution in case you do not have support for F# tools in your version of Visual Studio.\r\n\r\n\r\n#### With Mono in Linux\r\n\r\n    # Install Mono\r\n    sudo apt-get install mono-complete monodevelop monodevelop-nunit git autoconf make\r\n\r\n    # Clone the repository\r\n    git clone https://github.com/accord-net/framework.git\r\n\r\n    # Enter the directory\r\n    cd framework\r\n\r\n    # Build the framework solution using Mono\r\n    ./autogen.sh\r\n    make build\r\n    make samples\r\n    make test\r\n\r\n\r\n#### With Mono in OS X\r\n\r\n    # Install Mono\r\n    brew update\r\n    brew cask install mono-mdk pkg-config automake\r\n\r\n    # Clone the repository\r\n    git clone https://github.com/accord-net/framework.git\r\n\r\n    # Enter the directory\r\n    cd framework\r\n    \r\n    # Set some environment variables with OSX-specific paths\r\n    export PKG_CONFIG_PATH=/Library/Frameworks/Mono.framework/Versions/Current/lib/pkgconfig/\r\n    export MONO=/Library/Frameworks/Mono.framework/Versions/Current/bin/mono\r\n    export XBUILD=/Library/Frameworks/Mono.framework/Versions/Current/bin/xbuild\r\n    \r\n    # Build the framework solution using Mono\r\n    ./autogen.sh\r\n    make build\r\n    make samples\r\n    make test\r\n\r\n\r\n# Contributing\r\n\r\nIf you would like to contribute, please do so by helping us update the [project's Wiki pages](https://github.com/accord-net/framework/wiki). While you could also make a donation through PayPal [![Donate](https://www.paypalobjects.com/en_US/i/btn/btn_donate_LG.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=N4Q6YQSPWN8BG), Flattr [![Flattr this git repo](http://api.flattr.com/button/flattr-badge-large.png)](https://flattr.com/submit/auto?user_id=cesarsouza&url=https://github.com/accord-net/framework&title=Accord.NET&language=&tags=github&category=software), or any of the cryptocurrencies shown below, as well as fill-in bug reports and contribute code in the form of pull requests, the most precious donation we could receive would be a bit of your time - [please take some minutes to submit us more documentation examples to our Wiki pages](https://github.com/accord-net/framework/wiki) :wink: \r\n\r\nDonate using cryptocurrencies:\r\n- ```BTC: 16EUrG7AqbhrAbgVA1J3m4udFm3XFUntDE```\r\n- ```ETH: 0xc152EA8c985984C34C08b54201a632E98AE98e8F```\r\n- ```LTC: LPkWpq1ChUXXxpHZwvKFicVeWSXKPtnaYC```\r\n\r\nNote: all donations are 100% invested towards improving the framework, including, but not limited to, the hiring of extra developers to work on issues currently present at the project's issue tracker. If you would like to donate resources towards the development of a particular issue, please let us know!\r\n\r\nJoin the chat at https://gitter.im/accord-net/framework - but to have issues and questions answered, [post it as an issue](https://github.com/accord-net/framework/issues).\r\n",
	"cli cloc code complexity golang linux macos sloc sloccount statistics tokei windows": "Sloc Cloc and Code (scc)\n------------------------\n\n<img alt=\"scc\" src=https://github.com/boyter/scc/raw/master/scc.jpg>\n\nA tool similar to cloc, sloccount and tokei. For counting physical the lines of code, blank lines, comment lines, and physical lines of source code in many programming languages.\n\nGoal is to be the fastest code counter possible, but also perform COCOMO calculation like sloccount and to estimate code complexity similar to cyclomatic complexity calculators. In short one tool to rule them all.\n\nAlso it has a very short name which is easy to type `scc`. \n\nIf you don't like sloc cloc and code feel free to use the name `Succinct Code Counter`.\n\n[![Go](https://github.com/boyter/scc/actions/workflows/go.yml/badge.svg)](https://github.com/boyter/scc/actions/workflows/go.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/boyter/scc)](https://goreportcard.com/report/github.com/boyter/scc)\n[![Coverage Status](https://coveralls.io/repos/github/boyter/scc/badge.svg?branch=master)](https://coveralls.io/github/boyter/scc?branch=master)\n[![Scc Count Badge](https://sloc.xyz/github/boyter/scc/)](https://github.com/boyter/scc/)\n[![Mentioned in Awesome Go](https://awesome.re/mentioned-badge.svg)](https://github.com/avelino/awesome-go)\n\nDual-licensed under MIT or the [UNLICENSE](http://unlicense.org).\n\n### Install\n\n#### Go Get\n\nIf you are comfortable using Go and have >= 1.17 installed:\n\n`go install github.com/boyter/scc/v3@latest`\n\nor bleeding edge with\n\n`go install github.com/boyter/scc@master`\n\n#### Snap\n\nA [snap install](https://snapcraft.io/scc) exists thanks to [Ricardo](https://feliciano.tech/).\n\n`$ sudo snap install scc`\n\n*NB* Snap installed applications cannot run outside of `/home` https://askubuntu.com/questions/930437/permission-denied-error-when-running-apps-installed-as-snap-packages-ubuntu-17 so you may encounter issues if you use snap and attempt to run outside this directory.\n\n#### Homebrew\n\nOr if you have [homebrew](https://brew.sh/) installed\n\n`$ brew install scc`\n\n#### MacPorts\n\nOn macOS, you can also install via [MacPorts](https://www.macports.org)\n\n`$ sudo port install scc`\n\n#### Scoop\n\nOr if you are using [Scoop](https://scoop.sh/) on Windows\n\n`$ scoop install scc`\n\n#### Chocolatey\n\nOr if you are using [Chocolatey](https://chocolatey.org/) on Windows\n\n`$ choco install scc`\n\n#### Manual\n\nBinaries for Windows, GNU/Linux and macOS for both i386 and x86_64 machines are available from the [releases](https://github.com/boyter/scc/releases) page.\n\n#### GitHub Action workflow\n\nhttps://github.com/marketplace/actions/scc-docker-action https://github.com/iRyanBell/scc-docker-action\n\n_.github/workflows/main.yml_\n\n```\non: [push]\n\njobs:\n  scc_job:\n    runs-on: ubuntu-latest\n    name: A job to count the lines of code.\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n      - name: Get the lines of code.\n        id: scc\n        uses: iryanbell/scc-docker-action@v1.0.2\n        with:\n          args: ${{ env.workspace }} -i js,go,html,css\n```\n\n#### Other\n\nIf you would like to assist with getting `scc` added into apt/chocolatey/etc... please submit a PR or at least raise an issue with instructions.\n\n### Background\n\nRead all about how it came to be along with performance benchmarks,\n\n - https://boyter.org/posts/sloc-cloc-code/\n - https://boyter.org/posts/why-count-lines-of-code/\n - https://boyter.org/posts/sloc-cloc-code-revisited/\n - https://boyter.org/posts/sloc-cloc-code-performance/\n - https://boyter.org/posts/sloc-cloc-code-performance-update/\n\nSome reviews of `scc`\n\n - https://nickmchardy.com/2018/10/counting-lines-of-code-in-koi-cms.html\n - https://www.feliciano.tech/blog/determine-source-code-size-and-complexity-with-scc/\n - https://metaredux.com/posts/2019/12/13/counting-lines.html\n\nA talk given at the first GopherCon AU about `scc` (press S to see speaker notes)\n\n - https://boyter.org/static/gophercon-syd-presentation/\n - https://www.youtube.com/watch?v=jd-sjoy3GZo\n\nFor performance see the [Performance](https://github.com/boyter/scc#performance) section\n\nOther similar projects,\n\n - [SLOCCount](https://www.dwheeler.com/sloccount/) the original sloc counter\n - [cloc](https://github.com/AlDanial/cloc), inspired by SLOCCount; implemented in Perl for portability\n - [gocloc](https://github.com/hhatto/gocloc) a sloc counter in Go inspired by tokei\n - [loc](https://github.com/cgag/loc) rust implementation similar to tokei but often faster\n - [loccount](https://gitlab.com/esr/loccount) Go implementation written and maintained by ESR\n - [ployglot](https://github.com/vmchale/polyglot) ATS sloc counter\n - [tokei](https://github.com/XAMPPRocky/tokei) fast, accurate and written in rust\n - [sloc](https://github.com/flosse/sloc) coffeescript code counter\n\nInteresting reading about other code counting projects tokei, loc, polyglot and loccount\n\n - https://www.reddit.com/r/rust/comments/59bm3t/a_fast_cloc_replacement_in_rust/\n - https://www.reddit.com/r/rust/comments/82k9iy/loc_count_lines_of_code_quickly/\n - http://blog.vmchale.com/article/polyglot-comparisons\n - http://esr.ibiblio.org/?p=8270\n\nFurther reading about processing files on the disk performance\n\n - https://blog.burntsushi.net/ripgrep/\n \nUsing `scc` to process 40 TB of files from Github/Bitbucket/Gitlab\n\n - https://boyter.org/posts/an-informal-survey-of-10-million-github-bitbucket-gitlab-projects/\n\n### Pitch\n\nWhy use `scc`?\n\n - It is very fast and gets faster the more CPU you throw at it\n - Accurate\n - Works very well across multiple platforms without slowdown (Windows, Linux, macOS)\n - Large language support\n - Can ignore duplicate files\n - Has complexity estimations\n - You need to tell the difference between Coq and Verilog in the same directory\n - cloc yaml output support so potentially a drop in replacement for some users\n - Can identify or ignore minified files\n - Able to identify many #! files ADVANCED! https://github.com/boyter/scc/issues/115\n - Can ignore large files by lines or bytes\n\nWhy not use `scc`?\n\n - You don't like Go for some reason\n - It cannot count D source with different nested multi-line comments correctly https://github.com/boyter/scc/issues/27\n\n### Differences\n\nThere are some important differences between `scc` and other tools that are out there. Here are a few important ones for you to consider.\n\nBlank lines inside comments are counted as comments. While the line is technically blank the decision was made that \nonce in a comment everything there should be considered a comment until that comment is ended. As such the following,\n \n```\n/* blank lines follow\n\n\n*/\n```\n\nWould be counted as 4 lines of comments. This is noticeable when comparing scc's output to other tools on large\nrepositories.\n\n`scc` is able to count verbatim strings correctly. For example in C# the following,\n\n```\nprivate const string BasePath = @\"a:\\\";\n// The below is returned to the user as a version\nprivate const string Version = \"1.0.0\";\n```\n\nBecause of the prefixed @ this string ends at the trailing \" by ignoring the escape character \\ and as such should be \ncounted as 2 code lines and 1 comment. Some tools are unable to\ndeal with this and instead count up to the \"1.0.0\" as a string which can cause the middle comment to be counted as\ncode rather than a comment.\n\n`scc` will also tell you the number of bytes it has processed (for most output formats) allowing you to estimate the\ncost of running some static analysis tools. \n\n### Usage\n\nCommand line usage of `scc` is designed to be as simple as possible.\nFull details can be found in `scc --help` or `scc -h`. Note that the below reflects the state of master not a release, as such\nfeatures listed below may be missing from your installation.\n\n```\n$ scc -h                                                                                      \nSloc, Cloc and Code. Count lines of code in a directory with complexity estimation.\nVersion 3.1.0\nBen Boyter <ben@boyter.org> + Contributors\n\nUsage:\n  scc [flags] [files or directories]\n\nFlags:\n      --avg-wage int                 average wage value used for basic COCOMO calculation (default 56286)\n      --binary                       disable binary file detection\n      --by-file                      display output for every file\n      --ci                           enable CI output settings where stdout is ASCII\n      --cocomo-project-type string   change COCOMO model type [organic, semi-detached, embedded, \"custom,1,1,1,1\"] (default \"organic\")\n      --count-as string              count extension as language [e.g. jsp:htm,chead:\"C Header\" maps extension jsp to html and chead to C Header]\n      --currency-symbol string       set currency symbol (default \"$\")\n      --debug                        enable debug output\n      --eaf float                    the effort adjustment factor derived from the cost drivers (1.0 if rated nominal) (default 1)\n      --exclude-dir strings          directories to exclude (default [.git,.hg,.svn])\n  -x, --exclude-ext strings          ignore file extensions (overrides include-ext) [comma separated list: e.g. go,java,js]\n      --file-gc-count int            number of files to parse before turning the GC on (default 10000)\n  -f, --format string                set output format [tabular, wide, json, csv, csv-stream, cloc-yaml, html, html-table, sql, sql-insert, openmetrics] (default \"tabular\")\n      --format-multi string          have multiple format output overriding --format [e.g. tabular:stdout,csv:file.csv,json:file.json]\n      --gen                          identify generated files\n      --generated-markers strings    string markers in head of generated files (default [do not edit,<auto-generated />])\n  -h, --help                         help for scc\n  -i, --include-ext strings          limit to file extensions [comma separated list: e.g. go,java,js]\n      --include-symlinks             if set will count symlink files\n  -l, --languages                    print supported languages and extensions\n      --large-byte-count int         number of bytes a file can contain before being removed from output (default 1000000)\n      --large-line-count int         number of lines a file can contain before being removed from output (default 40000)\n      --min                          identify minified files\n  -z, --min-gen                      identify minified or generated files\n      --min-gen-line-length int      number of bytes per average line for file to be considered minified or generated (default 255)\n      --no-cocomo                    remove COCOMO calculation output\n  -c, --no-complexity                skip calculation of code complexity\n  -d, --no-duplicates                remove duplicate files from stats and output\n      --no-gen                       ignore generated files in output (implies --gen)\n      --no-gitignore                 disables .gitignore file logic\n      --no-ignore                    disables .ignore file logic\n      --no-large                     ignore files over certain byte and line size set by max-line-count and max-byte-count\n      --no-min                       ignore minified files in output (implies --min)\n      --no-min-gen                   ignore minified or generated files in output (implies --min-gen)\n      --no-size                      remove size calculation output\n  -M, --not-match stringArray        ignore files and directories matching regular expression\n  -o, --output string                output filename (default stdout)\n      --overhead float               set the overhead multiplier for corporate overhead (facilities, equipment, accounting, etc.) (default 2.4)\n      --remap-all string             inspect every file and remap by checking for a string and remapping the language [e.g. \"-*- C++ -*-\":\"C Header\"]\n      --remap-unknown string         inspect files of unknown type and remap by checking for a string and remapping the language [e.g. \"-*- C++ -*-\":\"C Header\"]\n      --size-unit string             set size unit [si, binary, mixed, xkcd-kb, xkcd-kelly, xkcd-imaginary, xkcd-intel, xkcd-drive, xkcd-bakers] (default \"si\")\n      --sloccount-format             print a more SLOCCount like COCOMO calculation\n  -s, --sort string                  column to sort by [files, name, lines, blanks, code, comments, complexity] (default \"files\")\n      --sql-project string           use supplied name as the project identifier for the current run. Only valid with the --format sql or sql-insert option\n  -t, --trace                        enable trace output (not recommended when processing multiple files)\n  -v, --verbose                      verbose output\n      --version                      version for scc\n  -w, --wide                         wider output with additional statistics (implies --complexity)\n```\n\nOutput should look something like the below for the redis project\n\n```\n$ scc redis \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nLanguage                 Files     Lines   Blanks  Comments     Code Complexity\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nC                          296    180267    20367     31679   128221      32548\nC Header                   215     32362     3624      6968    21770       1636\nTCL                        143     28959     3130      1784    24045       2340\nShell                       44      1658      222       326     1110        187\nAutoconf                    22     10871     1038      1326     8507        953\nLua                         20       525       68        70      387         65\nMarkdown                    16      2595      683         0     1912          0\nMakefile                    11      1363      262       125      976         59\nRuby                        10       795       78        78      639        116\ngitignore                   10       162       16         0      146          0\nYAML                         6       711       46         8      657          0\nHTML                         5      9658     2928        12     6718          0\nC++                          4       286       48        14      224         31\nLicense                      4       100       20         0       80          0\nPlain Text                   3       185       26         0      159          0\nCMake                        2       214       43         3      168          4\nCSS                          2       107       16         0       91          0\nPython                       2       219       12         6      201         34\nSystemd                      2        80        6         0       74          0\nBASH                         1       118       14         5       99         31\nBatch                        1        28        2         0       26          3\nC++ Header                   1         9        1         3        5          0\nExtensible Styleshe\u2026         1        10        0         0       10          0\nSmarty Template              1        44        1         0       43          5\nm4                           1       562      116        53      393          0\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal                      823    271888    32767     42460   196661      38012\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nEstimated Cost to Develop (organic) $6,918,301\nEstimated Schedule Effort (organic) 28.682292 months\nEstimated People Required (organic) 21.428982\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nProcessed 9425137 bytes, 9.425 megabytes (SI)\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n```\n\nNote that you don't have to specify the directory you want to run against. Running `scc` will assume you want to run against the current directory.\n\nYou can also run against multiple files or directories `scc directory1 directory2 file1 file2` with the results aggregated in the output.\n\n### Ignore Files\n\n`scc` mostly supports .ignore files inside directories that it scans. This is similar to how ripgrep, ag and tokei work. .ignore files are 100% the same as .gitignore files with the same syntax, and as such `scc` will ignore files and directories listed in them. You can add .ignore files to ignore things like vendored dependency checked in files and such. The idea is allowing you to add a file or folder to git and have ignored in the count.\n\n### Interesting Use Cases\n\nUsed inside Intel Nemu Hypervisor to track code changes between revisions https://github.com/intel/nemu/blob/topic/virt-x86/tools/cloc-change.sh#L9\nAppears to also be used inside both http://codescoop.com/ https://pinpoint.com/ https://github.com/chaoss/grimoirelab-graal\n\nIt also is used to count code and guess language types in https://searchcode.com/ which makes it one of the most frequently run code counters in the world. \n\nYou can also hook scc into your gitlab pipeline https://gitlab.com/guided-explorations/ci-cd-plugin-extensions/ci-cd-plugin-extension-scc\n\nAlso used by CodeQL https://github.com/boyter/scc/pull/317 and Scaleway https://twitter.com/Scaleway/status/1488087029476995074?s=20&t=N2-z6O-ISDdDzULg4o4uVQ\n\n### Features\n\n`scc` uses a small state machine in order to determine what state the code is when it reaches a newline `\\n`. As such it is aware of and able to count\n\n - Single Line Comments\n - Multi Line Comments\n - Strings\n - Multi Line Strings\n - Blank lines\n\nBecause of this it is able to accurately determine if a comment is in a string or is actually a comment.\n\nIt also attempts to count the complexity of code. This is done by checking for branching operations in the code. For example, each of the following `for if switch while else || && != ==` if encountered in Java would increment that files complexity by one.\n\n### Complexity Estimates\n\nLets take a minute to discuss the complexity estimate itself.\n\nThe complexity estimate is really just a number that is only comparable to files in the same language. It should not be used to compare languages directly without weighting them. The reason for this is that its calculated by looking for branch and loop statements in the code and incrementing a counter for that file.\n\nBecause some languages don't have loops and instead use recursion they can have a lower complexity count. Does this mean they are less complex? Probably not, but the tool cannot see this because it does not build an AST of the code as it only scans through it.\n\nGenerally though the complexity there is to help estimate between projects written in the same language, or for finding the most complex file in a project `scc --by-file -s complexity` which can be useful when you are estimating on how hard something is to maintain, or when looking for those files that should probably be refactored.\n\n### COCOMO\n\nThe COCOMO statistics displayed at the bottom of any command line run can be configured as needed.\n\n```\nEstimated Cost to Develop (organic) $664,081\nEstimated Schedule Effort (organic) 11.772217 months\nEstimated People Required (organic) 5.011633\n```\n\nTo change the COCOMO parameters, you can either use one of the default COCOMO models.\n\n```\nscc --cocomo-project-type organic\nscc --cocomo-project-type semi-detached\nscc --cocomo-project-type embedded\n```\n\nYou can also supply your own parameters if you are familiar with COCOMO as follows,\n\n```\nscc --cocomo-project-type \"custom,1,1,1,1\"\n```\n\nSee below for details about how the model choices, and the parameters they use.\n\nOrganic \u2013 A software project is said to be an organic type if the team size required is adequately small, the\nproblem is well understood and has been solved in the past and also the team members have a nominal experience\nregarding the problem.\n\n`scc --cocomo-project-type \"organic,2.4,1.05,2.5,0.38\"`\n\nSemi-detached \u2013 A software project is said to be a Semi-detached type if the vital characteristics such as team-size,\nexperience, knowledge of the various programming environment lie in between that of organic and Embedded.\nThe projects classified as Semi-Detached are comparatively less familiar and difficult to develop compared to\nthe organic ones and require more experience and better guidance and creativity. Eg: Compilers or\ndifferent Embedded Systems can be considered of Semi-Detached type.\n\n`scc --cocomo-project-type \"semi-detached,3.0,1.12,2.5,0.35\"`\n\nEmbedded \u2013 A software project with requiring the highest level of complexity, creativity, and experience\nrequirement fall under this category. Such software requires a larger team size than the other two models\nand also the developers need to be sufficiently experienced and creative to develop such complex models.\n\n`scc --cocomo-project-type \"embedded,3.6,1.20,2.5,0.32\"`\n\n### Large File Detection\n\nYou can have `scc` exclude large files from the output. \n\nThe option to do so is `--no-large` which by default will exclude files over 1,000,000 bytes or 40,000 lines.\n\nYou can control the size of either value using `--large-byte-count` or `--large-line-count`.\n\nFor example to exclude files over 1,000 lines and 50kb you could use the following,\n\n`scc --no-large --large-byte-count 50000 --large-line-count 1000`\n\n### Minified/Generated File Detection\n\nYou can have `scc` identify and optionally remove files identified as being minified or generated from the output.\n\nYou can do so by enabling the `-z` flag like so `scc -z` which will identify any file with an average line byte size >= 255 (by default) as being minified.\n\nMinified files appear like so in the output.\n\n```\n$ scc --no-cocomo -z ./examples/minified/jquery-3.1.1.min.js\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nLanguage                 Files     Lines   Blanks  Comments     Code Complexity\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nJavaScript (min)             1         4        0         1        3         17\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal                        1         4        0         1        3         17\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nProcessed 86709 bytes, 0.087 megabytes (SI)\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n```\n\nMinified files are indicated with the text `(min)` after the language name.\n\nGenerated files are indicated with the text `(gen)` after the language name.\n\nYou can control the average line byte size using `--min-gen-line-length` such as `scc -z --min-gen-line-length 1`. Please note you need `-z` as modifying this value does not imply minified detection.\n\nYou can exclude minified files from the count totally using the flag `--no-min-gen`. Files which match the minified check will be excluded from the output.\n\n### Remapping\n\nSome files may not have an extension. They will be checked to see if they are a #! file. If they are then the language will be remapped to the \ncorrect language. Otherwise, it will not process.\n\nHowever, you may have the situation where you want to remap such files based on a string inside it. To do so you can use `--remap-unknown`\n\n```\n scc --remap-unknown \"-*- C++ -*-\":\"C Header\"\n```\n\nThe above will inspect any file with no extension looking for the string `-*- C++ -*-` and if found remap the file to be counted using the C Header rules. \nYou can have multiple remap rules if required,\n\n```\n scc --remap-unknown \"-*- C++ -*-\":\"C Header\",\"other\":\"Java\"\n```\n\nThere is also the `--remap-all` parameter which will remap all files.\n\nNote that in all cases if the remap rule does not apply normal #! rules will apply.\n\n### Output Formats\n\nBy default `scc` will output to the console. However you can produce output in other formats if you require.\n\nThe different options are `tabular, wide, json, csv, csv-stream, cloc-yaml, html, html-table, sql, sql-insert, openmetrics`. \n\nNote that you can write `scc` output to disk using the `-o, --output` option. This allows you to specify a file to\nwrite your output to. For example `scc -f html -o output.html` will run `scc` against the current directory, and output\nthe results in html to the file `output.html`.\n\nYou can also write to multiple output files, or multiple types to stdout if you want using the `--format-multi` option. This is \nmost useful when working in CI/CD systems where you want HTML reports as an artefact while also displaying the counts in stdout. \n\n```\nscc --format-multi \"tabular:stdout,html:output.html,csv:output.csv\"\n```\n\nThe above will run against the current directory, outputting to standard output the the default output, as well as writing\nto output.html and output.csv with the appropiate formats.\n\n#### Tabular \n\nThis is the default output format when scc is run.\n\n#### Wide \n\nWide produces some additional information which is the complexity/lines metric. This can be useful when trying to\nidentify the most complex file inside a project based on the complexity estimate.\n\n#### JSON\n\nJSON produces JSON output. Mostly designed to allow `scc` to feed into other programs.\n\nNote that this format will give you the byte size of every file it `scc` reads allowing you to get a breakdown of the\nnumber of bytes processed.\n\n#### CSV\n\nCSV as an option is good for importing into a spreadsheet for analysis. \n\nNote that this format will give you the byte size of every file it `scc` reads allowing you to get a breakdown of the\nnumber of bytes processed. Also note that CSV respects `--by-file` and as such will return a summary by default.\n\n#### CSV-Stream\n\ncsv-stream is an option useful for processing very large repositories where you are likely to run into memory issues. It's output format is 100% the same as CSV. \n\nNote that you should not use this with the `format-multi` option as it will always print to standard output, and because of how it works will negate the memory saving it normally gains.\nsavings that this option provides. Note that there is no sort applied with this option. \n\n#### cloc-yaml \n\nIs a drop in replacement for cloc using its yaml output option. This is quite often used for passing into other \nbuild systems and can help with replacing cloc if required.\n\n```\n$ scc -f cloc-yml processor\n# https://github.com/boyter/scc/\nheader:\n  url: https://github.com/boyter/scc/\n  version: 2.11.0\n  elapsed_seconds: 0.008\n  n_files: 21\n  n_lines: 6562\n  files_per_second: 2625\n  lines_per_second: 820250\nGo:\n  name: Go\n  code: 5186\n  comment: 273\n  blank: 1103\n  nFiles: 21\nSUM:\n  code: 5186\n  comment: 273\n  blank: 1103\n  nFiles: 21\n\n$ cloc --yaml processor\n      21 text files.\n      21 unique files.\n       0 files ignored.\n\n---\n# http://cloc.sourceforge.net\nheader :\n  cloc_url           : http://cloc.sourceforge.net\n  cloc_version       : 1.60\n  elapsed_seconds    : 0.196972846984863\n  n_files            : 21\n  n_lines            : 6562\n  files_per_second   : 106.613679608407\n  lines_per_second   : 33314.2364566841\nGo:\n  nFiles: 21\n  blank: 1137\n  comment: 606\n  code: 4819\nSUM:\n  blank: 1137\n  code: 4819\n  comment: 606\n  nFiles: 21\n```\n\n#### HTML and HTML-TABLE\n\nThe HTML output options produce a minimal html report using a table that is either standalone `html` or as just a table `html-table`\nwhich can be injected into your own HTML pages. The only difference between the two is that the `html` option includes \nhtml head and body tags with minimal styling.\n\nThe markup is designed to allow your own custom styles to be applied. An example report\n[is here to view](SCC-OUTPUT-REPORT.html).\n\nNote that the HTML options follow the command line options, so you can use `scc --by-file -f html` to produce a report with every\nfile and not just the summary.\n\nNote that this format if it has the `--by-file` option will give you the byte size of every file it `scc` reads allowing you to get a breakdown of the\nnumber of bytes processed.\n\n#### SQL and SQL-Insert\n\nThe SQL output format \"mostly\" compatible with cloc's SQL output format https://github.com/AlDanial/cloc#sql-\n\nWhile all queries on the cloc documentation should work as expected, you will not be able to append output from `scc` and `cloc` into the same database. This is because the table format is slightly different\nto account for scc including complexity counts and bytes.\n\nThe difference between `sql` and `sql-insert` is that `sql` will include table creation while the latter will only have the insert commands.\n\nUsage is 100% the same as any other `scc` command but sql output will always contain per file details. You can compute totals yourself using SQL.\n\nThe below will run scc against the current directory, name the ouput as the project scc and then pipe the output to sqlite to put into the database code.db\n\n```\nscc --format sql --sql-project scc . | sqlite3 code.db\n```\n\nAssuming you then wanted to append another project\n\n```\nscc --format sql-insert --sql-project redis . | sqlite3 code.db\n```\n\nYou could then run SQL against the database,\n\n```\nsqlite3 code.db 'select project,file,max(nCode) as nL from t\n                         group by project order by nL desc;'\n```\n\nSee the cloc documentation for more examples.\n\n\n#### OpenMetrics\n\n[OpenMetrics](https://openmetrics.io/) is a metric reporting format specification extending the Prometheus exposition text format.\n\nThe produced output is natively supported by [Prometheus](https://prometheus.io/) and [GitLab CI](https://docs.gitlab.com/ee/ci/metrics_reports.html)\n\nNote that OpenMetrics respects `--by-file` and as such will return a summary by default.\n\nThe output includes a metadata header containing definitions of the returned metrics: \n```text\n# TYPE scc_files count\n# HELP scc_files Number of sourcecode files.\n# TYPE scc_lines count\n# UNIT scc_lines lines\n# HELP scc_lines Number of lines.\n# TYPE scc_code count\n# UNIT scc_code lines\n# HELP scc_code Number of lines of actual code.\n# TYPE scc_comments count\n# HELP scc_comments Number of comments.\n# TYPE scc_blanks count\n# UNIT scc_blanks lines\n# HELP scc_blanks Number of blank lines.\n# TYPE scc_complexity count\n# UNIT scc_complexity lines\n# HELP scc_complexity Code complexity.\n# TYPE scc_bytes count\n# UNIT scc_bytes bytes\n# HELP scc_bytes Size in bytes.\n```\n\nThe header is followed by the metric data in either language summary form:\n```text\nscc_files{language=\"Go\"} 1\nscc_lines{language=\"Go\"} 1000\nscc_code{language=\"Go\"} 1000\nscc_comments{language=\"Go\"} 1000\nscc_blanks{language=\"Go\"} 1000\nscc_complexity{language=\"Go\"} 1000\nscc_bytes{language=\"Go\"} 1000\n```\n\nor, if `--by-file` is present, in per file form:\n```text\nscc_lines{language=\"Go\", file=\"./bbbb.go\"} 1000\nscc_code{language=\"Go\", file=\"./bbbb.go\"} 1000\nscc_comments{language=\"Go\", file=\"./bbbb.go\"} 1000\nscc_blanks{language=\"Go\", file=\"./bbbb.go\"} 1000\nscc_complexity{language=\"Go\", file=\"./bbbb.go\"} 1000\nscc_bytes{language=\"Go\", file=\"./bbbb.go\"} 1000\n```\n\n### Performance\n\nGenerally `scc` will the fastest code counter compared to any I am aware of and have compared against. The below comparisons are taken from the fastest alternative counters. See `Other similar projects` above to see all of the other code counters compared against. It is designed to scale to as many CPU's cores as you can provide.\n\nHowever if you want greater performance and you have RAM to spare you can disable the garbage collector like the following on linux `GOGC=-1 scc .` which should speed things up considerably. For some repositories turning off the code complexity calculation via `-c` can reduce runtime as well.\n\nBenchmarks are run on fresh 32 Core CPU Optimised Digital Ocean Virtual Machine 2022/09/20 all done using [hyperfine](https://github.com/sharkdp/hyperfine) with 3 warm-up runs and 10 timed runs.\n\n```\nscc v3.1.0\ntokei v12.1.2\nloc v0.5.0\npolyglot v0.5.29\n```\n\nSee https://github.com/boyter/scc/blob/master/benchmark.sh to see how the benchmarks are run.\n\n\n#### Redis https://github.com/antirez/redis/\n\n```shell\nBenchmark 1: scc redis\n  Time (mean \u00b1 \u03c3):      20.2 ms \u00b1   1.7 ms    [User: 127.1 ms, System: 47.0 ms]\n  Range (min \u2026 max):    16.8 ms \u2026  25.8 ms    132 runs\n \nBenchmark 2: scc -c redis\n  Time (mean \u00b1 \u03c3):      17.0 ms \u00b1   1.4 ms    [User: 91.6 ms, System: 32.7 ms]\n  Range (min \u2026 max):    14.3 ms \u2026  21.6 ms    169 runs\n \nBenchmark 3: tokei redis\n  Time (mean \u00b1 \u03c3):      33.7 ms \u00b1   5.0 ms    [User: 246.4 ms, System: 55.0 ms]\n  Range (min \u2026 max):    24.2 ms \u2026  47.5 ms    76 runs\n \nBenchmark 4: loc redis\n  Time (mean \u00b1 \u03c3):      36.9 ms \u00b1  30.6 ms    [User: 756.5 ms, System: 20.7 ms]\n  Range (min \u2026 max):     9.9 ms \u2026 123.9 ms    71 runs\n \nBenchmark 5: polyglot redis\n  Time (mean \u00b1 \u03c3):      21.8 ms \u00b1   0.9 ms    [User: 32.1 ms, System: 46.3 ms]\n  Range (min \u2026 max):    20.0 ms \u2026  28.4 ms    138 runs\n \nSummary\n  'scc -c redis' ran\n    1.19 \u00b1 0.14 times faster than 'scc redis'\n    1.28 \u00b1 0.12 times faster than 'polyglot redis'\n    1.98 \u00b1 0.33 times faster than 'tokei redis'\n    2.17 \u00b1 1.81 times faster than 'loc redis'\n```\n\n#### CPython https://github.com/python/cpython\n\n```shell\nBenchmark 1: scc cpython\n  Time (mean \u00b1 \u03c3):      52.6 ms \u00b1   3.8 ms    [User: 624.3 ms, System: 121.5 ms]\n  Range (min \u2026 max):    45.3 ms \u2026  62.3 ms    47 runs\n \nBenchmark 2: scc -c cpython\n  Time (mean \u00b1 \u03c3):      46.0 ms \u00b1   3.8 ms    [User: 468.0 ms, System: 111.2 ms]\n  Range (min \u2026 max):    40.0 ms \u2026  58.0 ms    67 runs\n \nBenchmark 3: tokei cpython\n  Time (mean \u00b1 \u03c3):     110.4 ms \u00b1   6.6 ms    [User: 1239.8 ms, System: 114.5 ms]\n  Range (min \u2026 max):    98.3 ms \u2026 123.6 ms    26 runs\n \nBenchmark 4: loc cpython\n  Time (mean \u00b1 \u03c3):      52.9 ms \u00b1  25.2 ms    [User: 1103.0 ms, System: 57.4 ms]\n  Range (min \u2026 max):    30.0 ms \u2026 118.9 ms    49 runs\n \nBenchmark 5: polyglot cpython\n  Time (mean \u00b1 \u03c3):      82.4 ms \u00b1   3.0 ms    [User: 153.3 ms, System: 168.8 ms]\n  Range (min \u2026 max):    74.8 ms \u2026  88.7 ms    36 runs\n \nSummary\n  'scc -c cpython' ran\n    1.14 \u00b1 0.13 times faster than 'scc cpython'\n    1.15 \u00b1 0.56 times faster than 'loc cpython'\n    1.79 \u00b1 0.16 times faster than 'polyglot cpython'\n    2.40 \u00b1 0.24 times faster than 'tokei cpython'\n```\n\n#### Linux Kernel https://github.com/torvalds/linux\n\n```shell\nBenchmark 1: scc linux\n  Time (mean \u00b1 \u03c3):     743.0 ms \u00b1  18.8 ms    [User: 17133.4 ms, System: 1280.2 ms]\n  Range (min \u2026 max):   709.4 ms \u2026 778.8 ms    10 runs\n \nBenchmark 2: scc -c linux\n  Time (mean \u00b1 \u03c3):     528.8 ms \u00b1  11.8 ms    [User: 10272.0 ms, System: 1236.9 ms]\n  Range (min \u2026 max):   508.9 ms \u2026 543.1 ms    10 runs\n \nBenchmark 3: tokei linux\n  Time (mean \u00b1 \u03c3):     736.5 ms \u00b1  18.2 ms    [User: 13098.3 ms, System: 2276.0 ms]\n  Range (min \u2026 max):   699.3 ms \u2026 760.8 ms    10 runs\n \nBenchmark 4: loc linux\n  Time (mean \u00b1 \u03c3):     567.1 ms \u00b1 113.4 ms    [User: 15984.5 ms, System: 1037.0 ms]\n  Range (min \u2026 max):   381.8 ms \u2026 656.3 ms    10 runs\n \nBenchmark 5: polyglot linux\n  Time (mean \u00b1 \u03c3):      1.241 s \u00b1  0.027 s    [User: 2.973 s, System: 2.636 s]\n  Range (min \u2026 max):    1.196 s \u2026  1.299 s    10 runs\n \nSummary\n  'scc -c linux' ran\n    1.07 \u00b1 0.22 times faster than 'loc linux'\n    1.39 \u00b1 0.05 times faster than 'tokei linux'\n    1.41 \u00b1 0.05 times faster than 'scc linux'\n    2.35 \u00b1 0.07 times faster than 'polyglot linux'\n```\n\nIf you enable duplicate detection expect performance to fall by about 20% in `scc`.\n\nPerformance is tracked over each release and presented below. Currently, the most recent release 3.1.0 is the fastest version.\n\n<img alt=\"scc\" src=https://github.com/boyter/scc/raw/master/performance-over-time.png>\n\nhttps://jsfiddle.net/m1w7kgqv/\n\n### CI/CD Support\n\nSome CI/CD systems which will remain nameless do not work very well with the box-lines used by `scc`. To support those systems better there is an option `--ci` which will change the default output to ASCII only.\n\n```\n$ scc --ci main.go\n-------------------------------------------------------------------------------\nLanguage                 Files     Lines   Blanks  Comments     Code Complexity\n-------------------------------------------------------------------------------\nGo                           1       272        7         6      259          4\n-------------------------------------------------------------------------------\nTotal                        1       272        7         6      259          4\n-------------------------------------------------------------------------------\nEstimated Cost to Develop $6,539\nEstimated Schedule Effort 2.268839 months\nEstimated People Required 0.341437\n-------------------------------------------------------------------------------\nProcessed 5674 bytes, 0.006 megabytes (SI)\n-------------------------------------------------------------------------------\n```\n\nThe `--format-multi` option is especially useful in CI/CD where you want to get multiple output formats useful for storage or reporting.\n\n### Development\n\nIf you want to hack away feel free! PR's are accepted. Some things to keep in mind. If you want to change a language definition you need to update `languages.json` and then run `go generate` which will convert it into the `processor/constants.go` file.\n\nFor all other changes ensure you run all tests before submitting. You can do so using `go test ./...`. However for maximum coverage please run `test-all.sh` which will run `gofmt`, unit tests, race detector and then all of the integration tests. All of those must pass to ensure a stable release.\n\n### API Support\n\nThe core part of `scc` which is the counting engine is exposed publicly to be integrated into other Go applications. See https://github.com/pinpt/ripsrc for an example of how to do this. \n\nIt also powers all of the code calculations displayed in https://searchcode.com/ such as https://searchcode.com/file/169350674/main.go/ making it one of the more used code counters in the world.\n\nHowever as a quick start consider the following,\n\nNote that you must pass in the number of bytes in the content in order to ensure it is counted!\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io/ioutil\"\n\n\t\"github.com/boyter/scc/v3/processor\"\n)\n\ntype statsProcessor struct{}\n\nfunc (p *statsProcessor) ProcessLine(job *processor.FileJob, currentLine int64, lineType processor.LineType) bool {\n\tswitch lineType {\n\tcase processor.LINE_BLANK:\n\t\tfmt.Println(currentLine, \"lineType\", \"BLANK\")\n\tcase processor.LINE_CODE:\n\t\tfmt.Println(currentLine, \"lineType\", \"CODE\")\n\tcase processor.LINE_COMMENT:\n\t\tfmt.Println(currentLine, \"lineType\", \"COMMENT\")\n\t}\n\treturn true\n}\n\nfunc main() {\n\tbts, _ := ioutil.ReadFile(\"somefile.go\")\n\n\tt := &statsProcessor{}\n\tfilejob := &processor.FileJob{\n\t\tFilename: \"test.go\",\n\t\tLanguage: \"Go\",\n\t\tContent:  bts,\n\t\tCallback: t,\n\t\tBytes:    int64(len(bts)),\n\t}\n\n\tprocessor.ProcessConstants() // Required to load the language information and need only be done once\n\tprocessor.CountStats(filejob)\n}\n```\n\n\n### Adding/Modifying Languages\n\nTo add or modify a language you will need to edit the `languages.json` file in the root of the project, and then run `go generate` to build it into the application. You can then `go install` or `go build` as normal to produce the binary with your modifications.\n\n### Issues\n\nIts possible that you may see the counts vary between runs. This usually means one of two things. Either something is changing or locking the files under scc, or that you are hitting ulimit restrictions. To change the ulimit see the following links.\n\n - https://superuser.com/questions/261023/how-to-change-default-ulimit-values-in-mac-os-x-10-6#306555\n - https://unix.stackexchange.com/questions/108174/how-to-persistently-control-maximum-system-resource-consumption-on-mac/221988#221988\n - https://access.redhat.com/solutions/61334\n - https://serverfault.com/questions/356962/where-are-the-default-ulimit-values-set-linux-centos\n - https://www.tecmint.com/increase-set-open-file-limits-in-linux/\n\nTo help identify this issue run scc like so `scc -v .` and look for the message `too many open files` in the output. If it is there you can rectify it by setting your ulimit to a higher value.\n\n### Low Memory\n\nIf you are running `scc` in a low memory environment < 512 MB of RAM you may need to set `--file-gc-count` to a lower value such as `0` to force the garbage collector to be on at all times.\n\nA sign that this is required will be `scc` crashing with panic errors.\n\n### Tests\n\nscc is pretty well tested with many unit, integration and benchmarks to ensure that it is fast and complete.\n\n### Package\n\nPackaging as of version v3.1.0 is done through https://goreleaser.com/ \n\n### Containers\n\nNote if you plan to run `scc` in Alpine containers you will need to build with CGO_ENABLED=0.\n\nSee the below dockerfile as an example on how to achieve this based on this issue https://github.com/boyter/scc/issues/208\n\n```\nFROM golang as scc-get\n\nENV GOOS=linux \\\nGOARCH=amd64 \\\nCGO_ENABLED=0\n\nARG VERSION\nRUN git clone --branch $VERSION --depth 1 https://github.com/boyter/scc\nWORKDIR /go/scc\nRUN go build -ldflags=\"-s -w\"\n\nFROM alpine\nCOPY --from=scc-get /go/scc/scc /bin/\nENTRYPOINT [\"scc\"]\n```\n\n### Badges (beta)\n\nYou can use `scc` to provide badges on your github/bitbucket/gitlab open repositories. For example, [![Scc Count Badge](https://sloc.xyz/github/boyter/scc/)](https://github.com/boyter/scc/)\n The format to do so is,\n\nhttps://sloc.xyz/PROVIDER/USER/REPO\n\nAn example of the badge for `scc` is included below, and is used on this page.\n\n```\n[![Scc Count Badge](https://sloc.xyz/github/boyter/scc/)](https://github.com/boyter/scc/)\n```\n\nBy default the badge will show the repo's lines count. You can also specify for it to show a different category, by using the `?category=` query string. \n\nValid values include `code, blanks, lines, comments, cocomo` and examples of the appearance are included below.\n\n[![Scc Count Badge](https://sloc.xyz/github/boyter/scc/?category=code)](https://github.com/boyter/scc/)\n[![Scc Count Badge](https://sloc.xyz/github/boyter/scc/?category=blanks)](https://github.com/boyter/scc/)\n[![Scc Count Badge](https://sloc.xyz/github/boyter/scc/?category=lines)](https://github.com/boyter/scc/)\n[![Scc Count Badge](https://sloc.xyz/github/boyter/scc/?category=comments)](https://github.com/boyter/scc/)\n[![Scc Count Badge](https://sloc.xyz/github/boyter/scc/?category=cocomo)](https://github.com/boyter/scc/)\n\n\nFor `cocomo` you can also set the `avg-wage` value similar to `scc` itself. For example,\n\nhttps://sloc.xyz/github/boyter/scc/?category=cocomo&avg-wage=1\nhttps://sloc.xyz/github/boyter/scc/?category=cocomo&avg-wage=100000 \n\nNote that the avg-wage value must be a positive integer otherwise it will revert back to the default value of 56286.\n\n*NB* it may not work for VERY large repositories (has been tested on Apache hadoop/spark without issue).\n\n### Languages\n\nList of supported languages. The master version of `scc` supports 239 languages at last count. Note that this is always assumed that you built from master, and it might trail behind what is actually supported. To see what your version of `scc` supports run `scc --languages`\n\n[Click here to view all languages supported by master](LANGUAGES.md)\n"
}